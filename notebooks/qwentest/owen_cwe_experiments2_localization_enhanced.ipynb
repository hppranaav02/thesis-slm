{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee33739a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This notebook lets you run a set of **experiments** for the Owen (Qwen 2.5 Coder) model on your Go CWE dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c9204",
   "metadata": {},
   "source": [
    "## 1) Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085e54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_AVAILABLE_DEVICES=1\n",
    "!TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bcc294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0+cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#For colab\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "except Exception as e:\n",
    "    print(\"PyTorch not found. It will be installed below.\")\n",
    "\n",
    "%pip -q install --upgrade pip\n",
    "%pip -q install \"transformers\" \"accelerate\" \"bitsandbytes\" \\\n",
    "                \"peft\" \"scikit-learn\" \"pandas\" \"matplotlib\" \\\n",
    "                \"numpy\" \"tqdm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb707e01",
   "metadata": {},
   "source": [
    "## 2) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78344525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/s3905020/slm-go/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os, random, time, json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup\n",
    "from transformers.utils import logging as hf_logging\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "# DATA_PATH = \"/local/s3905020/notebooks/qwentest/go_cwe_7k-augmented+real-v3.jsonl\"\n",
    "DATA_PATH = \"/local/s3905020/notebooks/qwentest/cwe_code_before_min100.jsonl\"\n",
    "OUTPUT_DIR = \"./owen_experiments_line\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Model hub id ----\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-Coder-1.5B\"\n",
    "# MODEL_NAME = \"Salesforce/codegen-350M-multi\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "USE_PREFIX_DEFAULT = True\n",
    "PROMPT_PREFIX = \"[LANG:go][TASK:CWE_CLASSIFICATION]\\n\"\n",
    "MAX_LENGTH = 1024 \n",
    "\n",
    "\n",
    "BATCH_SIZE = 4             \n",
    "GRAD_ACCUM_STEPS = 4       \n",
    "EPOCHS_HEAD = 4\n",
    "EPOCHS_LORA = 4\n",
    "LR_HEAD = 1e-3\n",
    "LR_LORA = 2e-4\n",
    "EARLY_STOP_PATIENCE = 2     \n",
    "VAL_EVAL_STEPS = None       \n",
    "\n",
    "#LoRA target modules\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda:1\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2328c",
   "metadata": {},
   "source": [
    "## 3) Load data & create stratified splits (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3757e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2860 records from /local/s3905020/notebooks/qwentest/cwe_code_before_min100.jsonl\n",
      "Num classes: 14\n",
      "Label -> idx map (first 10): [(22, 0), (59, 1), (78, 2), (79, 3), (89, 4), (94, 5), (129, 6), (200, 7), (269, 8), (319, 9)]\n",
      "Train/Val/Test sizes: 2001/430/429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "raw = read_jsonl(DATA_PATH)\n",
    "print(f\"Loaded {len(raw)} records from {DATA_PATH}\")\n",
    "\n",
    "#fields: 'code' (str), 'cwe' (int/str label id)\n",
    "codes, labels = [], []\n",
    "for r in raw:\n",
    "    code = r.get(\"code\") or r.get(\"text\") or \"\"\n",
    "    cwe = r.get(\"cwe\") or r.get(\"label\")\n",
    "    if code is None or cwe is None:\n",
    "        continue\n",
    "    codes.append(code)\n",
    "    labels.append(int(cwe))\n",
    "\n",
    "codes = np.array(codes)\n",
    "labels = np.array(labels)\n",
    "\n",
    "unique_labels = sorted(np.unique(labels).tolist())\n",
    "label2id = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
    "id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "y_indices = np.array([label2id[l] for l in labels])\n",
    "\n",
    "print(\"Num classes:\", len(unique_labels))\n",
    "print(\"Label -> idx map (first 10):\", list(label2id.items())[:10])\n",
    "\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=SEED)\n",
    "trainval_idx, test_idx = next(sss1.split(codes, y_indices))\n",
    "\n",
    "codes_trainval, y_trainval = codes[trainval_idx], y_indices[trainval_idx]\n",
    "codes_test, y_test = codes[test_idx], y_indices[test_idx]\n",
    "\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.1765, random_state=SEED)  \n",
    "train_idx, val_idx = next(sss2.split(codes_trainval, y_trainval))\n",
    "\n",
    "codes_train, y_train = codes_trainval[train_idx], y_trainval[train_idx]\n",
    "codes_val, y_val = codes_trainval[val_idx], y_trainval[val_idx]\n",
    "\n",
    "print(f\"Train/Val/Test sizes: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01deb2b",
   "metadata": {},
   "source": [
    "## 4) Tokenizer & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6a721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def build_input(code: str, use_prefix: bool) -> str:\n",
    "    # return (PROMPT_PREFIX + code) if use_prefix else code\n",
    "    return code\n",
    "\n",
    "class GoCweDataset(Dataset):\n",
    "    def __init__(self, texts, y, use_prefix=True):\n",
    "        self.texts = texts\n",
    "        self.y = y\n",
    "        self.use_prefix = use_prefix\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = build_input(self.texts[idx], self.use_prefix)\n",
    "        return {\"text\": text, \"label\": int(self.y[idx])}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    labels = torch.tensor([b[\"label\"] for b in batch], dtype=torch.long)\n",
    "    enc = tokenizer(texts, max_length=MAX_LENGTH, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return {\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"], \"labels\": labels}\n",
    "\n",
    "train_ds = GoCweDataset(codes_train, y_train, use_prefix=USE_PREFIX_DEFAULT)\n",
    "val_ds   = GoCweDataset(codes_val, y_val, use_prefix=USE_PREFIX_DEFAULT)\n",
    "test_ds  = GoCweDataset(codes_test, y_test, use_prefix=USE_PREFIX_DEFAULT)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd0981",
   "metadata": {},
   "source": [
    "## 5) Model wrapper (pooled hidden states + classification head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OwenClassifier(nn.Module):\n",
    "    def __init__(self, base_model, hidden_size: int, num_labels: int, pooling: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        self.pooling = pooling  \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, **kwargs):\n",
    "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True, **kwargs)\n",
    "        last_hidden = outputs.hidden_states[-1]\n",
    "\n",
    "        if self.pooling == \"mean\":\n",
    "            # masked mean\n",
    "            mask = attention_mask.unsqueeze(-1) \n",
    "            summed = torch.sum(last_hidden * mask, dim=1)\n",
    "            count = torch.clamp(mask.sum(dim=1), min=1)\n",
    "            pooled = summed / count\n",
    "        else:\n",
    "            # last valid token\n",
    "            lengths = attention_mask.sum(dim=1) - 1  \n",
    "            pooled = last_hidden[torch.arange(last_hidden.size(0), device=last_hidden.device), lengths]\n",
    "\n",
    "        pooled = pooled.to(self.classifier.weight.dtype)\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "def load_qwen_base_4bit(model_name: str):\n",
    "    base = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map={\"\": 1},\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_4bit=True\n",
    "    )\n",
    "    hidden_size = base.config.hidden_size\n",
    "    return base, hidden_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73292dca",
   "metadata": {},
   "source": [
    "## 6) Training & evaluation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b9912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_trainable(module: nn.Module, trainable: bool):\n",
    "    for p in module.parameters():\n",
    "        # p.requires_grad = trainable\n",
    "        if hasattr(p, \"dtype\") and (p.dtype.is_floating_point or p.is_complex()):\n",
    "            p.requires_grad = trainable\n",
    "\n",
    "def count_trainable_params(module: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, data_loader: DataLoader, num_labels: int) -> Dict[str, Any]:\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    inference_times = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        start = time.time()\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask, labels=None)\n",
    "        inference_times.append((time.time() - start) * 1000.0)\n",
    "\n",
    "        logits = out[\"logits\"]\n",
    "        all_logits.append(logits.detach().cpu().numpy())\n",
    "        all_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "    y_prob = (np.exp(all_logits - np.max(all_logits, axis=1, keepdims=True)))\n",
    "    y_prob = y_prob / np.sum(y_prob, axis=1, keepdims=True)\n",
    "\n",
    "    y_pred = np.argmax(all_logits, axis=1)\n",
    "    y_true = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0, labels=list(range(num_labels))\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_labels)))\n",
    "\n",
    "    per_class = {\n",
    "        int(id2label[i]): {\n",
    "            \"precision\": float(precision_per_class[i]),\n",
    "            \"recall\": float(recall_per_class[i]),\n",
    "            \"f1\": float(f1_per_class[i]),\n",
    "            \"support\": int(support_per_class[i]),\n",
    "        }\n",
    "        for i in range(num_labels)\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        \"y_true\": y_true.tolist(),\n",
    "        \"y_pred\": y_pred.tolist(),\n",
    "        \"y_prob\": y_prob.tolist(),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision_macro\": float(precision),\n",
    "        \"recall_macro\": float(recall),\n",
    "        \"f1_macro\": float(f1),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"per_class_metrics\": per_class,\n",
    "        \"inference_time_ms\": float(np.mean(inference_times)),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def save_results(run_name: str, results: Dict[str, Any]):\n",
    "    run_dir = os.path.join(OUTPUT_DIR, run_name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # JSON dump\n",
    "    with open(os.path.join(run_dir, \"eval_results.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # Per-class CSV\n",
    "    rows = []\n",
    "    for cwe, stats in results[\"per_class_metrics\"].items():\n",
    "        row = {\"cwe\": cwe, **stats}\n",
    "        rows.append(row)\n",
    "    df_pc = pd.DataFrame(rows).sort_values(\"cwe\")\n",
    "    df_pc.to_csv(os.path.join(run_dir, \"per_class_metrics.csv\"), index=False)\n",
    "\n",
    "    # Confusion matrix CSV\n",
    "    cm = np.array(results[\"confusion_matrix\"])\n",
    "    df_cm = pd.DataFrame(cm, index=[id2label[i] for i in range(cm.shape[0])],\n",
    "                            columns=[id2label[i] for i in range(cm.shape[1])])\n",
    "    df_cm.to_csv(os.path.join(run_dir, \"confusion_matrix.csv\"))\n",
    "\n",
    "    print(f\"Saved results to {run_dir}\")\n",
    "\n",
    "def plot_confusion_matrix(results: Dict[str, Any], title=\"Confusion Matrix\"):\n",
    "    cm = np.array(results[\"confusion_matrix\"])\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    tick_labels = [str(id2label[i]) for i in range(cm.shape[0])]\n",
    "    ax.set_xticks(range(cm.shape[1]))\n",
    "    ax.set_yticks(range(cm.shape[0]))\n",
    "    ax.set_xticklabels(tick_labels, rotation=90)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    fig.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_per_class_f1(results: Dict[str, Any], title=\"Per-class F1\"):\n",
    "    items = sorted(results[\"per_class_metrics\"].items(), key=lambda x: x[0])\n",
    "    labels = [str(k) for k, _ in items]\n",
    "    f1s = [v[\"f1\"] for _, v in items]\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(labels, f1s)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"CWE\")\n",
    "    ax.set_ylabel(\"F1\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cwe_accuracy_heatmap(results: Dict[str, Any], title=\"Per-CWE Accuracy Heatmap\"):\n",
    "    cm = np.array(results[\"confusion_matrix\"])\n",
    "    per_class_acc = np.diag(cm) / np.maximum(1, cm.sum(axis=1))\n",
    "    fig, ax = plt.subplots(figsize=(10, 2))\n",
    "    im = ax.imshow(per_class_acc.reshape(1, -1), aspect=\"auto\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(range(len(per_class_acc)))\n",
    "    ax.set_xticklabels([str(id2label[i]) for i in range(len(per_class_acc))], rotation=90)\n",
    "    fig.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import html\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "def _tokenize_with_offsets(text: str, max_length: int, tokenizer, add_prefix: bool) -> Dict[str, Any]:\n",
    "    t = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    offsets = t.pop(\"offset_mapping\")[0].tolist()\n",
    "    return t, offsets\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits(model, input_ids, attention_mask):\n",
    "    out = model(input_ids=input_ids, attention_mask=attention_mask, labels=None)\n",
    "    return out[\"logits\"]\n",
    "\n",
    "# Token level saliency\n",
    "def saliency_importance(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    raw_code: str,\n",
    "    use_prefix: bool = True,\n",
    "    target_class: int = None,\n",
    "    reduce: str = \"gradxabs\",   \n",
    ") -> Dict[str, Any]:\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    # text = (PROMPT_PREFIX + raw_code) if use_prefix else raw_code\n",
    "    text = raw_code\n",
    "    toks, offsets = _tokenize_with_offsets(text, MAX_LENGTH, tokenizer, add_prefix=use_prefix)\n",
    "    input_ids = toks[\"input_ids\"].to(device)\n",
    "    attention_mask = toks[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        emb_layer = model.base.get_input_embeddings()\n",
    "        inputs_embeds = emb_layer(input_ids).detach().requires_grad_(True)\n",
    "\n",
    "        out = model(\n",
    "            input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=None,\n",
    "            inputs_embeds=inputs_embeds \n",
    "        )\n",
    "        logits = out[\"logits\"]  \n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        pred_class = int(torch.argmax(probs, dim=-1)[0].item())\n",
    "        cls = target_class if target_class is not None else pred_class\n",
    "\n",
    "        score = probs[0, cls]\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        score.backward()\n",
    "        grads = inputs_embeds.grad.detach()[0]            \n",
    "        embs  = inputs_embeds.detach()[0]                 \n",
    "\n",
    "        if reduce == \"gradxabs\":\n",
    "            token_imp = (grads * embs).abs().sum(dim=-1)  \n",
    "        else:\n",
    "            token_imp = grads.norm(dim=-1)\n",
    "\n",
    "        token_imp = token_imp.cpu().numpy().tolist()\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"raw_code\": raw_code,\n",
    "        \"use_prefix\": use_prefix,\n",
    "        \"input_ids\": input_ids[0].detach().cpu().tolist(),\n",
    "        \"attention_mask\": attention_mask[0].detach().cpu().tolist(),\n",
    "        \"offsets\": offsets,                \n",
    "        \"token_importance\": token_imp,     \n",
    "        \"pred_class\": pred_class,\n",
    "        \"target_class\": cls,\n",
    "    }\n",
    "\n",
    "def _line_spans(s: str) -> List[Tuple[int,int]]:\n",
    "    spans = []\n",
    "    start = 0\n",
    "    for i, ch in enumerate(s):\n",
    "        if ch == \"\\n\":\n",
    "            spans.append((start, i))\n",
    "            start = i+1\n",
    "    spans.append((start, len(s)))\n",
    "    return spans\n",
    "\n",
    "# Convert token to line importance\n",
    "def aggregate_to_lines(sal: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    text = sal[\"text\"]\n",
    "    token_imp = sal[\"token_importance\"]\n",
    "    offsets = sal[\"offsets\"]\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    spans = _line_spans(text)\n",
    "\n",
    "    line_scores = [0.0] * len(spans)\n",
    "    for tok_i, imp in enumerate(token_imp):\n",
    "        start, end = offsets[tok_i]\n",
    "        if end <= start:\n",
    "            continue\n",
    "        for li, (ls, le) in enumerate(spans):\n",
    "            if end <= ls:\n",
    "                break\n",
    "            if start >= le:\n",
    "                continue\n",
    "            # overlap\n",
    "            line_scores[li] += float(imp)\n",
    "\n",
    "    mx = max(line_scores) if line_scores else 1.0\n",
    "    norm = [ (sc / mx) if mx > 0 else 0.0 for sc in line_scores ]\n",
    "\n",
    "    return {\n",
    "        **sal,\n",
    "        \"lines\": lines,\n",
    "        \"line_scores\": line_scores,\n",
    "        \"line_scores_norm\": norm,\n",
    "    }\n",
    "\n",
    "def top_k_lines(agg: Dict[str,Any], k: int = 5) -> List[Tuple[int,float,str]]:\n",
    "    pairs = [(i, agg[\"line_scores\"][i], agg[\"lines\"][i]) for i in range(len(agg[\"lines\"]))]\n",
    "    pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "    return pairs[:k]\n",
    "\n",
    "def show_highlight_html(agg: Dict[str,Any], threshold: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Returns HTML with lines background-highlighted by normalized importance.\n",
    "    Darker = more important.\n",
    "    \"\"\"\n",
    "    html_lines = []\n",
    "    for idx, (line, score) in enumerate(zip(agg[\"lines\"], agg[\"line_scores_norm\"])):\n",
    "        if score < threshold:\n",
    "            color = \"#ffffff\"\n",
    "        else:\n",
    "            alpha = score\n",
    "            r = 255\n",
    "            g = int(255 * (1.0 - 0.6*alpha))\n",
    "            b = int(255 * (1.0 - 0.6*alpha))\n",
    "            color = f\"rgb({r},{g},{b})\"\n",
    "        esc = html.escape(line).replace(\" \", \"&nbsp;\")\n",
    "        html_lines.append(f'<div style=\"background:{color}; font-family:monospace;\">{idx+1:>4}: {esc}</div>')\n",
    "    return \"\\n\".join(html_lines)\n",
    "\n",
    "def explain_example_by_index(ds: GoCweDataset, idx: int, model, tokenizer, use_prefix: bool = True, k: int = 5):\n",
    "    raw = ds.texts[idx]\n",
    "    sal = saliency_importance(model, tokenizer, raw, use_prefix=use_prefix)\n",
    "    agg = aggregate_to_lines(sal)\n",
    "    tk = top_k_lines(agg, k=k)\n",
    "\n",
    "    print(f\"Pred class: {agg['pred_class']} | Used prefix: {use_prefix} | Top-{k} lines:\")\n",
    "    for i, sc, ln in tk:\n",
    "        print(f\"{i+1:>4}  score={sc:.2f}  {ln[:120]}\")\n",
    "\n",
    "    from IPython.display import HTML, display\n",
    "    display(HTML(show_highlight_html(agg, threshold=0.5)))\n",
    "    return agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bd8d1",
   "metadata": {},
   "source": [
    "## 7) Run a single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f7cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(\n",
    "    mode: str = \"head_only\",    \n",
    "    pooling: str = \"mean\",       \n",
    "    use_prefix: bool = True,\n",
    "    lr: float = None,\n",
    "    epochs: int = None,\n",
    "    run_suffix: Optional[str] = None,\n",
    "):\n",
    "    assert mode in [\"head_only\", \"lora\"]\n",
    "    assert pooling in [\"mean\", \"last\"]\n",
    "\n",
    "    train_ds.use_prefix = use_prefix\n",
    "    val_ds.use_prefix = use_prefix\n",
    "    test_ds.use_prefix = use_prefix\n",
    "\n",
    "    base, hidden_size = load_qwen_base_4bit(MODEL_NAME)\n",
    "    model = OwenClassifier(base_model=base, hidden_size=hidden_size, num_labels=len(unique_labels), pooling=pooling).to(device)\n",
    "\n",
    "    if mode == \"head_only\":\n",
    "        set_trainable(model.base, False)\n",
    "        set_trainable(model.classifier, True)\n",
    "        set_trainable(model.dropout, True)\n",
    "        lr = lr or LR_HEAD\n",
    "        epochs = epochs or EPOCHS_HEAD\n",
    "        trainable_params = count_trainable_params(model)\n",
    "        print(f\"[HEAD-ONLY] Trainable params: {trainable_params:,} | LR={lr} | epochs={epochs}\")\n",
    "        optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    else:\n",
    "        set_trainable(model.base, True) \n",
    "        set_trainable(model.classifier, True)\n",
    "        lr = lr or LR_LORA\n",
    "        epochs = epochs or EPOCHS_LORA\n",
    "\n",
    "        model.base = prepare_model_for_kbit_training(model.base)\n",
    "        lconf = LoraConfig(\n",
    "            r=8, lora_alpha=16, target_modules=LORA_TARGET_MODULES, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        model.base = get_peft_model(model.base, lconf)\n",
    "        trainable_params = count_trainable_params(model)\n",
    "        print(f\"[LoRA] Trainable params: {trainable_params:,} | LR={lr} | epochs={epochs}\")\n",
    "        optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    batches_per_epoch = len(train_loader)\n",
    "    opt_steps_per_epoch = (batches_per_epoch + GRAD_ACCUM_STEPS - 1) // GRAD_ACCUM_STEPS\n",
    "    num_training_steps = opt_steps_per_epoch * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=max(1, int(0.03 * num_training_steps)),\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    best_val_f1 = -1.0\n",
    "    patience = EARLY_STOP_PATIENCE\n",
    "    global_opt_steps = 0\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss_sum = 0.0      \n",
    "        accum_steps = 0\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        for step, batch in enumerate(train_loader, start=1):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # forward\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss_raw = out[\"loss\"]                    \n",
    "            epoch_loss_sum += float(loss_raw.detach())\n",
    "\n",
    "            (loss_raw / GRAD_ACCUM_STEPS).backward()\n",
    "            accum_steps += 1\n",
    "\n",
    "            if accum_steps == GRAD_ACCUM_STEPS:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    (p for p in model.parameters() if p.requires_grad), 1.0\n",
    "                )\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                accum_steps = 0\n",
    "                global_opt_steps += 1\n",
    "\n",
    "        if accum_steps > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                (p for p in model.parameters() if p.requires_grad), 1.0\n",
    "            )\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            global_opt_steps += 1\n",
    "\n",
    "        train_loss_avg = epoch_loss_sum / batches_per_epoch\n",
    "        val_results = evaluate(model, val_loader, num_labels=len(unique_labels))\n",
    "        print(f\"Epoch {ep}: train_loss={train_loss_avg:.4f} | val_f1_macro={val_results['f1_macro']:.4f} | val_acc={val_results['accuracy']:.4f}\")\n",
    "        if val_results[\"f1_macro\"] > best_val_f1 + 1e-6:\n",
    "            best_val_f1 = val_results[\"f1_macro\"]\n",
    "            patience = EARLY_STOP_PATIENCE\n",
    "\n",
    "            run_tag = f\"{mode}_pool-{pooling}_prefix-{int(use_prefix)}\"\n",
    "            ckpt_dir = os.path.join(OUTPUT_DIR, \"ckpt_\" + run_tag)\n",
    "            os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "            if mode == \"head_only\":\n",
    "                torch.save({\"classifier\": model.classifier.state_dict()},\n",
    "                        os.path.join(ckpt_dir, \"head_only.pt\"))\n",
    "            else:\n",
    "                model.base.save_pretrained(os.path.join(ckpt_dir, \"peft_adapter\"))\n",
    "                torch.save({\"classifier\": model.classifier.state_dict()},\n",
    "                        os.path.join(ckpt_dir, \"head.pt\"))\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience <= 0:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    run_tag = f\"{mode}_pool-{pooling}_prefix-{int(use_prefix)}\"\n",
    "    ckpt_dir = os.path.join(OUTPUT_DIR, \"ckpt_\" + run_tag)\n",
    "\n",
    "    if mode == \"head_only\":\n",
    "        hp = os.path.join(ckpt_dir, \"head_only.pt\")\n",
    "        if os.path.exists(hp):\n",
    "            sd = torch.load(hp, map_location=device)\n",
    "            model.classifier.load_state_dict(sd[\"classifier\"])\n",
    "    else:\n",
    "        ap = os.path.join(ckpt_dir, \"peft_adapter\")\n",
    "        hp = os.path.join(ckpt_dir, \"head.pt\")\n",
    "        if os.path.exists(ap):\n",
    "            model.base = PeftModel.from_pretrained(model.base, ap)\n",
    "            model.base.to(device)\n",
    "        if os.path.exists(hp):\n",
    "            sd = torch.load(hp, map_location=device)\n",
    "            model.classifier.load_state_dict(sd[\"classifier\"])\n",
    "\n",
    "    test_results = evaluate(model, test_loader, num_labels=len(unique_labels))\n",
    "\n",
    "    suffix = run_suffix or f\"{mode}_pool-{pooling}_prefix-{int(use_prefix)}_lr-{lr}_ep-{epochs}\"\n",
    "    run_name = time.strftime(\"%Y%m%d_%H%M%S_\") + suffix\n",
    "    save_results(run_name, test_results)\n",
    "\n",
    "    # Plots\n",
    "    plot_confusion_matrix(test_results, title=f\"CM — {suffix}\")\n",
    "    plot_per_class_f1(test_results, title=f\"Per-class F1 — {suffix}\")\n",
    "    plot_cwe_accuracy_heatmap(test_results, title=f\"Per-CWE Accuracy — {suffix}\")\n",
    "\n",
    "    return run_name, test_results, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4bfa1",
   "metadata": {},
   "source": [
    "## 8) Suggested runs (you can modify as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04d107",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1) Head-only, mean pooling, prefix on\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m run_name, test_results, model = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhead_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 2) Head-only, last-token pooling, prefix on\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#run_experiment(mode=\"head_only\", pooling=\"last\", use_prefix=True, lr=1e-3, epochs=4)\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 5) Prompt prefix ablation (LoRA, mean pooling), prefix off\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#run_experiment(mode=\"lora\", pooling=\"mean\", use_prefix=False, lr=2e-4, epochs=4)\u001b[39;00m\n\u001b[32m     16\u001b[39m agg = explain_example_by_index(\n\u001b[32m     17\u001b[39m     test_ds, idx=\u001b[32m2\u001b[39m,\n\u001b[32m     18\u001b[39m     model=model, tokenizer=tokenizer,\n\u001b[32m     19\u001b[39m     use_prefix=USE_PREFIX_DEFAULT,\n\u001b[32m     20\u001b[39m     k=\u001b[32m6\u001b[39m\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(mode, pooling, use_prefix, lr, epochs, run_suffix)\u001b[39m\n\u001b[32m     13\u001b[39m val_ds.use_prefix = use_prefix\n\u001b[32m     14\u001b[39m test_ds.use_prefix = use_prefix\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m base, hidden_size = \u001b[43mload_qwen_base_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m model = OwenClassifier(base_model=base, hidden_size=hidden_size, num_labels=\u001b[38;5;28mlen\u001b[39m(unique_labels), pooling=pooling).to(device)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mhead_only\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mload_qwen_base_4bit\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_qwen_base_4bit\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     base = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     hidden_size = base.config.hidden_size\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m base, hidden_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/modeling_utils.py:4680\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4671\u001b[39m     gguf_file\n\u001b[32m   4672\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4673\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4674\u001b[39m ):\n\u001b[32m   4675\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4676\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4677\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4678\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4680\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4682\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4687\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4693\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4700\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4701\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/modeling_utils.py:1137\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m   1124\u001b[39m     cached_file_kwargs = {\n\u001b[32m   1125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n\u001b[32m   1126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1135\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n\u001b[32m   1136\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m   1140\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m   1142\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/utils/hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/utils/hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    485\u001b[39m         snapshot_download(\n\u001b[32m    486\u001b[39m             path_or_repo_id,\n\u001b[32m    487\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    497\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/huggingface_hub/file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    989\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    990\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1005\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1006\u001b[39m     )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/huggingface_hub/file_download.py:1161\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1174\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/huggingface_hub/file_download.py:1710\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1709\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1710\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1716\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1718\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/huggingface_hub/file_download.py:627\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m    625\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Head-only, mean pooling, prefix on\n",
    "run_name, test_results, model = run_experiment(mode=\"head_only\", pooling=\"mean\", use_prefix=False, lr=1e-3, epochs=4)\n",
    "\n",
    "# Head-only, last-token pooling, prefix on\n",
    "#run_experiment(mode=\"head_only\", pooling=\"last\", use_prefix=True, lr=1e-3, epochs=4)\n",
    "\n",
    "# LoRA, mean pooling, prefix on\n",
    "# run_name, test_results, model = run_experiment(mode=\"lora\", pooling=\"mean\", use_prefix=True, lr=2e-4, epochs=4)\n",
    "\n",
    "# LoRA, last-token pooling, prefix on\n",
    "#run_experiment(mode=\"lora\", pooling=\"last\", use_prefix=True, lr=2e-4, epochs=4)\n",
    "\n",
    "# Prompt prefix ablation (LoRA, mean pooling), prefix off\n",
    "#run_experiment(mode=\"lora\", pooling=\"mean\", use_prefix=False, lr=2e-4, epochs=4)\n",
    "\n",
    "agg = explain_example_by_index(\n",
    "    test_ds, idx=2,\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    use_prefix=USE_PREFIX_DEFAULT,\n",
    "    k=6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4ce87",
   "metadata": {},
   "source": [
    "## 9) Batch grid runner (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615f3b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN 1/1 :: {'mode': 'head_only', 'pooling': 'mean', 'use_prefix': False, 'lr': 0.001, 'epochs': 4} ===\n",
      "[HEAD-ONLY] Trainable params: 21,518 | LR=0.001 | epochs=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/s3905020/slm-go/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=nan | val_f1_macro=0.0133 | val_acc=0.1023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m#FUll run\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df_summary = \u001b[43mrun_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mrun_grid\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, cfg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(configs, \u001b[32m1\u001b[39m):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== RUN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(configs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m :: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     run_name, res, model = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     agg = explain_example_by_index(\n\u001b[32m     14\u001b[39m         test_ds, idx=\u001b[32m2\u001b[39m,\n\u001b[32m     15\u001b[39m         model=model, tokenizer=tokenizer,\n\u001b[32m     16\u001b[39m         use_prefix=USE_PREFIX_DEFAULT,\n\u001b[32m     17\u001b[39m         k=\u001b[32m6\u001b[39m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     19\u001b[39m     summary.append({\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: cfg[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m         ]\n\u001b[32m     35\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(mode, pooling, use_prefix, lr, epochs, run_suffix)\u001b[39m\n\u001b[32m     65\u001b[39m labels = batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m loss_raw = out[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]                    \n\u001b[32m     70\u001b[39m epoch_loss_sum += \u001b[38;5;28mfloat\u001b[39m(loss_raw.detach())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mOwenClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, labels=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     last_hidden = outputs.hidden_states[-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# [B, T, H]\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooling == \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;66;03m# masked mean\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:544\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    539\u001b[39m output_hidden_states = (\n\u001b[32m    540\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    541\u001b[39m )\n\u001b[32m    543\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:432\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    430\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:252\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m residual = hidden_states\n\u001b[32m    251\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    255\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:48\u001b[39m, in \u001b[36mQwen2MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) * \u001b[38;5;28mself\u001b[39m.up_proj(x))\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/slm-go/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:490\u001b[39m, in \u001b[36mLinear4bit.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    486\u001b[39m     x = x.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    488\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def run_grid():\n",
    "    configs = [\n",
    "        {\"mode\": \"head_only\", \"pooling\": \"mean\", \"use_prefix\": False,  \"lr\": 1e-3,  \"epochs\": 4},\n",
    "        # {\"mode\": \"head_only\", \"pooling\": \"last\", \"use_prefix\": True,  \"lr\": 1e-3,  \"epochs\": 4},\n",
    "        # {\"mode\": \"lora\",      \"pooling\": \"mean\", \"use_prefix\": True,  \"lr\": 2e-4,  \"epochs\": 4},\n",
    "        # {\"mode\": \"lora\",      \"pooling\": \"last\", \"use_prefix\": True,  \"lr\": 2e-4,  \"epochs\": 4},\n",
    "        # {\"mode\": \"lora\",      \"pooling\": \"mean\", \"use_prefix\": False, \"lr\": 1.5e-4,  \"epochs\": 4},\n",
    "    ]\n",
    "    summary = []\n",
    "    for i, cfg in enumerate(configs, 1):\n",
    "        print(f\"\\n=== RUN {i}/{len(configs)} :: {cfg} ===\")\n",
    "        run_name, res, model = run_experiment(**cfg)\n",
    "        agg = explain_example_by_index(\n",
    "            test_ds, idx=2,\n",
    "            model=model, tokenizer=tokenizer,\n",
    "            use_prefix=USE_PREFIX_DEFAULT,\n",
    "            k=6\n",
    "        )\n",
    "        summary.append({\n",
    "            \"run_name\": run_name,\n",
    "            \"mode\": cfg[\"mode\"],\n",
    "            \"pooling\": cfg[\"pooling\"],\n",
    "            \"use_prefix\": cfg[\"use_prefix\"],\n",
    "            \"lr\": cfg[\"lr\"],\n",
    "            \"epochs\": cfg[\"epochs\"],\n",
    "            \"accuracy\": res[\"accuracy\"],\n",
    "            \"precision_macro\": res[\"precision_macro\"],\n",
    "            \"recall_macro\": res[\"recall_macro\"],\n",
    "            \"f1_macro\": res[\"f1_macro\"],\n",
    "            \"inference_time_ms\": res[\"inference_time_ms\"],\n",
    "            \"top_k_lines\": [\n",
    "                {\"line_idx\": i, \"score\": float(sc), \"text\": ln}\n",
    "                for (i, sc, ln) in top_k_lines(agg, k=6)\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    df = pd.DataFrame(summary).sort_values(\"f1_macro\", ascending=False)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, \"grid_summary.csv\"), index=False)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "#FUll run\n",
    "df_summary = run_grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f0580",
   "metadata": {},
   "source": [
    "## 10) Load & compare saved runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_dir</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>inference_time_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251013_040818_head_only_pool-mean_prefix-1_l...</td>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.890104</td>\n",
       "      <td>0.882693</td>\n",
       "      <td>0.883287</td>\n",
       "      <td>63.225012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251013_053421_head_only_pool-mean_prefix-1_l...</td>\n",
       "      <td>0.879825</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.881469</td>\n",
       "      <td>0.881938</td>\n",
       "      <td>63.197354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251013_033951_head_only_pool-mean_prefix-1_l...</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.904780</td>\n",
       "      <td>0.884810</td>\n",
       "      <td>0.879047</td>\n",
       "      <td>68.975336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251013_042640_head_only_pool-mean_prefix-1_l...</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.879413</td>\n",
       "      <td>0.878881</td>\n",
       "      <td>63.573167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251013_055919_head_only_pool-mean_prefix-1_l...</td>\n",
       "      <td>0.885088</td>\n",
       "      <td>0.921673</td>\n",
       "      <td>0.885839</td>\n",
       "      <td>0.878014</td>\n",
       "      <td>63.375266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251013_060841_head_only_pool-last_prefix-1_l...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.869901</td>\n",
       "      <td>0.870554</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>61.563554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251013_051511_lora_pool-mean_prefix-1_lr-0.0...</td>\n",
       "      <td>0.125439</td>\n",
       "      <td>0.134968</td>\n",
       "      <td>0.114363</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>85.587590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             run_dir  accuracy  \\\n",
       "1  20251013_040818_head_only_pool-mean_prefix-1_l...  0.878947   \n",
       "4  20251013_053421_head_only_pool-mean_prefix-1_l...  0.879825   \n",
       "0  20251013_033951_head_only_pool-mean_prefix-1_l...  0.884211   \n",
       "2  20251013_042640_head_only_pool-mean_prefix-1_l...  0.877193   \n",
       "5  20251013_055919_head_only_pool-mean_prefix-1_l...  0.885088   \n",
       "6  20251013_060841_head_only_pool-last_prefix-1_l...  0.868421   \n",
       "3  20251013_051511_lora_pool-mean_prefix-1_lr-0.0...  0.125439   \n",
       "\n",
       "   precision_macro  recall_macro  f1_macro  inference_time_ms  \n",
       "1         0.890104      0.882693  0.883287          63.225012  \n",
       "4         0.886870      0.881469  0.881938          63.197354  \n",
       "0         0.904780      0.884810  0.879047          68.975336  \n",
       "2         0.881000      0.879413  0.878881          63.573167  \n",
       "5         0.921673      0.885839  0.878014          63.375266  \n",
       "6         0.869901      0.870554  0.868401          61.563554  \n",
       "3         0.134968      0.114363  0.046588          85.587590  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "def load_saved_results():\n",
    "    records = []\n",
    "    for run_dir in sorted(glob(f\"{OUTPUT_DIR}/*\")):\n",
    "        jr = os.path.join(run_dir, \"eval_results.json\")\n",
    "        if os.path.exists(jr):\n",
    "            with open(jr, \"r\", encoding=\"utf-8\") as f:\n",
    "                res = json.load(f)\n",
    "            meta = {\"run_dir\": run_dir}\n",
    "            \n",
    "            records.append({**meta, **res})\n",
    "    return records\n",
    "\n",
    "def compare_runs_table(records):\n",
    "    rows = []\n",
    "    for r in records:\n",
    "        \n",
    "        base = os.path.basename(r[\"run_dir\"])\n",
    "        rows.append({\n",
    "            \"run_dir\": base,\n",
    "            \"accuracy\": r[\"accuracy\"],\n",
    "            \"precision_macro\": r[\"precision_macro\"],\n",
    "            \"recall_macro\": r[\"recall_macro\"],\n",
    "            \"f1_macro\": r[\"f1_macro\"],\n",
    "            \"inference_time_ms\": r[\"inference_time_ms\"],\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"f1_macro\", ascending=False)\n",
    "    return df\n",
    "\n",
    "recs = load_saved_results()\n",
    "df = compare_runs_table(recs); df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824808ed",
   "metadata": {},
   "source": [
    "\n",
    "# Line Localization Metrics & Visualizations\n",
    "\n",
    "This section adds metrics and plots for line-level vulnerability localization.\n",
    "It expects your evaluation DataFrame \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dea4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from line_localization_metrics import (\n",
    "    compute_localization_metrics,\n",
    "    save_tables,\n",
    "    plot_distance_hist,\n",
    "    plot_distance_cdf,\n",
    "    plot_window_accuracy,\n",
    "    plot_by_cwe_bar,\n",
    "    plot_filelen_vs_error,\n",
    "    plot_hit_at_k,\n",
    ")\n",
    "\n",
    "LINE_LOC_FIG_DIR = \"./owen_experiments_line_figs\"\n",
    "os.makedirs(LINE_LOC_FIG_DIR, exist_ok=True\n",
    "# df_eval, df_test, eval_df, results_df.\n",
    "# EVAL_DF = None\n",
    "EVAL_DF = df_summary\n",
    "for name in [\"df_eval\", \"df_test\", \"eval_df\", \"results_df\"]:\n",
    "    if name in globals():\n",
    "        if isinstance(globals()[name], pd.DataFrame) and len(globals()[name]) > 0:\n",
    "            EVAL_DF = globals()[name]\n",
    "            print(f\"Using evaluation DataFrame: {name} with shape\", EVAL_DF.shape)\n",
    "            break\n",
    "\n",
    "if EVAL_DF is None:\n",
    "    print(\" Could not auto-detect an evaluation DataFrame. Set EVAL_DF = <your_dataframe> and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bff28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame must have columns 'true_lines' and 'pred_line'. Found: ['run_name', 'mode', 'pooling', 'use_prefix', 'lr', 'epochs', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'inference_time_ms', 'top_k_lines']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Compute localization metrics (edit column names if needed) ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m EVAL_DF \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     results = \u001b[43mcompute_localization_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEVAL_DF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpred_line\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# change if your column name differs\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue_lines\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# change if your column name differs\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrank_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpred_ranked_lines\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# optional\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwe_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcwe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# optional (for per-CWE aggregation)\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSummary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     display(results[\u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/s3905020/notebooks/qwentest/line_localization_metrics.py:110\u001b[39m, in \u001b[36mcompute_localization_metrics\u001b[39m\u001b[34m(df, pred_col, true_col, rank_col, cwe_col, window_set)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03mCompute sample-level and aggregate metrics for line localization.\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m  }\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m true_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;129;01mor\u001b[39;00m pred_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataFrame must have columns \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Normalize columns\u001b[39;00m\n\u001b[32m    113\u001b[39m dd = df.copy()\n",
      "\u001b[31mValueError\u001b[39m: DataFrame must have columns 'true_lines' and 'pred_line'. Found: ['run_name', 'mode', 'pooling', 'use_prefix', 'lr', 'epochs', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'inference_time_ms', 'top_k_lines']"
     ]
    }
   ],
   "source": [
    "\n",
    "if EVAL_DF is not None:\n",
    "    results = compute_localization_metrics(\n",
    "        EVAL_DF,\n",
    "        pred_col=\"pred_line\",         \n",
    "        true_col=\"true_lines\",\n",
    "        rank_col=\"pred_ranked_lines\",\n",
    "        cwe_col=\"cwe\", \n",
    "        window_set=(0, 1, 2, 3, 5, 10),\n",
    "    )\n",
    "    print(\"Summary:\")\n",
    "    display(results[\"summary\"])\n",
    "    if results[\"hit_at_k\"] is not None:\n",
    "        print(\"Hit@k:\")\n",
    "        display(results[\"hit_at_k\"])\n",
    "        print(\"MRR:\", results[\"mrr\"])\n",
    "else:\n",
    "    print(\"EVAL_DF is not set. Skipping metrics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d993da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if EVAL_DF is not None:\n",
    "    out_dir = os.path.join(\"/mnt/data/line_loc_figs\", \"tables\")\n",
    "    save_tables(results, out_dir)\n",
    "    print(\"Saved tables to:\", out_dir)\n",
    "else:\n",
    "    print(\"EVAL_DF is not set. Skipping save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if EVAL_DF is not None:\n",
    "    per_sample = results[\"per_sample\"]\n",
    "    by_cwe = results[\"by_cwe\"]\n",
    "    hit_at_k = results[\"hit_at_k\"]\n",
    "    mrr = results[\"mrr\"]\n",
    "\n",
    "    plot_distance_hist(per_sample, os.path.join(\"/mnt/data/line_loc_figs\", \"distance_hist.png\"))\n",
    "    plot_distance_cdf(per_sample, os.path.join(\"/mnt/data/line_loc_figs\", \"distance_cdf.png\"))\n",
    "    plot_window_accuracy(per_sample, os.path.join(\"/mnt/data/line_loc_figs\", \"accuracy_within_k.png\"))\n",
    "    plot_filelen_vs_error(per_sample, os.path.join(\"/mnt/data/line_loc_figs\", \"filelen_vs_error.png\"))\n",
    "    plot_hit_at_k(hit_at_k, mrr, os.path.join(\"/mnt/data/line_loc_figs\", \"hit_at_k.png\"))\n",
    "\n",
    "    if by_cwe is not None:\n",
    "        plot_by_cwe_bar(by_cwe, \"mean_abs_distance\", os.path.join(\"/mnt/data/line_loc_figs\", \"cwe_mean_distance_top20.png\"), top_n=20, sort_ascending=True)\n",
    "        plot_by_cwe_bar(by_cwe, \"exact_match_acc\", os.path.join(\"/mnt/data/line_loc_figs\", \"cwe_exact_match_top20.png\"), top_n=20, sort_ascending=False)\n",
    "        plot_by_cwe_bar(by_cwe, \"acc_within_±3\", os.path.join(\"/mnt/data/line_loc_figs\", \"cwe_acc_within_3_top20.png\"), top_n=20, sort_ascending=False)\n",
    "\n",
    "    print(\"Figures saved to:\", \"/mnt/data/line_loc_figs\")\n",
    "else:\n",
    "    print(\" EVAL_DF is not set. Skipping plots.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slm-go",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
