{"code": "func TestFindChartInAuthAndTLSAndPassRepoURL(t *testing.T) {\n\tsrv, err := startLocalTLSServerForTests(nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer srv.Close()\n\n\tchartURL, err := FindChartInAuthAndTLSAndPassRepoURL(srv.URL, \"\", \"\", \"nginx\", \"\", \"\", \"\", \"\", true, false, getter.All(&cli.EnvSettings{}))\n\tif err != nil {\n\t\tt.Fatalf(\"%v\", err)\n\t}\n\tif chartURL != \"https://charts.helm.sh/stable/nginx-0.2.0.tgz\" {\n\t\tt.Errorf(\"%s is not the valid URL\", chartURL)\n\t}\n\n\t// If the insecureSkipTLsverify is false, it will return an error that contains \"x509: certificate signed by unknown authority\".\n\t_, err = FindChartInAuthAndTLSAndPassRepoURL(srv.URL, \"\", \"\", \"nginx\", \"0.1.0\", \"\", \"\", \"\", false, false, getter.All(&cli.EnvSettings{}))\n\n\tif !strings.Contains(err.Error(), \"x509: certificate signed by unknown authority\") {\n\t\tt.Errorf(\"Expected TLS error for function  FindChartInAuthAndTLSAndPassRepoURL not found, but got a different error (%v)\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func WithinDuration(t TestingT, expected time.Time, actual time.Time, delta time.Duration, msgAndArgs ...interface{}) {\n\tif assert.WithinDuration(t, expected, actual, delta, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (c *CertChecker) CheckCert(principal string, cert *ssh.Certificate) error {\n\terr := c.validate(cert)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn c.CertChecker.CheckCert(principal, cert)\n}", "is_vulnerable": 1}
{"code": "func (m *KnownTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: KnownTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: KnownTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Dur\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Dur == nil {\n\t\t\t\tm.Dur = &types.Duration{}\n\t\t\t}\n\t\t\tif err := m.Dur.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Ts\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Ts == nil {\n\t\t\t\tm.Ts = &types.Timestamp{}\n\t\t\t}\n\t\t\tif err := m.Ts.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Dbl\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Dbl == nil {\n\t\t\t\tm.Dbl = &types.DoubleValue{}\n\t\t\t}\n\t\t\tif err := m.Dbl.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Flt\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Flt == nil {\n\t\t\t\tm.Flt = &types.FloatValue{}\n\t\t\t}\n\t\t\tif err := m.Flt.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field I64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.I64 == nil {\n\t\t\t\tm.I64 = &types.Int64Value{}\n\t\t\t}\n\t\t\tif err := m.I64.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field U64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.U64 == nil {\n\t\t\t\tm.U64 = &types.UInt64Value{}\n\t\t\t}\n\t\t\tif err := m.U64.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field I32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.I32 == nil {\n\t\t\t\tm.I32 = &types.Int32Value{}\n\t\t\t}\n\t\t\tif err := m.I32.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field U32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.U32 == nil {\n\t\t\t\tm.U32 = &types.UInt32Value{}\n\t\t\t}\n\t\t\tif err := m.U32.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Bool == nil {\n\t\t\t\tm.Bool = &types.BoolValue{}\n\t\t\t}\n\t\t\tif err := m.Bool.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Str == nil {\n\t\t\t\tm.Str = &types.StringValue{}\n\t\t\t}\n\t\t\tif err := m.Str.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Bytes == nil {\n\t\t\t\tm.Bytes = &types.BytesValue{}\n\t\t\t}\n\t\t\tif err := m.Bytes.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field St\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.St == nil {\n\t\t\t\tm.St = &types.Struct{}\n\t\t\t}\n\t\t\tif err := m.St.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func GetDNSKey() string {\n\tkey := \"\"\n\tif os.Getenv(\"DNS_KEY\") != \"\" {\n\t\tkey = os.Getenv(\"DNS_KEY\")\n\t} else if config.Config.Server.DNSKey != \"\" {\n\t\tkey = config.Config.Server.DNSKey\n\t}\n\treturn key\n}", "is_vulnerable": 0}
{"code": "func (a adminAPIHandlers) AddServiceAccount(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"AddServiceAccount\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\t// Get current object layer instance.\n\tobjectAPI := newObjectLayerFn()\n\tif objectAPI == nil || globalNotificationSys == nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL)\n\t\treturn\n\t}\n\n\tcred, claims, owner, s3Err := validateAdminSignature(ctx, r, \"\")\n\tif s3Err != ErrNone {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(s3Err), r.URL)\n\t\treturn\n\t}\n\n\tpassword := cred.SecretKey\n\treqBytes, err := madmin.DecryptData(password, io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErrWithErr(ErrAdminConfigBadJSON, err), r.URL)\n\t\treturn\n\t}\n\n\tvar createReq madmin.AddServiceAccountReq\n\tif err = json.Unmarshal(reqBytes, &createReq); err != nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErrWithErr(ErrAdminConfigBadJSON, err), r.URL)\n\t\treturn\n\t}\n\n\tvar (\n\t\ttargetUser   string\n\t\ttargetGroups []string\n\t)\n\n\t// If the request did not set a TargetUser, the service account is\n\t// created for the request sender.\n\ttargetUser = createReq.TargetUser\n\tif targetUser == \"\" {\n\t\ttargetUser = cred.AccessKey\n\t}\n\n\topts := newServiceAccountOpts{\n\t\taccessKey: createReq.AccessKey,\n\t\tsecretKey: createReq.SecretKey,\n\t\tclaims:    make(map[string]interface{}),\n\t}\n\n\t// Find the user for the request sender (as it may be sent via a service\n\t// account or STS account):\n\trequestorUser := cred.AccessKey\n\trequestorParentUser := cred.AccessKey\n\trequestorGroups := cred.Groups\n\trequestorIsDerivedCredential := false\n\tif cred.IsServiceAccount() || cred.IsTemp() {\n\t\trequestorParentUser = cred.ParentUser\n\t\trequestorIsDerivedCredential = true\n\t}\n\n\t// Check if we are creating svc account for request sender.\n\tisSvcAccForRequestor := false\n\tif targetUser == requestorUser || targetUser == requestorParentUser {\n\t\tisSvcAccForRequestor = true\n\t}\n\n\t// If we are creating svc account for request sender, ensure\n\t// that targetUser is a real user (i.e. not derived\n\t// credentials).\n\tif isSvcAccForRequestor {\n\t\t// Check if adding service account is explicitly denied.\n\t\t//\n\t\t// This allows turning off service accounts for request sender,\n\t\t// if there is no deny statement this call is implicitly enabled.\n\t\tif !globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     requestorUser,\n\t\t\tGroups:          requestorGroups,\n\t\t\tAction:          iampolicy.CreateServiceAccountAdminAction,\n\t\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t\tDenyOnly:        true,\n\t\t}) {\n\t\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrAccessDenied), r.URL)\n\t\t\treturn\n\t\t}\n\n\t\tif requestorIsDerivedCredential {\n\t\t\tif requestorParentUser == \"\" {\n\t\t\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx,\n\t\t\t\t\terrors.New(\"service accounts cannot be generated for temporary credentials without parent\")), r.URL)\n\t\t\t\treturn\n\t\t\t}\n\t\t\ttargetUser = requestorParentUser\n\t\t}\n\t\ttargetGroups = requestorGroups\n\n\t\t// In case of LDAP/OIDC we need to set `opts.claims` to ensure\n\t\t// it is associated with the LDAP/OIDC user properly.\n\t\tfor k, v := range cred.Claims {\n\t\t\tif k == expClaim {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\topts.claims[k] = v\n\t\t}\n\t} else {\n\t\t// Need permission if we are creating a service acccount for a\n\t\t// user <> to the request sender\n\t\tif !globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     requestorUser,\n\t\t\tGroups:          requestorGroups,\n\t\t\tAction:          iampolicy.CreateServiceAccountAdminAction,\n\t\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t\tDenyOnly:        true,\n\t\t}) {\n\t\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrAccessDenied), r.URL)\n\t\t\treturn\n\t\t}\n\n\t\t// In case of LDAP we need to resolve the targetUser to a DN and\n\t\t// query their groups:\n\t\tif globalLDAPConfig.Enabled {\n\t\t\topts.claims[ldapUserN] = targetUser // simple username\n\t\t\ttargetUser, targetGroups, err = globalLDAPConfig.LookupUserDN(targetUser)\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\t\t\treturn\n\t\t\t}\n\t\t\topts.claims[ldapUser] = targetUser // username DN\n\t\t}\n\n\t\t// NOTE: if not using LDAP, then internal IDP or open ID is\n\t\t// being used - in the former, group info is enforced when\n\t\t// generated credentials are used to make requests, and in the\n\t\t// latter, a group notion is not supported.\n\t}\n\n\tvar sp *iampolicy.Policy\n\tif len(createReq.Policy) > 0 {\n\t\tsp, err = iampolicy.ParseConfig(bytes.NewReader(createReq.Policy))\n\t\tif err != nil {\n\t\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\t\treturn\n\t\t}\n\t}\n\n\topts.sessionPolicy = sp\n\tnewCred, err := globalIAMSys.NewServiceAccount(ctx, targetUser, targetGroups, opts)\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\treturn\n\t}\n\n\t// Call hook for cluster-replication if the service account is not for a\n\t// root user.\n\tif newCred.ParentUser != globalActiveCred.AccessKey {\n\t\terr = globalSiteReplicationSys.IAMChangeHook(ctx, madmin.SRIAMItem{\n\t\t\tType: madmin.SRIAMItemSvcAcc,\n\t\t\tSvcAccChange: &madmin.SRSvcAccChange{\n\t\t\t\tCreate: &madmin.SRSvcAccCreate{\n\t\t\t\t\tParent:        newCred.ParentUser,\n\t\t\t\t\tAccessKey:     newCred.AccessKey,\n\t\t\t\t\tSecretKey:     newCred.SecretKey,\n\t\t\t\t\tGroups:        newCred.Groups,\n\t\t\t\t\tClaims:        opts.claims,\n\t\t\t\t\tSessionPolicy: createReq.Policy,\n\t\t\t\t\tStatus:        auth.AccountOn,\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\t\treturn\n\t\t}\n\t}\n\n\tcreateResp := madmin.AddServiceAccountResp{\n\t\tCredentials: madmin.Credentials{\n\t\t\tAccessKey: newCred.AccessKey,\n\t\t\tSecretKey: newCred.SecretKey,\n\t\t},\n\t}\n\n\tdata, err := json.Marshal(createResp)\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\treturn\n\t}\n\n\tencryptedData, err := madmin.EncryptData(password, data)\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\treturn\n\t}\n\n\twriteSuccessResponseJSON(w, encryptedData)\n}", "is_vulnerable": 1}
{"code": "func (ta *TaskArtifact) Validate() error {\n\t// Verify the source\n\tvar mErr multierror.Error\n\tif ta.GetterSource == \"\" {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"source must be specified\"))\n\t}\n\n\tswitch ta.GetterMode {\n\tcase \"\":\n\t\t// Default to any\n\t\tta.GetterMode = GetterModeAny\n\tcase GetterModeAny, GetterModeFile, GetterModeDir:\n\t\t// Ok\n\tdefault:\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid artifact mode %q; must be one of: %s, %s, %s\",\n\t\t\tta.GetterMode, GetterModeAny, GetterModeFile, GetterModeDir))\n\t}\n\n\tescaped, err := escapingfs.PathEscapesAllocViaRelative(\"task\", ta.RelativeDest)\n\tif err != nil {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid destination path: %v\", err))\n\t} else if escaped {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"destination escapes allocation directory\"))\n\t}\n\n\tif err := ta.validateChecksum(); err != nil {\n\t\tmErr.Errors = append(mErr.Errors, err)\n\t}\n\n\treturn mErr.ErrorOrNil()\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Impersonate(ctx context.Context, in *sliverpb.ImpersonateReq, opts ...grpc.CallOption) (*sliverpb.Impersonate, error) {\n\tout := new(sliverpb.Impersonate)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Impersonate\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func ExtractMessage(context string) (*model.Message, error) {\n\tvar msg model.Message\n\tif context == \"\" {\n\t\treturn &msg, errors.New(\"failed with error: context is empty\")\n\t}\n\terr := json.Unmarshal([]byte(context), &msg)\n\tif err != nil {\n\t\treturn &msg, err\n\t}\n\treturn &msg, nil\n}", "is_vulnerable": 0}
{"code": "func LoadDir(dirname string) (*Plugin, error) {\n\tdata, err := ioutil.ReadFile(filepath.Join(dirname, PluginFileName))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tplug := &Plugin{Dir: dirname}\n\tif err := yaml.Unmarshal(data, &plug.Metadata); err != nil {\n\t\treturn nil, err\n\t}\n\treturn plug, nil\n}", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) Touch(p string, flag int) (ufs.File, error) {\n\treturn fs.unixFS.Touch(p, flag, 0o644)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\treq := httptest.NewRequest(http.MethodGet, \"/foobar.html\", nil)\n\n\t\t\trw := httptest.NewRecorder()\n\n\t\t\ttest.handler.ServeHTTP(rw, req)\n\n\t\t\tassert.Equal(t, test.expected, rw.Code)\n\t\t\tassert.Equal(t, \"frame-src 'self' https://traefik.io https://*.traefik.io;\", rw.Result().Header.Get(\"Content-Security-Policy\"))\n\t\t})", "is_vulnerable": 0}
{"code": "func NewConnectionPool(address *url.URL, poolSize int) (*ConnectionPool, error) {\n\tcache, err := lru.NewWithEvict(poolSize, func(_, value interface{}) {\n\t\tconnectionPoolSize.Dec()\n\n\t\t// We attempt to gracefully close the connection\n\t\tconn, ok := value.(gitpod.APIInterface)\n\t\tif !ok {\n\t\t\tlog.Errorf(\"Failed to cast cache value to gitpod API Interface\")\n\t\t\treturn\n\t\t}\n\n\t\tcloseErr := conn.Close()\n\t\tif closeErr != nil {\n\t\t\tlog.Log.WithError(closeErr).Warn(\"Failed to close connection to server.\")\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create LRU cache: %w\", err)\n\t}\n\n\treturn &ConnectionPool{\n\t\tcache: cache,\n\t\tconnConstructor: func(ctx context.Context, token auth.Token) (gitpod.APIInterface, error) {\n\t\t\topts := gitpod.ConnectToServerOpts{\n\t\t\t\t// We're using Background context as we want the connection to persist beyond the lifecycle of a single request\n\t\t\t\tContext: context.Background(),\n\t\t\t\tLog:     log.Log,\n\t\t\t\tOrigin:  origin.FromContext(ctx),\n\t\t\t\tCloseHandler: func(_ error) {\n\t\t\t\t\tcache.Remove(token)\n\t\t\t\t\tconnectionPoolSize.Dec()\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tswitch token.Type {\n\t\t\tcase auth.AccessTokenType:\n\t\t\t\topts.Token = token.Value\n\t\t\tcase auth.CookieTokenType:\n\t\t\t\topts.Cookie = token.Value\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.New(\"unknown token type\")\n\t\t\t}\n\n\t\t\tendpoint, err := getEndpointBasedOnToken(token, address)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to construct endpoint: %w\", err)\n\t\t\t}\n\n\t\t\tconn, err := gitpod.ConnectToServer(endpoint, opts)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to create new connection to server: %w\", err)\n\t\t\t}\n\n\t\t\treturn conn, nil\n\t\t},\n\t}, nil\n\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"templates-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/test\", tempdir, false)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})", "is_vulnerable": 0}
{"code": "func authorizedForPolicy(info user.Info, policy *extensions.PodSecurityPolicy, authz authorizer.Authorizer) bool {\n\tif info == nil {\n\t\treturn false\n\t}\n\tattr := buildAttributes(info, policy)\n\tallowed, _, _ := authz.Authorize(attr)\n\treturn allowed\n}", "is_vulnerable": 0}
{"code": "func TestGetConsenterMetadataFromBlock(t *testing.T) {\n\tvar cases = []struct {\n\t\tname       string\n\t\tvalue      []byte\n\t\tsignatures []byte\n\t\torderer    []byte\n\t\tpass       bool\n\t}{\n\t\t{\n\t\t\tname:       \"empty\",\n\t\t\tvalue:      nil,\n\t\t\tsignatures: nil,\n\t\t\torderer:    nil,\n\t\t\tpass:       true,\n\t\t},\n\t\t{\n\t\t\tname:  \"signature only\",\n\t\t\tvalue: []byte(\"hello\"),\n\t\t\tsignatures: protoutil.MarshalOrPanic(&cb.Metadata{\n\t\t\t\tValue: protoutil.MarshalOrPanic(&cb.OrdererBlockMetadata{\n\t\t\t\t\tConsenterMetadata: protoutil.MarshalOrPanic(&cb.Metadata{Value: []byte(\"hello\")}),\n\t\t\t\t}),\n\t\t\t}),\n\t\t\torderer: nil,\n\t\t\tpass:    true,\n\t\t},\n\t\t{\n\t\t\tname:       \"orderer only\",\n\t\t\tvalue:      []byte(\"hello\"),\n\t\t\tsignatures: nil,\n\t\t\torderer:    protoutil.MarshalOrPanic(&cb.Metadata{Value: []byte(\"hello\")}),\n\t\t\tpass:       true,\n\t\t},\n\t\t{\n\t\t\tname:  \"both signatures and orderer\",\n\t\t\tvalue: []byte(\"hello\"),\n\t\t\tsignatures: protoutil.MarshalOrPanic(&cb.Metadata{\n\t\t\t\tValue: protoutil.MarshalOrPanic(&cb.OrdererBlockMetadata{\n\t\t\t\t\tConsenterMetadata: protoutil.MarshalOrPanic(&cb.Metadata{Value: []byte(\"hello\")}),\n\t\t\t\t}),\n\t\t\t}),\n\t\t\torderer: protoutil.MarshalOrPanic(&cb.Metadata{Value: []byte(\"hello\")}),\n\t\t\tpass:    true,\n\t\t},\n\t\t{\n\t\t\tname:       \"malformed OrdererBlockMetadata\",\n\t\t\tsignatures: protoutil.MarshalOrPanic(&cb.Metadata{Value: []byte(\"malformed\")}),\n\t\t\torderer:    nil,\n\t\t\tpass:       false,\n\t\t},\n\t}\n\n\tfor _, test := range cases {\n\t\tblock := protoutil.NewBlock(0, nil)\n\t\tblock.Metadata.Metadata[cb.BlockMetadataIndex_SIGNATURES] = test.signatures\n\t\tblock.Metadata.Metadata[cb.BlockMetadataIndex_ORDERER] = test.orderer\n\t\tresult, err := protoutil.GetConsenterMetadataFromBlock(block)\n\n\t\tif test.pass {\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Equal(t, result.Value, test.value)\n\t\t} else {\n\t\t\trequire.Error(t, err)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestStore_EnsureService_DoesNotPanicOnIngressGateway(t *testing.T) {\n\tstore := NewStateStore(nil)\n\n\terr := store.EnsureConfigEntry(1, &structs.IngressGatewayConfigEntry{\n\t\tKind: structs.IngressGateway,\n\t\tName: \"the-ingress\",\n\t\tListeners: []structs.IngressListener{\n\t\t\t{\n\t\t\t\tPort:     12345,\n\t\t\t\tProtocol: \"tcp\",\n\t\t\t\tServices: []structs.IngressService{{Name: \"the-service\"}},\n\t\t\t},\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\terr = store.EnsureRegistration(2, &structs.RegisterRequest{\n\t\tNode: \"the-node\",\n\t\tService: &structs.NodeService{\n\t\t\tKind:    structs.ServiceKindConnectProxy,\n\t\t\tService: \"the-proxy\",\n\t\t\tProxy: structs.ConnectProxyConfig{\n\t\t\t\tDestinationServiceName: \"the-ingress\",\n\t\t\t\tUpstreams: []structs.Upstream{\n\t\t\t\t\t{\n\t\t\t\t\t\tDestinationName: \"the-service\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func TestPrometheusTimeoutHTTP(t *testing.T) {\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttime.Sleep(2 * time.Second)\n\t}))\n\tdefer ts.Close()\n\n\treq, err := http.NewRequest(\"GET\", \"?target=\"+ts.URL, nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treq.Header.Set(\"X-Prometheus-Scrape-Timeout-Seconds\", \"1\")\n\n\trr := httptest.NewRecorder()\n\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil)\n\t})\n\n\thandler.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tt.Errorf(\"probe request handler returned wrong status code: %v, want %v\", status, http.StatusOK)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CrackFileChunkUpload(ctx context.Context, in *clientpb.CrackFileChunk, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CrackFileChunkUpload_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestInvalidCSV(t *testing.T) {\n\ttestCases := []struct {\n\t\tinput string\n\t\terr   string\n\t}{\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = ''\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` must not be empty\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = 'hello'\n\t\t\t\tdelimiter = 'hel'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = 'hel'\n\t\t\t\tdelimiter = 'hello'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\'\n\t\t\t\tbackslash-escape = false\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\uff0c'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = ''\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = 'hello'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = '\\'\n\t\t\t\tbackslash-escape = false\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\s'\n\t\t\t\tdelimiter = '\\d'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '|'\n\t\t\t\tdelimiter = '|'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\'\n\t\t\t\tbackslash-escape = true\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]cannot use '\\\\' as CSV separator when `mydumper.csv.backslash-escape` is true\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = '\\'\n\t\t\t\tbackslash-escape = true\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]cannot use '\\\\' as CSV delimiter when `mydumper.csv.backslash-escape` is true\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[tidb]\n\t\t\t\tsql-mode = \"invalid-sql-mode\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.tidb.sql_mode` must be a valid SQL_MODE: ERROR 1231 (42000): Variable 'sql_mode' can't be set to the value of 'invalid-sql-mode'\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[[routes]]\n\t\t\t\tschema-pattern = \"\"\n\t\t\t\ttable-pattern = \"shard_table_*\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]file route rule is invalid: schema pattern of table route rule should not be empty\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[[routes]]\n\t\t\t\tschema-pattern = \"schema_*\"\n\t\t\t\ttable-pattern = \"\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]file route rule is invalid: target schema of table route rule should not be empty\",\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tcomment := fmt.Sprintf(\"input = %s\", tc.input)\n\t\tcfg := config.NewConfig()\n\t\tcfg.Mydumper.SourceDir = \"file://.\"\n\t\tcfg.TiDB.Port = 4000\n\t\tcfg.TiDB.PdAddr = \"test.invalid:2379\"\n\t\tcfg.TikvImporter.Backend = config.BackendLocal\n\t\tcfg.TikvImporter.SortedKVDir = \".\"\n\t\tcfg.TiDB.DistSQLScanConcurrency = 1\n\t\terr := cfg.LoadFromTOML([]byte(tc.input))\n\t\trequire.NoError(t, err)\n\n\t\terr = cfg.Adjust(context.Background())\n\t\tif tc.err != \"\" {\n\t\t\trequire.EqualError(t, err, tc.err, comment)\n\t\t} else {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\t}\n}\n\nfunc TestInvalidTOML(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\tinvalid[mydumper.csv]\n\t\tdelimiter = '\\'\n\t\tbackslash-escape = true\n\t`))\n\trequire.EqualError(t, err, \"toml: line 2: expected '.' or '=', but got '[' instead\")\n}\n\nfunc TestTOMLUnusedKeys(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\t[lightning]\n\t\ttypo = 123\n\t`))\n\trequire.EqualError(t, err, \"config file contained unknown configuration options: lightning.typo\")\n}\n\nfunc TestDurationUnmarshal(t *testing.T) {\n\tduration := config.Duration{}\n\terr := duration.UnmarshalText([]byte(\"13m20s\"))\n\trequire.NoError(t, err)\n\trequire.Equal(t, 13*60+20.0, duration.Duration.Seconds())\n\terr = duration.UnmarshalText([]byte(\"13x20s\"))\n\trequire.Error(t, err)\n\trequire.Regexp(t, \"time: unknown unit .?x.? in duration .?13x20s.?\", err.Error())\n}\n\nfunc TestDurationMarshalJSON(t *testing.T) {\n\tduration := config.Duration{}\n\terr := duration.UnmarshalText([]byte(\"13m20s\"))\n\trequire.NoError(t, err)\n\trequire.Equal(t, 13*60+20.0, duration.Duration.Seconds())\n\tresult, err := duration.MarshalJSON()\n\trequire.NoError(t, err)\n\trequire.Equal(t, `\"13m20s\"`, string(result))\n}\n\nfunc TestDuplicateResolutionAlgorithm(t *testing.T) {\n\tvar dra config.DuplicateResolutionAlgorithm\n\trequire.NoError(t, dra.FromStringValue(\"record\"))\n\trequire.Equal(t, config.DupeResAlgRecord, dra)\n\trequire.NoError(t, dra.FromStringValue(\"none\"))\n\trequire.Equal(t, config.DupeResAlgNone, dra)\n\trequire.NoError(t, dra.FromStringValue(\"remove\"))\n\trequire.Equal(t, config.DupeResAlgRemove, dra)\n\n\trequire.Equal(t, \"record\", config.DupeResAlgRecord.String())\n\trequire.Equal(t, \"none\", config.DupeResAlgNone.String())\n\trequire.Equal(t, \"remove\", config.DupeResAlgRemove.String())\n}\n\nfunc TestLoadConfig(t *testing.T) {\n\tcfg, err := config.LoadGlobalConfig([]string{\"-tidb-port\", \"sss\"}, nil)\n\trequire.EqualError(t, err, `[Lightning:Common:ErrInvalidArgument]invalid argument: invalid value \"sss\" for flag -tidb-port: parse error`)\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"-V\"}, nil)\n\trequire.Equal(t, flag.ErrHelp, err)\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"-config\", \"not-exists\"}, nil)\n\trequire.Error(t, err)\n\trequire.Regexp(t, \".*(no such file or directory|The system cannot find the file specified).*\", err.Error())\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"--server-mode\"}, nil)\n\trequire.EqualError(t, err, \"[Lightning:Config:ErrInvalidConfig]If server-mode is enabled, the status-addr must be a valid listen address\")\n\trequire.Nil(t, cfg)\n\n\tpath, _ := filepath.Abs(\".\")\n\tcfg, err = config.LoadGlobalConfig([]string{\n\t\t\"-L\", \"debug\",\n\t\t\"-log-file\", \"/path/to/file.log\",\n\t\t\"-tidb-host\", \"172.16.30.11\",\n\t\t\"-tidb-port\", \"4001\",\n\t\t\"-tidb-user\", \"guest\",\n\t\t\"-tidb-password\", \"12345\",\n\t\t\"-pd-urls\", \"172.16.30.11:2379,172.16.30.12:2379\",\n\t\t\"-d\", path,\n\t\t\"-backend\", config.BackendLocal,\n\t\t\"-sorted-kv-dir\", \".\",\n\t\t\"-checksum=false\",\n\t}, nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"debug\", cfg.App.Config.Level)\n\trequire.Equal(t, \"/path/to/file.log\", cfg.App.Config.File)\n\trequire.Equal(t, \"172.16.30.11\", cfg.TiDB.Host)\n\trequire.Equal(t, 4001, cfg.TiDB.Port)\n\trequire.Equal(t, \"guest\", cfg.TiDB.User)\n\trequire.Equal(t, \"12345\", cfg.TiDB.Psw)\n\trequire.Equal(t, \"172.16.30.11:2379,172.16.30.12:2379\", cfg.TiDB.PdAddr)\n\trequire.Equal(t, path, cfg.Mydumper.SourceDir)\n\trequire.Equal(t, config.BackendLocal, cfg.TikvImporter.Backend)\n\trequire.Equal(t, \".\", cfg.TikvImporter.SortedKVDir)\n\trequire.Equal(t, config.OpLevelOff, cfg.PostRestore.Checksum)\n\trequire.Equal(t, config.OpLevelOptional, cfg.PostRestore.Analyze)\n\n\ttaskCfg := config.NewConfig()\n\terr = taskCfg.LoadFromGlobal(cfg)\n\trequire.NoError(t, err)\n\trequire.Equal(t, config.OpLevelOff, taskCfg.PostRestore.Checksum)\n\trequire.Equal(t, config.OpLevelOptional, taskCfg.PostRestore.Analyze)\n\n\ttaskCfg.Checkpoint.DSN = \"\"\n\ttaskCfg.Checkpoint.Driver = config.CheckpointDriverMySQL\n\ttaskCfg.TiDB.DistSQLScanConcurrency = 1\n\terr = taskCfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\tequivalentDSN := taskCfg.Checkpoint.MySQLParam.ToDriverConfig().FormatDSN()\n\texpectedDSN := \"guest:12345@tcp(172.16.30.11:4001)/?tls=false&maxAllowedPacket=67108864&charset=utf8mb4&sql_mode=%27ONLY_FULL_GROUP_BY%2CSTRICT_TRANS_TABLES%2CNO_ZERO_IN_DATE%2CNO_ZERO_DATE%2CERROR_FOR_DIVISION_BY_ZERO%2CNO_AUTO_CREATE_USER%2CNO_ENGINE_SUBSTITUTION%27\"\n\trequire.Equal(t, expectedDSN, equivalentDSN)\n\n\tresult := taskCfg.String()\n\trequire.Regexp(t, `.*\"pd-addr\":\"172.16.30.11:2379,172.16.30.12:2379\".*`, result)\n\n\tcfg, err = config.LoadGlobalConfig([]string{}, nil)\n\trequire.NoError(t, err)\n\trequire.Regexp(t, \".*lightning.log.*\", cfg.App.Config.File)\n\tcfg, err = config.LoadGlobalConfig([]string{\"--log-file\", \"-\"}, nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"-\", cfg.App.Config.File)\n}\n\nfunc TestDefaultImporterBackendValue(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"local\"\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, cfg.App.IndexConcurrency)\n\trequire.Equal(t, 6, cfg.App.TableConcurrency)\n}\n\nfunc TestDefaultTidbBackendValue(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"tidb\"\n\tcfg.App.RegionConcurrency = 123\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 123, cfg.App.TableConcurrency)\n}\n\nfunc TestDefaultCouldBeOverwritten(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"local\"\n\tcfg.App.IndexConcurrency = 20\n\tcfg.App.TableConcurrency = 60\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 20, cfg.App.IndexConcurrency)\n\trequire.Equal(t, 60, cfg.App.TableConcurrency)\n}\n\nfunc TestLoadFromInvalidConfig(t *testing.T) {\n\ttaskCfg := config.NewConfig()\n\terr := taskCfg.LoadFromGlobal(&config.GlobalConfig{\n\t\tConfigFileContent: []byte(\"invalid toml\"),\n\t})\n\trequire.Error(t, err)\n\trequire.Regexp(t, \"line 1.*\", err.Error())\n}\n\nfunc TestTomlPostRestore(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\t[post-restore]\n\t\tchecksum = \"req\"\n\t`))\n\trequire.EqualError(t, err, \"invalid op level 'req', please choose valid option between ['off', 'optional', 'required']\")\n\n\terr = cfg.LoadFromTOML([]byte(`\n\t\t[post-restore]\n\t\tanalyze = 123\n\t`))\n\trequire.EqualError(t, err, \"invalid op level '123', please choose valid option between ['off', 'optional', 'required']\")\n\n\tkvMap := map[string]config.PostOpLevel{\n\t\t`\"off\"`:      config.OpLevelOff,\n\t\t`\"required\"`: config.OpLevelRequired,\n\t\t`\"optional\"`: config.OpLevelOptional,\n\t\t\"true\":       config.OpLevelRequired,\n\t\t\"false\":      config.OpLevelOff,\n\t}\n\n\tvar b bytes.Buffer\n\tenc := toml.NewEncoder(&b)\n\n\tfor k, v := range kvMap {\n\t\tcfg := &config.Config{}\n\t\tconfStr := fmt.Sprintf(\"[post-restore]\\r\\nchecksum= %s\\r\\n\", k)\n\t\terr := cfg.LoadFromTOML([]byte(confStr))\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, v, cfg.PostRestore.Checksum)\n\n\t\tb.Reset()\n\t\trequire.NoError(t, enc.Encode(cfg.PostRestore))\n\t\trequire.Regexp(t, fmt.Sprintf(`(?s).*checksum = \"\\Q%s\\E\".*`, v), &b)\n\t}\n\n\tfor k, v := range kvMap {\n\t\tcfg := &config.Config{}\n\t\tconfStr := fmt.Sprintf(\"[post-restore]\\r\\nanalyze= %s\\r\\n\", k)\n\t\terr := cfg.LoadFromTOML([]byte(confStr))\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, v, cfg.PostRestore.Analyze)\n\n\t\tb.Reset()\n\t\trequire.NoError(t, enc.Encode(cfg.PostRestore))\n\t\trequire.Regexp(t, fmt.Sprintf(`(?s).*analyze = \"\\Q%s\\E\".*`, v), &b)\n\t}\n}\n\nfunc TestCronEncodeDecode(t *testing.T) {\n\tcfg := &config.Config{}\n\tcfg.Cron.SwitchMode.Duration = 1 * time.Minute\n\tcfg.Cron.LogProgress.Duration = 2 * time.Minute\n\tcfg.Cron.CheckDiskQuota.Duration = 3 * time.Second\n\tvar b bytes.Buffer\n\trequire.NoError(t, toml.NewEncoder(&b).Encode(cfg.Cron))\n\trequire.Equal(t, \"switch-mode = \\\"1m0s\\\"\\nlog-progress = \\\"2m0s\\\"\\ncheck-disk-quota = \\\"3s\\\"\\n\", b.String())\n\n\tconfStr := \"[cron]\\r\\n\" + b.String()\n\tcfg2 := &config.Config{}\n\trequire.NoError(t, cfg2.LoadFromTOML([]byte(confStr)))\n\trequire.Equal(t, cfg.Cron, cfg2.Cron)\n}\n\nfunc TestAdjustWithLegacyBlackWhiteList(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\trequire.Equal(t, config.GetDefaultFilter(), cfg.Mydumper.Filter)\n\trequire.False(t, cfg.HasLegacyBlackWhiteList())\n\n\tctx := context.Background()\n\tcfg.Mydumper.Filter = []string{\"test.*\"}\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.False(t, cfg.HasLegacyBlackWhiteList())\n\n\tcfg.BWList.DoDBs = []string{\"test\"}\n\trequire.EqualError(t, cfg.Adjust(ctx), \"[Lightning:Config:ErrInvalidConfig]`mydumper.filter` and `black-white-list` cannot be simultaneously defined\")\n\n\tcfg.Mydumper.Filter = config.GetDefaultFilter()\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.True(t, cfg.HasLegacyBlackWhiteList())\n}\n\nfunc TestAdjustDiskQuota(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\n\tbase := t.TempDir()\n\tctx := context.Background()\n\tcfg.TikvImporter.Backend = config.BackendLocal\n\tcfg.TikvImporter.DiskQuota = 0\n\tcfg.TikvImporter.SortedKVDir = base\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.Equal(t, int64(0), int64(cfg.TikvImporter.DiskQuota))\n}\n\nfunc TestDataCharacterSet(t *testing.T) {\n\ttestCases := []struct {\n\t\tinput string\n\t\terr   string\n\t}{\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'binary'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'utf8mb4'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'gb18030'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\\u2323\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"a\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"INV\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\ud83d\ude0a\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\ud83d\ude0a\ud83d\ude2d\ud83d\ude05\ud83d\ude04\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t}", "is_vulnerable": 0}
{"code": "func Test_buildControlPlanePrefixRoute(t *testing.T) {\n\tb := &Builder{filemgr: filemgr.NewManager()}\n\troute := b.buildControlPlanePrefixRoute(\"/hello/world/\", false)\n\ttestutil.AssertProtoJSONEqual(t, `\n\t\t{\n\t\t\t\"name\": \"pomerium-prefix-/hello/world/\",\n\t\t\t\"match\": {\n\t\t\t\t\"prefix\": \"/hello/world/\"\n\t\t\t},\n\t\t\t\"route\": {\n\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t},\n\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\"disabled\": true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t`, route)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CrackTaskUpdate(ctx context.Context, in *clientpb.CrackTask, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CrackTaskUpdate_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Message) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowEnumdecl\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Message: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Message: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field EnumeratedField\", wireType)\n\t\t\t}\n\t\t\tm.EnumeratedField = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowEnumdecl\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.EnumeratedField |= MyEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipEnumdecl(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthEnumdecl\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestIngressAnnotationOpentracingTrustSetTrue(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"enable-opentracing\")] = \"true\"\n\tdata[parser.GetAnnotationWithPrefix(\"opentracing-trust-incoming-span\")] = \"true\"\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\topenTracing, ok := val.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected a Config type\")\n\t}\n\n\tif !openTracing.Enabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif !openTracing.TrustEnabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestOperationsWithInvalidModel(t *testing.T) {\n\tctx := context.Background()\n\tstoreID := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\t// The model is invalid\n\ttypedefs := parser.MustParse(`\n\ttype user\n\n\ttype repo\n\t  relations\n        define admin: [user] as self\n\t    define r1: [user] as self and r2 and r3\n\t    define r2: [user] as self and r1 and r3\n\t    define r3: [user] as self and r1 and r2\n\t`)\n\n\ttk := tuple.NewTupleKey(\"repo:openfga\", \"r1\", \"user:anne\")\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().\n\t\tReadAuthorizationModel(gomock.Any(), storeID, modelID).\n\t\tAnyTimes().\n\t\tReturn(&openfgapb.AuthorizationModel{\n\t\t\tSchemaVersion:   typesystem.SchemaVersion1_1,\n\t\t\tTypeDefinitions: typedefs,\n\t\t}, nil)\n\n\t// the model is error and err should return\n\n\ts := New(&Dependencies{\n\t\tDatastore: mockDatastore,\n\t\tLogger:    logger.NewNoopLogger(),\n\t\tTransport: gateway.NewNoopTransport(),\n\t}, &Config{\n\t\tResolveNodeLimit: test.DefaultResolveNodeLimit,\n\t})\n\n\t_, err := s.Check(ctx, &openfgapb.CheckRequest{\n\t\tStoreId:              storeID,\n\t\tTupleKey:             tk,\n\t\tAuthorizationModelId: modelID,\n\t})\n\trequire.Error(t, err)\n\te, ok := status.FromError(err)\n\trequire.True(t, ok)\n\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\n\t_, err = s.ListObjects(ctx, &openfgapb.ListObjectsRequest{\n\t\tStoreId:              storeID,\n\t\tAuthorizationModelId: modelID,\n\t\tType:                 \"repo\",\n\t\tRelation:             \"r1\",\n\t\tUser:                 \"user:anne\",\n\t})\n\trequire.Error(t, err)\n\te, ok = status.FromError(err)\n\trequire.True(t, ok)\n\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\n\terr = s.StreamedListObjects(&openfgapb.StreamedListObjectsRequest{\n\t\tStoreId:              storeID,\n\t\tAuthorizationModelId: modelID,\n\t\tType:                 \"repo\",\n\t\tRelation:             \"r1\",\n\t\tUser:                 \"user:anne\",\n\t}, NewMockStreamServer())\n\trequire.Error(t, err)\n\te, ok = status.FromError(err)\n\trequire.True(t, ok)\n\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\n\t_, err = s.Expand(ctx, &openfgapb.ExpandRequest{\n\t\tStoreId:              storeID,\n\t\tAuthorizationModelId: modelID,\n\t\tTupleKey:             tk,\n\t})\n\trequire.Error(t, err)\n\te, ok = status.FromError(err)\n\trequire.True(t, ok)\n\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\n}", "is_vulnerable": 0}
{"code": "func NewUsageClientWithBaseURI(baseURI string, subscriptionID string) UsageClient {\n\treturn original.NewUsageClientWithBaseURI(baseURI, subscriptionID)\n}", "is_vulnerable": 0}
{"code": "func NotSubsetf(t TestingT, list interface{}, subset interface{}, msg string, args ...interface{}) {\n\tif assert.NotSubsetf(t, list, subset, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_IncomingHTTPSConfig(t *testing.T) {\n\tc := Configurator{base: &Config{}}\n\trequire.Equal(t, []string{\"h2\", \"http/1.1\"}, c.IncomingHTTPSConfig().NextProtos)\n}", "is_vulnerable": 0}
{"code": "func (a *API) RegisterRoutes(r *mux.Router) {\n\tapiv1 := r.PathPrefix(\"/api/v1\").Subrouter()\n\tapiv1.Use(a.requireCSRFToken)\n\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks\", a.sessionRequired(a.handleGetBlocks)).Methods(\"GET\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks\", a.sessionRequired(a.handlePostBlocks)).Methods(\"POST\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks/{blockID}\", a.sessionRequired(a.handleDeleteBlock)).Methods(\"DELETE\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks/{blockID}/subtree\", a.attachSession(a.handleGetSubTree, false)).Methods(\"GET\")\n\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks/export\", a.sessionRequired(a.handleExport)).Methods(\"GET\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/blocks/import\", a.sessionRequired(a.handleImport)).Methods(\"POST\")\n\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/sharing/{rootID}\", a.sessionRequired(a.handlePostSharing)).Methods(\"POST\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/sharing/{rootID}\", a.sessionRequired(a.handleGetSharing)).Methods(\"GET\")\n\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}\", a.sessionRequired(a.handleGetWorkspace)).Methods(\"GET\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/regenerate_signup_token\", a.sessionRequired(a.handlePostWorkspaceRegenerateSignupToken)).Methods(\"POST\")\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/users\", a.sessionRequired(a.getWorkspaceUsers)).Methods(\"GET\")\n\n\t// User APIs\n\tapiv1.HandleFunc(\"/users/me\", a.sessionRequired(a.handleGetMe)).Methods(\"GET\")\n\tapiv1.HandleFunc(\"/users/{userID}\", a.sessionRequired(a.handleGetUser)).Methods(\"GET\")\n\tapiv1.HandleFunc(\"/users/{userID}/changepassword\", a.sessionRequired(a.handleChangePassword)).Methods(\"POST\")\n\n\tapiv1.HandleFunc(\"/login\", a.handleLogin).Methods(\"POST\")\n\tapiv1.HandleFunc(\"/logout\", a.sessionRequired(a.handleLogout)).Methods(\"POST\")\n\tapiv1.HandleFunc(\"/register\", a.handleRegister).Methods(\"POST\")\n\n\tapiv1.HandleFunc(\"/workspaces/{workspaceID}/{rootID}/files\", a.sessionRequired(a.handleUploadFile)).Methods(\"POST\")\n\n\t// Get Files API\n\n\tfiles := r.PathPrefix(\"/files\").Subrouter()\n\tfiles.HandleFunc(\"/workspaces/{workspaceID}/{rootID}/{filename}\", a.attachSession(a.handleServeFile, false)).Methods(\"GET\")\n}", "is_vulnerable": 0}
{"code": "func (s *connectionsStruct) MountSmaba(username, host, directory, port, mountPoint, password string) string {\n\tstr := command2.ExecResultStr(\"source \" + config.AppInfo.ShellPath + \"/helper.sh ;MountCIFS \" + username + \" \" + host + \" \" + directory + \" \" + port + \" \" + mountPoint + \" \" + password)\n\treturn str\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeRequester) GetRequestedScopes() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetRequestedScopes\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (r *sqlRepository) parseRestOptions(ctx context.Context, options ...rest.QueryOptions) model.QueryOptions {\n\tqo := model.QueryOptions{}\n\tif len(options) > 0 {\n\t\tqo.Sort, qo.Order = r.sanitizeSort(options[0].Sort, options[0].Order)\n\t\tqo.Max = options[0].Max\n\t\tqo.Offset = options[0].Offset\n\t\tif seed, ok := options[0].Filters[\"seed\"].(string); ok {\n\t\t\tqo.Seed = seed\n\t\t\tdelete(options[0].Filters, \"seed\")\n\t\t}\n\t\tqo.Filters = r.parseRestFilters(ctx, options[0])\n\t}\n\treturn qo\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Ifconfig(ctx context.Context, in *sliverpb.IfconfigReq, opts ...grpc.CallOption) (*sliverpb.Ifconfig, error) {\n\tout := new(sliverpb.Ifconfig)\n\terr := c.cc.Invoke(ctx, SliverRPC_Ifconfig_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestV002Entry_IndexKeys(t *testing.T) {\n\tkey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tder, err := x509.MarshalPKIXPublicKey(&key.PublicKey)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tpub := pem.EncodeToMemory(&pem.Block{\n\t\tBytes: der,\n\t\tType:  \"PUBLIC KEY\",\n\t})\n\n\ttests := []struct {\n\t\tname      string\n\t\tstatement in_toto.Statement\n\t\twant      []string\n\t}{\n\t\t{\n\t\t\tname: \"standard\",\n\t\t\twant: []string{},\n\t\t\tstatement: in_toto.Statement{\n\t\t\t\tPredicate: \"hello\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"subject\",\n\t\t\twant: []string{\"sha256:foo\"},\n\t\t\tstatement: in_toto.Statement{\n\t\t\t\tStatementHeader: in_toto.StatementHeader{\n\t\t\t\t\tSubject: []in_toto.Subject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"foo\",\n\t\t\t\t\t\t\tDigest: map[string]string{\n\t\t\t\t\t\t\t\t\"sha256\": \"foo\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPredicate: \"hello\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"slsa\",\n\t\t\twant: []string{\"sha256:bar\"},\n\t\t\tstatement: in_toto.Statement{\n\t\t\t\tPredicate: slsa.ProvenancePredicate{\n\t\t\t\t\tMaterials: []common.ProvenanceMaterial{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tURI: \"foo\",\n\t\t\t\t\t\t\tDigest: map[string]string{\n\t\t\t\t\t\t\t\t\"sha256\": \"bar\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"slsa wit header\",\n\t\t\twant: []string{\"sha256:foo\", \"sha256:bar\"},\n\t\t\tstatement: in_toto.Statement{\n\t\t\t\tStatementHeader: in_toto.StatementHeader{\n\t\t\t\t\tSubject: []in_toto.Subject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"foo\",\n\t\t\t\t\t\t\tDigest: map[string]string{\n\t\t\t\t\t\t\t\t\"sha256\": \"foo\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPredicate: slsa.ProvenancePredicate{\n\t\t\t\t\tMaterials: []common.ProvenanceMaterial{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tURI: \"foo\",\n\t\t\t\t\t\t\tDigest: map[string]string{\n\t\t\t\t\t\t\t\t\"sha256\": \"bar\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tb, err := json.Marshal(tt.statement)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tpayloadHash := sha256.Sum256(b)\n\t\t\tv := V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: createRekorEnvelope(envelope(t, key, b), [][]byte{pub}),\n\t\t\t\t\t\tHash: &models.IntotoV002SchemaContentHash{\n\t\t\t\t\t\t\tAlgorithm: swag.String(models.IntotoV001SchemaContentHashAlgorithmSha256),\n\t\t\t\t\t\t\tValue:     swag.String(envelopeHash(t, envelope(t, key, b))),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPayloadHash: &models.IntotoV002SchemaContentPayloadHash{\n\t\t\t\t\t\t\tAlgorithm: swag.String(models.IntotoV001SchemaContentHashAlgorithmSha256),\n\t\t\t\t\t\t\tValue:     swag.String(hex.EncodeToString(payloadHash[:])),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *envelope(t, key, b),\n\t\t\t}\n\t\t\twant := []string{}\n\t\t\tfor _, sig := range v.IntotoObj.Content.Envelope.Signatures {\n\t\t\t\tkeyHash := sha256.Sum256(*sig.PublicKey)\n\t\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(keyHash[:]))\n\t\t\t}\n\n\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(payloadHash[:]))\n\n\t\t\twant = append(want, tt.want...)\n\t\t\tgot, _ := v.IndexKeys()\n\t\t\tsort.Strings(got)\n\t\t\tsort.Strings(want)\n\t\t\tif !cmp.Equal(got, want) {\n\t\t\t\tt.Errorf(\"V001Entry.IndexKeys() = %v, want %v\", got, want)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (e *EngineInfo) FileName() string {\n\treturn e.fileName\n}", "is_vulnerable": 0}
{"code": "func (c *linuxContainer) newSetnsProcess(p *Process, cmd *exec.Cmd, messageSockPair, logFilePair filePair) (*setnsProcess, error) {\n\tcmd.Env = append(cmd.Env, \"_LIBCONTAINER_INITTYPE=\"+string(initSetns))\n\tstate, err := c.currentState()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to get container state: %w\", err)\n\t}\n\t// for setns process, we don't have to set cloneflags as the process namespaces\n\t// will only be set via setns syscall\n\tdata, err := c.bootstrapData(0, state.NamespacePaths, initSetns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tproc := &setnsProcess{\n\t\tcmd:             cmd,\n\t\tcgroupPaths:     state.CgroupPaths,\n\t\trootlessCgroups: c.config.RootlessCgroups,\n\t\tintelRdtPath:    state.IntelRdtPath,\n\t\tmessageSockPair: messageSockPair,\n\t\tlogFilePair:     logFilePair,\n\t\tmanager:         c.cgroupManager,\n\t\tconfig:          c.newInitConfig(p),\n\t\tprocess:         p,\n\t\tbootstrapData:   data,\n\t\tinitProcessPid:  state.InitProcessPid,\n\t}\n\tif len(p.SubCgroupPaths) > 0 {\n\t\tif add, ok := p.SubCgroupPaths[\"\"]; ok {\n\t\t\t// cgroup v1: using the same path for all controllers.\n\t\t\t// cgroup v2: the only possible way.\n\t\t\tfor k := range proc.cgroupPaths {\n\t\t\t\tproc.cgroupPaths[k] = path.Join(proc.cgroupPaths[k], add)\n\t\t\t}\n\t\t\t// cgroup v2: do not try to join init process's cgroup\n\t\t\t// as a fallback (see (*setnsProcess).start).\n\t\t\tproc.initProcessPid = 0\n\t\t} else {\n\t\t\t// Per-controller paths.\n\t\t\tfor ctrl, add := range p.SubCgroupPaths {\n\t\t\t\tif val, ok := proc.cgroupPaths[ctrl]; ok {\n\t\t\t\t\tproc.cgroupPaths[ctrl] = path.Join(val, add)\n\t\t\t\t} else {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unknown controller %s in SubCgroupPaths\", ctrl)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn proc, nil\n}", "is_vulnerable": 0}
{"code": "func TestSortParameter_InvalidSortKey(t *testing.T) {\n\t_, err := NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"wrong\",\n\t}, sets.NewString(\"name\"))\n\n\tassert.EqualError(t, err, \"invalid sort key 'wrong'\")\n}", "is_vulnerable": 0}
{"code": "func TestParseInvalidAnnotations(t *testing.T) {\n\ting := buildIngress()\n\n\t// Test no annotations set\n\ti, err := NewParser(&resolver.Mock{}).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error parsing ingress with backend-protocol\")\n\t}\n\tval, ok := i.(string)\n\tif !ok {\n\t\tt.Errorf(\"expected a string type\")\n\t}\n\tif val != \"HTTP\" {\n\t\tt.Errorf(\"expected HTTPS but %v returned\", val)\n\t}\n\n\tdata := map[string]string{}\n\ting.SetAnnotations(data)\n\n\t// Test with empty annotations\n\ti, err = NewParser(&resolver.Mock{}).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error parsing ingress with backend-protocol\")\n\t}\n\tval, ok = i.(string)\n\tif !ok {\n\t\tt.Errorf(\"expected a string type\")\n\t}\n\tif val != \"HTTP\" {\n\t\tt.Errorf(\"expected HTTPS but %v returned\", val)\n\t}\n\n\t// Test invalid annotation set\n\tdata[parser.GetAnnotationWithPrefix(backendProtocolAnnotation)] = \"INVALID\"\n\ting.SetAnnotations(data)\n\n\ti, err = NewParser(&resolver.Mock{}).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error parsing ingress with backend-protocol\")\n\t}\n\tval, ok = i.(string)\n\tif !ok {\n\t\tt.Errorf(\"expected a string type\")\n\t}\n\tif val != \"HTTP\" {\n\t\tt.Errorf(\"expected HTTPS but %v returned\", val)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Reconfigure(ctx context.Context, in *sliverpb.ReconfigureReq, opts ...grpc.CallOption) (*sliverpb.Reconfigure, error) {\n\tout := new(sliverpb.Reconfigure)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Reconfigure\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestAppWithSecrets(t *testing.T) {\n\tcloser, client, err := ArgoCDClientset.NewApplicationClient()\n\tassert.NoError(t, err)\n\tdefer util.Close(closer)\n\n\tGiven(t).\n\t\tPath(\"secrets\").\n\t\tWhen().\n\t\tCreate().\n\t\tSync().\n\t\tThen().\n\t\tExpect(SyncStatusIs(SyncStatusCodeSynced)).\n\t\tAnd(func(app *Application) {\n\t\t\tres := FailOnErr(client.GetResource(context.Background(), &applicationpkg.ApplicationResourceRequest{\n\t\t\t\tNamespace:    app.Spec.Destination.Namespace,\n\t\t\t\tKind:         kube.SecretKind,\n\t\t\t\tGroup:        \"\",\n\t\t\t\tName:         &app.Name,\n\t\t\t\tVersion:      \"v1\",\n\t\t\t\tResourceName: \"test-secret\",\n\t\t\t})).(*applicationpkg.ApplicationResourceResponse)\n\t\t\tassetSecretDataHidden(t, res.Manifest)\n\n\t\t\tmanifests, err := client.GetManifests(context.Background(), &applicationpkg.ApplicationManifestQuery{Name: &app.Name})\n\t\t\terrors.CheckError(err)\n\n\t\t\tfor _, manifest := range manifests.Manifests {\n\t\t\t\tassetSecretDataHidden(t, manifest)\n\t\t\t}\n\n\t\t\tdiffOutput := FailOnErr(RunCli(\"app\", \"diff\", app.Name)).(string)\n\t\t\tassert.Empty(t, diffOutput)\n\n\t\t\t// patch secret and make sure app is out of sync and diff detects the change\n\t\t\tFailOnErr(KubeClientset.CoreV1().Secrets(DeploymentNamespace()).Patch(\n\t\t\t\t\"test-secret\", types.JSONPatchType, []byte(`[\n\t{\"op\": \"remove\", \"path\": \"/data/username\"},\n\t{\"op\": \"add\", \"path\": \"/stringData\", \"value\": {\"password\": \"foo\"}}\n]`)))\n\t\t}).\n\t\tWhen().\n\t\tRefresh(RefreshTypeNormal).\n\t\tThen().\n\t\tExpect(SyncStatusIs(SyncStatusCodeOutOfSync)).\n\t\tAnd(func(app *Application) {\n\t\t\tdiffOutput, err := RunCli(\"app\", \"diff\", app.Name)\n\t\t\tassert.Error(t, err)\n\t\t\tassert.Contains(t, diffOutput, \"username: ++++++++\")\n\t\t\tassert.Contains(t, diffOutput, \"password: ++++++++++++\")\n\n\t\t\t// local diff should ignore secrets\n\t\t\tdiffOutput = FailOnErr(RunCli(\"app\", \"diff\", app.Name, \"--local\", \"testdata/secrets\")).(string)\n\t\t\tassert.Empty(t, diffOutput)\n\n\t\t\t// ignore missing field and make sure diff shows no difference\n\t\t\tapp.Spec.IgnoreDifferences = []ResourceIgnoreDifferences{{\n\t\t\t\tKind: kube.SecretKind, JSONPointers: []string{\"/data\"},\n\t\t\t}}\n\t\t\tFailOnErr(client.UpdateSpec(context.Background(), &applicationpkg.ApplicationUpdateSpecRequest{Name: &app.Name, Spec: app.Spec}))\n\t\t}).\n\t\tWhen().\n\t\tRefresh(RefreshTypeNormal).\n\t\tThen().\n\t\tExpect(OperationPhaseIs(OperationSucceeded)).\n\t\tExpect(SyncStatusIs(SyncStatusCodeSynced)).\n\t\tAnd(func(app *Application) {\n\t\t\tdiffOutput := FailOnErr(RunCli(\"app\", \"diff\", app.Name)).(string)\n\t\t\tassert.Empty(t, diffOutput)\n\t\t})\n}", "is_vulnerable": 0}
{"code": "func TestGH681(t *testing.T) {\n\tprivkey, err := jwxtest.GenerateRsaKey()\n\tif !assert.NoError(t, err, \"failed to create private key\") {\n\t\treturn\n\t}\n\n\tbuf, err := jws.Sign(nil, jws.WithKey(jwa.RS256, privkey), jws.WithDetachedPayload([]byte(\"Lorem ipsum\")))\n\tif !assert.NoError(t, err, \"failed to sign payload\") {\n\t\treturn\n\t}\n\n\tt.Logf(\"%s\", buf)\n\n\t_, err = jws.Verify(buf, jws.WithKey(jwa.RS256, &privkey.PublicKey), jws.WithDetachedPayload([]byte(\"Lorem ipsum\")))\n\tif !assert.NoError(t, err, \"failed to verify JWS message\") {\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *Peer) handle(msg Msg) error {\n\tswitch {\n\tcase msg.Code == pingMsg:\n\t\tmsg.Discard()\n\t\tselect {\n\t\tcase p.pingRecv <- struct{}{}:\n\t\tcase <-p.closed:\n\t\t}\n\tcase msg.Code == discMsg:\n\t\t// This is the last message. We don't need to discard or\n\t\t// check errors because, the connection will be closed after it.\n\t\tvar m struct{ R DiscReason }\n\t\trlp.Decode(msg.Payload, &m)\n\t\treturn m.R\n\tcase msg.Code < baseProtocolLength:\n\t\t// ignore other base protocol messages\n\t\treturn msg.Discard()\n\tdefault:\n\t\t// it's a subprotocol message\n\t\tproto, err := p.getProto(msg.Code)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"msg code out of range: %v\", msg.Code)\n\t\t}\n\t\tif metrics.Enabled {\n\t\t\tm := fmt.Sprintf(\"%s/%s/%d/%#02x\", ingressMeterName, proto.Name, proto.Version, msg.Code-proto.offset)\n\t\t\tmetrics.GetOrRegisterMeter(m, nil).Mark(int64(msg.meterSize))\n\t\t\tmetrics.GetOrRegisterMeter(m+\"/packets\", nil).Mark(1)\n\t\t}\n\t\tselect {\n\t\tcase proto.in <- msg:\n\t\t\treturn nil\n\t\tcase <-p.closed:\n\t\t\treturn io.EOF\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestKubeExtensions(t *testing.T) {\n\tclock := clockwork.NewFakeClock()\n\tca, err := FromKeys([]byte(fixtures.SigningCertPEM), []byte(fixtures.SigningKeyPEM))\n\trequire.NoError(t, err)\n\n\tprivateKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\trequire.NoError(t, err)\n\n\texpires := clock.Now().Add(time.Hour)\n\tidentity := Identity{\n\t\tUsername:     \"alice@example.com\",\n\t\tGroups:       []string{\"admin\"},\n\t\tImpersonator: \"bob@example.com\",\n\t\t// Generate a certificate restricted for\n\t\t// use against a kubernetes endpoint, and not the API server endpoint\n\t\t// otherwise proxies can generate certs for any user.\n\t\tUsage:             []string{teleport.UsageKubeOnly},\n\t\tKubernetesGroups:  []string{\"system:masters\", \"admin\"},\n\t\tKubernetesUsers:   []string{\"IAM#alice@example.com\"},\n\t\tKubernetesCluster: \"kube-cluster\",\n\t\tTeleportCluster:   \"tele-cluster\",\n\t\tRouteToDatabase: RouteToDatabase{\n\t\t\tServiceName: \"postgres-rds\",\n\t\t\tProtocol:    \"postgres\",\n\t\t\tUsername:    \"postgres\",\n\t\t},\n\t\tDatabaseNames: []string{\"postgres\", \"main\"},\n\t\tDatabaseUsers: []string{\"postgres\", \"alice\"},\n\t\tExpires:       expires,\n\t}\n\n\tsubj, err := identity.Subject()\n\trequire.NoError(t, err)\n\n\tcertBytes, err := ca.GenerateCertificate(CertificateRequest{\n\t\tClock:     clock,\n\t\tPublicKey: privateKey.Public(),\n\t\tSubject:   subj,\n\t\tNotAfter:  expires,\n\t})\n\trequire.NoError(t, err)\n\n\tcert, err := ParseCertificatePEM(certBytes)\n\trequire.NoError(t, err)\n\tout, err := FromSubject(cert.Subject, cert.NotAfter)\n\trequire.NoError(t, err)\n\trequire.Empty(t, cmp.Diff(out, &identity))\n}", "is_vulnerable": 0}
{"code": "func (c *Context) KeyListEnd() error {\n\terr := handleError(C.gpgme_op_keylist_end(c.ctx))\n\truntime.KeepAlive(c)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Host(ctx context.Context, in *clientpb.Host, opts ...grpc.CallOption) (*clientpb.Host, error) {\n\tout := new(clientpb.Host)\n\terr := c.cc.Invoke(ctx, SliverRPC_Host_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\tufd, err := BuildUnixFS(func(b *Builder) {\n\t\tDataType(b, data.Data_HAMTShard)\n\t\tHashType(b, s.hasher)\n\t\tData(b, s.bitmap())\n\t\tFanout(b, uint64(s.size))\n\t})", "is_vulnerable": 1}
{"code": "\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tnow := time.Now()\n\t\t\td := newDelegator(w, nil)\n\t\t\tnext.ServeHTTP(d, r)\n\n\t\t\tobs.With(labels(code, method, r.Method, d.Status(), mwOpts.extraMethods...)).Observe(time.Since(now).Seconds())\n\t\t})", "is_vulnerable": 0}
{"code": "\t\t\t\t\tAssetDir: func(path string) ([]string, error) {\n\t\t\t\t\t\treturn []string{}, nil\n\t\t\t\t\t},", "is_vulnerable": 0}
{"code": "func (g *Git) gitCmd(output io.Writer, args ...string) error {\n\tkv := fmt.Sprintf(\"credential.helper=%s\", \"/bin/sh -c 'echo password=$GIT_PASSWORD'\")\n\tcmd := exec.Command(\"git\", append([]string{\"-c\", kv}, args...)...)\n\tcmd.Env = append(os.Environ(), fmt.Sprintf(\"GIT_PASSWORD=%s\", g.password))\n\tstderrBuf := &bytes.Buffer{}\n\tcmd.Stderr = stderrBuf\n\tcmd.Stdout = output\n\n\tif g.agent != nil {\n\t\tc, err := g.injectAgent(cmd)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer c.Close()\n\t}\n\n\tif len(g.knownHosts) != 0 {\n\t\tf, err := ioutil.TempFile(\"\", \"known_hosts\")\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer os.RemoveAll(f.Name())\n\t\tdefer f.Close()\n\n\t\tif _, err := f.Write(g.knownHosts); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := f.Close(); err != nil {\n\t\t\treturn fmt.Errorf(\"closing knownHosts file %s: %w\", f.Name(), err)\n\t\t}\n\n\t\tcmd.Env = append(cmd.Env, \"GIT_SSH_COMMAND=\"+fmt.Sprintf(\"ssh -o UserKnownHostsFile=%s\", f.Name()))\n\t} else {\n\t\tcmd.Env = append(cmd.Env, \"GIT_SSH_COMMAND=\"+fmt.Sprintf(\"ssh -o StrictHostKeyChecking=accept-new\"))\n\t}\n\tcmd.Env = append(cmd.Env, \"GIT_TERMINAL_PROMPT=0\")\n\n\tif g.insecureTLSVerify {\n\t\tcmd.Env = append(cmd.Env, \"GIT_SSL_NO_VERIFY=false\")\n\t}\n\n\tif len(g.caBundle) > 0 {\n\t\tf, err := ioutil.TempFile(\"\", \"ca-pem-\")\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer os.Remove(f.Name())\n\t\tdefer f.Close()\n\n\t\tif _, err := f.Write(g.caBundle); err != nil {\n\t\t\treturn fmt.Errorf(\"writing cabundle to %s: %w\", f.Name(), err)\n\t\t}\n\t\tif err := f.Close(); err != nil {\n\t\t\treturn fmt.Errorf(\"closing cabundle %s: %w\", f.Name(), err)\n\t\t}\n\t\tcmd.Env = append(cmd.Env, \"GIT_SSL_CAINFO=\"+f.Name())\n\t}\n\n\terr := cmd.Run()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"git %s error: %w, detail: %v\", strings.Join(args, \" \"), err, stderrBuf.String())\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *APIV2Service) UpdateStorage(ctx context.Context, request *apiv2pb.UpdateStorageRequest) (*apiv2pb.UpdateStorageResponse, error) {\n\tif request.UpdateMask == nil || len(request.UpdateMask.Paths) == 0 {\n\t\treturn nil, status.Errorf(codes.InvalidArgument, \"update_mask is required\")\n\t}\n\n\tupdate := &store.UpdateStorageV1{\n\t\tID:   request.Storage.Id,\n\t\tType: storepb.Storage_Type(storepb.Storage_Type_value[request.Storage.Type.String()]),\n\t}\n\tfor _, field := range request.UpdateMask.Paths {\n\t\tswitch field {\n\t\tcase \"name\":\n\t\t\tupdate.Name = &request.Storage.Title\n\t\tcase \"config\":\n\t\t\tupdate.Config = convertStorageConfigToStore(request.Storage.Type, request.Storage.Config)\n\t\t}\n\t}\n\n\tstorage, err := s.Store.UpdateStorageV1(ctx, update)\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.Internal, \"failed to update storage, error: %+v\", err)\n\t}\n\treturn &apiv2pb.UpdateStorageResponse{\n\t\tStorage: convertStorageFromStore(storage),\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) someValuesFromConfig() (bool, bool, string) {\n\tc.RLock()\n\tdefer c.RUnlock()\n\treturn c.base.VerifyServerHostname, c.base.VerifyOutgoing, c.base.Domain\n}", "is_vulnerable": 0}
{"code": "func runWeb(c *cli.Context) error {\n\terr := route.GlobalInit(c.String(\"config\"))\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to initialize application: %v\", err)\n\t}\n\n\tm := newMacaron()\n\n\treqSignIn := context.Toggle(&context.ToggleOptions{SignInRequired: true})\n\tignSignIn := context.Toggle(&context.ToggleOptions{SignInRequired: conf.Auth.RequireSigninView})\n\treqSignOut := context.Toggle(&context.ToggleOptions{SignOutRequired: true})\n\n\tbindIgnErr := binding.BindIgnErr\n\n\tm.SetAutoHead(true)\n\n\tm.Group(\"\", func() {\n\t\tm.Get(\"/\", ignSignIn, route.Home)\n\t\tm.Group(\"/explore\", func() {\n\t\t\tm.Get(\"\", func(c *context.Context) {\n\t\t\t\tc.Redirect(conf.Server.Subpath + \"/explore/repos\")\n\t\t\t})\n\t\t\tm.Get(\"/repos\", route.ExploreRepos)\n\t\t\tm.Get(\"/users\", route.ExploreUsers)\n\t\t\tm.Get(\"/organizations\", route.ExploreOrganizations)\n\t\t}, ignSignIn)\n\t\tm.Combo(\"/install\", route.InstallInit).Get(route.Install).\n\t\t\tPost(bindIgnErr(form.Install{}), route.InstallPost)\n\t\tm.Get(\"/^:type(issues|pulls)$\", reqSignIn, user.Issues)\n\n\t\t// ***** START: User *****\n\t\tm.Group(\"/user\", func() {\n\t\t\tm.Group(\"/login\", func() {\n\t\t\t\tm.Combo(\"\").Get(user.Login).\n\t\t\t\t\tPost(bindIgnErr(form.SignIn{}), user.LoginPost)\n\t\t\t\tm.Combo(\"/two_factor\").Get(user.LoginTwoFactor).Post(user.LoginTwoFactorPost)\n\t\t\t\tm.Combo(\"/two_factor_recovery_code\").Get(user.LoginTwoFactorRecoveryCode).Post(user.LoginTwoFactorRecoveryCodePost)\n\t\t\t})\n\n\t\t\tm.Get(\"/sign_up\", user.SignUp)\n\t\t\tm.Post(\"/sign_up\", bindIgnErr(form.Register{}), user.SignUpPost)\n\t\t\tm.Get(\"/reset_password\", user.ResetPasswd)\n\t\t\tm.Post(\"/reset_password\", user.ResetPasswdPost)\n\t\t}, reqSignOut)\n\n\t\tm.Group(\"/user/settings\", func() {\n\t\t\tm.Get(\"\", user.Settings)\n\t\t\tm.Post(\"\", bindIgnErr(form.UpdateProfile{}), user.SettingsPost)\n\t\t\tm.Combo(\"/avatar\").Get(user.SettingsAvatar).\n\t\t\t\tPost(binding.MultipartForm(form.Avatar{}), user.SettingsAvatarPost)\n\t\t\tm.Post(\"/avatar/delete\", user.SettingsDeleteAvatar)\n\t\t\tm.Combo(\"/email\").Get(user.SettingsEmails).\n\t\t\t\tPost(bindIgnErr(form.AddEmail{}), user.SettingsEmailPost)\n\t\t\tm.Post(\"/email/delete\", user.DeleteEmail)\n\t\t\tm.Get(\"/password\", user.SettingsPassword)\n\t\t\tm.Post(\"/password\", bindIgnErr(form.ChangePassword{}), user.SettingsPasswordPost)\n\t\t\tm.Combo(\"/ssh\").Get(user.SettingsSSHKeys).\n\t\t\t\tPost(bindIgnErr(form.AddSSHKey{}), user.SettingsSSHKeysPost)\n\t\t\tm.Post(\"/ssh/delete\", user.DeleteSSHKey)\n\t\t\tm.Group(\"/security\", func() {\n\t\t\t\tm.Get(\"\", user.SettingsSecurity)\n\t\t\t\tm.Combo(\"/two_factor_enable\").Get(user.SettingsTwoFactorEnable).\n\t\t\t\t\tPost(user.SettingsTwoFactorEnablePost)\n\t\t\t\tm.Combo(\"/two_factor_recovery_codes\").Get(user.SettingsTwoFactorRecoveryCodes).\n\t\t\t\t\tPost(user.SettingsTwoFactorRecoveryCodesPost)\n\t\t\t\tm.Post(\"/two_factor_disable\", user.SettingsTwoFactorDisable)\n\t\t\t})\n\t\t\tm.Group(\"/repositories\", func() {\n\t\t\t\tm.Get(\"\", user.SettingsRepos)\n\t\t\t\tm.Post(\"/leave\", user.SettingsLeaveRepo)\n\t\t\t})\n\t\t\tm.Group(\"/organizations\", func() {\n\t\t\t\tm.Get(\"\", user.SettingsOrganizations)\n\t\t\t\tm.Post(\"/leave\", user.SettingsLeaveOrganization)\n\t\t\t})\n\t\t\tm.Combo(\"/applications\").Get(user.SettingsApplications).\n\t\t\t\tPost(bindIgnErr(form.NewAccessToken{}), user.SettingsApplicationsPost)\n\t\t\tm.Post(\"/applications/delete\", user.SettingsDeleteApplication)\n\t\t\tm.Route(\"/delete\", \"GET,POST\", user.SettingsDelete)\n\t\t}, reqSignIn, func(c *context.Context) {\n\t\t\tc.Data[\"PageIsUserSettings\"] = true\n\t\t})\n\n\t\tm.Group(\"/user\", func() {\n\t\t\tm.Any(\"/activate\", user.Activate)\n\t\t\tm.Any(\"/activate_email\", user.ActivateEmail)\n\t\t\tm.Get(\"/email2user\", user.Email2User)\n\t\t\tm.Get(\"/forget_password\", user.ForgotPasswd)\n\t\t\tm.Post(\"/forget_password\", user.ForgotPasswdPost)\n\t\t\tm.Post(\"/logout\", user.SignOut)\n\t\t})\n\t\t// ***** END: User *****\n\n\t\treqAdmin := context.Toggle(&context.ToggleOptions{SignInRequired: true, AdminRequired: true})\n\n\t\t// ***** START: Admin *****\n\t\tm.Group(\"/admin\", func() {\n\t\t\tm.Combo(\"\").Get(admin.Dashboard).Post(admin.Operation) // \"/admin\"\n\t\t\tm.Get(\"/config\", admin.Config)\n\t\t\tm.Post(\"/config/test_mail\", admin.SendTestMail)\n\t\t\tm.Get(\"/monitor\", admin.Monitor)\n\n\t\t\tm.Group(\"/users\", func() {\n\t\t\t\tm.Get(\"\", admin.Users)\n\t\t\t\tm.Combo(\"/new\").Get(admin.NewUser).Post(bindIgnErr(form.AdminCrateUser{}), admin.NewUserPost)\n\t\t\t\tm.Combo(\"/:userid\").Get(admin.EditUser).Post(bindIgnErr(form.AdminEditUser{}), admin.EditUserPost)\n\t\t\t\tm.Post(\"/:userid/delete\", admin.DeleteUser)\n\t\t\t})\n\n\t\t\tm.Group(\"/orgs\", func() {\n\t\t\t\tm.Get(\"\", admin.Organizations)\n\t\t\t})\n\n\t\t\tm.Group(\"/repos\", func() {\n\t\t\t\tm.Get(\"\", admin.Repos)\n\t\t\t\tm.Post(\"/delete\", admin.DeleteRepo)\n\t\t\t})\n\n\t\t\tm.Group(\"/auths\", func() {\n\t\t\t\tm.Get(\"\", admin.Authentications)\n\t\t\t\tm.Combo(\"/new\").Get(admin.NewAuthSource).Post(bindIgnErr(form.Authentication{}), admin.NewAuthSourcePost)\n\t\t\t\tm.Combo(\"/:authid\").Get(admin.EditAuthSource).\n\t\t\t\t\tPost(bindIgnErr(form.Authentication{}), admin.EditAuthSourcePost)\n\t\t\t\tm.Post(\"/:authid/delete\", admin.DeleteAuthSource)\n\t\t\t})\n\n\t\t\tm.Group(\"/notices\", func() {\n\t\t\t\tm.Get(\"\", admin.Notices)\n\t\t\t\tm.Post(\"/delete\", admin.DeleteNotices)\n\t\t\t\tm.Get(\"/empty\", admin.EmptyNotices)\n\t\t\t})\n\t\t}, reqAdmin)\n\t\t// ***** END: Admin *****\n\n\t\tm.Group(\"\", func() {\n\t\t\tm.Group(\"/:username\", func() {\n\t\t\t\tm.Get(\"\", user.Profile)\n\t\t\t\tm.Get(\"/followers\", user.Followers)\n\t\t\t\tm.Get(\"/following\", user.Following)\n\t\t\t\tm.Get(\"/stars\", user.Stars)\n\t\t\t}, context.InjectParamsUser())\n\n\t\t\tm.Get(\"/attachments/:uuid\", func(c *context.Context) {\n\t\t\t\tattach, err := db.GetAttachmentByUUID(c.Params(\":uuid\"))\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.NotFoundOrError(err, \"get attachment by UUID\")\n\t\t\t\t\treturn\n\t\t\t\t} else if !com.IsFile(attach.LocalPath()) {\n\t\t\t\t\tc.NotFound()\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tfr, err := os.Open(attach.LocalPath())\n\t\t\t\tif err != nil {\n\t\t\t\t\tc.Error(err, \"open attachment file\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tdefer fr.Close()\n\n\t\t\t\tc.Header().Set(\"Content-Security-Policy\", \"default-src 'none'; style-src 'unsafe-inline'; sandbox\")\n\t\t\t\tc.Header().Set(\"Cache-Control\", \"public,max-age=86400\")\n\t\t\t\tc.Header().Set(\"Content-Disposition\", fmt.Sprintf(`inline; filename=\"%s\"`, attach.Name))\n\n\t\t\t\tif _, err = io.Copy(c.Resp, fr); err != nil {\n\t\t\t\t\tc.Error(err, \"copy from file to response\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t})\n\t\t\tm.Post(\"/issues/attachments\", repo.UploadIssueAttachment)\n\t\t\tm.Post(\"/releases/attachments\", repo.UploadReleaseAttachment)\n\t\t}, ignSignIn)\n\n\t\tm.Group(\"/:username\", func() {\n\t\t\tm.Post(\"/action/:action\", user.Action)\n\t\t}, reqSignIn, context.InjectParamsUser())\n\n\t\tif macaron.Env == macaron.DEV {\n\t\t\tm.Get(\"/template/*\", dev.TemplatePreview)\n\t\t}\n\n\t\treqRepoAdmin := context.RequireRepoAdmin()\n\t\treqRepoWriter := context.RequireRepoWriter()\n\n\t\twebhookRoutes := func() {\n\t\t\tm.Group(\"\", func() {\n\t\t\t\tm.Get(\"\", repo.Webhooks)\n\t\t\t\tm.Post(\"/delete\", repo.DeleteWebhook)\n\t\t\t\tm.Get(\"/:type/new\", repo.WebhooksNew)\n\t\t\t\tm.Post(\"/gogs/new\", bindIgnErr(form.NewWebhook{}), repo.WebhooksNewPost)\n\t\t\t\tm.Post(\"/slack/new\", bindIgnErr(form.NewSlackHook{}), repo.WebhooksSlackNewPost)\n\t\t\t\tm.Post(\"/discord/new\", bindIgnErr(form.NewDiscordHook{}), repo.WebhooksDiscordNewPost)\n\t\t\t\tm.Post(\"/dingtalk/new\", bindIgnErr(form.NewDingtalkHook{}), repo.WebhooksDingtalkNewPost)\n\t\t\t\tm.Get(\"/:id\", repo.WebhooksEdit)\n\t\t\t\tm.Post(\"/gogs/:id\", bindIgnErr(form.NewWebhook{}), repo.WebhooksEditPost)\n\t\t\t\tm.Post(\"/slack/:id\", bindIgnErr(form.NewSlackHook{}), repo.WebhooksSlackEditPost)\n\t\t\t\tm.Post(\"/discord/:id\", bindIgnErr(form.NewDiscordHook{}), repo.WebhooksDiscordEditPost)\n\t\t\t\tm.Post(\"/dingtalk/:id\", bindIgnErr(form.NewDingtalkHook{}), repo.WebhooksDingtalkEditPost)\n\t\t\t}, repo.InjectOrgRepoContext())\n\t\t}\n\n\t\t// ***** START: Organization *****\n\t\tm.Group(\"/org\", func() {\n\t\t\tm.Group(\"\", func() {\n\t\t\t\tm.Get(\"/create\", org.Create)\n\t\t\t\tm.Post(\"/create\", bindIgnErr(form.CreateOrg{}), org.CreatePost)\n\t\t\t}, func(c *context.Context) {\n\t\t\t\tif !c.User.CanCreateOrganization() {\n\t\t\t\t\tc.NotFound()\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tm.Group(\"/:org\", func() {\n\t\t\t\tm.Get(\"/dashboard\", user.Dashboard)\n\t\t\t\tm.Get(\"/^:type(issues|pulls)$\", user.Issues)\n\t\t\t\tm.Get(\"/members\", org.Members)\n\t\t\t\tm.Get(\"/members/action/:action\", org.MembersAction)\n\n\t\t\t\tm.Get(\"/teams\", org.Teams)\n\t\t\t}, context.OrgAssignment(true))\n\n\t\t\tm.Group(\"/:org\", func() {\n\t\t\t\tm.Get(\"/teams/:team\", org.TeamMembers)\n\t\t\t\tm.Get(\"/teams/:team/repositories\", org.TeamRepositories)\n\t\t\t\tm.Route(\"/teams/:team/action/:action\", \"GET,POST\", org.TeamsAction)\n\t\t\t\tm.Route(\"/teams/:team/action/repo/:action\", \"GET,POST\", org.TeamsRepoAction)\n\t\t\t}, context.OrgAssignment(true, false, true))\n\n\t\t\tm.Group(\"/:org\", func() {\n\t\t\t\tm.Get(\"/teams/new\", org.NewTeam)\n\t\t\t\tm.Post(\"/teams/new\", bindIgnErr(form.CreateTeam{}), org.NewTeamPost)\n\t\t\t\tm.Get(\"/teams/:team/edit\", org.EditTeam)\n\t\t\t\tm.Post(\"/teams/:team/edit\", bindIgnErr(form.CreateTeam{}), org.EditTeamPost)\n\t\t\t\tm.Post(\"/teams/:team/delete\", org.DeleteTeam)\n\n\t\t\t\tm.Group(\"/settings\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(org.Settings).\n\t\t\t\t\t\tPost(bindIgnErr(form.UpdateOrgSetting{}), org.SettingsPost)\n\t\t\t\t\tm.Post(\"/avatar\", binding.MultipartForm(form.Avatar{}), org.SettingsAvatar)\n\t\t\t\t\tm.Post(\"/avatar/delete\", org.SettingsDeleteAvatar)\n\t\t\t\t\tm.Group(\"/hooks\", webhookRoutes)\n\t\t\t\t\tm.Route(\"/delete\", \"GET,POST\", org.SettingsDelete)\n\t\t\t\t})\n\n\t\t\t\tm.Route(\"/invitations/new\", \"GET,POST\", org.Invitation)\n\t\t\t}, context.OrgAssignment(true, true))\n\t\t}, reqSignIn)\n\t\t// ***** END: Organization *****\n\n\t\t// ***** START: Repository *****\n\t\tm.Group(\"/repo\", func() {\n\t\t\tm.Get(\"/create\", repo.Create)\n\t\t\tm.Post(\"/create\", bindIgnErr(form.CreateRepo{}), repo.CreatePost)\n\t\t\tm.Get(\"/migrate\", repo.Migrate)\n\t\t\tm.Post(\"/migrate\", bindIgnErr(form.MigrateRepo{}), repo.MigratePost)\n\t\t\tm.Combo(\"/fork/:repoid\").Get(repo.Fork).\n\t\t\t\tPost(bindIgnErr(form.CreateRepo{}), repo.ForkPost)\n\t\t}, reqSignIn)\n\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\tm.Group(\"/settings\", func() {\n\t\t\t\tm.Combo(\"\").Get(repo.Settings).\n\t\t\t\t\tPost(bindIgnErr(form.RepoSetting{}), repo.SettingsPost)\n\t\t\t\tm.Combo(\"/avatar\").Get(repo.SettingsAvatar).\n\t\t\t\t\tPost(binding.MultipartForm(form.Avatar{}), repo.SettingsAvatarPost)\n\t\t\t\tm.Post(\"/avatar/delete\", repo.SettingsDeleteAvatar)\n\t\t\t\tm.Group(\"/collaboration\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.SettingsCollaboration).Post(repo.SettingsCollaborationPost)\n\t\t\t\t\tm.Post(\"/access_mode\", repo.ChangeCollaborationAccessMode)\n\t\t\t\t\tm.Post(\"/delete\", repo.DeleteCollaboration)\n\t\t\t\t})\n\t\t\t\tm.Group(\"/branches\", func() {\n\t\t\t\t\tm.Get(\"\", repo.SettingsBranches)\n\t\t\t\t\tm.Post(\"/default_branch\", repo.UpdateDefaultBranch)\n\t\t\t\t\tm.Combo(\"/*\").Get(repo.SettingsProtectedBranch).\n\t\t\t\t\t\tPost(bindIgnErr(form.ProtectBranch{}), repo.SettingsProtectedBranchPost)\n\t\t\t\t}, func(c *context.Context) {\n\t\t\t\t\tif c.Repo.Repository.IsMirror {\n\t\t\t\t\t\tc.NotFound()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t})\n\n\t\t\t\tm.Group(\"/hooks\", func() {\n\t\t\t\t\twebhookRoutes()\n\n\t\t\t\t\tm.Group(\"/:id\", func() {\n\t\t\t\t\t\tm.Post(\"/test\", repo.TestWebhook)\n\t\t\t\t\t\tm.Post(\"/redelivery\", repo.RedeliveryWebhook)\n\t\t\t\t\t})\n\n\t\t\t\t\tm.Group(\"/git\", func() {\n\t\t\t\t\t\tm.Get(\"\", repo.SettingsGitHooks)\n\t\t\t\t\t\tm.Combo(\"/:name\").Get(repo.SettingsGitHooksEdit).\n\t\t\t\t\t\t\tPost(repo.SettingsGitHooksEditPost)\n\t\t\t\t\t}, context.GitHookService())\n\t\t\t\t})\n\n\t\t\t\tm.Group(\"/keys\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.SettingsDeployKeys).\n\t\t\t\t\t\tPost(bindIgnErr(form.AddSSHKey{}), repo.SettingsDeployKeysPost)\n\t\t\t\t\tm.Post(\"/delete\", repo.DeleteDeployKey)\n\t\t\t\t})\n\n\t\t\t}, func(c *context.Context) {\n\t\t\t\tc.Data[\"PageIsSettings\"] = true\n\t\t\t})\n\t\t}, reqSignIn, context.RepoAssignment(), reqRepoAdmin, context.RepoRef())\n\n\t\tm.Post(\"/:username/:reponame/action/:action\", reqSignIn, context.RepoAssignment(), repo.Action)\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\tm.Get(\"/issues\", repo.RetrieveLabels, repo.Issues)\n\t\t\tm.Get(\"/issues/:index\", repo.ViewIssue)\n\t\t\tm.Get(\"/labels/\", repo.RetrieveLabels, repo.Labels)\n\t\t\tm.Get(\"/milestones\", repo.Milestones)\n\t\t}, ignSignIn, context.RepoAssignment(true))\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\t// FIXME: should use different URLs but mostly same logic for comments of issue and pull reuqest.\n\t\t\t// So they can apply their own enable/disable logic on routers.\n\t\t\tm.Group(\"/issues\", func() {\n\t\t\t\tm.Combo(\"/new\", repo.MustEnableIssues).Get(context.RepoRef(), repo.NewIssue).\n\t\t\t\t\tPost(bindIgnErr(form.NewIssue{}), repo.NewIssuePost)\n\n\t\t\t\tm.Group(\"/:index\", func() {\n\t\t\t\t\tm.Post(\"/title\", repo.UpdateIssueTitle)\n\t\t\t\t\tm.Post(\"/content\", repo.UpdateIssueContent)\n\t\t\t\t\tm.Combo(\"/comments\").Post(bindIgnErr(form.CreateComment{}), repo.NewComment)\n\t\t\t\t})\n\t\t\t})\n\t\t\tm.Group(\"/comments/:id\", func() {\n\t\t\t\tm.Post(\"\", repo.UpdateCommentContent)\n\t\t\t\tm.Post(\"/delete\", repo.DeleteComment)\n\t\t\t})\n\t\t}, reqSignIn, context.RepoAssignment(true))\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\tm.Group(\"/wiki\", func() {\n\t\t\t\tm.Get(\"/?:page\", repo.Wiki)\n\t\t\t\tm.Get(\"/_pages\", repo.WikiPages)\n\t\t\t}, repo.MustEnableWiki, context.RepoRef())\n\t\t}, ignSignIn, context.RepoAssignment(false, true))\n\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\t// FIXME: should use different URLs but mostly same logic for comments of issue and pull reuqest.\n\t\t\t// So they can apply their own enable/disable logic on routers.\n\t\t\tm.Group(\"/issues\", func() {\n\t\t\t\tm.Group(\"/:index\", func() {\n\t\t\t\t\tm.Post(\"/label\", repo.UpdateIssueLabel)\n\t\t\t\t\tm.Post(\"/milestone\", repo.UpdateIssueMilestone)\n\t\t\t\t\tm.Post(\"/assignee\", repo.UpdateIssueAssignee)\n\t\t\t\t}, reqRepoWriter)\n\t\t\t})\n\t\t\tm.Group(\"/labels\", func() {\n\t\t\t\tm.Post(\"/new\", bindIgnErr(form.CreateLabel{}), repo.NewLabel)\n\t\t\t\tm.Post(\"/edit\", bindIgnErr(form.CreateLabel{}), repo.UpdateLabel)\n\t\t\t\tm.Post(\"/delete\", repo.DeleteLabel)\n\t\t\t\tm.Post(\"/initialize\", bindIgnErr(form.InitializeLabels{}), repo.InitializeLabels)\n\t\t\t}, reqRepoWriter, context.RepoRef())\n\t\t\tm.Group(\"/milestones\", func() {\n\t\t\t\tm.Combo(\"/new\").Get(repo.NewMilestone).\n\t\t\t\t\tPost(bindIgnErr(form.CreateMilestone{}), repo.NewMilestonePost)\n\t\t\t\tm.Get(\"/:id/edit\", repo.EditMilestone)\n\t\t\t\tm.Post(\"/:id/edit\", bindIgnErr(form.CreateMilestone{}), repo.EditMilestonePost)\n\t\t\t\tm.Get(\"/:id/:action\", repo.ChangeMilestonStatus)\n\t\t\t\tm.Post(\"/delete\", repo.DeleteMilestone)\n\t\t\t}, reqRepoWriter, context.RepoRef())\n\n\t\t\tm.Group(\"/releases\", func() {\n\t\t\t\tm.Get(\"/new\", repo.NewRelease)\n\t\t\t\tm.Post(\"/new\", bindIgnErr(form.NewRelease{}), repo.NewReleasePost)\n\t\t\t\tm.Post(\"/delete\", repo.DeleteRelease)\n\t\t\t\tm.Get(\"/edit/*\", repo.EditRelease)\n\t\t\t\tm.Post(\"/edit/*\", bindIgnErr(form.EditRelease{}), repo.EditReleasePost)\n\t\t\t}, repo.MustBeNotBare, reqRepoWriter, func(c *context.Context) {\n\t\t\t\tc.Data[\"PageIsViewFiles\"] = true\n\t\t\t})\n\n\t\t\t// FIXME: Should use c.Repo.PullRequest to unify template, currently we have inconsistent URL\n\t\t\t// for PR in same repository. After select branch on the page, the URL contains redundant head user name.\n\t\t\t// e.g. /org1/test-repo/compare/master...org1:develop\n\t\t\t// which should be /org1/test-repo/compare/master...develop\n\t\t\tm.Combo(\"/compare/*\", repo.MustAllowPulls).Get(repo.CompareAndPullRequest).\n\t\t\t\tPost(bindIgnErr(form.NewIssue{}), repo.CompareAndPullRequestPost)\n\n\t\t\tm.Group(\"\", func() {\n\t\t\t\tm.Combo(\"/_edit/*\").Get(repo.EditFile).\n\t\t\t\t\tPost(bindIgnErr(form.EditRepoFile{}), repo.EditFilePost)\n\t\t\t\tm.Combo(\"/_new/*\").Get(repo.NewFile).\n\t\t\t\t\tPost(bindIgnErr(form.EditRepoFile{}), repo.NewFilePost)\n\t\t\t\tm.Post(\"/_preview/*\", bindIgnErr(form.EditPreviewDiff{}), repo.DiffPreviewPost)\n\t\t\t\tm.Combo(\"/_delete/*\").Get(repo.DeleteFile).\n\t\t\t\t\tPost(bindIgnErr(form.DeleteRepoFile{}), repo.DeleteFilePost)\n\n\t\t\t\tm.Group(\"\", func() {\n\t\t\t\t\tm.Combo(\"/_upload/*\").Get(repo.UploadFile).\n\t\t\t\t\t\tPost(bindIgnErr(form.UploadRepoFile{}), repo.UploadFilePost)\n\t\t\t\t\tm.Post(\"/upload-file\", repo.UploadFileToServer)\n\t\t\t\t\tm.Post(\"/upload-remove\", bindIgnErr(form.RemoveUploadFile{}), repo.RemoveUploadFileFromServer)\n\t\t\t\t}, func(c *context.Context) {\n\t\t\t\t\tif !conf.Repository.Upload.Enabled {\n\t\t\t\t\t\tc.NotFound()\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t})\n\t\t\t}, repo.MustBeNotBare, reqRepoWriter, context.RepoRef(), func(c *context.Context) {\n\t\t\t\tif !c.Repo.CanEnableEditor() {\n\t\t\t\t\tc.NotFound()\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tc.Data[\"PageIsViewFiles\"] = true\n\t\t\t})\n\t\t}, reqSignIn, context.RepoAssignment())\n\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\tm.Group(\"\", func() {\n\t\t\t\tm.Get(\"/releases\", repo.MustBeNotBare, repo.Releases)\n\t\t\t\tm.Get(\"/pulls\", repo.RetrieveLabels, repo.Pulls)\n\t\t\t\tm.Get(\"/pulls/:index\", repo.ViewPull)\n\t\t\t}, context.RepoRef())\n\n\t\t\tm.Group(\"/branches\", func() {\n\t\t\t\tm.Get(\"\", repo.Branches)\n\t\t\t\tm.Get(\"/all\", repo.AllBranches)\n\t\t\t\tm.Post(\"/delete/*\", reqSignIn, reqRepoWriter, repo.DeleteBranchPost)\n\t\t\t}, repo.MustBeNotBare, func(c *context.Context) {\n\t\t\t\tc.Data[\"PageIsViewFiles\"] = true\n\t\t\t})\n\n\t\t\tm.Group(\"/wiki\", func() {\n\t\t\t\tm.Group(\"\", func() {\n\t\t\t\t\tm.Combo(\"/_new\").Get(repo.NewWiki).\n\t\t\t\t\t\tPost(bindIgnErr(form.NewWiki{}), repo.NewWikiPost)\n\t\t\t\t\tm.Combo(\"/:page/_edit\").Get(repo.EditWiki).\n\t\t\t\t\t\tPost(bindIgnErr(form.NewWiki{}), repo.EditWikiPost)\n\t\t\t\t\tm.Post(\"/:page/delete\", repo.DeleteWikiPagePost)\n\t\t\t\t}, reqSignIn, reqRepoWriter)\n\t\t\t}, repo.MustEnableWiki, context.RepoRef())\n\n\t\t\tm.Get(\"/archive/*\", repo.MustBeNotBare, repo.Download)\n\n\t\t\tm.Group(\"/pulls/:index\", func() {\n\t\t\t\tm.Get(\"/commits\", context.RepoRef(), repo.ViewPullCommits)\n\t\t\t\tm.Get(\"/files\", context.RepoRef(), repo.ViewPullFiles)\n\t\t\t\tm.Post(\"/merge\", reqRepoWriter, repo.MergePullRequest)\n\t\t\t}, repo.MustAllowPulls)\n\n\t\t\tm.Group(\"\", func() {\n\t\t\t\tm.Get(\"/src/*\", repo.Home)\n\t\t\t\tm.Get(\"/raw/*\", repo.SingleDownload)\n\t\t\t\tm.Get(\"/commits/*\", repo.RefCommits)\n\t\t\t\tm.Get(\"/commit/:sha([a-f0-9]{7,40})$\", repo.Diff)\n\t\t\t\tm.Get(\"/forks\", repo.Forks)\n\t\t\t}, repo.MustBeNotBare, context.RepoRef())\n\t\t\tm.Get(\"/commit/:sha([a-f0-9]{7,40})\\\\.:ext(patch|diff)\", repo.MustBeNotBare, repo.RawDiff)\n\n\t\t\tm.Get(\"/compare/:before([a-z0-9]{40})\\\\.\\\\.\\\\.:after([a-z0-9]{40})\", repo.MustBeNotBare, context.RepoRef(), repo.CompareDiff)\n\t\t}, ignSignIn, context.RepoAssignment())\n\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\tm.Get(\"\", context.ServeGoGet(), repo.Home)\n\t\t\tm.Get(\"/stars\", repo.Stars)\n\t\t\tm.Get(\"/watchers\", repo.Watchers)\n\t\t}, ignSignIn, context.RepoAssignment(), context.RepoRef())\n\t\t// ***** END: Repository *****\n\n\t\t// **********************\n\t\t// ----- API routes -----\n\t\t// **********************\n\n\t\t// TODO: Without session and CSRF\n\t\tm.Group(\"/api\", func() {\n\t\t\tapiv1.RegisterRoutes(m)\n\t\t}, ignSignIn)\n\t},\n\t\tsession.Sessioner(session.Options{\n\t\t\tProvider:       conf.Session.Provider,\n\t\t\tProviderConfig: conf.Session.ProviderConfig,\n\t\t\tCookieName:     conf.Session.CookieName,\n\t\t\tCookiePath:     conf.Server.Subpath,\n\t\t\tGclifetime:     conf.Session.GCInterval,\n\t\t\tMaxlifetime:    conf.Session.MaxLifeTime,\n\t\t\tSecure:         conf.Session.CookieSecure,\n\t\t}),\n\t\tcsrf.Csrfer(csrf.Options{\n\t\t\tSecret:         conf.Security.SecretKey,\n\t\t\tHeader:         \"X-CSRF-Token\",\n\t\t\tCookie:         conf.Session.CSRFCookieName,\n\t\t\tCookieDomain:   conf.Server.URL.Hostname(),\n\t\t\tCookiePath:     conf.Server.Subpath,\n\t\t\tCookieHttpOnly: true,\n\t\t\tSetCookie:      true,\n\t\t\tSecure:         conf.Server.URL.Scheme == \"https\",\n\t\t}),\n\t\tcontext.Contexter(),\n\t)\n\n\t// ***************************\n\t// ----- HTTP Git routes -----\n\t// ***************************\n\n\tm.Group(\"/:username/:reponame\", func() {\n\t\tm.Get(\"/tasks/trigger\", repo.TriggerTask)\n\n\t\tm.Group(\"/info/lfs\", func() {\n\t\t\tlfs.RegisterRoutes(m.Router)\n\t\t})\n\n\t\tm.Route(\"/*\", \"GET,POST,OPTIONS\", context.ServeGoGet(), repo.HTTPContexter(), repo.HTTP)\n\t})\n\n\t// ***************************\n\t// ----- Internal routes -----\n\t// ***************************\n\n\tm.Group(\"/-\", func() {\n\t\tm.Get(\"/metrics\", app.MetricsFilter(), promhttp.Handler()) // \"/-/metrics\"\n\n\t\tm.Group(\"/api\", func() {\n\t\t\tm.Post(\"/sanitize_ipynb\", app.SanitizeIpynb()) // \"/-/api/sanitize_ipynb\"\n\t\t})\n\t})\n\n\t// **********************\n\t// ----- robots.txt -----\n\t// **********************\n\n\tm.Get(\"/robots.txt\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif conf.HasRobotsTxt {\n\t\t\thttp.ServeFile(w, r, filepath.Join(conf.CustomDir(), \"robots.txt\"))\n\t\t} else {\n\t\t\tw.WriteHeader(http.StatusNotFound)\n\t\t}\n\t})\n\n\tm.NotFound(route.NotFound)\n\n\t// Flag for port number in case first time run conflict.\n\tif c.IsSet(\"port\") {\n\t\tconf.Server.URL.Host = strings.Replace(conf.Server.URL.Host, \":\"+conf.Server.URL.Port(), \":\"+c.String(\"port\"), 1)\n\t\tconf.Server.ExternalURL = conf.Server.URL.String()\n\t\tconf.Server.HTTPPort = c.String(\"port\")\n\t}\n\n\tvar listenAddr string\n\tif conf.Server.Protocol == \"unix\" {\n\t\tlistenAddr = conf.Server.HTTPAddr\n\t\tlog.Info(\"Listen on %v://%s\", conf.Server.Protocol, listenAddr)\n\t} else {\n\t\tlistenAddr = fmt.Sprintf(\"%s:%s\", conf.Server.HTTPAddr, conf.Server.HTTPPort)\n\t\tlog.Info(\"Listen on %v://%s%s\", conf.Server.Protocol, listenAddr, conf.Server.Subpath)\n\t}\n\n\tswitch conf.Server.Protocol {\n\tcase \"http\":\n\t\terr = http.ListenAndServe(listenAddr, m)\n\n\tcase \"https\":\n\t\ttlsMinVersion := tls.VersionTLS12\n\t\tswitch conf.Server.TLSMinVersion {\n\t\tcase \"TLS13\":\n\t\t\ttlsMinVersion = tls.VersionTLS13\n\t\tcase \"TLS12\":\n\t\t\ttlsMinVersion = tls.VersionTLS12\n\t\tcase \"TLS11\":\n\t\t\ttlsMinVersion = tls.VersionTLS11\n\t\tcase \"TLS10\":\n\t\t\ttlsMinVersion = tls.VersionTLS10\n\t\t}\n\t\tserver := &http.Server{\n\t\t\tAddr: listenAddr,\n\t\t\tTLSConfig: &tls.Config{\n\t\t\t\tMinVersion:               uint16(tlsMinVersion),\n\t\t\t\tCurvePreferences:         []tls.CurveID{tls.X25519, tls.CurveP256, tls.CurveP384, tls.CurveP521},\n\t\t\t\tPreferServerCipherSuites: true,\n\t\t\t\tCipherSuites: []uint16{\n\t\t\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\t\t\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\t\t\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\t\t\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n\t\t\t\t\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\t\t\t\t\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n\t\t\t\t},\n\t\t\t}, Handler: m}\n\t\terr = server.ListenAndServeTLS(conf.Server.CertFile, conf.Server.KeyFile)\n\n\tcase \"fcgi\":\n\t\terr = fcgi.Serve(nil, m)\n\n\tcase \"unix\":\n\t\tif osutil.IsExist(listenAddr) {\n\t\t\terr = os.Remove(listenAddr)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatal(\"Failed to remove existing Unix domain socket: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\tvar listener *net.UnixListener\n\t\tlistener, err = net.ListenUnix(\"unix\", &net.UnixAddr{Name: listenAddr, Net: \"unix\"})\n\t\tif err != nil {\n\t\t\tlog.Fatal(\"Failed to listen on Unix networks: %v\", err)\n\t\t}\n\n\t\t// FIXME: add proper implementation of signal capture on all protocols\n\t\t// execute this on SIGTERM or SIGINT: listener.Close()\n\t\tif err = os.Chmod(listenAddr, conf.Server.UnixSocketMode); err != nil {\n\t\t\tlog.Fatal(\"Failed to change permission of Unix domain socket: %v\", err)\n\t\t}\n\t\terr = http.Serve(listener, m)\n\n\tdefault:\n\t\tlog.Fatal(\"Unexpected server protocol: %s\", conf.Server.Protocol)\n\t}\n\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to start server: %v\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) MonitorListConfig(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.MonitoringProviders, error) {\n\tout := new(clientpb.MonitoringProviders)\n\terr := c.cc.Invoke(ctx, SliverRPC_MonitorListConfig_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (client GroupsClient) CheckExistenceSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (m *Manager) downloadAll(deps []*chart.Dependency) error {\n\trepos, err := m.loadChartRepositories()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdestPath := filepath.Join(m.ChartPath, \"charts\")\n\ttmpPath := filepath.Join(m.ChartPath, \"tmpcharts\")\n\n\t// Create 'charts' directory if it doesn't already exist.\n\tif fi, err := os.Stat(destPath); err != nil {\n\t\tif err := os.MkdirAll(destPath, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else if !fi.IsDir() {\n\t\treturn errors.Errorf(\"%q is not a directory\", destPath)\n\t}\n\n\tif err := fs.RenameWithFallback(destPath, tmpPath); err != nil {\n\t\treturn errors.Wrap(err, \"unable to move current charts to tmp dir\")\n\t}\n\n\tif err := os.MkdirAll(destPath, 0755); err != nil {\n\t\treturn err\n\t}\n\n\tfmt.Fprintf(m.Out, \"Saving %d charts\\n\", len(deps))\n\tvar saveError error\n\tchurls := make(map[string]struct{})\n\tfor _, dep := range deps {\n\t\t// No repository means the chart is in charts directory\n\t\tif dep.Repository == \"\" {\n\t\t\tfmt.Fprintf(m.Out, \"Dependency %s did not declare a repository. Assuming it exists in the charts directory\\n\", dep.Name)\n\t\t\tchartPath := filepath.Join(tmpPath, dep.Name)\n\t\t\tch, err := loader.LoadDir(chartPath)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"Unable to load chart: %v\", err)\n\t\t\t}\n\n\t\t\tconstraint, err := semver.NewConstraint(dep.Version)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"Dependency %s has an invalid version/constraint format: %s\", dep.Name, err)\n\t\t\t}\n\n\t\t\tv, err := semver.NewVersion(ch.Metadata.Version)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"Invalid version %s for dependency %s: %s\", dep.Version, dep.Name, err)\n\t\t\t}\n\n\t\t\tif !constraint.Check(v) {\n\t\t\t\tsaveError = fmt.Errorf(\"Dependency %s at version %s does not satisfy the constraint %s\", dep.Name, ch.Metadata.Version, dep.Version)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(dep.Repository, \"file://\") {\n\t\t\tif m.Debug {\n\t\t\t\tfmt.Fprintf(m.Out, \"Archiving %s from repo %s\\n\", dep.Name, dep.Repository)\n\t\t\t}\n\t\t\tver, err := tarFromLocalDir(m.ChartPath, dep.Name, dep.Repository, dep.Version)\n\t\t\tif err != nil {\n\t\t\t\tsaveError = err\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdep.Version = ver\n\t\t\tcontinue\n\t\t}\n\n\t\t// Any failure to resolve/download a chart should fail:\n\t\t// https://github.com/helm/helm/issues/1439\n\t\tchurl, username, password, passcredentialsall, err := m.findChartURL(dep.Name, dep.Version, dep.Repository, repos)\n\t\tif err != nil {\n\t\t\tsaveError = errors.Wrapf(err, \"could not find %s\", churl)\n\t\t\tbreak\n\t\t}\n\n\t\tif _, ok := churls[churl]; ok {\n\t\t\tfmt.Fprintf(m.Out, \"Already downloaded %s from repo %s\\n\", dep.Name, dep.Repository)\n\t\t\tcontinue\n\t\t}\n\n\t\tfmt.Fprintf(m.Out, \"Downloading %s from repo %s\\n\", dep.Name, dep.Repository)\n\n\t\tdl := ChartDownloader{\n\t\t\tOut:              m.Out,\n\t\t\tVerify:           m.Verify,\n\t\t\tKeyring:          m.Keyring,\n\t\t\tRepositoryConfig: m.RepositoryConfig,\n\t\t\tRepositoryCache:  m.RepositoryCache,\n\t\t\tGetters:          m.Getters,\n\t\t\tOptions: []getter.Option{\n\t\t\t\tgetter.WithBasicAuth(username, password),\n\t\t\t\tgetter.WithPassCredentialsAll(passcredentialsall),\n\t\t\t},\n\t\t}\n\n\t\tversion := \"\"\n\t\tif strings.HasPrefix(churl, \"oci://\") {\n\t\t\tif !resolver.FeatureGateOCI.IsEnabled() {\n\t\t\t\treturn errors.Wrapf(resolver.FeatureGateOCI.Error(),\n\t\t\t\t\t\"the repository %s is an OCI registry\", churl)\n\t\t\t}\n\n\t\t\tchurl, version, err = parseOCIRef(churl)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"could not parse OCI reference\")\n\t\t\t}\n\t\t\tdl.Options = append(dl.Options,\n\t\t\t\tgetter.WithRegistryClient(m.RegistryClient),\n\t\t\t\tgetter.WithTagName(version))\n\t\t}\n\n\t\t_, _, err = dl.DownloadTo(churl, version, destPath)\n\t\tif err != nil {\n\t\t\tsaveError = errors.Wrapf(err, \"could not download %s\", churl)\n\t\t\tbreak\n\t\t}\n\n\t\tchurls[churl] = struct{}{}\n\t}\n\n\tif saveError == nil {\n\t\tfmt.Fprintln(m.Out, \"Deleting outdated charts\")\n\t\tfor _, dep := range deps {\n\t\t\t// Chart from local charts directory stays in place\n\t\t\tif dep.Repository != \"\" {\n\t\t\t\tif err := m.safeDeleteDep(dep.Name, tmpPath); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif err := move(tmpPath, destPath); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := os.RemoveAll(tmpPath); err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to remove %v\", tmpPath)\n\t\t}\n\t} else {\n\t\tfmt.Fprintln(m.Out, \"Save error occurred: \", saveError)\n\t\tfmt.Fprintln(m.Out, \"Deleting newly downloaded charts, restoring pre-update state\")\n\t\tfor _, dep := range deps {\n\t\t\tif err := m.safeDeleteDep(dep.Name, destPath); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif err := os.RemoveAll(destPath); err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to remove %v\", destPath)\n\t\t}\n\t\tif err := fs.RenameWithFallback(tmpPath, destPath); err != nil {\n\t\t\treturn errors.Wrap(err, \"unable to move current charts to tmp dir\")\n\t\t}\n\t\treturn saveError\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) SaveHTTPC2Profile(ctx context.Context, in *clientpb.HTTPC2ConfigReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/SaveHTTPC2Profile\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tif err := cmd.Process.Release(); err != nil {\n\t\t\tlogrus.Errorf(\"unable to release rootlessport process: %q\", err)\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CrackstationRegister(ctx context.Context, in *clientpb.Crackstation, opts ...grpc.CallOption) (SliverRPC_CrackstationRegisterClient, error) {\n\tstream, err := c.cc.NewStream(ctx, &SliverRPC_ServiceDesc.Streams[2], \"/rpcpb.SliverRPC/CrackstationRegister\", opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tx := &sliverRPCCrackstationRegisterClient{stream}\n\tif err := x.ClientStream.SendMsg(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := x.ClientStream.CloseSend(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn x, nil\n}", "is_vulnerable": 0}
{"code": "\t\tapp.WithHandlerFunc(\"/helloworld\", func(w http.ResponseWriter, r *http.Request) {\n\t\t\tn.ch <- r.Header\n\t\t}),", "is_vulnerable": 0}
{"code": "func NewRiskyAnnotations(name string) error {\n\treturn RiskyAnnotationError{\n\t\tReason: fmt.Errorf(\"annotation group %s contains risky annotation based on ingress configuration\", name),\n\t}\n}", "is_vulnerable": 0}
{"code": "func extractStatements(ctx context.Context, repoRef name.Reference, desc v1.Descriptor, craneOpts ...crane.Option) ([]map[string]interface{}, error) {", "is_vulnerable": 0}
{"code": "func (a affinity) cookieAffinityParse(ing *networking.Ingress) *Cookie {\n\tvar err error\n\n\tcookie := &Cookie{}\n\n\tcookie.Name, err = parser.GetStringAnnotation(annotationAffinityCookieName, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieName, \"default\", defaultAffinityCookieName)\n\t\tcookie.Name = defaultAffinityCookieName\n\t}\n\n\tcookie.Expires, err = parser.GetStringAnnotation(annotationAffinityCookieExpires, ing)\n\tif err != nil || !affinityCookieExpiresRegex.MatchString(cookie.Expires) {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieExpires)\n\t\tcookie.Expires = \"\"\n\t}\n\n\tcookie.MaxAge, err = parser.GetStringAnnotation(annotationAffinityCookieMaxAge, ing)\n\tif err != nil || !affinityCookieExpiresRegex.MatchString(cookie.MaxAge) {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieMaxAge)\n\t\tcookie.MaxAge = \"\"\n\t}\n\n\tcookie.Path, err = parser.GetStringAnnotation(annotationAffinityCookiePath, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookiePath)\n\t}\n\n\tcookie.Domain, err = parser.GetStringAnnotation(annotationAffinityCookieDomain, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieDomain)\n\t}\n\n\tcookie.SameSite, err = parser.GetStringAnnotation(annotationAffinityCookieSameSite, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieSameSite)\n\t}\n\n\tcookie.Secure, err = parser.GetBoolAnnotation(annotationAffinityCookieSecure, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieSecure)\n\t}\n\n\tcookie.ConditionalSameSiteNone, err = parser.GetBoolAnnotation(annotationAffinityCookieConditionalSameSiteNone, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieConditionalSameSiteNone)\n\t}\n\n\tcookie.ChangeOnFailure, err = parser.GetBoolAnnotation(annotationAffinityCookieChangeOnFailure, ing)\n\tif err != nil {\n\t\tklog.V(3).InfoS(\"Invalid or no annotation value found. Ignoring\", \"ingress\", klog.KObj(ing), \"annotation\", annotationAffinityCookieChangeOnFailure)\n\t}\n\n\treturn cookie\n}", "is_vulnerable": 1}
{"code": "func DeleteExecutionsWorkflow(ctx workflow.Context, params DeleteExecutionsParams) (DeleteExecutionsResult, error) {\n\tlogger := workflow.GetLogger(ctx)\n\tlogger.Info(\"Workflow started.\", tag.WorkflowType(WorkflowName))\n\tresult := DeleteExecutionsResult{\n\t\tSuccessCount: params.PreviousSuccessCount,\n\t\tErrorCount:   params.PreviousErrorCount,\n\t}\n\n\tif err := validateParams(&params); err != nil {\n\t\treturn result, err\n\t}\n\tlogger.Info(\"Effective config.\", tag.Value(params.Config.String()))\n\n\tvar a *Activities\n\tnextPageToken := params.NextPageToken\n\trunningDeleteExecutionsActivityCount := 0\n\trunningDeleteExecutionsSelector := workflow.NewSelector(ctx)\n\tvar lastDeleteExecutionsActivityErr error\n\n\t// Two activities DeleteExecutionsActivity and GetNextPageTokenActivity are executed here essentially in reverse order\n\t// because Get is called immediately for GetNextPageTokenActivity but not for DeleteExecutionsActivity.\n\t// These activities scan visibility storage independently but GetNextPageTokenActivity considered to be quick and can be done synchronously.\n\t// It reads nextPageToken and pass it DeleteExecutionsActivity. This allocates block of workflow executions to delete for\n\t// DeleteExecutionsActivity which takes much longer to complete. This is why this workflow starts\n\t// ConcurrentDeleteExecutionsActivities number of them and executes them concurrently on available workers.\n\tfor i := 0; i < params.Config.PagesPerExecution; i++ {\n\t\tctx1 := workflow.WithActivityOptions(ctx, deleteWorkflowExecutionsActivityOptions)\n\t\tdeleteExecutionsFuture := workflow.ExecuteActivity(ctx1, a.DeleteExecutionsActivity, &DeleteExecutionsActivityParams{\n\t\t\tNamespace:     params.Namespace,\n\t\t\tNamespaceID:   params.NamespaceID,\n\t\t\tRPS:           params.Config.DeleteActivityRPS,\n\t\t\tListPageSize:  params.Config.PageSize,\n\t\t\tNextPageToken: nextPageToken,\n\t\t})\n\n\t\tctx2 := workflow.WithLocalActivityOptions(ctx, localActivityOptions)\n\t\terr := workflow.ExecuteLocalActivity(ctx2, a.GetNextPageTokenActivity, GetNextPageTokenParams{\n\t\t\tNamespaceID:   params.NamespaceID,\n\t\t\tNamespace:     params.Namespace,\n\t\t\tPageSize:      params.Config.PageSize,\n\t\t\tNextPageToken: nextPageToken,\n\t\t}).Get(ctx, &nextPageToken)\n\t\tif err != nil {\n\t\t\treturn result, fmt.Errorf(\"%w: GetNextPageTokenActivity: %v\", errors.ErrUnableToExecuteActivity, err)\n\t\t}\n\n\t\trunningDeleteExecutionsActivityCount++\n\t\trunningDeleteExecutionsSelector.AddFuture(deleteExecutionsFuture, func(f workflow.Future) {\n\t\t\trunningDeleteExecutionsActivityCount--\n\t\t\tvar der DeleteExecutionsActivityResult\n\t\t\tdeErr := f.Get(ctx, &der)\n\t\t\tif deErr != nil {\n\t\t\t\tlastDeleteExecutionsActivityErr = deErr\n\t\t\t\treturn\n\t\t\t}\n\t\t\tresult.SuccessCount += der.SuccessCount\n\t\t\tresult.ErrorCount += der.ErrorCount\n\t\t})\n\n\t\tif runningDeleteExecutionsActivityCount >= params.Config.ConcurrentDeleteExecutionsActivities {\n\t\t\t// Wait for one of running activities to complete.\n\t\t\trunningDeleteExecutionsSelector.Select(ctx)\n\t\t\tif lastDeleteExecutionsActivityErr != nil {\n\t\t\t\treturn result, fmt.Errorf(\"%w: DeleteExecutionsActivity: %v\", errors.ErrUnableToExecuteActivity, lastDeleteExecutionsActivityErr)\n\t\t\t}\n\t\t}\n\n\t\tif nextPageToken == nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Wait for all running activities to complete.\n\tfor runningDeleteExecutionsActivityCount > 0 {\n\t\trunningDeleteExecutionsSelector.Select(ctx)\n\t\tif lastDeleteExecutionsActivityErr != nil {\n\t\t\treturn result, fmt.Errorf(\"%w: DeleteExecutionsActivity: %v\", errors.ErrUnableToExecuteActivity, lastDeleteExecutionsActivityErr)\n\t\t}\n\t}\n\n\tif nextPageToken == nil {\n\t\tif result.ErrorCount == 0 {\n\t\t\tlogger.Info(\"Successfully deleted workflow executions.\", tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount))\n\t\t} else {\n\t\t\tlogger.Error(\"Finish deleting workflow executions with some errors.\", tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount), tag.DeletedExecutionsErrorCount(result.ErrorCount))\n\t\t}\n\t\treturn result, nil\n\t}\n\n\t// Too many workflow executions, and ConcurrentDeleteExecutionsActivities activities has been started already.\n\t// Continue as new to prevent workflow history size explosion.\n\n\tparams.PreviousSuccessCount = result.SuccessCount\n\tparams.PreviousErrorCount = result.ErrorCount\n\tparams.ContinueAsNewCount++\n\tparams.NextPageToken = nextPageToken\n\n\tlogger.Info(\"There are more workflows to delete. Continuing workflow as new.\", tag.WorkflowType(WorkflowName), tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount), tag.DeletedExecutionsErrorCount(result.ErrorCount), tag.Counter(params.ContinueAsNewCount))\n\treturn result, workflow.NewContinueAsNewError(ctx, DeleteExecutionsWorkflow, params)\n}", "is_vulnerable": 1}
{"code": "func (t *InvalidPrevATXProof) DecodeScale(dec *scale.Decoder) (total int, err error) {\n\t{\n\t\tn, err := t.Atx1.DecodeScale(dec)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t\ttotal += n\n\t}\n\t{\n\t\tn, err := t.Atx2.DecodeScale(dec)\n\t\tif err != nil {\n\t\t\treturn total, err\n\t\t}\n\t\ttotal += n\n\t}\n\treturn total, nil\n}", "is_vulnerable": 0}
{"code": "func (cr *cancelingReader) ReverseQueryRelationships(\n\tctx context.Context,\n\tsubjectsFilter datastore.SubjectsFilter,\n\toptions ...options.ReverseQueryOptionsOption,\n) (datastore.RelationshipIterator, error) {\n\tcr.counter++\n\tif cr.counter > 1 {\n\t\treturn nil, context.Canceled\n\t}\n\treturn cr.Reader.ReverseQueryRelationships(ctx, subjectsFilter, options...)\n}", "is_vulnerable": 0}
{"code": "func stripSensitiveValueByKey(req fmt.Stringer, key string) string {\n\tvar parsed map[string]interface{}\n\n\terr := json.Unmarshal([]byte(req.String()), &parsed)\n\tif err != nil || parsed == nil {\n\t\treturn req.String()\n\t}\n\n\tvolumeContext, ok := parsed[\"volume_context\"].(map[string]interface{})\n\tif !ok {\n\t\treturn req.String()\n\t}\n\n\tif _, ok := volumeContext[key]; !ok {\n\t\treturn req.String()\n\t}\n\n\tvolumeContext[key] = \"***stripped***\"\n\n\tb, err := json.Marshal(parsed)\n\tif err != nil {\n\t\treturn req.String()\n\t}\n\n\treturn string(b)\n}", "is_vulnerable": 0}
{"code": "func migrationsSqlCockroach10Sql() (*asset, error) {\n\tbytes, err := migrationsSqlCockroach10SqlBytes()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo := bindataFileInfo{name: \"migrations/sql/cockroach/10.sql\", size: 173, mode: os.FileMode(420), modTime: time.Unix(1585815362, 0)}\n\ta := &asset{bytes: bytes, info: info}\n\treturn a, nil\n}", "is_vulnerable": 0}
{"code": "func Greater(t TestingT, e1 interface{}, e2 interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Greater(t, e1, e2, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func InEpsilon(t TestingT, expected interface{}, actual interface{}, epsilon float64, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.InEpsilon(t, expected, actual, epsilon, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (s *Squashfs) extract(files []string, reader io.Reader, dest string) error {\n\tif !s.HasUnsquashfs() {\n\t\treturn fmt.Errorf(\"could not extract squashfs data, unsquashfs not found\")\n\t}\n\n\t// pipe over stdin by default\n\tstdin := true\n\tfilename := \"/proc/self/fd/0\"\n\n\tif _, ok := reader.(*os.File); !ok {\n\t\t// use the destination parent directory to store the\n\t\t// temporary archive\n\t\ttmpdir := filepath.Dir(dest)\n\n\t\t// unsquashfs doesn't support to send file content over\n\t\t// a stdin pipe since it use lseek for every read it does\n\t\ttmp, err := ioutil.TempFile(tmpdir, \"archive-\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to create staging file: %s\", err)\n\t\t}\n\t\tfilename = tmp.Name()\n\t\tstdin = false\n\t\tdefer os.Remove(filename)\n\n\t\tif _, err := io.Copy(tmp, reader); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to copy content in staging file: %s\", err)\n\t\t}\n\t\tif err := tmp.Close(); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to close staging file: %s\", err)\n\t\t}\n\t}\n\n\t// If we are running as non-root, first try with `-user-xattrs` so we won't fail trying\n\t// to set system xatts. This isn't supported on unsquashfs 4.0 in RHEL6 so we\n\t//  have to fall back to not using that option on failure.\n\tif os.Geteuid() != 0 {\n\t\tsylog.Debugf(\"Rootless extraction. Trying -user-xattrs for unsquashfs\")\n\t\targs := []string{\"-user-xattrs\", \"-f\", \"-d\", dest, filename}\n\t\targs = append(args, files...)\n\t\tcmd := exec.Command(s.UnsquashfsPath, args...)\n\t\tif stdin {\n\t\t\tcmd.Stdin = reader\n\t\t}\n\n\t\to, err := cmd.CombinedOutput()\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Invalid options give output...\n\t\t// SYNTAX: unsquashfs [options] filesystem [directories or files to extract]\n\t\tif bytes.HasPrefix(o, []byte(\"SYNTAX\")) {\n\t\t\tsylog.Warningf(\"unsquashfs does not support -user-xattrs. Images with system xattrs may fail to extract\")\n\t\t} else {\n\t\t\t// A different error is fatal\n\t\t\treturn fmt.Errorf(\"extract command failed: %s: %s\", string(o), err)\n\t\t}\n\t}\n\n\targs := []string{\"-f\", \"-d\", dest, filename}\n\targs = append(args, files...)\n\tcmd := exec.Command(s.UnsquashfsPath, args...)\n\tif stdin {\n\t\tcmd.Stdin = reader\n\t}\n\tif o, err := cmd.CombinedOutput(); err != nil {\n\t\treturn fmt.Errorf(\"extract command failed: %s: %s\", string(o), err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_OutgoingTLS_OnlyCA(t *testing.T) {\n\tconf := &Config{\n\t\tCAFile: \"../test/ca/root.cer\",\n\t}\n\tc := NewConfigurator(conf)\n\ttlsConf, err := c.OutgoingRPCConfig()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, tlsConf)\n}", "is_vulnerable": 1}
{"code": "func (m *BytesValue) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowWrappers\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: BytesValue: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: BytesValue: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowWrappers\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthWrappers\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthWrappers\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Value = append(m.Value[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Value == nil {\n\t\t\t\tm.Value = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipWrappers(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthWrappers\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerSnapYamlBadPermsFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\tc.Assert(os.Chmod(s.snapDirPath, 0755), IsNil)\n\tc.Assert(os.Mkdir(filepath.Join(s.snapDirPath, \"meta\"), 0755), IsNil)\n\tc.Assert(os.WriteFile(filepath.Join(s.snapDirPath, \"meta\", \"snap.yaml\"), nil, 0), IsNil)\n\n\t// snapdir's / and /meta are 0755 (i.e. OK),\n\t// /meta/snap.yaml exists, but isn't readable\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(s.container(), info, discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tassert.Equal(t, test.want, IsBlockedLocalHostname(test.hostname, test.allowlist))\n\t\t})", "is_vulnerable": 0}
{"code": "func TestMqttAdaptorConnectError(t *testing.T) {\n\ta := initTestMqttAdaptor()\n\n\terr := a.Connect()\n\tgobottest.Assert(t, strings.Contains(err.Error(), \"connection refused\"), true)\n}", "is_vulnerable": 1}
{"code": "func newTerminalSession(w http.ResponseWriter, r *http.Request, responseHeader http.Header, sessionManager *util_session.SessionManager) (*terminalSession, error) {\n\ttoken, err := getToken(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tconn, err := upgrader.Upgrade(w, r, responseHeader)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsession := &terminalSession{\n\t\twsConn:         conn,\n\t\ttty:            true,\n\t\tsizeChan:       make(chan remotecommand.TerminalSize),\n\t\tdoneChan:       make(chan struct{}),\n\t\tsessionManager: sessionManager,\n\t\ttoken:          &token,\n\t}\n\treturn session, nil\n}", "is_vulnerable": 1}
{"code": "func (a opentracing) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, opentracingAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_CommonTLSConfigInsecureSkipVerify(t *testing.T) {\n\tc, err := NewConfigurator(Config{}, nil)\n\trequire.NoError(t, err)\n\ttlsConf := c.commonTLSConfig(false)\n\trequire.True(t, tlsConf.InsecureSkipVerify)\n\n\trequire.NoError(t, c.Update(Config{VerifyServerHostname: false}))\n\ttlsConf = c.commonTLSConfig(false)\n\trequire.True(t, tlsConf.InsecureSkipVerify)\n\n\trequire.NoError(t, c.Update(Config{VerifyServerHostname: true}))\n\ttlsConf = c.commonTLSConfig(false)\n\trequire.False(t, tlsConf.InsecureSkipVerify)\n}", "is_vulnerable": 0}
{"code": "func (m *EntriesClient) GetLogEntryByUUID(params *entries.GetLogEntryByUUIDParams, opts ...entries.ClientOption) (*entries.GetLogEntryByUUIDOK, error) {\n\treturn &entries.GetLogEntryByUUIDOK{\n\t\tPayload: data,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func Uncompress(in, out []byte) (error) {\n\tif int(C.LZ4_decompress_safe(p(in), p(out), clen(in), clen(out))) < 0 {\n\t\treturn errors.New(\"Malformed compression stream\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (hs *HTTPServer) makePluginResourceRequest(w http.ResponseWriter, req *http.Request, pCtx backend.PluginContext) error {\n\tkeepCookieModel := struct {\n\t\tKeepCookies []string `json:\"keepCookies\"`\n\t}{}\n\tif dis := pCtx.DataSourceInstanceSettings; dis != nil {\n\t\terr := json.Unmarshal(dis.JSONData, &keepCookieModel)\n\t\tif err != nil {\n\t\t\ths.log.Warn(\"failed to to unpack JSONData in datasource instance settings\", \"err\", err)\n\t\t}\n\t}\n\n\tlist := contexthandler.AuthHTTPHeaderListFromContext(req.Context())\n\tif list != nil {\n\t\tfor _, name := range list.Items {\n\t\t\treq.Header.Del(name)\n\t\t}\n\t}\n\n\tproxyutil.ClearCookieHeader(req, keepCookieModel.KeepCookies)\n\tproxyutil.PrepareProxyRequest(req)\n\n\tbody, err := ioutil.ReadAll(req.Body)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to read request body: %w\", err)\n\t}\n\n\tcrReq := &backend.CallResourceRequest{\n\t\tPluginContext: pCtx,\n\t\tPath:          req.URL.Path,\n\t\tMethod:        req.Method,\n\t\tURL:           req.URL.String(),\n\t\tHeaders:       req.Header,\n\t\tBody:          body,\n\t}\n\n\tchildCtx, cancel := context.WithCancel(req.Context())\n\tdefer cancel()\n\tstream := newCallResourceResponseStream(childCtx)\n\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\n\tdefer func() {\n\t\tif err := stream.Close(); err != nil {\n\t\t\ths.log.Warn(\"Failed to close plugin resource stream\", \"err\", err)\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tvar flushStreamErr error\n\tgo func() {\n\t\tflushStreamErr = hs.flushStream(stream, w)\n\t\twg.Done()\n\t}()\n\n\tif err := hs.pluginClient.CallResource(req.Context(), crReq, stream); err != nil {\n\t\treturn err\n\t}\n\n\treturn flushStreamErr\n}", "is_vulnerable": 1}
{"code": "func TestRewrite(t *testing.T) {\n\trepl := caddy.NewReplacer()\n\n\tfor i, tc := range []struct {\n\t\tinput, expect *http.Request\n\t\trule          Rewrite\n\t}{\n\t\t{\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{Method: \"GET\", URI: \"/\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{Method: \"POST\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"POST\", \"/\"),\n\t\t},\n\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"foo\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"foo\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo{http.request.uri.path}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/index.php?p={http.request.uri.path}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/index.php?p=%2Ffoo%2Fbar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"?a=b&{http.request.uri.query}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/?a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"{http.request.uri.path}?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"{http.request.uri.path}?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/index.php?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/index.php?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"?a=b&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?a=b&c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/index.php?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/index.php?a=b&c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/index.php?c=d&{http.request.uri.query}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/index.php?c=d&a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/index.php?{http.request.uri.query}&p={http.request.uri.path}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/index.php?a=b&p=%2Ffoo%2Fbar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"{http.request.uri.path}?\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar?a=b&c=d\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"?qs={http.request.uri.query}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo?a=b&c=d\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?qs=a%3Db%26c%3Dd\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo?{http.request.uri.query}#frag\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo?a=b#frag\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar?a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo{http.request.uri}?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/foo{http.request.uri}?{http.request.uri.query}&c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar?a=b&c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/bar?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/bar?a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"{http.request.uri.path}bar?c=d\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar?c=d\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/i{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/%C2%B7%E2%88%B5.png\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/i/%C2%B7%E2%88%B5.png\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/i{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/\u00b7\u2235.png?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/i/%C2%B7%E2%88%B5.png?a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/i{http.request.uri}\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/%C2%B7%E2%88%B5.png?a=b\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/i/%C2%B7%E2%88%B5.png?a=b\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/bar#?\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo#fragFirst?c=d\"), // not a valid query string (is part of fragment)\n\t\t\texpect: newRequest(t, \"GET\", \"/bar#?\"),             // I think this is right? but who knows; std lib drops fragment when parsing\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URI: \"/bar\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo#fragFirst?c=d\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/bar#fragFirst?c=d\"),\n\t\t},\n\n\t\t{\n\t\t\trule:   Rewrite{StripPathPrefix: \"/prefix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathPrefix: \"/prefix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/prefix/foo/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathPrefix: \"/prefix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/prefix/foo%2Fbar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo%2Fbar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathPrefix: \"/prefix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/prefix/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/prefix/bar\"),\n\t\t},\n\n\t\t{\n\t\t\trule:   Rewrite{StripPathSuffix: \"/suffix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathSuffix: \"suffix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar/suffix\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar/\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathSuffix: \"suffix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo%2Fbar/suffix\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo%2Fbar/\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{StripPathSuffix: \"/suffix\"},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/suffix/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/suffix/bar\"),\n\t\t},\n\n\t\t{\n\t\t\trule:   Rewrite{URISubstring: []substrReplacer{{Find: \"findme\", Replace: \"replaced\"}}},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URISubstring: []substrReplacer{{Find: \"findme\", Replace: \"replaced\"}}},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/findme/bar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/replaced/bar\"),\n\t\t},\n\t\t{\n\t\t\trule:   Rewrite{URISubstring: []substrReplacer{{Find: \"findme\", Replace: \"replaced\"}}},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo/findme%2Fbar\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/replaced%2Fbar\"),\n\t\t},\n\n\t\t{\n\t\t\trule:   Rewrite{PathRegexp: []*regexReplacer{{Find: \"/{2,}\", Replace: \"/\"}}},\n\t\t\tinput:  newRequest(t, \"GET\", \"/foo//bar///baz?a=b//c\"),\n\t\t\texpect: newRequest(t, \"GET\", \"/foo/bar/baz?a=b//c\"),\n\t\t},\n\t} {\n\t\t// copy the original input just enough so that we can\n\t\t// compare it after the rewrite to see if it changed\n\t\turlCopy := *tc.input.URL\n\t\toriginalInput := &http.Request{\n\t\t\tMethod:     tc.input.Method,\n\t\t\tRequestURI: tc.input.RequestURI,\n\t\t\tURL:        &urlCopy,\n\t\t}\n\n\t\t// populate the replacer just enough for our tests\n\t\trepl.Set(\"http.request.uri\", tc.input.RequestURI)\n\t\trepl.Set(\"http.request.uri.path\", tc.input.URL.Path)\n\t\trepl.Set(\"http.request.uri.query\", tc.input.URL.RawQuery)\n\n\t\t// we can't directly call Provision() without a valid caddy.Context\n\t\t// (TODO: fix that) so here we ad-hoc compile the regex\n\t\tfor _, rep := range tc.rule.PathRegexp {\n\t\t\tre, err := regexp.Compile(rep.Find)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\trep.re = re\n\t\t}\n\n\t\tchanged := tc.rule.Rewrite(tc.input, repl)\n\n\t\tif expected, actual := !reqEqual(originalInput, tc.input), changed; expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected changed=%t but was %t\", i, expected, actual)\n\t\t}\n\t\tif expected, actual := tc.expect.Method, tc.input.Method; expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected Method='%s' but got '%s'\", i, expected, actual)\n\t\t}\n\t\tif expected, actual := tc.expect.RequestURI, tc.input.RequestURI; expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected RequestURI='%s' but got '%s'\", i, expected, actual)\n\t\t}\n\t\tif expected, actual := tc.expect.URL.String(), tc.input.URL.String(); expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected URL='%s' but got '%s'\", i, expected, actual)\n\t\t}\n\t\tif expected, actual := tc.expect.URL.RequestURI(), tc.input.URL.RequestURI(); expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected URL.RequestURI()='%s' but got '%s'\", i, expected, actual)\n\t\t}\n\t\tif expected, actual := tc.expect.URL.Fragment, tc.input.URL.Fragment; expected != actual {\n\t\t\tt.Errorf(\"Test %d: Expected URL.Fragment='%s' but got '%s'\", i, expected, actual)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) ListComplete(ctx context.Context, resourceGroupName string, filter string, top *int32) (result DeploymentListResultIterator, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/DeploymentsClient.List\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response().Response.Response != nil {\n\t\t\t\tsc = result.page.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tresult.page, err = client.List(ctx, resourceGroupName, filter, top)\n\treturn\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\ts := sigs{\n\t\t\t\tImage: &fake.FakeImage{\n\t\t\t\t\tManifestStub: func() (*v1.Manifest, error) {\n\t\t\t\t\t\treturn &v1.Manifest{\n\t\t\t\t\t\t\tLayers: make([]v1.Descriptor, test.layers),\n\t\t\t\t\t\t}, nil\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\t\t\t_, err := s.Get()\n\t\t\tif test.wantError != nil && test.wantError.Error() != err.Error() {\n\t\t\t\tt.Fatalf(\"Get() = %v, wanted %v\", err, test.wantError)\n\t\t\t}\n\t\t\tif test.wantError == nil && err != nil {\n\t\t\t\tt.Fatalf(\"Get() = %v, wanted %v\", err, test.wantError)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func TestXfccAuthenticator(t *testing.T) {\n\tcases := []struct {\n\t\tname               string\n\t\txfccHeader         string\n\t\tcaller             *security.Caller\n\t\tauthenticateErrMsg string\n\t}{\n\t\t{\n\t\t\tname:       \"No xfcc header\",\n\t\t\txfccHeader: \"\",\n\t\t\tcaller:     nil,\n\t\t},\n\t\t{\n\t\t\tname:               \"junk xfcc header\",\n\t\t\txfccHeader:         `junk xfcc header`,\n\t\t\tauthenticateErrMsg: `error in parsing xfcc header: invalid header format: unexpected token \"junk xfcc header\"`,\n\t\t},\n\t\t{\n\t\t\tname: \"Xfcc Header single hop\",\n\t\t\t// nolint lll\n\t\t\txfccHeader: `Hash=meshclient;Subject=\"\";URI=spiffe://mesh.example.com/ns/otherns/sa/othersa`,\n\t\t\tcaller: &security.Caller{\n\t\t\t\tAuthSource: security.AuthSourceClientCertificate,\n\t\t\t\tIdentities: []string{\n\t\t\t\t\t\"spiffe://mesh.example.com/ns/otherns/sa/othersa\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Xfcc Header multiple hops\",\n\t\t\t// nolint lll\n\t\t\txfccHeader: `Hash=hash;Cert=\"-----BEGIN%20CERTIFICATE-----%0cert%0A-----END%20CERTIFICATE-----%0A\";Subject=\"CN=hello,OU=hello,O=Acme\\, Inc.\";URI=spiffe://mesh.example.com/ns/firstns/sa/firstsa;DNS=hello.west.example.com;DNS=hello.east.example.com,By=spiffe://mesh.example.com/ns/hellons/sa/hellosa;Hash=again;Subject=\"\";URI=spiffe://mesh.example.com/ns/otherns/sa/othersa`,\n\t\t\tcaller: &security.Caller{\n\t\t\t\tAuthSource: security.AuthSourceClientCertificate,\n\t\t\t\tIdentities: []string{\n\t\t\t\t\t\"spiffe://mesh.example.com/ns/firstns/sa/firstsa\",\n\t\t\t\t\t\"hello.west.example.com\",\n\t\t\t\t\t\"hello.east.example.com\",\n\t\t\t\t\t\"hello\",\n\t\t\t\t\t\"spiffe://mesh.example.com/ns/otherns/sa/othersa\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tauth := &XfccAuthenticator{}\n\n\tfor _, tt := range cases {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tmd := metadata.MD{}\n\t\t\tif len(tt.xfccHeader) > 0 {\n\t\t\t\tmd.Append(xfccparser.ForwardedClientCertHeader, tt.xfccHeader)\n\t\t\t}\n\t\t\taddr := net.TCPAddrFromAddrPort(netip.MustParseAddrPort(\"127.0.0.1:2301\"))\n\t\t\tctx := peer.NewContext(context.Background(), &peer.Peer{Addr: addr})\n\t\t\tctx = metadata.NewIncomingContext(ctx, md)\n\t\t\tresult, err := auth.Authenticate(security.AuthContext{GrpcContext: ctx})\n\t\t\tif len(tt.authenticateErrMsg) > 0 {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Errorf(\"Succeeded. Error expected: %v\", err)\n\t\t\t\t} else if err.Error() != tt.authenticateErrMsg {\n\t\t\t\t\tt.Errorf(\"Incorrect error message: want %s but got %s\",\n\t\t\t\t\t\ttt.authenticateErrMsg, err.Error())\n\t\t\t\t}\n\t\t\t} else if err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected Error: %v\", err)\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(tt.caller, result) {\n\t\t\t\tt.Errorf(\"Unexpected authentication result: want %v but got %v\",\n\t\t\t\t\ttt.caller, result)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tWriteHeader: func(httpsnoop.WriteHeaderFunc) httpsnoop.WriteHeaderFunc {\n\t\t\treturn rww.WriteHeader\n\t\t},\n\t})\n\n\tlabeler := &Labeler{}\n\tctx = injectLabeler(ctx, labeler)\n\n\tnext.ServeHTTP(w, r.WithContext(ctx))\n\n\tsetAfterServeAttributes(span, bw.read, rww.written, rww.statusCode, bw.err, rww.err)\n\n\t// Add metrics\n\tattributes := append(labeler.Get(), semconvutil.HTTPServerRequest(h.server, r)...)\n\tif rww.statusCode > 0 {\n\t\tattributes = append(attributes, semconv.HTTPStatusCode(rww.statusCode))\n\t}\n\to := metric.WithAttributes(attributes...)\n\th.counters[RequestContentLength].Add(ctx, bw.read, o)\n\th.counters[ResponseContentLength].Add(ctx, rww.written, o)\n\n\t// Use floating point division here for higher precision (instead of Millisecond method).\n\telapsedTime := float64(time.Since(requestStartTime)) / float64(time.Millisecond)\n\n\th.valueRecorders[ServerLatency].Record(ctx, elapsedTime, o)\n}", "is_vulnerable": 1}
{"code": "func (s *SMTP) GetDialer() (mailer.Dialer, error) {\n\t// Setup the message and dial\n\thp := strings.Split(s.Host, \":\")\n\tif len(hp) < 2 {\n\t\thp = append(hp, \"25\")\n\t}\n\thost := hp[0]\n\t// Any issues should have been caught in validation, but we'll\n\t// double check here.\n\tport, err := strconv.Atoi(hp[1])\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn nil, err\n\t}\n\tdialer := dialer.Dialer()\n\td := gomail.NewWithDialer(dialer, host, port, s.Username, s.Password)\n\td.TLSConfig = &tls.Config{\n\t\tServerName:         host,\n\t\tInsecureSkipVerify: s.IgnoreCertErrors,\n\t}\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\tlog.Error(err)\n\t\thostname = \"localhost\"\n\t}\n\td.LocalName = hostname\n\treturn &Dialer{d}, err\n}", "is_vulnerable": 0}
{"code": "func (sp *ServiceProvider) validateXMLResponse(resp *Response, responseEl *etree.Element, possibleRequestIDs []string, now time.Time, needSig bool) (*Assertion, *string, error) {\n\tvar err error\n\tvar updatedResponse *string\n\tif err := sp.validateDestination(responseEl, resp); err != nil {\n\t\treturn nil, updatedResponse, err\n\t}\n\n\trequestIDvalid := false\n\n\tif sp.AllowIDPInitiated {\n\t\trequestIDvalid = true\n\t} else {\n\t\tfor _, possibleRequestID := range possibleRequestIDs {\n\t\t\tif resp.InResponseTo == possibleRequestID {\n\t\t\t\trequestIDvalid = true\n\t\t\t}\n\t\t}\n\t}\n\n\tif !requestIDvalid {\n\t\treturn nil, updatedResponse, fmt.Errorf(\"`InResponseTo` does not match any of the possible request IDs (expected %v)\", possibleRequestIDs)\n\t}\n\n\tif resp.IssueInstant.Add(MaxIssueDelay).Before(now) {\n\t\treturn nil, updatedResponse, fmt.Errorf(\"response IssueInstant expired at %s\", resp.IssueInstant.Add(MaxIssueDelay))\n\t}\n\tif resp.Issuer != nil && resp.Issuer.Value != sp.IDPMetadata.EntityID {\n\t\treturn nil, updatedResponse, fmt.Errorf(\"response Issuer does not match the IDP metadata (expected %q)\", sp.IDPMetadata.EntityID)\n\t}\n\tif resp.Status.StatusCode.Value != StatusSuccess {\n\t\treturn nil, updatedResponse, ErrBadStatus{Status: resp.Status.StatusCode.Value}\n\t}\n\n\tvar assertion *Assertion\n\tif resp.EncryptedAssertion == nil {\n\t\t// TODO(ross): verify that the namespace is urn:oasis:names:tc:SAML:2.0:protocol\n\t\tif responseEl.Tag != \"Response\" {\n\t\t\treturn nil, updatedResponse, fmt.Errorf(\"expected to find a response object, not %s\", responseEl.Tag)\n\t\t}\n\n\t\tif err = sp.validateSigned(responseEl); err != nil && !(!needSig && err.Error() == \"either the Response or Assertion must be signed\") {\n\t\t\treturn nil, updatedResponse, err\n\t\t}\n\n\t\tassertion = resp.Assertion\n\t}\n\n\t// decrypt the response\n\tif resp.EncryptedAssertion != nil {\n\t\t// encrypted assertions are part of the signature\n\t\t// before decrypting the response verify that\n\t\tresponseSigned, err := responseIsSigned(responseEl)\n\t\tif err != nil {\n\t\t\treturn nil, updatedResponse, err\n\t\t}\n\t\tif responseSigned {\n\t\t\tif err := sp.validateSigned(responseEl); err != nil {\n\t\t\t\treturn nil, updatedResponse, err\n\t\t\t}\n\t\t}\n\n\t\tvar key interface{} = sp.Key\n\t\tkeyEl := responseEl.FindElement(\"//EncryptedAssertion/EncryptedKey\")\n\t\tif keyEl != nil {\n\t\t\tkey, err = xmlenc.Decrypt(sp.Key, keyEl)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, updatedResponse, fmt.Errorf(\"failed to decrypt key from response: %s\", err)\n\t\t\t}\n\t\t}\n\n\t\tel := responseEl.FindElement(\"//EncryptedAssertion/EncryptedData\")\n\t\tplaintextAssertion, err := xmlenc.Decrypt(key, el)\n\t\tif err != nil {\n\t\t\treturn nil, updatedResponse, fmt.Errorf(\"failed to decrypt response: %s\", err)\n\t\t}\n\t\tupdatedResponse = new(string)\n\t\t*updatedResponse = string(plaintextAssertion)\n\n\t\t// TODO(ross): add test case for this\n\t\tif err := xrv.Validate(bytes.NewReader(plaintextAssertion)); err != nil {\n\t\t\treturn nil, updatedResponse, fmt.Errorf(\"plaintext response contains invalid XML: %s\", err)\n\t\t}\n\n\t\tdoc := etree.NewDocument()\n\t\tif err := doc.ReadFromBytes(plaintextAssertion); err != nil {\n\t\t\treturn nil, updatedResponse, fmt.Errorf(\"cannot parse plaintext response %v\", err)\n\t\t}\n\n\t\t// the decrypted assertion may be signed too\n\t\t// otherwise, a signed response is sufficient\n\t\tif err := sp.validateSigned(doc.Root()); err != nil && !((responseSigned || !needSig) && err.Error() == \"either the Response or Assertion must be signed\") {\n\t\t\treturn nil, updatedResponse, err\n\t\t}\n\n\t\tassertion = &Assertion{}\n\t\t// Note: plaintextAssertion is known to be safe to parse because\n\t\t// plaintextAssertion is unmodified from when xrv.Validate() was called above.\n\t\tif err := xml.Unmarshal(plaintextAssertion, assertion); err != nil {\n\t\t\treturn nil, updatedResponse, err\n\t\t}\n\t}\n\n\tif err := sp.validateAssertion(assertion, possibleRequestIDs, now); err != nil {\n\t\treturn nil, updatedResponse, fmt.Errorf(\"assertion invalid: %s\", err)\n\t}\n\n\treturn assertion, updatedResponse, nil\n}", "is_vulnerable": 1}
{"code": "func init() {\n\tconf.App.Version = \"0.13.0+dev\"\n}", "is_vulnerable": 1}
{"code": "func (o *StackTrieOptions) WithWriter(writer func(path []byte, hash common.Hash, blob []byte)) *StackTrieOptions {", "is_vulnerable": 1}
{"code": "func handleGetProfile(w http.ResponseWriter, r *http.Request) {\n\tpj := profileJSON{}\n\tu := Context.auth.getCurrentUser(r)\n\n\tpj.Name = u.Name\n\n\tdata, err := json.Marshal(pj)\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"json.Marshal: %s\", err)\n\n\t\treturn\n\t}\n\n\t_, _ = w.Write(data)\n}", "is_vulnerable": 0}
{"code": "\tetcHostsPathFunc := func(podUID types.UID) string { return getEtcHostsPath(klet.getPodDir(podUID)) }", "is_vulnerable": 0}
{"code": "func (t *TelegramHandler) MessageHandle(ctx context.Context, bot *telegram.Bot, message telegram.Message, attachments []telegram.Attachment) error {\n\treply, err := bot.SendReplyMessage(ctx, message.Chat.ID, message.MessageID, workingMessage)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to SendReplyMessage\")\n\t}\n\n\tmessageSenderID := strconv.FormatInt(message.From.ID, 10)\n\tvar creatorID int32\n\tuserSettingList, err := t.store.ListUserSettings(ctx, &store.FindUserSetting{\n\t\tKey: storepb.UserSettingKey_USER_SETTING_TELEGRAM_USER_ID,\n\t})\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to find userSettingList\")\n\t}\n\tfor _, userSetting := range userSettingList {\n\t\tif userSetting.GetTelegramUserId() == messageSenderID {\n\t\t\tcreatorID = userSetting.UserId\n\t\t}\n\t}\n\n\t// If creatorID is not found, ask the user to set the telegram userid in UserSetting of memos.\n\tif creatorID == 0 {\n\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Please set your telegram userid %d in UserSetting of memos\", message.From.ID), nil)\n\t\treturn err\n\t}\n\n\tcreate := &store.Memo{\n\t\tUID:        shortuuid.New(),\n\t\tCreatorID:  creatorID,\n\t\tVisibility: store.Private,\n\t}\n\tif message.Text != nil {\n\t\tcreate.Content = convertToMarkdown(*message.Text, message.Entities)\n\t}\n\tif message.Caption != nil {\n\t\tcreate.Content = convertToMarkdown(*message.Caption, message.CaptionEntities)\n\t}\n\tif message.ForwardFromChat != nil {\n\t\tcreate.Content += fmt.Sprintf(\"\\n\\n[Message link](%s)\", message.GetMessageLink())\n\t}\n\tmemoMessage, err := t.store.CreateMemo(ctx, create)\n\tif err != nil {\n\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to CreateMemo: %s\", err), nil)\n\t\treturn err\n\t}\n\n\t// Dynamically upsert tags from memo content.\n\tnodes, err := parser.Parse(tokenizer.Tokenize(create.Content))\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to parse content\")\n\t}\n\ttags := []string{}\n\tapiv2.TraverseASTNodes(nodes, func(node ast.Node) {\n\t\tif tagNode, ok := node.(*ast.Tag); ok {\n\t\t\ttag := tagNode.Content\n\t\t\tif !slices.Contains(tags, tag) {\n\t\t\t\ttags = append(tags, tag)\n\t\t\t}\n\t\t}\n\t})\n\tfor _, tag := range tags {\n\t\t_, err := t.store.UpsertTag(ctx, &store.Tag{\n\t\t\tName:      tag,\n\t\t\tCreatorID: creatorID,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"Failed to upsert tag\")\n\t\t}\n\t}\n\n\t// Create memo related resources.\n\tfor _, attachment := range attachments {\n\t\t// Fill the common field of create\n\t\tcreate := store.Resource{\n\t\t\tUID:       shortuuid.New(),\n\t\t\tCreatorID: creatorID,\n\t\t\tFilename:  filepath.Base(attachment.FileName),\n\t\t\tType:      attachment.GetMimeType(),\n\t\t\tSize:      attachment.FileSize,\n\t\t\tMemoID:    &memoMessage.ID,\n\t\t\tBlob:      attachment.Data,\n\t\t}\n\n\t\terr := apiv2.SaveResourceBlob(ctx, t.store, &create)\n\t\tif err != nil {\n\t\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to SaveResourceBlob: %s\", err), nil)\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = t.store.CreateResource(ctx, &create)\n\t\tif err != nil {\n\t\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to CreateResource: %s\", err), nil)\n\t\t\treturn err\n\t\t}\n\t}\n\n\tkeyboard := generateKeyboardForMemoID(memoMessage.ID)\n\t_, err = bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Saved as %s Memo %d\", memoMessage.Visibility, memoMessage.ID), keyboard)\n\t_ = t.dispatchMemoRelatedWebhook(ctx, *memoMessage, \"memos.memo.created\")\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func StartManager(ctx context.Context, opt *Options) error {\n\tconfig, err := controllerruntime.GetConfig()\n\tif err != nil {\n\t\treturn err\n\t}\n\tconfig.QPS, config.Burst = opt.KubeAPIQPS, opt.KubeAPIBurst\n\tcontrollerManager, err := controllerruntime.NewManager(config, controllerruntime.Options{\n\t\tScheme:                     util.NewSchema(), // register schema\n\t\tLeaderElection:             opt.LeaderElection.LeaderElect,\n\t\tLeaderElectionID:           opt.LeaderElection.ResourceName,\n\t\tLeaderElectionNamespace:    opt.LeaderElection.ResourceNamespace,\n\t\tLeaderElectionResourceLock: opt.LeaderElection.ResourceLock,\n\t\tHealthProbeBindAddress:     net.JoinHostPort(opt.BindAddress, strconv.Itoa(opt.SecurePort)),\n\t\tLivenessEndpointName:       \"/healthz\",\n\t\tNamespace:                  util.GetCurrentNSOrDefault(),\n\t})\n\tif err != nil {\n\t\tklog.Errorf(\"Failed to build controllerManager ,%s\", err)\n\t\treturn err\n\t}\n\tif err := controllerManager.AddHealthzCheck(\"ping\", healthz.Ping); err != nil {\n\t\tklog.Errorf(\"Failed to add health check endpoint: %s\", err)\n\t\treturn err\n\t}\n\tif err := setupManager(controllerManager, opt, ctx.Done()); err != nil {\n\t\tklog.Errorf(\"setupManager %s\", err)\n\t\treturn err\n\t}\n\tif err := controllerManager.Start(ctx); err != nil {\n\t\tklog.Errorf(\"KubeanOperator ControllerManager exit ,%s\", err)\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func FsDirs(c *gin.Context) {\n\tvar req DirReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\tif req.ForceRoot {\n\t\tif !user.IsAdmin() {\n\t\t\tcommon.ErrorStrResp(c, \"Permission denied\", 403)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\treq.Path = stdpath.Join(user.BasePath, req.Path)\n\t}\n\tmeta, err := db.GetNearestMeta(req.Path)\n\tif err != nil {\n\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\treturn\n\t\t}\n\t}\n\tc.Set(\"meta\", meta)\n\tif !common.CanAccess(user, meta, req.Path, req.Password) {\n\t\tcommon.ErrorStrResp(c, \"password is incorrect\", 403)\n\t\treturn\n\t}\n\tobjs, err := fs.List(c, req.Path)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\tdirs := filterDirs(objs)\n\tcommon.SuccessResp(c, dirs)\n}", "is_vulnerable": 0}
{"code": "func (i *IDsViewHandler) GetIDs(params GetIDsParams, idsShouldMatch bool) ([]string, error) {\n\tids := []string{}\n\n\tif len(params.FilterIDs) == 0 {\n\t\t// nothing to filter by, so return nil so that the caller knows\n\t\t// the difference between a query wasn't made, and there were\n\t\t// no results\n\t\treturn nil, nil\n\t}\n\n\tlookupIDColumnName := getIDViewColumnNameByIDType(params.LookupIDType)\n\n\t// we will use Session(&gorm.Session{}) here so every call to the handler will start from scratch\n\ttx := i.IDsView.\n\t\tSession(&gorm.Session{}).\n\t\tSelect(\"distinct \" + lookupIDColumnName)\n\n\tfilterIDColumnName := getIDViewColumnNameByIDType(params.FilterIDType)\n\n\tif idsShouldMatch {\n\t\tfor _, id := range params.FilterIDs {\n\t\t\t// for each OR filter we need to verify that lookup id column is not null to avoid failing during Find\n\t\t\ttx.Or(\"? = ? AND ? is not null\", filterIDColumnName, id,\n\t\t\t\tlookupIDColumnName)\n\t\t}\n\t} else {\n\t\tfor _, id := range params.FilterIDs {\n\t\t\ttx.Not(filterIDColumnName+\" = ?\", id)\n\t\t}\n\t\t// after we filter out all ids need to verify that lookup id column is not null to avoid failing during Find\n\t\ttx.Where(lookupIDColumnName + \" is not null\")\n\t}\n\n\t// Verify that query will return at least one result.\n\tvar count int64\n\tif err := tx.Count(&count).Error; err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to count IDs: %v\", err)\n\t}\n\tif count <= 0 {\n\t\t// No need to run query, but return empty list of strings\n\t\t// because there are no results, not nil\n\t\tlog.Debugf(\"no IDs found. pararms=%+v\", params)\n\t\treturn ids, nil\n\t}\n\n\t// Run query.\n\tif err := tx.Find(&ids).Error; err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get IDs: %v\", err)\n\t}\n\n\treturn ids, nil\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tAuthRequests: func(tt *testing.T, userID string) cache.AuthRequestCache {\n\t\t\t\t\tm := mock.NewMockAuthRequestCache(gomock.NewController(tt))\n\t\t\t\t\ta := authRequest(userID)\n\t\t\t\t\tm.EXPECT().GetAuthRequestByID(gomock.Any(), \"authRequestID\").Return(a, nil)\n\t\t\t\t\tm.EXPECT().CacheAuthRequest(gomock.Any(), a)\n\t\t\t\t\treturn m\n\t\t\t\t},\n\t\t\t\tUserViewProvider:  &mockViewUser{},\n\t\t\t\tUserEventProvider: &mockEventUser{},\n\t\t\t\tOrgViewProvider:   &mockViewOrg{State: domain.OrgStateActive},\n\t\t\t\tPasswordChecker: &mockPasswordChecker{\n\t\t\t\t\terr: command.ErrPasswordInvalid(nil),\n\t\t\t\t},\n\t\t\t},\n\t\t\targs: args{\n\t\t\t\tctx:           authz.NewMockContext(\"instance1\", \"\", \"\"),\n\t\t\t\tauthReqID:     \"authRequestID\",\n\t\t\t\tuserID:        \"user1\",\n\t\t\t\tresourceOwner: \"org1\",\n\t\t\t\tpassword:      \"password\",\n\t\t\t\tuserAgentID:   \"userAgentID\",\n\t\t\t\tinfo: &domain.BrowserInfo{\n\t\t\t\t\tUserAgent: \"useragent\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\trepo := &AuthRequestRepo{\n\t\t\t\tAuthRequests:      tt.fields.AuthRequests(t, tt.args.userID),\n\t\t\t\tUserViewProvider:  tt.fields.UserViewProvider,\n\t\t\t\tUserEventProvider: tt.fields.UserEventProvider,\n\t\t\t\tOrgViewProvider:   tt.fields.OrgViewProvider,\n\t\t\t\tPasswordChecker:   tt.fields.PasswordChecker,\n\t\t\t}\n\t\t\terr := repo.VerifyPassword(tt.args.ctx, tt.args.authReqID, tt.args.userID, tt.args.resourceOwner, tt.args.password, tt.args.userAgentID, tt.args.info)\n\t\t\tassert.ErrorIs(t, err, zerrors.ThrowInvalidArgument(nil, \"EVENT-SDe2f\", \"Errors.User.UsernameOrPassword.Invalid\"))\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\tds.ListSoftwareFunc = func(ctx context.Context, opt fleet.SoftwareListOptions) ([]fleet.Software, error) {\n\t\treturn []fleet.Software{}, nil\n\t}", "is_vulnerable": 0}
{"code": "\tt.Run(\"database_errors\", func(t *testing.T) {\n\t\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\t\ts := MustNewServerWithOpts(\n\t\t\tWithDatastore(mockDatastore),\n\t\t)\n\n\t\tmodelID := ulid.Make().String()\n\n\t\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgav1.AuthorizationModel{\n\t\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\t\tTypeDefinitions: parser.MustParse(`\n\t\t\ttype user\n\t\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t\tdefine viewer: [user, user:*] as self\n\t\t\t`),\n\t\t}, nil)\n\n\t\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, storage.ReadStartingWithUserFilter{\n\t\t\tObjectType: \"document\",\n\t\t\tRelation:   \"viewer\",\n\t\t\tUserFilter: []*openfgav1.ObjectRelation{\n\t\t\t\t{Object: \"user:*\"},\n\t\t\t\t{Object: \"user:bob\"},\n\t\t\t}}).AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\t\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\t\tres, err := s.ListObjects(ctx, &openfgav1.ListObjectsRequest{\n\t\t\t\tStoreId:              store,\n\t\t\t\tAuthorizationModelId: modelID,\n\t\t\t\tType:                 \"document\",\n\t\t\t\tRelation:             \"viewer\",\n\t\t\t\tUser:                 \"user:bob\",\n\t\t\t})\n\n\t\t\trequire.Nil(t, res)\n\t\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t\t})\n\n\t\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\t\terr := s.StreamedListObjects(&openfgav1.StreamedListObjectsRequest{\n\t\t\t\tStoreId:              store,\n\t\t\t\tAuthorizationModelId: modelID,\n\t\t\t\tType:                 \"document\",\n\t\t\t\tRelation:             \"viewer\",\n\t\t\t\tUser:                 \"user:bob\",\n\t\t\t}, NewMockStreamServer())\n\n\t\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t\t})\n\t})", "is_vulnerable": 0}
{"code": "func (sp *ServiceProvider) ParseXMLResponse(decodedResponseXML []byte, possibleRequestIDs []string) (*Assertion, error) {\n\tnow := TimeNow()\n\tvar err error\n\tretErr := &InvalidResponseError{\n\t\tNow:      now,\n\t\tResponse: string(decodedResponseXML),\n\t}\n\n\t// ensure that the response XML is well-formed before we parse it\n\tif err := xrv.Validate(bytes.NewReader(decodedResponseXML)); err != nil {\n\t\tretErr.PrivateErr = fmt.Errorf(\"invalid xml: %s\", err)\n\t\treturn nil, retErr\n\t}\n\n\tdoc := etree.NewDocument()\n\tif err := doc.ReadFromBytes(decodedResponseXML); err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn nil, retErr\n\t}\n\n\tassertion, err := sp.parseResponse(doc.Root(), possibleRequestIDs, now, signatureRequired)\n\tif err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn nil, retErr\n\t}\n\n\treturn assertion, nil\n}", "is_vulnerable": 0}
{"code": "func GetRandomString(i int) string {\n\tif i < 1 {\n\t\ti = 40\n\t}\n\treturn gen(uint32(i), charset)\n}", "is_vulnerable": 0}
{"code": "func (v Version) StringVerbose() string {\n\tvar (\n\t\tvers = v.Vers\n\t\thash = v.Hash\n\t\tdate = v.Date\n\t)\n\tif vers == \"\" {\n\t\tvers = \"v0.0.0\"\n\t}\n\tif hash == \"\" {\n\t\thash = \"source\"\n\t}\n\tif date == \"\" {\n\t\tdate = time.Now().Format(time.RFC3339)\n\t}\n\tfuncVersion := fmt.Sprintf(\"%s-%s-%s\", vers, hash, date)\n\treturn fmt.Sprintf(\"Version: %s\\n\"+\n\t\t\"SocatImage: %s\\n\"+\n\t\t\"TarImage: %s\", funcVersion,\n\t\tk8s.SocatImage,\n\t\tk8s.TarImage)\n}", "is_vulnerable": 0}
{"code": "func (c *immuClient) OpenSession(ctx context.Context, user []byte, pass []byte, database string) (err error) {\n\tif c.IsConnected() {\n\t\treturn errors.FromError(ErrSessionAlreadyOpen)\n\t}\n\n\tif c.Options.ServerSigningPubKey != \"\" {\n\t\tpk, e := signer.ParsePublicKeyFile(c.Options.ServerSigningPubKey)\n\t\tif e != nil {\n\t\t\treturn e\n\t\t}\n\t\tc.WithServerSigningPubKey(pk)\n\t}\n\n\tif c.Options.StreamChunkSize < stream.MinChunkSize {\n\t\treturn errors.New(stream.ErrChunkTooSmall).WithCode(errors.CodInvalidParameterValue)\n\t}\n\n\tdialOptions := c.SetupDialOptions(c.Options)\n\n\tclientConn, err := grpc.Dial(c.Options.Bind(), dialOptions...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\tif err != nil {\n\t\t\t_ = clientConn.Close()\n\t\t}\n\t}()\n\n\tserviceClient := schema.NewImmuServiceClient(clientConn)\n\tresp, err := serviceClient.OpenSession(ctx, &schema.OpenSessionRequest{\n\t\tUsername:     user,\n\t\tPassword:     pass,\n\t\tDatabaseName: database,\n\t})\n\tif err != nil {\n\t\treturn errors.FromError(err)\n\t}\n\tdefer func() {\n\t\tif err != nil {\n\t\t\t_, _ = serviceClient.CloseSession(ctx, new(empty.Empty))\n\t\t}\n\t}()\n\n\tstateCache := cache.NewFileCache(c.Options.Dir)\n\tif !c.Options.DisableIdentityCheck {\n\t\terr = stateCache.ServerIdentityCheck(\n\t\t\tfmt.Sprintf(\"%s:%d\", c.Options.Address, c.Options.Port),\n\t\t\tresp.GetServerUUID(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tstateProvider := state.NewStateProvider(serviceClient)\n\n\tstateService, err := state.NewStateServiceWithUUID(stateCache, c.Logger, stateProvider, resp.GetServerUUID())\n\tif err != nil {\n\t\treturn errors.FromError(fmt.Errorf(\"unable to create state service: %v\", err))\n\t}\n\n\tc.clientConn = clientConn\n\tc.ServiceClient = serviceClient\n\tc.Options.DialOptions = dialOptions\n\tc.SessionID = resp.GetSessionID()\n\n\tc.HeartBeater = heartbeater.NewHeartBeater(c.SessionID, c.ServiceClient, c.Options.HeartBeatFrequency)\n\tc.HeartBeater.KeepAlive(context.Background())\n\n\tc.WithStateService(stateService)\n\n\tc.Options.CurrentDatabase = database\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tconvey.Convey(\"Test url verification request\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\turlVer := slackevents.EventsAPIURLVerificationEvent{\n\t\t\t\tType:      slackevents.URLVerification,\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tChallenge: \"3eZbrw1aBm2rZgRNFdxV2595E9CY3gmdALWMmHkvFXO7tYXAYM8P\",\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(urlVer)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\tconvey.So(payload, convey.ShouldNotBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})", "is_vulnerable": 0}
{"code": "func IsReservedName(name string) bool {\n\t// Device names can have arbitrary trailing characters following a dot or colon.\n\tbase := name\n\tfor i := 0; i < len(base); i++ {\n\t\tswitch base[i] {\n\t\tcase ':', '.':\n\t\t\tbase = base[:i]\n\t\t}\n\t}\n\t// Trailing spaces in the last path element are ignored.\n\tfor len(base) > 0 && base[len(base)-1] == ' ' {\n\t\tbase = base[:len(base)-1]\n\t}\n\tif !isReservedBaseName(base) {\n\t\treturn false\n\t}\n\tif len(base) == len(name) {\n\t\treturn true\n\t}\n\t// The path element is a reserved name with an extension.\n\t// Some Windows versions consider this a reserved name,\n\t// while others do not. Use FullPath to see if the name is\n\t// reserved.\n\tif p, _ := syscall.FullPath(name); len(p) >= 4 && p[:4] == `\\\\.\\` {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) saveSyncStatus() {\n\t// Serialize any partial progress to disk before spinning down\n\tfor _, task := range s.tasks {\n\t\t// Claim the right boundary as incomplete before flushing the\n\t\t// accumulated nodes in batch, the nodes on right boundary\n\t\t// will be discarded and cleaned up by this call.\n\t\ttask.genTrie.commit(false)\n\t\tif err := task.genBatch.Write(); err != nil {\n\t\t\tlog.Error(\"Failed to persist account slots\", \"err\", err)\n\t\t}\n\t\tfor _, subtasks := range task.SubTasks {\n\t\t\tfor _, subtask := range subtasks {\n\t\t\t\t// Same for account trie, discard and cleanup the\n\t\t\t\t// incomplete right boundary.\n\t\t\t\tsubtask.genTrie.commit(false)\n\t\t\t\tif err := subtask.genBatch.Write(); err != nil {\n\t\t\t\t\tlog.Error(\"Failed to persist storage slots\", \"err\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// Save the account hashes of completed storage.\n\t\ttask.StorageCompleted = make([]common.Hash, 0, len(task.stateCompleted))\n\t\tfor hash := range task.stateCompleted {\n\t\t\ttask.StorageCompleted = append(task.StorageCompleted, hash)\n\t\t}\n\t\tif len(task.StorageCompleted) > 0 {\n\t\t\tlog.Debug(\"Leftover completed storages\", \"number\", len(task.StorageCompleted), \"next\", task.Next, \"last\", task.Last)\n\t\t}\n\t}\n\t// Store the actual progress markers\n\tprogress := &SyncProgress{\n\t\tTasks:              s.tasks,\n\t\tAccountSynced:      s.accountSynced,\n\t\tAccountBytes:       s.accountBytes,\n\t\tBytecodeSynced:     s.bytecodeSynced,\n\t\tBytecodeBytes:      s.bytecodeBytes,\n\t\tStorageSynced:      s.storageSynced,\n\t\tStorageBytes:       s.storageBytes,\n\t\tTrienodeHealSynced: s.trienodeHealSynced,\n\t\tTrienodeHealBytes:  s.trienodeHealBytes,\n\t\tBytecodeHealSynced: s.bytecodeHealSynced,\n\t\tBytecodeHealBytes:  s.bytecodeHealBytes,\n\t}\n\tstatus, err := json.Marshal(progress)\n\tif err != nil {\n\t\tpanic(err) // This can only fail during implementation\n\t}\n\trawdb.WriteSnapshotSyncStatus(s.db, status)\n}", "is_vulnerable": 0}
{"code": "func FailNow(t TestingT, failureMessage string, msgAndArgs ...interface{}) {\n\tif assert.FailNow(t, failureMessage, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func NewServerLogger(config *Config, logger *log.Logger, tokens *token.Store, tlsConfigurator *tlsutil.Configurator) (*Server, error) {\n\t// Check the protocol version.\n\tif err := config.CheckProtocolVersion(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check for a data directory.\n\tif config.DataDir == \"\" && !config.DevMode {\n\t\treturn nil, fmt.Errorf(\"Config must provide a DataDir\")\n\t}\n\n\t// Sanity check the ACLs.\n\tif err := config.CheckACL(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Ensure we have a log output and create a logger.\n\tif config.LogOutput == nil {\n\t\tconfig.LogOutput = os.Stderr\n\t}\n\tif logger == nil {\n\t\tlogger = log.New(config.LogOutput, \"\", log.LstdFlags)\n\t}\n\n\t// Check if TLS is enabled\n\tif config.CAFile != \"\" || config.CAPath != \"\" {\n\t\tconfig.UseTLS = true\n\t}\n\n\t// Set the primary DC if it wasn't set.\n\tif config.PrimaryDatacenter == \"\" {\n\t\tif config.ACLDatacenter != \"\" {\n\t\t\tconfig.PrimaryDatacenter = config.ACLDatacenter\n\t\t} else {\n\t\t\tconfig.PrimaryDatacenter = config.Datacenter\n\t\t}\n\t}\n\n\t// Create the tombstone GC.\n\tgc, err := state.NewTombstoneGC(config.TombstoneTTL, config.TombstoneTTLGranularity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create the shutdown channel - this is closed but never written to.\n\tshutdownCh := make(chan struct{})\n\n\tconnPool := &pool.ConnPool{\n\t\tSrcAddr:    config.RPCSrcAddr,\n\t\tLogOutput:  config.LogOutput,\n\t\tMaxTime:    serverRPCCache,\n\t\tMaxStreams: serverMaxStreams,\n\t\tTLSWrapper: tlsConfigurator.OutgoingRPCWrapper(),\n\t\tForceTLS:   config.VerifyOutgoing,\n\t}\n\n\t// Create server.\n\ts := &Server{\n\t\tconfig:           config,\n\t\ttokens:           tokens,\n\t\tconnPool:         connPool,\n\t\teventChLAN:       make(chan serf.Event, serfEventChSize),\n\t\teventChWAN:       make(chan serf.Event, serfEventChSize),\n\t\tlogger:           logger,\n\t\tleaveCh:          make(chan struct{}),\n\t\treconcileCh:      make(chan serf.Member, reconcileChSize),\n\t\trouter:           router.NewRouter(logger, config.Datacenter),\n\t\trpcServer:        rpc.NewServer(),\n\t\trpcTLS:           tlsConfigurator.IncomingRPCConfig(),\n\t\treassertLeaderCh: make(chan chan error),\n\t\tsegmentLAN:       make(map[string]*serf.Serf, len(config.Segments)),\n\t\tsessionTimers:    NewSessionTimers(),\n\t\ttombstoneGC:      gc,\n\t\tserverLookup:     NewServerLookup(),\n\t\tshutdownCh:       shutdownCh,\n\t}\n\n\t// Initialize enterprise specific server functionality\n\tif err := s.initEnterprise(); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, err\n\t}\n\n\t// Initialize the stats fetcher that autopilot will use.\n\ts.statsFetcher = NewStatsFetcher(logger, s.connPool, s.config.Datacenter)\n\n\ts.sentinel = sentinel.New(logger)\n\ts.useNewACLs = 0\n\taclConfig := ACLResolverConfig{\n\t\tConfig:      config,\n\t\tDelegate:    s,\n\t\tCacheConfig: serverACLCacheConfig,\n\t\tAutoDisable: false,\n\t\tLogger:      logger,\n\t\tSentinel:    s.sentinel,\n\t}\n\t// Initialize the ACL resolver.\n\tif s.acls, err = NewACLResolver(&aclConfig); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to create ACL resolver: %v\", err)\n\t}\n\n\t// Initialize the RPC layer.\n\tif err := s.setupRPC(tlsConfigurator.OutgoingRPCWrapper()); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to start RPC layer: %v\", err)\n\t}\n\n\t// Initialize any extra RPC listeners for segments.\n\tsegmentListeners, err := s.setupSegmentRPC()\n\tif err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to start segment RPC layer: %v\", err)\n\t}\n\n\t// Initialize the Raft server.\n\tif err := s.setupRaft(); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to start Raft: %v\", err)\n\t}\n\n\t// Serf and dynamic bind ports\n\t//\n\t// The LAN serf cluster announces the port of the WAN serf cluster\n\t// which creates a race when the WAN cluster is supposed to bind to\n\t// a dynamic port (port 0). The current memberlist implementation will\n\t// update the bind port in the configuration after the memberlist is\n\t// created, so we can pull it out from there reliably, even though it's\n\t// a little gross to be reading the updated config.\n\n\t// Initialize the WAN Serf if enabled\n\tserfBindPortWAN := -1\n\tif config.SerfWANConfig != nil {\n\t\tserfBindPortWAN = config.SerfWANConfig.MemberlistConfig.BindPort\n\t\ts.serfWAN, err = s.setupSerf(config.SerfWANConfig, s.eventChWAN, serfWANSnapshot, true, serfBindPortWAN, \"\", s.Listener)\n\t\tif err != nil {\n\t\t\ts.Shutdown()\n\t\t\treturn nil, fmt.Errorf(\"Failed to start WAN Serf: %v\", err)\n\t\t}\n\t\t// See big comment above why we are doing this.\n\t\tif serfBindPortWAN == 0 {\n\t\t\tserfBindPortWAN = config.SerfWANConfig.MemberlistConfig.BindPort\n\t\t\tif serfBindPortWAN == 0 {\n\t\t\t\treturn nil, fmt.Errorf(\"Failed to get dynamic bind port for WAN Serf\")\n\t\t\t}\n\t\t\ts.logger.Printf(\"[INFO] agent: Serf WAN TCP bound to port %d\", serfBindPortWAN)\n\t\t}\n\t}\n\n\t// Initialize the LAN segments before the default LAN Serf so we have\n\t// updated port information to publish there.\n\tif err := s.setupSegments(config, serfBindPortWAN, segmentListeners); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to setup network segments: %v\", err)\n\t}\n\n\t// Initialize the LAN Serf for the default network segment.\n\ts.serfLAN, err = s.setupSerf(config.SerfLANConfig, s.eventChLAN, serfLANSnapshot, false, serfBindPortWAN, \"\", s.Listener)\n\tif err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to start LAN Serf: %v\", err)\n\t}\n\tgo s.lanEventHandler()\n\n\t// Start the flooders after the LAN event handler is wired up.\n\ts.floodSegments(config)\n\n\t// Add a \"static route\" to the WAN Serf and hook it up to Serf events.\n\tif s.serfWAN != nil {\n\t\tif err := s.router.AddArea(types.AreaWAN, s.serfWAN, s.connPool, s.config.VerifyOutgoing); err != nil {\n\t\t\ts.Shutdown()\n\t\t\treturn nil, fmt.Errorf(\"Failed to add WAN serf route: %v\", err)\n\t\t}\n\t\tgo router.HandleSerfEvents(s.logger, s.router, types.AreaWAN, s.serfWAN.ShutdownCh(), s.eventChWAN)\n\n\t\t// Fire up the LAN <-> WAN join flooder.\n\t\tportFn := func(s *metadata.Server) (int, bool) {\n\t\t\tif s.WanJoinPort > 0 {\n\t\t\t\treturn s.WanJoinPort, true\n\t\t\t}\n\t\t\treturn 0, false\n\t\t}\n\t\tgo s.Flood(nil, portFn, s.serfWAN)\n\t}\n\n\t// Start enterprise specific functionality\n\tif err := s.startEnterprise(); err != nil {\n\t\ts.Shutdown()\n\t\treturn nil, err\n\t}\n\n\t// Initialize Autopilot. This must happen before starting leadership monitoring\n\t// as establishing leadership could attempt to use autopilot and cause a panic.\n\ts.initAutopilot(config)\n\n\t// Start monitoring leadership. This must happen after Serf is set up\n\t// since it can fire events when leadership is obtained.\n\tgo s.monitorLeadership()\n\n\t// Start listening for RPC requests.\n\tgo s.listen(s.Listener)\n\n\t// Start listeners for any segments with separate RPC listeners.\n\tfor _, listener := range segmentListeners {\n\t\tgo s.listen(listener)\n\t}\n\n\t// Start the metrics handlers.\n\tgo s.sessionStats()\n\n\treturn s, nil\n}", "is_vulnerable": 0}
{"code": "func TestXXMigrations(t *testing.T) {\n\tif testing.Short() {\n\t\tt.SkipNow()\n\t\treturn\n\t}\n\n\tmigratest.RunPackrMigrationTests(\n\t\tt,\n\t\tmigratest.MigrationSchemas{client.Migrations, consent.Migrations, oauth2.Migrations},\n\t\tmigratest.MigrationSchemas{nil, nil, dbal.FindMatchingTestMigrations(\"migrations/sql/tests/\", oauth2.Migrations, oauth2.AssetNames(), oauth2.Asset)},\n\t\tx.CleanSQL,\n\t\tx.CleanSQL,\n\t\tfunc(t *testing.T, dbName string, db *sqlx.DB, m, k, steps int) {\n\t\t\tt.Run(fmt.Sprintf(\"poll=%d\", k), func(t *testing.T) {\n\t\t\t\tconf := internal.NewConfigurationWithDefaults()\n\t\t\t\treg := internal.NewRegistrySQL(conf, db)\n\n\t\t\t\tif m != 2 {\n\t\t\t\t\tt.Skip(\"Skipping polling unless it's the last migration schema\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\ts := reg.OAuth2Storage().(*oauth2.FositeSQLStore)\n\t\t\t\tif dbName == \"cockroach\" {\n\t\t\t\t\tk += 8\n\t\t\t\t}\n\t\t\t\tsig := fmt.Sprintf(\"%d-sig\", k+1)\n\n\t\t\t\tif k < 8 {\n\t\t\t\t\t// With migration 8, all previous test data has been removed because the client is non-existent.\n\t\t\t\t\t_, err := s.GetAccessTokenSession(context.Background(), sig, oauth2.NewSession(\"\"))\n\t\t\t\t\trequire.Error(t, err)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t_, err := s.GetAccessTokenSession(context.Background(), sig, oauth2.NewSession(\"\"))\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\t_, err = s.GetRefreshTokenSession(context.Background(), sig, oauth2.NewSession(\"\"))\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\t_, err = s.GetAuthorizeCodeSession(context.Background(), sig, oauth2.NewSession(\"\"))\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\t_, err = s.GetOpenIDConnectSession(context.Background(), sig, &fosite.Request{Session: oauth2.NewSession(\"\")})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif k > 2 {\n\t\t\t\t\t_, err = s.GetPKCERequestSession(context.Background(), sig, oauth2.NewSession(\"\"))\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t}\n\n\t\t\t\tif k >= 11 {\n\t\t\t\t\trequire.True(t, errors.Is(s.ClientAssertionJWTValid(context.Background(), sig), fosite.ErrJTIKnown), \"%+v\", err)\n\t\t\t\t}\n\t\t\t})\n\t\t},\n\t)\n}", "is_vulnerable": 0}
{"code": "func (f *ConfigurationFile) parseXmlFile(path string) error {\n\tdoc := etree.NewDocument()\n\tfile, err := os.OpenFile(path, os.O_CREATE|os.O_RDWR, 0o644)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\n\tif _, err := doc.ReadFrom(file); err != nil {\n\t\treturn err\n\t}\n\n\t// If there is no root we should create a basic start to the file. This isn't required though,\n\t// and if it doesn't work correctly I'll just remove the code.\n\tif doc.Root() == nil {\n\t\tdoc.CreateProcInst(\"xml\", `version=\"1.0\" encoding=\"utf-8\"`)\n\t}\n\n\tfor i, replacement := range f.Replace {\n\t\tvalue, err := f.LookupConfigurationValue(replacement)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If this is the first item and there is no root element, create that root now and apply\n\t\t// it for future use.\n\t\tif i == 0 && doc.Root() == nil {\n\t\t\tparts := strings.SplitN(replacement.Match, \".\", 2)\n\t\t\tdoc.SetRoot(doc.CreateElement(parts[0]))\n\t\t}\n\n\t\tpath := \"./\" + strings.Replace(replacement.Match, \".\", \"/\", -1)\n\n\t\t// If we're not doing a wildcard replacement go ahead and create the\n\t\t// missing element if we cannot find it yet.\n\t\tif !strings.Contains(path, \"*\") {\n\t\t\tparts := strings.Split(replacement.Match, \".\")\n\n\t\t\t// Set the initial element to be the root element, and then work from there.\n\t\t\telement := doc.Root()\n\n\t\t\t// Iterate over the path to create the required structure for the given element's path.\n\t\t\t// This does not set a value, only ensures that the base structure exists. We start at index\n\t\t\t// 1 because an XML document can only contain a single root element, and from there we'll\n\t\t\t// work our way down the chain.\n\t\t\tfor _, tag := range parts[1:] {\n\t\t\t\tif e := element.FindElement(tag); e == nil {\n\t\t\t\t\telement = element.CreateElement(tag)\n\t\t\t\t} else {\n\t\t\t\t\telement = e\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Iterate over the elements we found and update their values.\n\t\tfor _, element := range doc.FindElements(path) {\n\t\t\tif xmlValueMatchRegex.MatchString(value) {\n\t\t\t\tk := xmlValueMatchRegex.ReplaceAllString(value, \"$1\")\n\t\t\t\tv := xmlValueMatchRegex.ReplaceAllString(value, \"$2\")\n\n\t\t\t\telement.CreateAttr(k, v)\n\t\t\t} else {\n\t\t\t\telement.SetText(value)\n\t\t\t}\n\t\t}\n\t}\n\n\t// If you don't truncate the file you'll end up duplicating the data in there (or just appending\n\t// to the end of the file. We don't want to do that.\n\tif err := file.Truncate(0); err != nil {\n\t\treturn err\n\t}\n\n\t// Move the cursor to the start of the file to avoid weird spacing issues.\n\tfile.Seek(0, 0)\n\n\t// Ensure the XML is indented properly.\n\tdoc.Indent(2)\n\n\t// Truncate the file before attempting to write the changes.\n\tif err := os.Truncate(path, 0); err != nil {\n\t\treturn err\n\t}\n\n\t// Write the XML to the file.\n\t_, err = doc.WriteTo(file)\n\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (c *Container) rollbackFailingContainerCreation() {\n\tif err := c.detachDevices(); err != nil {\n\t\tc.Logger().WithError(err).Error(\"rollback failed detachDevices()\")\n\t}\n\tif err := c.removeDrive(); err != nil {\n\t\tc.Logger().WithError(err).Error(\"rollback failed removeDrive()\")\n\t}\n\tif err := c.unmountHostMounts(); err != nil {\n\t\tc.Logger().WithError(err).Error(\"rollback failed unmountHostMounts()\")\n\t}\n\tif err := bindUnmountContainerRootfs(c.ctx, kataHostSharedDir(), c.sandbox.id, c.id); err != nil {\n\t\tc.Logger().WithError(err).Error(\"rollback failed bindUnmountContainerRootfs()\")\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tFetcher: func() jwk.Fetcher {\n\t\t\t\t\tc := jwk.NewCache(context.TODO())\n\t\t\t\t\treturn jwk.FetchFunc(func(ctx context.Context, u string, options ...jwk.FetchOption) (jwk.Set, error) {\n\t\t\t\t\t\tvar cacheopts []jwk.RegisterOption\n\t\t\t\t\t\tfor _, option := range options {\n\t\t\t\t\t\t\tcacheopts = append(cacheopts, option)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcacheopts = append(cacheopts, jwk.WithHTTPClient(srv.Client()))\n\t\t\t\t\t\tcacheopts = append(cacheopts, jwk.WithFetchWhitelist(httprc.InsecureWhitelist{}))\n\t\t\t\t\t\tc.Register(u, cacheopts...)\n\n\t\t\t\t\t\treturn c.Get(ctx, u)\n\t\t\t\t\t})\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testcases {\n\t\t\ttc := tc\n\t\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\t\thdr := jws.NewHeaders()\n\t\t\t\tu := srv.URL\n\t\t\t\tif tc.Query != \"\" {\n\t\t\t\t\tu += \"?\" + tc.Query\n\t\t\t\t}\n\t\t\t\thdr.Set(jws.JWKSetURLKey, u)\n\t\t\t\tsigned, err := jws.Sign(payload, jws.WithKey(jwa.RS256, key, jws.WithProtectedHeaders(hdr)))\n\t\t\t\trequire.NoError(t, err, `jws.Sign should succeed`)\n\n\t\t\t\tvar options []jwk.FetchOption\n\t\t\t\tif f := tc.FetchOptions; f != nil {\n\t\t\t\t\toptions = append(options, f()...)\n\t\t\t\t}\n\n\t\t\t\tvar fetcher jwk.Fetcher\n\t\t\t\tif f := tc.Fetcher; f != nil {\n\t\t\t\t\tfetcher = f()\n\t\t\t\t}\n\t\t\t\tdecoded, err := jws.Verify(signed, jws.WithVerifyAuto(fetcher, options...))\n\t\t\t\tif tc.Error {\n\t\t\t\t\trequire.Error(t, err, `jws.Verify should fail`)\n\t\t\t\t} else {\n\t\t\t\t\trequire.NoError(t, err, `jws.Verify should succeed`)\n\t\t\t\t\trequire.Equal(t, payload, decoded, `decoded payload should match`)\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "\treturn newServiceWithOpt(t, func(gitClient *gitmocks.Client, helmClient *helmmocks.Client, paths *iomocks.TempPaths) {\n\t\tgitClient.On(\"Init\").Return(nil)\n\t\tgitClient.On(\"Fetch\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"Checkout\", mock.Anything, mock.Anything).Return(nil)\n\t\tgitClient.On(\"LsRemote\", mock.Anything).Return(mock.Anything, nil)\n\t\tgitClient.On(\"CommitSHA\").Return(mock.Anything, nil)\n\t\tgitClient.On(\"Root\").Return(root)\n\t\tgitClient.On(\"IsAnnotatedTag\").Return(false)\n\t\tif signed {\n\t\t\tgitClient.On(\"VerifyCommitSignature\", mock.Anything).Return(testSignature, nil)\n\t\t} else {\n\t\t\tgitClient.On(\"VerifyCommitSignature\", mock.Anything).Return(\"\", nil)\n\t\t}\n\n\t\tchart := \"my-chart\"\n\t\toobChart := \"out-of-bounds-chart\"\n\t\tversion := \"1.1.0\"\n\t\thelmClient.On(\"GetIndex\", mock.AnythingOfType(\"bool\")).Return(&helm.Index{Entries: map[string]helm.Entries{\n\t\t\tchart:    {{Version: \"1.0.0\"}, {Version: version}},\n\t\t\toobChart: {{Version: \"1.0.0\"}, {Version: version}},\n\t\t}}, nil)\n\t\thelmClient.On(\"ExtractChart\", chart, version).Return(\"./testdata/my-chart\", io.NopCloser, nil)\n\t\thelmClient.On(\"ExtractChart\", oobChart, version).Return(\"./testdata2/out-of-bounds-chart\", io.NopCloser, nil)\n\t\thelmClient.On(\"CleanChartCache\", chart, version).Return(nil)\n\t\thelmClient.On(\"CleanChartCache\", oobChart, version).Return(nil)\n\t\thelmClient.On(\"DependencyBuild\").Return(nil)\n\n\t\tpaths.On(\"Add\", mock.Anything, mock.Anything).Return(root, nil)\n\t\tpaths.On(\"GetPath\", mock.Anything).Return(root, nil)\n\t\tpaths.On(\"GetPathIfExists\", mock.Anything).Return(root, nil)\n\t}, root)", "is_vulnerable": 1}
{"code": "func (sp *ServiceProvider) parseResponseHTTP(req *http.Request, possibleRequestIDs []string) (*Assertion, error) {\n\tretErr := &InvalidResponseError{\n\t\tNow: TimeNow(),\n\t}\n\n\trawResponseBuf, err := base64.StdEncoding.DecodeString(req.PostForm.Get(\"SAMLResponse\"))\n\tif err != nil {\n\t\tretErr.PrivateErr = fmt.Errorf(\"cannot parse base64: %s\", err)\n\t\treturn nil, retErr\n\t}\n\n\tassertion, err := sp.ParseXMLResponse(rawResponseBuf, possibleRequestIDs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn assertion, nil\n}", "is_vulnerable": 0}
{"code": "func (s *Sync) schedule(req *request) {\n\t// If we're already requesting this node, add a new reference and stop\n\tif old, ok := s.requests[req.hash]; ok {\n\t\told.parents = append(old.parents, req.parents...)\n\t\treturn\n\t}\n\t// Schedule the request for future retrieval\n\ts.queue.Push(req.hash, int64(req.depth))\n\ts.requests[req.hash] = req\n}", "is_vulnerable": 1}
{"code": "func (b *Builder) buildMainHTTPConnectionManagerFilter(\n\tctx context.Context,\n\tcfg *config.Config,\n\tfullyStatic bool,\n) (*envoy_config_listener_v3.Filter, error) {\n\tvar grpcClientTimeout *durationpb.Duration\n\tif cfg.Options.GRPCClientTimeout != 0 {\n\t\tgrpcClientTimeout = durationpb.New(cfg.Options.GRPCClientTimeout)\n\t} else {\n\t\tgrpcClientTimeout = durationpb.New(30 * time.Second)\n\t}\n\n\tfilters := []*envoy_http_connection_manager.HttpFilter{\n\t\tLuaFilter(luascripts.RemoveImpersonateHeaders),\n\t\tExtAuthzFilter(grpcClientTimeout),\n\t\tLuaFilter(luascripts.ExtAuthzSetCookie),\n\t\tLuaFilter(luascripts.CleanUpstream),\n\t\tLuaFilter(luascripts.RewriteHeaders),\n\t}\n\tfilters = append(filters, HTTPRouterFilter())\n\n\tvar maxStreamDuration *durationpb.Duration\n\tif cfg.Options.WriteTimeout > 0 {\n\t\tmaxStreamDuration = durationpb.New(cfg.Options.WriteTimeout)\n\t}\n\n\ttracingProvider, err := buildTracingHTTP(cfg.Options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmgr := &envoy_http_connection_manager.HttpConnectionManager{\n\t\tAlwaysSetRequestIdInResponse: true,\n\t\tCodecType:                    cfg.Options.GetCodecType().ToEnvoy(),\n\t\tStatPrefix:                   \"ingress\",\n\t\tHttpFilters:                  filters,\n\t\tAccessLog:                    buildAccessLogs(cfg.Options),\n\t\tCommonHttpProtocolOptions: &envoy_config_core_v3.HttpProtocolOptions{\n\t\t\tIdleTimeout:       durationpb.New(cfg.Options.IdleTimeout),\n\t\t\tMaxStreamDuration: maxStreamDuration,\n\t\t},\n\t\tHttpProtocolOptions: http1ProtocolOptions,\n\t\tRequestTimeout:      durationpb.New(cfg.Options.ReadTimeout),\n\t\tTracing: &envoy_http_connection_manager.HttpConnectionManager_Tracing{\n\t\t\tRandomSampling: &envoy_type_v3.Percent{Value: cfg.Options.TracingSampleRate * 100},\n\t\t\tProvider:       tracingProvider,\n\t\t},\n\t\t// See https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#x-forwarded-for\n\t\tUseRemoteAddress:  &wrappers.BoolValue{Value: true},\n\t\tSkipXffAppend:     cfg.Options.SkipXffAppend,\n\t\tXffNumTrustedHops: cfg.Options.XffNumTrustedHops,\n\t\tLocalReplyConfig:  b.buildLocalReplyConfig(cfg.Options, false),\n\t\tNormalizePath:     wrapperspb.Bool(true),\n\t}\n\n\tif fullyStatic {\n\t\trouteConfiguration, err := b.buildMainRouteConfiguration(ctx, cfg)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tmgr.RouteSpecifier = &envoy_http_connection_manager.HttpConnectionManager_RouteConfig{\n\t\t\tRouteConfig: routeConfiguration,\n\t\t}\n\t} else {\n\t\tmgr.RouteSpecifier = &envoy_http_connection_manager.HttpConnectionManager_Rds{\n\t\t\tRds: &envoy_http_connection_manager.Rds{\n\t\t\t\tConfigSource: &envoy_config_core_v3.ConfigSource{\n\t\t\t\t\tResourceApiVersion:    envoy_config_core_v3.ApiVersion_V3,\n\t\t\t\t\tConfigSourceSpecifier: &envoy_config_core_v3.ConfigSource_Ads{},\n\t\t\t\t},\n\t\t\t\tRouteConfigName: \"main\",\n\t\t\t},\n\t\t}\n\t}\n\n\treturn HTTPConnectionManagerFilter(mgr), nil\n}", "is_vulnerable": 0}
{"code": "func walkDir(fs Filesystem, name string, d DirEntry, walkDirFn WalkDirFunc) error {\n\tif err := walkDirFn(name, d, nil); err != nil || !d.IsDir() {\n\t\tif err == SkipDir && d.IsDir() {\n\t\t\t// Successfully skipped directory.\n\t\t\terr = nil\n\t\t}\n\t\treturn err\n\t}\n\n\tdirs, err := fs.ReadDir(name)\n\tif err != nil {\n\t\t// Second call, to report ReadDir error.\n\t\terr = walkDirFn(name, d, err)\n\t\tif err != nil {\n\t\t\tif err == SkipDir && d.IsDir() {\n\t\t\t\terr = nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, d1 := range dirs {\n\t\tname1 := path.Join(name, d1.Name())\n\t\tif err := walkDir(fs, name1, d1, walkDirFn); err != nil {\n\t\t\tif err == SkipDir {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (q *Query) Sanitize(args ...any) (string, error) {\n\targUse := make([]bool, len(args))\n\tbuf := &bytes.Buffer{}\n\n\tfor _, part := range q.Parts {\n\t\tvar str string\n\t\tswitch part := part.(type) {\n\t\tcase string:\n\t\t\tstr = part\n\t\tcase int:\n\t\t\targIdx := part - 1\n\n\t\t\tif argIdx < 0 {\n\t\t\t\treturn \"\", fmt.Errorf(\"first sql argument must be > 0\")\n\t\t\t}\n\n\t\t\tif argIdx >= len(args) {\n\t\t\t\treturn \"\", fmt.Errorf(\"insufficient arguments\")\n\t\t\t}\n\t\t\targ := args[argIdx]\n\t\t\tswitch arg := arg.(type) {\n\t\t\tcase nil:\n\t\t\t\tstr = \"null\"\n\t\t\tcase int64:\n\t\t\t\tstr = strconv.FormatInt(arg, 10)\n\t\t\tcase float64:\n\t\t\t\tstr = strconv.FormatFloat(arg, 'f', -1, 64)\n\t\t\tcase bool:\n\t\t\t\tstr = strconv.FormatBool(arg)\n\t\t\tcase []byte:\n\t\t\t\tstr = QuoteBytes(arg)\n\t\t\tcase string:\n\t\t\t\tstr = QuoteString(arg)\n\t\t\tcase time.Time:\n\t\t\t\tstr = arg.Truncate(time.Microsecond).Format(\"'2006-01-02 15:04:05.999999999Z07:00:00'\")\n\t\t\tdefault:\n\t\t\t\treturn \"\", fmt.Errorf(\"invalid arg type: %T\", arg)\n\t\t\t}\n\t\t\targUse[argIdx] = true\n\n\t\t\t// Prevent SQL injection via Line Comment Creation\n\t\t\t// https://github.com/jackc/pgx/security/advisories/GHSA-m7wr-2xf7-cm9p\n\t\t\tstr = \"(\" + str + \")\"\n\t\tdefault:\n\t\t\treturn \"\", fmt.Errorf(\"invalid Part type: %T\", part)\n\t\t}\n\t\tbuf.WriteString(str)\n\t}\n\n\tfor i, used := range argUse {\n\t\tif !used {\n\t\t\treturn \"\", fmt.Errorf(\"unused argument: %d\", i)\n\t\t}\n\t}\n\treturn buf.String(), nil\n}", "is_vulnerable": 0}
{"code": "func FromURLQuery(query string) (Map, error) {\n\tvals, err := url.ParseQuery(query)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tm := Map{}\n\tfor k, vals := range vals {\n\t\tm[k] = vals[0]\n\t}\n\treturn m, nil\n}", "is_vulnerable": 0}
{"code": "func migrationsSqlCockroach11Sql() (*asset, error) {\n\tbytes, err := migrationsSqlCockroach11SqlBytes()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinfo := bindataFileInfo{name: \"migrations/sql/cockroach/11.sql\", size: 289, mode: os.FileMode(420), modTime: time.Unix(1585817202, 0)}\n\ta := &asset{bytes: bytes, info: info}\n\treturn a, nil\n}", "is_vulnerable": 0}
{"code": "func (t *Teler) checkCommonWebAttack(r *http.Request) error {\n\t// Decode the URL-encoded and unescape HTML entities in the\n\t// request URI of the URL then remove all special characters\n\turi := removeSpecialChars(stringDeUnescape(r.URL.RequestURI()))\n\n\t// Declare byte slice for request body.\n\tvar body string\n\n\t// Initialize buffer to hold request body.\n\tbuf := &bytes.Buffer{}\n\n\t// Use io.Copy to copy the request body to the buffer.\n\t_, err := io.Copy(buf, r.Body)\n\tif err == nil {\n\t\t// If the read not fails, replace the request body\n\t\t// with a new io.ReadCloser that reads from the buffer.\n\t\tr.Body = io.NopCloser(buf)\n\n\t\t// Convert the buffer to a string.\n\t\tbody = buf.String()\n\t}\n\n\t// Decode the URL-encoded and unescape HTML entities in the\n\t// body of request then remove all special characters\n\tbody = removeSpecialChars(stringDeUnescape(body))\n\n\t// Iterate over the filters in the CommonWebAttack data stored in the t.threat.cwa.Filters field\n\tfor _, filter := range t.threat.cwa.Filters {\n\t\t// Initialize a variable to track whether a match is found\n\t\tvar match bool\n\n\t\t// Check the type of the filter's pattern\n\t\tswitch pattern := filter.pattern.(type) {\n\t\tcase *regexp.Regexp: // If the pattern is a regex\n\t\t\tmatch = pattern.MatchString(uri) || pattern.MatchString(body)\n\t\tcase *pcre.Matcher: // If the pattern is a PCRE expr\n\t\t\tmatch = pattern.MatchString(uri, 0) || pattern.MatchString(body, 0)\n\t\tdefault: // If the pattern is of an unknown type, skip to the next iteration\n\t\t\tcontinue\n\t\t}\n\n\t\t// If the pattern matches the request URI or body, return an error indicating a common web attack has been detected\n\t\tif match {\n\t\t\treturn errors.New(filter.Description)\n\t\t}\n\t}\n\n\t// Return nil if no match is found\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *AndBranch) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: AndBranch: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: AndBranch: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Left\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Left.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Right\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Right.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Castaway) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Castaway: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Castaway: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CastMapValueMessage\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.CastMapValueMessage == nil {\n\t\t\t\tm.CastMapValueMessage = make(map[int32]MyWilson)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &Wilson{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Wilson{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCastvalue(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.CastMapValueMessage[mapkey] = ((MyWilson)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CastMapValueMessageNullable\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.CastMapValueMessageNullable == nil {\n\t\t\t\tm.CastMapValueMessageNullable = make(map[int32]*MyWilson)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *Wilson\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCastvalue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Wilson{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCastvalue(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.CastMapValueMessageNullable[mapkey] = ((*MyWilson)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipCastvalue(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthCastvalue\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *immuClient) verifiedGet(ctx context.Context, kReq *schema.KeyRequest) (vi *schema.Entry, err error) {\n\terr = c.StateService.CacheLock()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer c.StateService.CacheUnlock()\n\n\tif !c.IsConnected() {\n\t\treturn nil, errors.FromError(ErrNotConnected)\n\t}\n\n\tstate, err := c.StateService.GetState(ctx, c.Options.CurrentDatabase)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treq := &schema.VerifiableGetRequest{\n\t\tKeyRequest:   kReq,\n\t\tProveSinceTx: state.TxId,\n\t}\n\n\tvEntry, err := c.ServiceClient.VerifiableGet(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tentrySpecDigest, err := store.EntrySpecDigestFor(int(vEntry.VerifiableTx.Tx.Header.Version))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tinclusionProof := schema.InclusionProofFromProto(vEntry.InclusionProof)\n\tdualProof := schema.DualProofFromProto(vEntry.VerifiableTx.DualProof)\n\n\tvar eh [sha256.Size]byte\n\n\tvar sourceID, targetID uint64\n\tvar sourceAlh, targetAlh [sha256.Size]byte\n\n\tvTx := kReq.AtTx\n\tvar e *store.EntrySpec\n\n\tif vEntry.Entry.ReferencedBy == nil {\n\t\tif kReq.AtTx == 0 {\n\t\t\tvTx = vEntry.Entry.Tx\n\t\t}\n\n\t\te = database.EncodeEntrySpec(kReq.Key, schema.KVMetadataFromProto(vEntry.Entry.Metadata), vEntry.Entry.Value)\n\t} else {\n\t\tref := vEntry.Entry.ReferencedBy\n\n\t\tif kReq.AtTx == 0 {\n\t\t\tvTx = ref.Tx\n\t\t}\n\n\t\te = database.EncodeReference(kReq.Key, schema.KVMetadataFromProto(ref.Metadata), vEntry.Entry.Key, ref.AtTx)\n\t}\n\n\tif state.TxId <= vTx {\n\t\teh = schema.DigestFromProto(vEntry.VerifiableTx.DualProof.TargetTxHeader.EH)\n\n\t\tsourceID = state.TxId\n\t\tsourceAlh = schema.DigestFromProto(state.TxHash)\n\t\ttargetID = vTx\n\t\ttargetAlh = dualProof.TargetTxHeader.Alh()\n\t} else {\n\t\teh = schema.DigestFromProto(vEntry.VerifiableTx.DualProof.SourceTxHeader.EH)\n\n\t\tsourceID = vTx\n\t\tsourceAlh = dualProof.SourceTxHeader.Alh()\n\t\ttargetID = state.TxId\n\t\ttargetAlh = schema.DigestFromProto(state.TxHash)\n\t}\n\n\tverifies := store.VerifyInclusion(\n\t\tinclusionProof,\n\t\tentrySpecDigest(e),\n\t\teh)\n\tif !verifies {\n\t\treturn nil, store.ErrCorruptedData\n\t}\n\n\tif state.TxId > 0 {\n\t\tverifies = store.VerifyDualProof(\n\t\t\tdualProof,\n\t\t\tsourceID,\n\t\t\ttargetID,\n\t\t\tsourceAlh,\n\t\t\ttargetAlh,\n\t\t)\n\t\tif !verifies {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\tnewState := &schema.ImmutableState{\n\t\tDb:        c.currentDatabase(),\n\t\tTxId:      targetID,\n\t\tTxHash:    targetAlh[:],\n\t\tSignature: vEntry.VerifiableTx.Signature,\n\t}\n\n\tif c.serverSigningPubKey != nil {\n\t\tok, err := newState.CheckSignature(c.serverSigningPubKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !ok {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\terr = c.StateService.SetState(c.Options.CurrentDatabase, newState)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn vEntry.Entry, nil\n}", "is_vulnerable": 1}
{"code": "func (t *TestPodLogsServer) SendMsg(m interface{}) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestHostnameParam(t *testing.T) {\n\theaders := map[string]string{}\n\tc := &config.Config{\n\t\tModules: map[string]config.Module{\n\t\t\t\"http_2xx\": {\n\t\t\t\tProber:  \"http\",\n\t\t\t\tTimeout: 10 * time.Second,\n\t\t\t\tHTTP: config.HTTPProbe{\n\t\t\t\t\tHeaders:            headers,\n\t\t\t\t\tIPProtocolFallback: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// check that 'hostname' parameter make its way to Host header\n\thostname := \"foo.example.com\"\n\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif r.Host != hostname {\n\t\t\tt.Errorf(\"Unexpected Host: expected %q, got %q.\", hostname, r.Host)\n\t\t}\n\t\tw.WriteHeader(http.StatusOK)\n\t}))\n\tdefer ts.Close()\n\n\trequrl := fmt.Sprintf(\"?debug=true&hostname=%s&target=%s\", hostname, ts.URL)\n\n\treq, err := http.NewRequest(\"GET\", requrl, nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\trr := httptest.NewRecorder()\n\n\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil, level.AllowNone())\n\t})\n\n\thandler.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tt.Errorf(\"probe request handler returned wrong status code: %v, want %v\", status, http.StatusOK)\n\t}\n\n\t// check that ts got the request to perform header check\n\tif !strings.Contains(rr.Body.String(), \"probe_success 1\") {\n\t\tt.Errorf(\"probe failed, response body: %v\", rr.Body.String())\n\t}\n\n\t// check that host header both in config and in parameter will result in 400\n\tc.Modules[\"http_2xx\"].HTTP.Headers[\"Host\"] = hostname + \".something\"\n\n\thandler = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil, level.AllowNone())\n\t})\n\n\trr = httptest.NewRecorder()\n\thandler.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusBadRequest {\n\t\tt.Errorf(\"probe request handler returned wrong status code: %v, want %v\", status, http.StatusBadRequest)\n\t}\n}", "is_vulnerable": 0}
{"code": "func isAllowedToRun(uid uint32, args []string) bool {\n\t// Root can run all snapctl commands.\n\tif uid == 0 {\n\t\treturn true\n\t}\n\n\tfor idx, arg := range args {\n\t\t// A number of sub-commands are allowed to be executed by non-root users.\n\t\tif idx == 0 && strutil.ListContains(nonRootAllowed, arg) {\n\t\t\treturn true\n\t\t}\n\n\t\t// Invoking help is always allowed.\n\t\tif arg == \"-h\" || arg == \"--help\" {\n\t\t\treturn true\n\t\t}\n\n\t\t// Note that we are not interrupting parsing after the first non-option\n\t\t// argument (POSIX style), because we want to cater to the use case of\n\t\t// the user appending --help or -h at the end of the command and still\n\t\t// getting something useful. The only exception is the condition below.\n\n\t\t// The explicit termination argument terminates parsing.\n\t\tif arg == \"--\" {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (m *VDEAgentChainInfo) GetOneByID() (*VDEAgentChainInfo, error) {\r\n\terr := DBConn.Where(\"id=?\", m.ID).First(&m).Error\r\n\treturn m, err\r\n}\r", "is_vulnerable": 1}
{"code": "func (m *SizeMessage) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowProtosize\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: SizeMessage: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: SizeMessage: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Size\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProtosize\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Size = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field ProtoSize_\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProtosize\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.ProtoSize_ = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Equal_\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProtosize\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.Equal_ = &b\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field String_\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProtosize\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthProtosize\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthProtosize\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.String_ = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipProtosize(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthProtosize\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func doDecryptCtx(dctx *decryptCtx) ([]byte, error) {\n\tm := dctx.msg\n\talg := dctx.alg\n\tkey := dctx.key\n\n\tif jwkKey, ok := key.(jwk.Key); ok {\n\t\tvar raw interface{}\n\t\tif err := jwkKey.Raw(&raw); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, `failed to retrieve raw key from %T`, key)\n\t\t}\n\t\tkey = raw\n\t}\n\n\tvar err error\n\tctx := context.TODO()\n\th, err := m.protectedHeaders.Clone(ctx)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, `failed to copy protected headers`)\n\t}\n\th, err = h.Merge(ctx, m.unprotectedHeaders)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to merge headers for message decryption\")\n\t}\n\n\tenc := m.protectedHeaders.ContentEncryption()\n\tvar aad []byte\n\tif aadContainer := m.authenticatedData; aadContainer != nil {\n\t\taad = base64.Encode(aadContainer)\n\t}\n\n\tvar computedAad []byte\n\tif len(m.rawProtectedHeaders) > 0 {\n\t\tcomputedAad = m.rawProtectedHeaders\n\t} else {\n\t\t// this is probably not required once msg.Decrypt is deprecated\n\t\tvar err error\n\t\tcomputedAad, err = m.protectedHeaders.Encode()\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to encode protected headers\")\n\t\t}\n\t}\n\n\tdec := NewDecrypter(alg, enc, key).\n\t\tAuthenticatedData(aad).\n\t\tComputedAuthenticatedData(computedAad).\n\t\tInitializationVector(m.initializationVector).\n\t\tTag(m.tag)\n\n\tvar plaintext []byte\n\tvar lastError error\n\n\t// if we have no recipients, pretend like we only have one\n\trecipients := m.recipients\n\tif len(recipients) == 0 {\n\t\tr := NewRecipient()\n\t\tif err := r.SetHeaders(m.protectedHeaders); err != nil {\n\t\t\treturn nil, errors.Wrap(err, `failed to set headers to recipient`)\n\t\t}\n\t\trecipients = append(recipients, r)\n\t}\n\n\tfor _, recipient := range recipients {\n\t\t// strategy: try each recipient. If we fail in one of the steps,\n\t\t// keep looping because there might be another key with the same algo\n\t\tif recipient.Headers().Algorithm() != alg {\n\t\t\t// algorithms don't match\n\t\t\tcontinue\n\t\t}\n\n\t\th2, err := h.Clone(ctx)\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to copy headers (1)`)\n\t\t\tcontinue\n\t\t}\n\n\t\th2, err = h2.Merge(ctx, recipient.Headers())\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to copy headers (2)`)\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch alg {\n\t\tcase jwa.ECDH_ES, jwa.ECDH_ES_A128KW, jwa.ECDH_ES_A192KW, jwa.ECDH_ES_A256KW:\n\t\t\tepkif, ok := h2.Get(EphemeralPublicKeyKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'epk' field\")\n\t\t\t}\n\t\t\tswitch epk := epkif.(type) {\n\t\t\tcase jwk.ECDSAPublicKey:\n\t\t\t\tvar pubkey ecdsa.PublicKey\n\t\t\t\tif err := epk.Raw(&pubkey); err != nil {\n\t\t\t\t\treturn nil, errors.Wrap(err, \"failed to get public key\")\n\t\t\t\t}\n\t\t\t\tdec.PublicKey(&pubkey)\n\t\t\tcase jwk.OKPPublicKey:\n\t\t\t\tvar pubkey interface{}\n\t\t\t\tif err := epk.Raw(&pubkey); err != nil {\n\t\t\t\t\treturn nil, errors.Wrap(err, \"failed to get public key\")\n\t\t\t\t}\n\t\t\t\tdec.PublicKey(pubkey)\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.Errorf(\"unexpected 'epk' type %T for alg %s\", epkif, alg)\n\t\t\t}\n\n\t\t\tif apu := h2.AgreementPartyUInfo(); len(apu) > 0 {\n\t\t\t\tdec.AgreementPartyUInfo(apu)\n\t\t\t}\n\n\t\t\tif apv := h2.AgreementPartyVInfo(); len(apv) > 0 {\n\t\t\t\tdec.AgreementPartyVInfo(apv)\n\t\t\t}\n\t\tcase jwa.A128GCMKW, jwa.A192GCMKW, jwa.A256GCMKW:\n\t\t\tivB64, ok := h2.Get(InitializationVectorKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'iv' field\")\n\t\t\t}\n\t\t\tivB64Str, ok := ivB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'iv': %T\", ivB64)\n\t\t\t}\n\t\t\ttagB64, ok := h2.Get(TagKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'tag' field\")\n\t\t\t}\n\t\t\ttagB64Str, ok := tagB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'tag': %T\", tagB64)\n\t\t\t}\n\t\t\tiv, err := base64.DecodeString(ivB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'iv'\")\n\t\t\t}\n\t\t\ttag, err := base64.DecodeString(tagB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'tag'\")\n\t\t\t}\n\t\t\tdec.KeyInitializationVector(iv)\n\t\t\tdec.KeyTag(tag)\n\t\tcase jwa.PBES2_HS256_A128KW, jwa.PBES2_HS384_A192KW, jwa.PBES2_HS512_A256KW:\n\t\t\tsaltB64, ok := h2.Get(SaltKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'p2s' field\")\n\t\t\t}\n\t\t\tsaltB64Str, ok := saltB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'p2s': %T\", saltB64)\n\t\t\t}\n\n\t\t\tcount, ok := h2.Get(CountKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'p2c' field\")\n\t\t\t}\n\t\t\tcountFlt, ok := count.(float64)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'p2c': %T\", count)\n\t\t\t}\n\t\t\t// in v1, this number is hardcoded to 10000. Use v2 if you need to\n\t\t\t// finetune this value\n\t\t\tif countFlt > 10000 {\n\t\t\t\treturn nil, errors.Errorf(\"invalid value for 'p2c'\")\n\t\t\t}\n\t\t\tsalt, err := base64.DecodeString(saltB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'salt'\")\n\t\t\t}\n\t\t\tdec.KeySalt(salt)\n\t\t\tdec.KeyCount(int(countFlt))\n\t\t}\n\n\t\tplaintext, err = dec.Decrypt(recipient.EncryptedKey(), m.cipherText)\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to decrypt`)\n\t\t\tcontinue\n\t\t}\n\n\t\tif h2.Compression() == jwa.Deflate {\n\t\t\tbuf, err := uncompress(plaintext, dctx.maxDecompressBufferSize)\n\t\t\tif err != nil {\n\t\t\t\tlastError = errors.Wrap(err, `failed to uncompress payload`)\n\t\t\t\tplaintext = nil\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tplaintext = buf\n\t\t}\n\t\tbreak\n\t}\n\n\tif plaintext == nil {\n\t\tif lastError != nil {\n\t\t\treturn nil, errors.Errorf(`failed to find matching recipient to decrypt key (last error = %s)`, lastError)\n\t\t}\n\t\treturn nil, errors.New(\"failed to find matching recipient\")\n\t}\n\n\treturn plaintext, nil\n}", "is_vulnerable": 0}
{"code": "func (config *CreateConfig) createConfigToOCISpec(runtime *libpod.Runtime, userMounts []spec.Mount) (*spec.Spec, error) {\n\tcgroupPerm := \"ro\"\n\tg, err := generate.New(\"linux\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Remove the default /dev/shm mount to ensure we overwrite it\n\tg.RemoveMount(\"/dev/shm\")\n\tg.HostSpecific = true\n\taddCgroup := true\n\tcanMountSys := true\n\n\tisRootless := rootless.IsRootless()\n\tinUserNS := config.User.InNS(isRootless)\n\n\tif inUserNS && config.Network.NetMode.IsHost() {\n\t\tcanMountSys = false\n\t}\n\n\tif config.Security.Privileged && canMountSys {\n\t\tcgroupPerm = \"rw\"\n\t\tg.RemoveMount(\"/sys\")\n\t\tsysMnt := spec.Mount{\n\t\t\tDestination: \"/sys\",\n\t\t\tType:        \"sysfs\",\n\t\t\tSource:      \"sysfs\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", \"rw\"},\n\t\t}\n\t\tg.AddMount(sysMnt)\n\t} else if !canMountSys {\n\t\taddCgroup = false\n\t\tg.RemoveMount(\"/sys\")\n\t\tr := \"ro\"\n\t\tif config.Security.Privileged {\n\t\t\tr = \"rw\"\n\t\t}\n\t\tsysMnt := spec.Mount{\n\t\t\tDestination: \"/sys\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/sys\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", r, \"rbind\"},\n\t\t}\n\t\tg.AddMount(sysMnt)\n\t\tif !config.Security.Privileged && isRootless {\n\t\t\tg.AddLinuxMaskedPaths(\"/sys/kernel\")\n\t\t}\n\t}\n\tvar runtimeConfig *cconfig.Config\n\n\tif runtime != nil {\n\t\truntimeConfig, err = runtime.GetConfig()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tg.Config.Process.Capabilities.Bounding = runtimeConfig.Containers.DefaultCapabilities\n\t\tsysctls, err := util.ValidateSysctls(runtimeConfig.Containers.DefaultSysctls)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor name, val := range config.Security.Sysctl {\n\t\t\tsysctls[name] = val\n\t\t}\n\t\tconfig.Security.Sysctl = sysctls\n\t\tif !util.StringInSlice(\"host\", config.Resources.Ulimit) {\n\t\t\tconfig.Resources.Ulimit = append(runtimeConfig.Containers.DefaultUlimits, config.Resources.Ulimit...)\n\t\t}\n\t\tif config.Resources.PidsLimit < 0 && !config.cgroupDisabled() {\n\t\t\tconfig.Resources.PidsLimit = runtimeConfig.Containers.PidsLimit\n\t\t}\n\n\t} else {\n\t\tg.Config.Process.Capabilities.Bounding = cconfig.DefaultCapabilities\n\t\tif config.Resources.PidsLimit < 0 && !config.cgroupDisabled() {\n\t\t\tconfig.Resources.PidsLimit = cconfig.DefaultPidsLimit\n\t\t}\n\t}\n\n\tgid5Available := true\n\tif isRootless {\n\t\tnGids, err := GetAvailableGids()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tgid5Available = nGids >= 5\n\t}\n\t// When using a different user namespace, check that the GID 5 is mapped inside\n\t// the container.\n\tif gid5Available && len(config.User.IDMappings.GIDMap) > 0 {\n\t\tmappingFound := false\n\t\tfor _, r := range config.User.IDMappings.GIDMap {\n\t\t\tif r.ContainerID <= 5 && 5 < r.ContainerID+r.Size {\n\t\t\t\tmappingFound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !mappingFound {\n\t\t\tgid5Available = false\n\t\t}\n\n\t}\n\tif !gid5Available {\n\t\t// If we have no GID mappings, the gid=5 default option would fail, so drop it.\n\t\tg.RemoveMount(\"/dev/pts\")\n\t\tdevPts := spec.Mount{\n\t\t\tDestination: \"/dev/pts\",\n\t\t\tType:        \"devpts\",\n\t\t\tSource:      \"devpts\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"newinstance\", \"ptmxmode=0666\", \"mode=0620\"},\n\t\t}\n\t\tg.AddMount(devPts)\n\t}\n\n\tif inUserNS && config.Ipc.IpcMode.IsHost() {\n\t\tg.RemoveMount(\"/dev/mqueue\")\n\t\tdevMqueue := spec.Mount{\n\t\t\tDestination: \"/dev/mqueue\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/dev/mqueue\",\n\t\t\tOptions:     []string{\"bind\", \"nosuid\", \"noexec\", \"nodev\"},\n\t\t}\n\t\tg.AddMount(devMqueue)\n\t}\n\tif inUserNS && config.Pid.PidMode.IsHost() {\n\t\tg.RemoveMount(\"/proc\")\n\t\tprocMount := spec.Mount{\n\t\t\tDestination: \"/proc\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/proc\",\n\t\t\tOptions:     []string{\"rbind\", \"nosuid\", \"noexec\", \"nodev\"},\n\t\t}\n\t\tg.AddMount(procMount)\n\t}\n\n\tif addCgroup {\n\t\tcgroupMnt := spec.Mount{\n\t\t\tDestination: \"/sys/fs/cgroup\",\n\t\t\tType:        \"cgroup\",\n\t\t\tSource:      \"cgroup\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", \"relatime\", cgroupPerm},\n\t\t}\n\t\tg.AddMount(cgroupMnt)\n\t}\n\tg.SetProcessCwd(config.WorkDir)\n\tg.SetProcessArgs(config.Command)\n\tg.SetProcessTerminal(config.Tty)\n\n\tfor key, val := range config.Annotations {\n\t\tg.AddAnnotation(key, val)\n\t}\n\n\taddedResources := false\n\n\t// RESOURCES - MEMORY\n\tif config.Resources.Memory != 0 {\n\t\tg.SetLinuxResourcesMemoryLimit(config.Resources.Memory)\n\t\t// If a swap limit is not explicitly set, also set a swap limit\n\t\t// Default to double the memory limit\n\t\tif config.Resources.MemorySwap == 0 {\n\t\t\tg.SetLinuxResourcesMemorySwap(2 * config.Resources.Memory)\n\t\t}\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemoryReservation != 0 {\n\t\tg.SetLinuxResourcesMemoryReservation(config.Resources.MemoryReservation)\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemorySwap != 0 {\n\t\tg.SetLinuxResourcesMemorySwap(config.Resources.MemorySwap)\n\t\taddedResources = true\n\t}\n\tif config.Resources.KernelMemory != 0 {\n\t\tg.SetLinuxResourcesMemoryKernel(config.Resources.KernelMemory)\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemorySwappiness != -1 {\n\t\tg.SetLinuxResourcesMemorySwappiness(uint64(config.Resources.MemorySwappiness))\n\t\taddedResources = true\n\t}\n\tg.SetLinuxResourcesMemoryDisableOOMKiller(config.Resources.DisableOomKiller)\n\tg.SetProcessOOMScoreAdj(config.Resources.OomScoreAdj)\n\n\t// RESOURCES - CPU\n\tif config.Resources.CPUShares != 0 {\n\t\tg.SetLinuxResourcesCPUShares(config.Resources.CPUShares)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUQuota != 0 {\n\t\tg.SetLinuxResourcesCPUQuota(config.Resources.CPUQuota)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUPeriod != 0 {\n\t\tg.SetLinuxResourcesCPUPeriod(config.Resources.CPUPeriod)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUs != 0 {\n\t\tg.SetLinuxResourcesCPUPeriod(CpuPeriod)\n\t\tg.SetLinuxResourcesCPUQuota(int64(config.Resources.CPUs * CpuPeriod))\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPURtRuntime != 0 {\n\t\tg.SetLinuxResourcesCPURealtimeRuntime(config.Resources.CPURtRuntime)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPURtPeriod != 0 {\n\t\tg.SetLinuxResourcesCPURealtimePeriod(config.Resources.CPURtPeriod)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUsetCPUs != \"\" {\n\t\tg.SetLinuxResourcesCPUCpus(config.Resources.CPUsetCPUs)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUsetMems != \"\" {\n\t\tg.SetLinuxResourcesCPUMems(config.Resources.CPUsetMems)\n\t\taddedResources = true\n\t}\n\n\t// Devices\n\tif config.Security.Privileged {\n\t\t// If privileged, we need to add all the host devices to the\n\t\t// spec.  We do not add the user provided ones because we are\n\t\t// already adding them all.\n\t\tif err := AddPrivilegedDevices(&g); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\tfor _, devicePath := range config.Devices {\n\t\t\tif err := DevicesFromPath(&g, devicePath); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tif len(config.Resources.DeviceCgroupRules) != 0 {\n\t\t\tif err := deviceCgroupRules(&g, config.Resources.DeviceCgroupRules); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\taddedResources = true\n\t\t}\n\t}\n\n\tg.SetProcessNoNewPrivileges(config.Security.NoNewPrivs)\n\n\tif !config.Security.Privileged {\n\t\tg.SetProcessApparmorProfile(config.Security.ApparmorProfile)\n\t}\n\n\t// Unless already set via the CLI, check if we need to disable process\n\t// labels or set the defaults.\n\tif len(config.Security.LabelOpts) == 0 && runtimeConfig != nil {\n\t\tif !runtimeConfig.Containers.EnableLabeling {\n\t\t\t// Disabled in the config.\n\t\t\tconfig.Security.LabelOpts = append(config.Security.LabelOpts, \"disable\")\n\t\t} else if err := config.Security.SetLabelOpts(runtime, &config.Pid, &config.Ipc); err != nil {\n\t\t\t// Defaults!\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tBlockAccessToKernelFilesystems(config.Security.Privileged, config.Pid.PidMode.IsHost(), &g)\n\n\t// RESOURCES - PIDS\n\tif config.Resources.PidsLimit > 0 {\n\t\t// if running on rootless on a cgroupv1 machine or using the cgroupfs manager, pids\n\t\t// limit is not supported.  If the value is still the default\n\t\t// then ignore the settings.  If the caller asked for a\n\t\t// non-default, then try to use it.\n\t\tsetPidLimit := true\n\t\tif rootless.IsRootless() {\n\t\t\tcgroup2, err := cgroups.IsCgroup2UnifiedMode()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif (!cgroup2 || (runtimeConfig != nil && runtimeConfig.Engine.CgroupManager != cconfig.SystemdCgroupsManager)) && config.Resources.PidsLimit == sysinfo.GetDefaultPidsLimit() {\n\t\t\t\tsetPidLimit = false\n\t\t\t}\n\t\t}\n\t\tif setPidLimit {\n\t\t\tg.SetLinuxResourcesPidsLimit(config.Resources.PidsLimit)\n\t\t\taddedResources = true\n\t\t}\n\t}\n\n\t// Make sure to always set the default variables unless overridden in the\n\t// config.\n\tvar defaultEnv map[string]string\n\tif runtimeConfig == nil {\n\t\tdefaultEnv = env.DefaultEnvVariables\n\t} else {\n\t\tdefaultEnv, err = env.ParseSlice(runtimeConfig.Containers.Env)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"Env fields in containers.conf failed ot parse\")\n\t\t}\n\t\tdefaultEnv = env.Join(env.DefaultEnvVariables, defaultEnv)\n\t}\n\n\tif err := addRlimits(config, &g); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// NAMESPACES\n\n\tif err := config.Pid.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.User.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Network.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Uts.ConfigureGenerator(&g, &config.Network, runtime); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Ipc.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Cgroup.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tconfig.Env = env.Join(defaultEnv, config.Env)\n\tfor name, val := range config.Env {\n\t\tg.AddProcessEnv(name, val)\n\t}\n\tconfigSpec := g.Config\n\n\t// If the container image specifies an label with a\n\t// capabilities.ContainerImageLabel then split the comma separated list\n\t// of capabilities and record them.  This list indicates the only\n\t// capabilities, required to run the container.\n\tvar capRequired []string\n\tfor key, val := range config.Labels {\n\t\tif util.StringInSlice(key, capabilities.ContainerImageLabels) {\n\t\t\tcapRequired = strings.Split(val, \",\")\n\t\t}\n\t}\n\tconfig.Security.CapRequired = capRequired\n\n\tif err := config.Security.ConfigureGenerator(&g, &config.User); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// BIND MOUNTS\n\tconfigSpec.Mounts = SupercedeUserMounts(userMounts, configSpec.Mounts)\n\t// Process mounts to ensure correct options\n\tif err := InitFSMounts(configSpec.Mounts); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// BLOCK IO\n\tblkio, err := config.CreateBlockIO()\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"error creating block io\")\n\t}\n\tif blkio != nil {\n\t\tconfigSpec.Linux.Resources.BlockIO = blkio\n\t\taddedResources = true\n\t}\n\n\tif rootless.IsRootless() {\n\t\tcgroup2, err := cgroups.IsCgroup2UnifiedMode()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !addedResources {\n\t\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\t\t}\n\n\t\tcanUseResources := cgroup2 && runtimeConfig != nil && (runtimeConfig.Engine.CgroupManager == cconfig.SystemdCgroupsManager)\n\n\t\tif addedResources && !canUseResources {\n\t\t\treturn nil, errors.New(\"invalid configuration, cannot specify resource limits without cgroups v2 and --cgroup-manager=systemd\")\n\t\t}\n\t\tif !canUseResources {\n\t\t\t// Force the resources block to be empty instead of having default values.\n\t\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\t\t}\n\t}\n\n\tswitch config.Cgroup.Cgroups {\n\tcase \"disabled\":\n\t\tif addedResources {\n\t\t\treturn nil, errors.New(\"cannot specify resource limits when cgroups are disabled is specified\")\n\t\t}\n\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\tcase \"enabled\", \"no-conmon\", \"\":\n\t\t// Do nothing\n\tdefault:\n\t\treturn nil, errors.New(\"unrecognized option for cgroups; supported are 'default', 'disabled', 'no-conmon'\")\n\t}\n\n\t// Add annotations\n\tif configSpec.Annotations == nil {\n\t\tconfigSpec.Annotations = make(map[string]string)\n\t}\n\n\tif config.CidFile != \"\" {\n\t\tconfigSpec.Annotations[define.InspectAnnotationCIDFile] = config.CidFile\n\t}\n\n\tif config.Rm {\n\t\tconfigSpec.Annotations[define.InspectAnnotationAutoremove] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationAutoremove] = define.InspectResponseFalse\n\t}\n\n\tif len(config.VolumesFrom) > 0 {\n\t\tconfigSpec.Annotations[define.InspectAnnotationVolumesFrom] = strings.Join(config.VolumesFrom, \",\")\n\t}\n\n\tif config.Security.Privileged {\n\t\tconfigSpec.Annotations[define.InspectAnnotationPrivileged] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationPrivileged] = define.InspectResponseFalse\n\t}\n\n\tif config.Init {\n\t\tconfigSpec.Annotations[define.InspectAnnotationInit] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationInit] = define.InspectResponseFalse\n\t}\n\n\treturn configSpec, nil\n}", "is_vulnerable": 1}
{"code": "func TestCreateProposalBlock(t *testing.T) {\n\tconfig := cfg.ResetTestRoot(\"node_create_proposal\")\n\tdefer os.RemoveAll(config.RootDir)\n\tcc := proxy.NewLocalClientCreator(kvstore.NewApplication())\n\tproxyApp := proxy.NewAppConns(cc)\n\terr := proxyApp.Start()\n\trequire.Nil(t, err)\n\tdefer proxyApp.Stop() //nolint:errcheck // ignore for tests\n\n\tlogger := log.TestingLogger()\n\n\tvar height int64 = 1\n\tstate, stateDB, privVals := state(1, height)\n\tstateStore := sm.NewStore(stateDB)\n\tmaxBytes := 16384\n\tvar partSize uint32 = 256\n\tmaxEvidenceBytes := int64(maxBytes / 2)\n\tstate.ConsensusParams.Block.MaxBytes = int64(maxBytes)\n\tstate.ConsensusParams.Evidence.MaxBytes = maxEvidenceBytes\n\tproposerAddr, _ := state.Validators.GetByIndex(0)\n\n\t// Make Mempool\n\tmemplMetrics := mempl.PrometheusMetrics(\"node_test_1\")\n\tmempool := mempl.NewCListMempool(\n\t\tconfig.Mempool,\n\t\tproxyApp.Mempool(),\n\t\tstate.LastBlockHeight,\n\t\tmempl.WithMetrics(memplMetrics),\n\t\tmempl.WithPreCheck(sm.TxPreCheck(state)),\n\t\tmempl.WithPostCheck(sm.TxPostCheck(state)),\n\t)\n\tmempool.SetLogger(logger)\n\n\t// Make EvidencePool\n\tevidenceDB := dbm.NewMemDB()\n\tblockStore := store.NewBlockStore(dbm.NewMemDB())\n\tevidencePool, err := evidence.NewPool(evidenceDB, stateStore, blockStore)\n\trequire.NoError(t, err)\n\tevidencePool.SetLogger(logger)\n\n\t// fill the evidence pool with more evidence\n\t// than can fit in a block\n\tvar currentBytes int64 = 0\n\tfor currentBytes <= maxEvidenceBytes {\n\t\tev := types.NewMockDuplicateVoteEvidenceWithValidator(height, time.Now(), privVals[0], \"test-chain\")\n\t\tcurrentBytes += int64(len(ev.Bytes()))\n\t\tevidencePool.ReportConflictingVotes(ev.VoteA, ev.VoteB)\n\t}\n\n\tevList, size := evidencePool.PendingEvidence(state.ConsensusParams.Evidence.MaxBytes)\n\trequire.Less(t, size, state.ConsensusParams.Evidence.MaxBytes+1)\n\tevData := &types.EvidenceData{Evidence: evList}\n\trequire.EqualValues(t, size, evData.ByteSize())\n\n\t// fill the mempool with more txs\n\t// than can fit in a block\n\ttxLength := 100\n\tfor i := 0; i <= maxBytes/txLength; i++ {\n\t\ttx := tmrand.Bytes(txLength)\n\t\terr := mempool.CheckTx(tx, nil, mempl.TxInfo{})\n\t\tassert.NoError(t, err)\n\t}\n\n\tblockExec := sm.NewBlockExecutor(\n\t\tstateStore,\n\t\tlogger,\n\t\tproxyApp.Consensus(),\n\t\tmempool,\n\t\tevidencePool,\n\t)\n\n\tcommit := types.NewCommit(height-1, 0, types.BlockID{}, nil)\n\tblock, _ := blockExec.CreateProposalBlock(\n\t\theight,\n\t\tstate, commit,\n\t\tproposerAddr,\n\t)\n\n\t// check that the part set does not exceed the maximum block size\n\tpartSet := block.MakePartSet(partSize)\n\tassert.Less(t, partSet.ByteSize(), int64(maxBytes))\n\n\tpartSetFromHeader := types.NewPartSetFromHeader(partSet.Header())\n\tfor partSetFromHeader.Count() < partSetFromHeader.Total() {\n\t\tadded, err := partSetFromHeader.AddPart(partSet.GetPart(int(partSetFromHeader.Count())))\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, added)\n\t}\n\tassert.EqualValues(t, partSetFromHeader.ByteSize(), partSet.ByteSize())\n\n\terr = blockExec.ValidateBlock(state, block)\n\tassert.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func NoError(t TestingT, err error, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NoError(t, err, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (g *TarGzExtractor) Extract(buffer *bytes.Buffer, targetDir string) error {\n\tuncompressedStream, err := gzip.NewReader(buffer)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := os.MkdirAll(targetDir, 0755); err != nil {\n\t\treturn err\n\t}\n\n\ttarReader := tar.NewReader(uncompressedStream)\n\tfor {\n\t\theader, err := tarReader.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tpath, err := cleanJoin(targetDir, header.Name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tswitch header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif err := os.Mkdir(path, 0755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase tar.TypeReg:\n\t\t\toutFile, err := os.OpenFile(path, os.O_CREATE|os.O_RDWR, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif _, err := io.Copy(outFile, tarReader); err != nil {\n\t\t\t\toutFile.Close()\n\t\t\t\treturn err\n\t\t\t}\n\t\t\toutFile.Close()\n\t\t// We don't want to process these extension header files.\n\t\tcase tar.TypeXGlobalHeader, tar.TypeXHeader:\n\t\t\tcontinue\n\t\tdefault:\n\t\t\treturn errors.Errorf(\"unknown type: %b in %s\", header.Typeflag, header.Name)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *managedIdentityClient) authenticate(ctx context.Context, id ManagedIDKind, scopes []string) (azcore.AccessToken, error) {\n\t// no need to synchronize around this value because it's true only when DefaultAzureCredential constructed the client,\n\t// and in that case ChainedTokenCredential.GetToken synchronizes goroutines that would execute this block\n\tif c.probeIMDS {\n\t\tcx, cancel := context.WithTimeout(ctx, imdsProbeTimeout)\n\t\tdefer cancel()\n\t\tcx = policy.WithRetryOptions(cx, policy.RetryOptions{MaxRetries: -1})\n\t\treq, err := runtime.NewRequest(cx, http.MethodGet, c.endpoint)\n\t\tif err == nil {\n\t\t\t_, err = c.azClient.Pipeline().Do(req)\n\t\t}\n\t\tif err != nil {\n\t\t\tmsg := err.Error()\n\t\t\tif errors.Is(err, context.Canceled) || errors.Is(err, context.DeadlineExceeded) {\n\t\t\t\tmsg = \"managed identity timed out. See https://aka.ms/azsdk/go/identity/troubleshoot#dac for more information\"\n\t\t\t}\n\t\t\treturn azcore.AccessToken{}, newCredentialUnavailableError(credNameManagedIdentity, msg)\n\t\t}\n\t\t// send normal token requests from now on because something responded\n\t\tc.probeIMDS = false\n\t}\n\n\tmsg, err := c.createAuthRequest(ctx, id, scopes)\n\tif err != nil {\n\t\treturn azcore.AccessToken{}, err\n\t}\n\n\tresp, err := c.azClient.Pipeline().Do(msg)\n\tif err != nil {\n\t\treturn azcore.AccessToken{}, newAuthenticationFailedError(credNameManagedIdentity, err.Error(), nil, err)\n\t}\n\n\tif runtime.HasStatusCode(resp, http.StatusOK, http.StatusCreated) {\n\t\treturn c.createAccessToken(resp)\n\t}\n\n\tif c.msiType == msiTypeIMDS {\n\t\tswitch resp.StatusCode {\n\t\tcase http.StatusBadRequest:\n\t\t\tif id != nil {\n\t\t\t\treturn azcore.AccessToken{}, newAuthenticationFailedError(credNameManagedIdentity, \"the requested identity isn't assigned to this resource\", resp, nil)\n\t\t\t}\n\t\t\tmsg := \"failed to authenticate a system assigned identity\"\n\t\t\tif body, err := runtime.Payload(resp); err == nil && len(body) > 0 {\n\t\t\t\tmsg += fmt.Sprintf(\". The endpoint responded with %s\", body)\n\t\t\t}\n\t\t\treturn azcore.AccessToken{}, newCredentialUnavailableError(credNameManagedIdentity, msg)\n\t\tcase http.StatusForbidden:\n\t\t\t// Docker Desktop runs a proxy that responds 403 to IMDS token requests. If we get that response,\n\t\t\t// we return credentialUnavailableError so credential chains continue to their next credential\n\t\t\tbody, err := runtime.Payload(resp)\n\t\t\tif err == nil && strings.Contains(string(body), \"unreachable\") {\n\t\t\t\treturn azcore.AccessToken{}, newCredentialUnavailableError(credNameManagedIdentity, fmt.Sprintf(\"unexpected response %q\", string(body)))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn azcore.AccessToken{}, newAuthenticationFailedError(credNameManagedIdentity, \"\", resp, nil)\n}", "is_vulnerable": 1}
{"code": "func TestPeerIsAddedToPeersWhenMessageReceivedOrSent(t *testing.T) {\n\ttest.Flaky(t)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\tsanfrancisco := newTestEngine(ctx, \"sf\")\n\tseattle := newTestEngine(ctx, \"sea\")\n\n\tm := message.New(true)\n\n\tsanfrancisco.Engine.MessageSent(seattle.Peer, m)\n\tseattle.Engine.MessageReceived(ctx, sanfrancisco.Peer, m)\n\n\tif seattle.Peer == sanfrancisco.Peer {\n\t\tt.Fatal(\"Sanity Check: Peers have same Key!\")\n\t}\n\n\tif !peerIsPartner(seattle.Peer, sanfrancisco.Engine) {\n\t\tt.Fatal(\"Peer wasn't added as a Partner\")\n\t}\n\n\tif !peerIsPartner(sanfrancisco.Peer, seattle.Engine) {\n\t\tt.Fatal(\"Peer wasn't added as a Partner\")\n\t}\n\n\tseattle.Engine.PeerDisconnected(sanfrancisco.Peer)\n\tif peerIsPartner(sanfrancisco.Peer, seattle.Engine) {\n\t\tt.Fatal(\"expected peer to be removed\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *WriteCommand) validateTuplesets(ctx context.Context, req *openfgapb.WriteRequest) error {\n\tctx, span := c.tracer.Start(ctx, \"validateTuplesets\")\n\tdefer span.End()\n\n\tstore := req.GetStoreId()\n\tmodelID := req.GetAuthorizationModelId()\n\tdeletes := req.GetDeletes().GetTupleKeys()\n\twrites := req.GetWrites().GetTupleKeys()\n\n\tif deletes == nil && writes == nil {\n\t\treturn serverErrors.InvalidWriteInput\n\t}\n\n\tvar authModel *openfgapb.AuthorizationModel\n\n\tif len(writes) > 0 {\n\t\t// only read the auth model if we are adding tuples\n\t\tvar err error\n\t\tauthModel, err = c.datastore.ReadAuthorizationModel(ctx, store, modelID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, tk := range writes {\n\t\ttupleUserset, err := validation.ValidateTuple(ctx, c.datastore, store, modelID, tk)\n\t\tif err != nil {\n\t\t\treturn serverErrors.HandleTupleValidateError(err)\n\t\t}\n\n\t\t// Validate that we are not trying to write to an indirect-only relationship\n\t\tif !typesystem.RewriteContainsSelf(tupleUserset) {\n\t\t\treturn serverErrors.HandleTupleValidateError(&tupleUtils.IndirectWriteError{Reason: IndirectWriteErrorReason, TupleKey: tk})\n\t\t}\n\n\t\tif err := c.validateNoUsersetForRelationReferencedInTupleset(authModel, tk); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := c.validateTypesForTuple(authModel, tk); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tfor _, tk := range deletes {\n\t\t// For delete, we only need to ensure it is well form but no need to validate whether relation exists\n\t\tif err := tupleUtils.ValidateUser(tk); err != nil {\n\t\t\treturn serverErrors.HandleTupleValidateError(err)\n\t\t}\n\t}\n\n\tif err := c.validateNoDuplicatesAndCorrectSize(deletes, writes); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tUpdateFunc: func(old, obj interface{}) { u(old.(T), obj.(T)) },", "is_vulnerable": 1}
{"code": "func Regexpf(t TestingT, rx interface{}, str interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Regexpf(t, rx, str, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func Reset() {\n\tNetwork = \"tcp\"\n\tBind = \":8080\"\n\tReadTimeout = 10\n\tWriteTimeout = 10\n\tKeepAliveTimeout = 10\n\tClientKeepAliveTimeout = 90\n\tDownloadTimeout = 5\n\tConcurrency = runtime.GOMAXPROCS(0) * 2\n\tRequestsQueueSize = 0\n\tMaxClients = 2048\n\n\tTTL = 31536000\n\tCacheControlPassthrough = false\n\tSetCanonicalHeader = false\n\n\tSoReuseport = false\n\n\tPathPrefix = \"\"\n\n\tMaxSrcResolution = 16800000\n\tMaxSrcFileSize = 0\n\tMaxAnimationFrames = 1\n\tMaxAnimationFrameResolution = 0\n\tMaxSvgCheckBytes = 32 * 1024\n\tMaxRedirects = 10\n\tAllowSecurityOptions = false\n\n\tJpegProgressive = false\n\tPngInterlaced = false\n\tPngQuantize = false\n\tPngQuantizationColors = 256\n\tAvifSpeed = 8\n\tQuality = 80\n\tFormatQuality = map[imagetype.Type]int{imagetype.AVIF: 65}\n\tStripMetadata = true\n\tKeepCopyright = true\n\tStripColorProfile = true\n\tAutoRotate = true\n\tEnforceThumbnail = false\n\tReturnAttachment = false\n\tSvgFixUnsupported = false\n\n\tEnableWebpDetection = false\n\tEnforceWebp = false\n\tEnableAvifDetection = false\n\tEnforceAvif = false\n\tEnableClientHints = false\n\n\tPreferredFormats = []imagetype.Type{\n\t\timagetype.JPEG,\n\t\timagetype.PNG,\n\t\timagetype.GIF,\n\t}\n\n\tSkipProcessingFormats = make([]imagetype.Type, 0)\n\n\tUseLinearColorspace = false\n\tDisableShrinkOnLoad = false\n\n\tKeys = make([][]byte, 0)\n\tSalts = make([][]byte, 0)\n\tSignatureSize = 32\n\n\tSecret = \"\"\n\n\tAllowOrigin = \"\"\n\n\tUserAgent = fmt.Sprintf(\"imgproxy/%s\", version.Version())\n\n\tIgnoreSslVerification = false\n\tDevelopmentErrorsMode = false\n\n\tAllowedSources = make([]*regexp.Regexp, 0)\n\tAllowLoopbackSourceAddresses = false\n\tAllowLinkLocalSourceAddresses = false\n\tAllowPrivateSourceAddresses = true\n\n\tSanitizeSvg = true\n\n\tCookiePassthrough = false\n\tCookieBaseURL = \"\"\n\n\tLocalFileSystemRoot = \"\"\n\tS3Enabled = false\n\tS3Region = \"\"\n\tS3Endpoint = \"\"\n\tGCSEnabled = false\n\tGCSKey = \"\"\n\tABSEnabled = false\n\tABSName = \"\"\n\tABSKey = \"\"\n\tABSEndpoint = \"\"\n\tSwiftEnabled = false\n\tSwiftUsername = \"\"\n\tSwiftAPIKey = \"\"\n\tSwiftAuthURL = \"\"\n\tSwiftAuthVersion = 0\n\tSwiftTenant = \"\"\n\tSwiftDomain = \"\"\n\tSwiftConnectTimeoutSeconds = 10\n\tSwiftTimeoutSeconds = 60\n\n\tETagEnabled = false\n\tETagBuster = \"\"\n\n\tBaseURL = \"\"\n\n\tPresets = make([]string, 0)\n\tOnlyPresets = false\n\n\tWatermarkData = \"\"\n\tWatermarkPath = \"\"\n\tWatermarkURL = \"\"\n\tWatermarkOpacity = 1\n\n\tFallbackImageData = \"\"\n\tFallbackImagePath = \"\"\n\tFallbackImageURL = \"\"\n\tFallbackImageHTTPCode = 200\n\tFallbackImageTTL = 0\n\n\tDataDogEnable = false\n\n\tNewRelicAppName = \"\"\n\tNewRelicKey = \"\"\n\tNewRelicLabels = make(map[string]string)\n\n\tPrometheusBind = \"\"\n\tPrometheusNamespace = \"\"\n\n\tOpenTelemetryEndpoint = \"\"\n\tOpenTelemetryProtocol = \"grpc\"\n\tOpenTelemetryServiceName = \"imgproxy\"\n\tOpenTelemetryEnableMetrics = false\n\tOpenTelemetryServerCert = \"\"\n\tOpenTelemetryClientCert = \"\"\n\tOpenTelemetryClientKey = \"\"\n\tOpenTelemetryGRPCInsecure = true\n\tOpenTelemetryPropagators = make([]string, 0)\n\tOpenTelemetryTraceIDGenerator = \"xray\"\n\tOpenTelemetryConnectionTimeout = 5\n\n\tCloudWatchServiceName = \"\"\n\tCloudWatchNamespace = \"imgproxy\"\n\tCloudWatchRegion = \"\"\n\n\tBugsnagKey = \"\"\n\tBugsnagStage = \"production\"\n\n\tHoneybadgerKey = \"\"\n\tHoneybadgerEnv = \"production\"\n\n\tSentryDSN = \"\"\n\tSentryEnvironment = \"production\"\n\tSentryRelease = fmt.Sprintf(\"imgproxy@%s\", version.Version())\n\n\tAirbrakeProjecID = 0\n\tAirbrakeProjecKey = \"\"\n\tAirbrakeEnv = \"production\"\n\n\tReportDownloadingErrors = true\n\n\tEnableDebugHeaders = false\n\n\tFreeMemoryInterval = 10\n\tDownloadBufferSize = 0\n\tBufferPoolCalibrationThreshold = 1024\n\n\tHealthCheckPath = \"\"\n}", "is_vulnerable": 0}
{"code": "func (m *Message) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Message: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Message: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Hilarity\", wireType)\n\t\t\t}\n\t\t\tm.Hilarity = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Hilarity |= Message_Humour(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field HeightInCm\", wireType)\n\t\t\t}\n\t\t\tm.HeightInCm = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.HeightInCm |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Data\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Data = append(m.Data[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Data == nil {\n\t\t\t\tm.Data = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Key = append(m.Key, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Key) == 0 {\n\t\t\t\t\tm.Key = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Key = append(m.Key, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Key\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Nested\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Nested == nil {\n\t\t\t\tm.Nested = &Nested{}\n\t\t\t}\n\t\t\tif err := m.Nested.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field ResultCount\", wireType)\n\t\t\t}\n\t\t\tm.ResultCount = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.ResultCount |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field TrueScotsman\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TrueScotsman = bool(v != 0)\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Score\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.Score = float32(math.Float32frombits(v))\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Terrain\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Terrain == nil {\n\t\t\t\tm.Terrain = make(map[int64]*Nested)\n\t\t\t}\n\t\t\tvar mapkey int64\n\t\t\tvar mapvalue *Nested\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Nested{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Terrain[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Proto2Field\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Proto2Field == nil {\n\t\t\t\tm.Proto2Field = &both.NinOptNative{}\n\t\t\t}\n\t\t\tif err := m.Proto2Field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Proto2Value\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Proto2Value == nil {\n\t\t\t\tm.Proto2Value = make(map[int64]*both.NinOptEnum)\n\t\t\t}\n\t\t\tvar mapkey int64\n\t\t\tvar mapvalue *both.NinOptEnum\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &both.NinOptEnum{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Proto2Value[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func intFromInterface(selector interface{}) int {\n\tvar value int\n\tswitch selector.(type) {\n\tcase int:\n\t\tvalue = selector.(int)\n\tcase int8:\n\t\tvalue = int(selector.(int8))\n\tcase int16:\n\t\tvalue = int(selector.(int16))\n\tcase int32:\n\t\tvalue = int(selector.(int32))\n\tcase int64:\n\t\tvalue = int(selector.(int64))\n\tcase uint:\n\t\tvalue = int(selector.(uint))\n\tcase uint8:\n\t\tvalue = int(selector.(uint8))\n\tcase uint16:\n\t\tvalue = int(selector.(uint16))\n\tcase uint32:\n\t\tvalue = int(selector.(uint32))\n\tcase uint64:\n\t\tvalue = int(selector.(uint64))\n\tdefault:\n\t\treturn 0\n\t}\n\treturn value\n}", "is_vulnerable": 0}
{"code": "func (k *Key) CanEncrypt() bool {\n\treturn C.key_can_encrypt(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Rm(ctx context.Context, in *sliverpb.RmReq, opts ...grpc.CallOption) (*sliverpb.Rm, error) {\n\tout := new(sliverpb.Rm)\n\terr := c.cc.Invoke(ctx, SliverRPC_Rm_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\t\tonce.Do(func() {\n\t\t\tfmt.Fprintf(os.Stderr, \"WARNING: Due to an old rpk bug, your redpanda.yaml's redpanda.rpc_server_tls property is an array, and redpanda reads the field as a struct. rpk cannot automatically fix this: brokers would not be able to rejoin the cluster during a rolling upgrade. To enable TLS on broker RPC ports, you must turn off your cluster, switch the redpanda.rpc_server_tls field to a struct, and then turn your cluster back on. To switch from a list to a struct, replace the single dash under redpanda.rpc_server_tls with a space. This message will continue to appear while redpanda.rpc_server_tls exists and is an array\\n\")\n\t\t})", "is_vulnerable": 0}
{"code": "func authenticateDNSToken(tokenString string) bool {\n\ttokens := strings.Split(tokenString, \" \")\n\tif len(tokens) < 2 {\n\t\treturn false\n\t}\n\treturn tokens[1] == servercfg.GetDNSKey()\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"broker url must be specified\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"emitter.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Emitter)\n\n\tfor _, value := range eventSource.Spec.Emitter {\n\t\tl := &EventListener{\n\t\t\tEmitterEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func setupContainerUser(ctx context.Context, specgen *generate.Generator, rootfs, mountLabel, ctrRunDir string, sc *types.LinuxContainerSecurityContext, imageConfig *v1.Image) error {\n\tif sc == nil {\n\t\treturn nil\n\t}\n\tif sc.RunAsGroup != nil && sc.RunAsUser == nil && sc.RunAsUsername == \"\" {\n\t\treturn fmt.Errorf(\"user group is specified without user or username\")\n\t}\n\timageUser := \"\"\n\thomedir := \"\"\n\tfor _, env := range specgen.Config.Process.Env {\n\t\tif strings.HasPrefix(env, \"HOME=\") {\n\t\t\thomedir = strings.TrimPrefix(env, \"HOME=\")\n\t\t\tbreak\n\t\t}\n\t}\n\tif homedir == \"\" {\n\t\thomedir = specgen.Config.Process.Cwd\n\t}\n\n\tif imageConfig != nil {\n\t\timageUser = imageConfig.Config.User\n\t}\n\tcontainerUser := generateUserString(\n\t\tsc.RunAsUsername,\n\t\timageUser,\n\t\tsc.RunAsUser,\n\t)\n\tlog.Debugf(ctx, \"CONTAINER USER: %+v\", containerUser)\n\n\t// Add uid, gid and groups from user\n\tuid, gid, addGroups, err := utils.GetUserInfo(rootfs, containerUser)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tgenPasswd := true\n\tfor _, mount := range specgen.Config.Mounts {\n\t\tif mount.Destination == \"/etc\" ||\n\t\t\tmount.Destination == \"/etc/\" ||\n\t\t\tmount.Destination == \"/etc/passwd\" {\n\t\t\tgenPasswd = false\n\t\t\tbreak\n\t\t}\n\t}\n\tif genPasswd {\n\t\t// verify uid exists in containers /etc/passwd, else generate a passwd with the user entry\n\t\tpasswdPath, err := utils.GeneratePasswd(containerUser, uid, gid, homedir, rootfs, ctrRunDir)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif passwdPath != \"\" {\n\t\t\tif err := securityLabel(passwdPath, mountLabel, false, false); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tmnt := rspec.Mount{\n\t\t\t\tType:        \"bind\",\n\t\t\t\tSource:      passwdPath,\n\t\t\t\tDestination: \"/etc/passwd\",\n\t\t\t\tOptions:     []string{\"rw\", \"bind\", \"nodev\", \"nosuid\", \"noexec\"},\n\t\t\t}\n\t\t\tspecgen.AddMount(mnt)\n\t\t}\n\t}\n\n\tspecgen.SetProcessUID(uid)\n\tif sc.RunAsGroup != nil {\n\t\tgid = uint32(sc.RunAsGroup.Value)\n\t}\n\tspecgen.SetProcessGID(gid)\n\tspecgen.AddProcessAdditionalGid(gid)\n\n\tfor _, group := range addGroups {\n\t\tspecgen.AddProcessAdditionalGid(group)\n\t}\n\n\t// Add groups from CRI\n\tgroups := sc.SupplementalGroups\n\tfor _, group := range groups {\n\t\tspecgen.AddProcessAdditionalGid(uint32(group))\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_CommonTLSConfigCAs(t *testing.T) {\n\tc, err := NewConfigurator(Config{}, nil)\n\trequire.NoError(t, err)\n\trequire.Nil(t, c.commonTLSConfig(false).ClientCAs)\n\trequire.Nil(t, c.commonTLSConfig(false).RootCAs)\n\n\tc.cas = &x509.CertPool{}\n\trequire.Equal(t, c.cas, c.commonTLSConfig(false).ClientCAs)\n\trequire.Equal(t, c.cas, c.commonTLSConfig(false).RootCAs)\n}", "is_vulnerable": 0}
{"code": "func (c *repositoryClient) FetchSignatureBlob(ctx context.Context, desc ocispec.Descriptor) ([]byte, ocispec.Descriptor, error) {\n\tmanifestRef := c.getReferenceFromDescriptor(desc)\n\n\tmanifestBytes, err := crane.Manifest(manifestRef)\n\tif err != nil {\n\t\treturn nil, ocispec.Descriptor{}, err\n\t}\n\n\tvar manifest ocispec.Manifest\n\tif err := json.Unmarshal(manifestBytes, &manifest); err != nil {\n\t\treturn nil, ocispec.Descriptor{}, err\n\t}\n\tmanifestDesc := manifest.Layers[0]\n\n\tsignatureBlobRef := c.getReferenceFromDescriptor(manifestDesc)\n\n\tsignatureBlobLayer, err := crane.PullLayer(signatureBlobRef)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tio, err := signatureBlobLayer.Uncompressed()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tSigBlobBuf := new(bytes.Buffer)\n\n\t_, err = SigBlobBuf.ReadFrom(io)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn SigBlobBuf.Bytes(), manifestDesc, nil\n}", "is_vulnerable": 0}
{"code": "func handleI18nCurrentLanguage(w http.ResponseWriter, _ *http.Request) {\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\tlog.Printf(\"config.Language is %s\", config.Language)\n\t_, err := fmt.Fprintf(w, \"%s\\n\", config.Language)\n\tif err != nil {\n\t\tmsg := fmt.Sprintf(\"Unable to write response json: %s\", err)\n\t\tlog.Println(msg)\n\t\thttp.Error(w, msg, http.StatusInternalServerError)\n\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "\tpred := func(limit int64, continueValue string) storage.SelectionPredicate {\n\t\treturn storage.SelectionPredicate{\n\t\t\tLimit:    limit,\n\t\t\tContinue: continueValue,\n\t\t\tLabel:    labels.Everything(),\n\t\t\tField:    fields.OneTermNotEqualSelector(\"metadata.name\", \"bar\"),\n\t\t\tGetAttrs: func(obj runtime.Object) (labels.Set, fields.Set, error) {\n\t\t\t\tpod := obj.(*example.Pod)\n\t\t\t\treturn nil, fields.Set{\"metadata.name\": pod.Name}, nil\n\t\t\t},\n\t\t}\n\t}\n\toptions := storage.ListOptions{\n\t\tResourceVersion: \"0\",\n\t\tPredicate:       pred(2, \"\"),\n\t\tRecursive:       true,\n\t}\n\tif err := store.GetList(ctx, \"/\", options, out); err != nil {\n\t\tt.Errorf(\"Unable to get initial list: %v\", err)\n\t}\n\tif len(out.Continue) == 0 {\n\t\tt.Errorf(\"No continuation token set\")\n\t}\n\tExpectNoDiff(t, \"incorrect first page\", []example.Pod{*preset[0].storedObj, *preset[2].storedObj}, out.Items)\n\tif validation != nil {\n\t\tvalidation(t, 2, 3)\n\t}\n\n\t// the rest of the test does not make sense if the previous call failed\n\tif t.Failed() {\n\t\treturn\n\t}\n\n\tcont := out.Continue\n\n\t// the second list call should try to get 2 more items from etcd\n\t// but since there is only one item left, that is all we should get with no continueValue\n\t// both read counters should be incremented for the singular calls they make in this case\n\tout = &example.PodList{}\n\toptions = storage.ListOptions{\n\t\tResourceVersion: \"0\",\n\t\tPredicate:       pred(2, cont),\n\t\tRecursive:       true,\n\t}\n\tif err := store.GetList(ctx, \"/\", options, out); err != nil {\n\t\tt.Errorf(\"Unable to get second page: %v\", err)\n\t}\n\tif len(out.Continue) != 0 {\n\t\tt.Errorf(\"Unexpected continuation token set\")\n\t}\n\tExpectNoDiff(t, \"incorrect second page\", []example.Pod{*preset[3].storedObj}, out.Items)\n\tif validation != nil {\n\t\tvalidation(t, 2, 1)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (fs *Quota) removeAll(path string) error {\n\treturn removeAll(fs, path)\n}", "is_vulnerable": 0}
{"code": "func (f *basicAuthorizer) AuthZReq(authZReq *authorization.Request) *authorization.Response {\n\n\tlogrus.Debugf(\"Received AuthZ request, method: '%s', url: '%s'\", authZReq.RequestMethod, authZReq.RequestURI)\n\n\taction := core.ParseRoute(authZReq.RequestMethod, authZReq.RequestURI)\n\n\tfor _, policy := range f.policies {\n\t\tfor _, user := range policy.Users {\n\t\t\tif user == authZReq.User {\n\t\t\t\tfor _, policyActionPattern := range policy.Actions {\n\t\t\t\t\tmatch, err := regexp.MatchString(policyActionPattern, action)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlogrus.Errorf(\"Failed to evaulate action %q against policy %q error %q\", action, policyActionPattern, err.Error())\n\t\t\t\t\t}\n\n\t\t\t\t\tif match {\n\n\t\t\t\t\t\tif policy.Readonly && authZReq.RequestMethod != \"GET\" {\n\t\t\t\t\t\t\treturn &authorization.Response{\n\t\t\t\t\t\t\t\tAllow: false,\n\t\t\t\t\t\t\t\tMsg:   fmt.Sprintf(\"action '%s' not allowed for user '%s' by readonly policy '%s'\", action, authZReq.User, policy.Name),\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn &authorization.Response{\n\t\t\t\t\t\t\tAllow: true,\n\t\t\t\t\t\t\tMsg:   fmt.Sprintf(\"action '%s' allowed for user '%s' by policy '%s'\", action, authZReq.User, policy.Name),\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn &authorization.Response{\n\t\t\t\t\tAllow: false,\n\t\t\t\t\tMsg:   fmt.Sprintf(\"action '%s' denied for user '%s' by policy '%s'\", action, authZReq.User, policy.Name),\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn &authorization.Response{\n\t\tAllow: false,\n\t\tMsg:   fmt.Sprintf(\"no policy applied (user: '%s' action: '%s')\", authZReq.User, action),\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e errorTranslateQuerier) LabelValues(name string, matchers ...*labels.Matcher) ([]string, storage.Warnings, error) {\n\tvalues, warnings, err := e.q.LabelValues(name, matchers...)\n\treturn values, warnings, TranslateToPromqlAPIError(err)\n}", "is_vulnerable": 1}
{"code": "\terr = hostNS.Do(func(_ ns.NetNS) error {\n\t\thostVeth, err = netlink.LinkByName(hostVethName)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to lookup %q in %q: %v\", hostVethName, hostNS.Path(), err)\n\t\t}\n\n\t\tif err = netlink.LinkSetUp(hostVeth); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to set %q up: %v\", hostVethName, err)\n\t\t}\n\n\t\t// we want to own the routes for this interface\n\t\t_, _ = sysctl.Sysctl(fmt.Sprintf(\"net/ipv6/conf/%s/accept_ra\", hostVethName), \"0\")\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func NewCachedCheckResolver(opts ...CachedCheckResolverOpt) *CachedCheckResolver {\n\tchecker := &CachedCheckResolver{\n\t\tmaxCacheSize: defaultMaxCacheSize,\n\t\tcacheTTL:     defaultCacheTTL,\n\t\tlogger:       logger.NewNoopLogger(),\n\t}\n\tchecker.delegate = checker\n\n\tfor _, opt := range opts {\n\t\topt(checker)\n\t}\n\n\tif checker.cache == nil {\n\t\tchecker.allocatedCache = true\n\t\tchecker.cache = ccache.New(\n\t\t\tccache.Configure[*CachedResolveCheckResponse]().MaxSize(checker.maxCacheSize),\n\t\t)\n\t}\n\n\treturn checker\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"detects_cycle_and_returns_cycle_detected_error\", func(t *testing.T) {\n\t\tcyclicalTuple := tuple.NewTupleKey(\"document:1\", \"viewer\", \"user:will\")\n\n\t\tvisitedPaths := make(map[string]struct{}, 0)\n\t\tvisitedPaths[tuple.TupleKeyToString(cyclicalTuple)] = struct{}{}\n\n\t\tresp, err := cycleDetectionCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:         uuid.NewString(),\n\t\t\tTupleKey:        cyclicalTuple,\n\t\t\tRequestMetadata: NewCheckRequestMetadata(defaultResolveNodeLimit),\n\t\t\tVisitedPaths:    visitedPaths,\n\t\t})\n\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, resp)\n\t\trequire.False(t, resp.GetAllowed())\n\t\trequire.True(t, resp.GetCycleDetected())\n\t\trequire.NotNil(t, resp.ResolutionMetadata)\n\t})", "is_vulnerable": 0}
{"code": "func (m *MapProtoTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: MapProtoTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: MapProtoTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableTimestamp == nil {\n\t\t\t\tm.NullableTimestamp = make(map[int32]*types.Timestamp)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Timestamp\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Timestamp{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableTimestamp[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Timestamp == nil {\n\t\t\t\tm.Timestamp = make(map[int32]types.Timestamp)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Timestamp{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Timestamp{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Timestamp[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDuration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDuration == nil {\n\t\t\t\tm.NullableDuration = make(map[int32]*types.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Duration\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Duration{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDuration[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Duration == nil {\n\t\t\t\tm.Duration = make(map[int32]types.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Duration{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Duration{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Duration[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDouble == nil {\n\t\t\t\tm.NullableDouble = make(map[int32]*types.DoubleValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.DoubleValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.DoubleValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDouble[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullDouble == nil {\n\t\t\t\tm.NonnullDouble = make(map[int32]types.DoubleValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.DoubleValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.DoubleValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullDouble[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableFloat == nil {\n\t\t\t\tm.NullableFloat = make(map[int32]*types.FloatValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.FloatValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.FloatValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableFloat[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullFloat == nil {\n\t\t\t\tm.NonnullFloat = make(map[int32]types.FloatValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.FloatValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.FloatValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullFloat[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt64 == nil {\n\t\t\t\tm.NullableInt64 = make(map[int32]*types.Int64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Int64Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt64[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt64 == nil {\n\t\t\t\tm.NonnullInt64 = make(map[int32]types.Int64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Int64Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt64[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt64 == nil {\n\t\t\t\tm.NullableUInt64 = make(map[int32]*types.UInt64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.UInt64Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt64[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt64 == nil {\n\t\t\t\tm.NonnullUInt64 = make(map[int32]types.UInt64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.UInt64Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt64[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt32 == nil {\n\t\t\t\tm.NullableInt32 = make(map[int32]*types.Int32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Int32Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt32[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt32 == nil {\n\t\t\t\tm.NonnullInt32 = make(map[int32]types.Int32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Int32Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt32[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt32 == nil {\n\t\t\t\tm.NullableUInt32 = make(map[int32]*types.UInt32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.UInt32Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt32[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt32 == nil {\n\t\t\t\tm.NonnullUInt32 = make(map[int32]types.UInt32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.UInt32Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt32[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBool == nil {\n\t\t\t\tm.NullableBool = make(map[int32]*types.BoolValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.BoolValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BoolValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBool[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBool == nil {\n\t\t\t\tm.NonnullBool = make(map[int32]types.BoolValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.BoolValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BoolValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBool[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableString == nil {\n\t\t\t\tm.NullableString = make(map[int32]*types.StringValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.StringValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.StringValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableString[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullString == nil {\n\t\t\t\tm.NonnullString = make(map[int32]types.StringValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.StringValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.StringValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullString[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBytes == nil {\n\t\t\t\tm.NullableBytes = make(map[int32]*types.BytesValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.BytesValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BytesValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBytes[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBytes == nil {\n\t\t\t\tm.NonnullBytes = make(map[int32]types.BytesValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.BytesValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BytesValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBytes[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (nvd NonceVerificationDecorator) AnteHandle(ctx sdk.Context, tx sdk.Tx, simulate bool, next sdk.AnteHandler) (newCtx sdk.Context, err error) {\n\tmsgEthTx, ok := tx.(evmtypes.MsgEthereumTx)\n\tif !ok {\n\t\treturn ctx, sdkerrors.Wrapf(sdkerrors.ErrUnknownRequest, \"invalid transaction type: %T\", tx)\n\t}\n\n\t// sender address should be in the tx cache from the previous AnteHandle call\n\taddress := msgEthTx.From()\n\tif address.Empty() {\n\t\tpanic(\"sender address cannot be empty\")\n\t}\n\n\tacc := nvd.ak.GetAccount(ctx, address)\n\tif acc == nil {\n\t\treturn ctx, sdkerrors.Wrapf(\n\t\t\tsdkerrors.ErrUnknownAddress,\n\t\t\t\"account %s (%s) is nil\", common.BytesToAddress(address.Bytes()), address,\n\t\t)\n\t}\n\n\tseq := acc.GetSequence()\n\t// if multiple transactions are submitted in succession with increasing nonces,\n\t// all will be rejected except the first, since the first needs to be included in a block\n\t// before the sequence increments\n\tif msgEthTx.Data.AccountNonce < seq {\n\t\treturn ctx, sdkerrors.Wrapf(\n\t\t\tsdkerrors.ErrInvalidSequence,\n\t\t\t\"invalid nonce; got %d, expected %d\", msgEthTx.Data.AccountNonce, seq,\n\t\t)\n\t}\n\n\treturn next(ctx, tx, simulate)\n}", "is_vulnerable": 1}
{"code": "func (r *CountedReader) Read(p []byte) (int, error) {\n\tif r.err != nil {\n\t\treturn 0, io.EOF\n\t}\n\n\tn, err := r.reader.Read(p)\n\tr.counter.Add(int64(n))\n\tr.err = err\n\n\tif err == io.EOF {\n\t\treturn n, io.EOF\n\t} else {\n\t\treturn n, nil\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tp.P(`func (m *`, ccTypeName, `) Unmarshal(dAtA []byte) error {`)\n\t\tp.In()\n\t\tif rfCount > 0 {\n\t\t\tp.P(`var hasFields [`, strconv.Itoa(1+(rfCount-1)/64), `]uint64`)\n\t\t}\n\t\tp.P(`l := len(dAtA)`)\n\t\tp.P(`iNdEx := 0`)\n\t\tp.P(`for iNdEx < l {`)\n\t\tp.In()\n\t\tp.P(`preIndex := iNdEx`)\n\t\tp.P(`var wire uint64`)\n\t\tp.decodeVarint(\"wire\", \"uint64\")\n\t\tp.P(`fieldNum := int32(wire >> 3)`)\n\t\tif len(message.Field) > 0 || !message.IsGroup() {\n\t\t\tp.P(`wireType := int(wire & 0x7)`)\n\t\t}\n\t\tif !message.IsGroup() {\n\t\t\tp.P(`if wireType == `, strconv.Itoa(proto.WireEndGroup), ` {`)\n\t\t\tp.In()\n\t\t\tp.P(`return `, fmtPkg.Use(), `.Errorf(\"proto: `+message.GetName()+`: wiretype end group for non-group\")`)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t}\n\t\tp.P(`if fieldNum <= 0 {`)\n\t\tp.In()\n\t\tp.P(`return `, fmtPkg.Use(), `.Errorf(\"proto: `+message.GetName()+`: illegal tag %d (wire type %d)\", fieldNum, wire)`)\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tp.P(`switch fieldNum {`)\n\t\tp.In()\n\t\tfor _, field := range message.Field {\n\t\t\tfieldname := p.GetFieldName(message, field)\n\t\t\terrFieldname := fieldname\n\t\t\tif field.OneofIndex != nil {\n\t\t\t\terrFieldname = p.GetOneOfFieldName(message, field)\n\t\t\t}\n\t\t\tpossiblyPacked := field.IsScalar() && field.IsRepeated()\n\t\t\tp.P(`case `, strconv.Itoa(int(field.GetNumber())), `:`)\n\t\t\tp.In()\n\t\t\twireType := field.WireType()\n\t\t\tif possiblyPacked {\n\t\t\t\tp.P(`if wireType == `, strconv.Itoa(wireType), `{`)\n\t\t\t\tp.In()\n\t\t\t\tp.field(file, message, field, fieldname, false)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`} else if wireType == `, strconv.Itoa(proto.WireBytes), `{`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`var packedLen int`)\n\t\t\t\tp.decodeVarint(\"packedLen\", \"int\")\n\t\t\t\tp.P(`if packedLen < 0 {`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`return ErrInvalidLength` + p.localName)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\t\t\t\tp.P(`postIndex := iNdEx + packedLen`)\n\t\t\t\tp.P(`if postIndex < 0 {`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`return ErrInvalidLength` + p.localName)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\t\t\t\tp.P(`if postIndex > l {`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`return `, p.ioPkg.Use(), `.ErrUnexpectedEOF`)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\n\t\t\t\tp.P(`var elementCount int`)\n\t\t\t\tswitch *field.Type {\n\t\t\t\tcase descriptor.FieldDescriptorProto_TYPE_DOUBLE, descriptor.FieldDescriptorProto_TYPE_FIXED64, descriptor.FieldDescriptorProto_TYPE_SFIXED64:\n\t\t\t\t\tp.P(`elementCount = packedLen/`, 8)\n\t\t\t\tcase descriptor.FieldDescriptorProto_TYPE_FLOAT, descriptor.FieldDescriptorProto_TYPE_FIXED32, descriptor.FieldDescriptorProto_TYPE_SFIXED32:\n\t\t\t\t\tp.P(`elementCount = packedLen/`, 4)\n\t\t\t\tcase descriptor.FieldDescriptorProto_TYPE_INT64, descriptor.FieldDescriptorProto_TYPE_UINT64, descriptor.FieldDescriptorProto_TYPE_INT32, descriptor.FieldDescriptorProto_TYPE_UINT32, descriptor.FieldDescriptorProto_TYPE_SINT32, descriptor.FieldDescriptorProto_TYPE_SINT64:\n\t\t\t\t\tp.P(`var count int`)\n\t\t\t\t\tp.P(`for _, integer := range dAtA[iNdEx:postIndex] {`)\n\t\t\t\t\tp.In()\n\t\t\t\t\tp.P(`if integer < 128 {`)\n\t\t\t\t\tp.In()\n\t\t\t\t\tp.P(`count++`)\n\t\t\t\t\tp.Out()\n\t\t\t\t\tp.P(`}`)\n\t\t\t\t\tp.Out()\n\t\t\t\t\tp.P(`}`)\n\t\t\t\t\tp.P(`elementCount = count`)\n\t\t\t\tcase descriptor.FieldDescriptorProto_TYPE_BOOL:\n\t\t\t\t\tp.P(`elementCount = packedLen`)\n\t\t\t\t}\n\t\t\t\tp.P(`if elementCount != 0 && len(m.`, fieldname, `) == 0 {`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`m.`, fieldname, ` = make([]`, p.noStarOrSliceType(message, field), `, 0, elementCount)`)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\n\t\t\t\tp.P(`for iNdEx < postIndex {`)\n\t\t\t\tp.In()\n\t\t\t\tp.field(file, message, field, fieldname, false)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`} else {`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`return ` + fmtPkg.Use() + `.Errorf(\"proto: wrong wireType = %d for field ` + errFieldname + `\", wireType)`)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\t\t\t} else {\n\t\t\t\tp.P(`if wireType != `, strconv.Itoa(wireType), `{`)\n\t\t\t\tp.In()\n\t\t\t\tp.P(`return ` + fmtPkg.Use() + `.Errorf(\"proto: wrong wireType = %d for field ` + errFieldname + `\", wireType)`)\n\t\t\t\tp.Out()\n\t\t\t\tp.P(`}`)\n\t\t\t\tp.field(file, message, field, fieldname, proto3)\n\t\t\t}\n\n\t\t\tif field.IsRequired() {\n\t\t\t\tfieldBit, ok := rfMap[field.GetNumber()]\n\t\t\t\tif !ok {\n\t\t\t\t\tpanic(\"field is required, but no bit registered\")\n\t\t\t\t}\n\t\t\t\tp.P(`hasFields[`, strconv.Itoa(int(fieldBit/64)), `] |= uint64(`, fmt.Sprintf(\"0x%08x\", uint64(1)<<(fieldBit%64)), `)`)\n\t\t\t}\n\t\t}\n\t\tp.Out()\n\t\tp.P(`default:`)\n\t\tp.In()\n\t\tif message.DescriptorProto.HasExtension() {\n\t\t\tc := []string{}\n\t\t\tfor _, erange := range message.GetExtensionRange() {\n\t\t\t\tc = append(c, `((fieldNum >= `+strconv.Itoa(int(erange.GetStart()))+\") && (fieldNum<\"+strconv.Itoa(int(erange.GetEnd()))+`))`)\n\t\t\t}\n\t\t\tp.P(`if `, strings.Join(c, \"||\"), `{`)\n\t\t\tp.In()\n\t\t\tp.P(`var sizeOfWire int`)\n\t\t\tp.P(`for {`)\n\t\t\tp.In()\n\t\t\tp.P(`sizeOfWire++`)\n\t\t\tp.P(`wire >>= 7`)\n\t\t\tp.P(`if wire == 0 {`)\n\t\t\tp.In()\n\t\t\tp.P(`break`)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t\tp.P(`iNdEx-=sizeOfWire`)\n\t\t\tp.P(`skippy, err := skip`, p.localName+`(dAtA[iNdEx:])`)\n\t\t\tp.P(`if err != nil {`)\n\t\t\tp.In()\n\t\t\tp.P(`return err`)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t\tp.P(`if (skippy < 0) || (iNdEx + skippy) < 0 {`)\n\t\t\tp.In()\n\t\t\tp.P(`return ErrInvalidLength`, p.localName)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t\tp.P(`if (iNdEx + skippy) > l {`)\n\t\t\tp.In()\n\t\t\tp.P(`return `, p.ioPkg.Use(), `.ErrUnexpectedEOF`)\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t\tp.P(protoPkg.Use(), `.AppendExtension(m, int32(fieldNum), dAtA[iNdEx:iNdEx+skippy])`)\n\t\t\tp.P(`iNdEx += skippy`)\n\t\t\tp.Out()\n\t\t\tp.P(`} else {`)\n\t\t\tp.In()\n\t\t}\n\t\tp.P(`iNdEx=preIndex`)\n\t\tp.P(`skippy, err := skip`, p.localName, `(dAtA[iNdEx:])`)\n\t\tp.P(`if err != nil {`)\n\t\tp.In()\n\t\tp.P(`return err`)\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tp.P(`if (skippy < 0) || (iNdEx + skippy) < 0 {`)\n\t\tp.In()\n\t\tp.P(`return ErrInvalidLength`, p.localName)\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tp.P(`if (iNdEx + skippy) > l {`)\n\t\tp.In()\n\t\tp.P(`return `, p.ioPkg.Use(), `.ErrUnexpectedEOF`)\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tif gogoproto.HasUnrecognized(file.FileDescriptorProto, message.DescriptorProto) {\n\t\t\tp.P(`m.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)`)\n\t\t}\n\t\tp.P(`iNdEx += skippy`)\n\t\tp.Out()\n\t\tif message.DescriptorProto.HasExtension() {\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t}\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tp.Out()\n\t\tp.P(`}`)\n\n\t\tfor _, field := range message.Field {\n\t\t\tif !field.IsRequired() {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfieldBit, ok := rfMap[field.GetNumber()]\n\t\t\tif !ok {\n\t\t\t\tpanic(\"field is required, but no bit registered\")\n\t\t\t}\n\n\t\t\tp.P(`if hasFields[`, strconv.Itoa(int(fieldBit/64)), `] & uint64(`, fmt.Sprintf(\"0x%08x\", uint64(1)<<(fieldBit%64)), `) == 0 {`)\n\t\t\tp.In()\n\t\t\tif !gogoproto.ImportsGoGoProto(file.FileDescriptorProto) {\n\t\t\t\tp.P(`return new(`, protoPkg.Use(), `.RequiredNotSetError)`)\n\t\t\t} else {\n\t\t\t\tp.P(`return `, protoPkg.Use(), `.NewRequiredNotSetError(\"`, field.GetName(), `\")`)\n\t\t\t}\n\t\t\tp.Out()\n\t\t\tp.P(`}`)\n\t\t}\n\t\tp.P()\n\t\tp.P(`if iNdEx > l {`)\n\t\tp.In()\n\t\tp.P(`return ` + p.ioPkg.Use() + `.ErrUnexpectedEOF`)\n\t\tp.Out()\n\t\tp.P(`}`)\n\t\tp.P(`return nil`)\n\t\tp.Out()\n\t\tp.P(`}`)", "is_vulnerable": 0}
{"code": "func (s *Server) getMetricBucket(path string) string {\n\troot := getURLRootPath(path)\n\tif s.metricsBuckets[root] == true {\n\t\treturn root\n\t}\n\treturn \"Invalid path\"\n}", "is_vulnerable": 0}
{"code": "func TestInstallRelease_DryRun_Lookup(t *testing.T) {\n\tis := assert.New(t)\n\tinstAction := installAction(t)\n\tinstAction.DryRun = true\n\tvals := map[string]interface{}{}\n\n\tmockChart := buildChart(withSampleTemplates())\n\tmockChart.Templates = append(mockChart.Templates, &chart.File{\n\t\tName: \"templates/lookup\",\n\t\tData: []byte(`goodbye: {{ lookup \"v1\" \"Namespace\" \"\" \"___\" }}`),\n\t})\n\n\tres, err := instAction.Run(mockChart, vals)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed install: %s\", err)\n\t}\n\n\tis.Contains(res.Manifest, \"goodbye: map[]\")\n}", "is_vulnerable": 0}
{"code": "func validateAndCreateWebhook(c *context.Context, orCtx *orgRepoContext, w *db.Webhook) {\n\tc.Data[\"Webhook\"] = w\n\n\tif c.HasError() {\n\t\tc.Success(orCtx.TmplNew)\n\t\treturn\n\t}\n\n\tfield, msg, ok := validateWebhook(c.User, c.Locale, w)\n\tif !ok {\n\t\tc.FormErr(field)\n\t\tc.RenderWithErr(msg, orCtx.TmplNew, nil)\n\t\treturn\n\t}\n\n\tif err := w.UpdateEvent(); err != nil {\n\t\tc.Error(err, \"update event\")\n\t\treturn\n\t} else if err := db.CreateWebhook(w); err != nil {\n\t\tc.Error(err, \"create webhook\")\n\t\treturn\n\t}\n\n\tc.Flash.Success(c.Tr(\"repo.settings.add_hook_success\"))\n\tc.Redirect(orCtx.Link + \"/settings/hooks\")\n}", "is_vulnerable": 1}
{"code": "func (h *DNSServer) ServeDNS(w dns.ResponseWriter, r *dns.Msg) {\n\tm := new(dns.Msg)\n\tm.SetReply(r)\n\tm.Authoritative = true\n\n\t// bail early for no queries.\n\tif len(r.Question) == 0 {\n\t\treturn\n\t}\n\trequestMsg := r.String()\n\n\tgologger.Debug().Msgf(\"New DNS request: %s\\n\", requestMsg)\n\tdomain := strings.ToLower(m.Question[0].Name)\n\n\tvar uniqueID, fullID string\n\n\t// Clould providers\n\tif r.Question[0].Qtype == dns.TypeTXT {\n\t\tm.Answer = append(m.Answer, &dns.TXT{Hdr: dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeTXT, Class: dns.ClassINET, Ttl: 0}, Txt: []string{h.TxtRecord}})\n\t} else if r.Question[0].Qtype == dns.TypeA || r.Question[0].Qtype == dns.TypeANY {\n\t\tnsHeader := dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeNS, Class: dns.ClassINET, Ttl: h.timeToLive}\n\n\t\thandleClould := func(ipAddress net.IP) {\n\t\t\tm.Answer = append(m.Answer, &dns.A{Hdr: dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: ipAddress})\n\n\t\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns1Domain})\n\t\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns2Domain})\n\t\t\tm.Extra = append(m.Extra, &dns.A{Hdr: dns.RR_Header{Name: h.ns1Domain, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: h.ipAddress})\n\t\t\tm.Extra = append(m.Extra, &dns.A{Hdr: dns.RR_Header{Name: h.ns2Domain, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: h.ipAddress})\n\t\t}\n\n\t\thandleAppWithCname := func(cname string, ips ...net.IP) {\n\t\t\tfqdnCname := dns.Fqdn(cname)\n\t\t\tm.Answer = append(m.Answer, &dns.CNAME{Hdr: dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeCNAME, Class: dns.ClassINET, Ttl: h.timeToLive}, Target: fqdnCname})\n\t\t\tfor _, ip := range ips {\n\t\t\t\tm.Answer = append(m.Answer, &dns.A{Hdr: dns.RR_Header{Name: fqdnCname, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: ip})\n\t\t\t}\n\n\t\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns1Domain})\n\t\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns2Domain})\n\t\t\tm.Extra = append(m.Extra, &dns.A{Hdr: dns.RR_Header{Name: h.ns1Domain, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: h.ipAddress})\n\t\t\tm.Extra = append(m.Extra, &dns.A{Hdr: dns.RR_Header{Name: h.ns2Domain, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: h.timeToLive}, A: h.ipAddress})\n\t\t}\n\n\t\t// check for clould providers\n\t\tswitch {\n\t\tcase strings.EqualFold(domain, \"aws\"+h.dotDomain):\n\t\t\thandleClould(net.ParseIP(\"169.254.169.254\"))\n\t\tcase strings.EqualFold(domain, \"alibaba\"+h.dotDomain):\n\t\t\thandleClould(net.ParseIP(\"100.100.100.200\"))\n\t\tcase strings.EqualFold(domain, \"app\"+h.dotDomain):\n\t\t\thandleAppWithCname(\"projectdiscovery.github.io\", net.ParseIP(\"185.199.108.153\"), net.ParseIP(\"185.199.110.153\"), net.ParseIP(\"185.199.111.153\"), net.ParseIP(\"185.199.108.153\"))\n\t\tdefault:\n\t\t\thandleClould(h.ipAddress)\n\t\t}\n\n\t} else if r.Question[0].Qtype == dns.TypeSOA {\n\t\tnsHdr := dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeSOA, Class: dns.ClassINET, Ttl: h.timeToLive}\n\t\tm.Answer = append(m.Answer, &dns.SOA{Hdr: nsHdr, Ns: h.ns1Domain, Mbox: h.options.Hostmaster})\n\t} else if r.Question[0].Qtype == dns.TypeMX {\n\t\tnsHdr := dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeMX, Class: dns.ClassINET, Ttl: h.timeToLive}\n\t\tm.Answer = append(m.Answer, &dns.MX{Hdr: nsHdr, Mx: h.mxDomain, Preference: 1})\n\t} else if r.Question[0].Qtype == dns.TypeNS {\n\t\tnsHeader := dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeNS, Class: dns.ClassINET, Ttl: h.timeToLive}\n\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns1Domain})\n\t\tm.Ns = append(m.Ns, &dns.NS{Hdr: nsHeader, Ns: h.ns2Domain})\n\t}\n\tresponseMsg := m.String()\n\n\t// if root-tld is enabled stores any interaction towards the main domain\n\tif h.options.RootTLD && strings.HasSuffix(domain, h.dotDomain) {\n\t\tcorrelationID := h.options.Domain\n\t\thost, _, _ := net.SplitHostPort(w.RemoteAddr().String())\n\t\tinteraction := &Interaction{\n\t\t\tProtocol:      \"dns\",\n\t\t\tUniqueID:      domain,\n\t\t\tFullId:        domain,\n\t\t\tQType:         toQType(r.Question[0].Qtype),\n\t\t\tRawRequest:    requestMsg,\n\t\t\tRawResponse:   responseMsg,\n\t\t\tRemoteAddress: host,\n\t\t\tTimestamp:     time.Now(),\n\t\t}\n\t\tbuffer := &bytes.Buffer{}\n\t\tif err := jsoniter.NewEncoder(buffer).Encode(interaction); err != nil {\n\t\t\tgologger.Warning().Msgf(\"Could not encode root tld dns interaction: %s\\n\", err)\n\t\t} else {\n\t\t\tgologger.Debug().Msgf(\"Root TLD DNS Interaction: \\n%s\\n\", buffer.String())\n\t\t\tif err := h.options.Storage.AddInteractionWithId(correlationID, buffer.Bytes()); err != nil {\n\t\t\t\tgologger.Warning().Msgf(\"Could not store dns interaction: %s\\n\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif strings.HasSuffix(domain, h.dotDomain) {\n\t\tparts := strings.Split(domain, \".\")\n\t\tfor i, part := range parts {\n\t\t\tif len(part) == 33 {\n\t\t\t\tuniqueID = part\n\t\t\t\tfullID = part\n\t\t\t\tif i+1 <= len(parts) {\n\t\t\t\t\tfullID = strings.Join(parts[:i+1], \".\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif uniqueID != \"\" {\n\t\tcorrelationID := uniqueID[:20]\n\t\thost, _, _ := net.SplitHostPort(w.RemoteAddr().String())\n\t\tinteraction := &Interaction{\n\t\t\tProtocol:      \"dns\",\n\t\t\tUniqueID:      uniqueID,\n\t\t\tFullId:        fullID,\n\t\t\tQType:         toQType(r.Question[0].Qtype),\n\t\t\tRawRequest:    requestMsg,\n\t\t\tRawResponse:   responseMsg,\n\t\t\tRemoteAddress: host,\n\t\t\tTimestamp:     time.Now(),\n\t\t}\n\t\tbuffer := &bytes.Buffer{}\n\t\tif err := jsoniter.NewEncoder(buffer).Encode(interaction); err != nil {\n\t\t\tgologger.Warning().Msgf(\"Could not encode dns interaction: %s\\n\", err)\n\t\t} else {\n\t\t\tgologger.Debug().Msgf(\"DNS Interaction: \\n%s\\n\", buffer.String())\n\t\t\tif err := h.options.Storage.AddInteraction(correlationID, buffer.Bytes()); err != nil {\n\t\t\t\tgologger.Warning().Msgf(\"Could not store dns interaction: %s\\n\", err)\n\t\t\t}\n\t\t}\n\t}\n\tif err := w.WriteMsg(m); err != nil {\n\t\tgologger.Warning().Msgf(\"Could not write DNS response: %s\\n\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func Samef(t TestingT, expected interface{}, actual interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Samef(t, expected, actual, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\t\tsrv := a.CreateSASL(\"XWHATEVER\", &net.TCPAddr{}, func([]string) error { return nil })", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.path, func(t *testing.T) {\n\t\t\tassert.Equal(t, test.wantVal, Clean(test.path))\n\t\t})", "is_vulnerable": 0}
{"code": "func (sch *scheme) Encapsulate(pk kem.PublicKey) (ct []byte, ss []byte, err error) {\n\tvar seed [EncapsulationSeedSize]byte\n\tcryptoRand.Read(seed[:])\n\treturn sch.EncapsulateDeterministically(pk, seed[:])\n}", "is_vulnerable": 1}
{"code": "func updateConfigFile(dir, owner, repo, version string) ([]string, error) {\n\tvar submodules []string\n\tfilename := filepath.Join(dir, \".gitmodules\")\n\tdata, err := os.ReadFile(filename)\n\n\tif err != nil {\n\t\treturn submodules, errors.Wrapf(err, \"failed to read gitmodules file %s\", filename)\n\t}\n\n\tcfg := config.NewModules()\n\terr = cfg.Unmarshal(data)\n\n\tfor _, submodule := range cfg.Submodules {\n\t\tif submodule.URL == fmt.Sprintf(\"https://github.com/%s/%s.git\", owner, repo) {\n\t\t\tsubmodules = append(submodules, submodule.Name)\n\t\t\tsubmodule.Branch = version\n\t\t}\n\t}\n\tinfo, err := os.Stat(filename)\n\n\toutput, err := cfg.Marshal()\n\treturn submodules, os.WriteFile(filename, output, info.Mode())\n\n}", "is_vulnerable": 0}
{"code": "func TestVerifyBlobCmdWithBundle(t *testing.T) {\n\tkeyless := newKeylessStack(t)\n\n\tt.Run(\"Normal verification\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\t// Sign blob with private key\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",       /*certRef*/ // Cert is fetched from bundle\n\t\t\tidentity, /*certEmail*/\n\t\t\tissuer,   /*certOidcIssuer*/\n\t\t\t\"\",       /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",       /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath, /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n\tt.Run(\"Mismatched cert/sig\", func(t *testing.T) {\n\t\t// This test ensures that the signature and cert at the top level in the LocalSignedPayload must be identical to the ones in the RekorBundle.\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\t\t_, _, leafPemCert2, signer2 := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tsig2, err := signer2.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert2, sig2)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",       /*certRef*/ // Cert is fetched from bundle\n\t\t\t\"\",       /*certEmail*/\n\t\t\t\"\",       /*certOidcIssuer*/\n\t\t\t\"\",       /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",       /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath, /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expecting err due to mismatched signatures, got nil\")\n\t\t}\n\t})\n\tt.Run(\"Expired cert\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\t// Sign blob with private key\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()-1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",       /*certRef*/ // Cert is fetched from bundle\n\t\t\t\"\",       /*certEmail*/\n\t\t\t\"\",       /*certOidcIssuer*/\n\t\t\t\"\",       /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",       /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath, /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err == nil {\n\t\t\tt.Fatal(\"expected error due to expired cert, received nil\")\n\t\t}\n\t})\n\tt.Run(\"Attestation\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\tstmt := `{\"_type\":\"https://in-toto.io/Statement/v0.1\",\"predicateType\":\"customFoo\",\"subject\":[{\"name\":\"subject\",\"digest\":{\"sha256\":\"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef\"}}],\"predicate\":{}}`\n\t\twrapped := dsse.WrapSigner(signer, ctypes.IntotoPayloadType)\n\t\tsignedPayload, err := wrapped.SignMessage(bytes.NewReader([]byte(stmt)), signatureoptions.WithContext(context.Background()))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\t// intoto sig = json-serialized dsse envelope\n\t\tsig := signedPayload\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, intoto.KIND, intoto.New().DefaultVersion(), signedPayload, leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, string(signedPayload), \"attestation.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",       /*certRef*/ // Cert is fetched from bundle\n\t\t\t\"\",       /*certEmail*/\n\t\t\t\"\",       /*certOidcIssuer*/\n\t\t\t\"\",       /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",       /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath, /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t})\n\tt.Run(\"Invalid blob signature\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\t// Sign blob with private key\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = []byte{'i', 'n', 'v', 'a', 'l', 'i', 'd'}\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",       /*certRef*/ // Cert is fetched from bundle\n\t\t\t\"\",       /*certEmail*/\n\t\t\t\"\",       /*certOidcIssuer*/\n\t\t\t\"\",       /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",       /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath, /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err == nil || !strings.Contains(err.Error(), \"unable to verify SET\") {\n\t\t\tt.Fatalf(\"expected error verifying SET, got %v\", err)\n\t\t}\n\t})\n\tt.Run(\"Mismatched certificate email\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\t// Sign blob with private key\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",                    /*certRef*/ // Cert is fetched from bundle\n\t\t\t\"invalid@example.com\", /*certEmail*/\n\t\t\tissuer,                /*certOidcIssuer*/\n\t\t\t\"\",                    /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",                    /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath,              /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err == nil || !strings.Contains(err.Error(), \"expected email not found in certificate\") {\n\t\t\tt.Fatalf(\"expected error with mismatched identity, got %v\", err)\n\t\t}\n\t})\n\tt.Run(\"Mismatched certificate issuer\", func(t *testing.T) {\n\t\tidentity := \"hello@foo.com\"\n\t\tissuer := \"issuer\"\n\t\tleafCert, _, leafPemCert, signer := keyless.genLeafCert(t, identity, issuer)\n\n\t\t// Create blob\n\t\tblob := \"someblob\"\n\n\t\t// Sign blob with private key\n\t\tsig, err := signer.SignMessage(bytes.NewReader([]byte(blob)))\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\t// Create bundle\n\t\tentry := genRekorEntry(t, hashedrekord.KIND, hashedrekord.New().DefaultVersion(), []byte(blob), leafPemCert, sig)\n\t\tb := createBundle(t, sig, leafPemCert, keyless.rekorLogID, leafCert.NotBefore.Unix()+1, entry)\n\t\tb.Bundle.SignedEntryTimestamp = keyless.rekorSignPayload(t, b.Bundle.Payload)\n\t\tbundlePath := writeBundleFile(t, keyless.td, b, \"bundle.json\")\n\t\tblobPath := writeBlobFile(t, keyless.td, blob, \"blob.txt\")\n\n\t\t// Verify command\n\t\terr = VerifyBlobCmd(context.Background(),\n\t\t\toptions.KeyOpts{BundlePath: bundlePath},\n\t\t\t\"\",        /*certRef*/ // Cert is fetched from bundle\n\t\t\tidentity,  /*certEmail*/\n\t\t\t\"invalid\", /*certOidcIssuer*/\n\t\t\t\"\",        /*certChain*/ // Chain is fetched from TUF/SIGSTORE_ROOT_FILE\n\t\t\t\"\",        /*sigRef*/    // Sig is fetched from bundle\n\t\t\tblobPath,  /*blobRef*/\n\t\t\t// GitHub identity flags start\n\t\t\t\"\", \"\", \"\", \"\", \"\",\n\t\t\t// GitHub identity flags end\n\t\t\tfalse /*enforceSCT*/)\n\t\tif err == nil || !strings.Contains(err.Error(), \"expected oidc issuer not found in certificate\") {\n\t\t\tt.Fatalf(\"expected error with mismatched issuer, got %v\", err)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func dockerDefaultCaps() []string {\n\treturn append(nomadDefaultCaps(), \"NET_RAW\")\n}", "is_vulnerable": 0}
{"code": "\t\tdb.StoreSession(store, r.URL.String(), func() {\n\t\t\tok = authenticationHandler(w, r)\n\t\t})", "is_vulnerable": 0}
{"code": "func TestUnmarshalConfig(t *testing.T) {\n\trawConfig := []byte(`\nissuer: http://127.0.0.1:5556/dex\nstorage:\n  type: postgres\n  config:\n    host: 10.0.0.1\n    port: 65432\n    maxOpenConns: 5\n    maxIdleConns: 3\n    connMaxLifetime: 30\n    connectionTimeout: 3\nweb:\n  https: 127.0.0.1:5556\n  tlsMinVersion: 1.3\n  tlsMaxVersion: 1.2\n\nfrontend:\n  dir: ./web\n  extra:\n    foo: bar\n\nstaticClients:\n- id: example-app\n  redirectURIs:\n  - 'http://127.0.0.1:5555/callback'\n  name: 'Example App'\n  secret: ZXhhbXBsZS1hcHAtc2VjcmV0\n\noauth2:\n  alwaysShowLoginScreen: true\n  grantTypes:\n  - refresh_token\n  - \"urn:ietf:params:oauth:grant-type:token-exchange\"\n\nconnectors:\n- type: mockCallback\n  id: mock\n  name: Example\n- type: oidc\n  id: google\n  name: Google\n  config:\n    issuer: https://accounts.google.com\n    clientID: foo\n    clientSecret: bar\n    redirectURI: http://127.0.0.1:5556/dex/callback/google\n\nenablePasswordDB: true\nstaticPasswords:\n- email: \"admin@example.com\"\n  # bcrypt hash of the string \"password\"\n  hash: \"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"\n  username: \"admin\"\n  userID: \"08a8684b-db88-4b73-90a9-3cd1661f5466\"\n- email: \"foo@example.com\"\n  # base64'd value of the same bcrypt hash above. We want to be able to parse both of these\n  hash: \"JDJhJDEwJDMzRU1UMGNWWVZsUHk2V0FNQ0xzY2VMWWpXaHVIcGJ6NXl1Wnh1L0dBRmowM0o5THl0anV5\"\n  username: \"foo\"\n  userID: \"41331323-6f44-45e6-b3b9-2c4b60c02be5\"\n\nexpiry:\n  signingKeys: \"7h\"\n  idTokens: \"25h\"\n  authRequests: \"25h\"\n  deviceRequests: \"10m\"\n\nlogger:\n  level: \"debug\"\n  format: \"json\"\n`)\n\n\twant := Config{\n\t\tIssuer: \"http://127.0.0.1:5556/dex\",\n\t\tStorage: Storage{\n\t\t\tType: \"postgres\",\n\t\t\tConfig: &sql.Postgres{\n\t\t\t\tNetworkDB: sql.NetworkDB{\n\t\t\t\t\tHost:              \"10.0.0.1\",\n\t\t\t\t\tPort:              65432,\n\t\t\t\t\tMaxOpenConns:      5,\n\t\t\t\t\tMaxIdleConns:      3,\n\t\t\t\t\tConnMaxLifetime:   30,\n\t\t\t\t\tConnectionTimeout: 3,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tWeb: Web{\n\t\t\tHTTPS:         \"127.0.0.1:5556\",\n\t\t\tTLSMinVersion: \"1.3\",\n\t\t\tTLSMaxVersion: \"1.2\",\n\t\t},\n\t\tFrontend: server.WebConfig{\n\t\t\tDir: \"./web\",\n\t\t\tExtra: map[string]string{\n\t\t\t\t\"foo\": \"bar\",\n\t\t\t},\n\t\t},\n\t\tStaticClients: []storage.Client{\n\t\t\t{\n\t\t\t\tID:     \"example-app\",\n\t\t\t\tSecret: \"ZXhhbXBsZS1hcHAtc2VjcmV0\",\n\t\t\t\tName:   \"Example App\",\n\t\t\t\tRedirectURIs: []string{\n\t\t\t\t\t\"http://127.0.0.1:5555/callback\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tOAuth2: OAuth2{\n\t\t\tAlwaysShowLoginScreen: true,\n\t\t\tGrantTypes: []string{\n\t\t\t\t\"refresh_token\",\n\t\t\t\t\"urn:ietf:params:oauth:grant-type:token-exchange\",\n\t\t\t},\n\t\t},\n\t\tStaticConnectors: []Connector{\n\t\t\t{\n\t\t\t\tType:   \"mockCallback\",\n\t\t\t\tID:     \"mock\",\n\t\t\t\tName:   \"Example\",\n\t\t\t\tConfig: &mock.CallbackConfig{},\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"oidc\",\n\t\t\t\tID:   \"google\",\n\t\t\t\tName: \"Google\",\n\t\t\t\tConfig: &oidc.Config{\n\t\t\t\t\tIssuer:       \"https://accounts.google.com\",\n\t\t\t\t\tClientID:     \"foo\",\n\t\t\t\t\tClientSecret: \"bar\",\n\t\t\t\t\tRedirectURI:  \"http://127.0.0.1:5556/dex/callback/google\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tEnablePasswordDB: true,\n\t\tStaticPasswords: []password{\n\t\t\t{\n\t\t\t\tEmail:    \"admin@example.com\",\n\t\t\t\tHash:     []byte(\"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"),\n\t\t\t\tUsername: \"admin\",\n\t\t\t\tUserID:   \"08a8684b-db88-4b73-90a9-3cd1661f5466\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tEmail:    \"foo@example.com\",\n\t\t\t\tHash:     []byte(\"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"),\n\t\t\t\tUsername: \"foo\",\n\t\t\t\tUserID:   \"41331323-6f44-45e6-b3b9-2c4b60c02be5\",\n\t\t\t},\n\t\t},\n\t\tExpiry: Expiry{\n\t\t\tSigningKeys:    \"7h\",\n\t\t\tIDTokens:       \"25h\",\n\t\t\tAuthRequests:   \"25h\",\n\t\t\tDeviceRequests: \"10m\",\n\t\t},\n\t\tLogger: Logger{\n\t\t\tLevel:  \"debug\",\n\t\t\tFormat: \"json\",\n\t\t},\n\t}\n\n\tvar c Config\n\tif err := yaml.Unmarshal(rawConfig, &c); err != nil {\n\t\tt.Fatalf(\"failed to decode config: %v\", err)\n\t}\n\tif diff := pretty.Compare(c, want); diff != \"\" {\n\t\tt.Errorf(\"got!=want: %s\", diff)\n\t}\n}\n\nfunc TestUnmarshalConfigWithEnvNoExpand(t *testing.T) {\n\t// If the env variable DEX_EXPAND_ENV is set and has a \"falsy\" value, os.ExpandEnv is disabled.\n\t// ParseBool: \"It accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False.\"\n\tcheckUnmarshalConfigWithEnv(t, \"0\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"f\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"F\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"FALSE\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"false\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"False\", false)\n\tos.Unsetenv(\"DEX_EXPAND_ENV\")\n}\n\nfunc TestUnmarshalConfigWithEnvExpand(t *testing.T) {\n\t// If the env variable DEX_EXPAND_ENV is unset or has a \"truthy\" or unknown value, os.ExpandEnv is enabled.\n\t// ParseBool: \"It accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False.\"\n\tcheckUnmarshalConfigWithEnv(t, \"1\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"t\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"T\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"TRUE\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"true\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"True\", true)\n\t// Values that can't be parsed as bool:\n\tcheckUnmarshalConfigWithEnv(t, \"UNSET\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"whatever - true is default\", true)\n\tos.Unsetenv(\"DEX_EXPAND_ENV\")\n}", "is_vulnerable": 0}
{"code": "\t\t\t\t\tm.HandleFunc(\"/start\", func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\t\t\ts, err := os.Executable()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlock.Lock()\n\t\t\t\t\t\tdefer lock.Unlock()\n\t\t\t\t\t\tcmd = exec.Command(\"/bin/sh\", \"-c\", s+\" tproxy \"+r.FormValue(\"args\"))\n\t\t\t\t\t\tlog.Println(s + \" tproxy \" + r.FormValue(\"args\"))\n\t\t\t\t\t\tdone := make(chan byte)\n\t\t\t\t\t\tdefer close(done)\n\t\t\t\t\t\terrch := make(chan error)\n\t\t\t\t\t\tgo func() {\n\t\t\t\t\t\t\tout, _ := cmd.CombinedOutput()\n\t\t\t\t\t\t\tselect {\n\t\t\t\t\t\t\tcase <-done:\n\t\t\t\t\t\t\t\tlog.Println(string(out))\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tselect {\n\t\t\t\t\t\t\t\tcase <-done:\n\t\t\t\t\t\t\t\t\tlog.Println(string(out))\n\t\t\t\t\t\t\t\tcase errch <- errors.New(string(out)):\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlock.Lock()\n\t\t\t\t\t\t\tcmd = nil\n\t\t\t\t\t\t\tlock.Unlock()\n\t\t\t\t\t\t}()\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase err := <-errch:\n\t\t\t\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\tcase <-time.After(6 * time.Second):\n\t\t\t\t\t\t\tw.Write([]byte(\"connected\"))\n\t\t\t\t\t\t}\n\t\t\t\t\t})", "is_vulnerable": 1}
{"code": "func TestV3AuthWithLeaseTimeToLive(t *testing.T) {\n\tintegration.BeforeTest(t)\n\tclus := integration.NewCluster(t, &integration.ClusterConfig{Size: 1})\n\tdefer clus.Terminate(t)\n\n\tusers := []user{\n\t\t{\n\t\t\tname:     \"user1\",\n\t\t\tpassword: \"user1-123\",\n\t\t\trole:     \"role1\",\n\t\t\tkey:      \"k1\",\n\t\t\tend:      \"k3\",\n\t\t},\n\t\t{\n\t\t\tname:     \"user2\",\n\t\t\tpassword: \"user2-123\",\n\t\t\trole:     \"role2\",\n\t\t\tkey:      \"k2\",\n\t\t\tend:      \"k4\",\n\t\t},\n\t}\n\tauthSetupUsers(t, integration.ToGRPC(clus.Client(0)).Auth, users)\n\n\tauthSetupRoot(t, integration.ToGRPC(clus.Client(0)).Auth)\n\n\tuser1c, cerr := integration.NewClient(t, clientv3.Config{Endpoints: clus.Client(0).Endpoints(), Username: \"user1\", Password: \"user1-123\"})\n\tif cerr != nil {\n\t\tt.Fatal(cerr)\n\t}\n\tdefer user1c.Close()\n\n\tuser2c, cerr := integration.NewClient(t, clientv3.Config{Endpoints: clus.Client(0).Endpoints(), Username: \"user2\", Password: \"user2-123\"})\n\tif cerr != nil {\n\t\tt.Fatal(cerr)\n\t}\n\tdefer user2c.Close()\n\n\tleaseResp, err := user1c.Grant(context.TODO(), 90)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tleaseID := leaseResp.ID\n\t_, err = user1c.Put(context.TODO(), \"k1\", \"val\", clientv3.WithLease(leaseID))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\t// k2 can be accessed from both user1 and user2\n\t_, err = user1c.Put(context.TODO(), \"k2\", \"val\", clientv3.WithLease(leaseID))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = user1c.TimeToLive(context.TODO(), leaseID)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = user2c.TimeToLive(context.TODO(), leaseID)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = user2c.TimeToLive(context.TODO(), leaseID, clientv3.WithAttachedKeys())\n\tif err == nil {\n\t\tt.Fatal(\"timetolive from user2 should be failed with permission denied\")\n\t}\n\n\trootc, cerr := integration.NewClient(t, clientv3.Config{Endpoints: clus.Client(0).Endpoints(), Username: \"root\", Password: \"123\"})\n\tif cerr != nil {\n\t\tt.Fatal(cerr)\n\t}\n\tdefer rootc.Close()\n\n\tif _, err := rootc.RoleRevokePermission(context.TODO(), \"role1\", \"k1\", \"k3\"); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t_, err = user1c.TimeToLive(context.TODO(), leaseID, clientv3.WithAttachedKeys())\n\tif err == nil {\n\t\tt.Fatal(\"timetolive from user2 should be failed with permission denied\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mt *MultiTenantServicePrincipalToken) PrimaryOAuthToken() string {\n\treturn mt.PrimaryToken.OAuthToken()\n}", "is_vulnerable": 0}
{"code": "func TestEmptyRequest(t *testing.T) {\n\t// Scenario: Ensures empty messages are discarded and an error is returned\n\t// back to the sender.\n\n\tnode1 := newTestNode(t)\n\tnode2 := newTestNode(t)\n\n\tnode2.srv.Stop()\n\tsvc := &cluster.Service{\n\t\tStepLogger: flogging.MustGetLogger(\"test\"),\n\t\tLogger:     flogging.MustGetLogger(\"test\"),\n\t\tStreamCountReporter: &cluster.StreamCountReporter{\n\t\t\tMetrics: cluster.NewMetrics(&disabled.Provider{}),\n\t\t},\n\t\tDispatcher: node2.c,\n\t}\n\tnode2.dispatcher = svc\n\n\t// Sleep to let the gRPC service be closed\n\ttime.Sleep(time.Second)\n\n\t// Resurrect the node with the new dispatcher\n\tnode2.resurrect()\n\n\tdefer node1.stop()\n\tdefer node2.stop()\n\n\tconfig := []cluster.RemoteNode{node1.nodeInfo, node2.nodeInfo}\n\tnode1.c.Configure(testChannel, config)\n\tnode2.c.Configure(testChannel, config)\n\n\tassertBiDiCommunication(t, node1, node2, testReq)\n\n\trm, err := node1.c.Remote(testChannel, node2.nodeInfo.ID)\n\trequire.NoError(t, err)\n\n\tstream, err := rm.NewStream(time.Second * 10)\n\trequire.NoError(t, err)\n\n\terr = stream.Send(&orderer.StepRequest{})\n\trequire.NoError(t, err)\n\n\t_, err = stream.Recv()\n\trequire.Error(t, err, \"message is neither a Submit nor a Consensus request\")\n}", "is_vulnerable": 0}
{"code": "func buildArmClient(config BackendConfig) (*ArmClient, error) {\n\tenv, err := buildArmEnvironment(config)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclient := ArmClient{\n\t\tenvironment:        *env,\n\t\tresourceGroupName:  config.ResourceGroupName,\n\t\tstorageAccountName: config.StorageAccountName,\n\t}\n\n\t// if we have an Access Key - we don't need the other clients\n\tif config.AccessKey != \"\" {\n\t\tclient.accessKey = config.AccessKey\n\t\treturn &client, nil\n\t}\n\n\t// likewise with a SAS token\n\tif config.SasToken != \"\" {\n\t\tclient.sasToken = config.SasToken\n\t\treturn &client, nil\n\t}\n\n\tbuilder := authentication.Builder{\n\t\tClientID:                      config.ClientID,\n\t\tClientSecret:                  config.ClientSecret,\n\t\tSubscriptionID:                config.SubscriptionID,\n\t\tTenantID:                      config.TenantID,\n\t\tCustomResourceManagerEndpoint: config.CustomResourceManagerEndpoint,\n\t\tEnvironment:                   config.Environment,\n\t\tMsiEndpoint:                   config.MsiEndpoint,\n\n\t\t// Feature Toggles\n\t\tSupportsAzureCliToken:          true,\n\t\tSupportsClientSecretAuth:       true,\n\t\tSupportsManagedServiceIdentity: config.UseMsi,\n\t\t// TODO: support for Client Certificate auth\n\t}\n\tarmConfig, err := builder.Build()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error building ARM Config: %+v\", err)\n\t}\n\n\toauthConfig, err := adal.NewOAuthConfig(env.ActiveDirectoryEndpoint, armConfig.TenantID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauth, err := armConfig.GetAuthorizationToken(oauthConfig, env.TokenAudience)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\taccountsClient := armStorage.NewAccountsClientWithBaseURI(env.ResourceManagerEndpoint, armConfig.SubscriptionID)\n\tclient.configureClient(&accountsClient.Client, auth)\n\tclient.storageAccountsClient = &accountsClient\n\n\tgroupsClient := resources.NewGroupsClientWithBaseURI(env.ResourceManagerEndpoint, armConfig.SubscriptionID)\n\tclient.configureClient(&groupsClient.Client, auth)\n\tclient.groupsClient = &groupsClient\n\n\treturn &client, nil\n}", "is_vulnerable": 1}
{"code": "\t\t\tgo func(fs *Filesystem) {\n\t\t\t\tif _, err := fs.updateCachedDiskUsage(); err != nil {\n\t\t\t\t\tlog.WithField(\"root\", fs.root).WithField(\"error\", err).Warn(\"failed to update fs disk usage from within routine\")\n\t\t\t\t}\n\t\t\t}(fs)", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\n\t\t\tf := NewFactory()\n\t\t\tv, command := config.Viperize(f.AddFlags)\n\t\t\terr := command.ParseFlags(test.flags)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tf.InitFromViper(v)\n\n\t\t\tparsedConfig := f.Builder.(*kafkaConfig.Configuration)\n\t\t\tf.Builder = &mockProducerBuilder{t: t, Configuration: *parsedConfig}\n\t\t\tlogbuf := &bytes.Buffer{}\n\t\t\tlogger := zap.New(zapcore.NewCore(\n\t\t\t\tzapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()),\n\t\t\t\tzapcore.AddSync(logbuf),\n\t\t\t\tzap.NewAtomicLevel(),\n\t\t\t))\n\t\t\terr = f.Initialize(metrics.NullFactory, logger)\n\t\t\trequire.NoError(t, err)\n\t\t\tlogger.Sync()\n\n\t\t\trequire.NotContains(t, logbuf.String(), \"SECRET\", \"log output must not contain password in clear text\")\n\t\t})", "is_vulnerable": 0}
{"code": "func (m *MockTokenRevocationStorage) RevokeRefreshToken(arg0 context.Context, arg1 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"RevokeRefreshToken\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessResponderMockRecorder) ToMap() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ToMap\", reflect.TypeOf((*MockAccessResponder)(nil).ToMap))\n}", "is_vulnerable": 0}
{"code": "func authorizedForPolicy(info user.Info, policy *extensions.PodSecurityPolicy, authz authorizer.Authorizer) bool {\n\t// if no info exists then the API is being hit via the unsecured port.  In this case\n\t// authorize the request.\n\tif info == nil {\n\t\treturn true\n\t}\n\tattr := buildAttributes(info, policy)\n\tallowed, _, _ := authz.Authorize(attr)\n\treturn allowed\n}", "is_vulnerable": 1}
{"code": "func TestParsePubSizeOverflow(t *testing.T) {\n\tc := dummyClient()\n\n\tpub := []byte(\"PUB foo 3333333333333333333333333333333333333333333333333333333333333333\\r\\n\")\n\tif err := c.parse(pub); err == nil {\n\t\tt.Fatalf(\"Expected an error\")\n\t}\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"ProjectDoesNotExist\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Spec.Project = \"none\"\n\t\tappServer := newTestAppServer(t, testApp)\n\n\t\tactive, err := appServer.GetApplicationSyncWindows(context.Background(), &application.ApplicationSyncWindowsQuery{Name: &testApp.Name})\n\t\tassert.Contains(t, err.Error(), \"not found\")\n\t\tassert.Nil(t, active)\n\t})", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetSystem(ctx context.Context, in *clientpb.GetSystemReq, opts ...grpc.CallOption) (*sliverpb.GetSystem, error) {\n\tout := new(sliverpb.GetSystem)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetSystem\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Context) EngineInfo() *EngineInfo {\n\treturn &EngineInfo{info: C.gpgme_ctx_get_engine_info(c.ctx)}\n}", "is_vulnerable": 1}
{"code": "func (m *RepStdTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: RepStdTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: RepStdTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableTimestamps = append(m.NullableTimestamps, new(time.Time))\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(m.NullableTimestamps[len(m.NullableTimestamps)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDurations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDurations = append(m.NullableDurations, new(time.Duration))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(m.NullableDurations[len(m.NullableDurations)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Timestamps = append(m.Timestamps, time.Time{})\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&(m.Timestamps[len(m.Timestamps)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Durations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Durations = append(m.Durations, time.Duration(0))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(&(m.Durations[len(m.Durations)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDouble = append(m.NullableDouble, new(float64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(m.NullableDouble[len(m.NullableDouble)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullDouble = append(m.NonnullDouble, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(&(m.NonnullDouble[len(m.NonnullDouble)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableFloat = append(m.NullableFloat, new(float32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(m.NullableFloat[len(m.NullableFloat)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullFloat = append(m.NonnullFloat, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(&(m.NonnullFloat[len(m.NonnullFloat)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt64 = append(m.NullableInt64, new(int64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(m.NullableInt64[len(m.NullableInt64)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt64 = append(m.NonnullInt64, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(&(m.NonnullInt64[len(m.NonnullInt64)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt64 = append(m.NullableUInt64, new(uint64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(m.NullableUInt64[len(m.NullableUInt64)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt64 = append(m.NonnullUInt64, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(&(m.NonnullUInt64[len(m.NonnullUInt64)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt32 = append(m.NullableInt32, new(int32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(m.NullableInt32[len(m.NullableInt32)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt32 = append(m.NonnullInt32, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(&(m.NonnullInt32[len(m.NonnullInt32)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt32 = append(m.NullableUInt32, new(uint32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(m.NullableUInt32[len(m.NullableUInt32)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt32 = append(m.NonnullUInt32, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(&(m.NonnullUInt32[len(m.NonnullUInt32)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBool = append(m.NullableBool, new(bool))\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(m.NullableBool[len(m.NullableBool)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBool = append(m.NonnullBool, false)\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(&(m.NonnullBool[len(m.NonnullBool)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableString = append(m.NullableString, new(string))\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(m.NullableString[len(m.NullableString)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullString = append(m.NonnullString, \"\")\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(&(m.NonnullString[len(m.NonnullString)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBytes = append(m.NullableBytes, new([]byte))\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(m.NullableBytes[len(m.NullableBytes)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBytes = append(m.NonnullBytes, []byte{})\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(&(m.NonnullBytes[len(m.NonnullBytes)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestAuditEvent_Validate(t *testing.T) {\n\ttests := map[string]struct {\n\t\tValue                *auditEvent\n\t\tIsErrorExpected      bool\n\t\tExpectedErrorMessage string\n\t}{\n\t\t\"nil\": {\n\t\t\tValue:                nil,\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: event is nil: invalid parameter\",\n\t\t},\n\t\t\"default\": {\n\t\t\tValue:                &auditEvent{},\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: missing ID: invalid parameter\",\n\t\t},\n\t\t\"id-empty\": {\n\t\t\tValue: &auditEvent{\n\t\t\t\tID:        \"\",\n\t\t\t\tVersion:   version,\n\t\t\t\tSubtype:   RequestType,\n\t\t\t\tTimestamp: time.Now(),\n\t\t\t\tData:      nil,\n\t\t\t},\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: missing ID: invalid parameter\",\n\t\t},\n\t\t\"version-fiddled\": {\n\t\t\tValue: &auditEvent{\n\t\t\t\tID:        \"audit_123\",\n\t\t\t\tVersion:   \"magic-v2\",\n\t\t\t\tSubtype:   RequestType,\n\t\t\t\tTimestamp: time.Now(),\n\t\t\t\tData:      nil,\n\t\t\t},\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: event version unsupported: invalid parameter\",\n\t\t},\n\t\t\"subtype-fiddled\": {\n\t\t\tValue: &auditEvent{\n\t\t\t\tID:        \"audit_123\",\n\t\t\t\tVersion:   version,\n\t\t\t\tSubtype:   subtype(\"moon\"),\n\t\t\t\tTimestamp: time.Now(),\n\t\t\t\tData:      nil,\n\t\t\t},\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: audit.(subtype).validate: 'moon' is not a valid event subtype: invalid parameter\",\n\t\t},\n\t\t\"default-time\": {\n\t\t\tValue: &auditEvent{\n\t\t\t\tID:        \"audit_123\",\n\t\t\t\tVersion:   version,\n\t\t\t\tSubtype:   ResponseType,\n\t\t\t\tTimestamp: time.Time{},\n\t\t\t\tData:      nil,\n\t\t\t},\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(auditEvent).validate: event timestamp cannot be the zero time instant: invalid parameter\",\n\t\t},\n\t\t\"valid\": {\n\t\t\tValue: &auditEvent{\n\t\t\t\tID:        \"audit_123\",\n\t\t\t\tVersion:   version,\n\t\t\t\tSubtype:   ResponseType,\n\t\t\t\tTimestamp: time.Now(),\n\t\t\t\tData:      nil,\n\t\t\t},\n\t\t\tIsErrorExpected: false,\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tname := name\n\t\ttc := tc\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\terr := tc.Value.validate()\n\t\t\tswitch {\n\t\t\tcase tc.IsErrorExpected:\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.EqualError(t, err, tc.ExpectedErrorMessage)\n\t\t\tdefault:\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "\tb.Run(name, func(b *testing.B) {\n\t\tb.ReportAllocs()\n\t\tfor i := 0; i < b.N; i++ {\n\t\t\tvmenv.Call(sender, destination, nil, gas, cfg.Value)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func TestDownloadTo(t *testing.T) {\n\t// Set up a fake repo with basic auth enabled\n\tsrv, err := repotest.NewTempServerWithCleanup(t, \"testdata/*.tgz*\")\n\tsrv.Stop()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tsrv.WithMiddleware(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tusername, password, ok := r.BasicAuth()\n\t\tif !ok || username != \"username\" || password != \"password\" {\n\t\t\tt.Errorf(\"Expected request to use basic auth and for username == 'username' and password == 'password', got '%v', '%s', '%s'\", ok, username, password)\n\t\t}\n\t}))\n\tsrv.Start()\n\tdefer srv.Stop()\n\tif err := srv.CreateIndex(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif err := srv.LinkIndices(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tc := ChartDownloader{\n\t\tOut:              os.Stderr,\n\t\tVerify:           VerifyAlways,\n\t\tKeyring:          \"testdata/helm-test-key.pub\",\n\t\tRepositoryConfig: repoConfig,\n\t\tRepositoryCache:  repoCache,\n\t\tGetters: getter.All(&cli.EnvSettings{\n\t\t\tRepositoryConfig: repoConfig,\n\t\t\tRepositoryCache:  repoCache,\n\t\t}),\n\t\tOptions: []getter.Option{\n\t\t\tgetter.WithBasicAuth(\"username\", \"password\"),\n\t\t\tgetter.WithPassCredentialsAll(false),\n\t\t},\n\t}\n\tcname := \"/signtest-0.1.0.tgz\"\n\tdest := srv.Root()\n\twhere, v, err := c.DownloadTo(srv.URL()+cname, \"\", dest)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif expect := filepath.Join(dest, cname); where != expect {\n\t\tt.Errorf(\"Expected download to %s, got %s\", expect, where)\n\t}\n\n\tif v.FileHash == \"\" {\n\t\tt.Error(\"File hash was empty, but verification is required.\")\n\t}\n\n\tif _, err := os.Stat(filepath.Join(dest, cname)); err != nil {\n\t\tt.Error(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewUsageClientWithBaseURI(baseURI string, subscriptionID string) UsageClient {\n\treturn original.NewUsageClientWithBaseURI(baseURI, subscriptionID)\n}", "is_vulnerable": 1}
{"code": "func (j *JuiceFSEngine) transformFuse(runtime *datav1alpha1.JuiceFSRuntime, dataset *datav1alpha1.Dataset, value *JuiceFS) (err error) {\n\tif len(dataset.Spec.Mounts) <= 0 {\n\t\treturn errors.New(\"do not assign mount point\")\n\t}\n\tmount := dataset.Spec.Mounts[0]\n\n\tvalue.Configs.Name = security.EscapeBashStr(mount.Name)\n\n\t// transform image\n\timage := runtime.Spec.Fuse.Image\n\ttag := runtime.Spec.Fuse.ImageTag\n\timagePullPolicy := runtime.Spec.Fuse.ImagePullPolicy\n\tvalue.Fuse.Image, value.Fuse.ImageTag, value.Fuse.ImagePullPolicy, err = j.parseJuiceFSImage(value.Edition, image, tag, imagePullPolicy)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// transform envs\n\tvalue.Fuse.Envs = runtime.Spec.Fuse.Env\n\n\t// transform options\n\tvar tiredStoreLevel *datav1alpha1.Level\n\tif len(runtime.Spec.TieredStore.Levels) != 0 {\n\t\ttiredStoreLevel = &runtime.Spec.TieredStore.Levels[0]\n\t}\n\toptionsFromDataset, err := j.genValue(mount, tiredStoreLevel, value, dataset.Spec.SharedOptions, dataset.Spec.SharedEncryptOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform format cmd\n\tj.genFormatCmd(value, runtime.Spec.Configs, optionsFromDataset)\n\n\t// transform quota cmd\n\terr = j.genQuotaCmd(value, mount)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform mount cmd & stat cmd\n\toptions, err := j.genMountOptions(mount, tiredStoreLevel)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Keep mount options in dataset still work, but it can be overwrited by fuse speicifed option\n\toptions = utils.UnionMapsWithOverride(optionsFromDataset, options)\n\tfor k, v := range runtime.Spec.Fuse.Options {\n\t\toptions[k] = v\n\t}\n\terr = j.genFuseMount(value, options)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform nodeSelector\n\tj.transformFuseNodeSelector(runtime, value)\n\tvalue.Fuse.Enabled = true\n\n\t// transform resource\n\terr = j.transformResourcesForFuse(runtime, value)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// transform volumes for fuse\n\terr = j.transformFuseVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform volumes for fuse\")\n\t\treturn err\n\t}\n\t// transform cache volumes for fuse\n\terr = j.transformFuseCacheVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform cache volumes for fuse\")\n\t\treturn err\n\t}\n\n\t// set critical fuse pod to avoid eviction\n\tvalue.Fuse.CriticalPod = common.CriticalFusePodEnabled()\n\n\t// parse fuse container network mode\n\tvalue.Fuse.HostNetwork = datav1alpha1.IsHostNetwork(runtime.Spec.Fuse.NetworkMode)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (reader *S3Reader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading s3Artifact from %s/%s\", reader.s3.Bucket.Name, reader.s3.Bucket.Key)\n\tobj, err := reader.client.GetObject(context.Background(), reader.s3.Bucket.Name, reader.s3.Bucket.Key, minio.GetObjectOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := obj.Close(); err != nil {\n\t\t\tfmt.Printf(\"failed to close object. err: %+v\", err)\n\t\t}\n\t}()\n\n\tb, err := ioutil.ReadAll(obj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, nil\n}", "is_vulnerable": 1}
{"code": "func (m *NinRepNonByteCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNonByteCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNonByteCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field1 = append(m.Field1, T{})\n\t\t\tif err := m.Field1[len(m.Field1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\treturn httpclient.NamedMiddlewareFunc(ForwardedCookiesMiddlewareName, func(opts httpclient.Options, next http.RoundTripper) http.RoundTripper {\n\t\treturn httpclient.RoundTripperFunc(func(req *http.Request) (*http.Response, error) {\n\t\t\tfor _, cookie := range forwardedCookies {\n\t\t\t\treq.AddCookie(cookie)\n\t\t\t}\n\t\t\tproxyutil.ClearCookieHeader(req, allowedCookies)\n\t\t\treturn next.RoundTrip(req)\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func isTemporaryNetworkError(err error) bool {\n\tif netErr, ok := err.(net.Error); !ok || (ok && netErr.Temporary()) {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tindex := sort.Search(len(res.hashes[i]), func(k int) bool {\n\t\t\t\t\tcmp := res.hashes[i][k].Big().Cmp(last)\n\t\t\t\t\tif cmp >= 0 {\n\t\t\t\t\t\tres.cont = false\n\t\t\t\t\t}\n\t\t\t\t\treturn cmp > 0\n\t\t\t\t})\n\t\t\t\tif index >= 0 {\n\t\t\t\t\t// cut off excess\n\t\t\t\t\tres.hashes[i] = res.hashes[i][:index]\n\t\t\t\t\tres.slots[i] = res.slots[i][:index]\n\t\t\t\t}\n\t\t\t\t// Forward the relevant storage chunk (even if created just now)\n\t\t\t\tif res.cont {\n\t\t\t\t\tres.subTask.Next = incHash(res.hashes[i][len(res.hashes[i])-1])\n\t\t\t\t} else {\n\t\t\t\t\tres.subTask.done = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// Iterate over all the complete contracts, reconstruct the trie nodes and\n\t\t// push them to disk. If the contract is chunked, the trie nodes will be\n\t\t// reconstructed later.\n\t\tslots += len(res.hashes[i])\n\n\t\tif i < len(res.hashes)-1 || res.subTask == nil {\n\t\t\t// no need to make local reassignment of account: this closure does not outlive the loop\n\t\t\toptions := trie.NewStackTrieOptions()\n\t\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\t\trawdb.WriteTrieNode(batch, account, path, hash, blob, s.scheme)\n\t\t\t})\n\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t// Configure the dangling node cleaner only in the context of the\n\t\t\t\t// path scheme. Deletion is forbidden in the hash scheme, as it can\n\t\t\t\t// disrupt state completeness.\n\t\t\t\t//\n\t\t\t\t// Notably, boundary nodes can be also kept because the whole storage\n\t\t\t\t// trie is complete.\n\t\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\t\ts.cleanPath(batch, account, path)\n\t\t\t\t})\n\t\t\t}\n\t\t\ttr := trie.NewStackTrie(options)\n\t\t\tfor j := 0; j < len(res.hashes[i]); j++ {\n\t\t\t\ttr.Update(res.hashes[i][j][:], res.slots[i][j])\n\t\t\t}\n\t\t\ttr.Commit()\n\t\t}\n\t\t// Persist the received storage segments. These flat state maybe\n\t\t// outdated during the sync, but it can be fixed later during the\n\t\t// snapshot generation.\n\t\tfor j := 0; j < len(res.hashes[i]); j++ {\n\t\t\trawdb.WriteStorageSnapshot(batch, account, res.hashes[i][j], res.slots[i][j])\n\n\t\t\t// If we're storing large contracts, generate the trie nodes\n\t\t\t// on the fly to not trash the gluing points\n\t\t\tif i == len(res.hashes)-1 && res.subTask != nil {\n\t\t\t\tres.subTask.genTrie.Update(res.hashes[i][j][:], res.slots[i][j])\n\t\t\t}\n\t\t}\n\t}", "is_vulnerable": 1}
{"code": "\tgo func() {\n\t\terr := http.ListenAndServe(ssc.ip+\":\"+ssc.port, nil)\n\t\tif err != nil {\n\t\t\tlog.Errorf(context.Background(),\"start blade server error, %v\", err)\n\t\t\t//log.Error(err, \"start blade server error\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}()", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn loadbalancing{r}\n}", "is_vulnerable": 1}
{"code": "\tvar refreshFunc adal.TokenRefresh = func(ctx context.Context, resource string) (*adal.Token, error) {\n\t\ttoken, err := obtainAuthorizationToken(resource, a.profile.subscriptionId)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tadalToken, err := token.ToADALToken()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn &adalToken, nil\n\t}", "is_vulnerable": 0}
{"code": "func (p *parser) markExprAsParenthesized(value js_ast.Expr, openParenLoc logger.Loc, isAsync bool) {\n\t// Don't lose comments due to parentheses. For example, we don't want to lose\n\t// the comment here:\n\t//\n\t//   ( /* comment */ (foo) );\n\t//\n\tif !isAsync {\n\t\tif comments, ok := p.exprComments[openParenLoc]; ok {\n\t\t\tdelete(p.exprComments, openParenLoc)\n\t\t\tp.exprComments[value.Loc] = append(comments, p.exprComments[value.Loc]...)\n\t\t}\n\t}\n\n\tswitch e := value.Data.(type) {\n\tcase *js_ast.EArray:\n\t\te.IsParenthesized = true\n\tcase *js_ast.EObject:\n\t\te.IsParenthesized = true\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestUnmarshallToEmbeddedNoData(t *testing.T) {\n\tdata := map[string][]string{\n\t\t\"F3\": {\"raw a\"},\n\t}\n\n\ts := &S24e{}\n\n\tdecoder := NewDecoder()\n\terr := decoder.Decode(s, data);\n\t\n\texpectedErr := `schema: invalid path \"F3\"`\n\tif err.Error() != expectedErr {\n\t\tt.Fatalf(\"got %q, want %q\", err, expectedErr)\n\t}\n}", "is_vulnerable": 1}
{"code": "func tryConnectMySQL(dsn string) (*sql.DB, error) {\n\tdriverName := \"mysql\"\n\tfailpoint.Inject(\"MockMySQLDriver\", func(val failpoint.Value) {\n\t\tdriverName = val.(string)\n\t})\n\tdb, err := sql.Open(driverName, dsn)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\tif err = db.Ping(); err != nil {\n\t\t_ = db.Close()\n\t\treturn nil, errors.Trace(err)\n\t}\n\treturn db, nil\n}", "is_vulnerable": 1}
{"code": "func ValidMethod(method string) bool {\n\treturn methodsRegex.MatchString(method)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Upload(ctx context.Context, in *sliverpb.UploadReq, opts ...grpc.CallOption) (*sliverpb.Upload, error) {\n\tout := new(sliverpb.Upload)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Upload\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (pt *pollingTrackerBase) updateErrorFromResponse() {\n\tvar err error\n\tif pt.resp.ContentLength != 0 {\n\t\ttype respErr struct {\n\t\t\tServiceError *ServiceError `json:\"error\"`\n\t\t}\n\t\tre := respErr{}\n\t\tdefer pt.resp.Body.Close()\n\t\tvar b []byte\n\t\tif b, err = ioutil.ReadAll(pt.resp.Body); err != nil {\n\t\t\tgoto Default\n\t\t}\n\t\tif err = json.Unmarshal(b, &re); err != nil {\n\t\t\tgoto Default\n\t\t}\n\t\t// unmarshalling the error didn't yield anything, try unwrapped error\n\t\tif re.ServiceError == nil {\n\t\t\terr = json.Unmarshal(b, &re.ServiceError)\n\t\t\tif err != nil {\n\t\t\t\tgoto Default\n\t\t\t}\n\t\t}\n\t\t// the unmarshaller will ensure re.ServiceError is non-nil\n\t\t// even if there was no content unmarshalled so check the code.\n\t\tif re.ServiceError.Code != \"\" {\n\t\t\tpt.Err = re.ServiceError\n\t\t\treturn\n\t\t}\n\t}\nDefault:\n\tse := &ServiceError{\n\t\tCode:    pt.pollingStatus(),\n\t\tMessage: \"The async operation failed.\",\n\t}\n\tif err != nil {\n\t\tse.InnerError = make(map[string]interface{})\n\t\tse.InnerError[\"unmarshalError\"] = err.Error()\n\t}\n\t// stick the response body into the error object in hopes\n\t// it contains something useful to help diagnose the failure.\n\tif len(pt.rawBody) > 0 {\n\t\tse.AdditionalInfo = []map[string]interface{}{\n\t\t\tpt.rawBody,\n\t\t}\n\t}\n\tpt.Err = se\n}", "is_vulnerable": 1}
{"code": "func (t *TelegramHandler) MessageHandle(ctx context.Context, bot *telegram.Bot, message telegram.Message, attachments []telegram.Attachment) error {\n\treply, err := bot.SendReplyMessage(ctx, message.Chat.ID, message.MessageID, workingMessage)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to SendReplyMessage\")\n\t}\n\n\tmessageSenderID := strconv.FormatInt(message.From.ID, 10)\n\tvar creatorID int32\n\tuserSettingList, err := t.store.ListUserSettings(ctx, &store.FindUserSetting{\n\t\tKey: storepb.UserSettingKey_USER_SETTING_TELEGRAM_USER_ID,\n\t})\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to find userSettingList\")\n\t}\n\tfor _, userSetting := range userSettingList {\n\t\tif userSetting.GetTelegramUserId() == messageSenderID {\n\t\t\tcreatorID = userSetting.UserId\n\t\t}\n\t}\n\n\t// If creatorID is not found, ask the user to set the telegram userid in UserSetting of memos.\n\tif creatorID == 0 {\n\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Please set your telegram userid %d in UserSetting of memos\", message.From.ID), nil)\n\t\treturn err\n\t}\n\n\tcreate := &store.Memo{\n\t\tUID:        shortuuid.New(),\n\t\tCreatorID:  creatorID,\n\t\tVisibility: store.Private,\n\t}\n\tif message.Text != nil {\n\t\tcreate.Content = convertToMarkdown(*message.Text, message.Entities)\n\t}\n\tif message.Caption != nil {\n\t\tcreate.Content = convertToMarkdown(*message.Caption, message.CaptionEntities)\n\t}\n\tif message.ForwardFromChat != nil {\n\t\tcreate.Content += fmt.Sprintf(\"\\n\\n[Message link](%s)\", message.GetMessageLink())\n\t}\n\tmemoMessage, err := t.store.CreateMemo(ctx, create)\n\tif err != nil {\n\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to CreateMemo: %s\", err), nil)\n\t\treturn err\n\t}\n\n\t// Dynamically upsert tags from memo content.\n\tnodes, err := parser.Parse(tokenizer.Tokenize(create.Content))\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Failed to parse content\")\n\t}\n\ttags := []string{}\n\tapiv2.TraverseASTNodes(nodes, func(node ast.Node) {\n\t\tif tagNode, ok := node.(*ast.Tag); ok {\n\t\t\ttag := tagNode.Content\n\t\t\tif !slices.Contains(tags, tag) {\n\t\t\t\ttags = append(tags, tag)\n\t\t\t}\n\t\t}\n\t})\n\tfor _, tag := range tags {\n\t\t_, err := t.store.UpsertTag(ctx, &store.Tag{\n\t\t\tName:      tag,\n\t\t\tCreatorID: creatorID,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"Failed to upsert tag\")\n\t\t}\n\t}\n\n\t// Create memo related resources.\n\tfor _, attachment := range attachments {\n\t\t// Fill the common field of create\n\t\tcreate := store.Resource{\n\t\t\tUID:       shortuuid.New(),\n\t\t\tCreatorID: creatorID,\n\t\t\tFilename:  filepath.Base(attachment.FileName),\n\t\t\tType:      attachment.GetMimeType(),\n\t\t\tSize:      attachment.FileSize,\n\t\t\tMemoID:    &memoMessage.ID,\n\t\t}\n\n\t\terr := apiv1.SaveResourceBlob(ctx, t.store, &create, bytes.NewReader(attachment.Data))\n\t\tif err != nil {\n\t\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to SaveResourceBlob: %s\", err), nil)\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = t.store.CreateResource(ctx, &create)\n\t\tif err != nil {\n\t\t\t_, err := bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Failed to CreateResource: %s\", err), nil)\n\t\t\treturn err\n\t\t}\n\t}\n\n\tkeyboard := generateKeyboardForMemoID(memoMessage.ID)\n\t_, err = bot.EditMessage(ctx, message.Chat.ID, reply.MessageID, fmt.Sprintf(\"Saved as %s Memo %d\", memoMessage.Visibility, memoMessage.ID), keyboard)\n\t_ = t.dispatchMemoRelatedWebhook(ctx, *memoMessage, \"memos.memo.created\")\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (src *NoData) Encode(dst []byte) []byte {\n\treturn append(dst, 'n', 0, 0, 0, 4)\n}", "is_vulnerable": 1}
{"code": "func (m *NestedDefinition_NestedMessage) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMessage: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMessage: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NestedField1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.NestedField1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NNM\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NNM == nil {\n\t\t\t\tm.NNM = &NestedDefinition_NestedMessage_NestedNestedMsg{}\n\t\t\t}\n\t\t\tif err := m.NNM.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (this *Stats) GoString() string {\n\tif this == nil {\n\t\treturn \"nil\"\n\t}\n\ts := make([]string, 0, 5)\n\ts = append(s, \"&stats.Stats{\")\n\ts = append(s, \"WallTime: \"+fmt.Sprintf(\"%#v\", this.WallTime)+\",\\n\")\n\ts = append(s, \"}\")\n\treturn strings.Join(s, \"\")\n}", "is_vulnerable": 1}
{"code": "func RunTestListWithoutPaging(ctx context.Context, t *testing.T, store storage.Interface) {\n\tdefer featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.RemainingItemCount, true)()\n\n\t_, preset, err := seedMultiLevelData(ctx, store)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tgetAttrs := func(obj runtime.Object) (labels.Set, fields.Set, error) {\n\t\tpod := obj.(*example.Pod)\n\t\treturn nil, fields.Set{\"metadata.name\": pod.Name}, nil\n\t}\n\n\ttests := []struct {\n\t\tname                       string\n\t\tdisablePaging              bool\n\t\trv                         string\n\t\trvMatch                    metav1.ResourceVersionMatch\n\t\tprefix                     string\n\t\tpred                       storage.SelectionPredicate\n\t\texpectedOut                []*example.Pod\n\t\texpectContinue             bool\n\t\texpectedRemainingItemCount *int64\n\t\texpectError                bool\n\t}{\n\t\t{\n\t\t\tname:          \"test List with limit when paging disabled\",\n\t\t\tdisablePaging: true,\n\t\t\tprefix:        \"/second/\",\n\t\t\tpred: storage.SelectionPredicate{\n\t\t\t\tLabel: labels.Everything(),\n\t\t\t\tField: fields.Everything(),\n\t\t\t\tLimit: 1,\n\t\t\t},\n\t\t\texpectedOut:    []*example.Pod{preset[1], preset[2]},\n\t\t\texpectContinue: false,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif tt.pred.GetAttrs == nil {\n\t\t\t\ttt.pred.GetAttrs = getAttrs\n\t\t\t}\n\n\t\t\tout := &example.PodList{}\n\t\t\tstorageOpts := storage.ListOptions{\n\t\t\t\tResourceVersion:      tt.rv,\n\t\t\t\tResourceVersionMatch: tt.rvMatch,\n\t\t\t\tPredicate:            tt.pred,\n\t\t\t\tRecursive:            true,\n\t\t\t}\n\n\t\t\tif err := store.GetList(ctx, tt.prefix, storageOpts, out); err != nil {\n\t\t\t\tt.Fatalf(\"GetList failed: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif (len(out.Continue) > 0) != tt.expectContinue {\n\t\t\t\tt.Errorf(\"unexpected continue token: %q\", out.Continue)\n\t\t\t}\n\n\t\t\tif len(tt.expectedOut) != len(out.Items) {\n\t\t\t\tt.Fatalf(\"length of list want=%d, got=%d\", len(tt.expectedOut), len(out.Items))\n\t\t\t}\n\t\t\tif diff := cmp.Diff(tt.expectedRemainingItemCount, out.ListMeta.GetRemainingItemCount()); diff != \"\" {\n\t\t\t\tt.Errorf(\"incorrect remainingItemCount: %s\", diff)\n\t\t\t}\n\t\t\tfor j, wantPod := range tt.expectedOut {\n\t\t\t\tgetPod := &out.Items[j]\n\t\t\t\tExpectNoDiff(t, fmt.Sprintf(\"%s: incorrect pod\", tt.name), wantPod, getPod)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestAccessLog(t *testing.T) {\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {}))\n\n\tt.Cleanup(func() { server.Close() })\n\n\ttestCases := []struct {\n\t\tdesc              string\n\t\troutersConfig     map[string]*dynamic.Router\n\t\tserviceConfig     map[string]*dynamic.Service\n\t\tmiddlewaresConfig map[string]*dynamic.Middleware\n\t\tentryPoints       []string\n\t\texpected          string\n\t}{\n\t\t{\n\t\t\tdesc: \"apply routerName in accesslog (first match)\",\n\t\t\troutersConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: server.URL,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tentryPoints: []string{\"web\"},\n\t\t\texpected:    \"foo\",\n\t\t},\n\t\t{\n\t\t\tdesc: \"apply routerName in accesslog (second match)\",\n\t\t\troutersConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: server.URL,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tentryPoints: []string{\"web\"},\n\t\t\texpected:    \"bar\",\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\t\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\t\t\tServices:    test.serviceConfig,\n\t\t\t\t\tRouters:     test.routersConfig,\n\t\t\t\t\tMiddlewares: test.middlewaresConfig,\n\t\t\t\t},\n\t\t\t})\n\n\t\t\troundTripperManager := service.NewRoundTripperManager()\n\t\t\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\t\t\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\t\t\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\t\t\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\t\t\ttlsManager := tls.NewManager()\n\n\t\t\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry(), tlsManager)\n\n\t\t\thandlers := routerManager.BuildHandlers(context.Background(), test.entryPoints, false)\n\n\t\t\tw := httptest.NewRecorder()\n\t\t\treq := testhelpers.MustNewRequest(http.MethodGet, \"http://foo.bar/\", nil)\n\n\t\t\taccesslogger, err := accesslog.NewHandler(&types.AccessLog{\n\t\t\t\tFormat: \"json\",\n\t\t\t})\n\t\t\trequire.NoError(t, err)\n\n\t\t\treqHost := requestdecorator.New(nil)\n\n\t\t\tchain := alice.New()\n\t\t\tchain = chain.Append(capture.Wrap)\n\t\t\tchain = chain.Append(accesslog.WrapHandler(accesslogger))\n\t\t\thandler, err := chain.Then(http.HandlerFunc(func(rw http.ResponseWriter, req *http.Request) {\n\t\t\t\treqHost.ServeHTTP(w, req, handlers[\"web\"].ServeHTTP)\n\n\t\t\t\tdata := accesslog.GetLogData(req)\n\t\t\t\trequire.NotNil(t, data)\n\n\t\t\t\tassert.Equal(t, test.expected, data.Core[accesslog.RouterName])\n\t\t\t}))\n\t\t\trequire.NoError(t, err)\n\n\t\t\thandler.ServeHTTP(w, req)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestArtifactUploadBlob(t *testing.T) {\n\tassert := assert.New(t)\n\n\tvar memfs = fstest.MapFS(map[string]*fstest.MapFile{})\n\n\trouter := httprouter.New()\n\tuploads(router, \"artifact/server/path\", writeMapFS{memfs})\n\n\treq, _ := http.NewRequest(\"PUT\", \"http://localhost/upload/1?itemPath=some/file\", strings.NewReader(\"content\"))\n\trr := httptest.NewRecorder()\n\n\trouter.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tassert.Fail(\"Wrong status\")\n\t}\n\n\tresponse := ResponseMessage{}\n\terr := json.Unmarshal(rr.Body.Bytes(), &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tassert.Equal(\"success\", response.Message)\n\tassert.Equal(\"content\", string(memfs[\"artifact/server/path/1/some/file\"].Data))\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"terminal alloc should be denied\", func(t *testing.T) {\n\t\t_, _, err = srv.staticEndpoints.Variables.handleMixedAuthEndpoint(\n\t\t\tstructs.QueryOptions{AuthToken: idToken, Namespace: ns}, acl.PolicyList,\n\t\t\tfmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID))\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t})", "is_vulnerable": 0}
{"code": "func desiredLoadBalancerService(ci *operatorv1.IngressController, deploymentRef metav1.OwnerReference, platform *configv1.PlatformStatus, proxyNeeded bool) (bool, *corev1.Service, error) {\n\tif ci.Status.EndpointPublishingStrategy.Type != operatorv1.LoadBalancerServiceStrategyType {\n\t\treturn false, nil, nil\n\t}\n\tservice := manifests.LoadBalancerService()\n\n\tname := controller.LoadBalancerServiceName(ci)\n\n\tservice.Namespace = name.Namespace\n\tservice.Name = name.Name\n\n\tif service.Labels == nil {\n\t\tservice.Labels = map[string]string{}\n\t}\n\tservice.Labels[\"router\"] = name.Name\n\tservice.Labels[manifests.OwningIngressControllerLabel] = ci.Name\n\n\tservice.Spec.Selector = controller.IngressControllerDeploymentPodSelector(ci).MatchLabels\n\n\tisInternal := ci.Status.EndpointPublishingStrategy.LoadBalancer != nil && ci.Status.EndpointPublishingStrategy.LoadBalancer.Scope == operatorv1.InternalLoadBalancer\n\n\tif service.Annotations == nil {\n\t\tservice.Annotations = map[string]string{}\n\t}\n\n\tif proxyNeeded {\n\t\tservice.Annotations[awsLBProxyProtocolAnnotation] = \"*\"\n\t}\n\n\tif platform != nil {\n\t\tif isInternal {\n\t\t\tannotation := InternalLBAnnotations[platform.Type]\n\t\t\tfor name, value := range annotation {\n\t\t\t\tservice.Annotations[name] = value\n\t\t\t}\n\t\t}\n\t\tswitch platform.Type {\n\t\tcase configv1.AWSPlatformType:\n\t\t\tif ci.Status.EndpointPublishingStrategy.LoadBalancer != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.Type == operatorv1.AWSLoadBalancerProvider &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.AWS != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.AWS.Type == operatorv1.AWSNetworkLoadBalancer {\n\t\t\t\tservice.Annotations[AWSLBTypeAnnotation] = AWSNLBAnnotation\n\t\t\t}\n\t\t\t// Set the load balancer for AWS to be as aggressive as Azure (2 fail @ 5s interval, 2 healthy)\n\t\t\tservice.Annotations[awsLBHealthCheckIntervalAnnotation] = awsLBHealthCheckIntervalDefault\n\t\t\tservice.Annotations[awsLBHealthCheckTimeoutAnnotation] = awsLBHealthCheckTimeoutDefault\n\t\t\tservice.Annotations[awsLBHealthCheckUnhealthyThresholdAnnotation] = awsLBHealthCheckUnhealthyThresholdDefault\n\t\t\tservice.Annotations[awsLBHealthCheckHealthyThresholdAnnotation] = awsLBHealthCheckHealthyThresholdDefault\n\t\tcase configv1.IBMCloudPlatformType:\n\t\t\tif !isInternal {\n\t\t\t\tservice.Annotations[iksLBScopeAnnotation] = iksLBScopePublic\n\t\t\t}\n\t\t}\n\t\t// Azure load balancers are not customizable and are set to (2 fail @ 5s interval, 2 healthy)\n\t\t// GCP load balancers are not customizable and are set to (3 fail @ 8s interval, 1 healthy)\n\t}\n\n\tservice.SetOwnerReferences([]metav1.OwnerReference{deploymentRef})\n\tservice.Finalizers = []string{manifests.LoadBalancerServiceFinalizer}\n\treturn true, service, nil\n}", "is_vulnerable": 0}
{"code": "\t\t\t\teval:    func(ms *runtime.MemStats) float64 { return float64(ms.Sys) },\n\t\t\t\tvalType: GaugeValue,\n\t\t\t}, {", "is_vulnerable": 1}
{"code": "func (e Engine) initFunMap(t *template.Template, referenceTpls map[string]renderable) {\n\tfuncMap := funcMap()\n\tincludedNames := make(map[string]int)\n\n\t// Add the 'include' function here so we can close over t.\n\tfuncMap[\"include\"] = func(name string, data interface{}) (string, error) {\n\t\tvar buf strings.Builder\n\t\tif v, ok := includedNames[name]; ok {\n\t\t\tif v > recursionMaxNums {\n\t\t\t\treturn \"\", errors.Wrapf(fmt.Errorf(\"unable to execute template\"), \"rendering template has a nested reference name: %s\", name)\n\t\t\t}\n\t\t\tincludedNames[name]++\n\t\t} else {\n\t\t\tincludedNames[name] = 1\n\t\t}\n\t\terr := t.ExecuteTemplate(&buf, name, data)\n\t\tincludedNames[name]--\n\t\treturn buf.String(), err\n\t}\n\n\t// Add the 'tpl' function here\n\tfuncMap[\"tpl\"] = func(tpl string, vals chartutil.Values) (string, error) {\n\t\tbasePath, err := vals.PathValue(\"Template.BasePath\")\n\t\tif err != nil {\n\t\t\treturn \"\", errors.Wrapf(err, \"cannot retrieve Template.Basepath from values inside tpl function: %s\", tpl)\n\t\t}\n\n\t\ttemplateName, err := vals.PathValue(\"Template.Name\")\n\t\tif err != nil {\n\t\t\treturn \"\", errors.Wrapf(err, \"cannot retrieve Template.Name from values inside tpl function: %s\", tpl)\n\t\t}\n\n\t\ttemplates := map[string]renderable{\n\t\t\ttemplateName.(string): {\n\t\t\t\ttpl:      tpl,\n\t\t\t\tvals:     vals,\n\t\t\t\tbasePath: basePath.(string),\n\t\t\t},\n\t\t}\n\n\t\tresult, err := e.renderWithReferences(templates, referenceTpls)\n\t\tif err != nil {\n\t\t\treturn \"\", errors.Wrapf(err, \"error during tpl function execution for %q\", tpl)\n\t\t}\n\t\treturn result[templateName.(string)], nil\n\t}\n\n\t// Add the `required` function here so we can use lintMode\n\tfuncMap[\"required\"] = func(warn string, val interface{}) (interface{}, error) {\n\t\tif val == nil {\n\t\t\tif e.LintMode {\n\t\t\t\t// Don't fail on missing required values when linting\n\t\t\t\tlog.Printf(\"[INFO] Missing required value: %s\", warn)\n\t\t\t\treturn \"\", nil\n\t\t\t}\n\t\t\treturn val, errors.Errorf(warnWrap(warn))\n\t\t} else if _, ok := val.(string); ok {\n\t\t\tif val == \"\" {\n\t\t\t\tif e.LintMode {\n\t\t\t\t\t// Don't fail on missing required values when linting\n\t\t\t\t\tlog.Printf(\"[INFO] Missing required value: %s\", warn)\n\t\t\t\t\treturn \"\", nil\n\t\t\t\t}\n\t\t\t\treturn val, errors.Errorf(warnWrap(warn))\n\t\t\t}\n\t\t}\n\t\treturn val, nil\n\t}\n\n\t// If we are not linting and have a cluster connection, provide a Kubernetes-backed\n\t// implementation.\n\tif !e.LintMode && e.config != nil {\n\t\tfuncMap[\"lookup\"] = NewLookupFunction(e.config)\n\t}\n\n\tt.Funcs(funcMap)\n}", "is_vulnerable": 0}
{"code": "func TestConnect(t *testing.T) {\n\tplainPsw := \"dQAUoDiyb1ucWZk7\"\n\n\trequire.NoError(t, failpoint.Enable(\n\t\t\"github.com/pingcap/tidb/br/pkg/lightning/common/MustMySQLPassword\",\n\t\tfmt.Sprintf(\"return(\\\"%s\\\")\", plainPsw)))\n\tdefer func() {\n\t\trequire.NoError(t, failpoint.Disable(\"github.com/pingcap/tidb/br/pkg/lightning/common/MustMySQLPassword\"))\n\t}()\n\n\tparam := common.MySQLConnectParam{\n\t\tHost:             \"127.0.0.1\",\n\t\tPort:             4000,\n\t\tUser:             \"root\",\n\t\tPassword:         plainPsw,\n\t\tSQLMode:          \"strict\",\n\t\tMaxAllowedPacket: 1234,\n\t}\n\t_, err := param.Connect()\n\trequire.NoError(t, err)\n\tparam.Password = base64.StdEncoding.EncodeToString([]byte(plainPsw))\n\t_, err = param.Connect()\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func (m *A) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: A: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: A: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field B\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.B = append(m.B, &B{})\n\t\t\tif err := m.B[len(m.B)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognized(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tctx := context.Background()\n\t\t\tstoreID := ulid.Make().String()\n\n\t\t\t// arrange: write model\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              ulid.Make().String(),\n\t\t\t\tSchemaVersion:   test.schema,\n\t\t\t\tTypeDefinitions: parser.MustParse(test.model),\n\t\t\t}\n\t\t\terr := ds.WriteAuthorizationModel(ctx, storeID, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// arrange: write tuples\n\t\t\terr = ds.Write(context.Background(), storeID, nil, test.tuples)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// act: run ListObjects\n\n\t\t\tlistObjectsDeadline := time.Minute\n\t\t\tif test.listObjectsDeadline > 0 {\n\t\t\t\tlistObjectsDeadline = test.listObjectsDeadline\n\t\t\t}\n\n\t\t\tdatastore := ds\n\t\t\tif test.readTuplesDelay > 0 {\n\t\t\t\tdatastore = mocks.NewMockSlowDataStorage(ds, test.readTuplesDelay)\n\t\t\t}\n\n\t\t\tlistObjectsQuery := &commands.ListObjectsQuery{\n\t\t\t\tDatastore:             datastore,\n\t\t\t\tLogger:                logger.NewNoopLogger(),\n\t\t\t\tListObjectsDeadline:   listObjectsDeadline,\n\t\t\t\tListObjectsMaxResults: test.maxResults,\n\t\t\t\tResolveNodeLimit:      defaultResolveNodeLimit,\n\t\t\t}\n\t\t\ttypesys := typesystem.New(model)\n\t\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\t\t\t// assertions\n\t\t\tt.Run(\"streaming_endpoint\", func(t *testing.T) {\n\t\t\t\tserver := &mockStreamServer{\n\t\t\t\t\tchannel: make(chan string, len(test.allResults)),\n\t\t\t\t}\n\n\t\t\t\tdone := make(chan struct{})\n\t\t\t\tvar streamedObjectIds []string\n\t\t\t\tgo func() {\n\t\t\t\t\tfor x := range server.channel {\n\t\t\t\t\t\tstreamedObjectIds = append(streamedObjectIds, x)\n\t\t\t\t\t}\n\n\t\t\t\t\tdone <- struct{}{}\n\t\t\t\t}()\n\n\t\t\t\terr := listObjectsQuery.ExecuteStreamed(ctx, &openfgapb.StreamedListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t}, server)\n\t\t\t\tclose(server.channel)\n\t\t\t\t<-done\n\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.GreaterOrEqual(t, len(streamedObjectIds), int(test.minimumResultsExpected))\n\t\t\t\trequire.ElementsMatch(t, test.allResults, streamedObjectIds)\n\t\t\t})\n\n\t\t\tt.Run(\"regular_endpoint\", func(t *testing.T) {\n\t\t\t\tres, err := listObjectsQuery.Execute(ctx, &openfgapb.ListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t})\n\n\t\t\t\trequire.NotNil(t, res)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.LessOrEqual(t, len(res.Objects), int(test.maxResults))\n\t\t\t\trequire.GreaterOrEqual(t, len(res.Objects), int(test.minimumResultsExpected))\n\t\t\t\trequire.Subset(t, test.allResults, res.Objects)\n\t\t\t})\n\t\t})", "is_vulnerable": 1}
{"code": "func TestParseReader(t *testing.T) {\n\tt.Parallel()\n\tt.Run(\"Empty []byte\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\t_, err := jws.Parse(nil)\n\t\tif !assert.Error(t, err, \"Parsing an empty byte slice should result in an error\") {\n\t\t\treturn\n\t\t}\n\t})\n\tt.Run(\"Empty bytes.Buffer\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\t_, err := jws.ParseReader(&bytes.Buffer{})\n\t\tif !assert.Error(t, err, \"Parsing an empty buffer should result in an error\") {\n\t\t\treturn\n\t\t}\n\t})\n\tt.Run(\"Compact detached payload\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tsplit := strings.Split(exampleCompactSerialization, \".\")\n\t\tincoming := strings.Join([]string{split[0], \"\", split[2]}, \".\")\n\t\t_, err := jws.ParseString(incoming)\n\t\tif !assert.NoError(t, err, `jws.ParseString should succeed`) {\n\t\t\treturn\n\t\t}\n\t})\n\tt.Run(\"Compact missing header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tincoming := strings.Join(\n\t\t\t(strings.Split(\n\t\t\t\texampleCompactSerialization,\n\t\t\t\t\".\",\n\t\t\t))[:2],\n\t\t\t\".\",\n\t\t)\n\n\t\tfor _, useReader := range []bool{true, false} {\n\t\t\tvar err error\n\t\t\tif useReader {\n\t\t\t\t// Force ParseReader() to choose un-optimized path by using bufio.NewReader\n\t\t\t\t_, err = jws.ParseReader(bufio.NewReader(strings.NewReader(incoming)))\n\t\t\t} else {\n\t\t\t\t_, err = jws.ParseString(incoming)\n\t\t\t}\n\t\t\tif !assert.Error(t, err, \"Parsing compact serialization with less than 3 parts should be an error\") {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t})\n\tt.Run(\"Compact bad header\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tparts := strings.Split(exampleCompactSerialization, \".\")\n\t\tparts[0] = badValue\n\t\tincoming := strings.Join(parts, \".\")\n\n\t\tfor _, useReader := range []bool{true, false} {\n\t\t\tvar err error\n\t\t\tif useReader {\n\t\t\t\t_, err = jws.ParseReader(bufio.NewReader(strings.NewReader(incoming)))\n\t\t\t} else {\n\t\t\t\t_, err = jws.ParseString(incoming)\n\t\t\t}\n\t\t\tif !assert.Error(t, err, \"Parsing compact serialization with bad header should be an error\") {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t})\n\tt.Run(\"Compact bad payload\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tparts := strings.Split(exampleCompactSerialization, \".\")\n\t\tparts[1] = badValue\n\t\tincoming := strings.Join(parts, \".\")\n\n\t\tfor _, useReader := range []bool{true, false} {\n\t\t\tvar err error\n\t\t\tif useReader {\n\t\t\t\t_, err = jws.ParseReader(bufio.NewReader(strings.NewReader(incoming)))\n\t\t\t} else {\n\t\t\t\t_, err = jws.ParseString(incoming)\n\t\t\t}\n\t\t\tif !assert.Error(t, err, \"Parsing compact serialization with bad payload should be an error\") {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t})\n\tt.Run(\"Compact bad signature\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tparts := strings.Split(exampleCompactSerialization, \".\")\n\t\tparts[2] = badValue\n\t\tincoming := strings.Join(parts, \".\")\n\n\t\tfor _, useReader := range []bool{true, false} {\n\t\t\tvar err error\n\t\t\tif useReader {\n\t\t\t\t_, err = jws.ParseReader(bufio.NewReader(strings.NewReader(incoming)))\n\t\t\t} else {\n\t\t\t\t_, err = jws.ParseString(incoming)\n\t\t\t}\n\t\t\tif !assert.Error(t, err, \"Parsing compact serialization with bad signature should be an error\") {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func (ctx *Ctx) AuthZRequest(w http.ResponseWriter, r *http.Request) error {\n\tvar body []byte\n\tif sendBody(ctx.requestURI, r.Header) && (r.ContentLength > 0 || isChunked(r)) && r.ContentLength < maxBodySize {\n\t\tvar err error\n\t\tbody, r.Body, err = drainBody(r.Body)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tvar h bytes.Buffer\n\tif err := r.Header.Write(&h); err != nil {\n\t\treturn err\n\t}\n\n\tctx.authReq = &Request{\n\t\tUser:            ctx.user,\n\t\tUserAuthNMethod: ctx.userAuthNMethod,\n\t\tRequestMethod:   ctx.requestMethod,\n\t\tRequestURI:      ctx.requestURI,\n\t\tRequestBody:     body,\n\t\tRequestHeaders:  headers(r.Header),\n\t}\n\n\tif r.TLS != nil {\n\t\tfor _, c := range r.TLS.PeerCertificates {\n\t\t\tpc := PeerCertificate(*c)\n\t\t\tctx.authReq.RequestPeerCertificates = append(ctx.authReq.RequestPeerCertificates, &pc)\n\t\t}\n\t}\n\n\tfor _, plugin := range ctx.plugins {\n\t\tlogrus.Debugf(\"AuthZ request using plugin %s\", plugin.Name())\n\n\t\tauthRes, err := plugin.AuthZRequest(ctx.authReq)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"plugin %s failed with error: %s\", plugin.Name(), err)\n\t\t}\n\n\t\tif !authRes.Allow {\n\t\t\treturn newAuthorizationError(plugin.Name(), authRes.Msg)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (e *EngineInfo) HomeDir() string {\n\treturn C.GoString(e.info.home_dir)\n}", "is_vulnerable": 1}
{"code": "func (self *CryptoManager) Decrypt(cipher_text []byte) (*vcrypto.MessageInfo, error) {\n\tvar err error\n\t// Parse the ClientCommunication protobuf.\n\tcommunications := &crypto_proto.ClientCommunication{}\n\terr = proto.Unmarshal(cipher_text, communications)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t// An empty message is not an error but we can't figure out the\n\t// source.\n\tif len(communications.EncryptedCipher) == 0 {\n\t\treturn &vcrypto.MessageInfo{}, nil\n\t}\n\n\tcipher, ok := self.cipher_lru.GetByInboundCipher(communications.EncryptedCipher)\n\tif ok {\n\t\t// Check HMAC to save checking the RSA signature for\n\t\t// malformed packets.\n\t\tif !hmac.Equal(\n\t\t\tCalcHMAC(communications, cipher.cipher_properties),\n\t\t\tcommunications.FullHmac) {\n\t\t\treturn nil, errors.New(\"HMAC did not verify\")\n\t\t}\n\n\t\tmsg_info, _, err := self.extractMessageInfo(\n\t\t\tcipher.cipher_properties, communications)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Cipher was cached so we trust it\n\t\tmsg_info.Authenticated = true\n\t\tmsg_info.Source = cipher.cipher_metadata.Source\n\n\t\treturn msg_info, nil\n\t}\n\n\t// Decrypt the CipherProperties\n\tRsaDecryptCounter.Inc()\n\tserialized_cipher, err := rsa.DecryptOAEP(\n\t\tsha1.New(), rand.Reader,\n\t\tself.private_key,\n\t\tcommunications.EncryptedCipher,\n\t\t[]byte(\"\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcipher_properties := &crypto_proto.CipherProperties{}\n\terr = proto.Unmarshal(serialized_cipher, cipher_properties)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t// Check HMAC first to save checking the RSA signature for\n\t// malformed packets.\n\tif !hmac.Equal(\n\t\tCalcHMAC(communications, cipher_properties),\n\t\tcommunications.FullHmac) {\n\t\treturn nil, errors.New(\"HMAC did not verify\")\n\t}\n\n\t// Extract the serialized CipherMetadata.\n\tserialized_metadata, err := decryptSymmetric(\n\t\tcipher_properties, communications.EncryptedCipherMetadata,\n\t\tcipher_properties.MetadataIv)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcipher_metadata := &crypto_proto.CipherMetadata{}\n\terr = proto.Unmarshal(serialized_metadata, cipher_metadata)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tmsg_info, org_config_obj, err := self.extractMessageInfo(\n\t\tcipher_properties, communications)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Verify the cipher metadata signature.\n\tcipher_metadata.Source = utils.ClientIdFromSourceAndOrg(\n\t\tcipher_metadata.Source, msg_info.OrgId)\n\n\tmsg_info.Authenticated, err = self.getAuthState(\n\t\torg_config_obj, cipher_metadata, serialized_cipher, cipher_properties)\n\n\t// If we could verify the authentication state and it\n\t// was authenticated, we are now allowed to cache the\n\t// cipher in the input cache. The next packet from\n\t// this session will NOT be verified.\n\tif err == nil && msg_info.Authenticated {\n\t\tself.cipher_lru.Set(\n\t\t\tmsg_info.Source,\n\t\t\t&_Cipher{\n\t\t\t\tcipher_metadata:   cipher_metadata,\n\t\t\t\tencrypted_cipher:  communications.EncryptedCipher,\n\t\t\t\tcipher_properties: cipher_properties,\n\t\t\t},\n\t\t\tnil, /* outbound_cipher */\n\t\t)\n\n\t\tmsg_info.Authenticated = true\n\t\tmsg_info.Source = cipher_metadata.Source\n\t\treturn msg_info, nil\n\t}\n\n\t// Make sure the message source is set from the cipher_metadata\n\t// overriding the internal Source. The source is cryptographically\n\t// verified by the encryption of the outer envelop.\n\tmsg_info.Source = cipher_metadata.Source\n\treturn msg_info, nil\n}", "is_vulnerable": 0}
{"code": "func TestKeeperIntegrationTestSuite(t *testing.T) {\n\ts = new(KeeperTestSuite)\n\ts.SetT(t)\n\n\t// Run Ginkgo integration tests\n\tRegisterFailHandler(Fail)\n\tRunSpecs(t, \"Keeper Suite\")\n}", "is_vulnerable": 0}
{"code": "func (client Client) MoveResources(ctx context.Context, sourceResourceGroupName string, parameters MoveInfo) (result MoveResourcesFuture, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: sourceResourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"sourceResourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"sourceResourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"sourceResourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"MoveResources\", err.Error())\n\t}\n\n\treq, err := client.MoveResourcesPreparer(ctx, sourceResourceGroupName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"MoveResources\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresult, err = client.MoveResourcesSender(req)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"MoveResources\", result.Response(), \"Failure sending request\")\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (mr *MockClientMockRecorder) GetID() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetID\", reflect.TypeOf((*MockClient)(nil).GetID))\n}", "is_vulnerable": 0}
{"code": "func (ipn *IPNet) GetRange() (net.IP, net.IP, bool) {\n\terr, min, max := GetRangeIP(ipn.IPNet)\n\tif err != nil {\n\t\treturn nil, nil, false\n\t}\n\treturn min, max, false\n}", "is_vulnerable": 0}
{"code": "func TarWithChroot(source string) (io.ReadCloser, error) {\n\tlogrus.Debugf(\"creating tarball of %s\", source)\n\treturn chrootarchive.Tar(source, nil, source)\n}", "is_vulnerable": 0}
{"code": "func (t *DictController) GetSysDictByCode(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tcode := ctx.Param(\"code\")\n\tdata, err := t.sysDictService.GetSysDictByCode(code)\n\tif err != nil {\n\t\te := &response.AdminError{\n\t\t\tErrorCode:    http.StatusBadRequest,\n\t\t\tErrorMessage: err.Error(),\n\t\t}\n\t\t_ = ctx.Error(e)\n\t\treturn\n\t}\n\tresp.SetData(data)\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestImportValidation(t *testing.T) {\n\tak := createAccountNKey(t)\n\tak2 := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\takp2 := publicKey(ak2, t)\n\ti := &Import{Subject: \"test\", Account: akp2, To: \"bar\", Type: Stream}\n\n\tvr := CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif vr.IsEmpty() {\n\t\tt.Errorf(\"imports without token or url should warn the caller\")\n\t}\n\n\tif vr.IsBlocking(true) {\n\t\tt.Errorf(\"imports without token or url should not be blocking\")\n\t}\n\n\ti.Type = Service\n\tvr = CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif vr.IsEmpty() {\n\t\tt.Errorf(\"imports without token or url should warn the caller\")\n\t}\n\n\tif vr.IsBlocking(true) {\n\t\tt.Errorf(\"imports without token or url should not be blocking\")\n\t}\n\n\tactivation := NewActivationClaims(akp)\n\tactivation.Max = 1024 * 1024\n\tactivation.Expires = time.Now().Add(time.Duration(time.Hour)).UTC().Unix()\n\n\tactivation.ImportSubject = \"test\"\n\tactivation.ImportType = Stream\n\tactJWT := encode(activation, ak2, t)\n\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports with token should be valid\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestBuilderLookupService(t *testing.T) {\n\ts1 := &v1.Service{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"kuard\",\n\t\t\tNamespace: \"default\",\n\t\t},\n\t\tSpec: v1.ServiceSpec{\n\t\t\tPorts: []v1.ServicePort{{\n\t\t\t\tName:       \"http\",\n\t\t\t\tProtocol:   \"TCP\",\n\t\t\t\tPort:       8080,\n\t\t\t\tTargetPort: intstr.FromInt(8080),\n\t\t\t}},\n\t\t},\n\t}\n\tservices := map[types.NamespacedName]*v1.Service{\n\t\t{Name: \"service1\", Namespace: \"default\"}: s1,\n\t}\n\n\ttests := map[string]struct {\n\t\ttypes.NamespacedName\n\t\tport    intstr.IntOrString\n\t\twant    *Service\n\t\twantErr error\n\t}{\n\t\t\"lookup service by port number\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"service1\", Namespace: \"default\"},\n\t\t\tport:           intstr.FromInt(8080),\n\t\t\twant:           service(s1),\n\t\t},\n\t\t\"lookup service by port name\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"service1\", Namespace: \"default\"},\n\t\t\tport:           intstr.FromString(\"http\"),\n\t\t\twant:           service(s1),\n\t\t},\n\t\t\"lookup service by port number (as string)\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"service1\", Namespace: \"default\"},\n\t\t\tport:           intstr.Parse(\"8080\"),\n\t\t\twant:           service(s1),\n\t\t},\n\t\t\"lookup service by port number (from string)\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"service1\", Namespace: \"default\"},\n\t\t\tport:           intstr.FromString(\"8080\"),\n\t\t\twant:           service(s1),\n\t\t},\n\t\t\"when service does not exist an error is returned\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"nonexistent-service\", Namespace: \"default\"},\n\t\t\tport:           intstr.FromString(\"8080\"),\n\t\t\twantErr:        errors.New(`service \"default/nonexistent-service\" not found`),\n\t\t},\n\t\t\"when port does not exist an error is returned\": {\n\t\t\tNamespacedName: types.NamespacedName{Name: \"service1\", Namespace: \"default\"},\n\t\t\tport:           intstr.FromString(\"9999\"),\n\t\t\twantErr:        errors.New(`port \"9999\" on service \"default/service1\" not matched`),\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tb := Builder{\n\t\t\t\tSource: KubernetesCache{\n\t\t\t\t\tservices:    services,\n\t\t\t\t\tFieldLogger: fixture.NewTestLogger(t),\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tvar dag DAG\n\n\t\t\tgot, gotErr := dag.EnsureService(tc.NamespacedName, tc.port, &b.Source)\n\t\t\tassert.Equal(t, tc.want, got)\n\t\t\tassert.Equal(t, tc.wantErr, gotErr)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestUnixFS_Rename(t *testing.T) {\n\tt.Parallel()\n\tfs, err := newTestUnixFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t\treturn\n\t}\n\tdefer fs.Cleanup()\n\n\tt.Run(\"rename base directory\", func(t *testing.T) {\n\t\t// Try to rename the base directory.\n\t\tif err := fs.Rename(\"\", \"yeet\"); !errors.Is(err, ufs.ErrBadPathResolution) {\n\t\t\tt.Errorf(\"expected an a bad path resolution error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n\n\tt.Run(\"rename over base directory\", func(t *testing.T) {\n\t\t// Create a directory that we are going to try and move over top of the\n\t\t// existing base directory.\n\t\tif err := fs.Mkdir(\"overwrite_dir\", 0o755); err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\n\t\t// Try to rename over the base directory.\n\t\tif err := fs.Rename(\"overwrite_dir\", \"\"); !errors.Is(err, ufs.ErrBadPathResolution) {\n\t\t\tt.Errorf(\"expected an a bad path resolution error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n\n\tt.Run(\"directory rename\", func(t *testing.T) {\n\t\t// Create a directory to rename to something else.\n\t\tif err := fs.Mkdir(\"test_directory\", 0o755); err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t}\n\n\t\t// Try to rename \"test_directory\" to \"directory\".\n\t\tif err := fs.Rename(\"test_directory\", \"directory\"); err != nil {\n\t\t\tt.Errorf(\"expected no error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Sanity check\n\t\tif _, err := os.Lstat(filepath.Join(fs.Root, \"directory\")); err != nil {\n\t\t\tt.Errorf(\"Lstat errored when performing sanity check: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n\n\tt.Run(\"file rename\", func(t *testing.T) {\n\t\t// Create a directory to rename to something else.\n\t\tif f, err := fs.Create(\"test_file\"); err != nil {\n\t\t\tt.Error(err)\n\t\t\treturn\n\t\t} else {\n\t\t\t_ = f.Close()\n\t\t}\n\n\t\t// Try to rename \"test_file\" to \"file\".\n\t\tif err := fs.Rename(\"test_file\", \"file\"); err != nil {\n\t\t\tt.Errorf(\"expected no error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Sanity check\n\t\tif _, err := os.Lstat(filepath.Join(fs.Root, \"file\")); err != nil {\n\t\t\tt.Errorf(\"Lstat errored when performing sanity check: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func Decrypt(buf []byte, alg jwa.KeyEncryptionAlgorithm, key interface{}, options ...DecryptOption) ([]byte, error) {\n\tvar ctx decryptCtx\n\tctx.key = key\n\tctx.alg = alg\n\n\tvar dst *Message\n\tvar postParse PostParser\n\t// in v1 the default value is hardcoded. Use v2 if you want to change this value globally\n\tvar maxDecompressBufferSize int64 = 10 * 1024 * 1024\n\t//nolint:forcetypeassert\n\tfor _, option := range options {\n\t\tswitch option.Ident() {\n\t\tcase identMessage{}:\n\t\t\tdst = option.Value().(*Message)\n\t\tcase identPostParser{}:\n\t\t\tpostParse = option.Value().(PostParser)\n\t\tcase identMaxDecompressBufferSize{}:\n\t\t\tmaxDecompressBufferSize = option.Value().(int64)\n\t\t}\n\t}\n\n\tmsg, err := parseJSONOrCompact(buf, true)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse buffer for Decrypt\")\n\t}\n\n\tctx.msg = msg\n\tif postParse != nil {\n\t\tif err := postParse.PostParse(&ctx); err != nil {\n\t\t\treturn nil, errors.Wrap(err, `failed to execute PostParser hook`)\n\t\t}\n\t}\n\tctx.maxDecompressBufferSize = maxDecompressBufferSize\n\n\tpayload, err := doDecryptCtx(&ctx)\n\tif err != nil {\n\t\tfmt.Printf(\"failed to decrypt: %s\\n\", err)\n\t\treturn nil, errors.Wrap(err, `failed to decrypt message`)\n\t}\n\n\tif dst != nil {\n\t\t*dst = *msg\n\t\tdst.rawProtectedHeaders = nil\n\t\tdst.storeProtectedHeaders = false\n\t}\n\n\treturn payload, nil\n}", "is_vulnerable": 0}
{"code": "func getMatchingPolicies(store cache.Store, user user.Info, sa user.Info, authz authorizer.Authorizer) ([]*extensions.PodSecurityPolicy, error) {\n\tmatchedPolicies := make([]*extensions.PodSecurityPolicy, 0)\n\n\tfor _, c := range store.List() {\n\t\tconstraint, ok := c.(*extensions.PodSecurityPolicy)\n\t\tif !ok {\n\t\t\treturn nil, errors.NewInternalError(fmt.Errorf(\"error converting object from store to a pod security policy: %v\", c))\n\t\t}\n\n\t\t// if no user info exists then the API is being hit via the unsecured port. In this case authorize the request.\n\t\tif user == nil || authorizedForPolicy(user, constraint, authz) || authorizedForPolicy(sa, constraint, authz) {\n\t\t\tmatchedPolicies = append(matchedPolicies, constraint)\n\t\t}\n\t}\n\n\treturn matchedPolicies, nil\n}", "is_vulnerable": 0}
{"code": "func (f *Folder) scan(ctx context.Context, path string) {\n\tconst method = \"domain.ide.workspace.folder.scan\"\n\tif !f.IsTrusted() {\n\t\tlog.Warn().Str(\"path\", path).Str(\"method\", method).Msg(\"skipping scan of untrusted path\")\n\t\treturn\n\t}\n\tissuesSlice := f.DocumentDiagnosticsFromCache(path)\n\tif issuesSlice != nil {\n\t\tlog.Info().Str(\"method\", method).Msgf(\"Cached results found: Skipping scan for %s\", path)\n\t\tf.processResults(issuesSlice)\n\t\treturn\n\t}\n\n\tf.scanner.Scan(ctx, path, f.processResults, f.path)\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleProppatch(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\treqPath, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\trelease, status, err := h.confirmLocks(r, reqPath, \"\")\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\treqPath, err = user.JoinPath(reqPath)\n\tif err != nil {\n\t\treturn 403, err\n\t}\n\tif _, err := fs.Get(ctx, reqPath); err != nil {\n\t\tif errs.IsObjectNotFound(err) {\n\t\t\treturn http.StatusNotFound, err\n\t\t}\n\t\treturn http.StatusMethodNotAllowed, err\n\t}\n\tpatches, status, err := readProppatch(r.Body)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tpstats, err := patch(ctx, h.LockSystem, reqPath, patches)\n\tif err != nil {\n\t\treturn http.StatusInternalServerError, err\n\t}\n\tmw := multistatusWriter{w: w}\n\twriteErr := mw.write(makePropstatResponse(r.URL.Path, pstats))\n\tcloseErr := mw.close()\n\tif writeErr != nil {\n\t\treturn http.StatusInternalServerError, writeErr\n\t}\n\tif closeErr != nil {\n\t\treturn http.StatusInternalServerError, closeErr\n\t}\n\treturn 0, nil\n}", "is_vulnerable": 0}
{"code": "func sanitizeMethod(m string) string {\n\tswitch m {\n\tcase \"GET\", \"get\":\n\t\treturn \"get\"\n\tcase \"PUT\", \"put\":\n\t\treturn \"put\"\n\tcase \"HEAD\", \"head\":\n\t\treturn \"head\"\n\tcase \"POST\", \"post\":\n\t\treturn \"post\"\n\tcase \"DELETE\", \"delete\":\n\t\treturn \"delete\"\n\tcase \"CONNECT\", \"connect\":\n\t\treturn \"connect\"\n\tcase \"OPTIONS\", \"options\":\n\t\treturn \"options\"\n\tcase \"NOTIFY\", \"notify\":\n\t\treturn \"notify\"\n\tdefault:\n\t\treturn strings.ToLower(m)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *Any) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowAny\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Any: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Any: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field TypeUrl\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowAny\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.TypeUrl = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowAny\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Value = append(m.Value[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Value == nil {\n\t\t\t\tm.Value = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipAny(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthAny\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (f *RouterFactory) CreateRouters(rtConf *runtime.Configuration) (map[string]*tcprouter.Router, map[string]udptypes.Handler) {\n\tctx := context.Background()\n\n\t// HTTP\n\tserviceManager := f.managerFactory.Build(rtConf)\n\n\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, f.pluginBuilder)\n\n\trouterManager := router.NewManager(rtConf, serviceManager, middlewaresBuilder, f.chainBuilder, f.metricsRegistry, f.tlsManager)\n\n\thandlersNonTLS := routerManager.BuildHandlers(ctx, f.entryPointsTCP, false)\n\thandlersTLS := routerManager.BuildHandlers(ctx, f.entryPointsTCP, true)\n\n\tserviceManager.LaunchHealthCheck()\n\n\t// TCP\n\tsvcTCPManager := tcp.NewManager(rtConf)\n\n\tmiddlewaresTCPBuilder := tcpmiddleware.NewBuilder(rtConf.TCPMiddlewares)\n\n\trtTCPManager := tcprouter.NewManager(rtConf, svcTCPManager, middlewaresTCPBuilder, handlersNonTLS, handlersTLS, f.tlsManager)\n\troutersTCP := rtTCPManager.BuildHandlers(ctx, f.entryPointsTCP)\n\n\t// UDP\n\tsvcUDPManager := udp.NewManager(rtConf)\n\trtUDPManager := udprouter.NewManager(rtConf, svcUDPManager)\n\troutersUDP := rtUDPManager.BuildHandlers(ctx, f.entryPointsUDP)\n\n\trtConf.PopulateUsedBy()\n\n\treturn routersTCP, routersUDP\n}", "is_vulnerable": 0}
{"code": "func TestManager_Get(t *testing.T) {\n\tdynamicConfigs := []*CertAndStores{{\n\t\tCertificate: Certificate{\n\t\t\tCertFile: localhostCert,\n\t\t\tKeyFile:  localhostKey,\n\t\t},\n\t}}\n\n\ttlsConfigs := map[string]Options{\n\t\t\"foo\":     {MinVersion: \"VersionTLS12\"},\n\t\t\"bar\":     {MinVersion: \"VersionTLS11\"},\n\t\t\"invalid\": {CurvePreferences: []string{\"42\"}},\n\t}\n\n\ttestCases := []struct {\n\t\tdesc               string\n\t\ttlsOptionsName     string\n\t\texpectedMinVersion uint16\n\t\texpectedError      bool\n\t}{\n\t\t{\n\t\t\tdesc:               \"Get a tls config from a valid name\",\n\t\t\ttlsOptionsName:     \"foo\",\n\t\t\texpectedMinVersion: uint16(tls.VersionTLS12),\n\t\t},\n\t\t{\n\t\t\tdesc:               \"Get another tls config from a valid name\",\n\t\t\ttlsOptionsName:     \"bar\",\n\t\t\texpectedMinVersion: uint16(tls.VersionTLS11),\n\t\t},\n\t\t{\n\t\t\tdesc:           \"Get a tls config from an invalid name\",\n\t\t\ttlsOptionsName: \"unknown\",\n\t\t\texpectedError:  true,\n\t\t},\n\t\t{\n\t\t\tdesc:           \"Get a tls config from unexisting 'default' name\",\n\t\t\ttlsOptionsName: \"default\",\n\t\t\texpectedError:  true,\n\t\t},\n\t\t{\n\t\t\tdesc:           \"Get an invalid tls config\",\n\t\t\ttlsOptionsName: \"invalid\",\n\t\t\texpectedError:  true,\n\t\t},\n\t}\n\n\ttlsManager := NewManager()\n\ttlsManager.UpdateConfigs(context.Background(), nil, tlsConfigs, dynamicConfigs)\n\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tconfig, err := tlsManager.Get(\"default\", test.tlsOptionsName)\n\t\t\tif test.expectedError {\n\t\t\t\trequire.Nil(t, config)\n\t\t\t\trequire.Error(t, err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.NoError(t, err)\n\t\t\tassert.Equal(t, config.MinVersion, test.expectedMinVersion)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn func(db *gorm.DB) *gorm.DB {\n\t\tsort := c.DefaultQuery(\"order\", \"desc\")\n\n\t\torder := fmt.Sprintf(\"`%s` %s\", DefaultQuery(c, \"sort_by\", \"id\"), sort)\n\t\tdb = db.Order(order)\n\n\t\tpage := cast.ToInt(c.Query(\"page\"))\n\t\tif page == 0 {\n\t\t\tpage = 1\n\t\t}\n\t\tpageSize := settings.ServerSettings.PageSize\n\t\treqPageSize := c.Query(\"page_size\")\n\t\tif reqPageSize != \"\" {\n\t\t\tpageSize = cast.ToInt(reqPageSize)\n\t\t}\n\t\toffset := (page - 1) * pageSize\n\n\t\treturn db.Offset(offset).Limit(pageSize)\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\taction := args[2].(func(child argoappv1.ResourceNode, appName string) bool)\n\t\tappName := \"\"\n\t\tif res, ok := data.namespacedResources[key]; ok {\n\t\t\tappName = res.AppName\n\t\t}\n\t\t_ = action(argoappv1.ResourceNode{ResourceRef: argoappv1.ResourceRef{Kind: key.Kind, Group: key.Group, Namespace: key.Namespace, Name: key.Name}}, appName)\n\t}).Return(nil)", "is_vulnerable": 0}
{"code": "func (mnt *Mount) LogRefs() bool {\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (f *BlockFetcher) loop() {\n\t// Iterate the block fetching until a quit is requested\n\tfetchTimer := time.NewTimer(0)\n\tcompleteTimer := time.NewTimer(0)\n\tdefer fetchTimer.Stop()\n\tdefer completeTimer.Stop()\n\n\tfor {\n\t\t// Clean up any expired block fetches\n\t\tfor hash, announce := range f.fetching {\n\t\t\tif time.Since(announce.time) > fetchTimeout {\n\t\t\t\tf.forgetHash(hash)\n\t\t\t}\n\t\t}\n\t\t// Import any queued blocks that could potentially fit\n\t\theight := f.chainHeight()\n\t\tfor !f.queue.Empty() {\n\t\t\top := f.queue.PopItem().(*blockOrHeaderInject)\n\t\t\thash := op.hash()\n\t\t\tif f.queueChangeHook != nil {\n\t\t\t\tf.queueChangeHook(hash, false)\n\t\t\t}\n\t\t\t// If too high up the chain or phase, continue later\n\t\t\tnumber := op.number()\n\t\t\tif number > height+1 {\n\t\t\t\tf.queue.Push(op, -int64(number))\n\t\t\t\tif f.queueChangeHook != nil {\n\t\t\t\t\tf.queueChangeHook(hash, true)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// Otherwise if fresh and still unknown, try and import\n\t\t\tif (number+maxUncleDist < height) || (f.light && f.getHeader(hash) != nil) || (!f.light && f.getBlock(hash) != nil) {\n\t\t\t\tf.forgetBlock(hash)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif f.light {\n\t\t\t\tf.importHeaders(op.origin, op.header)\n\t\t\t} else {\n\t\t\t\tf.importBlocks(op.origin, op.block)\n\t\t\t}\n\t\t}\n\t\t// Wait for an outside event to occur\n\t\tselect {\n\t\tcase <-f.quit:\n\t\t\t// BlockFetcher terminating, abort all operations\n\t\t\treturn\n\n\t\tcase notification := <-f.notify:\n\t\t\t// A block was announced, make sure the peer isn't DOSing us\n\t\t\tblockAnnounceInMeter.Mark(1)\n\n\t\t\tcount := f.announces[notification.origin] + 1\n\t\t\tif count > hashLimit {\n\t\t\t\tlog.Debug(\"Peer exceeded outstanding announces\", \"peer\", notification.origin, \"limit\", hashLimit)\n\t\t\t\tblockAnnounceDOSMeter.Mark(1)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// If we have a valid block number, check that it's potentially useful\n\t\t\tif notification.number > 0 {\n\t\t\t\tif dist := int64(notification.number) - int64(f.chainHeight()); dist < -maxUncleDist || dist > maxQueueDist {\n\t\t\t\t\tlog.Debug(\"Peer discarded announcement\", \"peer\", notification.origin, \"number\", notification.number, \"hash\", notification.hash, \"distance\", dist)\n\t\t\t\t\tblockAnnounceDropMeter.Mark(1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\t// All is well, schedule the announce if block's not yet downloading\n\t\t\tif _, ok := f.fetching[notification.hash]; ok {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif _, ok := f.completing[notification.hash]; ok {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tf.announces[notification.origin] = count\n\t\t\tf.announced[notification.hash] = append(f.announced[notification.hash], notification)\n\t\t\tif f.announceChangeHook != nil && len(f.announced[notification.hash]) == 1 {\n\t\t\t\tf.announceChangeHook(notification.hash, true)\n\t\t\t}\n\t\t\tif len(f.announced) == 1 {\n\t\t\t\tf.rescheduleFetch(fetchTimer)\n\t\t\t}\n\n\t\tcase op := <-f.inject:\n\t\t\t// A direct block insertion was requested, try and fill any pending gaps\n\t\t\tblockBroadcastInMeter.Mark(1)\n\n\t\t\t// Now only direct block injection is allowed, drop the header injection\n\t\t\t// here silently if we receive.\n\t\t\tif f.light {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tf.enqueue(op.origin, nil, op.block)\n\n\t\tcase hash := <-f.done:\n\t\t\t// A pending import finished, remove all traces of the notification\n\t\t\tf.forgetHash(hash)\n\t\t\tf.forgetBlock(hash)\n\n\t\tcase <-fetchTimer.C:\n\t\t\t// At least one block's timer ran out, check for needing retrieval\n\t\t\trequest := make(map[string][]common.Hash)\n\n\t\t\tfor hash, announces := range f.announced {\n\t\t\t\t// In current LES protocol(les2/les3), only header announce is\n\t\t\t\t// available, no need to wait too much time for header broadcast.\n\t\t\t\ttimeout := arriveTimeout - gatherSlack\n\t\t\t\tif f.light {\n\t\t\t\t\ttimeout = 0\n\t\t\t\t}\n\t\t\t\tif time.Since(announces[0].time) > timeout {\n\t\t\t\t\t// Pick a random peer to retrieve from, reset all others\n\t\t\t\t\tannounce := announces[rand.Intn(len(announces))]\n\t\t\t\t\tf.forgetHash(hash)\n\n\t\t\t\t\t// If the block still didn't arrive, queue for fetching\n\t\t\t\t\tif (f.light && f.getHeader(hash) == nil) || (!f.light && f.getBlock(hash) == nil) {\n\t\t\t\t\t\trequest[announce.origin] = append(request[announce.origin], hash)\n\t\t\t\t\t\tf.fetching[hash] = announce\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Send out all block header requests\n\t\t\tfor peer, hashes := range request {\n\t\t\t\tlog.Trace(\"Fetching scheduled headers\", \"peer\", peer, \"list\", hashes)\n\n\t\t\t\t// Create a closure of the fetch and schedule in on a new thread\n\t\t\t\tfetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes\n\t\t\t\tgo func() {\n\t\t\t\t\tif f.fetchingHook != nil {\n\t\t\t\t\t\tf.fetchingHook(hashes)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, hash := range hashes {\n\t\t\t\t\t\theaderFetchMeter.Mark(1)\n\t\t\t\t\t\tfetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n\t\t\t// Schedule the next fetch if blocks are still pending\n\t\t\tf.rescheduleFetch(fetchTimer)\n\n\t\tcase <-completeTimer.C:\n\t\t\t// At least one header's timer ran out, retrieve everything\n\t\t\trequest := make(map[string][]common.Hash)\n\n\t\t\tfor hash, announces := range f.fetched {\n\t\t\t\t// Pick a random peer to retrieve from, reset all others\n\t\t\t\tannounce := announces[rand.Intn(len(announces))]\n\t\t\t\tf.forgetHash(hash)\n\n\t\t\t\t// If the block still didn't arrive, queue for completion\n\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\trequest[announce.origin] = append(request[announce.origin], hash)\n\t\t\t\t\tf.completing[hash] = announce\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Send out all block body requests\n\t\t\tfor peer, hashes := range request {\n\t\t\t\tlog.Trace(\"Fetching scheduled bodies\", \"peer\", peer, \"list\", hashes)\n\n\t\t\t\t// Create a closure of the fetch and schedule in on a new thread\n\t\t\t\tif f.completingHook != nil {\n\t\t\t\t\tf.completingHook(hashes)\n\t\t\t\t}\n\t\t\t\tbodyFetchMeter.Mark(int64(len(hashes)))\n\t\t\t\tgo f.completing[hashes[0]].fetchBodies(hashes)\n\t\t\t}\n\t\t\t// Schedule the next fetch if blocks are still pending\n\t\t\tf.rescheduleComplete(completeTimer)\n\n\t\tcase filter := <-f.headerFilter:\n\t\t\t// Headers arrived from a remote peer. Extract those that were explicitly\n\t\t\t// requested by the fetcher, and return everything else so it's delivered\n\t\t\t// to other parts of the system.\n\t\t\tvar task *headerFilterTask\n\t\t\tselect {\n\t\t\tcase task = <-filter:\n\t\t\tcase <-f.quit:\n\t\t\t\treturn\n\t\t\t}\n\t\t\theaderFilterInMeter.Mark(int64(len(task.headers)))\n\n\t\t\t// Split the batch of headers into unknown ones (to return to the caller),\n\t\t\t// known incomplete ones (requiring body retrievals) and completed blocks.\n\t\t\tunknown, incomplete, complete, lightHeaders := []*types.Header{}, []*blockAnnounce{}, []*types.Block{}, []*blockAnnounce{}\n\t\t\tfor _, header := range task.headers {\n\t\t\t\thash := header.Hash()\n\n\t\t\t\t// Filter fetcher-requested headers from other synchronisation algorithms\n\t\t\t\tif announce := f.fetching[hash]; announce != nil && announce.origin == task.peer && f.fetched[hash] == nil && f.completing[hash] == nil && f.queued[hash] == nil {\n\t\t\t\t\t// If the delivered header does not match the promised number, drop the announcer\n\t\t\t\t\tif header.Number.Uint64() != announce.number {\n\t\t\t\t\t\tlog.Trace(\"Invalid block number fetched\", \"peer\", announce.origin, \"hash\", header.Hash(), \"announced\", announce.number, \"provided\", header.Number)\n\t\t\t\t\t\tf.dropPeer(announce.origin)\n\t\t\t\t\t\tf.forgetHash(hash)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\t// Collect all headers only if we are running in light\n\t\t\t\t\t// mode and the headers are not imported by other means.\n\t\t\t\t\tif f.light {\n\t\t\t\t\t\tif f.getHeader(hash) == nil {\n\t\t\t\t\t\t\tannounce.header = header\n\t\t\t\t\t\t\tlightHeaders = append(lightHeaders, announce)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tf.forgetHash(hash)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\t// Only keep if not imported by other means\n\t\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\t\tannounce.header = header\n\t\t\t\t\t\tannounce.time = task.time\n\n\t\t\t\t\t\t// If the block is empty (header only), short circuit into the final import queue\n\t\t\t\t\t\tif header.TxHash == types.EmptyRootHash && header.UncleHash == types.EmptyUncleHash {\n\t\t\t\t\t\t\tlog.Trace(\"Block empty, skipping body retrieval\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n\n\t\t\t\t\t\t\tblock := types.NewBlockWithHeader(header)\n\t\t\t\t\t\t\tblock.ReceivedAt = task.time\n\n\t\t\t\t\t\t\tcomplete = append(complete, block)\n\t\t\t\t\t\t\tf.completing[hash] = announce\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Otherwise add to the list of blocks needing completion\n\t\t\t\t\t\tincomplete = append(incomplete, announce)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlog.Trace(\"Block already imported, discarding header\", \"peer\", announce.origin, \"number\", header.Number, \"hash\", header.Hash())\n\t\t\t\t\t\tf.forgetHash(hash)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// BlockFetcher doesn't know about it, add to the return list\n\t\t\t\t\tunknown = append(unknown, header)\n\t\t\t\t}\n\t\t\t}\n\t\t\theaderFilterOutMeter.Mark(int64(len(unknown)))\n\t\t\tselect {\n\t\t\tcase filter <- &headerFilterTask{headers: unknown, time: task.time}:\n\t\t\tcase <-f.quit:\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Schedule the retrieved headers for body completion\n\t\t\tfor _, announce := range incomplete {\n\t\t\t\thash := announce.header.Hash()\n\t\t\t\tif _, ok := f.completing[hash]; ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tf.fetched[hash] = append(f.fetched[hash], announce)\n\t\t\t\tif len(f.fetched) == 1 {\n\t\t\t\t\tf.rescheduleComplete(completeTimer)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Schedule the header for light fetcher import\n\t\t\tfor _, announce := range lightHeaders {\n\t\t\t\tf.enqueue(announce.origin, announce.header, nil)\n\t\t\t}\n\t\t\t// Schedule the header-only blocks for import\n\t\t\tfor _, block := range complete {\n\t\t\t\tif announce := f.completing[block.Hash()]; announce != nil {\n\t\t\t\t\tf.enqueue(announce.origin, nil, block)\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase filter := <-f.bodyFilter:\n\t\t\t// Block bodies arrived, extract any explicitly requested blocks, return the rest\n\t\t\tvar task *bodyFilterTask\n\t\t\tselect {\n\t\t\tcase task = <-filter:\n\t\t\tcase <-f.quit:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tbodyFilterInMeter.Mark(int64(len(task.transactions)))\n\t\t\tblocks := []*types.Block{}\n\t\t\t// abort early if there's nothing explicitly requested\n\t\t\tif len(f.completing) > 0 {\n\t\t\t\tfor i := 0; i < len(task.transactions) && i < len(task.uncles); i++ {\n\t\t\t\t\t// Match up a body to any possible completion request\n\t\t\t\t\tvar (\n\t\t\t\t\t\tmatched   = false\n\t\t\t\t\t\tuncleHash common.Hash // calculated lazily and reused\n\t\t\t\t\t\ttxnHash   common.Hash // calculated lazily and reused\n\t\t\t\t\t)\n\t\t\t\t\tfor hash, announce := range f.completing {\n\t\t\t\t\t\tif f.queued[hash] != nil || announce.origin != task.peer {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif uncleHash == (common.Hash{}) {\n\t\t\t\t\t\t\tuncleHash = types.CalcUncleHash(task.uncles[i])\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif uncleHash != announce.header.UncleHash {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif txnHash == (common.Hash{}) {\n\t\t\t\t\t\t\ttxnHash = types.DeriveSha(types.Transactions(task.transactions[i]), new(trie.Trie))\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif txnHash != announce.header.TxHash {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Mark the body matched, reassemble if still unknown\n\t\t\t\t\t\tmatched = true\n\t\t\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\t\t\tblock := types.NewBlockWithHeader(announce.header).WithBody(task.transactions[i], task.uncles[i])\n\t\t\t\t\t\t\tblock.ReceivedAt = task.time\n\t\t\t\t\t\t\tblocks = append(blocks, block)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tf.forgetHash(hash)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\t\t\t\t\tif matched {\n\t\t\t\t\t\ttask.transactions = append(task.transactions[:i], task.transactions[i+1:]...)\n\t\t\t\t\t\ttask.uncles = append(task.uncles[:i], task.uncles[i+1:]...)\n\t\t\t\t\t\ti--\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tbodyFilterOutMeter.Mark(int64(len(task.transactions)))\n\t\t\tselect {\n\t\t\tcase filter <- task:\n\t\t\tcase <-f.quit:\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Schedule the retrieved blocks for ordered import\n\t\t\tfor _, block := range blocks {\n\t\t\t\tif announce := f.completing[block.Hash()]; announce != nil {\n\t\t\t\t\tf.enqueue(announce.origin, nil, block)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client UsageClient) ListSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (m Migrator) Migrate2to3(ctx sdk.Context) error {\n\treturn v3.MigrateStore(ctx, m.keeper.accountKeeper)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) MonitorAddConfig(ctx context.Context, in *clientpb.MonitoringProvider, opts ...grpc.CallOption) (*commonpb.Response, error) {\n\tout := new(commonpb.Response)\n\terr := c.cc.Invoke(ctx, SliverRPC_MonitorAddConfig_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func init() {\n\trouters = make([]testInfo, 0)\n\t// match example\n\trouters = append(routers, matchTestInfo(\"/topic/?:auth:int\", \"/topic\", nil))\n\trouters = append(routers, matchTestInfo(\"/topic/?:auth:int\", \"/topic/123\", map[string]string{\":auth\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/topic/:id/?:auth\", \"/topic/1\", map[string]string{\":id\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/topic/:id/?:auth\", \"/topic/1/2\", map[string]string{\":id\": \"1\", \":auth\": \"2\"}))\n\trouters = append(routers, matchTestInfo(\"/topic/:id/?:auth:int\", \"/topic/1\", map[string]string{\":id\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/topic/:id/?:auth:int\", \"/topic/1/123\", map[string]string{\":id\": \"1\", \":auth\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/:id\", \"/123\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/hello/?:id\", \"/hello\", map[string]string{\":id\": \"\"}))\n\trouters = append(routers, matchTestInfo(\"/\", \"/\", nil))\n\trouters = append(routers, matchTestInfo(\"/customer/login\", \"/customer/login\", nil))\n\trouters = append(routers, matchTestInfo(\"/customer/login\", \"/customer/login.json\", map[string]string{\":ext\": \"json\"}))\n\trouters = append(routers, matchTestInfo(\"/*\", \"/http://customer/123/\", map[string]string{\":splat\": \"http://customer/123/\"}))\n\trouters = append(routers, matchTestInfo(\"/*\", \"/customer/2009/12/11\", map[string]string{\":splat\": \"customer/2009/12/11\"}))\n\trouters = append(routers, matchTestInfo(\"/aa/*/bb\", \"/aa/2009/bb\", map[string]string{\":splat\": \"2009\"}))\n\trouters = append(routers, matchTestInfo(\"/cc/*/dd\", \"/cc/2009/11/dd\", map[string]string{\":splat\": \"2009/11\"}))\n\trouters = append(routers, matchTestInfo(\"/cc/:id/*\", \"/cc/2009/11/dd\", map[string]string{\":id\": \"2009\", \":splat\": \"11/dd\"}))\n\trouters = append(routers, matchTestInfo(\"/ee/:year/*/ff\", \"/ee/2009/11/ff\", map[string]string{\":year\": \"2009\", \":splat\": \"11\"}))\n\trouters = append(routers, matchTestInfo(\"/thumbnail/:size/uploads/*\", \"/thumbnail/100x100/uploads/items/2014/04/20/dPRCdChkUd651t1Hvs18.jpg\", map[string]string{\":size\": \"100x100\", \":splat\": \"items/2014/04/20/dPRCdChkUd651t1Hvs18.jpg\"}))\n\trouters = append(routers, matchTestInfo(\"/*.*\", \"/nice/api.json\", map[string]string{\":path\": \"nice/api\", \":ext\": \"json\"}))\n\trouters = append(routers, matchTestInfo(\"/:name/*.*\", \"/nice/api.json\", map[string]string{\":name\": \"nice\", \":path\": \"api\", \":ext\": \"json\"}))\n\trouters = append(routers, matchTestInfo(\"/:name/test/*.*\", \"/nice/test/api.json\", map[string]string{\":name\": \"nice\", \":path\": \"api\", \":ext\": \"json\"}))\n\trouters = append(routers, matchTestInfo(\"/dl/:width:int/:height:int/*.*\", \"/dl/48/48/05ac66d9bda00a3acf948c43e306fc9a.jpg\", map[string]string{\":width\": \"48\", \":height\": \"48\", \":ext\": \"jpg\", \":path\": \"05ac66d9bda00a3acf948c43e306fc9a\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id:int\", \"/v1/shop/123\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id\\\\((a|b|c)\\\\)\", \"/v1/shop/123(a)\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id\\\\((a|b|c)\\\\)\", \"/v1/shop/123(b)\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id\\\\((a|b|c)\\\\)\", \"/v1/shop/123(c)\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/:year:int/:month:int/:id/:endid\", \"/1111/111/aaa/aaa\", map[string]string{\":year\": \"1111\", \":month\": \"111\", \":id\": \"aaa\", \":endid\": \"aaa\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id/:name\", \"/v1/shop/123/nike\", map[string]string{\":id\": \"123\", \":name\": \"nike\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id/account\", \"/v1/shop/123/account\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:name:string\", \"/v1/shop/nike\", map[string]string{\":name\": \"nike\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id([0-9]+)\", \"/v1/shop//123\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id([0-9]+)_:name\", \"/v1/shop/123_nike\", map[string]string{\":id\": \"123\", \":name\": \"nike\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/:id(.+)_cms.html\", \"/v1/shop/123_cms.html\", map[string]string{\":id\": \"123\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/shop/cms_:id(.+)_:page(.+).html\", \"/v1/shop/cms_123_1.html\", map[string]string{\":id\": \"123\", \":page\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/:v/cms/aaa_:id(.+)_:page(.+).html\", \"/v1/2/cms/aaa_123_1.html\", map[string]string{\":v\": \"2\", \":id\": \"123\", \":page\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/:v/cms_:id(.+)_:page(.+).html\", \"/v1/2/cms_123_1.html\", map[string]string{\":v\": \"2\", \":id\": \"123\", \":page\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/v1/:v(.+)_cms/ttt_:id(.+)_:page(.+).html\", \"/v1/2_cms/ttt_123_1.html\", map[string]string{\":v\": \"2\", \":id\": \"123\", \":page\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/api/projects/:pid/members/?:mid\", \"/api/projects/1/members\", map[string]string{\":pid\": \"1\"}))\n\trouters = append(routers, matchTestInfo(\"/api/projects/:pid/members/?:mid\", \"/api/projects/1/members/2\", map[string]string{\":pid\": \"1\", \":mid\": \"2\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/?:month/?:day\", \"/2020/11/10\", map[string]string{\":year\": \"2020\", \":month\": \"11\", \":day\": \"10\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/?:month/?:day\", \"/2020/11\", map[string]string{\":year\": \"2020\", \":month\": \"11\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year\", \"/2020\", map[string]string{\":year\": \"2020\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year([0-9]+)/?:month([0-9]+)/mid/?:day([0-9]+)/?:hour([0-9]+)\", \"/2020/11/mid/10/24\", map[string]string{\":year\": \"2020\", \":month\": \"11\", \":day\": \"10\", \":hour\": \"24\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/?:month/mid/?:day/?:hour\", \"/2020/mid/10\", map[string]string{\":year\": \"2020\", \":day\": \"10\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/?:month/mid/?:day/?:hour\", \"/2020/11/mid\", map[string]string{\":year\": \"2020\", \":month\": \"11\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/?:month/mid/?:day/?:hour\", \"/mid/10/24\", map[string]string{\":day\": \"10\", \":hour\": \"24\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year([0-9]+)/:month([0-9]+)/mid/:day([0-9]+)/?:hour([0-9]+)\", \"/2020/11/mid/10/24\", map[string]string{\":year\": \"2020\", \":month\": \"11\", \":day\": \"10\", \":hour\": \"24\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/:month/mid/:day/?:hour\", \"/11/mid/10/24\", map[string]string{\":month\": \"11\", \":day\": \"10\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/:month/mid/:day/?:hour\", \"/2020/11/mid/10\", map[string]string{\":year\": \"2020\", \":month\": \"11\", \":day\": \"10\"}))\n\trouters = append(routers, matchTestInfo(\"/?:year/:month/mid/:day/?:hour\", \"/11/mid/10\", map[string]string{\":month\": \"11\", \":day\": \"10\"}))\n\t// not match example\n\n\t// https://github.com/beego/beego/v2/issues/3865\n\trouters = append(routers, notMatchTestInfo(\"/read_:id:int\\\\.htm\", \"/read_222htm\"))\n\trouters = append(routers, notMatchTestInfo(\"/read_:id:int\\\\.htm\", \"/read_222_htm\"))\n\trouters = append(routers, notMatchTestInfo(\"/read_:id:int\\\\.htm\", \" /read_262shtm\"))\n\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_wrapTLS_OK(t *testing.T) {\n\tconfig := Config{\n\t\tCAFile:         \"../test/ca/root.cer\",\n\t\tCertFile:       \"../test/key/ourdomain.cer\",\n\t\tKeyFile:        \"../test/key/ourdomain.key\",\n\t\tVerifyOutgoing: true,\n\t}\n\n\tclient, errc := startTLSServer(&config)\n\tif client == nil {\n\t\tt.Fatalf(\"startTLSServer err: %v\", <-errc)\n\t}\n\n\tc, err := NewConfigurator(config, nil)\n\trequire.NoError(t, err)\n\n\ttlsClient, err := c.wrapTLSClient(\"dc1\", client)\n\trequire.NoError(t, err)\n\n\ttlsClient.Close()\n\terr = <-errc\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerBadAppPathOK(c *C) {\n\t// we actually support this, but don't validate it here\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: ../../../bin/echo\n`\n\td := emptyContainer(c)\n\n\t// snapdir does not contain the app, but the command is\n\t// \"outside\" so it might be OK\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(d, info, discard)\n\tc.Check(err, IsNil)\n}", "is_vulnerable": 1}
{"code": "func TestHg(t *testing.T) {\n\n\ttempDir, err := ioutil.TempDir(\"\", \"go-vcs-hg-tests\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer func() {\n\t\terr = os.RemoveAll(tempDir)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}()\n\n\trepo, err := NewHgRepo(\"http://hg.code.sf.net/p/vcstesthgrepo/code\", tempDir+\"/testhgrepo\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tif repo.Vcs() != Hg {\n\t\tt.Error(\"Hg is detecting the wrong type\")\n\t}\n\n\t// Check the basic getters.\n\tif repo.Remote() != \"http://hg.code.sf.net/p/vcstesthgrepo/code\" {\n\t\tt.Error(\"Remote not set properly\")\n\t}\n\tif repo.LocalPath() != tempDir+\"/testhgrepo\" {\n\t\tt.Error(\"Local disk location not set properly\")\n\t}\n\n\t//Logger = log.New(os.Stdout, \"\", log.LstdFlags)\n\n\t// Do an initial clone.\n\terr = repo.Get()\n\tif err != nil {\n\t\tt.Errorf(\"Unable to clone Hg repo. Err was %s\", err)\n\t}\n\n\t// Verify Hg repo is a Hg repo\n\tif !repo.CheckLocal() {\n\t\tt.Error(\"Problem checking out repo or Hg CheckLocal is not working\")\n\t}\n\n\t// Test internal lookup mechanism used outside of Hg specific functionality.\n\tltype, err := DetectVcsFromFS(tempDir + \"/testhgrepo\")\n\tif err != nil {\n\t\tt.Error(\"detectVcsFromFS unable to Hg repo\")\n\t}\n\tif ltype != Hg {\n\t\tt.Errorf(\"detectVcsFromFS detected %s instead of Hg type\", ltype)\n\t}\n\n\t// Test NewRepo on existing checkout. This should simply provide a working\n\t// instance without error based on looking at the local directory.\n\tnrepo, nrerr := NewRepo(\"http://hg.code.sf.net/p/vcstesthgrepo/code\", tempDir+\"/testhgrepo\")\n\tif nrerr != nil {\n\t\tt.Error(nrerr)\n\t}\n\t// Verify the right oject is returned. It will check the local repo type.\n\tif !nrepo.CheckLocal() {\n\t\tt.Error(\"Wrong version returned from NewRepo\")\n\t}\n\n\tv, err := repo.Current()\n\tif err != nil {\n\t\tt.Errorf(\"Error trying Hg Current: %s\", err)\n\t}\n\tif v != \"default\" {\n\t\tt.Errorf(\"Current failed to detect Hg on tip of default. Got version: %s\", v)\n\t}\n\n\t// Set the version using the short hash.\n\terr = repo.UpdateVersion(\"059e82823f3e\")\n\tif err != nil {\n\t\tt.Errorf(\"Unable to update Hg repo version. Err was %s\", err)\n\t}\n\n\t// Use Version to verify we are on the right version.\n\tv, err = repo.Version()\n\tif v != \"059e82823f3ec23fceb532621ee7c15d5624f35f\" {\n\t\tt.Errorf(\"Error checking checked out Hg version: %s\", v)\n\t}\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tv, err = repo.Current()\n\tif err != nil {\n\t\tt.Errorf(\"Error trying Hg Current for ref: %s\", err)\n\t}\n\tif v != \"059e82823f3ec23fceb532621ee7c15d5624f35f\" {\n\t\tt.Errorf(\"Current failed to detect Hg on ref of branch. Got version: %s\", v)\n\t}\n\n\t// Use Date to verify we are on the right commit.\n\td, err := repo.Date()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif d.Format(longForm) != \"2022-03-21 15:53:47 -0400\" {\n\t\tt.Error(\"Error checking checked out Hg commit date. Got wrong date:\", d)\n\t}\n\n\t// Perform an update.\n\terr = repo.Update()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\tv, err = repo.Version()\n\tif v != \"c068171728d3cc343fef21ffdff43cdb14e3c716\" {\n\t\tt.Errorf(\"Error checking checked out Hg version: %s\", v)\n\t}\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\ttags, err := repo.Tags()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif tags[1] != \"1.0.0\" {\n\t\tt.Error(\"Hg tags is not reporting the correct version\")\n\t}\n\n\ttags, err = repo.TagsFromCommit(\"059e82823f3e\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif len(tags) != 0 {\n\t\tt.Error(\"Hg is incorrectly returning tags for a commit\")\n\t}\n\n\ttags, err = repo.TagsFromCommit(\"96379533a643\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif len(tags) != 1 || tags[0] != \"1.0.0\" {\n\t\tt.Error(\"Hg is incorrectly returning tags for a commit\")\n\t}\n\n\tbranches, err := repo.Branches()\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\t// The branches should be HEAD, master, and test.\n\tif branches[0] != \"test\" {\n\t\tt.Error(\"Hg is incorrectly returning branches\")\n\t}\n\n\tif !repo.IsReference(\"1.0.0\") {\n\t\tt.Error(\"Hg is reporting a reference is not one\")\n\t}\n\n\tif !repo.IsReference(\"test\") {\n\t\tt.Error(\"Hg is reporting a reference is not one\")\n\t}\n\n\tif repo.IsReference(\"foo\") {\n\t\tt.Error(\"Hg is reporting a non-existent reference is one\")\n\t}\n\n\tif repo.IsDirty() {\n\t\tt.Error(\"Hg incorrectly reporting dirty\")\n\t}\n\n\tci, err := repo.CommitInfo(\"72a363187366\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tif ci.Commit != \"72a3631873669f4bd4c41e4d9146104e1e55e767\" {\n\t\tt.Error(\"Hg.CommitInfo wrong commit id\")\n\t}\n\tif ci.Author != \"Matt Farina <matt@mattfarina.com>\" {\n\t\tt.Error(\"Hg.CommitInfo wrong author\")\n\t}\n\tif ci.Message != \"Removing a\" {\n\t\tt.Error(\"Hg.CommitInfo wrong message\")\n\t}\n\n\tti := time.Unix(1647898961, 0)\n\tif !ti.Equal(ci.Date) {\n\t\tt.Error(\"Hg.CommitInfo wrong date\")\n\t}\n\n\t_, err = repo.CommitInfo(\"asdfasdfasdf\")\n\tif err != ErrRevisionUnavailable {\n\t\tt.Error(\"Hg didn't return expected ErrRevisionUnavailable\")\n\t}\n\n\ttempDir2, err := ioutil.TempDir(\"\", \"go-vcs-hg-tests-export\")\n\tif err != nil {\n\t\tt.Fatalf(\"Error creating temp directory: %s\", err)\n\t}\n\tdefer func() {\n\t\terr = os.RemoveAll(tempDir2)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}()\n\n\texportDir := filepath.Join(tempDir2, \"src\")\n\n\terr = repo.ExportDir(exportDir)\n\tif err != nil {\n\t\tt.Errorf(\"Unable to export Hg repo. Err was %s\", err)\n\t}\n\n\t_, err = os.Stat(filepath.Join(exportDir, \"README.md\"))\n\tif err != nil {\n\t\tt.Errorf(\"Error checking exported file in Hg: %s\", err)\n\t}\n\n\t_, err = os.Stat(filepath.Join(exportDir, string(repo.Vcs())))\n\tif err != nil {\n\t\tif found := os.IsNotExist(err); !found {\n\t\t\tt.Errorf(\"Error checking exported metadata in Hg: %s\", err)\n\t\t}\n\t} else {\n\t\tt.Error(\"Error checking Hg metadata. It exists.\")\n\t}\n}", "is_vulnerable": 0}
{"code": "\tg.POST(\"/tag\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing user in session\")\n\t\t}\n\n\t\ttagUpsert := &api.TagUpsert{\n\t\t\tCreatorID: userID,\n\t\t}\n\t\tif err := json.NewDecoder(c.Request().Body).Decode(tagUpsert); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Malformatted post tag request\").SetInternal(err)\n\t\t}\n\t\tif tagUpsert.Name == \"\" {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Tag name shouldn't be empty\")\n\t\t}\n\n\t\ttag, err := s.Store.UpsertTag(ctx, tagUpsert)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to upsert tag\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"tag created\",\n\t\t})\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(tag.Name)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode tag response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "func newHandlerRole(namespace string) *rbacv1.Role {\n\treturn &rbacv1.Role{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"Role\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: namespace,\n\t\t\tName:      HandlerServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRules: []rbacv1.PolicyRule{\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"configmaps\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func NewMachine(opts machine.InitOptions) (machine.VM, error) {\n\tvmConfigDir, err := machine.GetConfDir(vmtype)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvm := new(MachineVM)\n\tif len(opts.Name) > 0 {\n\t\tvm.Name = opts.Name\n\t}\n\tignitionFile := filepath.Join(vmConfigDir, vm.Name+\".ign\")\n\tvm.IgnitionFilePath = ignitionFile\n\n\t// An image was specified\n\tif len(opts.ImagePath) > 0 {\n\t\tvm.ImagePath = opts.ImagePath\n\t}\n\n\t// Assign remote user name. if not provided, use default\n\tvm.RemoteUsername = opts.Username\n\tif len(vm.RemoteUsername) < 1 {\n\t\tvm.RemoteUsername = defaultRemoteUser\n\t}\n\n\t// Add a random port for ssh\n\tport, err := utils.GetRandomPort()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvm.Port = port\n\n\tvm.CPUs = opts.CPUS\n\tvm.Memory = opts.Memory\n\n\t// Look up the executable\n\texecPath, err := exec.LookPath(QemuCommand)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcmd := append([]string{execPath})\n\t// Add memory\n\tcmd = append(cmd, []string{\"-m\", strconv.Itoa(int(vm.Memory))}...)\n\t// Add cpus\n\tcmd = append(cmd, []string{\"-smp\", strconv.Itoa(int(vm.CPUs))}...)\n\t// Add ignition file\n\tcmd = append(cmd, []string{\"-fw_cfg\", \"name=opt/com.coreos/config,file=\" + vm.IgnitionFilePath}...)\n\t// Add qmp socket\n\tmonitor, err := NewQMPMonitor(\"unix\", vm.Name, defaultQMPTimeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvm.QMPMonitor = monitor\n\tcmd = append(cmd, []string{\"-qmp\", monitor.Network + \":/\" + monitor.Address + \",server=on,wait=off\"}...)\n\n\t// Add network\n\tcmd = append(cmd, \"-nic\", \"user,model=virtio,hostfwd=tcp::\"+strconv.Itoa(vm.Port)+\"-:22\")\n\n\tsocketPath, err := getSocketDir()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvirtualSocketPath := filepath.Join(socketPath, \"podman\", vm.Name+\"_ready.sock\")\n\t// Add serial port for readiness\n\tcmd = append(cmd, []string{\n\t\t\"-device\", \"virtio-serial\",\n\t\t\"-chardev\", \"socket,path=\" + virtualSocketPath + \",server=on,wait=off,id=\" + vm.Name + \"_ready\",\n\t\t\"-device\", \"virtserialport,chardev=\" + vm.Name + \"_ready\" + \",name=org.fedoraproject.port.0\"}...)\n\tvm.CmdLine = cmd\n\treturn vm, nil\n}", "is_vulnerable": 1}
{"code": "func FsList(c *gin.Context) {\n\tvar req ListReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\treq.Validate()\n\tuser := c.MustGet(\"user\").(*model.User)\n\treq.Path = stdpath.Join(user.BasePath, req.Path)\n\tmeta, err := db.GetNearestMeta(req.Path)\n\tif err != nil {\n\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\treturn\n\t\t}\n\t}\n\tc.Set(\"meta\", meta)\n\tif !common.CanAccess(user, meta, req.Path, req.Password) {\n\t\tcommon.ErrorStrResp(c, \"password is incorrect\", 403)\n\t\treturn\n\t}\n\tif !user.CanWrite() && !common.CanWrite(meta, req.Path) && req.Refresh {\n\t\tcommon.ErrorStrResp(c, \"Refresh without permission\", 403)\n\t\treturn\n\t}\n\tobjs, err := fs.List(c, req.Path, req.Refresh)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\ttotal, objs := pagination(objs, &req.PageReq)\n\tprovider := \"unknown\"\n\tstorage, err := fs.GetStorage(req.Path)\n\tif err == nil {\n\t\tprovider = storage.GetStorage().Driver\n\t}\n\tcommon.SuccessResp(c, FsListResp{\n\t\tContent:  toObjResp(objs, req.Path, isEncrypt(meta, req.Path)),\n\t\tTotal:    int64(total),\n\t\tReadme:   getReadme(meta, req.Path),\n\t\tWrite:    user.CanWrite() || common.CanWrite(meta, req.Path),\n\t\tProvider: provider,\n\t})\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) ExportTemplateSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "\t\tdefer func() {\n\t\t\tresetErr := setUids(ruid, euid, suid)\n\t\t\tif resetErr != nil {\n\t\t\t\terr = resetErr\n\t\t\t}\n\t\t}()", "is_vulnerable": 0}
{"code": "func TakeOwnership(rw io.ReadWriter, newOwnerAuth Digest, newSRKAuth Digest, pubEK []byte) error {\n\n\t// Encrypt the owner and SRK auth with the endorsement key.\n\tek, err := UnmarshalPubRSAPublicKey(pubEK)\n\tif err != nil {\n\t\treturn err\n\t}\n\tencOwnerAuth, err := rsa.EncryptOAEP(sha1.New(), rand.Reader, ek, newOwnerAuth[:], oaepLabel)\n\tif err != nil {\n\t\treturn err\n\t}\n\tencSRKAuth, err := rsa.EncryptOAEP(sha1.New(), rand.Reader, ek, newSRKAuth[:], oaepLabel)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The params for the SRK have very tight requirements:\n\t// - KeyLength must be 2048\n\t// - alg must be RSA\n\t// - Enc must be OAEP SHA1 MGF1\n\t// - Sig must be None\n\t// - Key usage must be Storage\n\t// - Key must not be migratable\n\tsrkRSAParams := rsaKeyParams{\n\t\tKeyLength: 2048,\n\t\tNumPrimes: 2,\n\t}\n\tsrkpb, err := tpmutil.Pack(srkRSAParams)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsrkParams := keyParams{\n\t\tAlgID:     AlgRSA,\n\t\tEncScheme: esRSAEsOAEPSHA1MGF1,\n\t\tSigScheme: ssNone,\n\t\tParams:    srkpb,\n\t}\n\tsrk := &key{\n\t\tVersion:         0x01010000,\n\t\tKeyUsage:        keyStorage,\n\t\tKeyFlags:        0,\n\t\tAuthDataUsage:   authAlways,\n\t\tAlgorithmParams: srkParams,\n\t}\n\n\t// Get command auth using OIAP with the new owner auth.\n\toiapr, err := oiap(rw)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer oiapr.Close(rw)\n\n\t// The digest for TakeOwnership is\n\t//\n\t// SHA1(ordTakeOwnership || pidOwner || encOwnerAuth || encSRKAuth || srk)\n\tauthIn := []interface{}{ordTakeOwnership, pidOwner, encOwnerAuth, encSRKAuth, srk}\n\tca, err := newCommandAuth(oiapr.AuthHandle, oiapr.NonceEven, newOwnerAuth[:], authIn)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tk, ra, ret, err := takeOwnership(rw, encOwnerAuth, encSRKAuth, srk, ca)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\traIn := []interface{}{ret, ordTakeOwnership, k}\n\treturn ra.verify(ca.NonceOdd, newOwnerAuth[:], raIn)\n}", "is_vulnerable": 1}
{"code": "func FindClientIP(r *http.Request) string {\n\theaders := []string{\"X-Forwarded-For\", \"X-Real-Ip\"}\n\tfor _, header := range headers {\n\t\tvalue := r.Header.Get(header)\n\n\t\tif value != \"\" {\n\t\t\taddresses := strings.Split(value, \",\")\n\t\t\taddress := strings.TrimSpace(addresses[0])\n\t\t\taddress = dropIPv6zone(address)\n\n\t\t\tif net.ParseIP(address) != nil {\n\t\t\t\treturn address\n\t\t\t}\n\t\t}\n\t}\n\n\t// Fallback to TCP/IP source IP address.\n\treturn FindRemoteIP(r)\n}", "is_vulnerable": 0}
{"code": "func TestBasicTokenFile(t *testing.T) {\n\ttoken := \"exampletoken\"\n\tf, err := ioutil.TempFile(\"\", \"tokenfile\")\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t\treturn\n\t}\n\tdefer os.Remove(f.Name())\n\tif err := ioutil.WriteFile(f.Name(), []byte(token), 0644); err != nil {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t\treturn\n\t}\n\n\tconfig := clientcmdapi.NewConfig()\n\tconfig.Clusters[\"clean\"] = &clientcmdapi.Cluster{\n\t\tServer: \"https://localhost:8443\",\n\t}\n\tconfig.AuthInfos[\"clean\"] = &clientcmdapi.AuthInfo{\n\t\tTokenFile: f.Name(),\n\t}\n\tconfig.Contexts[\"clean\"] = &clientcmdapi.Context{\n\t\tCluster:  \"clean\",\n\t\tAuthInfo: \"clean\",\n\t}\n\tconfig.CurrentContext = \"clean\"\n\n\tclientBuilder := NewNonInteractiveClientConfig(*config, \"clean\", &ConfigOverrides{}, nil)\n\n\tclientConfig, err := clientBuilder.ClientConfig()\n\tif err != nil {\n\t\tt.Fatalf(\"Unexpected error: %v\", err)\n\t}\n\n\tmatchStringArg(token, clientConfig.BearerToken, t)\n}", "is_vulnerable": 0}
{"code": "func Test_buildMainHTTPConnectionManagerFilter(t *testing.T) {\n\tb := New(\"local-grpc\", \"local-http\", \"local-metrics\", nil, nil)\n\n\toptions := config.NewDefaultOptions()\n\toptions.SkipXffAppend = true\n\toptions.XffNumTrustedHops = 1\n\tfilter, err := b.buildMainHTTPConnectionManagerFilter(options, []string{\"example.com\"}, \"*\")\n\trequire.NoError(t, err)\n\ttestutil.AssertProtoJSONEqual(t, `{\n\t\t\"name\": \"envoy.filters.network.http_connection_manager\",\n\t\t\"typedConfig\": {\n\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\",\n\t\t\t\"accessLog\": [{\n\t\t\t\t\"name\": \"envoy.access_loggers.http_grpc\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.access_loggers.grpc.v3.HttpGrpcAccessLogConfig\",\n\t\t\t\t\t\"commonConfig\": {\n\t\t\t\t\t\t\"grpcService\": {\n\t\t\t\t\t\t\t\"envoyGrpc\": {\n\t\t\t\t\t\t\t\t\"clusterName\": \"pomerium-control-plane-grpc\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"logName\": \"ingress-http\",\n\t\t\t\t\t\t\"transportApiVersion\": \"V3\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}],\n\t\t\t\"codecType\": \"HTTP1\",\n\t\t\t\"commonHttpProtocolOptions\": {\n\t\t\t\t\"idleTimeout\": \"300s\"\n\t\t\t},\n\t\t\t\"httpFilters\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.lua\",\n\t\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua\",\n\t\t\t\t\t\t\"inlineCode\": \"local function starts_with(str, start)\\n    return str:sub(1, #start) == start\\nend\\n\\nfunction envoy_on_request(request_handle)\\n    local headers = request_handle:headers()\\n    local metadata = request_handle:metadata()\\n\\n    local remove_impersonate_headers = metadata:get(\\\"remove_impersonate_headers\\\")\\n    if remove_impersonate_headers then\\n        local to_remove = {}\\n        for k, v in pairs(headers) do\\n            if starts_with(k, \\\"impersonate-extra-\\\") or k == \\\"impersonate-group\\\" or k == \\\"impersonate-user\\\" then\\n                table.insert(to_remove, k)\\n            end\\n        end\\n\\n        for k, v in pairs(to_remove) do\\n            headers:remove(v)\\n        end\\n    end\\nend\\n\\nfunction envoy_on_response(response_handle)\\nend\\n\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.ext_authz\",\n\t\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz\",\n\t\t\t\t\t\t\"grpcService\": {\n\t\t\t\t\t\t\t\"envoyGrpc\": {\n\t\t\t\t\t\t\t\t\"clusterName\": \"pomerium-authorize\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"timeout\": \"10s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"includePeerCertificate\": true,\n\t\t\t\t\t\t\"statusOnError\": {\n\t\t\t\t\t\t\t\"code\": \"InternalServerError\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"transportApiVersion\": \"V3\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.lua\",\n\t\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua\",\n\t\t\t\t\t\t\"inlineCode\": \"function envoy_on_request(request_handle)\\n    local headers = request_handle:headers()\\n    local dynamic_meta = request_handle:streamInfo():dynamicMetadata()\\n    if headers:get(\\\"x-pomerium-set-cookie\\\") ~= nil then\\n        dynamic_meta:set(\\\"envoy.filters.http.lua\\\", \\\"pomerium_set_cookie\\\",\\n                         headers:get(\\\"x-pomerium-set-cookie\\\"))\\n        headers:remove(\\\"x-pomerium-set-cookie\\\")\\n    end\\nend\\n\\nfunction envoy_on_response(response_handle)\\n    local headers = response_handle:headers()\\n    local dynamic_meta = response_handle:streamInfo():dynamicMetadata()\\n    local tbl = dynamic_meta:get(\\\"envoy.filters.http.lua\\\")\\n    if tbl ~= nil and tbl[\\\"pomerium_set_cookie\\\"] ~= nil then\\n        headers:add(\\\"set-cookie\\\", tbl[\\\"pomerium_set_cookie\\\"])\\n    end\\nend\\n\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.lua\",\n\t\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua\",\n\t\t\t\t\t\t\"inlineCode\": \"function remove_pomerium_cookie(cookie_name, cookie)\\n    -- lua doesn't support optional capture groups\\n    -- so we replace twice to handle pomerium=xyz at the end of the string\\n    cookie = cookie:gsub(cookie_name .. \\\"=[^;]+; \\\", \\\"\\\")\\n    cookie = cookie:gsub(cookie_name .. \\\"=[^;]+\\\", \\\"\\\")\\n    return cookie\\nend\\n\\nfunction has_prefix(str, prefix)\\n    return str ~= nil and str:sub(1, #prefix) == prefix\\nend\\n\\nfunction envoy_on_request(request_handle)\\n    local headers = request_handle:headers()\\n    local metadata = request_handle:metadata()\\n\\n    local remove_cookie_name = metadata:get(\\\"remove_pomerium_cookie\\\")\\n    if remove_cookie_name then\\n        local cookie = headers:get(\\\"cookie\\\")\\n        if cookie ~= nil then\\n            newcookie = remove_pomerium_cookie(remove_cookie_name, cookie)\\n            headers:replace(\\\"cookie\\\", newcookie)\\n        end\\n    end\\n\\n    local remove_authorization = metadata:get(\\\"remove_pomerium_authorization\\\")\\n    if remove_authorization then\\n        local authorization = headers:get(\\\"authorization\\\")\\n        local authorization_prefix = \\\"Pomerium \\\"\\n        if has_prefix(authorization, authorization_prefix) then\\n            headers:remove(\\\"authorization\\\")\\n        end\\n\\n        headers:remove('x-pomerium-authorization')\\n    end\\nend\\n\\nfunction envoy_on_response(response_handle) end\\n\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.lua\",\n\t\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua\",\n\t\t\t\t\t\t\"inlineCode\": \"function replace_prefix(str, prefix, value)\\n    return str:gsub(\\\"^\\\"..prefix, value)\\nend\\n\\nfunction envoy_on_request(request_handle)\\nend\\n\\nfunction envoy_on_response(response_handle)\\n    local headers = response_handle:headers()\\n    local metadata = response_handle:metadata()\\n\\n    -- should be in the form:\\n    -- [{\\n    --   \\\"header\\\":\\\"Location\\\",\\n    --   \\\"prefix\\\":\\\"http://localhost:8000/two/\\\",\\n    --   \\\"value\\\":\\\"http://frontend/one/\\\"\\n    -- }]\\n    local rewrite_response_headers = metadata:get(\\\"rewrite_response_headers\\\")\\n    if rewrite_response_headers then\\n        for _, obj in pairs(rewrite_response_headers) do\\n            local hdr = headers:get(obj.header)\\n            if hdr ~= nil then\\n                local newhdr = replace_prefix(hdr, obj.prefix, obj.value)\\n                headers:replace(obj.header, newhdr)\\n            end\\n        end\\n    end\\nend\\n\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"envoy.filters.http.router\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"requestTimeout\": \"30s\",\n\t\t\t\"routeConfig\": {\n\t\t\t\t\"name\": \"main\",\n\t\t\t\t\"virtualHosts\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"name\": \"example.com\",\n\t\t\t\t\t\t\"domains\": [\"example.com\"],\n\t\t\t\t\t\t\"responseHeadersToAdd\": [{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"Strict-Transport-Security\",\n\t\t\t\t\t\t\t\t\"value\": \"max-age=31536000; includeSubDomains; preload\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"X-Frame-Options\",\n\t\t\t\t\t\t\t\t\"value\": \"SAMEORIGIN\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"X-XSS-Protection\",\n\t\t\t\t\t\t\t\t\"value\": \"1; mode=block\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}],\n\t\t\t\t\t\t\"routes\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.pomerium/jwt\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.pomerium/jwt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/ping\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/ping\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/healthz\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/healthz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.pomerium\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.pomerium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-prefix-/.pomerium/\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"prefix\": \"/.pomerium/\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.well-known/pomerium\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.well-known/pomerium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-prefix-/.well-known/pomerium/\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"prefix\": \"/.well-known/pomerium/\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/robots.txt\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/robots.txt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"name\": \"catch-all\",\n\t\t\t\t\t\t\"domains\": [\"*\"],\n\t\t\t\t\t\t\"responseHeadersToAdd\": [{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"Strict-Transport-Security\",\n\t\t\t\t\t\t\t\t\"value\": \"max-age=31536000; includeSubDomains; preload\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"X-Frame-Options\",\n\t\t\t\t\t\t\t\t\"value\": \"SAMEORIGIN\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"append\": false,\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"key\": \"X-XSS-Protection\",\n\t\t\t\t\t\t\t\t\"value\": \"1; mode=block\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}],\n\t\t\t\t\t\t\"routes\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.pomerium/jwt\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.pomerium/jwt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/ping\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/ping\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/healthz\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/healthz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.pomerium\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.pomerium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-prefix-/.pomerium/\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"prefix\": \"/.pomerium/\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/.well-known/pomerium\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/.well-known/pomerium\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-prefix-/.well-known/pomerium/\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"prefix\": \"/.well-known/pomerium/\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"name\": \"pomerium-path-/robots.txt\",\n\t\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\t\"path\": \"/robots.txt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"validateClusters\": false\n\t\t\t},\n\t\t\t\"statPrefix\": \"ingress\",\n\t\t\t\"tracing\": {\n\t\t\t\t\"randomSampling\": {\n\t\t\t\t\t\"value\": 0.01\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"useRemoteAddress\": true,\n\t\t\t\"skipXffAppend\": true,\n\t\t\t\"xffNumTrustedHops\": 1,\n\t\t\t\"localReplyConfig\":{\n\t\t\t\t\"mappers\":[\n\t\t\t\t\t{\n\t\t\t\t\t\t\"filter\":{\n\t\t\t\t\t\t\t\"responseFlagFilter\":{}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"headersToAdd\":[\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"append\":false,\n\t\t\t\t\t\t\t\t\"header\":{\n\t\t\t\t\t\t\t\t\t\"key\":\"Strict-Transport-Security\",\n\t\t\t\t\t\t\t\t\t\"value\":\"max-age=31536000; includeSubDomains; preload\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"append\":false,\n\t\t\t\t\t\t\t\t\"header\":{\n\t\t\t\t\t\t\t\t\t\"key\":\"X-Frame-Options\",\n\t\t\t\t\t\t\t\t\t\"value\":\"SAMEORIGIN\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"append\":false,\n\t\t\t\t\t\t\t\t\"header\":{\n\t\t\t\t\t\t\t\t\t\"key\":\"X-XSS-Protection\",\n\t\t\t\t\t\t\t\t\t\"value\":\"1; mode=block\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t}\n\t}`, filter)\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessRequester) GetGrantedAudience() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetGrantedAudience\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (mr *MockERC20BridgeViewMockRecorder) FindAssetList(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"FindAssetList\", reflect.TypeOf((*MockERC20BridgeView)(nil).FindAssetList), arg0, arg1, arg2)\n}", "is_vulnerable": 1}
{"code": "func TestBlocksStoreQuerier_Labels(t *testing.T) {\n\tt.Parallel()\n\n\tconst (\n\t\tmetricName = \"test_metric\"\n\t\tminT       = int64(10)\n\t\tmaxT       = int64(20)\n\t)\n\n\tvar (\n\t\tblock1  = ulid.MustNew(1, nil)\n\t\tblock2  = ulid.MustNew(2, nil)\n\t\tblock3  = ulid.MustNew(3, nil)\n\t\tblock4  = ulid.MustNew(4, nil)\n\t\tseries1 = labels.FromMap(map[string]string{\n\t\t\tlabels.MetricName: metricName + \"_1\",\n\t\t\t\"series1\":         \"1\",\n\t\t})\n\t\tseries2 = labels.FromMap(map[string]string{\n\t\t\tlabels.MetricName: metricName + \"_2\",\n\t\t\t\"series2\":         \"1\",\n\t\t})\n\t)\n\n\ttests := map[string]struct {\n\t\tfinderResult        bucketindex.Blocks\n\t\tfinderErr           error\n\t\tstoreSetResponses   []interface{}\n\t\texpectedLabelNames  []string\n\t\texpectedLabelValues []string // For __name__\n\t\texpectedErr         string\n\t\texpectedMetrics     string\n\t}{\n\t\t\"no block in the storage matching the query time range\": {\n\t\t\tfinderResult: nil,\n\t\t\texpectedErr:  \"\",\n\t\t},\n\t\t\"error while finding blocks matching the query time range\": {\n\t\t\tfinderErr:   errors.New(\"unable to find blocks\"),\n\t\t\texpectedErr: \"unable to find blocks\",\n\t\t},\n\t\t\"error while getting clients to query the store-gateway\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\terrors.New(\"no client found\"),\n\t\t\t},\n\t\t\texpectedErr: \"no client found\",\n\t\t},\n\t\t\"a single store-gateway instance holds the required blocks\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1, block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1, block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1, block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks without overlapping series\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks with overlapping series (single returned series)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks with overlapping series (multiple returned series)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\t// Block1 has series1 and series2\n\t\t\t// Block2 has only series1\n\t\t\t// Block3 has only series2\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"3.3.3.3\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block3},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\texpectedMetrics: `\n\t\t\t\t# HELP cortex_querier_storegateway_instances_hit_per_query Number of store-gateway instances hit for a single query.\n\t\t\t\t# TYPE cortex_querier_storegateway_instances_hit_per_query histogram\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"2\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"3\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"4\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"5\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"6\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"7\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"8\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"9\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"10\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_sum 3\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_count 1\n\n\t\t\t\t# HELP cortex_querier_storegateway_refetches_per_query Number of re-fetches attempted while querying store-gateway instances due to missing blocks.\n\t\t\t\t# TYPE cortex_querier_storegateway_refetches_per_query histogram\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"0\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"1\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"2\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_sum 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_count 1\n\t\t\t`,\n\t\t},\n\t\t\"a single store-gateway instance has some missing blocks (consistency check failed)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns an error because there are no other store-gateways left.\n\t\t\t\terrors.New(\"no store-gateway remaining after exclude\"),\n\t\t\t},\n\t\t\texpectedErr: fmt.Sprintf(\"consistency check failed because some blocks were not queried: %s\", block2.String()),\n\t\t},\n\t\t\"multiple store-gateway instances have some missing blocks (consistency check failed)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t\t&bucketindex.Block{ID: block3},\n\t\t\t\t&bucketindex.Block{ID: block4},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns an error because there are no other store-gateways left.\n\t\t\t\terrors.New(\"no store-gateway remaining after exclude\"),\n\t\t\t},\n\t\t\texpectedErr: fmt.Sprintf(\"consistency check failed because some blocks were not queried: %s %s\", block3.String(), block4.String()),\n\t\t},\n\t\t\"multiple store-gateway instances have some missing blocks but queried from a replica during subsequent attempts\": {\n\t\t\t// Block1 has series1\n\t\t\t// Block2 has series2\n\t\t\t// Block3 has series1 and series2\n\t\t\t// Block4 has no series (poor lonely block)\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t\t&bucketindex.Block{ID: block2},\n\t\t\t\t&bucketindex.Block{ID: block3},\n\t\t\t\t&bucketindex.Block{ID: block4},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1, block3},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2, block4},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns 1 missing block.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"3.3.3.3\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block3, block4},\n\t\t\t\t},\n\t\t\t\t// Third attempt returns the last missing block.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"4.4.4.4\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    []string{},\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block4),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   []string{},\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block4),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block4},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\texpectedMetrics: `\n\t\t\t\t# HELP cortex_querier_storegateway_instances_hit_per_query Number of store-gateway instances hit for a single query.\n\t\t\t\t# TYPE cortex_querier_storegateway_instances_hit_per_query histogram\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"2\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"3\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"4\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"5\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"6\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"7\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"8\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"9\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"10\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_sum 4\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_count 1\n\n\t\t\t\t# HELP cortex_querier_storegateway_refetches_per_query Number of re-fetches attempted while querying store-gateway instances due to missing blocks.\n\t\t\t\t# TYPE cortex_querier_storegateway_refetches_per_query histogram\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"2\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_sum 2\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_count 1\n\t\t\t`,\n\t\t},\n\t\t\"multiple store-gateways has the block, but one of them fails to return\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t&bucketindex.Block{ID: block1},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesErr: status.Error(codes.Unavailable, \"unavailable\"),\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1),\n\t\t},\n\t}\n\n\tfor testName, testData := range tests {\n\t\ttestData := testData\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\t// Splitting it because we need a new registry for names and values.\n\t\t\t// And also the initial expectedErr checking needs to be done for both.\n\t\t\tfor _, testFunc := range []string{\"LabelNames\", \"LabelValues\"} {\n\t\t\t\tctx := user.InjectOrgID(context.Background(), \"user-1\")\n\t\t\t\treg := prometheus.NewPedanticRegistry()\n\t\t\t\tstores := &blocksStoreSetMock{mockedResponses: testData.storeSetResponses}\n\t\t\t\tfinder := &blocksFinderMock{}\n\t\t\t\tfinder.On(\"GetBlocks\", mock.Anything, \"user-1\", minT, maxT).Return(testData.finderResult, map[ulid.ULID]*bucketindex.BlockDeletionMark(nil), testData.finderErr)\n\n\t\t\t\tq := &blocksStoreQuerier{\n\t\t\t\t\tminT:        minT,\n\t\t\t\t\tmaxT:        maxT,\n\t\t\t\t\tfinder:      finder,\n\t\t\t\t\tstores:      stores,\n\t\t\t\t\tconsistency: NewBlocksConsistencyChecker(0, 0, log.NewNopLogger(), nil),\n\t\t\t\t\tlogger:      log.NewNopLogger(),\n\t\t\t\t\tmetrics:     newBlocksStoreQueryableMetrics(reg),\n\t\t\t\t\tlimits:      &blocksStoreLimitsMock{},\n\t\t\t\t}\n\n\t\t\t\tif testFunc == \"LabelNames\" {\n\t\t\t\t\tnames, warnings, err := q.LabelNames(ctx)\n\t\t\t\t\tif testData.expectedErr != \"\" {\n\t\t\t\t\t\trequire.Equal(t, testData.expectedErr, err.Error())\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.Equal(t, 0, len(warnings))\n\t\t\t\t\trequire.Equal(t, testData.expectedLabelNames, names)\n\n\t\t\t\t\t// Assert on metrics (optional, only for test cases defining it).\n\t\t\t\t\tif testData.expectedMetrics != \"\" {\n\t\t\t\t\t\tassert.NoError(t, testutil.GatherAndCompare(reg, strings.NewReader(testData.expectedMetrics)))\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif testFunc == \"LabelValues\" {\n\t\t\t\t\tvalues, warnings, err := q.LabelValues(ctx, labels.MetricName)\n\t\t\t\t\tif testData.expectedErr != \"\" {\n\t\t\t\t\t\trequire.Equal(t, testData.expectedErr, err.Error())\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.Equal(t, 0, len(warnings))\n\t\t\t\t\trequire.Equal(t, testData.expectedLabelValues, values)\n\n\t\t\t\t\t// Assert on metrics (optional, only for test cases defining it).\n\t\t\t\t\tif testData.expectedMetrics != \"\" {\n\t\t\t\t\t\tassert.NoError(t, testutil.GatherAndCompare(reg, strings.NewReader(testData.expectedMetrics)))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t *TableController) UpdateTableRelation(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tid, err := strconv.Atoi(ctx.Param(\"id\"))\n\tif err != nil {\n\t\te := &response.AdminError{\n\t\t\tErrorCode:    http.StatusBadRequest,\n\t\t\tErrorMessage: err.Error(),\n\t\t}\n\t\t_ = ctx.Error(e)\n\t\treturn\n\t}\n\tvar data request.TableRelationUpdateReq\n\tdata.Id = id\n\ttranslator, _ := t.translators[\"zh\"]\n\terr = utils.ValidatorBody[request.TableRelationUpdateReq](ctx, &data, translator)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\terr = t.sysTableService.UpdateTableRelation(ctx, data)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"at least one repository is required\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"bitbucketserver.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.BitbucketServer)\n\n\tfor name, value := range eventSource.Spec.BitbucketServer {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tBitbucketServerEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (self UploadsPlugins) Call(\n\tctx context.Context,\n\tscope vfilter.Scope,\n\targs *ordereddict.Dict) <-chan vfilter.Row {\n\toutput_chan := make(chan vfilter.Row)\n\n\tgo func() {\n\t\tdefer close(output_chan)\n\n\t\terr := vql_subsystem.CheckAccess(scope, acls.READ_RESULTS)\n\t\tif err != nil {\n\t\t\tscope.Log(\"uploads: %s\", err)\n\t\t\treturn\n\t\t}\n\n\t\targ := &UploadsPluginsArgs{}\n\n\t\tconfig_obj, ok := vql_subsystem.GetServerConfig(scope)\n\t\tif !ok {\n\t\t\tscope.Log(\"Command can only run on the server\")\n\t\t\treturn\n\t\t}\n\n\t\tParseUploadArgsFromScope(arg, scope)\n\n\t\t// Allow the plugin args to override the environment scope.\n\t\terr = arg_parser.ExtractArgsWithContext(ctx, scope, args, arg)\n\t\tif err != nil {\n\t\t\tscope.Log(\"uploads: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tflow_path_manager := paths.NewFlowPathManager(arg.ClientId, arg.FlowId)\n\t\trow_chan, err := file_store.GetTimeRange(ctx, config_obj,\n\t\t\tflow_path_manager.UploadMetadata(), 0, 0)\n\t\tif err != nil {\n\t\t\tscope.Log(\"uploads: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tfor row := range row_chan {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tcase output_chan <- row:\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn output_chan\n}", "is_vulnerable": 0}
{"code": "func Version() string {\n\treturn _VERSION\n}", "is_vulnerable": 1}
{"code": "func TestKubeExtensions(t *testing.T) {\n\tclock := clockwork.NewFakeClock()\n\tca, err := FromKeys([]byte(fixtures.TLSCACertPEM), []byte(fixtures.TLSCAKeyPEM))\n\trequire.NoError(t, err)\n\n\tprivateKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\trequire.NoError(t, err)\n\n\texpires := clock.Now().Add(time.Hour)\n\tidentity := Identity{\n\t\tUsername:     \"alice@example.com\",\n\t\tGroups:       []string{\"admin\"},\n\t\tImpersonator: \"bob@example.com\",\n\t\t// Generate a certificate restricted for\n\t\t// use against a kubernetes endpoint, and not the API server endpoint\n\t\t// otherwise proxies can generate certs for any user.\n\t\tUsage:             []string{teleport.UsageKubeOnly},\n\t\tKubernetesGroups:  []string{\"system:masters\", \"admin\"},\n\t\tKubernetesUsers:   []string{\"IAM#alice@example.com\"},\n\t\tKubernetesCluster: \"kube-cluster\",\n\t\tTeleportCluster:   \"tele-cluster\",\n\t\tRouteToDatabase: RouteToDatabase{\n\t\t\tServiceName: \"postgres-rds\",\n\t\t\tProtocol:    \"postgres\",\n\t\t\tUsername:    \"postgres\",\n\t\t},\n\t\tDatabaseNames: []string{\"postgres\", \"main\"},\n\t\tDatabaseUsers: []string{\"postgres\", \"alice\"},\n\t\tExpires:       expires,\n\t}\n\n\tsubj, err := identity.Subject()\n\trequire.NoError(t, err)\n\n\tcertBytes, err := ca.GenerateCertificate(CertificateRequest{\n\t\tClock:     clock,\n\t\tPublicKey: privateKey.Public(),\n\t\tSubject:   subj,\n\t\tNotAfter:  expires,\n\t})\n\trequire.NoError(t, err)\n\n\tcert, err := ParseCertificatePEM(certBytes)\n\trequire.NoError(t, err)\n\tout, err := FromSubject(cert.Subject, cert.NotAfter)\n\trequire.NoError(t, err)\n\trequire.Empty(t, cmp.Diff(out, &identity))\n}", "is_vulnerable": 0}
{"code": "func (t *transport) writePacket(packet []byte) error {\n\tif debugTransport {\n\t\tt.printPacket(packet, true)\n\t}\n\treturn t.writer.writePacket(t.bufWriter, t.rand, packet)\n}", "is_vulnerable": 1}
{"code": "func programSA(localIP, remoteIP net.IP, spi *spi, k *key, dir int, add bool) (fSA *netlink.XfrmState, rSA *netlink.XfrmState, err error) {\n\tvar (\n\t\taction      = \"Removing\"\n\t\txfrmProgram = ns.NlHandle().XfrmStateDel\n\t)\n\n\tif add {\n\t\taction = \"Adding\"\n\t\txfrmProgram = ns.NlHandle().XfrmStateAdd\n\t}\n\n\tif dir&reverse > 0 {\n\t\trSA = &netlink.XfrmState{\n\t\t\tSrc:   remoteIP,\n\t\t\tDst:   localIP,\n\t\t\tProto: netlink.XFRM_PROTO_ESP,\n\t\t\tSpi:   spi.reverse,\n\t\t\tMode:  netlink.XFRM_MODE_TRANSPORT,\n\t\t\tReqid: r,\n\t\t}\n\t\tif add {\n\t\t\trSA.Aead = buildAeadAlgo(k, spi.reverse)\n\t\t}\n\n\t\texists, err := saExists(rSA)\n\t\tif err != nil {\n\t\t\texists = !add\n\t\t}\n\n\t\tif add != exists {\n\t\t\tlogrus.Debugf(\"%s: rSA{%s}\", action, rSA)\n\t\t\tif err := xfrmProgram(rSA); err != nil {\n\t\t\t\tlogrus.Warnf(\"Failed %s rSA{%s}: %v\", action, rSA, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif dir&forward > 0 {\n\t\tfSA = &netlink.XfrmState{\n\t\t\tSrc:   localIP,\n\t\t\tDst:   remoteIP,\n\t\t\tProto: netlink.XFRM_PROTO_ESP,\n\t\t\tSpi:   spi.forward,\n\t\t\tMode:  netlink.XFRM_MODE_TRANSPORT,\n\t\t\tReqid: r,\n\t\t}\n\t\tif add {\n\t\t\tfSA.Aead = buildAeadAlgo(k, spi.forward)\n\t\t}\n\n\t\texists, err := saExists(fSA)\n\t\tif err != nil {\n\t\t\texists = !add\n\t\t}\n\n\t\tif add != exists {\n\t\t\tlogrus.Debugf(\"%s fSA{%s}\", action, fSA)\n\t\t\tif err := xfrmProgram(fSA); err != nil {\n\t\t\t\tlogrus.Warnf(\"Failed %s fSA{%s}: %v.\", action, fSA, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tsetup()\n\t\t\tdefer teardown()\n\n\t\t\trtr.PathPrefix(tokenPathPrefix).HandlerFunc(testTokenHandler)\n\t\t\trtr.MatcherFunc(invalidTokenPathMatcher).HandlerFunc(testInvalidRequestHandler)\n\t\t\trtr.PathPrefix(hostTokenPathPrefix).HandlerFunc(testHostTokenHandler)\n\t\t\trtr.PathPrefix(instancePathPrefix).HandlerFunc(testInstanceHandler)\n\t\t\trtr.PathPrefix(\"/\").HandlerFunc(testDefaultHandler)\n\n\t\t\treq, err := http.NewRequest(http.MethodGet, test.url, nil)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\trecorder := httptest.NewRecorder()\n\t\t\trtr.ServeHTTP(recorder, req)\n\n\t\t\tif recorder.Code != test.expectedStatusCode {\n\t\t\t\tt.Errorf(\"unexpected status code %d\", recorder.Code)\n\t\t\t}\n\n\t\t\tif test.expectedBody != strings.TrimSpace(recorder.Body.String()) {\n\t\t\t\tt.Errorf(\"unexpected response body %s\", recorder.Body.String())\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func TestVariousFuzz(t *testing.T) {\n\t// Issue #192\tassert(t, squash(`\"000\"hello`) == `\"000\"`)\n\tassert(t, squash(`\"000\"`) == `\"000\"`)\n\tassert(t, squash(`\"000`) == `\"000`)\n\tassert(t, squash(`\"`) == `\"`)\n\n\tassert(t, squash(`[000]hello`) == `[000]`)\n\tassert(t, squash(`[000]`) == `[000]`)\n\tassert(t, squash(`[000`) == `[000`)\n\tassert(t, squash(`[`) == `[`)\n\tassert(t, squash(`]`) == `]`)\n\n\ttestJSON := `0.#[[{}]].@valid:\"000`\n\tGet(testJSON, testJSON)\n\n\t// Issue #195\n\ttestJSON = `\\************************************` +\n\t\t`**********{**\",**,,**,**,**,**,\"\",**,**,**,**,**,**,**,**,**,**]`\n\tGet(testJSON, testJSON)\n\n\t// Issue #196\n\ttestJSON = `[#.@pretty.@join:{\"\"[]\"\"preserve\"3,\"][{]]]`\n\tGet(testJSON, testJSON)\n\n\t// Issue #237\n\ttestJSON1 := `[\"*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,,,,,,\"]`\n\ttestJSON2 := `#[%\"*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,,,,,,\"\"*,*\"]`\n\tGet(testJSON1, testJSON2)\n\n}", "is_vulnerable": 0}
{"code": "func (s *TestSuiteIAM) TestLDAPSTSServiceAccountsWithGroups(c *check) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\tbucket := getRandomBucketName()\n\terr := s.client.MakeBucket(ctx, bucket, minio.MakeBucketOptions{})\n\tif err != nil {\n\t\tc.Fatalf(\"bucket create error: %v\", err)\n\t}\n\n\t// Create policy\n\tpolicy := \"mypolicy\"\n\tpolicyBytes := []byte(fmt.Sprintf(`{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n  {\n   \"Effect\": \"Allow\",\n   \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:ListBucket\"\n   ],\n   \"Resource\": [\n    \"arn:aws:s3:::%s/*\"\n   ]\n  }\n ]\n}`, bucket))\n\terr = s.adm.AddCannedPolicy(ctx, policy, policyBytes)\n\tif err != nil {\n\t\tc.Fatalf(\"policy add error: %v\", err)\n\t}\n\n\tgroupDN := \"cn=projecta,ou=groups,ou=swengg,dc=min,dc=io\"\n\terr = s.adm.SetPolicy(ctx, policy, groupDN, true)\n\tif err != nil {\n\t\tc.Fatalf(\"Unable to set policy: %v\", err)\n\t}\n\n\tldapID := cr.LDAPIdentity{\n\t\tClient:       s.TestSuiteCommon.client,\n\t\tSTSEndpoint:  s.endPoint,\n\t\tLDAPUsername: \"dillon\",\n\t\tLDAPPassword: \"dillon\",\n\t}\n\n\tvalue, err := ldapID.Retrieve()\n\tif err != nil {\n\t\tc.Fatalf(\"Expected to generate STS creds, got err: %#v\", err)\n\t}\n\n\t// Check that the LDAP sts cred is actually working.\n\tminioClient, err := minio.New(s.endpoint, &minio.Options{\n\t\tCreds:     cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure:    s.secure,\n\t\tTransport: s.TestSuiteCommon.client.Transport,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Error initializing client: %v\", err)\n\t}\n\n\t// Validate that the client from sts creds can access the bucket.\n\tc.mustListObjects(ctx, minioClient, bucket)\n\n\t// Create an madmin client with user creds\n\tuserAdmClient, err := madmin.NewWithOptions(s.endpoint, &madmin.Options{\n\t\tCreds:  cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure: s.secure,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Err creating user admin client: %v\", err)\n\t}\n\tuserAdmClient.SetCustomTransport(s.TestSuiteCommon.client.Transport)\n\n\t// Create svc acc\n\tcr := c.mustCreateSvcAccount(ctx, value.AccessKeyID, userAdmClient)\n\n\t// 1. Check that svc account appears in listing\n\tc.assertSvcAccAppearsInListing(ctx, userAdmClient, value.AccessKeyID, cr.AccessKey)\n\n\t// 2. Check that svc account info can be queried\n\tc.assertSvcAccInfoQueryable(ctx, userAdmClient, value.AccessKeyID, cr.AccessKey, true)\n\n\t// 3. Check S3 access\n\tc.assertSvcAccS3Access(ctx, s, cr, bucket)\n\n\t// 4. Check that svc account can restrict the policy, and that the\n\t// session policy can be updated.\n\tc.assertSvcAccSessionPolicyUpdate(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 4. Check that service account's secret key and account status can be\n\t// updated.\n\tc.assertSvcAccSecretKeyAndStatusUpdate(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 5. Check that service account can be deleted.\n\tc.assertSvcAccDeletion(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 6. Check that service account cannot be created for some other user.\n\tc.mustNotCreateSvcAccount(ctx, globalActiveCred.AccessKey, userAdmClient)\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn authReq{\n\t\tr:                r,\n\t\tannotationConfig: authReqAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (cs *State) tryAddVote(vote *types.Vote, peerID p2p.ID) (bool, error) {\n\tadded, err := cs.addVote(vote, peerID)\n\tif err != nil {\n\t\t// If the vote height is off, we'll just ignore it,\n\t\t// But if it's a conflicting sig, add it to the cs.evpool.\n\t\t// If it's otherwise invalid, punish peer.\n\t\t// nolint: gocritic\n\t\tif voteErr, ok := err.(*types.ErrVoteConflictingVotes); ok {\n\t\t\tif cs.privValidatorPubKey == nil {\n\t\t\t\treturn false, errPubKeyIsNotSet\n\t\t\t}\n\n\t\t\tif bytes.Equal(vote.ValidatorAddress, cs.privValidatorPubKey.Address()) {\n\t\t\t\tcs.Logger.Error(\n\t\t\t\t\t\"Found conflicting vote from ourselves. Did you unsafe_reset a validator?\",\n\t\t\t\t\t\"height\",\n\t\t\t\t\tvote.Height,\n\t\t\t\t\t\"round\",\n\t\t\t\t\tvote.Round,\n\t\t\t\t\t\"type\",\n\t\t\t\t\tvote.Type)\n\t\t\t\treturn added, err\n\t\t\t}\n\t\t\t// report conflicting votes to the evidence pool\n\t\t\tcs.evpool.ReportConflictingVotes(voteErr.VoteA, voteErr.VoteB)\n\t\t\tcs.Logger.Info(\"Found and sent conflicting votes to the evidence pool\",\n\t\t\t\t\"VoteA\", voteErr.VoteA,\n\t\t\t\t\"VoteB\", voteErr.VoteB,\n\t\t\t)\n\t\t\treturn added, err\n\t\t} else if err == types.ErrVoteNonDeterministicSignature {\n\t\t\tcs.Logger.Debug(\"Vote has non-deterministic signature\", \"err\", err)\n\t\t} else {\n\t\t\t// Either\n\t\t\t// 1) bad peer OR\n\t\t\t// 2) not a bad peer? this can also err sometimes with \"Unexpected step\" OR\n\t\t\t// 3) tmkms use with multiple validators connecting to a single tmkms instance\n\t\t\t// \t\t(https://github.com/tendermint/tendermint/issues/3839).\n\t\t\tcs.Logger.Info(\"Error attempting to add vote\", \"err\", err)\n\t\t\treturn added, ErrAddingVote\n\t\t}\n\t}\n\treturn added, nil\n}", "is_vulnerable": 0}
{"code": "func (vfs *VirtualFilesystem) RemountAt(ctx context.Context, creds *auth.Credentials, pop *PathOperation, opts *MountOptions) error {\n\tvd, err := vfs.getMountpoint(ctx, creds, pop)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer vd.DecRef(ctx)\n\tvfs.lockMounts()\n\tdefer vfs.unlockMounts(ctx)\n\tmnt := vd.Mount()\n\tif mntns := MountNamespaceFromContext(ctx); mntns != nil {\n\t\tvfs.delayDecRef(mntns)\n\t\tif mntns != mnt.ns {\n\t\t\treturn linuxerr.EINVAL\n\t\t}\n\t}\n\treturn mnt.setMountOptions(opts)\n}", "is_vulnerable": 1}
{"code": "func NewMediaFileRepository(ctx context.Context, db dbx.Builder) *mediaFileRepository {\n\tr := &mediaFileRepository{}\n\tr.ctx = ctx\n\tr.db = db\n\tr.registerModel(&model.MediaFile{}, map[string]filterFunc{\n\t\t\"id\":      idFilter(r.tableName),\n\t\t\"title\":   fullTextFilter,\n\t\t\"starred\": booleanFilter,\n\t})\n\tif conf.Server.PreferSortTags {\n\t\tr.sortMappings = map[string]string{\n\t\t\t\"title\":        \"COALESCE(NULLIF(sort_title,''),title)\",\n\t\t\t\"artist\":       \"COALESCE(NULLIF(sort_artist_name,''),order_artist_name) asc, COALESCE(NULLIF(sort_album_name,''),order_album_name) asc, release_date asc, disc_number asc, track_number asc\",\n\t\t\t\"album\":        \"COALESCE(NULLIF(sort_album_name,''),order_album_name) asc, release_date asc, disc_number asc, track_number asc, COALESCE(NULLIF(sort_artist_name,''),order_artist_name) asc, COALESCE(NULLIF(sort_title,''),title) asc\",\n\t\t\t\"random\":       r.seededRandomSort(),\n\t\t\t\"created_at\":   \"media_file.created_at\",\n\t\t\t\"track_number\": \"album, release_date, disc_number, track_number\",\n\t\t}\n\t} else {\n\t\tr.sortMappings = map[string]string{\n\t\t\t\"title\":        \"order_title\",\n\t\t\t\"artist\":       \"order_artist_name asc, order_album_name asc, release_date asc, disc_number asc, track_number asc\",\n\t\t\t\"album\":        \"order_album_name asc, release_date asc, disc_number asc, track_number asc, order_artist_name asc, title asc\",\n\t\t\t\"random\":       r.seededRandomSort(),\n\t\t\t\"created_at\":   \"media_file.created_at\",\n\t\t\t\"track_number\": \"album, release_date, disc_number, track_number\",\n\t\t}\n\t}\n\treturn r\n}", "is_vulnerable": 0}
{"code": "func (m *OldA) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: OldA: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: OldA: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field B\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.B = append(m.B, &OldB{})\n\t\t\tif err := m.B[len(m.B)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognized(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func WritePreimages(db ethdb.KeyValueWriter, preimages map[common.Hash][]byte) {\n\tfor hash, preimage := range preimages {\n\t\tif err := db.Put(preimageKey(hash), preimage); err != nil {\n\t\t\tlog.Crit(\"Failed to store trie preimage\", \"err\", err)\n\t\t}\n\t}\n\tpreimageCounter.Inc(int64(len(preimages)))\n\tpreimageHitCounter.Inc(int64(len(preimages)))\n}", "is_vulnerable": 1}
{"code": "func (v *View) UserByLoginNameAndResourceOwner(ctx context.Context, loginName, resourceOwner, instanceID string) (*model.UserView, error) {\n\tqueriedUser, err := v.query.GetNotifyUserByLoginName(ctx, true, loginName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//nolint: contextcheck // no lint was added because refactor would change too much code\n\tuser, err := view.UserByID(v.Db, userTable, queriedUser.ID, instanceID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif user.ResourceOwner != resourceOwner {\n\t\treturn nil, zerrors.ThrowNotFound(nil, \"VIEW-qScmi\", \"Errors.User.NotFound\")\n\t}\n\n\treturn user, nil\n}", "is_vulnerable": 1}
{"code": "func TestCustomHTTPErrors(t *testing.T) {\n\tec := NewAnnotationExtractor(mockCfg{})\n\ting := buildIngress()\n\n\tfooAnns := []struct {\n\t\tannotations map[string]string\n\t\ter          []int\n\t}{\n\t\t{map[string]string{annotationCustomHTTPErrors: \"404,415\"}, []int{404, 415}},\n\t\t{map[string]string{annotationCustomHTTPErrors: \"404\"}, []int{404}},\n\t\t{map[string]string{annotationCustomHTTPErrors: \"\"}, []int{}},\n\t\t{map[string]string{annotationCustomHTTPErrors + \"_no\": \"404\"}, []int{}},\n\t\t{map[string]string{}, []int{}},\n\t\t{nil, []int{}},\n\t}\n\n\tfor _, foo := range fooAnns {\n\t\ting.SetAnnotations(foo.annotations)\n\t\tr := ec.Extract(ing).CustomHTTPErrors\n\n\t\t// Check that expected codes were created\n\t\tfor i := range foo.er {\n\t\t\tif r[i] != foo.er[i] {\n\t\t\t\tt.Errorf(\"Returned %v but expected %v\", r, foo.er)\n\t\t\t}\n\t\t}\n\n\t\t// Check that no unexpected codes were also created\n\t\tfor i := range r {\n\t\t\tif r[i] != foo.er[i] {\n\t\t\t\tt.Errorf(\"Returned %v but expected %v\", r, foo.er)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestMultiSign(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"skipping long test in -short mode\")\n\t}\n\n\tzero := quickRand(0)\n\tconfig := packet.Config{Rand: &zero}\n\n\tfor nKeys := 0; nKeys < 4; nKeys++ {\n\tnextTest:\n\t\tfor nExtra := 0; nExtra < 4; nExtra++ {\n\t\t\tvar signKeys []*packet.PrivateKey\n\t\t\tvar verifyKeys openpgp.EntityList\n\n\t\t\tdesc := fmt.Sprintf(\"%d keys; %d of which will be used to verify\", nKeys+nExtra, nKeys)\n\t\t\tfor i := 0; i < nKeys+nExtra; i++ {\n\t\t\t\te, err := openpgp.NewEntity(\"name\", \"comment\", \"email\", &config)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"cannot create key: %v\", err)\n\t\t\t\t\tcontinue nextTest\n\t\t\t\t}\n\t\t\t\tif i < nKeys {\n\t\t\t\t\tverifyKeys = append(verifyKeys, e)\n\t\t\t\t}\n\t\t\t\tsignKeys = append(signKeys, e.PrivateKey)\n\t\t\t}\n\n\t\t\tinput := []byte(\"this is random text\\r\\n4 17\")\n\t\t\tvar output bytes.Buffer\n\t\t\tw, err := EncodeMulti(&output, signKeys, nil)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"EncodeMulti (%s) failed: %v\", desc, err)\n\t\t\t}\n\t\t\tif _, err := w.Write(input); err != nil {\n\t\t\t\tt.Errorf(\"Write(%q) to signer (%s) failed: %v\", string(input), desc, err)\n\t\t\t}\n\t\t\tif err := w.Close(); err != nil {\n\t\t\t\tt.Errorf(\"Close() of signer (%s) failed: %v\", desc, err)\n\t\t\t}\n\n\t\t\tblock, _ := Decode(output.Bytes())\n\t\t\tif string(block.Bytes) != string(input) {\n\t\t\t\tt.Errorf(\"Inline data didn't match original; got %q want %q\", string(block.Bytes), string(input))\n\t\t\t}\n\t\t\t_, err = openpgp.CheckDetachedSignature(verifyKeys, bytes.NewReader(block.Bytes), block.ArmoredSignature.Body)\n\t\t\tif nKeys == 0 {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Errorf(\"verifying inline (%s) succeeded; want failure\", desc)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"verifying inline (%s) failed (%v); want success\", desc, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *C) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowC\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: C: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: C: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field F2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowC\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthC\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthC\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.F2 == nil {\n\t\t\t\tm.F2 = &github_com_gogo_protobuf_test_importcustom_issue389_imported.B{}\n\t\t\t}\n\t\t\tif err := m.F2.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipC(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthC\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (mr *MockERC20BridgeViewMockRecorder) FindBridgeResumed(arg0, arg1, arg2, arg3 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"FindBridgeResumed\", reflect.TypeOf((*MockERC20BridgeView)(nil).FindBridgeResumed), arg0, arg1, arg2, arg3)\n}", "is_vulnerable": 0}
{"code": "func TestTeamMembersAPIEndpoint_userLoggedIn(t *testing.T) {\n\tsettings := setting.NewCfg()\n\tsqlStore := sqlstore.InitTestDB(t)\n\ths := &HTTPServer{\n\t\tCfg:          settings,\n\t\tLicense:      &licensing.OSSLicensingService{},\n\t\tSQLStore:     sqlStore,\n\t\tteamGuardian: &TeamGuardianMock{},\n\t}\n\tmock := mockstore.NewSQLStoreMock()\n\n\tloggedInUserScenarioWithRole(t, \"When calling GET on\", \"GET\", \"api/teams/1/members\",\n\t\t\"api/teams/:teamId/members\", models.ROLE_ADMIN, func(sc *scenarioContext) {\n\t\t\tsetUpGetTeamMembersHandler(t, sqlStore)\n\n\t\t\tsc.handlerFunc = hs.GetTeamMembers\n\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{}).exec()\n\n\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\n\t\t\tvar resp []models.TeamMemberDTO\n\t\t\terr := json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\trequire.NoError(t, err)\n\t\t\tassert.Len(t, resp, 3)\n\t\t}, mock)\n\n\tt.Run(\"Given there is two hidden users\", func(t *testing.T) {\n\t\tsettings.HiddenUsers = map[string]struct{}{\n\t\t\t\"user1\":       {},\n\t\t\ttestUserLogin: {},\n\t\t}\n\t\tt.Cleanup(func() { settings.HiddenUsers = make(map[string]struct{}) })\n\n\t\tloggedInUserScenarioWithRole(t, \"When calling GET on\", \"GET\", \"api/teams/1/members\",\n\t\t\t\"api/teams/:teamId/members\", models.ROLE_ADMIN, func(sc *scenarioContext) {\n\t\t\t\tsetUpGetTeamMembersHandler(t, sqlStore)\n\n\t\t\t\tsc.handlerFunc = hs.GetTeamMembers\n\t\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{}).exec()\n\n\t\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\n\t\t\t\tvar resp []models.TeamMemberDTO\n\t\t\t\terr := json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tassert.Len(t, resp, 3)\n\t\t\t\tassert.Equal(t, \"loginuser0\", resp[0].Login)\n\t\t\t\tassert.Equal(t, \"loginuser1\", resp[1].Login)\n\t\t\t\tassert.Equal(t, \"loginuser2\", resp[2].Login)\n\t\t\t}, mock)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (s *MemoryStore) ClientAssertionJWTValid(_ context.Context, jti string) error {\n\tif exp, exists := s.BlacklistedJTIs[jti]; exists && exp.After(time.Now()) {\n\t\treturn fosite.ErrJTIKnown\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func GenerateSelfSignedCert(hostNames []string) (*TLSCredentials, error) {\n\tpriv, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tnotBefore := time.Now()\n\tnotAfter := notBefore.Add(time.Hour * 24 * 365 * 10) // 10 years\n\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, err := rand.Int(rand.Reader, serialNumberLimit)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tentity := pkix.Name{\n\t\tCommonName:   \"localhost\",\n\t\tCountry:      []string{\"US\"},\n\t\tOrganization: []string{\"localhost\"},\n\t}\n\n\ttemplate := x509.Certificate{\n\t\tSerialNumber:          serialNumber,\n\t\tIssuer:                entity,\n\t\tSubject:               entity,\n\t\tNotBefore:             notBefore,\n\t\tNotAfter:              notAfter,\n\t\tKeyUsage:              x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature | x509.KeyUsageCertSign,\n\t\tBasicConstraintsValid: true,\n\t\tIsCA:                  true,\n\t}\n\n\t// collect IP addresses localhost resolves to and add them to the cert. template:\n\ttemplate.DNSNames = append(hostNames, \"localhost.local\")\n\tips, _ := net.LookupIP(\"localhost\")\n\tif ips != nil {\n\t\ttemplate.IPAddresses = append(ips, net.ParseIP(\"::1\"))\n\t}\n\tderBytes, err := x509.CreateCertificate(rand.Reader, &template, &template, &priv.PublicKey, priv)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\tpublicKeyBytes, err := x509.MarshalPKIXPublicKey(priv.Public())\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn &TLSCredentials{\n\t\tPublicKey:  pem.EncodeToMemory(&pem.Block{Type: \"RSA PUBLIC KEY\", Bytes: publicKeyBytes}),\n\t\tPrivateKey: pem.EncodeToMemory(&pem.Block{Type: \"RSA PRIVATE KEY\", Bytes: x509.MarshalPKCS1PrivateKey(priv)}),\n\t\tCert:       pem.EncodeToMemory(&pem.Block{Type: \"CERTIFICATE\", Bytes: derBytes}),\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (a *Assertions) Eventuallyf(condition func() bool, waitFor time.Duration, tick time.Duration, msg string, args ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tEventuallyf(a.t, condition, waitFor, tick, msg, args...)\n}", "is_vulnerable": 0}
{"code": "func (m *MockHasher) Compare(arg0 context.Context, arg1, arg2 []byte) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"Compare\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func getRawFromStorage(c *fiber.Ctx, token string, cfg Config, sessionManager *sessionManager, storageManager *storageManager) []byte {\n\tif cfg.Session != nil {\n\t\treturn sessionManager.getRaw(c, token, dummyValue)\n\t}\n\treturn storageManager.getRaw(token)\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_loadCAs(t *testing.T) {\n\ttype variant struct {\n\t\tcafile, capath string\n\t\tshouldErr      bool\n\t\tisNil          bool\n\t\tcount          int\n\t}\n\tvariants := []variant{\n\t\t{\"\", \"\", false, true, 0},\n\t\t{\"bogus\", \"\", true, true, 0},\n\t\t{\"\", \"bogus\", true, true, 0},\n\t\t{\"\", \"../test/bin\", true, true, 0},\n\t\t{\"../test/ca/root.cer\", \"\", false, false, 1},\n\t\t{\"\", \"../test/ca_path\", false, false, 2},\n\t\t{\"../test/ca/root.cer\", \"../test/ca_path\", false, false, 1},\n\t}\n\tfor i, v := range variants {\n\t\tcas, err := loadCAs(v.cafile, v.capath)\n\t\tinfo := fmt.Sprintf(\"case %d\", i)\n\t\tif v.shouldErr {\n\t\t\trequire.Error(t, err, info)\n\t\t} else {\n\t\t\trequire.NoError(t, err, info)\n\t\t}\n\t\tif v.isNil {\n\t\t\trequire.Nil(t, cas, info)\n\t\t} else {\n\t\t\trequire.NotNil(t, cas, info)\n\t\t\trequire.Len(t, cas.Subjects(), v.count, info)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestMissingAccountInImport(t *testing.T) {\n\ti := &Import{Subject: \"foo\", To: \"bar\", Type: Stream}\n\n\tvr := CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif len(vr.Issues) != 2 {\n\t\tt.Errorf(\"imports without token or url should warn the caller, as should missing account\")\n\t}\n\n\tif vr.IsBlocking(true) {\n\t\tt.Errorf(\"Missing Account is not blocking, must import failures are warnings\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *MockCoreStrategy) GenerateAuthorizeCode(arg0 context.Context, arg1 fosite.Requester) (string, string, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GenerateAuthorizeCode\", arg0, arg1)\n\tret0, _ := ret[0].(string)\n\tret1, _ := ret[1].(string)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "is_vulnerable": 0}
{"code": "func (m *Bar7) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar7: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar7: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars71\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars71 = append(m.Bars71, Bar7{})\n\t\t\tif err := m.Bars71[len(m.Bars71)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars72\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars72 = append(m.Bars72, &Bar7{})\n\t\t\tif err := m.Bars72[len(m.Bars72)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str1\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Str1 = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str2\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Str2 = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (p *printer) printIf(s *js_ast.SIf) {\n\tp.printSpaceBeforeIdentifier()\n\tp.print(\"if\")\n\tp.printSpace()\n\tp.print(\"(\")\n\tif p.willPrintExprCommentsAtLoc(s.Test.Loc) {\n\t\tp.printNewline()\n\t\tp.options.Indent++\n\t\tp.printIndent()\n\t\tp.printExpr(s.Test, js_ast.LLowest, 0)\n\t\tp.printNewline()\n\t\tp.options.Indent--\n\t\tp.printIndent()\n\t} else {\n\t\tp.printExpr(s.Test, js_ast.LLowest, 0)\n\t}\n\tp.print(\")\")\n\n\t// Simplify the else branch, which may disappear entirely\n\tno := s.NoOrNil\n\tif expr, ok := no.Data.(*js_ast.SExpr); ok {\n\t\tif value := p.simplifyUnusedExpr(expr.Value); value.Data == nil {\n\t\t\tno.Data = nil\n\t\t} else if value.Data != expr.Value.Data {\n\t\t\tno.Data = &js_ast.SExpr{Value: value}\n\t\t}\n\t}\n\n\tif yes, ok := s.Yes.Data.(*js_ast.SBlock); ok {\n\t\tp.printSpace()\n\t\tp.printBlock(s.Yes.Loc, *yes)\n\n\t\tif no.Data != nil {\n\t\t\tp.printSpace()\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t}\n\t} else if wrapToAvoidAmbiguousElse(s.Yes.Data) {\n\t\tp.printSpace()\n\t\tp.print(\"{\")\n\t\tp.printNewline()\n\n\t\tp.options.Indent++\n\t\tp.printStmt(s.Yes, canOmitStatement)\n\t\tp.options.Indent--\n\t\tp.needsSemicolon = false\n\n\t\tp.printIndent()\n\t\tp.print(\"}\")\n\n\t\tif no.Data != nil {\n\t\t\tp.printSpace()\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t}\n\t} else {\n\t\tp.printNewline()\n\t\tp.options.Indent++\n\t\tp.printStmt(s.Yes, 0)\n\t\tp.options.Indent--\n\n\t\tif no.Data != nil {\n\t\t\tp.printIndent()\n\t\t}\n\t}\n\n\tif no.Data != nil {\n\t\tp.printSemicolonIfNeeded()\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.print(\"else\")\n\n\t\tif block, ok := no.Data.(*js_ast.SBlock); ok {\n\t\t\tp.printSpace()\n\t\t\tp.printBlock(no.Loc, *block)\n\t\t\tp.printNewline()\n\t\t} else if ifStmt, ok := no.Data.(*js_ast.SIf); ok {\n\t\t\tp.printIf(ifStmt)\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t\tp.options.Indent++\n\t\t\tp.printStmt(no, 0)\n\t\t\tp.options.Indent--\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *CustomNameNidOptNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNidOptNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNidOptNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldA\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.FieldA = float64(math.Float64frombits(v))\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldB\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.FieldB = float32(math.Float32frombits(v))\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldC\", wireType)\n\t\t\t}\n\t\t\tm.FieldC = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.FieldC |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldD\", wireType)\n\t\t\t}\n\t\t\tm.FieldD = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.FieldD |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldE\", wireType)\n\t\t\t}\n\t\t\tm.FieldE = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.FieldE |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldF\", wireType)\n\t\t\t}\n\t\t\tm.FieldF = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.FieldF |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldG\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.FieldG = v\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldH\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\tm.FieldH = int64(v)\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldI\", wireType)\n\t\t\t}\n\t\t\tm.FieldI = 0\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldI = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\tcase 10:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldJ\", wireType)\n\t\t\t}\n\t\t\tm.FieldJ = 0\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldJ = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\tcase 11:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldK\", wireType)\n\t\t\t}\n\t\t\tm.FieldK = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldK = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 12:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldL\", wireType)\n\t\t\t}\n\t\t\tm.FieldL = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldL = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldM\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.FieldM = bool(v != 0)\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldN\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldN = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldO\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldO = append(m.FieldO[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.FieldO == nil {\n\t\t\t\tm.FieldO = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (wb *WebsocketBroadcast) AddHook(hookID string, hookArgs map[string]any) {\n\twb.BroadcastHooks = append(wb.BroadcastHooks, hookID)\n\twb.BroadcastHookArgs = append(wb.BroadcastHookArgs, hookArgs)\n}", "is_vulnerable": 0}
{"code": "\tcrossAuthSrv := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tusername, password, ok := r.BasicAuth()\n\t\tif ok || username == \"username\" || password == \"password\" {\n\t\t\tt.Errorf(\"Expected request to not include but got '%v', '%s', '%s'\", ok, username, password)\n\t\t}\n\t\tfmt.Fprint(w, expect)\n\t}))", "is_vulnerable": 0}
{"code": "func (d oggGenerator) GetOriginDimensions(b []byte, contentType string, ctx rcontext.RequestContext) (bool, int, int, error) {\n\treturn false, 0, 0, nil\n}", "is_vulnerable": 0}
{"code": "func TestGenerateYamlManifestInDir(t *testing.T) {\n\tservice := newService(t, \"../../manifests/base\")\n\n\tsrc := argoappv1.ApplicationSource{Path: \".\"}\n\tq := apiclient.ManifestRequest{\n\t\tRepo:               &argoappv1.Repository{},\n\t\tApplicationSource:  &src,\n\t\tProjectName:        \"something\",\n\t\tProjectSourceRepos: []string{\"*\"},\n\t}\n\n\t// update this value if we add/remove manifests\n\tconst countOfManifests = 50\n\n\tres1, err := service.GenerateManifest(context.Background(), &q)\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, countOfManifests, len(res1.Manifests))\n\n\t// this will test concatenated manifests to verify we split YAMLs correctly\n\tres2, err := GenerateManifests(context.Background(), \"./testdata/concatenated\", \"/\", \"\", &q, false, &git.NoopCredsStore{}, resource.MustParse(\"0\"), nil)\n\tassert.NoError(t, err)\n\tassert.Equal(t, 3, len(res2.Manifests))\n}", "is_vulnerable": 0}
{"code": "func normalizeDomain(input string) string {\n\t// Remove scheme\n\tinput = strings.TrimPrefix(strings.TrimPrefix(input, \"http://\"), \"https://\")\n\n\t// Find and remove port, if present\n\tif portIndex := strings.Index(input, \":\"); portIndex != -1 {\n\t\tinput = input[:portIndex]\n\t}\n\n\treturn input\n}", "is_vulnerable": 0}
{"code": "func NewConfig(dc *dynamicconfig.Collection, numHistoryShards int32, enableReadFromES bool) *Config {\n\treturn &Config{\n\t\tNumHistoryShards:                      numHistoryShards,\n\t\tPersistenceMaxQPS:                     dc.GetIntProperty(dynamicconfig.FrontendPersistenceMaxQPS, 2000),\n\t\tPersistenceGlobalMaxQPS:               dc.GetIntProperty(dynamicconfig.FrontendPersistenceGlobalMaxQPS, 0),\n\t\tPersistenceNamespaceMaxQPS:            dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendPersistenceNamespaceMaxQPS, 0),\n\t\tEnablePersistencePriorityRateLimiting: dc.GetBoolProperty(dynamicconfig.FrontendEnablePersistencePriorityRateLimiting, true),\n\n\t\tStandardVisibilityPersistenceMaxReadQPS:   dc.GetIntProperty(dynamicconfig.StandardVisibilityPersistenceMaxReadQPS, 9000),\n\t\tStandardVisibilityPersistenceMaxWriteQPS:  dc.GetIntProperty(dynamicconfig.StandardVisibilityPersistenceMaxWriteQPS, 9000),\n\t\tAdvancedVisibilityPersistenceMaxReadQPS:   dc.GetIntProperty(dynamicconfig.AdvancedVisibilityPersistenceMaxReadQPS, 9000),\n\t\tAdvancedVisibilityPersistenceMaxWriteQPS:  dc.GetIntProperty(dynamicconfig.AdvancedVisibilityPersistenceMaxWriteQPS, 9000),\n\t\tVisibilityMaxPageSize:                     dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendVisibilityMaxPageSize, 1000),\n\t\tEnableReadVisibilityFromES:                dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.EnableReadVisibilityFromES, enableReadFromES),\n\t\tEnableReadFromSecondaryAdvancedVisibility: dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.EnableReadFromSecondaryAdvancedVisibility, false),\n\t\tESIndexMaxResultWindow:                    dc.GetIntProperty(dynamicconfig.FrontendESIndexMaxResultWindow, 10000),\n\t\tVisibilityDisableOrderByClause:            dc.GetBoolProperty(dynamicconfig.VisibilityDisableOrderByClause, false),\n\n\t\tHistoryMaxPageSize:                     dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendHistoryMaxPageSize, common.GetHistoryMaxPageSize),\n\t\tRPS:                                    dc.GetIntProperty(dynamicconfig.FrontendRPS, 2400),\n\t\tMaxNamespaceRPSPerInstance:             dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxNamespaceRPSPerInstance, 2400),\n\t\tMaxNamespaceBurstPerInstance:           dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxNamespaceBurstPerInstance, 4800),\n\t\tMaxNamespaceCountPerInstance:           dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxNamespaceCountPerInstance, 1200),\n\t\tMaxNamespaceVisibilityRPSPerInstance:   dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxNamespaceVisibilityRPSPerInstance, 10),\n\t\tMaxNamespaceVisibilityBurstPerInstance: dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxNamespaceVisibilityBurstPerInstance, 10),\n\t\tGlobalNamespaceRPS:                     dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendGlobalNamespaceRPS, 0),\n\t\tInternalFEGlobalNamespaceRPS:           dc.GetIntPropertyFilteredByNamespace(dynamicconfig.InternalFrontendGlobalNamespaceRPS, 0),\n\t\tGlobalNamespaceVisibilityRPS:           dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendGlobalNamespaceVisibilityRPS, 0),\n\t\tInternalFEGlobalNamespaceVisibilityRPS: dc.GetIntPropertyFilteredByNamespace(dynamicconfig.InternalFrontendGlobalNamespaceVisibilityRPS, 0),\n\t\tMaxIDLengthLimit:                       dc.GetIntProperty(dynamicconfig.MaxIDLengthLimit, 1000),\n\t\tWorkerBuildIdSizeLimit:                 dc.GetIntProperty(dynamicconfig.WorkerBuildIdSizeLimit, 1000),\n\t\tMaxBadBinaries:                         dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxBadBinaries, namespace.MaxBadBinaries),\n\t\tDisableListVisibilityByFilter:          dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.DisableListVisibilityByFilter, false),\n\t\tBlobSizeLimitError:                     dc.GetIntPropertyFilteredByNamespace(dynamicconfig.BlobSizeLimitError, 2*1024*1024),\n\t\tBlobSizeLimitWarn:                      dc.GetIntPropertyFilteredByNamespace(dynamicconfig.BlobSizeLimitWarn, 256*1024),\n\t\tThrottledLogRPS:                        dc.GetIntProperty(dynamicconfig.FrontendThrottledLogRPS, 20),\n\t\tShutdownDrainDuration:                  dc.GetDurationProperty(dynamicconfig.FrontendShutdownDrainDuration, 0*time.Second),\n\t\tShutdownFailHealthCheckDuration:        dc.GetDurationProperty(dynamicconfig.FrontendShutdownFailHealthCheckDuration, 0*time.Second),\n\t\tEnableNamespaceNotActiveAutoForwarding: dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.EnableNamespaceNotActiveAutoForwarding, true),\n\t\tSearchAttributesNumberOfKeysLimit:      dc.GetIntPropertyFilteredByNamespace(dynamicconfig.SearchAttributesNumberOfKeysLimit, 100),\n\t\tSearchAttributesSizeOfValueLimit:       dc.GetIntPropertyFilteredByNamespace(dynamicconfig.SearchAttributesSizeOfValueLimit, 2*1024),\n\t\tSearchAttributesTotalSizeLimit:         dc.GetIntPropertyFilteredByNamespace(dynamicconfig.SearchAttributesTotalSizeLimit, 40*1024),\n\t\tVisibilityArchivalQueryMaxPageSize:     dc.GetIntProperty(dynamicconfig.VisibilityArchivalQueryMaxPageSize, 10000),\n\t\tDisallowQuery:                          dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.DisallowQuery, false),\n\t\tSendRawWorkflowHistory:                 dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.SendRawWorkflowHistory, false),\n\t\tDefaultWorkflowRetryPolicy:             dc.GetMapPropertyFnWithNamespaceFilter(dynamicconfig.DefaultWorkflowRetryPolicy, common.GetDefaultRetryPolicyConfigOptions()),\n\t\tDefaultWorkflowTaskTimeout:             dc.GetDurationPropertyFilteredByNamespace(dynamicconfig.DefaultWorkflowTaskTimeout, common.DefaultWorkflowTaskTimeout),\n\t\tEnableServerVersionCheck:               dc.GetBoolProperty(dynamicconfig.EnableServerVersionCheck, os.Getenv(\"TEMPORAL_VERSION_CHECK_DISABLED\") == \"\"),\n\t\tEnableTokenNamespaceEnforcement:        dc.GetBoolProperty(dynamicconfig.EnableTokenNamespaceEnforcement, true),\n\t\tKeepAliveMinTime:                       dc.GetDurationProperty(dynamicconfig.KeepAliveMinTime, 10*time.Second),\n\t\tKeepAlivePermitWithoutStream:           dc.GetBoolProperty(dynamicconfig.KeepAlivePermitWithoutStream, true),\n\t\tKeepAliveMaxConnectionIdle:             dc.GetDurationProperty(dynamicconfig.KeepAliveMaxConnectionIdle, 2*time.Minute),\n\t\tKeepAliveMaxConnectionAge:              dc.GetDurationProperty(dynamicconfig.KeepAliveMaxConnectionAge, 5*time.Minute),\n\t\tKeepAliveMaxConnectionAgeGrace:         dc.GetDurationProperty(dynamicconfig.KeepAliveMaxConnectionAgeGrace, 70*time.Second),\n\t\tKeepAliveTime:                          dc.GetDurationProperty(dynamicconfig.KeepAliveTime, 1*time.Minute),\n\t\tKeepAliveTimeout:                       dc.GetDurationProperty(dynamicconfig.KeepAliveTimeout, 10*time.Second),\n\n\t\tDeleteNamespaceDeleteActivityRPS:                    dc.GetIntProperty(dynamicconfig.DeleteNamespaceDeleteActivityRPS, 100),\n\t\tDeleteNamespacePageSize:                             dc.GetIntProperty(dynamicconfig.DeleteNamespacePageSize, 1000),\n\t\tDeleteNamespacePagesPerExecution:                    dc.GetIntProperty(dynamicconfig.DeleteNamespacePagesPerExecution, 256),\n\t\tDeleteNamespaceConcurrentDeleteExecutionsActivities: dc.GetIntProperty(dynamicconfig.DeleteNamespaceConcurrentDeleteExecutionsActivities, 4),\n\t\tDeleteNamespaceNamespaceDeleteDelay:                 dc.GetDurationProperty(dynamicconfig.DeleteNamespaceNamespaceDeleteDelay, 0),\n\n\t\tEnableSchedules: dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.FrontendEnableSchedules, true),\n\n\t\tEnableBatcher:                   dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.FrontendEnableBatcher, true),\n\t\tMaxConcurrentBatchOperation:     dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxConcurrentBatchOperationPerNamespace, 1),\n\t\tMaxExecutionCountBatchOperation: dc.GetIntPropertyFilteredByNamespace(dynamicconfig.FrontendMaxExecutionCountBatchOperationPerNamespace, 1000),\n\n\t\tEnableUpdateWorkflowExecution: dc.GetBoolPropertyFnWithNamespaceFilter(dynamicconfig.FrontendEnableUpdateWorkflowExecution, false),\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn func(s ssh.Session) {\n\t\t// XXX: The authentication key is set in the context but gossh doesn't\n\t\t// validate the authentication. We need to verify that the _last_ key\n\t\t// that was approved is the one that's being used.\n\n\t\tpk := s.PublicKey()\n\t\tif pk != nil {\n\t\t\t// There is no public key stored in the context, public-key auth\n\t\t\t// was never requested, skip\n\t\t\tperms := s.Permissions().Permissions\n\t\t\tif perms == nil {\n\t\t\t\twish.Fatalln(s, ErrPermissionDenied)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Check if the key is the same as the one we have in context\n\t\t\tfp := perms.Extensions[\"pubkey-fp\"]\n\t\t\tif fp != gossh.FingerprintSHA256(pk) {\n\t\t\t\twish.Fatalln(s, ErrPermissionDenied)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tsh(s)\n\t}", "is_vulnerable": 0}
{"code": "\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tbearerTokenRaw := r.Header.Get(\"Authorization\")\n\t\tsplitToken := strings.Split(bearerTokenRaw, \"Bearer\")\n\t\tif len(splitToken) != 2 {\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\taccessTokenString := strings.TrimSpace(splitToken[1])\n\t\taccessClaims, err := auth.ValidateAccessToken(accessTokenString)\n\t\tif err != nil {\n\t\t\tif _, ok := err.(*auth.ErrExpiredToken); ok {\n\t\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\t\tw.Write([]byte(`{\n\t\"data\": {},\n\t\"errors\": [\n\t{\n\t\t\"extensions\": {\n\t\t\t\"code\": \"UNAUTHENTICATED\"\n\t\t}\n\t}\n\t]\n\t\t\t\t}`))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlog.Error(err)\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tvar userID uuid.UUID\n\t\tif accessClaims.Restricted == auth.InstallOnly {\n\t\t\tuserID = uuid.New()\n\t\t} else {\n\t\t\tuserID, err = uuid.Parse(accessClaims.UserID)\n\t\t\tif err != nil {\n\t\t\t\tlog.WithError(err).Error(\"middleware access token userID parse\")\n\t\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tctx := context.WithValue(r.Context(), \"userID\", userID)\n\t\tctx = context.WithValue(ctx, \"restricted_mode\", accessClaims.Restricted)\n\t\tctx = context.WithValue(ctx, \"org_role\", accessClaims.OrgRole)\n\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})", "is_vulnerable": 1}
{"code": "\trouter.Get(\"/new/*path\", func(w http.ResponseWriter, r *http.Request) {\n\t\tp := route.Param(r.Context(), \"path\")\n\t\thttp.Redirect(w, r, path.Join(o.ExternalURL.Path, p)+\"?\"+r.URL.RawQuery, http.StatusFound)\n\t})", "is_vulnerable": 0}
{"code": "func TestInvalidFingerprintCausesFailed(t *testing.T) {\n\tlim := test.TimeOut(time.Second * 40)\n\tdefer lim.Stop()\n\n\treport := test.CheckRoutines(t)\n\tdefer report()\n\n\tpcOffer, err := NewPeerConnection(Configuration{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tpcAnswer, err := NewPeerConnection(Configuration{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tpcAnswer.OnDataChannel(func(_ *DataChannel) {\n\t\tt.Fatal(\"A DataChannel must not be created when Fingerprint verification fails\")\n\t})\n\n\tdefer closePairNow(t, pcOffer, pcAnswer)\n\n\tofferChan := make(chan SessionDescription)\n\tpcOffer.OnICECandidate(func(candidate *ICECandidate) {\n\t\tif candidate == nil {\n\t\t\tofferChan <- *pcOffer.PendingLocalDescription()\n\t\t}\n\t})\n\n\tofferConnectionHasFailed := untilConnectionState(PeerConnectionStateFailed, pcOffer)\n\tanswerConnectionHasFailed := untilConnectionState(PeerConnectionStateFailed, pcAnswer)\n\n\tif _, err = pcOffer.CreateDataChannel(\"unusedDataChannel\", nil); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\toffer, err := pcOffer.CreateOffer(nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t} else if err := pcOffer.SetLocalDescription(offer); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tselect {\n\tcase offer := <-offerChan:\n\t\t// Replace with invalid fingerprint\n\t\tre := regexp.MustCompile(`sha-256 (.*?)\\r`)\n\t\toffer.SDP = re.ReplaceAllString(offer.SDP, \"sha-256 AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA\\r\")\n\n\t\tif err := pcAnswer.SetRemoteDescription(offer); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tanswer, err := pcAnswer.CreateAnswer(nil)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tif err = pcAnswer.SetLocalDescription(answer); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\tanswer.SDP = re.ReplaceAllString(answer.SDP, \"sha-256 AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA:AA\\r\")\n\n\t\terr = pcOffer.SetRemoteDescription(answer)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\tcase <-time.After(5 * time.Second):\n\t\tt.Fatal(\"timed out waiting to receive offer\")\n\t}\n\n\tofferConnectionHasFailed.Wait()\n\tanswerConnectionHasFailed.Wait()\n\n\tassert.Equal(t, pcOffer.SCTP().Transport().State(), DTLSTransportStateFailed)\n\tassert.Nil(t, pcOffer.SCTP().Transport().conn)\n\n\tassert.Equal(t, pcAnswer.SCTP().Transport().State(), DTLSTransportStateFailed)\n\tassert.Nil(t, pcAnswer.SCTP().Transport().conn)\n}", "is_vulnerable": 0}
{"code": "func (m *MapStdTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: MapStdTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: MapStdTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableTimestamp == nil {\n\t\t\t\tm.NullableTimestamp = make(map[int32]*time.Time)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Time)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableTimestamp[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Timestamp == nil {\n\t\t\t\tm.Timestamp = make(map[int32]time.Time)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Time)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Timestamp[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDuration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDuration == nil {\n\t\t\t\tm.NullableDuration = make(map[int32]*time.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Duration)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDuration[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Duration == nil {\n\t\t\t\tm.Duration = make(map[int32]time.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Duration)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Duration[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDouble == nil {\n\t\t\t\tm.NullableDouble = make(map[int32]*float64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDouble[mapkey] = ((*float64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullDouble == nil {\n\t\t\t\tm.NonnullDouble = make(map[int32]float64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullDouble[mapkey] = ((float64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableFloat == nil {\n\t\t\t\tm.NullableFloat = make(map[int32]*float32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableFloat[mapkey] = ((*float32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullFloat == nil {\n\t\t\t\tm.NonnullFloat = make(map[int32]float32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullFloat[mapkey] = ((float32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt64 == nil {\n\t\t\t\tm.NullableInt64 = make(map[int32]*int64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt64[mapkey] = ((*int64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt64 == nil {\n\t\t\t\tm.NonnullInt64 = make(map[int32]int64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt64[mapkey] = ((int64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt64 == nil {\n\t\t\t\tm.NullableUInt64 = make(map[int32]*uint64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt64[mapkey] = ((*uint64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt64 == nil {\n\t\t\t\tm.NonnullUInt64 = make(map[int32]uint64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt64[mapkey] = ((uint64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt32 == nil {\n\t\t\t\tm.NullableInt32 = make(map[int32]*int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt32[mapkey] = ((*int32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt32 == nil {\n\t\t\t\tm.NonnullInt32 = make(map[int32]int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt32[mapkey] = ((int32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt32 == nil {\n\t\t\t\tm.NullableUInt32 = make(map[int32]*uint32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt32[mapkey] = ((*uint32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt32 == nil {\n\t\t\t\tm.NonnullUInt32 = make(map[int32]uint32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt32[mapkey] = ((uint32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBool == nil {\n\t\t\t\tm.NullableBool = make(map[int32]*bool)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(bool)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBool[mapkey] = ((*bool)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBool == nil {\n\t\t\t\tm.NonnullBool = make(map[int32]bool)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(bool)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBool[mapkey] = ((bool)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableString == nil {\n\t\t\t\tm.NullableString = make(map[int32]*string)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(string)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableString[mapkey] = ((*string)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullString == nil {\n\t\t\t\tm.NonnullString = make(map[int32]string)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(string)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullString[mapkey] = ((string)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBytes == nil {\n\t\t\t\tm.NullableBytes = make(map[int32]*[]byte)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new([]byte)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBytes[mapkey] = ((*[]byte)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBytes == nil {\n\t\t\t\tm.NonnullBytes = make(map[int32][]byte)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new([]byte)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBytes[mapkey] = (([]byte)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func ConnectedObjectsTest(t *testing.T, ds storage.OpenFGADatastore) {\n\n\ttests := []struct {\n\t\tname             string\n\t\tmodel            string\n\t\ttuples           []*openfgapb.TupleKey\n\t\trequest          *commands.ConnectedObjectsRequest\n\t\tresolveNodeLimit uint32\n\t\tlimit            uint32\n\t\texpectedObjects  []string\n\t\texpectedError    error\n\t}{\n\t\t{\n\t\t\tname: \"restrict_results_based_on_limit\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"folder\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{},\n\t\t\t},\n\t\t\tlimit: 2,\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define viewer: [user] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder2\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder3\", \"viewer\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"folder:folder1\", \"folder:folder2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"resolve_direct_relationships_with_tuples_and_contextual_tuples\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{\n\t\t\t\t\ttuple.NewTupleKey(\"document:doc2\", \"viewer\", \"user:bob\"),\n\t\t\t\t\ttuple.NewTupleKey(\"document:doc3\", \"viewer\", \"user:jon\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"viewer\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:doc1\", \"document:doc3\"},\n\t\t},\n\t\t{\n\t\t\tname: \"direct_relations_involving_relationships_with_users_and_usersets\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"jon\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user, group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc2\", \"viewer\", \"user:bob\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc3\", \"viewer\", \"group:openfga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:openfga\", \"member\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:doc1\", \"document:doc3\"},\n\t\t},\n\t\t{\n\t\t\tname: \"success_with_direct_relationships_and_computed_usersets\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"jon\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define owner: [user, group#member] as self\n\t\t\t    define viewer as owner\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"owner\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc2\", \"owner\", \"user:bob\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc3\", \"owner\", \"group:openfga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:openfga\", \"member\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:doc1\", \"document:doc3\"},\n\t\t},\n\t\t{\n\t\t\tname: \"success_with_many_tuples\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{\n\t\t\t\t\ttuple.NewTupleKey(\"folder:folder5\", \"parent\", \"folder:folder4\"),\n\t\t\t\t\ttuple.NewTupleKey(\"folder:folder6\", \"viewer\", \"user:bob\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user, group#member] as self\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer: [user, group#member] as self or viewer from parent\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer as viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder2\", \"parent\", \"folder:folder1\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder3\", \"parent\", \"folder:folder2\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder4\", \"viewer\", \"group:eng#member\"),\n\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"folder:folder3\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc2\", \"parent\", \"folder:folder5\"),\n\t\t\t\ttuple.NewTupleKey(\"document:doc3\", \"parent\", \"folder:folder6\"),\n\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"group:openfga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:openfga\", \"member\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:doc1\", \"document:doc2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"resolve_objects_involved_in_recursive_hierarchy\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"folder\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer: [user] as self or viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder2\", \"parent\", \"folder:folder1\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder3\", \"parent\", \"folder:folder2\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"folder:folder1\", \"folder:folder2\", \"folder:folder3\"},\n\t\t},\n\t\t{\n\t\t\tname: \"resolution_depth_exceeded_failure\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"folder\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tresolveNodeLimit: 2,\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer: [user] as self or viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder2\", \"parent\", \"folder:folder1\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder3\", \"parent\", \"folder:folder2\"),\n\t\t\t},\n\t\t\texpectedError: serverErrors.AuthorizationModelResolutionTooComplex,\n\t\t},\n\t\t{\n\t\t\tname: \"objects_connected_to_a_userset\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"group\",\n\t\t\t\tRelation:   \"member\",\n\t\t\t\tUser: &commands.UserRefObjectRelation{\n\t\t\t\t\tObjectRelation: &openfgapb.ObjectRelation{\n\t\t\t\t\t\tObject:   \"group:iam\",\n\t\t\t\t\t\tRelation: \"member\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user, group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"group:opensource\", \"member\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"group:iam#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:iam\", \"member\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"group:opensource\", \"group:eng\"},\n\t\t},\n\t\t{\n\t\t\tname: \"objects_connected_through_a_computed_userset_1\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define owner: [user] as self\n\t\t\t    define editor as owner\n\t\t\t    define viewer: [document#editor] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"document:1#editor\"),\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"owner\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"objects_connected_through_a_computed_userset_2\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define manager: [user] as self\n\t\t\t    define member as manager\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"manager\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"objects_connected_through_a_computed_userset_3\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"trial\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"fede\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype team\n\t\t\t  relations\n\t\t\t    define admin: [user] as self\n\t\t\t    define member: [user,team#member] as self or admin\n\n\t\t\ttype trial\n\t\t\t  relations\n\t\t\t    define editor: [user,team#member] as self or owner\n\t\t\t    define owner: [user] as self\n\t\t\t    define viewer: [user,team#member] as self or editor\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"trial:1\", \"editor\", \"team:devs#member\"),\n\t\t\t\ttuple.NewTupleKey(\"team:devs\", \"admin\", \"user:fede\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"trial:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"objects_connected_indirectly_through_a_ttu\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"view\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"organization\",\n\t\t\t\t\t\tId:   \"2\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype organization\n\t\t\t  relations\n\t\t\t    define viewer: [organization] as self\n\t\t\t    define can_view as viewer\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [organization] as self\n\t\t\t    define view as can_view from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"organization:1\"),\n\t\t\t\ttuple.NewTupleKey(\"organization:1\", \"viewer\", \"organization:2\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"directly_related_typed_wildcard\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser:       &commands.UserRefTypedWildcard{Type: \"user\"},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user, user:*] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"document:3\", \"viewer\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\", \"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"indirectly_related_typed_wildcard\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser:       &commands.UserRefTypedWildcard{Type: \"user\"},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user:*] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"group:fga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"user:*\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"relationship_through_multiple_indirections\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype team\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [team#member] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:tigers\", \"member\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"team:tigers#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"typed_wildcard_relationship_through_multiple_indirections\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [team#member] as self\n\t\t\ttype team\n\t\t\t  relations\n\t\t\t    define member: [user:*] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:tigers\", \"member\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"team:tigers#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"simple_typed_wildcard_and_direct_relation\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{Type: \"user\", Id: \"jon\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user, user:*] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"user:jon\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\", \"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"simple_typed_wildcard_and_indirect_relation\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"jon\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user, user:*] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"group:fga\", \"member\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"group:fga#member\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\", \"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"connected_objects_with_public_user_access_1\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"*\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user:*] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"user:*\"),\n\t\t\t\ttuple.NewTupleKey(\"group:other\", \"member\", \"employee:*\"), // assume this comes from a prior model\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"group:fga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"document:3\", \"viewer\", \"group:other#member\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"connected_objects_with_public_user_access_2\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"resource\",\n\t\t\t\tRelation:   \"reader\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\tId:   \"bev\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define reader: [user, user:*, group#member] as self or writer\n\t\t\t\tdefine writer: [user, user:*, group#member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"resource:x\", \"writer\", \"user:*\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"resource:x\"},\n\t\t},\n\t\t{\n\t\t\tname: \"simple_typed_wildcard_with_contextual_tuples_1\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{\n\t\t\t\t\tObject: &openfgapb.Object{Type: \"user\", Id: \"jon\"},\n\t\t\t\t},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{\n\t\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"user:*\"),\n\t\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"user:jon\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user, user:*] as self\n\t\t\t`,\n\t\t\texpectedObjects: []string{\"document:1\", \"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"simple_typed_wildcard_with_contextual_tuples_2\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser:       &commands.UserRefTypedWildcard{Type: \"user\"},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{\n\t\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"employee:*\"),\n\t\t\t\t\ttuple.NewTupleKey(\"document:2\", \"viewer\", \"user:*\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype employee\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [user:*] as self\n\t\t\t`,\n\t\t\texpectedObjects: []string{\"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"simple_typed_wildcard_with_contextual_tuples_3\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObjectRelation{\n\t\t\t\t\tObjectRelation: &openfgapb.ObjectRelation{\n\t\t\t\t\t\tObject:   \"group:eng\",\n\t\t\t\t\t\tRelation: \"member\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tContextualTuples: []*openfgapb.TupleKey{\n\t\t\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\t\t\t`,\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable_ttu_relationship\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"jon\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define viewer: [user, user:*] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer as viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"folder:1\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"parent\", \"folder:2\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:2\", \"viewer\", \"user:*\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\", \"document:2\"},\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable_ttu_relationship_without_wildcard_connectivity\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"jon\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype employee\n\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define viewer: [user, employee:*] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer as viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"folder:1\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"parent\", \"folder:2\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:1\", \"viewer\", \"user:jon\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:2\", \"viewer\", \"user:*\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable_ttu_relationship_through_indirection_1\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"document\",\n\t\t\t\tRelation:   \"viewer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"jon\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user:*] as self\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define viewer: [group#member] as self\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer as viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"folder:1\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:1\", \"viewer\", \"group:eng#member\"),\n\t\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"user:*\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"document:1\"},\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable_ttu_relationship_through_indirection_2\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"resource\",\n\t\t\t\tRelation:   \"writer\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"anne\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype org\n\t\t\t  relations\n\t\t\t    define dept: [group] as self\n\t\t\t    define dept_member as member from dept\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define writer: [org#dept_member] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"resource:eng_handbook\", \"writer\", \"org:eng#dept_member\"),\n\t\t\t\ttuple.NewTupleKey(\"org:eng\", \"dept\", \"group:fga\"),\n\t\t\t\ttuple.NewTupleKey(\"group:fga\", \"member\", \"user:anne\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"resource:eng_handbook\"},\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable_ttu_relationship_through_indirection_3\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"resource\",\n\t\t\t\tRelation:   \"reader\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"anne\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype org\n\t\t\t  relations\n\t\t\t    define dept: [group] as self\n\t\t\t    define dept_member as member from dept\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t    define member: [user] as self\n\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define writer: [org#dept_member] as self\n\t\t\t    define reader: [org#dept_member] as self or writer\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"resource:eng_handbook\", \"writer\", \"org:eng#dept_member\"),\n\t\t\t\ttuple.NewTupleKey(\"org:eng\", \"dept\", \"group:fga\"),\n\t\t\t\ttuple.NewTupleKey(\"group:fga\", \"member\", \"user:anne\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"resource:eng_handbook\"},\n\t\t},\n\t\t{\n\t\t\tname: \"cyclical_tupleset_relation_terminates\",\n\t\t\trequest: &commands.ConnectedObjectsRequest{\n\t\t\t\tStoreID:    ulid.Make().String(),\n\t\t\t\tObjectType: \"node\",\n\t\t\t\tRelation:   \"editor\",\n\t\t\t\tUser: &commands.UserRefObject{Object: &openfgapb.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"wonder\",\n\t\t\t\t}},\n\t\t\t},\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype node\n\t\t\t  relations\n\t\t\t    define parent: [node] as self\n\t\t\t    define editor: [user] as self or editor from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"node:abc\", \"editor\", \"user:wonder\"),\n\t\t\t},\n\t\t\texpectedObjects: []string{\"node:abc\"},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\tctx := context.Background()\n\t\t\tstore := ulid.Make().String()\n\t\t\ttest.request.StoreID = store\n\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              ulid.Make().String(),\n\t\t\t\tSchemaVersion:   typesystem.SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: parser.MustParse(test.model),\n\t\t\t}\n\t\t\terr := ds.WriteAuthorizationModel(ctx, store, model)\n\t\t\trequire.NoError(err)\n\t\t\ttest.request.Typesystem = typesystem.New(model)\n\n\t\t\terr = ds.Write(ctx, store, nil, test.tuples)\n\t\t\trequire.NoError(err)\n\n\t\t\tif test.resolveNodeLimit == 0 {\n\t\t\t\ttest.resolveNodeLimit = defaultResolveNodeLimit\n\t\t\t}\n\n\t\t\tconnectedObjectsCmd := commands.ConnectedObjectsCommand{\n\t\t\t\tDatastore:        ds,\n\t\t\t\tResolveNodeLimit: test.resolveNodeLimit,\n\t\t\t\tLimit:            test.limit,\n\t\t\t}\n\n\t\t\tresultChan := make(chan commands.ListObjectsResult, 100)\n\t\t\tdone := make(chan struct{})\n\n\t\t\tvar results []string\n\t\t\tgo func() {\n\t\t\t\tfor result := range resultChan {\n\t\t\t\t\tresults = append(results, result.ObjectID)\n\t\t\t\t}\n\n\t\t\t\tdone <- struct{}{}\n\t\t\t}()\n\n\t\t\ttimeoutCtx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\t\t\tdefer cancel()\n\n\t\t\tgo func() {\n\t\t\t\terr = connectedObjectsCmd.StreamedConnectedObjects(timeoutCtx, test.request, resultChan)\n\t\t\t\trequire.ErrorIs(err, test.expectedError)\n\t\t\t\tclose(resultChan)\n\t\t\t}()\n\n\t\t\tselect {\n\t\t\tcase <-timeoutCtx.Done():\n\t\t\t\trequire.FailNow(\"timed out waiting for response\")\n\t\t\tcase <-done:\n\t\t\t}\n\n\t\t\tif test.expectedError == nil {\n\t\t\t\tsort.Strings(results)\n\t\t\t\tsort.Strings(test.expectedObjects)\n\n\t\t\t\trequire.Equal(test.expectedObjects, results)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *FositeSQLStore) ClientAssertionJWTValid(ctx context.Context, jti string) error {\n\td, err := s.getClientAssertionJWT(ctx, jti)\n\tif errors.Is(err, sqlcon.ErrNoRows) {\n\t\t// the jti is not known => valid\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn err\n\t}\n\tif d.Expiry.After(time.Now()) {\n\t\t// the jti is not expired yet => invalid\n\t\treturn errors.WithStack(fosite.ErrJTIKnown)\n\t}\n\t// the jti is expired => valid\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (iter *TagsListResultIterator) Next() error {\n\titer.i++\n\tif iter.i < len(iter.page.Values()) {\n\t\treturn nil\n\t}\n\terr := iter.page.Next()\n\tif err != nil {\n\t\titer.i--\n\t\treturn err\n\t}\n\titer.i = 0\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) ListByResourceGroupSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "\tdir1, s1 := testServerWithConfig(t, func(c *Config) {\n\t\tc.ACLDatacenter = \"dc1\"\n\t\tc.ACLsEnabled = true\n\t\tc.ACLMasterToken = TestDefaultMasterToken\n\t\tc.ACLDefaultPolicy = \"deny\"\n\t})", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\trecover()\n\t}()", "is_vulnerable": 0}
{"code": "func TestImportDashboardAPI(t *testing.T) {\n\tt.Run(\"Quota not reached, schema loader service disabled\", func(t *testing.T) {\n\t\timportDashboardServiceCalled := false\n\t\tservice := &serviceMock{\n\t\t\timportDashboardFunc: func(ctx context.Context, req *dashboardimport.ImportDashboardRequest) (*dashboardimport.ImportDashboardResponse, error) {\n\t\t\t\timportDashboardServiceCalled = true\n\t\t\t\treturn nil, nil\n\t\t\t},\n\t\t}\n\n\t\tschemaLoaderServiceCalled := false\n\t\tschemaLoaderService := &schemaLoaderServiceMock{\n\t\t\tdashboardApplyDefaultsFunc: func(input *simplejson.Json) (*simplejson.Json, error) {\n\t\t\t\tschemaLoaderServiceCalled = true\n\t\t\t\treturn input, nil\n\t\t\t},\n\t\t}\n\n\t\timportDashboardAPI := New(service, quotaServiceFunc(quotaNotReached), schemaLoaderService, nil)\n\t\trouteRegister := routing.NewRouteRegister()\n\t\timportDashboardAPI.RegisterAPIEndpoints(routeRegister)\n\t\ts := webtest.NewServer(t, routeRegister)\n\n\t\tt.Run(\"Not signed in should return 404\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusUnauthorized, resp.StatusCode)\n\t\t})\n\n\t\tt.Run(\"Signed in, empty plugin id and dashboard model empty should return error\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{\n\t\t\t\tPluginId:  \"\",\n\t\t\t\tDashboard: nil,\n\t\t\t}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{\n\t\t\t\tUserId: 1,\n\t\t\t})\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusUnprocessableEntity, resp.StatusCode)\n\t\t})\n\n\t\tt.Run(\"Signed in, dashboard model set should call import dashboard service\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{\n\t\t\t\tDashboard: simplejson.New(),\n\t\t\t}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{\n\t\t\t\tUserId: 1,\n\t\t\t})\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusOK, resp.StatusCode)\n\t\t\trequire.True(t, importDashboardServiceCalled)\n\t\t})\n\n\t\tt.Run(\"Signed in, dashboard model set, trimdefaults enabled should not call schema loader service\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{\n\t\t\t\tDashboard: simplejson.New(),\n\t\t\t}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import?trimdefaults=true\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{\n\t\t\t\tUserId: 1,\n\t\t\t})\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusOK, resp.StatusCode)\n\t\t\trequire.False(t, schemaLoaderServiceCalled)\n\t\t\trequire.True(t, importDashboardServiceCalled)\n\t\t})\n\t})\n\n\tt.Run(\"Quota not reached, schema loader service enabled\", func(t *testing.T) {\n\t\timportDashboardServiceCalled := false\n\t\tservice := &serviceMock{\n\t\t\timportDashboardFunc: func(ctx context.Context, req *dashboardimport.ImportDashboardRequest) (*dashboardimport.ImportDashboardResponse, error) {\n\t\t\t\timportDashboardServiceCalled = true\n\t\t\t\treturn nil, nil\n\t\t\t},\n\t\t}\n\n\t\tschemaLoaderServiceCalled := false\n\t\tschemaLoaderService := &schemaLoaderServiceMock{\n\t\t\tenabled: true,\n\t\t\tdashboardApplyDefaultsFunc: func(input *simplejson.Json) (*simplejson.Json, error) {\n\t\t\t\tschemaLoaderServiceCalled = true\n\t\t\t\treturn input, nil\n\t\t\t},\n\t\t}\n\n\t\timportDashboardAPI := New(service, quotaServiceFunc(quotaNotReached), schemaLoaderService, nil)\n\t\trouteRegister := routing.NewRouteRegister()\n\t\timportDashboardAPI.RegisterAPIEndpoints(routeRegister)\n\t\ts := webtest.NewServer(t, routeRegister)\n\n\t\tt.Run(\"Signed in, dashboard model set, trimdefaults enabled should call schema loader service\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{\n\t\t\t\tDashboard: simplejson.New(),\n\t\t\t}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import?trimdefaults=true\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{\n\t\t\t\tUserId: 1,\n\t\t\t})\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusOK, resp.StatusCode)\n\t\t\trequire.True(t, schemaLoaderServiceCalled)\n\t\t\trequire.True(t, importDashboardServiceCalled)\n\t\t})\n\t})\n\n\tt.Run(\"Quota reached\", func(t *testing.T) {\n\t\tservice := &serviceMock{}\n\t\tschemaLoaderService := &schemaLoaderServiceMock{}\n\t\timportDashboardAPI := New(service, quotaServiceFunc(quotaReached), schemaLoaderService, nil)\n\n\t\trouteRegister := routing.NewRouteRegister()\n\t\timportDashboardAPI.RegisterAPIEndpoints(routeRegister)\n\t\ts := webtest.NewServer(t, routeRegister)\n\n\t\tt.Run(\"Signed in, dashboard model set, should return 403 forbidden/quota reached\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{\n\t\t\t\tDashboard: simplejson.New(),\n\t\t\t}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{\n\t\t\t\tUserId: 1,\n\t\t\t})\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusForbidden, resp.StatusCode)\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *Core) handleLoginRequest(ctx context.Context, req *logical.Request) (retResp *logical.Response, retAuth *logical.Auth, retErr error) {\n\tdefer metrics.MeasureSince([]string{\"core\", \"handle_login_request\"}, time.Now())\n\n\treq.Unauthenticated = true\n\n\tvar nonHMACReqDataKeys []string\n\tentry := c.router.MatchingMountEntry(ctx, req.Path)\n\tif entry != nil {\n\t\t// Get and set ignored HMAC'd value.\n\t\tif rawVals, ok := entry.synthesizedConfigCache.Load(\"audit_non_hmac_request_keys\"); ok {\n\t\t\tnonHMACReqDataKeys = rawVals.([]string)\n\t\t}\n\t}\n\n\t// Do an unauth check. This will cause EGP policies to be checked\n\tvar auth *logical.Auth\n\tvar ctErr error\n\tauth, _, ctErr = c.checkToken(ctx, req, true)\n\tif ctErr == logical.ErrPerfStandbyPleaseForward {\n\t\treturn nil, nil, ctErr\n\t}\n\tif ctErr != nil {\n\t\t// If it is an internal error we return that, otherwise we\n\t\t// return invalid request so that the status codes can be correct\n\t\tvar errType error\n\t\tswitch ctErr {\n\t\tcase ErrInternalError, logical.ErrPermissionDenied:\n\t\t\terrType = ctErr\n\t\tdefault:\n\t\t\terrType = logical.ErrInvalidRequest\n\t\t}\n\n\t\tlogInput := &logical.LogInput{\n\t\t\tAuth:               auth,\n\t\t\tRequest:            req,\n\t\t\tOuterErr:           ctErr,\n\t\t\tNonHMACReqDataKeys: nonHMACReqDataKeys,\n\t\t}\n\t\tif err := c.auditBroker.LogRequest(ctx, logInput, c.auditedHeaders); err != nil {\n\t\t\tc.logger.Error(\"failed to audit request\", \"path\", req.Path, \"error\", err)\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\tif errType != nil {\n\t\t\tretErr = multierror.Append(retErr, errType)\n\t\t}\n\t\tif ctErr == ErrInternalError {\n\t\t\treturn nil, auth, retErr\n\t\t}\n\t\treturn logical.ErrorResponse(ctErr.Error()), auth, retErr\n\t}\n\n\t// Create an audit trail of the request. Attach auth if it was returned,\n\t// e.g. if a token was provided.\n\tlogInput := &logical.LogInput{\n\t\tAuth:               auth,\n\t\tRequest:            req,\n\t\tNonHMACReqDataKeys: nonHMACReqDataKeys,\n\t}\n\tif err := c.auditBroker.LogRequest(ctx, logInput, c.auditedHeaders); err != nil {\n\t\tc.logger.Error(\"failed to audit request\", \"path\", req.Path, \"error\", err)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// The token store uses authentication even when creating a new token,\n\t// so it's handled in handleRequest. It should not be reached here.\n\tif strings.HasPrefix(req.Path, \"auth/token/\") {\n\t\tc.logger.Error(\"unexpected login request for token backend\", \"request_path\", req.Path)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// Route the request\n\tresp, routeErr := c.doRouting(ctx, req)\n\tif resp != nil {\n\t\t// If wrapping is used, use the shortest between the request and response\n\t\tvar wrapTTL time.Duration\n\t\tvar wrapFormat, creationPath string\n\t\tvar sealWrap bool\n\n\t\t// Ensure no wrap info information is set other than, possibly, the TTL\n\t\tif resp.WrapInfo != nil {\n\t\t\tif resp.WrapInfo.TTL > 0 {\n\t\t\t\twrapTTL = resp.WrapInfo.TTL\n\t\t\t}\n\t\t\twrapFormat = resp.WrapInfo.Format\n\t\t\tcreationPath = resp.WrapInfo.CreationPath\n\t\t\tsealWrap = resp.WrapInfo.SealWrap\n\t\t\tresp.WrapInfo = nil\n\t\t}\n\n\t\tif req.WrapInfo != nil {\n\t\t\tif req.WrapInfo.TTL > 0 {\n\t\t\t\tswitch {\n\t\t\t\tcase wrapTTL == 0:\n\t\t\t\t\twrapTTL = req.WrapInfo.TTL\n\t\t\t\tcase req.WrapInfo.TTL < wrapTTL:\n\t\t\t\t\twrapTTL = req.WrapInfo.TTL\n\t\t\t\t}\n\t\t\t}\n\t\t\tif req.WrapInfo.Format != \"\" && wrapFormat == \"\" {\n\t\t\t\twrapFormat = req.WrapInfo.Format\n\t\t\t}\n\t\t}\n\n\t\tif wrapTTL > 0 {\n\t\t\tresp.WrapInfo = &wrapping.ResponseWrapInfo{\n\t\t\t\tTTL:          wrapTTL,\n\t\t\t\tFormat:       wrapFormat,\n\t\t\t\tCreationPath: creationPath,\n\t\t\t\tSealWrap:     sealWrap,\n\t\t\t}\n\t\t}\n\t}\n\n\t// A login request should never return a secret!\n\tif resp != nil && resp.Secret != nil {\n\t\tc.logger.Error(\"unexpected Secret response for login path\", \"request_path\", req.Path)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// If the response generated an authentication, then generate the token\n\tif resp != nil && resp.Auth != nil {\n\n\t\tvar entity *identity.Entity\n\t\tauth = resp.Auth\n\n\t\tmEntry := c.router.MatchingMountEntry(ctx, req.Path)\n\n\t\tif auth.Alias != nil &&\n\t\t\tmEntry != nil &&\n\t\t\t!mEntry.Local &&\n\t\t\tc.identityStore != nil {\n\t\t\t// Overwrite the mount type and mount path in the alias\n\t\t\t// information\n\t\t\tauth.Alias.MountType = req.MountType\n\t\t\tauth.Alias.MountAccessor = req.MountAccessor\n\n\t\t\tif auth.Alias.Name == \"\" {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"missing name in alias\")\n\t\t\t}\n\n\t\t\tvar err error\n\n\t\t\t// Fetch the entity for the alias, or create an entity if one\n\t\t\t// doesn't exist.\n\t\t\tentity, err = c.identityStore.CreateOrFetchEntity(ctx, auth.Alias)\n\t\t\tif err != nil {\n\t\t\t\tentity, err = possiblyForwardAliasCreation(ctx, c, err, auth, entity)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tif entity == nil {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to create an entity for the authenticated alias\")\n\t\t\t}\n\n\t\t\tif entity.Disabled {\n\t\t\t\treturn nil, nil, logical.ErrPermissionDenied\n\t\t\t}\n\n\t\t\tauth.EntityID = entity.ID\n\t\t\tif auth.GroupAliases != nil {\n\t\t\t\tvalidAliases, err := c.identityStore.refreshExternalGroupMembershipsByEntityID(ctx, auth.EntityID, auth.GroupAliases)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, nil, err\n\t\t\t\t}\n\t\t\t\tauth.GroupAliases = validAliases\n\t\t\t}\n\t\t}\n\n\t\t// Determine the source of the login\n\t\tsource := c.router.MatchingMount(ctx, req.Path)\n\t\tsource = strings.TrimPrefix(source, credentialRoutePrefix)\n\t\tsource = strings.Replace(source, \"/\", \"-\", -1)\n\n\t\t// Prepend the source to the display name\n\t\tauth.DisplayName = strings.TrimSuffix(source+auth.DisplayName, \"-\")\n\n\t\tsysView := c.router.MatchingSystemView(ctx, req.Path)\n\t\tif sysView == nil {\n\t\t\tc.logger.Error(\"unable to look up sys view for login path\", \"request_path\", req.Path)\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\ttokenTTL, warnings, err := framework.CalculateTTL(sysView, 0, auth.TTL, auth.Period, auth.MaxTTL, auth.ExplicitMaxTTL, time.Time{})\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tfor _, warning := range warnings {\n\t\t\tresp.AddWarning(warning)\n\t\t}\n\n\t\tns, err := namespace.FromContext(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\t_, identityPolicies, err := c.fetchEntityAndDerivedPolicies(ctx, ns, auth.EntityID)\n\t\tif err != nil {\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\tauth.TokenPolicies = policyutil.SanitizePolicies(auth.Policies, !auth.NoDefaultPolicy)\n\t\tallPolicies := policyutil.SanitizePolicies(append(auth.TokenPolicies, identityPolicies[ns.ID]...), policyutil.DoNotAddDefaultPolicy)\n\n\t\t// Prevent internal policies from being assigned to tokens. We check\n\t\t// this on auth.Policies including derived ones from Identity before\n\t\t// actually making the token.\n\t\tfor _, policy := range allPolicies {\n\t\t\tif policy == \"root\" {\n\t\t\t\treturn logical.ErrorResponse(\"auth methods cannot create root tokens\"), nil, logical.ErrInvalidRequest\n\t\t\t}\n\t\t\tif strutil.StrListContains(nonAssignablePolicies, policy) {\n\t\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"cannot assign policy %q\", policy)), nil, logical.ErrInvalidRequest\n\t\t\t}\n\t\t}\n\n\t\tvar registerFunc RegisterAuthFunc\n\t\tvar funcGetErr error\n\t\t// Batch tokens should not be forwarded to perf standby\n\t\tif auth.TokenType == logical.TokenTypeBatch {\n\t\t\tregisterFunc = c.RegisterAuth\n\t\t} else {\n\t\t\tregisterFunc, funcGetErr = getAuthRegisterFunc(c)\n\t\t}\n\t\tif funcGetErr != nil {\n\t\t\tretErr = multierror.Append(retErr, funcGetErr)\n\t\t\treturn nil, auth, retErr\n\t\t}\n\n\t\terr = registerFunc(ctx, tokenTTL, req.Path, auth)\n\t\tswitch {\n\t\tcase err == nil:\n\t\tcase err == ErrInternalError:\n\t\t\treturn nil, auth, err\n\t\tdefault:\n\t\t\treturn logical.ErrorResponse(err.Error()), auth, logical.ErrInvalidRequest\n\t\t}\n\n\t\tauth.IdentityPolicies = policyutil.SanitizePolicies(identityPolicies[ns.ID], policyutil.DoNotAddDefaultPolicy)\n\t\tdelete(identityPolicies, ns.ID)\n\t\tauth.ExternalNamespacePolicies = identityPolicies\n\t\tauth.Policies = allPolicies\n\n\t\t// Attach the display name, might be used by audit backends\n\t\treq.DisplayName = auth.DisplayName\n\n\t}\n\n\treturn resp, auth, routeErr\n}", "is_vulnerable": 1}
{"code": "func New(opts ...Options) *Teler {\n\tvar o Options\n\n\t// Set default options if none are provided\n\tif len(opts) == 0 {\n\t\to = Options{}\n\t} else {\n\t\to = opts[0]\n\t}\n\n\t// Create a new Teler struct and initialize its handler and threat fields\n\tt := &Teler{\n\t\thandler: http.HandlerFunc(defaultHandler),\n\t\tthreat:  &Threat{},\n\t}\n\n\t// Retrieve the data for each threat category\n\terr := t.getResources()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(errResources, err))\n\t}\n\n\t// Initialize writer for logging and add standard error (stderr)\n\t// as writer if NoStderr is false\n\tws := []zapcore.WriteSyncer{}\n\tif !o.NoStderr {\n\t\tws = append(ws, os.Stderr)\n\t}\n\n\t// If the LogFile option is set, open the log file and\n\t// set the log field of the Teler struct to the file descriptor\n\tif o.LogFile != \"\" {\n\t\tt.out, err = os.OpenFile(o.LogFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) // nosemgrep: trailofbits.go.questionable-assignment.questionable-assignment\n\t\tif err != nil {\n\t\t\tpanic(fmt.Sprintf(errLogFile, err))\n\t\t}\n\n\t\tws = append(ws, t.out)\n\t}\n\n\t// Create a new logger with the multiwriter as the output destination\n\tmw := zapcore.NewMultiWriteSyncer(ws...)\n\tt.log = zap.New(zapcore.NewCore(\n\t\tzapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()), // Use JSON encoding\n\t\tmw,            // Use the multiwriter\n\t\tzap.WarnLevel, // Set the logging level to debug\n\t))\n\n\t// The defer statement is used to ensure that the Sync function is called before the function exits.\n\t// This is used to flush any buffered writes to the output stream.\n\tdefer func() {\n\t\t_ = t.log.Sync()\n\t}()\n\n\t// Initialize the excludes field of the Threat struct to a new map and\n\t// set the boolean flag for each threat category specified in the Excludes option to true\n\tt.threat.excludes = map[threat.Threat]bool{\n\t\tthreat.CommonWebAttack:     false,\n\t\tthreat.CVE:                 false,\n\t\tthreat.BadIPAddress:        false,\n\t\tthreat.BadReferrer:         false,\n\t\tthreat.BadCrawler:          false,\n\t\tthreat.DirectoryBruteforce: false,\n\t}\n\tfor _, ex := range o.Excludes {\n\t\tt.threat.excludes[ex] = true\n\t}\n\n\t// For each entry in the Whitelists option, compile a regular expression and\n\t// add it to the whitelistRegexes slice of the Teler struct\n\tfor _, wl := range o.Whitelists {\n\t\tregex, err := regexp.Compile(wl)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Sprintf(errWhitelist, wl, err))\n\t\t}\n\t\tt.whitelistRegexes = append(t.whitelistRegexes, regex)\n\t}\n\n\t// Iterate over the Customs option and verify that each custom rule has a non-empty name and a valid condition\n\t// Compile the regular expression pattern for each rule and add it to the patternRegex field of the Rule struct\n\tfor _, rule := range o.Customs {\n\t\tif rule.Name == \"\" {\n\t\t\tpanic(errInvalidRuleName)\n\t\t}\n\n\t\t// Convert the condition to lowercase, if empty string then defaulting to \"or\"\n\t\trule.Condition = strings.ToLower(rule.Condition)\n\t\tif rule.Condition == \"\" {\n\t\t\trule.Condition = \"or\"\n\t\t}\n\n\t\t// Check the condition is either \"or\" or \"and\"\n\t\tif rule.Condition != \"or\" && rule.Condition != \"and\" {\n\t\t\tpanic(fmt.Sprintf(errInvalidRuleCond, rule.Name, rule.Condition))\n\t\t}\n\n\t\t// Iterate over the rules in the custom rules\n\t\tfor i, cond := range rule.Rules {\n\t\t\t// Check if the method rule condition is valid, and\n\t\t\t// set to UNDEFINED if it isn't.\n\t\t\tif !isValidMethod(cond.Method) {\n\t\t\t\tcond.Method = request.UNDEFINED\n\t\t\t}\n\n\t\t\t// Defaulting method rule condition to GET if empty or undefined\n\t\t\tif cond.Method == request.UNDEFINED {\n\t\t\t\tcond.Method = request.GET\n\t\t\t}\n\n\t\t\t// Empty pattern cannot be process\n\t\t\tif cond.Pattern == \"\" {\n\t\t\t\tpanic(fmt.Sprintf(errPattern, rule.Name, \"pattern can't be blank\"))\n\t\t\t}\n\n\t\t\t// Compile the regular expression pattern\n\t\t\tregex, err := regexp.Compile(cond.Pattern)\n\t\t\tif err != nil {\n\t\t\t\tpanic(fmt.Sprintf(errPattern, rule.Name, err))\n\t\t\t}\n\n\t\t\trule.Rules[i].patternRegex = regex\n\t\t}\n\t}\n\n\t// If development mode is enabled, create a cache with no default\n\t// expiration time and clean up interval by 15 minutes.\n\tif !o.Development {\n\t\tt.cache = cache.New(time.Duration(0), 15*time.Minute)\n\t}\n\n\t// Set the opt field of the Teler struct to the options\n\tt.opt = o\n\n\treturn t\n}", "is_vulnerable": 0}
{"code": "func (s *PrecompileTestSuite) setupRedelegations(redelAmt *big.Int) error {\n\tmsg := stakingtypes.MsgBeginRedelegate{\n\t\tDelegatorAddress:    sdk.AccAddress(s.address.Bytes()).String(),\n\t\tValidatorSrcAddress: s.validators[0].OperatorAddress,\n\t\tValidatorDstAddress: s.validators[1].OperatorAddress,\n\t\tAmount:              sdk.NewCoin(s.bondDenom, math.NewIntFromBigInt(redelAmt)),\n\t}\n\n\tmsgSrv := stakingkeeper.NewMsgServerImpl(&s.app.StakingKeeper)\n\t// create 2 entries for same redelegation\n\tfor i := 0; i < 2; i++ {\n\t\tif _, err := msgSrv.BeginRedelegate(s.ctx, &msg); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// create a validator with s.address and s.privKey\n\t// then create a redelegation from validator[0] to this new validator\n\ttestutil.CreateValidator(s.ctx, s.T(), s.privKey.PubKey(), s.app.StakingKeeper, math.NewInt(100))\n\tmsg.ValidatorDstAddress = sdk.ValAddress(s.address.Bytes()).String()\n\t_, err := msgSrv.BeginRedelegate(s.ctx, &msg)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GenerateStage(ctx context.Context, in *clientpb.GenerateStageReq, opts ...grpc.CallOption) (*clientpb.Generate, error) {\n\tout := new(clientpb.Generate)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GenerateStage\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func dup2(oldfd int, newfd int) error\n\nfunc Pause() error {\n\t_, err := ppoll(nil, 0, nil, nil)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func TestStreamConfigHandler(t *testing.T) {\n\tt.Run(\"test config\", func(t *testing.T) {\n\t\tv := map[string]interface{}{\n\t\t\t\"max_header_size\":       1024,\n\t\t\t\"max_request_body_size\": 1024,\n\t\t}\n\t\trv := streamConfigHandler(v)\n\t\tcfg, ok := rv.(StreamConfig)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"config handler should returns an StreamConfig\")\n\t\t}\n\t\tif !(cfg.MaxHeaderSize == 1024 &&\n\t\t\tcfg.MaxRequestBodySize == 1024) {\n\t\t\tt.Fatalf(\"unexpected config: %v\", cfg)\n\t\t}\n\t})\n\tt.Run(\"test body size\", func(t *testing.T) {\n\t\tv := map[string]interface{}{\n\t\t\t\"max_request_body_size\": 8192,\n\t\t}\n\t\trv := streamConfigHandler(v)\n\t\tcfg, ok := rv.(StreamConfig)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"config handler should returns an StreamConfig\")\n\t\t}\n\t\tif cfg.MaxHeaderSize != defaultMaxHeaderSize {\n\t\t\tt.Fatalf(\"no header size configured, should use default header size but not: %d\", cfg.MaxHeaderSize)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestInvalidIngressAuthNoSecret(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"auth-type\")] = \"basic\"\n\ting.SetAnnotations(data)\n\n\t_, dir, _ := dummySecretContent(t)\n\tdefer os.RemoveAll(dir)\n\n\texpected := ing_errors.LocationDenied{\n\t\tReason: errors.New(\"error reading secret name from annotation: ingress rule without annotations\"),\n\t}\n\t_, err := NewParser(dir, &mockSecret{}).Parse(ing)\n\tif err.Error() != expected.Reason.Error() {\n\t\tt.Errorf(\"expected '%v' but got '%v'\", expected, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Grep(ctx context.Context, in *sliverpb.GrepReq, opts ...grpc.CallOption) (*sliverpb.Grep, error) {\n\tout := new(sliverpb.Grep)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Grep\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (c *components) Supported() bool {\n\treturn c.platform == \"kubernetes\" || c.platform == \"standalone\"\n}", "is_vulnerable": 1}
{"code": "\tsetup := func(t *testing.T, ignores []v1alpha1.ResourceIgnoreDifferences) *fixture {\n\t\tt.Helper()\n\t\tdc, err := diff.NewDiffConfigBuilder().\n\t\t\tWithDiffSettings(ignores, nil, true).\n\t\t\tWithNoCache().\n\t\t\tBuild()\n\t\trequire.NoError(t, err)\n\t\tlive := test.YamlToUnstructured(testdata.LiveDeploymentYaml)\n\t\ttarget := test.YamlToUnstructured(testdata.TargetDeploymentYaml)\n\t\treturn &fixture{\n\t\t\t&comparisonResult{\n\t\t\t\treconciliationResult: sync.ReconciliationResult{\n\t\t\t\t\tLive:   []*unstructured.Unstructured{live},\n\t\t\t\t\tTarget: []*unstructured.Unstructured{target},\n\t\t\t\t},\n\t\t\t\tdiffConfig: dc,\n\t\t\t},\n\t\t}\n\t}\n\tt.Run(\"will modify target resource adding live state in fields it should ignore\", func(t *testing.T) {\n\t\t// given\n\t\tignore := v1alpha1.ResourceIgnoreDifferences{\n\t\t\tGroup:                 \"*\",\n\t\t\tKind:                  \"*\",\n\t\t\tManagedFieldsManagers: []string{\"janitor\"},\n\t\t}\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{ignore}\n\t\tf := setup(t, ignores)\n\n\t\t// when\n\t\ttargets, err := normalizeTargetResources(f.comparisonResult)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(targets))\n\t\tiksmVersion := targets[0].GetAnnotations()[\"iksm-version\"]\n\t\tassert.Equal(t, \"2.0\", iksmVersion)\n\t})\n\tt.Run(\"will not modify target resource if ignore difference is not configured\", func(t *testing.T) {\n\t\t// given\n\t\tf := setup(t, []v1alpha1.ResourceIgnoreDifferences{})\n\n\t\t// when\n\t\ttargets, err := normalizeTargetResources(f.comparisonResult)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(targets))\n\t\tiksmVersion := targets[0].GetAnnotations()[\"iksm-version\"]\n\t\tassert.Equal(t, \"1.0\", iksmVersion)\n\t})\n\tt.Run(\"will remove fields from target if not present in live\", func(t *testing.T) {\n\t\tignore := v1alpha1.ResourceIgnoreDifferences{\n\t\t\tGroup:        \"apps\",\n\t\t\tKind:         \"Deployment\",\n\t\t\tJSONPointers: []string{\"/metadata/annotations/iksm-version\"},\n\t\t}\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{ignore}\n\t\tf := setup(t, ignores)\n\t\tlive := f.comparisonResult.reconciliationResult.Live[0]\n\t\tunstructured.RemoveNestedField(live.Object, \"metadata\", \"annotations\", \"iksm-version\")\n\n\t\t// when\n\t\ttargets, err := normalizeTargetResources(f.comparisonResult)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(targets))\n\t\t_, ok := targets[0].GetAnnotations()[\"iksm-version\"]\n\t\tassert.False(t, ok)\n\t})\n\tt.Run(\"will correctly normalize with multiple ignore configurations\", func(t *testing.T) {\n\t\t// given\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{\n\t\t\t{\n\t\t\t\tGroup:        \"apps\",\n\t\t\t\tKind:         \"Deployment\",\n\t\t\t\tJSONPointers: []string{\"/spec/replicas\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tGroup:                 \"*\",\n\t\t\t\tKind:                  \"*\",\n\t\t\t\tManagedFieldsManagers: []string{\"janitor\"},\n\t\t\t},\n\t\t}\n\t\tf := setup(t, ignores)\n\n\t\t// when\n\t\ttargets, err := normalizeTargetResources(f.comparisonResult)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(targets))\n\t\tnormalized := targets[0]\n\t\tiksmVersion, ok := normalized.GetAnnotations()[\"iksm-version\"]\n\t\trequire.True(t, ok)\n\t\tassert.Equal(t, \"2.0\", iksmVersion)\n\t\treplicas, ok, err := unstructured.NestedInt64(normalized.Object, \"spec\", \"replicas\")\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, ok)\n\t\tassert.Equal(t, int64(4), replicas)\n\t})\n\tt.Run(\"will keep new array entries not found in live state if not ignored\", func(t *testing.T) {\n\t\tt.Skip(\"limitation in the current implementation\")\n\t\t// given\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{\n\t\t\t{\n\t\t\t\tGroup:             \"apps\",\n\t\t\t\tKind:              \"Deployment\",\n\t\t\t\tJQPathExpressions: []string{\".spec.template.spec.containers[] | select(.name == \\\"guestbook-ui\\\")\"},\n\t\t\t},\n\t\t}\n\t\tf := setup(t, ignores)\n\t\ttarget := test.YamlToUnstructured(testdata.TargetDeploymentNewEntries)\n\t\tf.comparisonResult.reconciliationResult.Target = []*unstructured.Unstructured{target}\n\n\t\t// when\n\t\ttargets, err := normalizeTargetResources(f.comparisonResult)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(targets))\n\t\tcontainers, ok, err := unstructured.NestedSlice(targets[0].Object, \"spec\", \"template\", \"spec\", \"containers\")\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, ok)\n\t\tassert.Equal(t, 2, len(containers))\n\t})\n}", "is_vulnerable": 1}
{"code": "func (kp *kmsKeyHandler) GenerateCipherDataWithContext(ctx aws.Context, keySize, ivSize int) (CipherData, error) {\n\tout, err := kp.kms.GenerateDataKeyWithContext(ctx,\n\t\t&kms.GenerateDataKeyInput{\n\t\t\tEncryptionContext: kp.CipherData.MaterialDescription,\n\t\t\tKeyId:             kp.cmkID,\n\t\t\tKeySpec:           aws.String(\"AES_256\"),\n\t\t})\n\tif err != nil {\n\t\treturn CipherData{}, err\n\t}\n\n\tiv := generateBytes(ivSize)\n\tcd := CipherData{\n\t\tKey:                 out.Plaintext,\n\t\tIV:                  iv,\n\t\tWrapAlgorithm:       KMSWrap,\n\t\tMaterialDescription: kp.CipherData.MaterialDescription,\n\t\tEncryptedKey:        out.CiphertextBlob,\n\t}\n\treturn cd, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CrackFileCreate(ctx context.Context, in *clientpb.CrackFile, opts ...grpc.CallOption) (*clientpb.CrackFile, error) {\n\tout := new(clientpb.CrackFile)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/CrackFileCreate\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (src *BackendKeyData) Encode(dst []byte) []byte {\n\tdst = append(dst, 'K')\n\tdst = pgio.AppendUint32(dst, 12)\n\tdst = pgio.AppendUint32(dst, src.ProcessID)\n\tdst = pgio.AppendUint32(dst, src.SecretKey)\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (s *SshExecutor) DeviceSetup(host, device, vgid string) (d *executors.DeviceInfo, e error) {\n\n\t// Setup commands\n\tcommands := []string{\n\t\tfmt.Sprintf(\"pvcreate --metadatasize=128M --dataalignment=256K '%v'\", device),\n\t\tfmt.Sprintf(\"vgcreate %v %v\", s.vgName(vgid), device),\n\t}\n\n\t// Execute command\n\t_, err := s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create a cleanup function if anything fails\n\tdefer func() {\n\t\tif e != nil {\n\t\t\ts.DeviceTeardown(host, device, vgid)\n\t\t}\n\t}()\n\n\t// Vg info\n\td = &executors.DeviceInfo{}\n\terr = s.getVgSizeFromNode(d, host, device, vgid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn d, nil\n}", "is_vulnerable": 0}
{"code": "func (c Certificate) GetTLSConfigForServer() (*tls.Config, error) {\n\tcertificate, err := tls.LoadX509KeyPair(\n\t\tc.CertFile,\n\t\tc.KeyFile,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcertPool := x509.NewCertPool()\n\tbs, err := ioutil.ReadFile(c.CAFile)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read client ca cert: %s\", err)\n\t}\n\n\tok := certPool.AppendCertsFromPEM(bs)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to append client certs\")\n\t}\n\n\ttlsConfig := &tls.Config{\n\t\tClientAuth:   tls.RequireAndVerifyClientCert,\n\t\tCertificates: []tls.Certificate{certificate},\n\t\tClientCAs:    certPool,\n\t}\n\n\treturn tlsConfig, nil\n}", "is_vulnerable": 0}
{"code": "func FilterPath(root, path string) (string, error) {\n\n\tnewPath := fmt.Sprintf(\"%s%s\", root, path)\n\tabsPath, err := filepath.Abs(newPath)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tabsPath = filepath.FromSlash(absPath)\n\tifOver := filepath.HasPrefix(absPath, filepath.FromSlash(root))\n\tfmt.Println(absPath)\n\tfmt.Println(filepath.FromSlash(root))\n\tif !ifOver {\n\t\treturn \"\", errors.New(\"access to the path is prohibited\")\n\t}\n\n\treturn absPath, nil\n}", "is_vulnerable": 0}
{"code": "func TestLimitsPrepareForPublishing(t *testing.T) {\n\tlimits := newLimitTracker(10)\n\n\tfor i := 0; i < 10; i++ {\n\t\tresult := limits.prepareForPublishing()\n\t\trequire.True(t, result)\n\t}\n\n\tresult := limits.prepareForPublishing()\n\trequire.False(t, result)\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) CalculateTemplateHashPreparer(ctx context.Context, templateParameter interface{}) (*http.Request, error) {\n\tconst APIVersion = \"2016-02-01\"\n\tqueryParameters := map[string]interface{}{\n\t\t\"api-version\": APIVersion,\n\t}\n\n\tpreparer := autorest.CreatePreparer(\n\t\tautorest.AsContentType(\"application/json; charset=utf-8\"),\n\t\tautorest.AsPost(),\n\t\tautorest.WithBaseURL(client.BaseURI),\n\t\tautorest.WithPath(\"/providers/Microsoft.Resources/calculateTemplateHash\"),\n\t\tautorest.WithJSON(templateParameter),\n\t\tautorest.WithQueryParameters(queryParameters))\n\treturn preparer.Prepare((&http.Request{}).WithContext(ctx))\n}", "is_vulnerable": 0}
{"code": "func migrationsSqlCockroach11SqlBytes() ([]byte, error) {\n\treturn bindataRead(\n\t\t_migrationsSqlCockroach11Sql,\n\t\t\"migrations/sql/cockroach/11.sql\",\n\t)\n}", "is_vulnerable": 0}
{"code": "func HTTPWrappersForConfig(config *Config, rt http.RoundTripper) (http.RoundTripper, error) {\n\tif config.WrapTransport != nil {\n\t\trt = config.WrapTransport(rt)\n\t}\n\n\trt = DebugWrappers(rt)\n\n\t// Set authentication wrappers\n\tswitch {\n\tcase config.HasBasicAuth() && config.HasTokenAuth():\n\t\treturn nil, fmt.Errorf(\"username/password or bearer token may be set, but not both\")\n\tcase config.HasTokenAuth():\n\t\tvar err error\n\t\trt, err = NewBearerAuthWithRefreshRoundTripper(config.BearerToken, config.BearerTokenFile, rt)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tcase config.HasBasicAuth():\n\t\trt = NewBasicAuthRoundTripper(config.Username, config.Password, rt)\n\t}\n\tif len(config.UserAgent) > 0 {\n\t\trt = NewUserAgentRoundTripper(config.UserAgent, rt)\n\t}\n\tif len(config.Impersonate.UserName) > 0 ||\n\t\tlen(config.Impersonate.Groups) > 0 ||\n\t\tlen(config.Impersonate.Extra) > 0 {\n\t\trt = NewImpersonatingRoundTripper(config.Impersonate, rt)\n\t}\n\treturn rt, nil\n}", "is_vulnerable": 0}
{"code": "func TestWithWorkspace(t *testing.T) {\n\tcompiler := New(\n\t\tWithWorkspace(\n\t\t\t\"/pipeline\",\n\t\t\t\"src/github.com/octocat/hello-world\",\n\t\t),\n\t)\n\tassert.Equal(t, \"/pipeline\", compiler.base)\n\tassert.Equal(t, \"src/github.com/octocat/hello-world\", compiler.path)\n}", "is_vulnerable": 1}
{"code": "func TestSendBody(t *testing.T) {\n\tvar (\n\t\ttestcases = []struct {\n\t\t\turl         string\n\t\t\tcontentType string\n\t\t\texpected    bool\n\t\t}{\n\t\t\t{\n\t\t\t\tcontentType: \"application/json\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"Application/json\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"application/JSON\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"APPLICATION/JSON\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"application/json; charset=utf-8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"application/json;charset=utf-8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"application/json; charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"text/html\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\tcontentType: \"\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/auth\",\n\t\t\t\tcontentType: \"\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/auth?p1=test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/test?p1=/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/something/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/v1.24/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"nothing.com/v1/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"www.nothing.com/v1.24/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"https://www.nothing.com/v1.24/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"http://nothing.com/v1.24/auth/test\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    false,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"www.nothing.com/test?p1=/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"http://www.nothing.com/test?p1=/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"www.nothing.com/something/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t\t{\n\t\t\t\turl:         \"https://www.nothing.com/something/auth\",\n\t\t\t\tcontentType: \"application/json;charset=UTF8\",\n\t\t\t\texpected:    true,\n\t\t\t},\n\t\t}\n\t)\n\n\tfor _, testcase := range testcases {\n\t\theader := http.Header{}\n\t\theader.Set(\"Content-Type\", testcase.contentType)\n\t\tif testcase.url == \"\" {\n\t\t\ttestcase.url = \"nothing.com\"\n\t\t}\n\n\t\tif b := sendBody(testcase.url, header); b != testcase.expected {\n\t\t\tt.Fatalf(\"sendBody failed: url: %s, content-type: %s; Expected: %t, Actual: %t\", testcase.url, testcase.contentType, testcase.expected, b)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "\tb.Run(\"default\", func(b *testing.B) {\n\t\tapp, store := fiber.New(), New()\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\t\tb.RunParallel(func(pb *testing.PB) {\n\t\t\tfor pb.Next() {\n\t\t\t\tc := app.AcquireCtx(&fasthttp.RequestCtx{})\n\t\t\t\tc.Request().Header.SetCookie(store.sessionName, \"12356789\")\n\n\t\t\t\tsess, _ := store.Get(c) //nolint:errcheck // We're inside a benchmark\n\t\t\t\tsess.Set(\"john\", \"doe\")\n\t\t\t\t_ = sess.Save() //nolint:errcheck // We're inside a benchmark\n\t\t\t\tapp.ReleaseCtx(c)\n\t\t\t}\n\t\t})\n\t})", "is_vulnerable": 0}
{"code": "func newMount(m specs.Mount) vc.Mount {\n\treadonly := false\n\tfor _, flag := range m.Options {\n\t\tif flag == \"ro\" {\n\t\t\treadonly = true\n\t\t\tbreak\n\t\t}\n\t}\n\treturn vc.Mount{\n\t\tSource:      m.Source,\n\t\tDestination: m.Destination,\n\t\tType:        m.Type,\n\t\tOptions:     m.Options,\n\t\tReadOnly:    readonly,\n\t}\n}", "is_vulnerable": 0}
{"code": "func main() {\n\t// Load the version\n\n\tversion, err := ioutil.ReadFile(\"./VERSION\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tkingpin.Version(string(version))\n\n\t// Parse the CLI flags and load the config\n\tkingpin.CommandLine.HelpFlag.Short('h')\n\tkingpin.Parse()\n\n\t// Load the config\n\tconf, err := config.LoadConfig(*configPath)\n\t// Just warn if a contact address hasn't been configured\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tif conf.ContactAddress == \"\" {\n\t\tlog.Warnf(\"No contact address has been configured.\")\n\t\tlog.Warnf(\"Please consider adding a contact_address entry in your config.json\")\n\t}\n\tconfig.Version = string(version)\n\n\t// Configure our various upstream clients to make sure that we restrict\n\t// outbound connections as needed.\n\tdialer.SetAllowedHosts(conf.AdminConf.AllowedInternalHosts)\n\twebhook.SetTransport(&http.Transport{\n\t\tDialContext: dialer.Dialer().DialContext,\n\t})\n\n\terr = log.Setup(conf.Logging)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Provide the option to disable the built-in mailer\n\t// Setup the global variables and settings\n\terr = models.Setup(conf)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Unlock any maillogs that may have been locked for processing\n\t// when Gophish was last shutdown.\n\terr = models.UnlockAllMailLogs()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Create our servers\n\tadminOptions := []controllers.AdminServerOption{}\n\tif *disableMailer {\n\t\tadminOptions = append(adminOptions, controllers.WithWorker(nil))\n\t}\n\tadminConfig := conf.AdminConf\n\tadminServer := controllers.NewAdminServer(adminConfig, adminOptions...)\n\tmiddleware.Store.Options.Secure = adminConfig.UseTLS\n\n\tphishConfig := conf.PhishConf\n\tphishServer := controllers.NewPhishingServer(phishConfig)\n\n\timapMonitor := imap.NewMonitor()\n\tif *mode == \"admin\" || *mode == \"all\" {\n\t\tgo adminServer.Start()\n\t\tgo imapMonitor.Start()\n\t}\n\tif *mode == \"phish\" || *mode == \"all\" {\n\t\tgo phishServer.Start()\n\t}\n\n\t// Handle graceful shutdown\n\tc := make(chan os.Signal, 1)\n\tsignal.Notify(c, os.Interrupt)\n\t<-c\n\tlog.Info(\"CTRL+C Received... Gracefully shutting down servers\")\n\tif *mode == modeAdmin || *mode == modeAll {\n\t\tadminServer.Shutdown()\n\t\timapMonitor.Shutdown()\n\t}\n\tif *mode == modePhish || *mode == modeAll {\n\t\tphishServer.Shutdown()\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func untarChart(tempDir string, cachedChartPath string, manifestMaxExtractedSize int64, disableManifestMaxExtractedSize bool) error {\n\tif disableManifestMaxExtractedSize {\n\t\tcmd := exec.Command(\"tar\", \"-zxvf\", cachedChartPath)\n\t\tcmd.Dir = tempDir\n\t\t_, err := executil.Run(cmd)\n\t\treturn err\n\t}\n\treader, err := os.Open(cachedChartPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn files.Untgz(tempDir, reader, manifestMaxExtractedSize, false)\n}", "is_vulnerable": 0}
{"code": "func (i *instances) Supported() bool {\n\treturn i.platform == platforms.Kubernetes || i.platform == platforms.Standalone || i.platform == platforms.DockerCompose\n}", "is_vulnerable": 0}
{"code": "func (d *Decoder) MaxSize(size int) {\n\td.maxSize = size\n}", "is_vulnerable": 0}
{"code": "\tassertPaths := func(expectedFiles []string, expectedDirs []string) func(t testing.TB, fs afero.Fs) {\n\t\treturn func(t testing.TB, fs afero.Fs) {\n\t\t\tt.Helper()\n\n\t\t\tsort.Strings(expectedFiles)\n\t\t\thaveFiles := strset.New()\n\t\t\thaveDirs := strset.New()\n\t\t\terr := afero.Walk(fs, \"/\", func(path string, info os.FileInfo, err error) error {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif info.IsDir() {\n\t\t\t\t\thaveDirs.Add(path)\n\t\t\t\t} else {\n\t\t\t\t\thaveFiles.Add(path)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\n\t\t\thaveFilesList := haveFiles.List()\n\t\t\tsort.Strings(haveFilesList)\n\n\t\t\thaveDirsList := haveDirs.List()\n\t\t\tsort.Strings(haveDirsList)\n\n\t\t\trequire.NoError(t, err)\n\n\t\t\tif d := cmp.Diff(expectedFiles, haveFilesList); d != \"\" {\n\t\t\t\tt.Errorf(\"unexpected files (-want +got):\\n%s\", d)\n\t\t\t}\n\n\t\t\tif d := cmp.Diff(expectedDirs, haveDirsList); d != \"\" {\n\t\t\t\tt.Errorf(\"unexpected dirs (-want +got):\\n%s\", d)\n\t\t\t}\n\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "\t\treturn sasl.NewLoginServer(func(username, password string) error {\n\t\t\taccounts, err := s.AuthPlain(username, password)\n\t\t\tif err != nil {\n\t\t\t\ts.Log.Error(\"authentication failed\", err, \"username\", username, \"src_ip\", remoteAddr)\n\t\t\t\treturn errors.New(\"auth: invalid credentials\")\n\t\t\t}\n\n\t\t\treturn successCb(accounts)\n\t\t})", "is_vulnerable": 1}
{"code": "\treturn func(ctx context.Context) (*ResolveCheckResponse, error) {\n\t\tparentReq.GetRequestMetadata().DispatchCounter.Add(1)\n\t\tchildRequest := clone(parentReq)\n\t\tchildRequest.TupleKey = tk\n\t\tchildRequest.GetRequestMetadata().Depth--\n\n\t\tresp, err := c.delegate.ResolveCheck(ctx, childRequest)\n\t\tif err != nil {\n\t\t\treturn resp, err\n\t\t}\n\t\treturn resp, nil\n\t}", "is_vulnerable": 1}
{"code": "func TestValidateSubscription(t *testing.T) {\n\tp := &Plugin{}\n\n\tp.instanceStore = p.getMockInstanceStoreKV(0)\n\n\tapi := &plugintest.API{}\n\tp.SetAPI(api)\n\n\tfor name, tc := range map[string]struct {\n\t\tsubscription          *ChannelSubscription\n\t\terrorMessage          string\n\t\tdisableSecurityConfig bool\n\t}{\n\t\t\"no event selected\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(),\n\t\t\t\t\tProjects:   NewStringSet(\"project\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"please provide at least one event type\",\n\t\t},\n\t\t\"no project selected\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"please provide a project identifier\",\n\t\t},\n\t\t\"no issue type selected\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"project\"),\n\t\t\t\t\tIssueTypes: NewStringSet(),\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"please provide at least one issue type\",\n\t\t},\n\t\t\"valid subscription\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"project\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"\",\n\t\t},\n\t\t\"valid subscription with security level\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"TEST\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t\tFields: []FieldFilter{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tKey:       \"security\",\n\t\t\t\t\t\t\tInclusion: FilterIncludeAll,\n\t\t\t\t\t\t\tValues:    NewStringSet(\"10001\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"\",\n\t\t},\n\t\t\"invalid 'Exclude' of security level\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"TEST\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t\tFields: []FieldFilter{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tKey:       \"security\",\n\t\t\t\t\t\t\tInclusion: FilterExcludeAny,\n\t\t\t\t\t\t\tValues:    NewStringSet(\"10001\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"security level does not allow for an \\\"Exclude\\\" clause\",\n\t\t},\n\t\t\"security config disabled, valid 'Exclude' of security level\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"TEST\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t\tFields: []FieldFilter{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tKey:       \"security\",\n\t\t\t\t\t\t\tInclusion: FilterExcludeAny,\n\t\t\t\t\t\t\tValues:    NewStringSet(\"10001\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tdisableSecurityConfig: true,\n\t\t\terrorMessage:          \"\",\n\t\t},\n\t\t\"invalid access to security level\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(\"TEST\"),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t\tFields: []FieldFilter{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tKey:       \"security\",\n\t\t\t\t\t\t\tInclusion: FilterIncludeAll,\n\t\t\t\t\t\t\tValues:    NewStringSet(\"10002\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"invalid access to security level\",\n\t\t},\n\t\t\"user does not have read access to the project\": {\n\t\t\tsubscription: &ChannelSubscription{\n\t\t\t\tID:         \"id\",\n\t\t\t\tName:       \"name\",\n\t\t\t\tChannelID:  \"channelid\",\n\t\t\t\tInstanceID: \"instance_id\",\n\t\t\t\tFilters: SubscriptionFilters{\n\t\t\t\t\tEvents:     NewStringSet(\"issue_created\"),\n\t\t\t\t\tProjects:   NewStringSet(nonExistantProjectKey),\n\t\t\t\t\tIssueTypes: NewStringSet(\"10001\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\terrorMessage: \"failed to get project \\\"FP\\\": Project FP not found\",\n\t\t},\n\t} {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tapi := &plugintest.API{}\n\t\t\tp.SetAPI(api)\n\t\t\tp.client = pluginapi.NewClient(p.API, p.Driver)\n\n\t\t\tapi.On(\"KVGet\", testSubKey).Return(nil, nil)\n\n\t\t\tp.updateConfig(func(conf *config) {\n\t\t\t\tconf.SecurityLevelEmptyForJiraSubscriptions = !tc.disableSecurityConfig\n\t\t\t})\n\n\t\t\tclient := testClient{}\n\t\t\terr := p.validateSubscription(testInstance1.InstanceID, tc.subscription, client)\n\n\t\t\tif tc.errorMessage == \"\" {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t} else {\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.Equal(t, tc.errorMessage, err.Error())\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func Test_requireProxyProtocol(t *testing.T) {\n\tb := New(\"local-grpc\", \"local-http\", nil, nil)\n\tt.Run(\"required\", func(t *testing.T) {\n\t\tli, err := b.buildMainListener(context.Background(), &config.Config{Options: &config.Options{\n\t\t\tUseProxyProtocol: true,\n\t\t\tInsecureServer:   true,\n\t\t}})\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `[\n\t\t\t{\n\t\t\t\t\"name\": \"envoy.filters.listener.proxy_protocol\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.listener.proxy_protocol.v3.ProxyProtocol\"\n\t\t\t\t}\n\t\t\t}\n\t\t]`, li.GetListenerFilters())\n\t})\n\tt.Run(\"not required\", func(t *testing.T) {\n\t\tli, err := b.buildMainListener(context.Background(), &config.Config{Options: &config.Options{\n\t\t\tUseProxyProtocol: false,\n\t\t\tInsecureServer:   true,\n\t\t}})\n\t\trequire.NoError(t, err)\n\t\tassert.Len(t, li.GetListenerFilters(), 0)\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestListObjects(t *testing.T, ds storage.OpenFGADatastore) {\n\ttestCases := []listObjectsTestCase{\n\t\t{\n\t\t\tname: \"max_results_equal_0_with_simple_model\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype repo\n  relations\n\tdefine admin: [user]`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:       \"user:alice\",\n\t\t\tobjectType: \"repo\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{tuple.NewTupleKey(\"repo:3\", \"admin\", \"user:alice\")},\n\t\t\t},\n\t\t\tmaxResults:             0,\n\t\t\tminimumResultsExpected: 3,\n\t\t\tallResults:             []string{\"repo:1\", \"repo:2\", \"repo:3\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"max_results_equal_2_with_simple_model\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype repo\n  relations\n\tdefine admin: [user]`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:       \"user:alice\",\n\t\t\tobjectType: \"repo\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{tuple.NewTupleKey(\"repo:3\", \"admin\", \"user:alice\")},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"repo:1\", \"repo:2\", \"repo:3\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"max_results_with_model_that_uses_exclusion\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype org\n  relations\n\tdefine blocked: [user]\n\tdefine admin: [user] but not blocked`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"org:1\", \"admin\", \"user:charlie\"),\n\t\t\t\ttuple.NewTupleKey(\"org:2\", \"admin\", \"user:charlie\"),\n\t\t\t},\n\t\t\tuser:       \"user:charlie\",\n\t\t\tobjectType: \"org\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{tuple.NewTupleKey(\"org:3\", \"admin\", \"user:charlie\")},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"org:1\", \"org:2\", \"org:3\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"max_results_with_model_that_uses_exclusion_and_one_object_is_a_false_candidate\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype org\n  relations\n\tdefine blocked: [user]\n\tdefine admin: [user] but not blocked`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"org:2\", \"blocked\", \"user:charlie\"),\n\t\t\t\ttuple.NewTupleKey(\"org:1\", \"admin\", \"user:charlie\"),\n\t\t\t\ttuple.NewTupleKey(\"org:2\", \"admin\", \"user:charlie\"),\n\t\t\t\ttuple.NewTupleKey(\"org:3\", \"admin\", \"user:charlie\"),\n\t\t\t},\n\t\t\tuser:                   \"user:charlie\",\n\t\t\tobjectType:             \"org\",\n\t\t\trelation:               \"admin\",\n\t\t\tcontextualTuples:       &openfgav1.ContextualTupleKeys{},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"org:1\", \"org:3\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"respects_when_schema_1_1_and_maxresults_is_higher_than_actual_result_length\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\n\ntype team\n  relations\n\tdefine admin: [user]`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:1\", \"admin\", \"user:bob\"),\n\t\t\t},\n\t\t\tuser:                   \"user:bob\",\n\t\t\tobjectType:             \"team\",\n\t\t\trelation:               \"admin\",\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 1,\n\t\t\tallResults:             []string{\"team:1\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"respects_max_results_when_deadline_timeout_and_returns_no_error_and_no_results\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype repo\n  relations\n\tdefine admin: [user]`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:                   \"user:alice\",\n\t\t\tobjectType:             \"repo\",\n\t\t\trelation:               \"admin\",\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 0,\n\t\t\t// We expect empty array to be returned as list object will timeout due to readTuplesDelay > listObjectsDeadline\n\t\t\tallResults:          []string{},\n\t\t\tlistObjectsDeadline: 1 * time.Second,\n\t\t\treadTuplesDelay:     2 * time.Second, // We are mocking the ds to slow down the read call and simulate timeout\n\t\t\tuseCheckCache:       false,\n\t\t},\n\t\t{\n\t\t\tname: \"list_object_use_check_cache\",\n\t\t\tmodel: `model\n\tschema 1.1\ntype user\ntype repo\n  relations\n\tdefine admin: [user]`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:       \"user:alice\",\n\t\t\tobjectType: \"repo\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{tuple.NewTupleKey(\"repo:3\", \"admin\", \"user:alice\")},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"repo:1\", \"repo:2\", \"repo:3\"},\n\t\t\t// when we use cache, the regular_endpoint should pick up the cached value from the streaming_endpoint run\n\t\t\tuseCheckCache: true,\n\t\t},\n\t\t{\n\t\t\tname: \"condition_with_tuples\",\n\t\t\tmodel: `model\n  schema 1.1\ntype user\ntype document\n  relations\n    define viewer: [user with condition1]\n\ncondition condition1(param1: string) {\n  param1 == 'ok'\n}`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:1\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:2\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"notok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tuser:                   \"user:anne\",\n\t\t\tobjectType:             \"document\",\n\t\t\trelation:               \"viewer\",\n\t\t\tcontextualTuples:       nil,\n\t\t\tmaxResults:             1,\n\t\t\tminimumResultsExpected: 1,\n\t\t\tallResults:             []string{\"document:1\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"condition_with_contextual_tuples\",\n\t\t\tmodel: `model\n  schema 1.1\ntype user\ntype document\n  relations\n    define viewer: [user with condition1]\n\ncondition condition1(param1: string) {\n  param1 == 'ok'\n}`,\n\t\t\ttuples:     nil,\n\t\t\tuser:       \"user:anne\",\n\t\t\tobjectType: \"document\",\n\t\t\trelation:   \"viewer\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:1\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:2\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"notok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmaxResults:             1,\n\t\t\tminimumResultsExpected: 1,\n\t\t\tallResults:             []string{\"document:1\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"condition_with_tuples_and_contextual_tuples\",\n\t\t\tmodel: `model\n  schema 1.1\ntype user\ntype document\n  relations\n    define viewer: [user with condition1]\n\ncondition condition1(param1: string) {\n  param1 == 'ok'\n}`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:1\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"notok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:2\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"notok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tuser:       \"user:anne\",\n\t\t\tobjectType: \"document\",\n\t\t\trelation:   \"viewer\",\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:1\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:2\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"document:1\", \"document:2\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"condition_with_tuples_and_contextual_tuples_and_context\",\n\t\t\tmodel: `model\n  schema 1.1\ntype user\ntype document\n  relations\n    define viewer: [user with condition1]\n\ncondition condition1(param1: string, param2: string) {\n  param1 == 'ok' && param2 == 'ok'\n}`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:1\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\tObject:   \"document:2\",\n\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tuser:       \"user:anne\",\n\t\t\tobjectType: \"document\",\n\t\t\trelation:   \"viewer\",\n\t\t\tcontext:    testutils.MustNewStruct(t, map[string]interface{}{\"param2\": \"ok\"}),\n\t\t\tcontextualTuples: &openfgav1.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgav1.TupleKey{\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:3\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tUser:     \"user:anne\",\n\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\tObject:   \"document:4\",\n\t\t\t\t\t\tCondition: &openfgav1.RelationshipCondition{\n\t\t\t\t\t\t\tName:    \"condition1\",\n\t\t\t\t\t\t\tContext: testutils.MustNewStruct(t, map[string]interface{}{\"param1\": \"ok\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmaxResults:             4,\n\t\t\tminimumResultsExpected: 4,\n\t\t\tallResults:             []string{\"document:1\", \"document:2\", \"document:3\", \"document:4\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t\t{\n\t\t\tname: \"condition_in_ttu_relationships\",\n\t\t\tmodel: `model\n  schema 1.1\n\ntype user\n\ntype folder\n  relations\n    define viewer: [user]\n\ntype document\n  relations\n    define parent: [folder with condition1]\n\tdefine viewer: viewer from parent\n\ncondition condition1(x: int) {\n  x < 100\n}`,\n\t\t\ttuples: []*openfgav1.TupleKey{\n\t\t\t\ttuple.NewTupleKeyWithCondition(\"document:1\", \"parent\", \"folder:x\", \"condition1\", nil),\n\t\t\t\ttuple.NewTupleKey(\"folder:x\", \"viewer\", \"user:jon\"),\n\t\t\t},\n\t\t\tuser:                   \"user:jon\",\n\t\t\tobjectType:             \"document\",\n\t\t\trelation:               \"viewer\",\n\t\t\tcontext:                testutils.MustNewStruct(t, map[string]interface{}{\"x\": 50}),\n\t\t\tminimumResultsExpected: 1,\n\t\t\tallResults:             []string{\"document:1\"},\n\t\t\tuseCheckCache:          false,\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tctx := context.Background()\n\t\t\tstoreID := ulid.Make().String()\n\n\t\t\t// arrange: write model\n\t\t\tmodel := testutils.MustTransformDSLToProtoWithID(test.model)\n\n\t\t\terr := ds.WriteAuthorizationModel(ctx, storeID, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// arrange: write tuples\n\t\t\terr = ds.Write(context.Background(), storeID, nil, test.tuples)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// act: run ListObjects\n\n\t\t\tdatastore := ds\n\t\t\tif test.readTuplesDelay > 0 {\n\t\t\t\tdatastore = mocks.NewMockSlowDataStorage(ds, test.readTuplesDelay)\n\t\t\t}\n\n\t\t\tctx = typesystem.ContextWithTypesystem(ctx, typesystem.New(model))\n\n\t\t\topts := []commands.ListObjectsQueryOption{\n\t\t\t\tcommands.WithListObjectsMaxResults(test.maxResults),\n\t\t\t\tcommands.WithListObjectsDeadline(10 * time.Second),\n\t\t\t}\n\n\t\t\tif test.listObjectsDeadline != 0 {\n\t\t\t\topts = append(opts, commands.WithListObjectsDeadline(test.listObjectsDeadline))\n\t\t\t}\n\n\t\t\tcheckOptions := []graph.LocalCheckerOption{\n\t\t\t\tgraph.WithResolveNodeBreadthLimit(100),\n\t\t\t\tgraph.WithMaxConcurrentReads(30),\n\t\t\t}\n\n\t\t\tif test.useCheckCache {\n\t\t\t\tcheckCache := ccache.New(\n\t\t\t\t\tccache.Configure[*graph.CachedResolveCheckResponse]().MaxSize(100),\n\t\t\t\t)\n\t\t\t\tdefer checkCache.Stop()\n\n\t\t\t\tcheckOptions = append(checkOptions, graph.WithCachedResolver(\n\t\t\t\t\tgraph.WithExistingCache(checkCache),\n\t\t\t\t\tgraph.WithCacheTTL(10*time.Second),\n\t\t\t\t))\n\t\t\t}\n\n\t\t\topts = append(opts, commands.WithCheckOptions(checkOptions))\n\t\t\tlistObjectsQuery := commands.NewListObjectsQuery(datastore, opts...)\n\n\t\t\t// assertions\n\t\t\tt.Run(\"streaming_endpoint\", func(t *testing.T) {\n\t\t\t\tserver := &mockStreamServer{\n\t\t\t\t\tchannel: make(chan string, len(test.allResults)),\n\t\t\t\t}\n\n\t\t\t\tdone := make(chan struct{})\n\t\t\t\tvar streamedObjectIds []string\n\t\t\t\tgo func() {\n\t\t\t\t\tfor x := range server.channel {\n\t\t\t\t\t\tstreamedObjectIds = append(streamedObjectIds, x)\n\t\t\t\t\t}\n\n\t\t\t\t\tdone <- struct{}{}\n\t\t\t\t}()\n\n\t\t\t\t_, err := listObjectsQuery.ExecuteStreamed(ctx, &openfgav1.StreamedListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t\tContext:          test.context,\n\t\t\t\t}, server)\n\t\t\t\tclose(server.channel)\n\t\t\t\t<-done\n\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\t// there is no upper bound of the number of results for the streamed version\n\t\t\t\trequire.GreaterOrEqual(t, len(streamedObjectIds), int(test.minimumResultsExpected))\n\t\t\t\trequire.ElementsMatch(t, test.allResults, streamedObjectIds)\n\t\t\t})\n\n\t\t\tt.Run(\"regular_endpoint\", func(t *testing.T) {\n\t\t\t\tres, err := listObjectsQuery.Execute(ctx, &openfgav1.ListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t\tContext:          test.context,\n\t\t\t\t})\n\n\t\t\t\trequire.NotNil(t, res)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif test.maxResults != 0 { // don't get all results\n\t\t\t\t\trequire.LessOrEqual(t, len(res.Objects), int(test.maxResults))\n\t\t\t\t}\n\t\t\t\trequire.GreaterOrEqual(t, len(res.Objects), int(test.minimumResultsExpected))\n\t\t\t\trequire.Subset(t, test.allResults, res.Objects)\n\t\t\t})\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func AddFlags(flagSet *pflag.FlagSet, cfg *config.Config) (configPath *string) {\n\t// A workaround to keep the original config intact to avoid\n\t// overwriting it with the default values.\n\toriginal := *cfg\n\tdefer func() { *cfg = original }()\n\n\tconfigPath = flagSet.StringP(\"config\", \"c\", \"\", \"load configuration from file\")\n\tflagSet.StringVarP(&cfg.Preset, \"preset\", \"p\", \"\",\n\t\tfmt.Sprintf(\"preset overwrites default values of the config. options %s\", presets.Options()))\n\n\t/** ======================== Checkpoint Flags ========================== **/\n\tflagSet.StringVar(&cfg.Recovery.Uri,\n\t\t\"recovery-uri\", cfg.Recovery.Uri, \"reset the node state based on the supplied checkpoint file\")\n\tflagSet.Uint32Var(&cfg.Recovery.Restore,\n\t\t\"recovery-layer\", cfg.Recovery.Restore, \"restart the mesh with the checkpoint file at this layer\")\n\n\t/** ======================== BaseConfig Flags ========================== **/\n\tflagSet.StringVarP(&cfg.BaseConfig.DataDirParent, \"data-folder\", \"d\",\n\t\tcfg.BaseConfig.DataDirParent, \"Specify data directory for spacemesh\")\n\tflagSet.StringVar(&cfg.BaseConfig.FileLock,\n\t\t\"filelock\", cfg.BaseConfig.FileLock, \"Filesystem lock to prevent running more than one instance.\")\n\tflagSet.StringVar(&cfg.LOGGING.Encoder, \"log-encoder\",\n\t\tcfg.LOGGING.Encoder, \"Log as JSON instead of plain text\")\n\tflagSet.BoolVar(&cfg.CollectMetrics, \"metrics\",\n\t\tcfg.CollectMetrics, \"collect node metrics\")\n\tflagSet.IntVar(&cfg.MetricsPort, \"metrics-port\",\n\t\tcfg.MetricsPort, \"metric server port\")\n\tflagSet.StringVar(&cfg.PublicMetrics.MetricsURL, \"metrics-push\",\n\t\tcfg.PublicMetrics.MetricsURL, \"Push metrics to url\")\n\tflagSet.DurationVar(&cfg.PublicMetrics.MetricsPushPeriod, \"metrics-push-period\",\n\t\tcfg.PublicMetrics.MetricsPushPeriod, \"Push period\")\n\tflagSet.Var(\n\t\t&flags.JSONFlag{Value: &cfg.PoetServers},\n\t\t\"poet-servers\",\n\t\t\"JSON-encoded list of poet servers (address and pubkey)\",\n\t)\n\tflagSet.StringVar(&cfg.Genesis.GenesisTime, \"genesis-time\",\n\t\tcfg.Genesis.GenesisTime, \"Time of the genesis layer in 2019-13-02T17:02:00+00:00 format\")\n\tflagSet.StringVar(&cfg.Genesis.ExtraData, \"genesis-extra-data\",\n\t\tcfg.Genesis.ExtraData, \"genesis extra-data will be committed to the genesis id\")\n\tflagSet.DurationVar(&cfg.LayerDuration, \"layer-duration\",\n\t\tcfg.LayerDuration, \"Duration between layers\")\n\tflagSet.Uint32Var(&cfg.LayerAvgSize, \"layer-average-size\",\n\t\tcfg.LayerAvgSize, \"Layer Avg size\")\n\tflagSet.BoolVar(&cfg.PprofHTTPServer, \"pprof-server\",\n\t\tcfg.PprofHTTPServer, \"enable http pprof server\")\n\tflagSet.StringVar(&cfg.PprofHTTPServerListener, \"pprof-listener\", cfg.PprofHTTPServerListener,\n\t\t\"Listen address for pprof server, not safe to expose publicly\")\n\tflagSet.Uint64Var(&cfg.TickSize, \"tick-size\", cfg.TickSize, \"number of poet leaves in a single tick\")\n\tflagSet.StringVar(&cfg.ProfilerURL, \"profiler-url\", cfg.ProfilerURL,\n\t\t\"send profiler data to certain url, if no url no profiling will be sent, format: http://<IP>:<PORT>\")\n\tflagSet.StringVar(&cfg.ProfilerName, \"profiler-name\",\n\t\tcfg.ProfilerName, \"the name to use when sending profiles\")\n\n\tflagSet.IntVar(&cfg.TxsPerProposal, \"txs-per-proposal\",\n\t\tcfg.TxsPerProposal, \"the number of transactions to select per proposal\")\n\tflagSet.Uint64Var(&cfg.BlockGasLimit, \"block-gas-limit\",\n\t\tcfg.BlockGasLimit, \"max gas allowed per block\")\n\tflagSet.IntVar(&cfg.OptFilterThreshold, \"optimistic-filtering-threshold\",\n\t\tcfg.OptFilterThreshold, \"threshold for optimistic filtering in percentage\")\n\n\tflagSet.IntVar(&cfg.DatabaseConnections, \"db-connections\",\n\t\tcfg.DatabaseConnections, \"configure number of active connections to enable parallel read requests\")\n\tflagSet.BoolVar(&cfg.DatabaseLatencyMetering, \"db-latency-metering\",\n\t\tcfg.DatabaseLatencyMetering, \"if enabled collect latency histogram for every database query\")\n\tflagSet.DurationVar(&cfg.DatabasePruneInterval, \"db-prune-interval\",\n\t\tcfg.DatabasePruneInterval, \"configure interval for database pruning\")\n\n\tflagSet.BoolVar(&cfg.ScanMalfeasantATXs, \"scan-malfeasant-atxs\", cfg.ScanMalfeasantATXs,\n\t\t\"scan for malfeasant ATXs\")\n\n\tflagSet.BoolVar(&cfg.NoMainOverride, \"no-main-override\",\n\t\tcfg.NoMainOverride, \"force 'nomain' builds to run on the mainnet\")\n\n\t/** ======================== P2P Flags ========================== **/\n\n\tflagSet.Var(flags.NewAddressListValue(cfg.P2P.Listen, &cfg.P2P.Listen),\n\t\t\"listen\", \"address(es) for listening\")\n\tflagSet.BoolVar(&cfg.P2P.Flood, \"flood\",\n\t\tcfg.P2P.Flood, \"flood created messages to all peers\")\n\tflagSet.BoolVar(&cfg.P2P.DisableNatPort, \"disable-natport\", cfg.P2P.DisableNatPort,\n\t\t\"disable nat port-mapping (if enabled upnp protocol is used to negotiate external port with router)\")\n\tflagSet.BoolVar(&cfg.P2P.DisableReusePort,\n\t\t\"disable-reuseport\",\n\t\tcfg.P2P.DisableReusePort,\n\t\t\"disables SO_REUSEPORT for tcp sockets. Try disabling this if your node can't reach bootnodes in the network\",\n\t)\n\tflagSet.BoolVar(&cfg.P2P.Metrics,\n\t\t\"p2p-metrics\",\n\t\tcfg.P2P.Metrics,\n\t\t\"enable extended metrics collection from libp2p components\",\n\t)\n\tflagSet.IntVar(&cfg.P2P.AcceptQueue,\n\t\t\"p2p-accept-queue\",\n\t\tcfg.P2P.AcceptQueue,\n\t\t\"number of connections that are fully setup before accepting new connections\",\n\t)\n\tflagSet.IntVar(&cfg.P2P.LowPeers, \"low-peers\",\n\t\tcfg.P2P.LowPeers, \"low watermark for the number of connections\")\n\tflagSet.IntVar(&cfg.P2P.HighPeers, \"high-peers\",\n\t\tcfg.P2P.HighPeers,\n\t\t\"high watermark for number of connections; once reached, connections are pruned until low watermark remains\")\n\tflagSet.IntVar(&cfg.P2P.MinPeers, \"min-peers\",\n\t\tcfg.P2P.MinPeers, \"actively search for peers until you get this much\")\n\tflagSet.StringSliceVar(&cfg.P2P.Bootnodes, \"bootnodes\",\n\t\tcfg.P2P.Bootnodes, \"entrypoints into the network\")\n\tflagSet.StringSliceVar(&cfg.P2P.PingPeers, \"ping-peers\", cfg.P2P.Bootnodes, \"peers to ping\")\n\tflagSet.DurationVar(&cfg.P2P.PingInterval, \"ping-interval\", cfg.P2P.PingInterval, \"ping interval\")\n\tflagSet.StringSliceVar(&cfg.P2P.StaticRelays, \"static-relays\",\n\t\tcfg.P2P.StaticRelays, \"static relay list\")\n\tflagSet.Var(flags.NewAddressListValue(cfg.P2P.AdvertiseAddress, &cfg.P2P.AdvertiseAddress),\n\t\t\"advertise-address\",\n\t\t\"libp2p address(es) with identity (example: /dns4/bootnode.spacemesh.io/tcp/5003)\")\n\tflagSet.BoolVar(&cfg.P2P.Bootnode, \"p2p-bootnode\", cfg.P2P.Bootnode,\n\t\t\"gossipsub and discovery will be running in a mode suitable for bootnode\")\n\tflagSet.BoolVar(&cfg.P2P.PrivateNetwork, \"p2p-private-network\", cfg.P2P.PrivateNetwork,\n\t\t\"discovery will work in private mode. mostly useful for testing, don't set in public networks\")\n\tflagSet.BoolVar(&cfg.P2P.ForceDHTServer, \"force-dht-server\", cfg.P2P.ForceDHTServer,\n\t\t\"force DHT server mode\")\n\tflagSet.BoolVar(&cfg.P2P.EnableTCPTransport, \"enable-tcp-transport\", cfg.P2P.EnableTCPTransport,\n\t\t\"enable TCP transport\")\n\tflagSet.BoolVar(&cfg.P2P.EnableQUICTransport, \"enable-quic-transport\", cfg.P2P.EnableQUICTransport,\n\t\t\"enable QUIC transport\")\n\tflagSet.BoolVar(&cfg.P2P.EnableRoutingDiscovery, \"enable-routing-discovery\", cfg.P2P.EnableQUICTransport,\n\t\t\"enable routing discovery\")\n\tflagSet.BoolVar(&cfg.P2P.RoutingDiscoveryAdvertise, \"routing-discovery-advertise\",\n\t\tcfg.P2P.RoutingDiscoveryAdvertise, \"advertise for routing discovery\")\n\n\t/** ======================== TIME Flags ========================== **/\n\n\tflagSet.BoolVar(&cfg.TIME.Peersync.Disable, \"peersync-disable\", cfg.TIME.Peersync.Disable,\n\t\t\"disable verification that local time is in sync with peers\")\n\tflagSet.DurationVar(&cfg.TIME.Peersync.RoundRetryInterval, \"peersync-round-retry-interval\",\n\t\tcfg.TIME.Peersync.RoundRetryInterval, \"when to retry a sync round after a failure\")\n\tflagSet.DurationVar(&cfg.TIME.Peersync.RoundInterval, \"peersync-round-interval\",\n\t\tcfg.TIME.Peersync.RoundRetryInterval, \"when to run a next sync round\")\n\tflagSet.DurationVar(&cfg.TIME.Peersync.RoundTimeout, \"peersync-round-timeout\",\n\t\tcfg.TIME.Peersync.RoundRetryInterval, \"how long to wait for a round to complete\")\n\tflagSet.DurationVar(&cfg.TIME.Peersync.MaxClockOffset, \"peersync-max-clock-offset\",\n\t\tcfg.TIME.Peersync.MaxClockOffset, \"max difference between local clock and peers clock\")\n\tflagSet.IntVar(&cfg.TIME.Peersync.MaxOffsetErrors, \"peersync-max-offset-errors\", cfg.TIME.Peersync.MaxOffsetErrors,\n\t\t\"node will exit when max number of consecutive offset errors has been reached\")\n\tflagSet.IntVar(&cfg.TIME.Peersync.RequiredResponses, \"peersync-required-responses\",\n\t\tcfg.TIME.Peersync.RequiredResponses, \"min number of clock samples fetched from others to verify time\")\n\n\t/** ======================== API Flags ========================== **/\n\n\tflagSet.StringVar(&cfg.API.PublicListener, \"grpc-public-listener\",\n\t\tcfg.API.PublicListener, \"Socket for grpc services that are save to expose publicly.\")\n\tflagSet.StringVar(&cfg.API.PrivateListener, \"grpc-private-listener\",\n\t\tcfg.API.PrivateListener, \"Socket for grpc services that are not safe to expose publicly.\")\n\tflagSet.StringVar(&cfg.API.PostListener, \"grpc-post-listener\", cfg.API.PostListener,\n\t\t\"Socket on which the node listens for post service connections.\")\n\tflagSet.StringSliceVar(&cfg.API.TLSServices, \"grpc-tls-services\",\n\t\tcfg.API.TLSServices, \"List of services that to be exposed via TLS Listener.\")\n\tflagSet.StringVar(&cfg.API.TLSListener, \"grpc-tls-listener\",\n\t\tcfg.API.TLSListener, \"Socket for the grpc services using mTLS.\")\n\tflagSet.StringVar(&cfg.API.TLSCACert, \"gprc-tls-ca-cert\",\n\t\tcfg.API.TLSCACert, \"Path to the file containing the CA certificate for mTLS.\")\n\tflagSet.StringVar(&cfg.API.TLSCert, \"grpc-tls-cert\",\n\t\tcfg.API.TLSCert, \"Path to the file containing the nodes certificate for mTLS.\")\n\tflagSet.StringVar(&cfg.API.TLSKey, \"grpc-tls-key\",\n\t\tcfg.API.TLSKey, \"Path to the file containing the nodes private key for mTLS.\")\n\tflagSet.IntVar(&cfg.API.GrpcRecvMsgSize, \"grpc-recv-msg-size\",\n\t\tcfg.API.GrpcRecvMsgSize, \"GRPC api recv message size\")\n\tflagSet.IntVar(&cfg.API.GrpcSendMsgSize, \"grpc-send-msg-size\",\n\t\tcfg.API.GrpcSendMsgSize, \"GRPC api send message size\")\n\tflagSet.StringVar(&cfg.API.JSONListener, \"grpc-json-listener\",\n\t\tcfg.API.JSONListener, \"(Optional) endpoint to expose public grpc services via HTTP/JSON.\")\n\n\t/**======================== Hare Eligibility Oracle Flags ========================== **/\n\n\tflagSet.Uint32Var(&cfg.HareEligibility.ConfidenceParam, \"eligibility-confidence-param\",\n\t\tcfg.HareEligibility.ConfidenceParam,\n\t\t\"The relative layer (with respect to the current layer) we are confident to have consensus about\")\n\n\t/**======================== Beacon Flags ========================== **/\n\n\tflagSet.IntVar(&cfg.Beacon.Kappa, \"beacon-kappa\",\n\t\tcfg.Beacon.Kappa, \"Security parameter (for calculating ATX threshold)\")\n\tflagSet.Var((*types.RatVar)(&cfg.Beacon.Q), \"beacon-q\",\n\t\t\"Ratio of dishonest spacetime (for calculating ATX threshold). Should be a string representing a rational.\")\n\tflagSet.Uint32Var((*uint32)(&cfg.Beacon.RoundsNumber), \"beacon-rounds-number\",\n\t\tuint32(cfg.Beacon.RoundsNumber), \"Amount of rounds in every epoch\")\n\tflagSet.DurationVar(&cfg.Beacon.GracePeriodDuration, \"beacon-grace-period-duration\",\n\t\tcfg.Beacon.GracePeriodDuration, \"Grace period duration in milliseconds\")\n\tflagSet.DurationVar(&cfg.Beacon.ProposalDuration, \"beacon-proposal-duration\",\n\t\tcfg.Beacon.ProposalDuration, \"Proposal duration in milliseconds\")\n\tflagSet.DurationVar(&cfg.Beacon.FirstVotingRoundDuration, \"beacon-first-voting-round-duration\",\n\t\tcfg.Beacon.FirstVotingRoundDuration, \"First voting round duration in milliseconds\")\n\tflagSet.DurationVar(&cfg.Beacon.VotingRoundDuration, \"beacon-voting-round-duration\",\n\t\tcfg.Beacon.VotingRoundDuration, \"Voting round duration in milliseconds\")\n\tflagSet.DurationVar(&cfg.Beacon.WeakCoinRoundDuration, \"beacon-weak-coin-round-duration\",\n\t\tcfg.Beacon.WeakCoinRoundDuration, \"Weak coin round duration in milliseconds\")\n\tflagSet.Var((*types.RatVar)(&cfg.Beacon.Theta), \"beacon-theta\",\n\t\t\"Ratio of votes for reaching consensus\")\n\tflagSet.Uint32Var(&cfg.Beacon.VotesLimit, \"beacon-votes-limit\",\n\t\tcfg.Beacon.VotesLimit, \"Maximum allowed number of votes to be sent\")\n\tflagSet.IntVar(&cfg.Beacon.BeaconSyncWeightUnits, \"beacon-sync-weight-units\",\n\t\tcfg.Beacon.BeaconSyncWeightUnits, \"Numbers of weight units to wait before determining beacon values from them.\")\n\n\t/**======================== Tortoise Flags ========================== **/\n\tflagSet.Uint32Var(&cfg.Tortoise.Hdist, \"tortoise-hdist\",\n\t\tcfg.Tortoise.Hdist, \"the distance for tortoise to vote according to hare output\")\n\tflagSet.Uint32Var(&cfg.Tortoise.Zdist, \"tortoise-zdist\",\n\t\tcfg.Tortoise.Zdist, \"the distance for tortoise to wait for hare output\")\n\tflagSet.Uint32Var(&cfg.Tortoise.WindowSize, \"tortoise-window-size\",\n\t\tcfg.Tortoise.WindowSize, \"size of the tortoise sliding window in layers\")\n\tflagSet.IntVar(&cfg.Tortoise.MaxExceptions, \"tortoise-max-exceptions\",\n\t\tcfg.Tortoise.MaxExceptions, \"number of exceptions tolerated for a base ballot\")\n\tflagSet.Uint32Var(&cfg.Tortoise.BadBeaconVoteDelayLayers, \"tortoise-delay-layers\",\n\t\tcfg.Tortoise.BadBeaconVoteDelayLayers, \"number of layers to ignore a ballot with a different beacon\")\n\tflagSet.BoolVar(&cfg.Tortoise.EnableTracer, \"tortoise-enable-tracer\",\n\t\tcfg.Tortoise.EnableTracer, \"record every tortoise input/output to the logging output\")\n\n\t// TODO(moshababo): add usage desc\n\tflagSet.Uint64Var(&cfg.POST.LabelsPerUnit, \"post-labels-per-unit\",\n\t\tcfg.POST.LabelsPerUnit, \"\")\n\tflagSet.Uint32Var(&cfg.POST.MinNumUnits, \"post-min-numunits\",\n\t\tcfg.POST.MinNumUnits, \"\")\n\tflagSet.Uint32Var(&cfg.POST.MaxNumUnits, \"post-max-numunits\",\n\t\tcfg.POST.MaxNumUnits, \"\")\n\tflagSet.UintVar(&cfg.POST.K1, \"post-k1\",\n\t\tcfg.POST.K1, \"difficulty factor for finding a good label when generating a proof\")\n\tflagSet.UintVar(&cfg.POST.K2, \"post-k2\",\n\t\tcfg.POST.K2, \"number of labels to prove\")\n\tflagSet.UintVar(\n\t\t&cfg.POST.K3,\n\t\t\"post-k3\",\n\t\tcfg.POST.K3,\n\t\t\"size of the subset of labels to verify in POST proofs\\n\"+\n\t\t\t\"lower values will result in faster ATX verification but increase the risk\\n\"+\n\t\t\t\"as the node must depend on malfeasance proofs to detect invalid ATXs\",\n\t)\n\tflagSet.AddFlag(&pflag.Flag{\n\t\tName:     \"post-pow-difficulty\",\n\t\tValue:    &cfg.POST.PowDifficulty,\n\t\tDefValue: cfg.POST.PowDifficulty.String(),\n\t\tUsage:    \"difficulty of randomx-based proof of work\",\n\t})\n\n\t/**======================== Smeshing Flags ========================== **/\n\n\t// TODO(moshababo): add usage desc\n\n\tflagSet.BoolVar(&cfg.SMESHING.Start, \"smeshing-start\",\n\t\tcfg.SMESHING.Start, \"\")\n\tflagSet.StringVar(&cfg.SMESHING.CoinbaseAccount, \"smeshing-coinbase\",\n\t\tcfg.SMESHING.CoinbaseAccount, \"coinbase account to accumulate rewards\")\n\tflagSet.StringVar(&cfg.SMESHING.Opts.DataDir, \"smeshing-opts-datadir\",\n\t\tcfg.SMESHING.Opts.DataDir, \"\")\n\tflagSet.Uint32Var(&cfg.SMESHING.Opts.NumUnits, \"smeshing-opts-numunits\",\n\t\tcfg.SMESHING.Opts.NumUnits, \"\")\n\tflagSet.Uint64Var(&cfg.SMESHING.Opts.MaxFileSize, \"smeshing-opts-maxfilesize\",\n\t\tcfg.SMESHING.Opts.MaxFileSize, \"\")\n\tflagSet.AddFlag(&pflag.Flag{\n\t\tName:     \"smeshing-opts-provider\",\n\t\tValue:    &cfg.SMESHING.Opts.ProviderID,\n\t\tDefValue: cfg.SMESHING.Opts.ProviderID.String(),\n\t})\n\tflagSet.BoolVar(&cfg.SMESHING.Opts.Throttle, \"smeshing-opts-throttle\",\n\t\tcfg.SMESHING.Opts.Throttle, \"\")\n\n\t/**======================== PoST Proving Flags ========================== **/\n\n\tflagSet.UintVar(&cfg.SMESHING.ProvingOpts.Threads, \"smeshing-opts-proving-threads\",\n\t\tcfg.SMESHING.ProvingOpts.Threads, \"\")\n\tflagSet.UintVar(&cfg.SMESHING.ProvingOpts.Nonces, \"smeshing-opts-proving-nonces\",\n\t\tcfg.SMESHING.ProvingOpts.Nonces, \"\")\n\tflagSet.AddFlag(&pflag.Flag{\n\t\tName:     \"smeshing-opts-proving-randomx-mode\",\n\t\tValue:    &cfg.SMESHING.ProvingOpts.RandomXMode,\n\t\tDefValue: cfg.SMESHING.ProvingOpts.RandomXMode.String(),\n\t})\n\n\t/**======================== PoST Verifying Flags ========================== **/\n\n\tflagSet.BoolVar(\n\t\t&cfg.SMESHING.VerifyingOpts.Disabled,\n\t\t\"smeshing-opts-verifying-disable\",\n\t\tfalse,\n\t\t\"Disable verifying POST proofs. Experimental.\\n\"+\n\t\t\t\"Use with caution, only on private nodes with a trusted public peer that validates the proofs.\",\n\t)\n\tflagSet.IntVar(\n\t\t&cfg.SMESHING.VerifyingOpts.MinWorkers,\n\t\t\"smeshing-opts-verifying-min-workers\",\n\t\tcfg.SMESHING.VerifyingOpts.MinWorkers,\n\t\t\"Minimal number of threads to use for verifying PoSTs (used while PoST is generated)\",\n\t)\n\tflagSet.IntVar(&cfg.SMESHING.VerifyingOpts.Workers, \"smeshing-opts-verifying-workers\",\n\t\tcfg.SMESHING.VerifyingOpts.Workers, \"\")\n\tflagSet.AddFlag(&pflag.Flag{\n\t\tName:     \"smeshing-opts-verifying-powflags\",\n\t\tValue:    &cfg.SMESHING.VerifyingOpts.Flags,\n\t\tDefValue: cfg.SMESHING.VerifyingOpts.Flags.String(),\n\t})\n\n\t/**======================== Consensus Flags ========================== **/\n\n\tflagSet.Uint32Var(&cfg.LayersPerEpoch, \"layers-per-epoch\",\n\t\tcfg.LayersPerEpoch, \"number of layers in epoch\")\n\n\t/**======================== PoET Flags ========================== **/\n\n\tflagSet.DurationVar(&cfg.POET.PhaseShift, \"phase-shift\",\n\t\tcfg.POET.PhaseShift, \"phase shift of poet server\")\n\tflagSet.DurationVar(&cfg.POET.CycleGap, \"cycle-gap\",\n\t\tcfg.POET.CycleGap, \"cycle gap of poet server\")\n\tflagSet.DurationVar(&cfg.POET.GracePeriod, \"grace-period\",\n\t\tcfg.POET.GracePeriod, \"time before PoET round starts when the node builds and submits a challenge\")\n\tflagSet.DurationVar(&cfg.POET.RequestTimeout, \"poet-request-timeout\",\n\t\tcfg.POET.RequestTimeout, \"timeout for poet requests\")\n\n\t/**======================== bootstrap data updater Flags ========================== **/\n\n\tflagSet.StringVar(&cfg.Bootstrap.URL, \"bootstrap-url\",\n\t\tcfg.Bootstrap.URL, \"the url to query bootstrap data update\")\n\tflagSet.StringVar(&cfg.Bootstrap.Version, \"bootstrap-version\",\n\t\tcfg.Bootstrap.Version, \"the update version of the bootstrap data\")\n\n\t/**======================== testing related flags ========================== **/\n\tflagSet.StringVar(&cfg.TestConfig.SmesherKey, \"testing-smesher-key\",\n\t\t\"\", \"import private smesher key for testing\",\n\t)\n\tflagSet.VarP(flags.NewStringToUint64Value(&cfg.Genesis.Accounts), \"accounts\", \"a\",\n\t\t\"List of pre-funded accounts (use in tests only\")\n\n\t/**========================  Deprecated flags ========================== **/\n\tflagSet.Var(flags.NewDeprecatedFlag(\n\t\tconfig.DeprecatedPoETServers{}), \"poet-server\", \"deprecated, use poet-servers instead\")\n\tif err := flagSet.MarkHidden(\"poet-server\"); err != nil {\n\t\tpanic(err) // unreachable\n\t}\n\n\treturn configPath\n}", "is_vulnerable": 0}
{"code": "func (e *Echo) Static(prefix, root string) *Route {\n\tif root == \"\" {\n\t\troot = \".\" // For security we want to restrict to CWD.\n\t}\n\treturn e.static(prefix, root, e.GET)\n}", "is_vulnerable": 1}
{"code": "func (ctx *cbcAEAD) Open(dst, nonce, ciphertext, data []byte) ([]byte, error) {\n\tif len(ciphertext) < ctx.authtagBytes {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (too short)\")\n\t}\n\n\toffset := len(ciphertext) - ctx.authtagBytes\n\texpectedTag := ctx.computeAuthTag(data, nonce, ciphertext[:offset])\n\tmatch := subtle.ConstantTimeCompare(expectedTag, ciphertext[offset:])\n\tif match != 1 {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (auth tag mismatch)\")\n\t}\n\n\tcbc := cipher.NewCBCDecrypter(ctx.blockCipher, nonce)\n\n\t// Make copy of ciphertext buffer, don't want to modify in place\n\tbuffer := append([]byte{}, []byte(ciphertext[:offset])...)\n\n\tif len(buffer)%ctx.blockCipher.BlockSize() > 0 {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (invalid length)\")\n\t}\n\n\tcbc.CryptBlocks(buffer, buffer)\n\n\t// Remove padding\n\tplaintext, err := unpadBuffer(buffer, ctx.blockCipher.BlockSize())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tret, out := resize(dst, uint64(len(dst))+uint64(len(plaintext)))\n\tcopy(out, plaintext)\n\n\treturn ret, nil\n}", "is_vulnerable": 0}
{"code": "func (v *SnapshotJob) do(ffmpegPath, inputUrl string) (err error) {\n\toutputPicDir := path.Join(StaticDir, v.App)\n\tif err = os.MkdirAll(outputPicDir, 0777); err != nil {\n\t\tlog.Println(fmt.Sprintf(\"create snapshot image dir:%v failed, err is %v\", outputPicDir, err))\n\t\treturn\n\t}\n\n\tnormalPicPath := path.Join(outputPicDir, fmt.Sprintf(\"%v\", v.Stream)+\"-%03d.png\")\n\tbestPng := path.Join(outputPicDir, fmt.Sprintf(\"%v-best.png\", v.Stream))\n\n\tparams := []string{\n\t\t\"-i\", inputUrl,\n\t\t\"-vf\", \"fps=1\",\n\t\t\"-vcodec\", \"png\",\n\t\t\"-f\", \"image2\",\n\t\t\"-an\",\n\t\t\"-vframes\", strconv.Itoa(v.vframes),\n\t\t\"-y\", normalPicPath,\n\t}\n\tlog.Println(fmt.Sprintf(\"start snapshot, cmd param=%v %v\", ffmpegPath, strings.Join(params, \" \")))\n\ttimeoutCtx, _ := context.WithTimeout(v.cancelCtx, v.timeout)\n\tcmd := exec.CommandContext(timeoutCtx, ffmpegPath, params...)\n\tif err = cmd.Run(); err != nil {\n\t\tlog.Println(fmt.Sprintf(\"run snapshot %v cmd failed, err is %v\", v.Tag(), err))\n\t\treturn\n\t}\n\n\tbestFileSize := int64(0)\n\tfor i := 1; i <= v.vframes; i++ {\n\t\tpic := path.Join(outputPicDir, fmt.Sprintf(\"%v-%03d.png\", v.Stream, i))\n\t\tfi, err := os.Stat(pic)\n\t\tif err != nil {\n\t\t\tlog.Println(fmt.Sprintf(\"stat pic:%v failed, err is %v\", pic, err))\n\t\t\tcontinue\n\t\t}\n\t\tif bestFileSize == 0 {\n\t\t\tbestFileSize = fi.Size()\n\t\t} else if fi.Size() > bestFileSize {\n\t\t\tos.Remove(bestPng)\n\t\t\tos.Symlink(pic, bestPng)\n\t\t\tbestFileSize = fi.Size()\n\t\t}\n\t}\n\tlog.Println(fmt.Sprintf(\"%v the best thumbnail is %v\", v.Tag(), bestPng))\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (o *LoginCreated) SetPayload(payload *models.LoginResponse) {\n\to.Payload = payload\n}", "is_vulnerable": 1}
{"code": "func (suite *KeeperTestSuite) SetupTest() {\n\tsuite.DoSetupTest(suite.T())\n}", "is_vulnerable": 1}
{"code": "func (p *HTTPProxyProcessor) computeRoutes(\n\tvalidCond *contour_api_v1.DetailedCondition,\n\trootProxy *contour_api_v1.HTTPProxy,\n\tproxy *contour_api_v1.HTTPProxy,\n\tconditions []contour_api_v1.MatchCondition,\n\tvisited []*contour_api_v1.HTTPProxy,\n\tenforceTLS bool,\n) []*Route {\n\tfor _, v := range visited {\n\t\t// ensure we are not following an edge that produces a cycle\n\t\tvar path []string\n\t\tfor _, vir := range visited {\n\t\t\tpath = append(path, fmt.Sprintf(\"%s/%s\", vir.Namespace, vir.Name))\n\t\t}\n\t\tif v.Name == proxy.Name && v.Namespace == proxy.Namespace {\n\t\t\tpath = append(path, fmt.Sprintf(\"%s/%s\", proxy.Namespace, proxy.Name))\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeIncludeError, \"IncludeCreatesCycle\",\n\t\t\t\t\"include creates an include cycle: %s\", strings.Join(path, \" -> \"))\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tvisited = append(visited, proxy)\n\tvar routes []*Route\n\n\t// Check for duplicate conditions on the includes\n\tif includeMatchConditionsIdentical(proxy.Spec.Includes) {\n\t\tvalidCond.AddError(contour_api_v1.ConditionTypeIncludeError, \"DuplicateMatchConditions\",\n\t\t\t\"duplicate conditions defined on an include\")\n\t\treturn nil\n\t}\n\n\t// Loop over and process all includes\n\tfor _, include := range proxy.Spec.Includes {\n\t\tnamespace := include.Namespace\n\t\tif namespace == \"\" {\n\t\t\tnamespace = proxy.Namespace\n\t\t}\n\n\t\tincludedProxy, ok := p.source.httpproxies[types.NamespacedName{Name: include.Name, Namespace: namespace}]\n\t\tif !ok {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeIncludeError, \"IncludeNotFound\",\n\t\t\t\t\"include %s/%s not found\", namespace, include.Name)\n\t\t\treturn nil\n\t\t}\n\t\tif includedProxy.Spec.VirtualHost != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeIncludeError, \"RootIncludesRoot\",\n\t\t\t\t\"root httpproxy cannot include another root httpproxy\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif err := pathMatchConditionsValid(include.Conditions); err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeIncludeError, \"PathMatchConditionsNotValid\",\n\t\t\t\t\"include: %s\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\tinc, incCommit := p.dag.StatusCache.ProxyAccessor(includedProxy)\n\t\tincValidCond := inc.ConditionFor(status.ValidCondition)\n\t\troutes = append(routes, p.computeRoutes(incValidCond, rootProxy, includedProxy, append(conditions, include.Conditions...), visited, enforceTLS)...)\n\t\tincCommit()\n\n\t\t// dest is not an orphaned httpproxy, as there is an httpproxy that points to it\n\t\tdelete(p.orphaned, types.NamespacedName{Name: includedProxy.Name, Namespace: includedProxy.Namespace})\n\t}\n\n\tdynamicHeaders := map[string]string{\n\t\t\"CONTOUR_NAMESPACE\": proxy.Namespace,\n\t}\n\n\tfor _, route := range proxy.Spec.Routes {\n\t\tif err := pathMatchConditionsValid(route.Conditions); err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeRouteError, \"PathMatchConditionsNotValid\",\n\t\t\t\t\"route: %s\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\tconds := append(conditions, route.Conditions...)\n\n\t\t// Look for invalid header conditions on this route\n\t\tif err := headerMatchConditionsValid(conds); err != nil {\n\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypeRouteError, \"HeaderMatchConditionsNotValid\",\n\t\t\t\terr.Error())\n\t\t\treturn nil\n\t\t}\n\n\t\treqHP, err := headersPolicyRoute(route.RequestHeadersPolicy, true /* allow Host */, dynamicHeaders)\n\t\tif err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeRouteError, \"RequestHeadersPolicyInvalid\",\n\t\t\t\t\"%s on request headers\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\trespHP, err := headersPolicyRoute(route.ResponseHeadersPolicy, false /* disallow Host */, dynamicHeaders)\n\t\tif err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeRouteError, \"ResponseHeaderPolicyInvalid\",\n\t\t\t\t\"%s on response headers\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\tif len(route.Services) < 1 {\n\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypeRouteError, \"NoServicesPresent\",\n\t\t\t\t\"route.services must have at least one entry\")\n\t\t\treturn nil\n\t\t}\n\n\t\ttp, err := timeoutPolicy(route.TimeoutPolicy)\n\t\tif err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeRouteError, \"TimeoutPolicyNotValid\",\n\t\t\t\t\"route.timeoutPolicy failed to parse: %s\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\trlp, err := rateLimitPolicy(route.RateLimitPolicy)\n\t\tif err != nil {\n\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeRouteError, \"RateLimitPolicyNotValid\",\n\t\t\t\t\"route.rateLimitPolicy is invalid: %s\", err)\n\t\t\treturn nil\n\t\t}\n\n\t\trequestHashPolicies, lbPolicy := loadBalancerRequestHashPolicies(route.LoadBalancerPolicy, validCond)\n\n\t\tr := &Route{\n\t\t\tPathMatchCondition:    mergePathMatchConditions(conds),\n\t\t\tHeaderMatchConditions: mergeHeaderMatchConditions(conds),\n\t\t\tWebsocket:             route.EnableWebsockets,\n\t\t\tHTTPSUpgrade:          routeEnforceTLS(enforceTLS, route.PermitInsecure && !p.DisablePermitInsecure),\n\t\t\tTimeoutPolicy:         tp,\n\t\t\tRetryPolicy:           retryPolicy(route.RetryPolicy),\n\t\t\tRequestHeadersPolicy:  reqHP,\n\t\t\tResponseHeadersPolicy: respHP,\n\t\t\tRateLimitPolicy:       rlp,\n\t\t\tRequestHashPolicies:   requestHashPolicies,\n\t\t}\n\n\t\t// If the enclosing root proxy enabled authorization,\n\t\t// enable it on the route and propagate defaults\n\t\t// downwards.\n\t\tif rootProxy.Spec.VirtualHost.AuthorizationConfigured() {\n\t\t\t// When the ext_authz filter is added to a\n\t\t\t// vhost, it is in enabled state, but we can\n\t\t\t// disable it per route. We emulate disabling\n\t\t\t// it at the vhost layer by defaulting the state\n\t\t\t// from the root proxy.\n\t\t\tdisabled := rootProxy.Spec.VirtualHost.DisableAuthorization()\n\n\t\t\t// Take the default for enabling authorization\n\t\t\t// from the virtual host. If this route has a\n\t\t\t// policy, let that override.\n\t\t\tif route.AuthPolicy != nil {\n\t\t\t\tdisabled = route.AuthPolicy.Disabled\n\t\t\t}\n\n\t\t\tr.AuthDisabled = disabled\n\t\t\tr.AuthContext = route.AuthorizationContext(rootProxy.Spec.VirtualHost.AuthorizationContext())\n\t\t}\n\n\t\tif len(route.GetPrefixReplacements()) > 0 {\n\t\t\tif !r.HasPathPrefix() {\n\t\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypePrefixReplaceError, \"MustHavePrefix\",\n\t\t\t\t\t\"cannot specify prefix replacements without a prefix condition\")\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tif reason, err := prefixReplacementsAreValid(route.GetPrefixReplacements()); err != nil {\n\t\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypePrefixReplaceError, reason, err.Error())\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Note that we are guaranteed to always have a prefix\n\t\t\t// condition. Even if the CRD user didn't specify a\n\t\t\t// prefix condition, mergePathConditions() guarantees\n\t\t\t// a prefix of '/'.\n\t\t\troutingPrefix := r.PathMatchCondition.(*PrefixMatchCondition).Prefix\n\n\t\t\t// First, try to apply an exact prefix match.\n\t\t\tfor _, prefix := range route.GetPrefixReplacements() {\n\t\t\t\tif len(prefix.Prefix) > 0 && routingPrefix == prefix.Prefix {\n\t\t\t\t\tr.PrefixRewrite = prefix.Replacement\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// If there wasn't a match, we can apply the default replacement.\n\t\t\tif len(r.PrefixRewrite) == 0 {\n\t\t\t\tfor _, prefix := range route.GetPrefixReplacements() {\n\t\t\t\t\tif len(prefix.Prefix) == 0 {\n\t\t\t\t\t\tr.PrefixRewrite = prefix.Replacement\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\n\t\tfor _, service := range route.Services {\n\t\t\tif service.Port < 1 || service.Port > 65535 {\n\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeServiceError, \"ServicePortInvalid\",\n\t\t\t\t\t\"service %q: port must be in the range 1-65535\", service.Name)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tm := types.NamespacedName{Name: service.Name, Namespace: proxy.Namespace}\n\t\t\ts, err := p.dag.EnsureService(m, intstr.FromInt(service.Port), p.source)\n\t\t\tif err != nil {\n\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeServiceError, \"ServiceUnresolvedReference\",\n\t\t\t\t\t\"Spec.Routes unresolved service reference: %s\", err)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Determine the protocol to use to speak to this Cluster.\n\t\t\tprotocol, err := getProtocol(service, s)\n\t\t\tif err != nil {\n\t\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypeServiceError, \"UnsupportedProtocol\", err.Error())\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tvar uv *PeerValidationContext\n\t\t\tif protocol == \"tls\" || protocol == \"h2\" {\n\t\t\t\t// we can only validate TLS connections to services that talk TLS\n\t\t\t\tuv, err = p.source.LookupUpstreamValidation(service.UpstreamValidation, proxy.Namespace)\n\t\t\t\tif err != nil {\n\t\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeServiceError, \"TLSUpstreamValidation\",\n\t\t\t\t\t\t\"Service [%s:%d] TLS upstream validation policy error: %s\", service.Name, service.Port, err)\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdynamicHeaders[\"CONTOUR_SERVICE_NAME\"] = service.Name\n\t\t\tdynamicHeaders[\"CONTOUR_SERVICE_PORT\"] = strconv.Itoa(service.Port)\n\n\t\t\treqHP, err := headersPolicyService(p.RequestHeadersPolicy, service.RequestHeadersPolicy, dynamicHeaders)\n\t\t\tif err != nil {\n\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeServiceError, \"RequestHeadersPolicyInvalid\",\n\t\t\t\t\t\"%s on request headers\", err)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\trespHP, err := headersPolicyService(p.ResponseHeadersPolicy, service.ResponseHeadersPolicy, dynamicHeaders)\n\t\t\tif err != nil {\n\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeServiceError, \"ResponseHeadersPolicyInvalid\",\n\t\t\t\t\t\"%s on response headers\", err)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tvar clientCertSecret *Secret\n\t\t\tif p.ClientCertificate != nil {\n\t\t\t\tclientCertSecret, err = p.source.LookupSecret(*p.ClientCertificate, validSecret)\n\t\t\t\tif err != nil {\n\t\t\t\t\tvalidCond.AddErrorf(contour_api_v1.ConditionTypeTLSError, \"SecretNotValid\",\n\t\t\t\t\t\t\"tls.envoy-client-certificate Secret %q is invalid: %s\", p.ClientCertificate, err)\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tc := &Cluster{\n\t\t\t\tUpstream:              s,\n\t\t\t\tLoadBalancerPolicy:    lbPolicy,\n\t\t\t\tWeight:                uint32(service.Weight),\n\t\t\t\tHTTPHealthCheckPolicy: httpHealthCheckPolicy(route.HealthCheckPolicy),\n\t\t\t\tUpstreamValidation:    uv,\n\t\t\t\tRequestHeadersPolicy:  reqHP,\n\t\t\t\tResponseHeadersPolicy: respHP,\n\t\t\t\tProtocol:              protocol,\n\t\t\t\tSNI:                   determineSNI(r.RequestHeadersPolicy, reqHP, s),\n\t\t\t\tDNSLookupFamily:       string(p.DNSLookupFamily),\n\t\t\t\tClientCertificate:     clientCertSecret,\n\t\t\t}\n\t\t\tif service.Mirror && r.MirrorPolicy != nil {\n\t\t\t\tvalidCond.AddError(contour_api_v1.ConditionTypeServiceError, \"OnlyOneMirror\",\n\t\t\t\t\t\"only one service per route may be nominated as mirror\")\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif service.Mirror {\n\t\t\t\tr.MirrorPolicy = &MirrorPolicy{\n\t\t\t\t\tCluster: c,\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tr.Clusters = append(r.Clusters, c)\n\t\t\t}\n\t\t}\n\t\troutes = append(routes, r)\n\t}\n\n\troutes = expandPrefixMatches(routes)\n\n\treturn routes\n}", "is_vulnerable": 1}
{"code": "func (k *Key) OwnerTrust() Validity {\n\treturn Validity(k.k.owner_trust)\n}", "is_vulnerable": 1}
{"code": "func ValidateUUID(value interface{}) error {\n\ts, _ := value.(string)\n\terr := validation.Validate(s, validation.RuneLength(32, 32), is.Hexadecimal)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"not a valid UUID\")\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func dropPrivileges(logf logger.Logf, wantUid, wantGid int, supplementaryGroups []int) error {\n\tfatalf := func(format string, args ...any) {\n\t\tlogf(format, args...)\n\t\tos.Exit(1)\n\t}\n\n\teuid := os.Geteuid()\n\tegid := os.Getegid()\n\n\tif runtime.GOOS == \"darwin\" || runtime.GOOS == \"freebsd\" {\n\t\t// On FreeBSD and Darwin, the first entry returned from the\n\t\t// getgroups(2) syscall is the egid, and changing it with\n\t\t// setgroups(2) changes the egid of the process. This is\n\t\t// technically a violation of the POSIX standard; see the\n\t\t// following article for more detail:\n\t\t//    https://www.usenix.org/system/files/login/articles/325-tsafrir.pdf\n\t\t//\n\t\t// In this case, we add an entry at the beginning of the\n\t\t// groupIDs list containing the expected gid if it's not\n\t\t// already there, which modifies the egid and additional groups\n\t\t// as one unit.\n\t\tif len(supplementaryGroups) == 0 || supplementaryGroups[0] != wantGid {\n\t\t\tsupplementaryGroups = append([]int{wantGid}, supplementaryGroups...)\n\t\t}\n\t}\n\n\tif err := setGroups(supplementaryGroups); err != nil {\n\t\treturn err\n\t}\n\tif egid != wantGid {\n\t\t// On FreeBSD and Darwin, we may have already called the\n\t\t// equivalent of setegid(wantGid) via the call to setGroups,\n\t\t// above. However, per the manpage, setgid(getegid()) is an\n\t\t// allowed operation regardless of privilege level.\n\t\t//\n\t\t// FreeBSD:\n\t\t//\tThe setgid() system call is permitted if the specified ID\n\t\t//\tis equal to the real group ID or the effective group ID\n\t\t//\tof the process, or if the effective user ID is that of\n\t\t//\tthe super user.\n\t\t//\n\t\t// Darwin:\n\t\t//\tThe setgid() function is permitted if the effective\n\t\t//\tuser ID is that of the super user, or if the specified\n\t\t//\tgroup ID is the same as the effective group ID.  If\n\t\t//\tnot, but the specified group ID is the same as the real\n\t\t//\tgroup ID, setgid() will set the effective group ID to\n\t\t//\tthe real group ID.\n\t\tif err := syscall.Setgid(wantGid); err != nil {\n\t\t\tfatalf(\"Setgid(%d): %v\", wantGid, err)\n\t\t}\n\t}\n\tif euid != wantUid {\n\t\t// Switch users if required before starting the desired process.\n\t\tif err := syscall.Setuid(wantUid); err != nil {\n\t\t\tfatalf(\"Setuid(%d): %v\", wantUid, err)\n\t\t}\n\t}\n\n\t// If we changed either the UID or GID, defensively assert that we\n\t// cannot reset the it back to our original values, and that the\n\t// current egid/euid are the expected values after we change\n\t// everything; if not, we exit the process.\n\tif assertDropPrivileges {\n\t\tif egid != wantGid {\n\t\t\tif err := syscall.Setegid(egid); err == nil {\n\t\t\t\tfatalf(\"unexpectedly able to set egid back to %d\", egid)\n\t\t\t}\n\t\t}\n\t\tif euid != wantUid {\n\t\t\tif err := syscall.Seteuid(euid); err == nil {\n\t\t\t\tfatalf(\"unexpectedly able to set euid back to %d\", euid)\n\t\t\t}\n\t\t}\n\n\t\tif got := os.Getegid(); got != wantGid {\n\t\t\tfatalf(\"got egid=%d, want %d\", got, wantGid)\n\t\t}\n\t\tif got := os.Geteuid(); got != wantUid {\n\t\t\tfatalf(\"got euid=%d, want %d\", got, wantUid)\n\t\t}\n\n\t\t// TODO(andrew-d): assert that our supplementary groups are correct\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *B) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: B: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: B: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field C\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.C == nil {\n\t\t\t\tm.C = &C{}\n\t\t\t}\n\t\t\tif err := m.C.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field D\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.D == nil {\n\t\t\t\tm.D = &D{}\n\t\t\t}\n\t\t\tif err := m.D.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field F\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.F == nil {\n\t\t\t\tm.F = &OldC{}\n\t\t\t}\n\t\t\tif err := m.F.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognized(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func NewFositeMemoryStore(\n\tr InternalRegistry,\n\tc Configuration,\n) *FositeMemoryStore {\n\treturn &FositeMemoryStore{\n\t\tAuthorizeCodes: make(map[string]authorizeCode),\n\t\tIDSessions:     make(map[string]fosite.Requester),\n\t\tAccessTokens:   make(map[string]fosite.Requester),\n\t\tPKCES:          make(map[string]fosite.Requester),\n\t\tRefreshTokens:  make(map[string]fosite.Requester),\n\n\t\tc: c,\n\t\tr: r,\n\t}\n}", "is_vulnerable": 1}
{"code": "func saveClusterState(ctx context.Context, kubeCluster *cluster.Cluster, clusterState *cluster.FullState) error {\n\tif err := kubeCluster.UpdateClusterCurrentState(ctx, clusterState); err != nil {\n\t\treturn fmt.Errorf(\"error updating cluster state: %w\", err)\n\t}\n\n\tk8sClient, err := k8s.NewClient(kubeCluster.LocalKubeConfigPath, kubeCluster.K8sWrapTransport)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create Kubernetes Client: %w\", err)\n\t}\n\n\tif err := cluster.SaveFullStateToK8s(ctx, k8sClient, clusterState); err != nil {\n\t\tlogrus.Warnf(\"Failed to save full state to Kubernetes: %v\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (r *RepTarget) Valid(v *validation.Validation) {\n\tif len(r.Name) == 0 {\n\t\tv.SetError(\"name\", \"can not be empty\")\n\t}\n\n\tif len(r.Name) > 64 {\n\t\tv.SetError(\"name\", \"max length is 64\")\n\t}\n\n\tif len(r.URL) == 0 {\n\t\tv.SetError(\"endpoint\", \"can not be empty\")\n\t}\n\n\tr.URL = utils.FormatEndpoint(r.URL)\n\n\tif len(r.URL) > 64 {\n\t\tv.SetError(\"endpoint\", \"max length is 64\")\n\t}\n\n\t// password is encoded using base64, the length of this field\n\t// in DB is 64, so the max length in request is 48\n\tif len(r.Password) > 48 {\n\t\tv.SetError(\"password\", \"max length is 48\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *Server) getApplicationEnforceRBACClient(ctx context.Context, action, namespace, name, resourceVersion string) (*appv1.Application, error) {\n\tnamespaceOrDefault := s.appNamespaceOrDefault(namespace)\n\treturn s.getAppEnforceRBAC(ctx, action, namespaceOrDefault, name, func() (*appv1.Application, error) {\n\t\treturn s.appclientset.ArgoprojV1alpha1().Applications(namespaceOrDefault).Get(ctx, name, metav1.GetOptions{\n\t\t\tResourceVersion: resourceVersion,\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessRequester) GetID() string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetID\")\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "\tnewBlock := func(seq uint64) *common.Block {\n\t\tsHdr := &common.SignatureHeader{\n\t\t\tCreator: []byte{1, 2, 3},\n\t\t\tNonce:   []byte{9, 5, 42, 66},\n\t\t}\n\t\tblock := protoutil.NewBlock(seq, nil)\n\t\tblockSignature := &common.MetadataSignature{\n\t\t\tSignatureHeader: protoutil.MarshalOrPanic(sHdr),\n\t\t}\n\t\tblock.Metadata.Metadata[common.BlockMetadataIndex_SIGNATURES] = protoutil.MarshalOrPanic(&common.Metadata{\n\t\t\tValue: nil,\n\t\t\tSignatures: []*common.MetadataSignature{\n\t\t\t\tblockSignature,\n\t\t\t},\n\t\t})\n\n\t\ttxn := protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\tSignature: []byte{1, 2, 3},\n\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\tHeader: &common.Header{},\n\t\t\t}),\n\t\t})\n\t\tblock.Data.Data = append(block.Data.Data, txn)\n\t\treturn block\n\t}\n\tvar blockchain []*common.Block\n\tfor seq := start; seq <= end; seq++ {\n\t\tblock := newBlock(seq)\n\t\tblock.Header.DataHash = protoutil.BlockDataHash(block.Data)\n\t\tblockchain = append(blockchain, block)\n\t}\n\tassignHashes(blockchain)\n\treturn blockchain\n}", "is_vulnerable": 0}
{"code": "func (src *SASLResponse) Encode(dst []byte) []byte {\n\tdst = append(dst, 'p')\n\tdst = pgio.AppendInt32(dst, int32(4+len(src.Data)))\n\n\tdst = append(dst, src.Data...)\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (c *Context) Sign(signers []*Key, plain, sig *Data, mode SigMode) error {\n\tC.gpgme_signers_clear(c.ctx)\n\tfor _, k := range signers {\n\t\tif err := handleError(C.gpgme_signers_add(c.ctx, k.k)); err != nil {\n\t\t\tC.gpgme_signers_clear(c.ctx)\n\t\t\treturn err\n\t\t}\n\t}\n\terr := handleError(C.gpgme_op_sign(c.ctx, plain.dh, sig.dh, C.gpgme_sig_mode_t(mode)))\n\truntime.KeepAlive(plain)\n\truntime.KeepAlive(sig)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (w wasm) CanApply(config *extensioncommon.RuntimeConfig) bool {\n\treturn config.Kind == w.wasmConfig.ProxyType\n}", "is_vulnerable": 0}
{"code": "\treturn func() string { return val }", "is_vulnerable": 0}
{"code": "func TestServerWithPostgresDatastore(t *testing.T) {\n\tds, stopFunc := MustBootstrapDatastore(t, \"postgres\")\n\tdefer func() {\n\t\tstopFunc()\n\t\tgoleak.VerifyNone(t)\n\t}()\n\n\ttest.RunAllTests(t, ds)\n}", "is_vulnerable": 0}
{"code": "func Authenticate(ctx context.Context, auth []security.Authenticator) *security.Caller {\n\t// TODO: apply different authenticators in specific order / according to configuration.\n\tvar errMsg string\n\tfor id, authn := range auth {\n\t\tu, err := authn.Authenticate(ctx)\n\t\tif err != nil {\n\t\t\terrMsg += fmt.Sprintf(\"Authenticator %s at index %d got error: %v. \", authn.AuthenticatorType(), id, err)\n\t\t}\n\t\tif u != nil && err == nil {\n\t\t\tserverCaLog.Debugf(\"Authentication successful through auth source %v\", u.AuthSource)\n\t\t\treturn u\n\t\t}\n\t}\n\tserverCaLog.Warnf(\"Authentication failed for %v: %s\", getConnectionAddress(ctx), errMsg)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func getGenAccountsAndBalances(cfg Config) (genAccounts []authtypes.GenesisAccount, balances []banktypes.Balance) {\n\tif len(cfg.balances) > 0 {\n\t\tbalances = cfg.balances\n\t\taccounts := getAccAddrsFromBalances(balances)\n\t\tgenAccounts = createGenesisAccounts(accounts)\n\t} else {\n\t\tcoin := sdktypes.NewCoin(cfg.denom, PrefundedAccountInitialBalance)\n\t\tgenAccounts = createGenesisAccounts(cfg.preFundedAccounts)\n\t\tbalances = createBalances(cfg.preFundedAccounts, coin)\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func BenchmarkBytes(b *testing.B) {\n\tbfa, err := NewBitfield(216)\n\tassertNoError(b, err)\n\tbfb, err := NewBitfield(216)\n\tassertNoError(b, err)\n\tfor j := 0; j*4 < 216; j++ {\n\t\tbfa.SetBit(j * 4)\n\t}\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tbfb.SetBytes(bfa.Bytes())\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestListAppWithProjects(t *testing.T) {\n\tappServer := newTestAppServer(t, newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"App1\"\n\t\tapp.Spec.Project = \"test-project1\"\n\t}), newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"App2\"\n\t\tapp.Spec.Project = \"test-project2\"\n\t}), newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"App3\"\n\t\tapp.Spec.Project = \"test-project3\"\n\t}))\n\n\tt.Run(\"List all apps\", func(t *testing.T) {\n\t\tappQuery := application.ApplicationQuery{}\n\t\tappList, err := appServer.List(context.Background(), &appQuery)\n\t\tassert.NoError(t, err)\n\t\tassert.Len(t, appList.Items, 3)\n\t})\n\n\tt.Run(\"List apps with projects filter set\", func(t *testing.T) {\n\t\tappQuery := application.ApplicationQuery{Projects: []string{\"test-project1\"}}\n\t\tappList, err := appServer.List(context.Background(), &appQuery)\n\t\tassert.NoError(t, err)\n\t\tassert.Len(t, appList.Items, 1)\n\t\tfor _, app := range appList.Items {\n\t\t\tassert.Equal(t, \"test-project1\", app.Spec.Project)\n\t\t}\n\t})\n\n\tt.Run(\"List apps with project filter set (legacy field)\", func(t *testing.T) {\n\t\tappQuery := application.ApplicationQuery{Project: []string{\"test-project1\"}}\n\t\tappList, err := appServer.List(context.Background(), &appQuery)\n\t\tassert.NoError(t, err)\n\t\tassert.Len(t, appList.Items, 1)\n\t\tfor _, app := range appList.Items {\n\t\t\tassert.Equal(t, \"test-project1\", app.Spec.Project)\n\t\t}\n\t})\n\n\tt.Run(\"List apps with both projects and project filter set\", func(t *testing.T) {\n\t\t// If the older field is present, we should use it instead of the newer field.\n\t\tappQuery := application.ApplicationQuery{Project: []string{\"test-project1\"}, Projects: []string{\"test-project2\"}}\n\t\tappList, err := appServer.List(context.Background(), &appQuery)\n\t\tassert.NoError(t, err)\n\t\tassert.Len(t, appList.Items, 1)\n\t\tfor _, app := range appList.Items {\n\t\t\tassert.Equal(t, \"test-project1\", app.Spec.Project)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func NewQMPMonitor(network, name string, timeout time.Duration) (Monitor, error) {\n\trtDir, err := getRuntimeDir()\n\tif err != nil {\n\t\treturn Monitor{}, err\n\t}\n\tif !rootless.IsRootless() {\n\t\trtDir = \"/run\"\n\t}\n\trtDir = filepath.Join(rtDir, \"podman\")\n\tif _, err := os.Stat(filepath.Join(rtDir)); os.IsNotExist(err) {\n\t\t// TODO 0644 is fine on linux but macos is weird\n\t\tif err := os.MkdirAll(rtDir, 0755); err != nil {\n\t\t\treturn Monitor{}, err\n\t\t}\n\t}\n\tif timeout == 0 {\n\t\ttimeout = defaultQMPTimeout\n\t}\n\tmonitor := Monitor{\n\t\tNetwork: network,\n\t\tAddress: filepath.Join(rtDir, \"qmp_\"+name+\".sock\"),\n\t\tTimeout: timeout,\n\t}\n\treturn monitor, nil\n}", "is_vulnerable": 0}
{"code": "func (wm *HumanPasswordReadModel) Query() *eventstore.SearchQueryBuilder {\n\tquery := eventstore.NewSearchQueryBuilder(eventstore.ColumnsEvent).\n\t\tAwaitOpenTransactions().\n\t\tAllowTimeTravel().\n\t\tAddQuery().\n\t\tAggregateTypes(user.AggregateType).\n\t\tAggregateIDs(wm.AggregateID).\n\t\tEventTypes(user.HumanAddedType,\n\t\t\tuser.HumanRegisteredType,\n\t\t\tuser.HumanInitialCodeAddedType,\n\t\t\tuser.HumanInitializedCheckSucceededType,\n\t\t\tuser.HumanPasswordChangedType,\n\t\t\tuser.HumanPasswordCodeAddedType,\n\t\t\tuser.HumanEmailVerifiedType,\n\t\t\tuser.HumanPasswordCheckFailedType,\n\t\t\tuser.HumanPasswordCheckSucceededType,\n\t\t\tuser.HumanPasswordHashUpdatedType,\n\t\t\tuser.UserRemovedType,\n\t\t\tuser.UserLockedType,\n\t\t\tuser.UserUnlockedType,\n\t\t\tuser.UserV1AddedType,\n\t\t\tuser.UserV1RegisteredType,\n\t\t\tuser.UserV1InitialCodeAddedType,\n\t\t\tuser.UserV1InitializedCheckSucceededType,\n\t\t\tuser.UserV1PasswordChangedType,\n\t\t\tuser.UserV1PasswordCodeAddedType,\n\t\t\tuser.UserV1EmailVerifiedType,\n\t\t\tuser.UserV1PasswordCheckFailedType,\n\t\t\tuser.UserV1PasswordCheckSucceededType,\n\t\t).\n\t\tBuilder()\n\n\tif wm.ResourceOwner != \"\" {\n\t\tquery.ResourceOwner(wm.ResourceOwner)\n\t}\n\treturn query\n}", "is_vulnerable": 0}
{"code": "func (s *TestServer) handleStartup(client *pgproto3.Backend) error {\n\tstartupMessage, err := client.ReceiveStartupMessage()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif _, ok := startupMessage.(*pgproto3.StartupMessage); !ok {\n\t\treturn trace.BadParameter(\"expected *pgproto3.StartupMessage, got: %#v\", startupMessage)\n\t}\n\ts.log.Debugf(\"Received %#v.\", startupMessage)\n\t// If auth token is specified, used it for password authentication, this\n\t// simulates cloud provider IAM auth.\n\tif s.cfg.AuthToken != \"\" {\n\t\tif err := s.handlePasswordAuth(client); err != nil {\n\t\t\tif trace.IsAccessDenied(err) {\n\t\t\t\tif err := client.Send(&pgproto3.ErrorResponse{Code: pgerrcode.InvalidPassword, Message: err.Error()}); err != nil {\n\t\t\t\t\treturn trace.Wrap(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\t// Accept auth and send ready for query.\n\tif err := client.Send(&pgproto3.AuthenticationOk{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := client.Send(&pgproto3.ReadyForQuery{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"WebListener\", func(t *testing.T) {\n\t\tlistener, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\t\trequire.Nil(t, err)\n\n\t\tmux, err := New(Config{\n\t\t\tListener:            listener,\n\t\t\tEnableProxyProtocol: true,\n\t\t})\n\t\trequire.Nil(t, err)\n\t\tgo mux.Serve()\n\t\tdefer mux.Close()\n\n\t\t// Generate self-signed CA.\n\t\tcaKey, caCert, err := tlsca.GenerateSelfSignedCA(pkix.Name{CommonName: \"test-ca\"}, nil, time.Hour)\n\t\trequire.NoError(t, err)\n\t\tca, err := tlsca.FromKeys(caCert, caKey)\n\t\trequire.NoError(t, err)\n\t\tcertPool := x509.NewCertPool()\n\t\tcertPool.AppendCertsFromPEM(caCert)\n\n\t\t// Sign server certificate.\n\t\tserverRSAKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\t\trequire.NoError(t, err)\n\t\tserverPEM, err := ca.GenerateCertificate(tlsca.CertificateRequest{\n\t\t\tSubject:   pkix.Name{CommonName: \"localhost\"},\n\t\t\tPublicKey: serverRSAKey.Public(),\n\t\t\tNotAfter:  time.Now().Add(time.Hour),\n\t\t\tDNSNames:  []string{\"127.0.0.1\"},\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tserverCert, err := tls.X509KeyPair(serverPEM, tlsca.MarshalPrivateKeyPEM(serverRSAKey))\n\t\trequire.NoError(t, err)\n\n\t\t// Sign client certificate with database access identity.\n\t\tclientRSAKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\t\trequire.NoError(t, err)\n\t\tsubject, err := (&tlsca.Identity{\n\t\t\tUsername: \"alice\",\n\t\t\tGroups:   []string{\"admin\"},\n\t\t\tRouteToDatabase: tlsca.RouteToDatabase{\n\t\t\t\tServiceName: \"postgres\",\n\t\t\t},\n\t\t}).Subject()\n\t\trequire.NoError(t, err)\n\t\tclientPEM, err := ca.GenerateCertificate(tlsca.CertificateRequest{\n\t\t\tSubject:   subject,\n\t\t\tPublicKey: clientRSAKey.Public(),\n\t\t\tNotAfter:  time.Now().Add(time.Hour),\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tclientCert, err := tls.X509KeyPair(clientPEM, tlsca.MarshalPrivateKeyPEM(clientRSAKey))\n\t\trequire.NoError(t, err)\n\n\t\twebLis, err := NewWebListener(WebListenerConfig{\n\t\t\tListener: tls.NewListener(mux.TLS(), &tls.Config{\n\t\t\t\tClientCAs:    certPool,\n\t\t\t\tClientAuth:   tls.VerifyClientCertIfGiven,\n\t\t\t\tCertificates: []tls.Certificate{serverCert},\n\t\t\t}),\n\t\t})\n\t\trequire.Nil(t, err)\n\t\tgo webLis.Serve()\n\t\tdefer webLis.Close()\n\n\t\tgo func() {\n\t\t\tconn, err := webLis.Web().Accept()\n\t\t\trequire.NoError(t, err)\n\t\t\tdefer conn.Close()\n\t\t\tconn.Write([]byte(\"web listener\"))\n\t\t}()\n\n\t\tgo func() {\n\t\t\tconn, err := webLis.DB().Accept()\n\t\t\trequire.NoError(t, err)\n\t\t\tdefer conn.Close()\n\t\t\tconn.Write([]byte(\"db listener\"))\n\t\t}()\n\n\t\twebConn, err := tls.Dial(\"tcp\", listener.Addr().String(), &tls.Config{\n\t\t\tRootCAs: certPool,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tdefer webConn.Close()\n\n\t\twebBytes, err := io.ReadAll(webConn)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, \"web listener\", string(webBytes))\n\n\t\tdbConn, err := tls.Dial(\"tcp\", listener.Addr().String(), &tls.Config{\n\t\t\tRootCAs:      certPool,\n\t\t\tCertificates: []tls.Certificate{clientCert},\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tdefer dbConn.Close()\n\n\t\tdbBytes, err := io.ReadAll(dbConn)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, \"db listener\", string(dbBytes))\n\t})", "is_vulnerable": 0}
{"code": "func NewCachedCheckResolver(opts ...CachedCheckResolverOpt) *CachedCheckResolver {\n\tchecker := &CachedCheckResolver{\n\t\tmaxCacheSize: defaultMaxCacheSize,\n\t\tcacheTTL:     defaultCacheTTL,\n\t\tlogger:       logger.NewNoopLogger(),\n\t}\n\tchecker.delegate = checker\n\n\tfor _, opt := range opts {\n\t\topt(checker)\n\t}\n\n\tif checker.cache == nil {\n\t\tchecker.allocatedCache = true\n\t\tchecker.cache = ccache.New(\n\t\t\tccache.Configure[*ResolveCheckResponse]().MaxSize(checker.maxCacheSize),\n\t\t)\n\t}\n\n\treturn checker\n}", "is_vulnerable": 0}
{"code": "func (h *Helper) InstallRouter(kubeClient kclientset.Interface, f *clientcmd.Factory, configDir, images, hostIP string, portForwarding bool, out, errout io.Writer) error {\n\t_, err := kubeClient.Core().Services(DefaultNamespace).Get(SvcRouter)\n\tif err == nil {\n\t\t// Router service already exists, nothing to do\n\t\treturn nil\n\t}\n\tif !apierrors.IsNotFound(err) {\n\t\treturn errors.NewError(\"error retrieving router service\").WithCause(err).WithDetails(h.OriginLog())\n\t}\n\n\tmasterDir := filepath.Join(configDir, \"master\")\n\n\t// Create service account for router\n\trouterSA := &kapi.ServiceAccount{}\n\trouterSA.Name = \"router\"\n\t_, err = kubeClient.Core().ServiceAccounts(\"default\").Create(routerSA)\n\tif err != nil {\n\t\treturn errors.NewError(\"cannot create router service account\").WithCause(err).WithDetails(h.OriginLog())\n\t}\n\n\t// Add router SA to privileged SCC\n\tprivilegedSCC, err := kubeClient.Core().SecurityContextConstraints().Get(\"privileged\")\n\tif err != nil {\n\t\treturn errors.NewError(\"cannot retrieve privileged SCC\").WithCause(err).WithDetails(h.OriginLog())\n\t}\n\tprivilegedSCC.Users = append(privilegedSCC.Users, serviceaccount.MakeUsername(\"default\", \"router\"))\n\t_, err = kubeClient.Core().SecurityContextConstraints().Update(privilegedSCC)\n\tif err != nil {\n\t\treturn errors.NewError(\"cannot update privileged SCC\").WithCause(err).WithDetails(h.OriginLog())\n\t}\n\n\t// Create router cert\n\tcmdOutput := &bytes.Buffer{}\n\tcreateCertOptions := &admin.CreateServerCertOptions{\n\t\tSignerCertOptions: &admin.SignerCertOptions{\n\t\t\tCertFile:   filepath.Join(masterDir, \"ca.crt\"),\n\t\t\tKeyFile:    filepath.Join(masterDir, \"ca.key\"),\n\t\t\tSerialFile: filepath.Join(masterDir, \"ca.serial.txt\"),\n\t\t},\n\t\tOverwrite: true,\n\t\tHostnames: []string{\n\t\t\tfmt.Sprintf(\"%s.xip.io\", hostIP),\n\t\t\t// This will ensure that routes using edge termination and the default\n\t\t\t// certs will use certs valid for their arbitrary subdomain names.\n\t\t\tfmt.Sprintf(\"*.%s.xip.io\", hostIP),\n\t\t},\n\t\tCertFile: filepath.Join(masterDir, \"router.crt\"),\n\t\tKeyFile:  filepath.Join(masterDir, \"router.key\"),\n\t\tOutput:   cmdOutput,\n\t}\n\t_, err = createCertOptions.CreateServerCert()\n\tif err != nil {\n\t\treturn errors.NewError(\"cannot create router cert\").WithCause(err)\n\t}\n\n\terr = catFiles(filepath.Join(masterDir, \"router.pem\"),\n\t\tfilepath.Join(masterDir, \"router.crt\"),\n\t\tfilepath.Join(masterDir, \"router.key\"),\n\t\tfilepath.Join(masterDir, \"ca.crt\"))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\timageTemplate := variable.NewDefaultImageTemplate()\n\timageTemplate.Format = images\n\tcfg := &router.RouterConfig{\n\t\tName:               \"router\",\n\t\tType:               \"haproxy-router\",\n\t\tImageTemplate:      imageTemplate,\n\t\tPorts:              \"80:80,443:443\",\n\t\tReplicas:           1,\n\t\tLabels:             \"router=<name>\",\n\t\tCredentials:        filepath.Join(masterDir, \"admin.kubeconfig\"),\n\t\tDefaultCertificate: filepath.Join(masterDir, \"router.pem\"),\n\t\tStatsPort:          1936,\n\t\tStatsUsername:      \"admin\",\n\t\tHostNetwork:        !portForwarding,\n\t\tHostPorts:          true,\n\t\tServiceAccount:     \"router\",\n\t}\n\toutput := &bytes.Buffer{}\n\tcmd := router.NewCmdRouter(f, \"\", \"router\", out, errout)\n\tcmd.SetOutput(output)\n\terr = router.RunCmdRouter(f, cmd, output, output, cfg, []string{})\n\tglog.V(4).Infof(\"Router command output:\\n%s\", output.String())\n\tif err != nil {\n\t\treturn errors.NewError(\"cannot install router\").WithCause(err).WithDetails(h.OriginLog())\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *C) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: C: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: C: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 2:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\tm.Field2 = &v2\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Field3 = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\tm.Field4 = &v2\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field5 = append(m.Field5, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.Field5[len(m.Field5)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field6 = &v\n\t\tcase 7:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field7 = append(m.Field7, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field7 = append(m.Field7, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognized(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func BuildService(config *Config, logger logger.Logger) (*service, error) {\n\ttracer := telemetry.NewNoopTracer()\n\tmeter := telemetry.NewNoopMeter()\n\ttokenEncoder := encoder.NewTokenEncoder(encrypter.NewNoopEncrypter(), encoder.NewBase64Encoder())\n\n\tvar datastore storage.OpenFGADatastore\n\tvar err error\n\tswitch config.Datastore.Engine {\n\tcase \"memory\":\n\t\tdatastore = memory.New(tracer, config.MaxTuplesPerWrite, config.MaxTypesPerAuthorizationModel)\n\tcase \"mysql\":\n\t\topts := []mysql.MySQLOption{\n\t\t\tmysql.WithLogger(logger),\n\t\t\tmysql.WithTracer(tracer),\n\t\t}\n\n\t\tdatastore, err = mysql.NewMySQLDatastore(config.Datastore.URI, opts...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Errorf(\"failed to initialize mysql datastore: %v\", err)\n\t\t}\n\tcase \"postgres\":\n\t\topts := []postgres.PostgresOption{\n\t\t\tpostgres.WithLogger(logger),\n\t\t\tpostgres.WithTracer(tracer),\n\t\t}\n\n\t\tdatastore, err = postgres.NewPostgresDatastore(config.Datastore.URI, opts...)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Errorf(\"failed to initialize postgres datastore: %v\", err)\n\t\t}\n\tdefault:\n\t\treturn nil, errors.Errorf(\"storage engine '%s' is unsupported\", config.Datastore.Engine)\n\t}\n\n\tlogger.Info(fmt.Sprintf(\"using '%v' storage engine\", config.Datastore.Engine))\n\n\tvar grpcTLSConfig *server.TLSConfig\n\tif config.GRPC.TLS.Enabled {\n\t\tif config.GRPC.TLS.CertPath == \"\" || config.GRPC.TLS.KeyPath == \"\" {\n\t\t\treturn nil, ErrInvalidGRPCTLSConfig\n\t\t}\n\t\tgrpcTLSConfig = &server.TLSConfig{\n\t\t\tCertPath: config.GRPC.TLS.CertPath,\n\t\t\tKeyPath:  config.GRPC.TLS.KeyPath,\n\t\t}\n\t\tlogger.Info(\"grpc TLS is enabled, serving connections using the provided certificate\")\n\t} else {\n\t\tlogger.Warn(\"grpc TLS is disabled, serving connections using insecure plaintext\")\n\t}\n\n\tvar httpTLSConfig *server.TLSConfig\n\tif config.HTTP.TLS.Enabled {\n\t\tif config.HTTP.TLS.CertPath == \"\" || config.HTTP.TLS.KeyPath == \"\" {\n\t\t\treturn nil, ErrInvalidHTTPTLSConfig\n\t\t}\n\t\thttpTLSConfig = &server.TLSConfig{\n\t\t\tCertPath: config.HTTP.TLS.CertPath,\n\t\t\tKeyPath:  config.HTTP.TLS.KeyPath,\n\t\t}\n\t\tlogger.Info(\"HTTP TLS is enabled, serving HTTP connections using the provided certificate\")\n\t} else {\n\t\tlogger.Warn(\"HTTP TLS is disabled, serving connections using insecure plaintext\")\n\t}\n\n\tvar authenticator authn.Authenticator\n\tswitch config.Authn.Method {\n\tcase \"none\":\n\t\tlogger.Warn(\"authentication is disabled\")\n\t\tauthenticator = authn.NoopAuthenticator{}\n\tcase \"preshared\":\n\t\tlogger.Info(\"using 'preshared' authentication\")\n\t\tauthenticator, err = presharedkey.NewPresharedKeyAuthenticator(config.Authn.Keys)\n\tcase \"oidc\":\n\t\tlogger.Info(\"using 'oidc' authentication\")\n\t\tauthenticator, err = oidc.NewRemoteOidcAuthenticator(config.Authn.Issuer, config.Authn.Audience)\n\tdefault:\n\t\treturn nil, errors.Errorf(\"unsupported authentication method '%v'\", config.Authn.Method)\n\t}\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to initialize authenticator: %v\", err)\n\t}\n\n\tunaryServerInterceptors := []grpc.UnaryServerInterceptor{\n\t\tgrpc_auth.UnaryServerInterceptor(middleware.AuthFunc(authenticator)),\n\t\tmiddleware.NewErrorLoggingInterceptor(logger),\n\t}\n\n\tstreamingServerInterceptors := []grpc.StreamServerInterceptor{\n\t\tgrpc_auth.StreamServerInterceptor(middleware.AuthFunc(authenticator)),\n\t\tmiddleware.NewStreamingErrorLoggingInterceptor(logger),\n\t}\n\n\tgrpcHostAddr, grpcHostPort, err := net.SplitHostPort(config.GRPC.Addr)\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"`grpc.addr` config must be in the form [host]:port\")\n\t}\n\n\tif grpcHostAddr == \"\" {\n\t\tgrpcHostAddr = \"0.0.0.0\"\n\t}\n\n\tgrpcAddr, err := netip.ParseAddrPort(fmt.Sprintf(\"%s:%s\", grpcHostAddr, grpcHostPort))\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to parse the 'grpc.addr' config: %v\", err)\n\t}\n\n\thttpHostAddr, httpHostPort, err := net.SplitHostPort(config.HTTP.Addr)\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"`http.addr` config must be in the form [host]:port\")\n\t}\n\n\tif httpHostAddr == \"\" {\n\t\thttpHostAddr = \"0.0.0.0\"\n\t}\n\n\thttpAddr, err := netip.ParseAddrPort(fmt.Sprintf(\"%s:%s\", httpHostAddr, httpHostPort))\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to parse the 'http.addr' config: %v\", err)\n\t}\n\n\topenFgaServer, err := server.New(&server.Dependencies{\n\t\tDatastore:    caching.NewCachedOpenFGADatastore(datastore, config.Datastore.MaxCacheSize),\n\t\tTracer:       tracer,\n\t\tLogger:       logger,\n\t\tMeter:        meter,\n\t\tTokenEncoder: tokenEncoder,\n\t}, &server.Config{\n\t\tGRPCServer: server.GRPCServerConfig{\n\t\t\tAddr:      grpcAddr,\n\t\t\tTLSConfig: grpcTLSConfig,\n\t\t},\n\t\tHTTPServer: server.HTTPServerConfig{\n\t\t\tEnabled:            config.HTTP.Enabled,\n\t\t\tAddr:               httpAddr,\n\t\t\tTLSConfig:          httpTLSConfig,\n\t\t\tUpstreamTimeout:    config.HTTP.UpstreamTimeout,\n\t\t\tCORSAllowedOrigins: config.HTTP.CORSAllowedOrigins,\n\t\t\tCORSAllowedHeaders: config.HTTP.CORSAllowedHeaders,\n\t\t},\n\t\tResolveNodeLimit:       config.ResolveNodeLimit,\n\t\tChangelogHorizonOffset: config.ChangelogHorizonOffset,\n\t\tListObjectsDeadline:    config.ListObjectsDeadline,\n\t\tListObjectsMaxResults:  config.ListObjectsMaxResults,\n\t\tUnaryInterceptors:      unaryServerInterceptors,\n\t\tStreamingInterceptors:  streamingServerInterceptors,\n\t\tMuxOptions:             nil,\n\t})\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"failed to initialize openfga server: %v\", err)\n\t}\n\n\treturn &service{\n\t\tserver:        openFgaServer,\n\t\tgrpcAddr:      grpcAddr,\n\t\thttpAddr:      httpAddr,\n\t\tdatastore:     datastore,\n\t\tauthenticator: authenticator,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (self *CryptoManager) Decrypt(cipher_text []byte) (*vcrypto.MessageInfo, error) {\n\tvar err error\n\t// Parse the ClientCommunication protobuf.\n\tcommunications := &crypto_proto.ClientCommunication{}\n\terr = proto.Unmarshal(cipher_text, communications)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t// An empty message is not an error but we can't figure out the\n\t// source.\n\tif len(communications.EncryptedCipher) == 0 {\n\t\treturn &vcrypto.MessageInfo{}, nil\n\t}\n\n\tcipher, ok := self.cipher_lru.GetByInboundCipher(communications.EncryptedCipher)\n\tif ok {\n\t\t// Check HMAC to save checking the RSA signature for\n\t\t// malformed packets.\n\t\tif !hmac.Equal(\n\t\t\tself.calcHMAC(communications, cipher.cipher_properties),\n\t\t\tcommunications.FullHmac) {\n\t\t\treturn nil, errors.New(\"HMAC did not verify\")\n\t\t}\n\n\t\tmsg_info, _, err := self.extractMessageInfo(\n\t\t\tcipher.cipher_properties, communications)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Cipher was cached so we trust it\n\t\tmsg_info.Authenticated = true\n\n\t\treturn msg_info, nil\n\n\t}\n\n\t// Decrypt the CipherProperties\n\tRsaDecryptCounter.Inc()\n\tserialized_cipher, err := rsa.DecryptOAEP(\n\t\tsha1.New(), rand.Reader,\n\t\tself.private_key,\n\t\tcommunications.EncryptedCipher,\n\t\t[]byte(\"\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcipher_properties := &crypto_proto.CipherProperties{}\n\terr = proto.Unmarshal(serialized_cipher, cipher_properties)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t// Check HMAC first to save checking the RSA signature for\n\t// malformed packets.\n\tif !hmac.Equal(\n\t\tself.calcHMAC(communications, cipher_properties),\n\t\tcommunications.FullHmac) {\n\t\treturn nil, errors.New(\"HMAC did not verify\")\n\t}\n\n\t// Extract the serialized CipherMetadata.\n\tserialized_metadata, err := decryptSymmetric(\n\t\tcipher_properties, communications.EncryptedCipherMetadata,\n\t\tcipher_properties.MetadataIv)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcipher_metadata := &crypto_proto.CipherMetadata{}\n\terr = proto.Unmarshal(serialized_metadata, cipher_metadata)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tmsg_info, org_config_obj, err := self.extractMessageInfo(\n\t\tcipher_properties, communications)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Verify the cipher metadata signature.\n\tcipher_metadata.Source = utils.ClientIdFromSourceAndOrg(\n\t\tcipher_metadata.Source, msg_info.OrgId)\n\n\tmsg_info.Authenticated, err = self.getAuthState(\n\t\torg_config_obj, cipher_metadata, serialized_cipher, cipher_properties)\n\n\t// If we could verify the authentication state and it\n\t// was authenticated, we are now allowed to cache the\n\t// cipher in the input cache. The next packet from\n\t// this session will NOT be verified.\n\tif err == nil && msg_info.Authenticated {\n\t\tself.cipher_lru.Set(\n\t\t\tmsg_info.Source,\n\t\t\t&_Cipher{\n\t\t\t\tencrypted_cipher:  communications.EncryptedCipher,\n\t\t\t\tcipher_properties: cipher_properties,\n\t\t\t},\n\t\t\tnil, /* outbound_cipher */\n\t\t)\n\t}\n\treturn msg_info, nil\n}", "is_vulnerable": 1}
{"code": "func UtimesNano(path string, ts []Timespec) error {\n\tif ts == nil {\n\t\terr := utimensat(AT_FDCWD, path, nil, 0)\n\t\tif err != ENOSYS {\n\t\t\treturn err\n\t\t}\n\t\treturn utimes(path, nil)\n\t}\n\tif len(ts) != 2 {\n\t\treturn EINVAL\n\t}\n\terr := utimensat(AT_FDCWD, path, (*[2]Timespec)(unsafe.Pointer(&ts[0])), 0)\n\tif err != ENOSYS {\n\t\treturn err\n\t}\n\t// If the utimensat syscall isn't available (utimensat was added to Linux\n\t// in 2.6.22, Released, 8 July 2007) then fall back to utimes\n\tvar tv [2]Timeval\n\tfor i := 0; i < 2; i++ {\n\t\ttv[i] = NsecToTimeval(TimespecToNsec(ts[i]))\n\t}\n\treturn utimes(path, (*[2]Timeval)(unsafe.Pointer(&tv[0])))\n}", "is_vulnerable": 1}
{"code": "func (*Zip) CheckPath(to, filename string) error {\n\tto, _ = filepath.Abs(to) //explicit the destination folder to prevent that 'string.HasPrefix' check can be 'bypassed' when no destination folder is supplied in input\n\tdest := filepath.Join(to, filename)\n\t//prevent path traversal attacks\n\tif !strings.HasPrefix(dest, to) {\n\t\treturn fmt.Errorf(\"illegal file path: %s\", filename)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (u *Upgrade) prepareUpgrade(name string, chart *chart.Chart, vals map[string]interface{}) (*release.Release, *release.Release, error) {\n\tif chart == nil {\n\t\treturn nil, nil, errMissingChart\n\t}\n\n\t// finds the deployed release with the given name\n\tcurrentRelease, err := u.cfg.Releases.Deployed(name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// determine if values will be reused\n\tvals, err = u.reuseValues(chart, currentRelease, vals)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif err := chartutil.ProcessDependencies(chart, vals); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// finds the non-deleted release with the given name\n\tlastRelease, err := u.cfg.Releases.Last(name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Increment revision count. This is passed to templates, and also stored on\n\t// the release object.\n\trevision := lastRelease.Version + 1\n\n\toptions := chartutil.ReleaseOptions{\n\t\tName:      name,\n\t\tNamespace: currentRelease.Namespace,\n\t\tRevision:  revision,\n\t\tIsUpgrade: true,\n\t}\n\n\tcaps, err := u.cfg.getCapabilities()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvaluesToRender, err := chartutil.ToRenderValues(chart, vals, options, caps)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\thooks, manifestDoc, notesTxt, err := u.cfg.renderResources(chart, valuesToRender, \"\", \"\", u.SubNotes, false, false, u.PostRenderer, u.DryRun)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Store an upgraded release.\n\tupgradedRelease := &release.Release{\n\t\tName:      name,\n\t\tNamespace: currentRelease.Namespace,\n\t\tChart:     chart,\n\t\tConfig:    vals,\n\t\tInfo: &release.Info{\n\t\t\tFirstDeployed: currentRelease.Info.FirstDeployed,\n\t\t\tLastDeployed:  Timestamper(),\n\t\t\tStatus:        release.StatusPendingUpgrade,\n\t\t\tDescription:   \"Preparing upgrade\", // This should be overwritten later.\n\t\t},\n\t\tVersion:  revision,\n\t\tManifest: manifestDoc.String(),\n\t\tHooks:    hooks,\n\t}\n\n\tif len(notesTxt) > 0 {\n\t\tupgradedRelease.Info.Notes = notesTxt\n\t}\n\terr = validateManifest(u.cfg.KubeClient, manifestDoc.Bytes(), !u.DisableOpenAPIValidation)\n\treturn currentRelease, upgradedRelease, err\n}", "is_vulnerable": 0}
{"code": "\t\tapp.WithOnInvokeFn(func(ctx context.Context, _ *commonv1.InvokeRequest) (*commonv1.InvokeResponse, error) {\n\t\t\tmd, ok := metadata.FromIncomingContext(ctx)\n\t\t\trequire.True(t, ok)\n\t\t\tn.ch <- md\n\t\t\treturn new(commonv1.InvokeResponse), nil\n\t\t}),", "is_vulnerable": 0}
{"code": "func UnZip(zipFile string, destPath string) error {\n\tzipReader, err := zip.OpenReader(zipFile)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer zipReader.Close()\n\n\tfor _, f := range zipReader.File {\n\t\tpath := filepath.Join(destPath, f.Name)\n\t\tif f.FileInfo().IsDir() {\n\t\t\tos.MkdirAll(path, os.ModePerm)\n\t\t} else {\n\t\t\tif err = os.MkdirAll(filepath.Dir(path), os.ModePerm); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tinFile, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer inFile.Close()\n\n\t\t\toutFile, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, f.Mode())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer outFile.Close()\n\n\t\t\t_, err = io.Copy(outFile, inFile)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *mockLayer) Compressed() (io.ReadCloser, error)  { panic(\"not implemented\") }", "is_vulnerable": 0}
{"code": "\treturn func(host string, a net.Addr, hostKey ssh.PublicKey) error {\n\t\tclusterCert, ok := hostKey.(*ssh.Certificate)\n\t\tif ok {\n\t\t\thostKey = clusterCert.SignatureKey\n\t\t}\n\t\tfor _, trustedKey := range trustedKeys {\n\t\t\tif sshutils.KeysEqual(trustedKey, hostKey) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn trace.AccessDenied(\"host %v is untrusted or Teleport CA has been rotated; try getting new credentials by logging in again ('tsh login') or re-exporting the identity file ('tctl auth sign' or 'tsh login -o'), depending on how you got them initially\", host)\n\t}, nil", "is_vulnerable": 1}
{"code": "\t\t\tgo func() {\n\t\t\t\treverseExpandQuery.Execute(timeoutCtx, test.request, resultChan, resolutionMetadata)\n\t\t\t}()", "is_vulnerable": 1}
{"code": "func TestHandleCrash(t *testing.T) {\n\tdefer func() {\n\t\tif x := recover(); x != nil {\n\t\t\tt.Errorf(\"Expected no panic \")\n\t\t}\n\t}()\n\n\tdefer HandleCrash()\n\tpanic(\"test\")\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tstore := id.Must(id.New()).String()\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              id.Must(id.New()).String(),\n\t\t\t\tSchemaVersion:   typesystem.SchemaVersion1_0,\n\t\t\t\tTypeDefinitions: test.typeDefinitions,\n\t\t\t}\n\n\t\t\terr := datastore.WriteAuthorizationModel(ctx, store, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tif test.tuples != nil {\n\t\t\t\terr := datastore.Write(ctx, store, nil, test.tuples)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\n\t\t\tcmd := commands.NewCheckQuery(datastore, tracer, meter, logger, test.resolveNodeLimit)\n\t\t\ttest.request.StoreId = store\n\t\t\ttest.request.AuthorizationModelId = model.Id\n\t\t\tresp, gotErr := cmd.Execute(ctx, test.request)\n\n\t\t\tif test.err == nil {\n\t\t\t\trequire.NoError(t, gotErr)\n\t\t\t}\n\n\t\t\tif test.err != nil {\n\t\t\t\trequire.EqualError(t, test.err, gotErr.Error())\n\t\t\t}\n\n\t\t\tif test.response != nil {\n\t\t\t\trequire.NoError(t, gotErr)\n\n\t\t\t\trequire.Equal(t, test.response.Allowed, resp.Allowed)\n\n\t\t\t\tif test.response.Allowed {\n\t\t\t\t\trequire.Equal(t, test.response.Resolution, resp.Resolution)\n\t\t\t\t}\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (m *LaunchPlanManager) ListLaunchPlans(ctx context.Context, request admin.ResourceListRequest) (\n\t*admin.LaunchPlanList, error) {\n\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"\")\n\t\treturn nil, err\n\t}\n\tctx = m.getNamedEntityContext(ctx, request.Id)\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListLaunchPlans\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plans for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanList, err := transformers.FromLaunchPlanModels(output.LaunchPlans)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform launch plan models [%+v] with err: %v\", output.LaunchPlans, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.LaunchPlanList{\n\t\tLaunchPlans: launchPlanList,\n\t\tToken:       token,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (e *ERC20LogicView) FindWithdrawal(\n\tw *types.ERC20Withdrawal,\n\tblockNumber, logIndex uint64,\n\tethAssetAddress string,\n) (*big.Int, string, uint, error) {\n\tbf, err := bridgecontract.NewErc20BridgeLogicRestrictedFilterer(\n\t\te.clt.CollateralBridgeAddress(), e.clt)\n\tif err != nil {\n\t\treturn nil, \"\", 0, err\n\t}\n\n\tresp := \"ok\"\n\tdefer func() {\n\t\tmetrics.EthCallInc(\"find_withdrawal\", w.VegaAssetID, resp)\n\t}()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\titer, err := bf.FilterAssetWithdrawn(\n\t\t&bind.FilterOpts{\n\t\t\tStart:   blockNumber - 1,\n\t\t\tContext: ctx,\n\t\t},\n\t\t// user_address\n\t\t[]ethcommon.Address{ethcommon.HexToAddress(w.TargetEthereumAddress)},\n\t\t// asset_source\n\t\t[]ethcommon.Address{ethcommon.HexToAddress(ethAssetAddress)})\n\tif err != nil {\n\t\tresp = getMaybeHTTPStatus(err)\n\t\treturn nil, \"\", 0, err\n\t}\n\tdefer iter.Close()\n\n\tvar event *bridgecontract.Erc20BridgeLogicRestrictedAssetWithdrawn\n\tnonce := &big.Int{}\n\t_, ok := nonce.SetString(w.ReferenceNonce, 10)\n\tif !ok {\n\t\treturn nil, \"\", 0, fmt.Errorf(\"could not use reference nonce, expected base 10 integer: %v\", w.ReferenceNonce)\n\t}\n\n\tfor iter.Next() {\n\t\tif nonce.Cmp(iter.Event.Nonce) == 0 &&\n\t\t\titer.Event.Raw.BlockNumber == blockNumber &&\n\t\t\tuint64(iter.Event.Raw.Index) == logIndex {\n\t\t\tevent = iter.Event\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif event == nil {\n\t\treturn nil, \"\", 0, ErrUnableToFindERC20Withdrawal\n\t}\n\n\t// now ensure we have enough confirmations\n\tif err := e.ethConfs.Check(event.Raw.BlockNumber); err != nil {\n\t\treturn nil, \"\", 0, err\n\t}\n\n\treturn nonce, event.Raw.TxHash.Hex(), event.Raw.Index, nil\n}", "is_vulnerable": 1}
{"code": "func TestHelmGetParams(t *testing.T) {\n\trepoRoot := \"./testdata/redis\"\n\trepoRootAbs, err := filepath.Abs(repoRoot)\n\trequire.NoError(t, err)\n\th, err := NewHelmApp(repoRootAbs, nil, false, \"\", \"\", false)\n\tassert.NoError(t, err)\n\tparams, err := h.GetParameters(nil)\n\tassert.Nil(t, err)\n\n\tslaveCountParam := params[\"cluster.slaveCount\"]\n\tassert.Equal(t, \"1\", slaveCountParam)\n}", "is_vulnerable": 1}
{"code": "\t\tRun(func(ctx framework.TestContext) {\n\t\t\tns := namespace.NewOrFail(t, ctx, namespace.Config{\n\t\t\t\tPrefix: \"v1beta1-ingress-gateway\",\n\t\t\t\tInject: true,\n\t\t\t})\n\t\t\targs := map[string]string{\n\t\t\t\t\"Namespace\":     ns.Name(),\n\t\t\t\t\"RootNamespace\": istio.GetOrFail(ctx, ctx).Settings().SystemNamespace,\n\t\t\t}\n\n\t\t\tapplyPolicy := func(filename string) []string {\n\t\t\t\tpolicy := tmpl.EvaluateAllOrFail(t, args, file.AsStringOrFail(t, filename))\n\t\t\t\tctx.Config().ApplyYAMLOrFail(t, \"\", policy...)\n\t\t\t\treturn policy\n\t\t\t}\n\t\t\tpolicies := applyPolicy(\"testdata/authz/v1beta1-ingress-gateway.yaml.tmpl\")\n\t\t\tdefer ctx.Config().DeleteYAMLOrFail(t, \"\", policies...)\n\n\t\t\tvar b echo.Instance\n\t\t\techoboot.NewBuilder(ctx).\n\t\t\t\tWith(&b, util.EchoConfig(\"b\", ns, false, nil)).\n\t\t\t\tBuildOrFail(t)\n\n\t\t\tingr := ist.IngressFor(ctx.Clusters().Default())\n\n\t\t\tcases := []struct {\n\t\t\t\tName     string\n\t\t\t\tHost     string\n\t\t\t\tPath     string\n\t\t\t\tIP       string\n\t\t\t\tWantCode int\n\t\t\t}{\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny deny.company.com\",\n\t\t\t\t\tHost:     \"deny.company.com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny DENY.COMPANY.COM\",\n\t\t\t\t\tHost:     \"DENY.COMPANY.COM\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny Deny.Company.Com\",\n\t\t\t\t\tHost:     \"Deny.Company.Com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny deny.suffix.company.com\",\n\t\t\t\t\tHost:     \"deny.suffix.company.com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny DENY.SUFFIX.COMPANY.COM\",\n\t\t\t\t\tHost:     \"DENY.SUFFIX.COMPANY.COM\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny Deny.Suffix.Company.Com\",\n\t\t\t\t\tHost:     \"Deny.Suffix.Company.Com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny prefix.company.com\",\n\t\t\t\t\tHost:     \"prefix.company.com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny PREFIX.COMPANY.COM\",\n\t\t\t\t\tHost:     \"PREFIX.COMPANY.COM\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"case-insensitive-deny Prefix.Company.Com\",\n\t\t\t\t\tHost:     \"Prefix.Company.Com\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"allow www.company.com\",\n\t\t\t\t\tHost:     \"www.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"172.16.0.1\",\n\t\t\t\t\tWantCode: 200,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny www.company.com/private\",\n\t\t\t\t\tHost:     \"www.company.com\",\n\t\t\t\t\tPath:     \"/private\",\n\t\t\t\t\tIP:       \"172.16.0.1\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"allow www.company.com/public\",\n\t\t\t\t\tHost:     \"www.company.com\",\n\t\t\t\t\tPath:     \"/public\",\n\t\t\t\t\tIP:       \"172.16.0.1\",\n\t\t\t\t\tWantCode: 200,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny internal.company.com\",\n\t\t\t\t\tHost:     \"internal.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"172.16.0.1\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny internal.company.com/private\",\n\t\t\t\t\tHost:     \"internal.company.com\",\n\t\t\t\t\tPath:     \"/private\",\n\t\t\t\t\tIP:       \"172.16.0.1\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny 172.17.72.46\",\n\t\t\t\t\tHost:     \"remoteipblocks.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"172.17.72.46\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny 192.168.5.233\",\n\t\t\t\t\tHost:     \"remoteipblocks.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"192.168.5.233\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"allow 10.4.5.6\",\n\t\t\t\t\tHost:     \"remoteipblocks.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"10.4.5.6\",\n\t\t\t\t\tWantCode: 200,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny 10.2.3.4\",\n\t\t\t\t\tHost:     \"notremoteipblocks.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"10.2.3.4\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"allow 172.23.242.188\",\n\t\t\t\t\tHost:     \"notremoteipblocks.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"172.23.242.188\",\n\t\t\t\t\tWantCode: 200,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny 10.242.5.7\",\n\t\t\t\t\tHost:     \"remoteipattr.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"10.242.5.7\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"deny 10.124.99.10\",\n\t\t\t\t\tHost:     \"remoteipattr.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"10.124.99.10\",\n\t\t\t\t\tWantCode: 403,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tName:     \"allow 10.4.5.6\",\n\t\t\t\t\tHost:     \"remoteipattr.company.com\",\n\t\t\t\t\tPath:     \"/\",\n\t\t\t\t\tIP:       \"10.4.5.6\",\n\t\t\t\t\tWantCode: 200,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tfor _, tc := range cases {\n\t\t\t\tctx.NewSubTest(tc.Name).Run(func(ctx framework.TestContext) {\n\t\t\t\t\theaders := map[string][]string{\n\t\t\t\t\t\t\"X-Forwarded-For\": {tc.IP},\n\t\t\t\t\t}\n\t\t\t\t\tauthn.CheckIngressOrFail(ctx, ingr, tc.Host, tc.Path, headers, \"\", tc.WantCode)\n\t\t\t\t})\n\t\t\t}\n\t\t})\n}", "is_vulnerable": 0}
{"code": "\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response != nil {\n\t\t\t\tsc = result.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()", "is_vulnerable": 0}
{"code": "func Build(ctx context.Context, containerFiles []string, options entities.BuildOptions) (*entities.BuildReport, error) {\n\tif options.CommonBuildOpts == nil {\n\t\toptions.CommonBuildOpts = new(define.CommonBuildOptions)\n\t}\n\n\tparams := url.Values{}\n\n\tif caps := options.AddCapabilities; len(caps) > 0 {\n\t\tc, err := jsoniter.MarshalToString(caps)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"addcaps\", c)\n\t}\n\n\tif annotations := options.Annotations; len(annotations) > 0 {\n\t\tl, err := jsoniter.MarshalToString(annotations)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"annotations\", l)\n\t}\n\n\tif cppflags := options.CPPFlags; len(cppflags) > 0 {\n\t\tl, err := jsoniter.MarshalToString(cppflags)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"cppflags\", l)\n\t}\n\n\tif options.AllPlatforms {\n\t\tparams.Add(\"allplatforms\", \"1\")\n\t}\n\n\tparams.Add(\"t\", options.Output)\n\tfor _, tag := range options.AdditionalTags {\n\t\tparams.Add(\"t\", tag)\n\t}\n\tif additionalBuildContexts := options.AdditionalBuildContexts; len(additionalBuildContexts) > 0 {\n\t\tadditionalBuildContextMap, err := jsoniter.Marshal(additionalBuildContexts)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"additionalbuildcontexts\", string(additionalBuildContextMap))\n\t}\n\tif options.IDMappingOptions != nil {\n\t\tidmappingsOptions, err := jsoniter.Marshal(options.IDMappingOptions)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"idmappingoptions\", string(idmappingsOptions))\n\t}\n\tif buildArgs := options.Args; len(buildArgs) > 0 {\n\t\tbArgs, err := jsoniter.MarshalToString(buildArgs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"buildargs\", bArgs)\n\t}\n\tif excludes := options.Excludes; len(excludes) > 0 {\n\t\tbArgs, err := jsoniter.MarshalToString(excludes)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"excludes\", bArgs)\n\t}\n\tif cpuPeriod := options.CommonBuildOpts.CPUPeriod; cpuPeriod > 0 {\n\t\tparams.Set(\"cpuperiod\", strconv.Itoa(int(cpuPeriod)))\n\t}\n\tif cpuQuota := options.CommonBuildOpts.CPUQuota; cpuQuota > 0 {\n\t\tparams.Set(\"cpuquota\", strconv.Itoa(int(cpuQuota)))\n\t}\n\tif cpuSetCpus := options.CommonBuildOpts.CPUSetCPUs; len(cpuSetCpus) > 0 {\n\t\tparams.Set(\"cpusetcpus\", cpuSetCpus)\n\t}\n\tif cpuSetMems := options.CommonBuildOpts.CPUSetMems; len(cpuSetMems) > 0 {\n\t\tparams.Set(\"cpusetmems\", cpuSetMems)\n\t}\n\tif cpuShares := options.CommonBuildOpts.CPUShares; cpuShares > 0 {\n\t\tparams.Set(\"cpushares\", strconv.Itoa(int(cpuShares)))\n\t}\n\tif len(options.CommonBuildOpts.CgroupParent) > 0 {\n\t\tparams.Set(\"cgroupparent\", options.CommonBuildOpts.CgroupParent)\n\t}\n\n\tparams.Set(\"networkmode\", strconv.Itoa(int(options.ConfigureNetwork)))\n\tparams.Set(\"outputformat\", options.OutputFormat)\n\n\tif devices := options.Devices; len(devices) > 0 {\n\t\td, err := jsoniter.MarshalToString(devices)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"devices\", d)\n\t}\n\n\tif dnsservers := options.CommonBuildOpts.DNSServers; len(dnsservers) > 0 {\n\t\tc, err := jsoniter.MarshalToString(dnsservers)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"dnsservers\", c)\n\t}\n\tif dnsoptions := options.CommonBuildOpts.DNSOptions; len(dnsoptions) > 0 {\n\t\tc, err := jsoniter.MarshalToString(dnsoptions)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"dnsoptions\", c)\n\t}\n\tif dnssearch := options.CommonBuildOpts.DNSSearch; len(dnssearch) > 0 {\n\t\tc, err := jsoniter.MarshalToString(dnssearch)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"dnssearch\", c)\n\t}\n\n\tif caps := options.DropCapabilities; len(caps) > 0 {\n\t\tc, err := jsoniter.MarshalToString(caps)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"dropcaps\", c)\n\t}\n\n\tif options.ForceRmIntermediateCtrs {\n\t\tparams.Set(\"forcerm\", \"1\")\n\t}\n\tif options.RemoveIntermediateCtrs {\n\t\tparams.Set(\"rm\", \"1\")\n\t} else {\n\t\tparams.Set(\"rm\", \"0\")\n\t}\n\tif options.CommonBuildOpts.OmitHistory {\n\t\tparams.Set(\"omithistory\", \"1\")\n\t} else {\n\t\tparams.Set(\"omithistory\", \"0\")\n\t}\n\tif len(options.From) > 0 {\n\t\tparams.Set(\"from\", options.From)\n\t}\n\tif options.IgnoreUnrecognizedInstructions {\n\t\tparams.Set(\"ignore\", \"1\")\n\t}\n\tparams.Set(\"isolation\", strconv.Itoa(int(options.Isolation)))\n\tif options.CommonBuildOpts.HTTPProxy {\n\t\tparams.Set(\"httpproxy\", \"1\")\n\t}\n\tif options.Jobs != nil {\n\t\tparams.Set(\"jobs\", strconv.FormatUint(uint64(*options.Jobs), 10))\n\t}\n\tif labels := options.Labels; len(labels) > 0 {\n\t\tl, err := jsoniter.MarshalToString(labels)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"labels\", l)\n\t}\n\n\tif opt := options.CommonBuildOpts.LabelOpts; len(opt) > 0 {\n\t\to, err := jsoniter.MarshalToString(opt)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"labelopts\", o)\n\t}\n\n\tif len(options.CommonBuildOpts.SeccompProfilePath) > 0 {\n\t\tparams.Set(\"seccomp\", options.CommonBuildOpts.SeccompProfilePath)\n\t}\n\n\tif len(options.CommonBuildOpts.ApparmorProfile) > 0 {\n\t\tparams.Set(\"apparmor\", options.CommonBuildOpts.ApparmorProfile)\n\t}\n\n\tif options.Layers {\n\t\tparams.Set(\"layers\", \"1\")\n\t}\n\tif options.LogRusage {\n\t\tparams.Set(\"rusage\", \"1\")\n\t}\n\tif len(options.RusageLogFile) > 0 {\n\t\tparams.Set(\"rusagelogfile\", options.RusageLogFile)\n\t}\n\tif len(options.Manifest) > 0 {\n\t\tparams.Set(\"manifest\", options.Manifest)\n\t}\n\tif options.CacheFrom != nil {\n\t\tcacheFrom := []string{}\n\t\tfor _, cacheSrc := range options.CacheFrom {\n\t\t\tcacheFrom = append(cacheFrom, cacheSrc.String())\n\t\t}\n\t\tcacheFromJSON, err := jsoniter.MarshalToString(cacheFrom)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"cachefrom\", cacheFromJSON)\n\t}\n\n\tswitch options.SkipUnusedStages {\n\tcase types.OptionalBoolTrue:\n\t\tparams.Set(\"skipunusedstages\", \"1\")\n\tcase types.OptionalBoolFalse:\n\t\tparams.Set(\"skipunusedstages\", \"0\")\n\t}\n\n\tif options.CacheTo != nil {\n\t\tcacheTo := []string{}\n\t\tfor _, cacheSrc := range options.CacheTo {\n\t\t\tcacheTo = append(cacheTo, cacheSrc.String())\n\t\t}\n\t\tcacheToJSON, err := jsoniter.MarshalToString(cacheTo)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"cacheto\", cacheToJSON)\n\t}\n\tif int64(options.CacheTTL) != 0 {\n\t\tparams.Set(\"cachettl\", options.CacheTTL.String())\n\t}\n\tif memSwap := options.CommonBuildOpts.MemorySwap; memSwap > 0 {\n\t\tparams.Set(\"memswap\", strconv.Itoa(int(memSwap)))\n\t}\n\tif mem := options.CommonBuildOpts.Memory; mem > 0 {\n\t\tparams.Set(\"memory\", strconv.Itoa(int(mem)))\n\t}\n\tif options.NoCache {\n\t\tparams.Set(\"nocache\", \"1\")\n\t}\n\tif t := options.Output; len(t) > 0 {\n\t\tparams.Set(\"output\", t)\n\t}\n\tif t := options.OSVersion; len(t) > 0 {\n\t\tparams.Set(\"osversion\", t)\n\t}\n\tfor _, t := range options.OSFeatures {\n\t\tparams.Set(\"osfeature\", t)\n\t}\n\tvar platform string\n\tif len(options.OS) > 0 {\n\t\tplatform = options.OS\n\t}\n\tif len(options.Architecture) > 0 {\n\t\tif len(platform) == 0 {\n\t\t\tplatform = \"linux\"\n\t\t}\n\t\tplatform += \"/\" + options.Architecture\n\t} else if len(platform) > 0 {\n\t\tplatform += \"/\" + runtime.GOARCH\n\t}\n\tif len(platform) > 0 {\n\t\tparams.Set(\"platform\", platform)\n\t}\n\tif len(options.Platforms) > 0 {\n\t\tparams.Del(\"platform\")\n\t\tfor _, platformSpec := range options.Platforms {\n\t\t\tplatform = platformSpec.OS + \"/\" + platformSpec.Arch\n\t\t\tif platformSpec.Variant != \"\" {\n\t\t\t\tplatform += \"/\" + platformSpec.Variant\n\t\t\t}\n\t\t\tparams.Add(\"platform\", platform)\n\t\t}\n\t}\n\n\tfor _, volume := range options.CommonBuildOpts.Volumes {\n\t\tparams.Add(\"volume\", volume)\n\t}\n\n\tfor _, group := range options.GroupAdd {\n\t\tparams.Add(\"groupadd\", group)\n\t}\n\n\tvar err error\n\tvar contextDir string\n\tif contextDir, err = filepath.EvalSymlinks(options.ContextDirectory); err == nil {\n\t\toptions.ContextDirectory = contextDir\n\t}\n\n\tparams.Set(\"pullpolicy\", options.PullPolicy.String())\n\n\tswitch options.CommonBuildOpts.IdentityLabel {\n\tcase types.OptionalBoolTrue:\n\t\tparams.Set(\"identitylabel\", \"1\")\n\tcase types.OptionalBoolFalse:\n\t\tparams.Set(\"identitylabel\", \"0\")\n\t}\n\tif options.Quiet {\n\t\tparams.Set(\"q\", \"1\")\n\t}\n\tif options.RemoveIntermediateCtrs {\n\t\tparams.Set(\"rm\", \"1\")\n\t}\n\tif len(options.Target) > 0 {\n\t\tparams.Set(\"target\", options.Target)\n\t}\n\n\tif hosts := options.CommonBuildOpts.AddHost; len(hosts) > 0 {\n\t\th, err := jsoniter.MarshalToString(hosts)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"extrahosts\", h)\n\t}\n\tif nsoptions := options.NamespaceOptions; len(nsoptions) > 0 {\n\t\tns, err := jsoniter.MarshalToString(nsoptions)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"nsoptions\", ns)\n\t}\n\tif shmSize := options.CommonBuildOpts.ShmSize; len(shmSize) > 0 {\n\t\tshmBytes, err := units.RAMInBytes(shmSize)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"shmsize\", strconv.Itoa(int(shmBytes)))\n\t}\n\tif options.Squash {\n\t\tparams.Set(\"squash\", \"1\")\n\t}\n\n\tif options.Timestamp != nil {\n\t\tt := *options.Timestamp\n\t\tparams.Set(\"timestamp\", strconv.FormatInt(t.Unix(), 10))\n\t}\n\n\tif len(options.CommonBuildOpts.Ulimit) > 0 {\n\t\tulimitsJSON, err := json.Marshal(options.CommonBuildOpts.Ulimit)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"ulimits\", string(ulimitsJSON))\n\t}\n\n\tfor _, env := range options.Envs {\n\t\tparams.Add(\"setenv\", env)\n\t}\n\n\tfor _, uenv := range options.UnsetEnvs {\n\t\tparams.Add(\"unsetenv\", uenv)\n\t}\n\n\tvar (\n\t\theaders http.Header\n\t)\n\tif options.SystemContext != nil {\n\t\tif options.SystemContext.DockerAuthConfig != nil {\n\t\t\theaders, err = auth.MakeXRegistryAuthHeader(options.SystemContext, options.SystemContext.DockerAuthConfig.Username, options.SystemContext.DockerAuthConfig.Password)\n\t\t} else {\n\t\t\theaders, err = auth.MakeXRegistryConfigHeader(options.SystemContext, \"\", \"\")\n\t\t}\n\t\tif options.SystemContext.DockerInsecureSkipTLSVerify == types.OptionalBoolTrue {\n\t\t\tparams.Set(\"tlsVerify\", \"false\")\n\t\t}\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tstdout := io.Writer(os.Stdout)\n\tif options.Out != nil {\n\t\tstdout = options.Out\n\t}\n\n\texcludes := options.Excludes\n\tif len(excludes) == 0 {\n\t\texcludes, err = parseDockerignore(options.ContextDirectory)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tcontextDir, err = filepath.Abs(options.ContextDirectory)\n\tif err != nil {\n\t\tlogrus.Errorf(\"Cannot find absolute path of %v: %v\", options.ContextDirectory, err)\n\t\treturn nil, err\n\t}\n\n\ttarContent := []string{options.ContextDirectory}\n\tnewContainerFiles := []string{} // dockerfile paths, relative to context dir, ToSlash()ed\n\n\tdontexcludes := []string{\"!Dockerfile\", \"!Containerfile\", \"!.dockerignore\", \"!.containerignore\"}\n\tfor _, c := range containerFiles {\n\t\tif c == \"/dev/stdin\" {\n\t\t\tcontent, err := io.ReadAll(os.Stdin)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\ttmpFile, err := os.CreateTemp(\"\", \"build\")\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tdefer os.Remove(tmpFile.Name()) // clean up\n\t\t\tdefer tmpFile.Close()\n\t\t\tif _, err := tmpFile.Write(content); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tc = tmpFile.Name()\n\t\t}\n\t\tc = filepath.Clean(c)\n\t\tcfDir := filepath.Dir(c)\n\t\tif absDir, err := filepath.EvalSymlinks(cfDir); err == nil {\n\t\t\tname := filepath.ToSlash(strings.TrimPrefix(c, cfDir+string(filepath.Separator)))\n\t\t\tc = filepath.Join(absDir, name)\n\t\t}\n\n\t\tcontainerfile, err := filepath.Abs(c)\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"Cannot find absolute path of %v: %v\", c, err)\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// Check if Containerfile is in the context directory, if so truncate the context directory off path\n\t\t// Do NOT add to tarfile\n\t\tif strings.HasPrefix(containerfile, contextDir+string(filepath.Separator)) {\n\t\t\tcontainerfile = strings.TrimPrefix(containerfile, contextDir+string(filepath.Separator))\n\t\t\tdontexcludes = append(dontexcludes, \"!\"+containerfile)\n\t\t} else {\n\t\t\t// If Containerfile does not exist, assume it is in context directory and do Not add to tarfile\n\t\t\tif _, err := os.Lstat(containerfile); err != nil {\n\t\t\t\tif !os.IsNotExist(err) {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tcontainerfile = c\n\t\t\t} else {\n\t\t\t\t// If Containerfile does exist and not in the context directory, add it to the tarfile\n\t\t\t\ttarContent = append(tarContent, containerfile)\n\t\t\t}\n\t\t}\n\t\tnewContainerFiles = append(newContainerFiles, filepath.ToSlash(containerfile))\n\t}\n\tif len(newContainerFiles) > 0 {\n\t\tcFileJSON, err := json.Marshal(newContainerFiles)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Set(\"dockerfile\", string(cFileJSON))\n\t}\n\n\t// build secrets are usually absolute host path or relative to context dir on host\n\t// in any case move secret to current context and ship the tar.\n\tif secrets := options.CommonBuildOpts.Secrets; len(secrets) > 0 {\n\t\tsecretsForRemote := []string{}\n\n\t\tfor _, secret := range secrets {\n\t\t\tsecretOpt := strings.Split(secret, \",\")\n\t\t\tif len(secretOpt) > 0 {\n\t\t\t\tmodifiedOpt := []string{}\n\t\t\t\tfor _, token := range secretOpt {\n\t\t\t\t\tarr := strings.SplitN(token, \"=\", 2)\n\t\t\t\t\tif len(arr) > 1 {\n\t\t\t\t\t\tif arr[0] == \"src\" {\n\t\t\t\t\t\t\t// read specified secret into a tmp file\n\t\t\t\t\t\t\t// move tmp file to tar and change secret source to relative tmp file\n\t\t\t\t\t\t\ttmpSecretFile, err := os.CreateTemp(options.ContextDirectory, \"podman-build-secret\")\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdefer os.Remove(tmpSecretFile.Name()) // clean up\n\t\t\t\t\t\t\tdefer tmpSecretFile.Close()\n\t\t\t\t\t\t\tsrcSecretFile, err := os.Open(arr[1])\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdefer srcSecretFile.Close()\n\t\t\t\t\t\t\t_, err = io.Copy(tmpSecretFile, srcSecretFile)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// add tmp file to context dir\n\t\t\t\t\t\t\ttarContent = append(tarContent, tmpSecretFile.Name())\n\n\t\t\t\t\t\t\tmodifiedSrc := fmt.Sprintf(\"src=%s\", filepath.Base(tmpSecretFile.Name()))\n\t\t\t\t\t\t\tmodifiedOpt = append(modifiedOpt, modifiedSrc)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tmodifiedOpt = append(modifiedOpt, token)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tsecretsForRemote = append(secretsForRemote, strings.Join(modifiedOpt, \",\"))\n\t\t\t}\n\t\t}\n\n\t\tc, err := jsoniter.MarshalToString(secretsForRemote)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparams.Add(\"secrets\", c)\n\t}\n\n\ttarfile, err := nTar(append(excludes, dontexcludes...), tarContent...)\n\tif err != nil {\n\t\tlogrus.Errorf(\"Cannot tar container entries %v error: %v\", tarContent, err)\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := tarfile.Close(); err != nil {\n\t\t\tlogrus.Errorf(\"%v\\n\", err)\n\t\t}\n\t}()\n\n\tconn, err := bindings.GetClient(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresponse, err := conn.DoRequest(ctx, tarfile, http.MethodPost, \"/build\", params, headers)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer response.Body.Close()\n\n\tif !response.IsSuccess() {\n\t\treturn nil, response.Process(err)\n\t}\n\n\tbody := response.Body.(io.Reader)\n\tif logrus.IsLevelEnabled(logrus.DebugLevel) {\n\t\tif v, found := os.LookupEnv(\"PODMAN_RETAIN_BUILD_ARTIFACT\"); found {\n\t\t\tif keep, _ := strconv.ParseBool(v); keep {\n\t\t\t\tt, _ := os.CreateTemp(\"\", \"build_*_client\")\n\t\t\t\tdefer t.Close()\n\t\t\t\tbody = io.TeeReader(response.Body, t)\n\t\t\t}\n\t\t}\n\t}\n\n\tdec := json.NewDecoder(body)\n\n\tvar id string\n\tfor {\n\t\tvar s struct {\n\t\t\tStream string `json:\"stream,omitempty\"`\n\t\t\tError  string `json:\"error,omitempty\"`\n\t\t}\n\n\t\tselect {\n\t\t// FIXME(vrothberg): it seems we always hit the EOF case below,\n\t\t// even when the server quit but it seems desirable to\n\t\t// distinguish a proper build from a transient EOF.\n\t\tcase <-response.Request.Context().Done():\n\t\t\treturn &entities.BuildReport{ID: id}, nil\n\t\tdefault:\n\t\t\t// non-blocking select\n\t\t}\n\n\t\tif err := dec.Decode(&s); err != nil {\n\t\t\tif errors.Is(err, io.ErrUnexpectedEOF) {\n\t\t\t\treturn nil, fmt.Errorf(\"server probably quit: %w\", err)\n\t\t\t}\n\t\t\t// EOF means the stream is over in which case we need\n\t\t\t// to have read the id.\n\t\t\tif errors.Is(err, io.EOF) && id != \"\" {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn &entities.BuildReport{ID: id}, fmt.Errorf(\"decoding stream: %w\", err)\n\t\t}\n\n\t\tswitch {\n\t\tcase s.Stream != \"\":\n\t\t\traw := []byte(s.Stream)\n\t\t\tstdout.Write(raw)\n\t\t\tif iidRegex.Match(raw) {\n\t\t\t\tid = strings.TrimSuffix(s.Stream, \"\\n\")\n\t\t\t}\n\t\tcase s.Error != \"\":\n\t\t\t// If there's an error, return directly.  The stream\n\t\t\t// will be closed on return.\n\t\t\treturn &entities.BuildReport{ID: id}, errors.New(s.Error)\n\t\tdefault:\n\t\t\treturn &entities.BuildReport{ID: id}, errors.New(\"failed to parse build results stream, unexpected input\")\n\t\t}\n\t}\n\treturn &entities.BuildReport{ID: id}, nil\n}", "is_vulnerable": 1}
{"code": "func RunTestListWithoutPaging(ctx context.Context, t *testing.T, store storage.Interface) {\n\tdefer featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.RemainingItemCount, true)()\n\n\t_, preset, err := seedMultiLevelData(ctx, store)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tgetAttrs := func(obj runtime.Object) (labels.Set, fields.Set, error) {\n\t\tpod := obj.(*example.Pod)\n\t\treturn nil, fields.Set{\"metadata.name\": pod.Name}, nil\n\t}\n\n\ttests := []struct {\n\t\tname                       string\n\t\tdisablePaging              bool\n\t\trv                         string\n\t\trvMatch                    metav1.ResourceVersionMatch\n\t\tprefix                     string\n\t\tpred                       storage.SelectionPredicate\n\t\texpectedOut                []*example.Pod\n\t\texpectContinue             bool\n\t\texpectedRemainingItemCount *int64\n\t\texpectError                bool\n\t}{\n\t\t{\n\t\t\tname:          \"test List with limit when paging disabled\",\n\t\t\tdisablePaging: true,\n\t\t\tprefix:        \"/pods/second/\",\n\t\t\tpred: storage.SelectionPredicate{\n\t\t\t\tLabel: labels.Everything(),\n\t\t\t\tField: fields.Everything(),\n\t\t\t\tLimit: 1,\n\t\t\t},\n\t\t\texpectedOut:    []*example.Pod{preset[1], preset[2]},\n\t\t\texpectContinue: false,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif tt.pred.GetAttrs == nil {\n\t\t\t\ttt.pred.GetAttrs = getAttrs\n\t\t\t}\n\n\t\t\tout := &example.PodList{}\n\t\t\tstorageOpts := storage.ListOptions{\n\t\t\t\tResourceVersion:      tt.rv,\n\t\t\t\tResourceVersionMatch: tt.rvMatch,\n\t\t\t\tPredicate:            tt.pred,\n\t\t\t\tRecursive:            true,\n\t\t\t}\n\n\t\t\tif err := store.GetList(ctx, tt.prefix, storageOpts, out); err != nil {\n\t\t\t\tt.Fatalf(\"GetList failed: %v\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif (len(out.Continue) > 0) != tt.expectContinue {\n\t\t\t\tt.Errorf(\"unexpected continue token: %q\", out.Continue)\n\t\t\t}\n\n\t\t\tif len(tt.expectedOut) != len(out.Items) {\n\t\t\t\tt.Fatalf(\"length of list want=%d, got=%d\", len(tt.expectedOut), len(out.Items))\n\t\t\t}\n\t\t\tif diff := cmp.Diff(tt.expectedRemainingItemCount, out.ListMeta.GetRemainingItemCount()); diff != \"\" {\n\t\t\t\tt.Errorf(\"incorrect remainingItemCount: %s\", diff)\n\t\t\t}\n\t\t\tfor j, wantPod := range tt.expectedOut {\n\t\t\t\tgetPod := &out.Items[j]\n\t\t\t\tExpectNoDiff(t, fmt.Sprintf(\"%s: incorrect pod\", tt.name), wantPod, getPod)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewReconcileCommand(clientOpts *argocdclient.ClientOptions) *cobra.Command {\n\tvar (\n\t\tclientConfig         clientcmd.ClientConfig\n\t\tselector             string\n\t\trepoServerAddress    string\n\t\toutputFormat         string\n\t\trefresh              bool\n\t\tignoreNormalizerOpts normalizers.IgnoreNormalizerOpts\n\t)\n\n\tvar command = &cobra.Command{\n\t\tUse:   \"get-reconcile-results PATH\",\n\t\tShort: \"Reconcile all applications and stores reconciliation summary in the specified file.\",\n\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tctx := c.Context()\n\n\t\t\t// get rid of logging error handler\n\t\t\truntime.ErrorHandlers = runtime.ErrorHandlers[1:]\n\n\t\t\tif len(args) != 1 {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\toutputPath := args[0]\n\n\t\t\terrors.CheckError(os.Setenv(v1alpha1.EnvVarFakeInClusterConfig, \"true\"))\n\t\t\tcfg, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\n\t\t\tvar result []appReconcileResult\n\t\t\tif refresh {\n\t\t\t\tif repoServerAddress == \"\" {\n\t\t\t\t\tprintLine(\"Repo server is not provided, trying to port-forward to argocd-repo-server pod.\")\n\t\t\t\t\toverrides := clientcmd.ConfigOverrides{}\n\t\t\t\t\trepoServerPodLabelSelector := common.LabelKeyAppName + \"=\" + clientOpts.RepoServerName\n\t\t\t\t\trepoServerPort, err := kubeutil.PortForward(8081, namespace, &overrides, repoServerPodLabelSelector)\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\trepoServerAddress = fmt.Sprintf(\"localhost:%d\", repoServerPort)\n\t\t\t\t}\n\t\t\t\trepoServerClient := reposerverclient.NewRepoServerClientset(repoServerAddress, 60, reposerverclient.TLSConfiguration{DisableTLS: false, StrictValidation: false})\n\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tkubeClientset := kubernetes.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = reconcileApplications(ctx, kubeClientset, appClientset, namespace, repoServerClient, selector, newLiveStateCache, ignoreNormalizerOpts)\n\t\t\t\terrors.CheckError(err)\n\t\t\t} else {\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = getReconcileResults(ctx, appClientset, namespace, selector)\n\t\t\t}\n\n\t\t\terrors.CheckError(saveToFile(err, outputFormat, reconcileResults{Applications: result}, outputPath))\n\t\t},\n\t}\n\tclientConfig = cli.AddKubectlFlagsToCmd(command)\n\tcommand.Flags().StringVar(&repoServerAddress, \"repo-server\", \"\", \"Repo server address.\")\n\tcommand.Flags().StringVar(&selector, \"l\", \"\", \"Label selector\")\n\tcommand.Flags().StringVar(&outputFormat, \"o\", \"yaml\", \"Output format (yaml|json)\")\n\tcommand.Flags().BoolVar(&refresh, \"refresh\", false, \"If set to true then recalculates apps reconciliation\")\n\tcommand.Flags().DurationVar(&ignoreNormalizerOpts.JQExecutionTimeout, \"ignore-normalizer-jq-execution-timeout\", normalizers.DefaultJQExecutionTimeout, \"Set ignore normalizer JQ execution timeout\")\n\n\treturn command\n}", "is_vulnerable": 0}
{"code": "func generateManifestHash(un *unstructured.Unstructured, ignores []v1alpha1.ResourceIgnoreDifferences, overrides map[string]v1alpha1.ResourceOverride, opts normalizers.IgnoreNormalizerOpts) (string, error) {\n\tnormalizer, err := normalizers.NewIgnoreNormalizer(ignores, overrides, opts)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error creating normalizer: %w\", err)\n\t}\n\n\tresource := un.DeepCopy()\n\terr = normalizer.Normalize(resource)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error normalizing resource: %w\", err)\n\t}\n\n\tdata, err := resource.MarshalJSON()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error marshaling resource: %w\", err)\n\t}\n\thash := hash(data)\n\treturn hash, nil\n}", "is_vulnerable": 0}
{"code": "func (p *Policy) sanitize(r io.Reader, w io.Writer) error {\n\t// It is possible that the developer has created the policy via:\n\t//   p := bluemonday.Policy{}\n\t// rather than:\n\t//   p := bluemonday.NewPolicy()\n\t// If this is the case, and if they haven't yet triggered an action that\n\t// would initiliaze the maps, then we need to do that.\n\tp.init()\n\n\tbuff, ok := w.(stringWriterWriter)\n\tif !ok {\n\t\tbuff = &asStringWriter{w}\n\t}\n\n\tvar (\n\t\tskipElementContent       bool\n\t\tskippingElementsCount    int64\n\t\tskipClosingTag           bool\n\t\tclosingTagToSkipStack    []string\n\t\tmostRecentlyStartedToken string\n\t)\n\n\ttokenizer := html.NewTokenizer(r)\n\tfor {\n\t\tif tokenizer.Next() == html.ErrorToken {\n\t\t\terr := tokenizer.Err()\n\t\t\tif err == io.EOF {\n\t\t\t\t// End of input means end of processing\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Raw tokenizer error\n\t\t\treturn err\n\t\t}\n\n\t\ttoken := tokenizer.Token()\n\t\tswitch token.Type {\n\t\tcase html.DoctypeToken:\n\n\t\t\t// DocType is not handled as there is no safe parsing mechanism\n\t\t\t// provided by golang.org/x/net/html for the content, and this can\n\t\t\t// be misused to insert HTML tags that are not then sanitized\n\t\t\t//\n\t\t\t// One might wish to recursively sanitize here using the same policy\n\t\t\t// but I will need to do some further testing before considering\n\t\t\t// this.\n\n\t\tcase html.CommentToken:\n\n\t\t\t// Comments are ignored by default\n\t\t\tif p.allowComments {\n\t\t\t\t// But if allowed then write the comment out as-is\n\t\t\t\tbuff.WriteString(token.String())\n\t\t\t}\n\n\t\tcase html.StartTagToken:\n\n\t\t\tmostRecentlyStartedToken = normaliseElementName(token.Data)\n\n\t\t\tswitch normaliseElementName(token.Data) {\n\t\t\tcase `script`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\tcase `style`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\taps, ok := p.elsAndAttrs[token.Data]\n\t\t\tif !ok {\n\t\t\t\taa, matched := p.matchRegex(token.Data)\n\t\t\t\tif !matched {\n\t\t\t\t\tif _, ok := p.setOfElementsToSkipContent[token.Data]; ok {\n\t\t\t\t\t\tskipElementContent = true\n\t\t\t\t\t\tskippingElementsCount++\n\t\t\t\t\t}\n\t\t\t\t\tif p.addSpaces {\n\t\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\taps = aa\n\t\t\t}\n\t\t\tif len(token.Attr) != 0 {\n\t\t\t\ttoken.Attr = escapeAttributes(\n\t\t\t\t\tp.sanitizeAttrs(token.Data, token.Attr, aps),\n\t\t\t\t)\n\t\t\t}\n\n\t\t\tif len(token.Attr) == 0 {\n\t\t\t\tif !p.allowNoAttrs(token.Data) {\n\t\t\t\t\tskipClosingTag = true\n\t\t\t\t\tclosingTagToSkipStack = append(closingTagToSkipStack, token.Data)\n\t\t\t\t\tif p.addSpaces {\n\t\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !skipElementContent {\n\t\t\t\tif _, err := buff.WriteString(token.String()); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase html.EndTagToken:\n\n\t\t\tif mostRecentlyStartedToken == normaliseElementName(token.Data) {\n\t\t\t\tmostRecentlyStartedToken = \"\"\n\t\t\t}\n\n\t\t\tswitch normaliseElementName(token.Data) {\n\t\t\tcase `script`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\tcase `style`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif skipClosingTag && closingTagToSkipStack[len(closingTagToSkipStack)-1] == token.Data {\n\t\t\t\tclosingTagToSkipStack = closingTagToSkipStack[:len(closingTagToSkipStack)-1]\n\t\t\t\tif len(closingTagToSkipStack) == 0 {\n\t\t\t\t\tskipClosingTag = false\n\t\t\t\t}\n\t\t\t\tif p.addSpaces {\n\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif _, ok := p.elsAndAttrs[token.Data]; !ok {\n\t\t\t\tmatch := false\n\t\t\t\tfor regex := range p.elsMatchingAndAttrs {\n\t\t\t\t\tif regex.MatchString(token.Data) {\n\t\t\t\t\t\tskipElementContent = false\n\t\t\t\t\t\tmatch = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif _, ok := p.setOfElementsToSkipContent[token.Data]; ok && !match {\n\t\t\t\t\tskippingElementsCount--\n\t\t\t\t\tif skippingElementsCount == 0 {\n\t\t\t\t\t\tskipElementContent = false\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !match {\n\t\t\t\t\tif p.addSpaces {\n\t\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !skipElementContent {\n\t\t\t\tif _, err := buff.WriteString(token.String()); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase html.SelfClosingTagToken:\n\n\t\t\tswitch normaliseElementName(token.Data) {\n\t\t\tcase `script`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\tcase `style`:\n\t\t\t\tif !p.allowUnsafe {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\taps, ok := p.elsAndAttrs[token.Data]\n\t\t\tif !ok {\n\t\t\t\taa, matched := p.matchRegex(token.Data)\n\t\t\t\tif !matched {\n\t\t\t\t\tif p.addSpaces && !matched {\n\t\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\taps = aa\n\t\t\t}\n\n\t\t\tif len(token.Attr) != 0 {\n\t\t\t\ttoken.Attr = escapeAttributes(p.sanitizeAttrs(token.Data, token.Attr, aps))\n\t\t\t}\n\n\t\t\tif len(token.Attr) == 0 && !p.allowNoAttrs(token.Data) {\n\t\t\t\tif p.addSpaces {\n\t\t\t\t\tif _, err := buff.WriteString(\" \"); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !skipElementContent {\n\t\t\t\tif _, err := buff.WriteString(token.String()); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase html.TextToken:\n\n\t\t\tif !skipElementContent {\n\t\t\t\tswitch mostRecentlyStartedToken {\n\t\t\t\tcase `script`:\n\t\t\t\t\t// not encouraged, but if a policy allows JavaScript we\n\t\t\t\t\t// should not HTML escape it as that would break the output\n\t\t\t\t\t//\n\t\t\t\t\t// requires p.AllowUnsafe()\n\t\t\t\t\tif p.allowUnsafe {\n\t\t\t\t\t\tif _, err := buff.WriteString(token.Data); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase \"style\":\n\t\t\t\t\t// not encouraged, but if a policy allows CSS styles we\n\t\t\t\t\t// should not HTML escape it as that would break the output\n\t\t\t\t\t//\n\t\t\t\t\t// requires p.AllowUnsafe()\n\t\t\t\t\tif p.allowUnsafe {\n\t\t\t\t\t\tif _, err := buff.WriteString(token.Data); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t\t// HTML escape the text\n\t\t\t\t\tif _, err := buff.WriteString(token.String()); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\t// A token that didn't exist in the html package when we wrote this\n\t\t\treturn fmt.Errorf(\"unknown token: %v\", token)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (ns *nodeServer) patchNodeWithLabel(node *v1.Node, labelsToModify common.LabelsToModify) error {\n\tlabels := labelsToModify.GetLabels()\n\tlabelValuePair := map[string]interface{}{}\n\n\tfor _, labelToModify := range labels {\n\t\toperationType := labelToModify.GetOperationType()\n\t\tlabelToModifyKey := labelToModify.GetLabelKey()\n\t\tlabelToModifyValue := labelToModify.GetLabelValue()\n\n\t\tswitch operationType {\n\t\tcase common.AddLabel, common.UpdateLabel:\n\t\t\tlabelValuePair[labelToModifyKey] = labelToModifyValue\n\t\tcase common.DeleteLabel:\n\t\t\tlabelValuePair[labelToModifyKey] = nil\n\t\tdefault:\n\t\t\terr := fmt.Errorf(\"fail to update the label due to the wrong operation: %s\", operationType)\n\t\t\treturn err\n\t\t}\n\t}\n\n\tmetadata := map[string]interface{}{\n\t\t\"metadata\": map[string]interface{}{\n\t\t\t\"labels\": labelValuePair,\n\t\t},\n\t}\n\n\tpatchByteData, err := json.Marshal(metadata)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = ns.nodeAuthorizedClient.CoreV1().Nodes().Patch(context.TODO(), node.Name, types.StrategicMergePatchType, patchByteData, metav1.PatchOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestExpandQueryErrors(t *testing.T, datastore storage.OpenFGADatastore) {\n\ttests := []struct {\n\t\tname            string\n\t\ttypeDefinitions []*openfgapb.TypeDefinition\n\t\ttuples          []*openfgapb.TupleKey\n\t\trequest         *openfgapb.ExpandRequest\n\t\texpected        error\n\t}{\n\t\t{\n\t\t\tname: \"missing object\",\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tRelation: \"bar\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.InvalidExpandInput,\n\t\t},\n\t\t{\n\t\t\tname: \"missing object id and type\",\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \":\",\n\t\t\t\t\tRelation: \"bar\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.InvalidObjectFormat(&openfgapb.TupleKey{\n\t\t\t\tObject:   \":\",\n\t\t\t\tRelation: \"bar\",\n\t\t\t}),\n\t\t},\n\t\t{\n\t\t\tname: \"missing object id\",\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"github:\",\n\t\t\t\t\tRelation: \"bar\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.InvalidObjectFormat(&openfgapb.TupleKey{\n\t\t\t\tObject:   \"github:\",\n\t\t\t\tRelation: \"bar\",\n\t\t\t}),\n\t\t},\n\t\t{\n\t\t\tname: \"missing relation\",\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject: \"bar\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.InvalidExpandInput,\n\t\t},\n\t\t{\n\t\t\tname: \"type not found\",\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"foo:bar\",\n\t\t\t\t\tRelation: \"baz\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.TypeNotFound(\"foo\"),\n\t\t},\n\t\t{\n\t\t\tname: \"relation not found\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:bar\",\n\t\t\t\t\tRelation: \"baz\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: serverErrors.RelationNotFound(\"baz\", \"repo\", &openfgapb.TupleKey{\n\t\t\t\tObject:   \"repo:bar\",\n\t\t\t\tRelation: \"baz\",\n\t\t\t}),\n\t\t},\n\t\t{\n\t\t\tname: \"TupleToUserset involving wildcard returns error\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\"viewer\": typesystem.Union(\n\t\t\t\t\t\t\ttypesystem.This(), typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"*\"),\n\t\t\t\ttuple.NewTupleKey(\"document:X\", \"viewer\", \"jon\"),\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:1\", \"viewer\", \"\"),\n\t\t\t},\n\t\t\texpected: serverErrors.InvalidTuple(\n\t\t\t\t\"unexpected wildcard evaluated on relation 'document#parent'\",\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"*\"),\n\t\t\t),\n\t\t},\n\t}\n\n\trequire := require.New(t)\n\tctx := context.Background()\n\ttracer := telemetry.NewNoopTracer()\n\tlogger := logger.NewNoopLogger()\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tstore := testutils.CreateRandomString(20)\n\n\t\t\tmodelID, err := setUp(ctx, store, datastore, test.typeDefinitions, test.tuples)\n\t\t\trequire.NoError(err)\n\n\t\t\tquery := commands.NewExpandQuery(datastore, tracer, logger)\n\t\t\ttest.request.StoreId = store\n\t\t\ttest.request.AuthorizationModelId = modelID\n\n\t\t\t_, err = query.Execute(ctx, test.request)\n\t\t\trequire.ErrorIs(err, test.expected)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(name, func(t *testing.T) {\n\t\t\ta.Equal(\n\t\t\t\tg.match,\n\t\t\t\thostMatchesGlob(g.hostname, g.glob),\n\t\t\t)\n\t\t})", "is_vulnerable": 0}
{"code": "func (m *kubeGenericRuntimeManager) applyPlatformSpecificContainerConfig(config *runtimeapi.ContainerConfig, container *v1.Container, pod *v1.Pod, uid *int64, username string, nsTarget *kubecontainer.ContainerID) error {\n\tenforceMemoryQoS := false\n\t// Set memory.min and memory.high if MemoryQoS enabled with cgroups v2\n\tif utilfeature.DefaultFeatureGate.Enabled(kubefeatures.MemoryQoS) &&\n\t\tlibcontainercgroups.IsCgroup2UnifiedMode() {\n\t\tenforceMemoryQoS = true\n\t}\n\tconfig.Linux = m.generateLinuxContainerConfig(container, pod, uid, username, nsTarget, enforceMemoryQoS)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func NewSortParameter(sort *admin.Sort, allowed sets.String) (SortParameter, error) {\n\tif sort == nil {\n\t\treturn nil, nil\n\t}\n\n\tkey := sort.Key\n\tif !allowed.Has(key) {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid sort key '%s'\", key)\n\t}\n\n\tvar gormOrderExpression string\n\tswitch sort.Direction {\n\tcase admin.Sort_DESCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormDescending, key)\n\tcase admin.Sort_ASCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormAscending, key)\n\tdefault:\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid sort order specified: %v\", sort)\n\t}\n\treturn &sortParamImpl{\n\t\tgormOrderExpression: gormOrderExpression,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (c *EncryptionClient) getClientOptions() EncryptionClientOptions {\n\treturn EncryptionClientOptions{\n\t\tS3Client:             c.S3Client,\n\t\tContentCipherBuilder: c.ContentCipherBuilder,\n\t\tSaveStrategy:         c.SaveStrategy,\n\t\tTempFolderPath:       c.TempFolderPath,\n\t\tMinFileSize:          c.MinFileSize,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (con adminSystemController) View(c *gin.Context) {\n\n\tvar (\n\t\terr       error\n\t\tstartLine int\n\t\tendLine   int\n\t\tscanner   *bufio.Scanner\n\t\tline      int\n\t)\n\n\tstartLine, err = strconv.Atoi(c.DefaultQuery(\"start_line\", \"1\"))\n\tif err != nil {\n\t\tcon.ErrorHtml(c, err)\n\t\treturn\n\t}\n\tendLine, err = strconv.Atoi(c.DefaultQuery(\"end_line\", \"20\"))\n\tif err != nil {\n\t\tcon.ErrorHtml(c, err)\n\t\treturn\n\t}\n\n\tvar filecontents []string\n\tfilePath := gstrings.JoinStr(configs.RootPath, c.Query(\"path\"))\n\tfi, err := os.Open(filePath)\n\tif err != nil {\n\t\tcon.ErrorHtml(c, err)\n\t\treturn\n\t}\n\tdefer fi.Close()\n\n\tscanner = bufio.NewScanner(fi)\n\tfor scanner.Scan() {\n\t\tline++\n\t\tif line >= startLine && line <= endLine {\n\t\t\t// \u5728\u8981\u6c42\u884c\u6570\u5185\u53d6\u5f97\u6570\u636e\n\t\t\tfilecontents = append(filecontents, scanner.Text())\n\t\t} else {\n\t\t\tcontinue\n\t\t}\n\t}\n\n\tc.HTML(http.StatusOK, \"setting/systemlog_view.html\", gin.H{\n\t\t\"file_path\":    c.Query(\"path\"),\n\t\t\"filecontents\": filecontents,\n\t\t\"start_line\":   startLine,\n\t\t\"end_line\":     endLine,\n\t\t\"line\":         line,\n\t})\n\n}", "is_vulnerable": 1}
{"code": "func New(ds model.DataStore, broker events.Broker) *Server {\n\ts := &Server{ds: ds, broker: broker}\n\tauth.Init(s.ds)\n\tinitialSetup(ds)\n\ts.initRoutes()\n\ts.mountAuthenticationRoutes()\n\ts.mountRootRedirector()\n\tcheckFfmpegInstallation()\n\tcheckExternalCredentials()\n\treturn s\n}", "is_vulnerable": 1}
{"code": "func (a *ClientApp) HandleLogin(w http.ResponseWriter, r *http.Request) {\n\toidcConf, err := a.provider.ParseConfig()\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tscopes := make([]string, 0)\n\tvar opts []oauth2.AuthCodeOption\n\tif config := a.settings.OIDCConfig(); config != nil {\n\t\tscopes = config.RequestedScopes\n\t\topts = AppendClaimsAuthenticationRequestParameter(opts, config.RequestedIDTokenClaims)\n\t}\n\toauth2Config, err := a.oauth2Config(GetScopesOrDefault(scopes))\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\treturnURL := r.FormValue(\"return_url\")\n\t// Check if return_url is valid, otherwise abort processing (see https://github.com/argoproj/argo-cd/pull/4780)\n\tif !isValidRedirectURL(returnURL, []string{a.settings.URL}) {\n\t\thttp.Error(w, \"Invalid redirect URL: the protocol and host (including port) must match and the path must be within allowed URLs if provided\", http.StatusBadRequest)\n\t\treturn\n\t}\n\tstateNonce, err := a.generateAppState(returnURL, w)\n\tif err != nil {\n\t\tlog.Errorf(\"Failed to initiate login flow: %v\", err)\n\t\thttp.Error(w, \"Failed to initiate login flow\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tgrantType := InferGrantType(oidcConf)\n\tvar url string\n\tswitch grantType {\n\tcase GrantTypeAuthorizationCode:\n\t\turl = oauth2Config.AuthCodeURL(stateNonce, opts...)\n\tcase GrantTypeImplicit:\n\t\turl, err = ImplicitFlowURL(oauth2Config, stateNonce, opts...)\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Failed to initiate implicit login flow: %v\", err)\n\t\t\thttp.Error(w, \"Failed to initiate implicit login flow\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\thttp.Error(w, fmt.Sprintf(\"Unsupported grant type: %v\", grantType), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tlog.Infof(\"Performing %s flow login: %s\", grantType, url)\n\thttp.Redirect(w, r, url, http.StatusSeeOther)\n}", "is_vulnerable": 0}
{"code": "func (k *skEd25519PublicKey) Verify(data []byte, sig *Signature) error {\n\tif sig.Format != k.Type() {\n\t\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\n\t}\n\tif l := len(k.PublicKey); l != ed25519.PublicKeySize {\n\t\treturn fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\n\t}\n\n\th := sha256.New()\n\th.Write([]byte(k.application))\n\tappDigest := h.Sum(nil)\n\n\th.Reset()\n\th.Write(data)\n\tdataDigest := h.Sum(nil)\n\n\tvar edSig struct {\n\t\tSignature []byte `ssh:\"rest\"`\n\t}\n\n\tif err := Unmarshal(sig.Blob, &edSig); err != nil {\n\t\treturn err\n\t}\n\n\tvar skf skFields\n\tif err := Unmarshal(sig.Rest, &skf); err != nil {\n\t\treturn err\n\t}\n\n\tblob := struct {\n\t\tApplicationDigest []byte `ssh:\"rest\"`\n\t\tFlags             byte\n\t\tCounter           uint32\n\t\tMessageDigest     []byte `ssh:\"rest\"`\n\t}{\n\t\tappDigest,\n\t\tskf.Flags,\n\t\tskf.Counter,\n\t\tdataDigest,\n\t}\n\n\toriginal := Marshal(blob)\n\n\tif ok := ed25519.Verify(k.PublicKey, original, edSig.Signature); !ok {\n\t\treturn errors.New(\"ssh: signature did not verify\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func buildFreshState(ctx context.Context, kubeCluster *Cluster, newState *FullState) error {\n\trkeConfig := &kubeCluster.RancherKubernetesEngineConfig\n\t// Get the certificate Bundle\n\tcertBundle, err := pki.GenerateRKECerts(ctx, *rkeConfig, \"\", \"\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to generate certificate bundle: %v\", err)\n\t}\n\tnewState.DesiredState.CertificatesBundle = certBundle\n\tif isEncryptionEnabled(rkeConfig) {\n\t\tif newState.DesiredState.EncryptionConfig, err = kubeCluster.getEncryptionProviderFile(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"Plugin with routes\", func(t *testing.T) {\n\t\troutes := []*plugins.Route{\n\t\t\t{\n\t\t\t\tPath:    \"api/v4/\",\n\t\t\t\tURL:     \"https://www.google.com\",\n\t\t\t\tReqRole: org.RoleEditor,\n\t\t\t\tHeaders: []plugins.Header{\n\t\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath:    \"api/admin\",\n\t\t\t\tURL:     \"https://www.google.com\",\n\t\t\t\tReqRole: org.RoleAdmin,\n\t\t\t\tHeaders: []plugins.Header{\n\t\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath: \"api/anon\",\n\t\t\t\tURL:  \"https://www.google.com\",\n\t\t\t\tHeaders: []plugins.Header{\n\t\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath: \"api/common\",\n\t\t\t\tURL:  \"{{.JsonData.dynamicUrl}}\",\n\t\t\t\tURLParams: []plugins.URLParam{\n\t\t\t\t\t{Name: \"{{.JsonData.queryParam}}\", Content: \"{{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t\tHeaders: []plugins.Header{\n\t\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath:    \"api/restricted\",\n\t\t\t\tReqRole: org.RoleAdmin,\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath: \"api/body\",\n\t\t\t\tURL:  \"http://www.test.com\",\n\t\t\t\tBody: []byte(`{ \"url\": \"{{.JsonData.dynamicUrl}}\", \"secret\": \"{{.SecureJsonData.key}}\"\t}`),\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath: \"mypath\",\n\t\t\t\tURL:  \"https://example.com/api/v1/\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath:      \"api/rbac-home\",\n\t\t\t\tReqAction: \"datasources:read\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tPath:      \"api/rbac-restricted\",\n\t\t\t\tReqAction: \"test-app.settings:read\",\n\t\t\t},\n\t\t}\n\n\t\tds := &datasources.DataSource{\n\t\t\tUID: \"dsUID\",\n\t\t\tJsonData: simplejson.NewFromAny(map[string]any{\n\t\t\t\t\"clientId\":   \"asd\",\n\t\t\t\t\"dynamicUrl\": \"https://dynamic.grafana.com\",\n\t\t\t\t\"queryParam\": \"apiKey\",\n\t\t\t}),\n\t\t}\n\n\t\tjd, err := ds.JsonData.Map()\n\t\trequire.NoError(t, err)\n\t\tdsInfo := DSInfo{\n\t\t\tID:       ds.ID,\n\t\t\tUpdated:  ds.Updated,\n\t\t\tJSONData: jd,\n\t\t\tDecryptedSecureJSONData: map[string]string{\n\t\t\t\t\"key\": \"123\",\n\t\t\t},\n\t\t}\n\n\t\tsetUp := func() (*contextmodel.ReqContext, *http.Request) {\n\t\t\treq, err := http.NewRequest(\"GET\", \"http://localhost/asd\", nil)\n\t\t\trequire.NoError(t, err)\n\t\t\tctx := &contextmodel.ReqContext{\n\t\t\t\tContext:      &web.Context{Req: req},\n\t\t\t\tSignedInUser: &user.SignedInUser{OrgRole: org.RoleEditor},\n\t\t\t}\n\t\t\treturn ctx, req\n\t\t}\n\n\t\tt.Run(\"When matching route path\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/v4/some/method\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = routes[0]\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tassert.Equal(t, \"https://www.google.com/some/method\", req.URL.String())\n\t\t\tassert.Equal(t, \"my secret 123\", req.Header.Get(\"x-header\"))\n\t\t})\n\n\t\tt.Run(\"When matching route path and has dynamic url\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/common/some/method\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = routes[3]\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tassert.Equal(t, \"https://dynamic.grafana.com/some/method?apiKey=123\", req.URL.String())\n\t\t\tassert.Equal(t, \"my secret 123\", req.Header.Get(\"x-header\"))\n\t\t})\n\n\t\tt.Run(\"When matching route path with no url\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = routes[4]\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tassert.Equal(t, \"http://localhost/asd\", req.URL.String())\n\t\t})\n\n\t\tt.Run(\"When matching route path and has setting url\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/common/some/method\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = &plugins.Route{\n\t\t\t\tPath: \"api/common\",\n\t\t\t\tURL:  \"{{.URL}}\",\n\t\t\t\tHeaders: []plugins.Header{\n\t\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t\tURLParams: []plugins.URLParam{\n\t\t\t\t\t{Name: \"{{.JsonData.queryParam}}\", Content: \"{{.SecureJsonData.key}}\"},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tdsInfo := DSInfo{\n\t\t\t\tID:       ds.ID,\n\t\t\t\tUpdated:  ds.Updated,\n\t\t\t\tJSONData: jd,\n\t\t\t\tDecryptedSecureJSONData: map[string]string{\n\t\t\t\t\t\"key\": \"123\",\n\t\t\t\t},\n\t\t\t\tURL: \"https://dynamic.grafana.com\",\n\t\t\t}\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tassert.Equal(t, \"https://dynamic.grafana.com/some/method?apiKey=123\", req.URL.String())\n\t\t\tassert.Equal(t, \"my secret 123\", req.Header.Get(\"x-header\"))\n\t\t})\n\n\t\tt.Run(\"When matching route path and has dynamic body\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/body\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = routes[5]\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tcontent, err := io.ReadAll(req.Body)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Equal(t, `{ \"url\": \"https://dynamic.grafana.com\", \"secret\": \"123\"\t}`, string(content))\n\t\t})\n\n\t\tt.Run(\"When matching route path ending with a slash\", func(t *testing.T) {\n\t\t\tctx, req := setUp()\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"mypath/some-route/\")\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.matchedRoute = routes[6]\n\t\t\tApplyRoute(proxy.ctx.Req.Context(), req, proxy.proxyPath, proxy.matchedRoute, dsInfo, proxy.cfg)\n\n\t\t\tassert.Equal(t, \"https://example.com/api/v1/some-route/\", req.URL.String())\n\t\t})\n\n\t\tt.Run(\"Validating request\", func(t *testing.T) {\n\t\t\tt.Run(\"plugin route with valid role\", func(t *testing.T) {\n\t\t\t\tctx, _ := setUp()\n\t\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/v4/some/method\")\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\terr = proxy.validateRequest()\n\t\t\t\trequire.NoError(t, err)\n\t\t\t})\n\n\t\t\tt.Run(\"plugin route with admin role and user is editor\", func(t *testing.T) {\n\t\t\t\tctx, _ := setUp()\n\t\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/admin\")\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\terr = proxy.validateRequest()\n\t\t\t\trequire.Error(t, err)\n\t\t\t})\n\n\t\t\tt.Run(\"plugin route with admin role and user is admin\", func(t *testing.T) {\n\t\t\t\tctx, _ := setUp()\n\t\t\t\tctx.SignedInUser.OrgRole = org.RoleAdmin\n\t\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/admin\")\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\terr = proxy.validateRequest()\n\t\t\t\trequire.NoError(t, err)\n\t\t\t})\n\t\t})\n\n\t\tt.Run(\"plugin route with RBAC protection user is allowed\", func(t *testing.T) {\n\t\t\tctx, _ := setUp()\n\t\t\tctx.SignedInUser.OrgID = int64(1)\n\t\t\tctx.SignedInUser.OrgRole = org.RoleNone\n\t\t\tctx.SignedInUser.Permissions = map[int64]map[string][]string{1: {\"test-app.settings:read\": nil}}\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/rbac-restricted\")\n\t\t\trequire.NoError(t, err)\n\t\t\terr = proxy.validateRequest()\n\t\t\trequire.NoError(t, err)\n\t\t})\n\n\t\tt.Run(\"plugin route with RBAC protection user is not allowed\", func(t *testing.T) {\n\t\t\tctx, _ := setUp()\n\t\t\tctx.SignedInUser.OrgID = int64(1)\n\t\t\tctx.SignedInUser.OrgRole = org.RoleNone\n\t\t\tctx.SignedInUser.Permissions = map[int64]map[string][]string{1: {\"test-app:read\": nil}}\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/rbac-restricted\")\n\t\t\trequire.NoError(t, err)\n\t\t\terr = proxy.validateRequest()\n\t\t\trequire.Error(t, err)\n\t\t})\n\n\t\tt.Run(\"plugin route with dynamic RBAC protection user is allowed\", func(t *testing.T) {\n\t\t\tctx, _ := setUp()\n\t\t\tctx.SignedInUser.OrgID = int64(1)\n\t\t\tctx.SignedInUser.OrgRole = org.RoleNone\n\t\t\tctx.SignedInUser.Permissions = map[int64]map[string][]string{1: {\"datasources:read\": {\"datasources:uid:dsUID\"}}}\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/rbac-home\")\n\t\t\trequire.NoError(t, err)\n\t\t\terr = proxy.validateRequest()\n\t\t\trequire.NoError(t, err)\n\t\t})\n\n\t\tt.Run(\"plugin route with dynamic RBAC protection user is not allowed\", func(t *testing.T) {\n\t\t\tctx, _ := setUp()\n\t\t\tctx.SignedInUser.OrgID = int64(1)\n\t\t\tctx.SignedInUser.OrgRole = org.RoleNone\n\t\t\t// Has access but to another app\n\t\t\tctx.SignedInUser.Permissions = map[int64]map[string][]string{1: {\"datasources:read\": {\"datasources:uid:notTheDsUID\"}}}\n\t\t\tproxy, err := setupDSProxyTest(t, ctx, ds, routes, \"api/rbac-home\")\n\t\t\trequire.NoError(t, err)\n\t\t\terr = proxy.validateRequest()\n\t\t\trequire.Error(t, err)\n\t\t})\n\t})", "is_vulnerable": 0}
{"code": "func ElementsMatch(t TestingT, listA interface{}, listB interface{}, msgAndArgs ...interface{}) {\n\tif assert.ElementsMatch(t, listA, listB, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "\treturn func(ctx context.Context, client oci.Client, _ *containers.Container, s *runtimespec.Spec) (err error) {\n\t\tif mountLabel == \"\" {\n\t\t\treturn nil\n\t\t}\n\t\tfor _, m := range s.Mounts {\n\t\t\tswitch m.Destination {\n\t\t\tcase etcHosts, etcHostname, resolvConfPath:\n\t\t\t\tif err := label.Relabel(m.Source, mountLabel, false); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}", "is_vulnerable": 1}
{"code": "func (suite *KeeperTestSuite) TestGovClawbackNoOps() {\n\tsuite.SetupTest()\n\n\taddr := sdk.AccAddress(suite.address.Bytes())\n\taddr2 := sdk.AccAddress(testutiltx.GenerateAddress().Bytes())\n\n\t// disable the address\n\tsuite.app.VestingKeeper.SetGovClawbackDisabled(suite.ctx, addr)\n\n\t// a duplicate entry should not panic but no-op\n\tsuite.app.VestingKeeper.SetGovClawbackDisabled(suite.ctx, addr)\n\n\t// check that the address is disabled\n\tdisabled := suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr)\n\tsuite.Require().True(disabled, \"expected address to be found in store\")\n\n\t// check that address 2 is not disabled\n\tdisabled = suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr2)\n\tsuite.Require().False(disabled, \"expected address not to be found in store\")\n\n\t// deleting a non-existent entry should not panic but no-op\n\tsuite.app.VestingKeeper.DeleteGovClawbackDisabled(suite.ctx, addr2)\n\n\t// check that the address is still not disabled\n\tdisabled = suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr2)\n\tsuite.Require().False(disabled, \"expected address not to be found in store\")\n}", "is_vulnerable": 1}
{"code": "func sanitizeExtractPath(filePath string, destination string) error {\n\t// to avoid zip slip (writing outside of the destination), we resolve\n\t// the target path, and make sure it's nested in the intended\n\t// destination, or bail otherwise.\n\tdestpath := filepath.Join(destination, filePath)\n\tif !strings.HasPrefix(destpath, destination) {\n\t\treturn fmt.Errorf(\"%s: illegal file path\", filePath)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestPluginProxy(t *testing.T) {\n\tsetting.SecretKey = \"password\"\n\tsecretsService := secretsManager.SetupTestService(t, fakes.NewFakeSecretsStore())\n\n\tt.Run(\"When getting proxy headers\", func(t *testing.T) {\n\t\troute := &plugins.Route{\n\t\t\tHeaders: []plugins.Header{\n\t\t\t\t{Name: \"x-header\", Content: \"my secret {{.SecureJsonData.key}}\"},\n\t\t\t},\n\t\t}\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tkey, _ := secretsService.Encrypt(context.Background(), []byte(\"123\"), secrets.WithoutScope())\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{\n\t\t\tSecureJsonData: map[string][]byte{\n\t\t\t\t\"key\": key,\n\t\t\t},\n\t\t}\n\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\troute,\n\t\t\tstore,\n\t\t)\n\n\t\tassert.Equal(t, \"my secret 123\", req.Header.Get(\"x-header\"))\n\t})\n\n\tt.Run(\"When SendUserHeader config is enabled\", func(t *testing.T) {\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{}\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\tnil,\n\t\t\tstore,\n\t\t)\n\n\t\t// Get will return empty string even if header is not set\n\t\tassert.Equal(t, \"test_user\", req.Header.Get(\"X-Grafana-User\"))\n\t})\n\n\tt.Run(\"When SendUserHeader config is disabled\", func(t *testing.T) {\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{}\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: false},\n\t\t\tnil,\n\t\t\tstore,\n\t\t)\n\t\t// Get will return empty string even if header is not set\n\t\tassert.Equal(t, \"\", req.Header.Get(\"X-Grafana-User\"))\n\t})\n\n\tt.Run(\"When SendUserHeader config is enabled but user is anonymous\", func(t *testing.T) {\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{}\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{IsAnonymous: true},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\tnil,\n\t\t\tstore,\n\t\t)\n\n\t\t// Get will return empty string even if header is not set\n\t\tassert.Equal(t, \"\", req.Header.Get(\"X-Grafana-User\"))\n\t})\n\n\tt.Run(\"When getting templated url\", func(t *testing.T) {\n\t\troute := &plugins.Route{\n\t\t\tURL:    \"{{.JsonData.dynamicUrl}}\",\n\t\t\tMethod: \"GET\",\n\t\t}\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{\n\t\t\tJsonData: map[string]interface{}{\n\t\t\t\t\"dynamicUrl\": \"https://dynamic.grafana.com\",\n\t\t\t},\n\t\t}\n\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\troute,\n\t\t\tstore,\n\t\t)\n\t\tassert.Equal(t, \"https://dynamic.grafana.com\", req.URL.String())\n\t\tassert.Equal(t, \"{{.JsonData.dynamicUrl}}\", route.URL)\n\t})\n\n\tt.Run(\"When getting complex templated url\", func(t *testing.T) {\n\t\troute := &plugins.Route{\n\t\t\tURL:    \"{{if .JsonData.apiHost}}{{.JsonData.apiHost}}{{else}}https://example.com{{end}}\",\n\t\t\tMethod: \"GET\",\n\t\t}\n\t\tstore := mockstore.NewSQLStoreMock()\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{}\n\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\troute,\n\t\t\tstore,\n\t\t)\n\t\tassert.Equal(t, \"https://example.com\", req.URL.String())\n\t})\n\n\tt.Run(\"When getting templated body\", func(t *testing.T) {\n\t\troute := &plugins.Route{\n\t\t\tPath: \"api/body\",\n\t\t\tURL:  \"http://www.test.com\",\n\t\t\tBody: []byte(`{ \"url\": \"{{.JsonData.dynamicUrl}}\", \"secret\": \"{{.SecureJsonData.key}}\"\t}`),\n\t\t}\n\n\t\tstore := mockstore.NewSQLStoreMock()\n\n\t\tencryptedJsonData, _ := secretsService.EncryptJsonData(\n\t\t\tcontext.Background(),\n\t\t\tmap[string]string{\"key\": \"123\"},\n\t\t\tsecrets.WithoutScope(),\n\t\t)\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{\n\t\t\tJsonData:       map[string]interface{}{\"dynamicUrl\": \"https://dynamic.grafana.com\"},\n\t\t\tSecureJsonData: encryptedJsonData,\n\t\t}\n\n\t\thttpReq, err := http.NewRequest(http.MethodGet, \"\", nil)\n\t\trequire.NoError(t, err)\n\n\t\treq := getPluginProxiedRequest(\n\t\t\tt,\n\t\t\tsecretsService,\n\t\t\t&models.ReqContext{\n\t\t\t\tSignedInUser: &models.SignedInUser{\n\t\t\t\t\tLogin: \"test_user\",\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq: httpReq,\n\t\t\t\t},\n\t\t\t},\n\t\t\t&setting.Cfg{SendUserHeader: true},\n\t\t\troute,\n\t\t\tstore,\n\t\t)\n\t\tcontent, err := ioutil.ReadAll(req.Body)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, `{ \"url\": \"https://dynamic.grafana.com\", \"secret\": \"123\"\t}`, string(content))\n\t})\n\n\tt.Run(\"When proxying a request should set expected response headers\", func(t *testing.T) {\n\t\trequestHandled := false\n\t\tbackendServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.WriteHeader(200)\n\t\t\t_, _ = w.Write([]byte(\"I am the backend\"))\n\t\t\trequestHandled = true\n\t\t}))\n\t\tt.Cleanup(backendServer.Close)\n\n\t\tresponseWriter := web.NewResponseWriter(\"GET\", httptest.NewRecorder())\n\n\t\troute := &plugins.Route{\n\t\t\tPath: \"/\",\n\t\t\tURL:  backendServer.URL,\n\t\t}\n\n\t\tctx := &models.ReqContext{\n\t\t\tSignedInUser: &models.SignedInUser{},\n\t\t\tContext: &web.Context{\n\t\t\t\tReq:  httptest.NewRequest(\"GET\", \"/\", nil),\n\t\t\t\tResp: responseWriter,\n\t\t\t},\n\t\t}\n\t\tstore := mockstore.NewSQLStoreMock()\n\n\t\tstore.ExpectedPluginSetting = &models.PluginSetting{\n\t\t\tSecureJsonData: map[string][]byte{},\n\t\t}\n\t\tproxy := NewApiPluginProxy(ctx, \"\", route, \"\", &setting.Cfg{}, store, secretsService)\n\t\tproxy.ServeHTTP(ctx.Resp, ctx.Req)\n\n\t\tfor {\n\t\t\tif requestHandled {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\trequire.Equal(t, \"sandbox\", ctx.Resp.Header().Get(\"Content-Security-Policy\"))\n\t})\n}", "is_vulnerable": 0}
{"code": "func (g *HTTPGetter) get(href string) (*bytes.Buffer, error) {\n\tbuf := bytes.NewBuffer(nil)\n\n\t// Set a helm specific user agent so that a repo server and metrics can\n\t// separate helm calls from other tools interacting with repos.\n\treq, err := http.NewRequest(\"GET\", href, nil)\n\tif err != nil {\n\t\treturn buf, err\n\t}\n\n\treq.Header.Set(\"User-Agent\", version.GetUserAgent())\n\tif g.opts.userAgent != \"\" {\n\t\treq.Header.Set(\"User-Agent\", g.opts.userAgent)\n\t}\n\n\tif g.opts.username != \"\" && g.opts.password != \"\" {\n\t\treq.SetBasicAuth(g.opts.username, g.opts.password)\n\t}\n\n\tclient, err := g.httpClient()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn buf, err\n\t}\n\tif resp.StatusCode != 200 {\n\t\treturn buf, errors.Errorf(\"failed to fetch %s : %s\", href, resp.Status)\n\t}\n\n\t_, err = io.Copy(buf, resp.Body)\n\tresp.Body.Close()\n\treturn buf, err\n}", "is_vulnerable": 1}
{"code": "func NewAppModule(\n\tcdc codec.Codec,\n\tk *keeper.Keeper,\n\tak types.AccountKeeper,\n\tbk types.BankKeeper,\n\tls exported.Subspace,\n) AppModule {\n\tam := staking.NewAppModule(cdc, k.Keeper, ak, bk, ls)\n\treturn AppModule{\n\t\tAppModule: &am,\n\t\tkeeper:    k,\n\t}\n}", "is_vulnerable": 0}
{"code": "func pipe2(p *[2]_C_int, flags int) (err error) {\n\t_, _, e1 := RawSyscall(SYS_PIPE2, uintptr(unsafe.Pointer(p)), uintptr(flags), 0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func NewOperatorClusterRole() *rbacv1.ClusterRole {\n\t// These are permissions needed by the operator itself.\n\t// For successfully deploying KubeVirt with the operator, you need to add everything\n\t// that the KubeVirt components' rules use, see below\n\t// (you can't create rules with permissions you don't have yourself)\n\toperatorRole := &rbacv1.ClusterRole{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"ClusterRole\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: components.OperatorServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRules: []rbacv1.PolicyRule{\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"kubevirts\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"update\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"serviceaccounts\",\n\t\t\t\t\t\"services\",\n\t\t\t\t\t\"endpoints\",\n\t\t\t\t\t// pods/exec is required for testing upgrades - that can be removed when we stop\n\t\t\t\t\t// supporting upgrades from versions in which virt-api required pods/exec privileges\n\t\t\t\t\t\"pods/exec\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"update\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"configmaps\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"batch\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"jobs\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apps\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"controllerrevisions\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apps\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"deployments\",\n\t\t\t\t\t\"daemonsets\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tVersionName,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"clusterroles\",\n\t\t\t\t\t\"clusterrolebindings\",\n\t\t\t\t\t\"roles\",\n\t\t\t\t\t\"rolebindings\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"update\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apiextensions.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"customresourcedefinitions\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tGroupNameSecurity,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"securitycontextconstraints\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tGroupNameSecurity,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"securitycontextconstraints\",\n\t\t\t\t},\n\t\t\t\tResourceNames: []string{\n\t\t\t\t\t\"privileged\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"update\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tGroupNameSecurity,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"securitycontextconstraints\",\n\t\t\t\t},\n\t\t\t\tResourceNames: []string{\n\t\t\t\t\t\"kubevirt-handler\",\n\t\t\t\t\t\"kubevirt-controller\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"update\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"admissionregistration.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"validatingwebhookconfigurations\",\n\t\t\t\t\t\"mutatingwebhookconfigurations\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"create\", \"delete\", \"update\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apiregistration.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"apiservices\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"create\", \"delete\", \"update\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"monitoring.coreos.com\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"servicemonitors\",\n\t\t\t\t\t\"prometheusrules\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"create\", \"delete\", \"update\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"namespaces\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t// FIXME - Keep the flavor (now renamed instancetype) permissions around until v0.56 to allow the operator to update from v0.54.\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"flavor.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"virtualmachineflavors\",\n\t\t\t\t\t\"virtualmachineclusterflavors\",\n\t\t\t\t\t\"virtualmachinepreferences\",\n\t\t\t\t\t\"virtualmachineclusterpreferences\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"delete\", \"create\", \"update\", \"patch\", \"list\", \"watch\", \"deletecollection\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// now append all rules needed by KubeVirt's components\n\toperatorRole.Rules = append(operatorRole.Rules, getKubeVirtComponentsRules()...)\n\treturn operatorRole\n}", "is_vulnerable": 0}
{"code": "func Compile(fn string, src []byte, debug bool) (string, error) {\n\tcompiler := asm.NewCompiler(debug)\n\tcompiler.Feed(asm.Lex(fn, src, debug))\n\n\tbin, compileErrors := compiler.Compile()\n\tif len(compileErrors) > 0 {\n\t\t// report errors\n\t\tfor _, err := range compileErrors {\n\t\t\tfmt.Printf(\"%s:%v\\n\", fn, err)\n\t\t}\n\t\treturn \"\", errors.New(\"compiling failed\")\n\t}\n\treturn bin, nil\n}", "is_vulnerable": 0}
{"code": "\tp, err := PrepareMounts(ctx, mm, cm, g, \"\", mnts, refs, func(m *opspb.Mount, ref cache.ImmutableRef) (cache.MutableRef, error) {\n\t\tif m.Input != opspb.Empty {\n\t\t\tcm = refs[m.Input].Worker.CacheManager()\n\t\t}\n\t\treturn cm.New(ctx, ref, g)\n\t}, platform.OS)", "is_vulnerable": 0}
{"code": "func inHeadIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase TextToken:\n\t\ts := strings.TrimLeft(p.tok.Data, whitespace)\n\t\tif len(s) < len(p.tok.Data) {\n\t\t\t// Add the initial whitespace to the current node.\n\t\t\tp.addText(p.tok.Data[:len(p.tok.Data)-len(s)])\n\t\t\tif s == \"\" {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tp.tok.Data = s\n\t\t}\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\treturn inBodyIM(p)\n\t\tcase a.Base, a.Basefont, a.Bgsound, a.Command, a.Link, a.Meta:\n\t\t\tp.addElement()\n\t\t\tp.oe.pop()\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\treturn true\n\t\tcase a.Script, a.Title, a.Noscript, a.Noframes, a.Style:\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.im = textIM\n\t\t\treturn true\n\t\tcase a.Head:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Head:\n\t\t\tn := p.oe.pop()\n\t\t\tif n.DataAtom != a.Head {\n\t\t\t\tpanic(\"html: bad parser state: <head> element not found, in the in-head insertion mode\")\n\t\t\t}\n\t\t\tp.im = afterHeadIM\n\t\t\treturn true\n\t\tcase a.Body, a.Html, a.Br:\n\t\t\tp.parseImpliedToken(EndTagToken, a.Head, a.Head.String())\n\t\t\treturn false\n\t\tdefault:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\t\treturn true\n\tcase DoctypeToken:\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\n\tp.parseImpliedToken(EndTagToken, a.Head, a.Head.String())\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (s *ConsoleServer) lookupConsoleUser(ctx context.Context, unameOrEmail, password string) (id uuid.UUID, uname string, email string, role console.UserRole, err error) {\n\trole = console.UserRole_USER_ROLE_UNKNOWN\n\tquery := \"SELECT id, username, email, role, password, disable_time FROM console_user WHERE username = $1 OR email = $1\"\n\tvar dbPassword []byte\n\tvar dbDisableTime pgtype.Timestamptz\n\terr = s.db.QueryRowContext(ctx, query, unameOrEmail).Scan(&id, &uname, &email, &role, &dbPassword, &dbDisableTime)\n\tif err != nil {\n\t\tif err == sql.ErrNoRows {\n\t\t\terr = nil\n\t\t}\n\t\treturn\n\t}\n\n\t// Check if it's disabled.\n\tif dbDisableTime.Status == pgtype.Present && dbDisableTime.Time.Unix() != 0 {\n\t\ts.logger.Info(\"Console user account is disabled.\", zap.String(\"username\", unameOrEmail))\n\t\terr = status.Error(codes.PermissionDenied, \"Invalid credentials.\")\n\t\treturn\n\t}\n\n\t// Check password\n\terr = bcrypt.CompareHashAndPassword(dbPassword, []byte(password))\n\tif err != nil {\n\t\terr = status.Error(codes.Unauthenticated, \"Invalid credentials.\")\n\t\treturn\n\t}\n\n\treturn\n\n}", "is_vulnerable": 1}
{"code": "func local_request_API_SetToolInfo_0(ctx context.Context, marshaler runtime.Marshaler, server APIServer, req *http.Request, pathParams map[string]string) (proto.Message, runtime.ServerMetadata, error) {\n\tvar protoReq proto_6.Tool\n\tvar metadata runtime.ServerMetadata\n\n\tnewReader, berr := utilities.IOReaderFactory(req.Body)\n\tif berr != nil {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", berr)\n\t}\n\tif err := marshaler.NewDecoder(newReader()).Decode(&protoReq); err != nil && err != io.EOF {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", err)\n\t}\n\n\tmsg, err := server.SetToolInfo(ctx, &protoReq)\n\treturn msg, metadata, err\n\n}", "is_vulnerable": 0}
{"code": "func RawToContainer(hostID int, idMap []IDMap) (int, error) {\n\tif idMap == nil {\n\t\treturn hostID, nil\n\t}\n\tfor _, m := range idMap {\n\t\tif (hostID >= m.HostID) && (hostID <= (m.HostID + m.Size - 1)) {\n\t\t\tcontID := m.ContainerID + (hostID - m.HostID)\n\t\t\treturn contID, nil\n\t\t}\n\t}\n\treturn -1, fmt.Errorf(\"Host ID %d cannot be mapped to a container ID\", hostID)\n}", "is_vulnerable": 0}
{"code": "func Clean(p string) string {\n\tp = strings.ReplaceAll(p, `\\`, \"/\")\n\treturn strings.Trim(path.Clean(\"/\"+p), \"/\")\n}", "is_vulnerable": 0}
{"code": "func (c *Config) OutgoingTLSConfig() (*tls.Config, error) {\n\t// If VerifyServerHostname is true, that implies VerifyOutgoing\n\tif c.VerifyServerHostname {\n\t\tc.VerifyOutgoing = true\n\t}\n\tif !c.UseTLS && !c.VerifyOutgoing {\n\t\treturn nil, nil\n\t}\n\t// Create the tlsConfig\n\ttlsConfig := &tls.Config{\n\t\tRootCAs:            x509.NewCertPool(),\n\t\tInsecureSkipVerify: true,\n\t}\n\tif c.ServerName != \"\" {\n\t\ttlsConfig.ServerName = c.ServerName\n\t\ttlsConfig.InsecureSkipVerify = false\n\t}\n\tif c.VerifyServerHostname {\n\t\t// ServerName is filled in dynamically based on the target DC\n\t\ttlsConfig.ServerName = \"VerifyServerHostname\"\n\t\ttlsConfig.InsecureSkipVerify = false\n\t}\n\tif len(c.CipherSuites) != 0 {\n\t\ttlsConfig.CipherSuites = c.CipherSuites\n\t}\n\tif c.PreferServerCipherSuites {\n\t\ttlsConfig.PreferServerCipherSuites = true\n\t}\n\n\t// Ensure we have a CA if VerifyOutgoing is set\n\tif c.VerifyOutgoing && c.CAFile == \"\" && c.CAPath == \"\" {\n\t\treturn nil, fmt.Errorf(\"VerifyOutgoing set, and no CA certificate provided!\")\n\t}\n\n\t// Parse the CA certs if any\n\trootConfig := &rootcerts.Config{\n\t\tCAFile: c.CAFile,\n\t\tCAPath: c.CAPath,\n\t}\n\tif err := rootcerts.ConfigureTLS(tlsConfig, rootConfig); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Add cert/key\n\tcert, err := c.KeyPair()\n\tif err != nil {\n\t\treturn nil, err\n\t} else if cert != nil {\n\t\ttlsConfig.Certificates = []tls.Certificate{*cert}\n\t}\n\n\t// Check if a minimum TLS version was set\n\tif c.TLSMinVersion != \"\" {\n\t\ttlsvers, ok := TLSLookup[c.TLSMinVersion]\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"TLSMinVersion: value %s not supported, please specify one of [tls10,tls11,tls12]\", c.TLSMinVersion)\n\t\t}\n\t\ttlsConfig.MinVersion = tlsvers\n\t}\n\n\treturn tlsConfig, nil\n}", "is_vulnerable": 1}
{"code": "func (p Precompile) UnbondingDelegation(\n\tctx sdk.Context,\n\t_ *vm.Contract,\n\tmethod *abi.Method,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewUnbondingDelegationRequest(args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: &p.stakingKeeper}\n\n\tres, err := queryServer.UnbondingDelegation(sdk.WrapSDKContext(ctx), req)\n\tif err != nil {\n\t\t// return empty unbonding delegation output if the unbonding delegation is not found\n\t\texpError := fmt.Sprintf(\"unbonding delegation with delegator %s not found for validator %s\", req.DelegatorAddr, req.ValidatorAddr)\n\t\tif strings.Contains(err.Error(), expError) {\n\t\t\treturn method.Outputs.Pack(UnbondingDelegationResponse{})\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tout := new(UnbondingDelegationOutput).FromResponse(res)\n\n\treturn method.Outputs.Pack(out.UnbondingDelegation)\n}", "is_vulnerable": 1}
{"code": "func PossibleResourceIdentityTypeValues() []ResourceIdentityType {\n\treturn original.PossibleResourceIdentityTypeValues()\n}", "is_vulnerable": 1}
{"code": "func HandleResponse(payload *PayloadData) (*PayloadData, error) {\n\tswitch payload.Request {\n\tcase \"screenshot\":\n\t\tfile, err := image.WritePNG(payload.Response)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tpayload.Response = utilities.StringToByte(file)\n\t\tbreak\n\tdefault:\n\t\treturn payload, nil\n\t}\n\treturn payload, nil\n}", "is_vulnerable": 1}
{"code": "func shmdt(addr uintptr) (err error) {\n\t_, _, e1 := Syscall(SYS_SHMDT, uintptr(addr), 0, 0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "\treturn func(c *contextmodel.ReqContext) {\n\t\tpluginID := web.Params(c.Req)[\":id\"]\n\t\tp, exists := ps.Plugin(c.Req.Context(), pluginID)\n\t\tif !exists {\n\t\t\t// The frontend will handle app not found appropriately\n\t\t\treturn\n\t\t}\n\n\t\tpermitted := true\n\t\tpath := normalizeIncludePath(c.Req.URL.Path)\n\t\thasAccess := ac.HasAccess(accessControl, c)\n\t\tfor _, i := range p.Includes {\n\t\t\tif i.Type != \"page\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tu, err := url.Parse(i.Path)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Error(\"failed to parse include path\", \"pluginId\", pluginID, \"include\", i.Name, \"err\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif normalizeIncludePath(u.Path) == path {\n\t\t\t\tuseRBAC := features.IsEnabledGlobally(featuremgmt.FlagAccessControlOnCall) && i.RequiresRBACAction()\n\t\t\t\tif useRBAC && !hasAccess(pluginaccesscontrol.GetPluginRouteEvaluator(pluginID, i.Action)) {\n\t\t\t\t\tlogger.Debug(\"Plugin include is covered by RBAC, user doesn't have access\", \"plugin\", pluginID, \"include\", i.Name)\n\t\t\t\t\tpermitted = false\n\t\t\t\t\tbreak\n\t\t\t\t} else if !useRBAC && !c.HasUserRole(i.Role) {\n\t\t\t\t\tpermitted = false\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif !permitted {\n\t\t\taccessForbidden(c)\n\t\t\treturn\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func (q *ListObjectsQuery) evaluate(\n\tctx context.Context,\n\treq listObjectsRequest,\n\tresultsChan chan<- ListObjectsResult,\n\tmaxResults uint32,\n\tresolutionMetadata *ListObjectsResolutionMetadata,\n) error {\n\ttargetObjectType := req.GetType()\n\ttargetRelation := req.GetRelation()\n\n\ttypesys, ok := typesystem.TypesystemFromContext(ctx)\n\tif !ok {\n\t\tpanic(\"typesystem missing in context\")\n\t}\n\n\tif !typesystem.IsSchemaVersionSupported(typesys.GetSchemaVersion()) {\n\t\treturn serverErrors.ValidationError(typesystem.ErrInvalidSchemaVersion)\n\t}\n\n\tfor _, ctxTuple := range req.GetContextualTuples().GetTupleKeys() {\n\t\tif err := validation.ValidateTuple(typesys, ctxTuple); err != nil {\n\t\t\treturn serverErrors.HandleTupleValidateError(err)\n\t\t}\n\t}\n\n\t_, err := typesys.GetRelation(targetObjectType, targetRelation)\n\tif err != nil {\n\t\tif errors.Is(err, typesystem.ErrObjectTypeUndefined) {\n\t\t\treturn serverErrors.TypeNotFound(targetObjectType)\n\t\t}\n\n\t\tif errors.Is(err, typesystem.ErrRelationUndefined) {\n\t\t\treturn serverErrors.RelationNotFound(targetRelation, targetObjectType, nil)\n\t\t}\n\n\t\treturn serverErrors.HandleError(\"\", err)\n\t}\n\n\tif err := validation.ValidateUser(typesys, req.GetUser()); err != nil {\n\t\treturn serverErrors.ValidationError(fmt.Errorf(\"invalid 'user' value: %s\", err))\n\t}\n\n\thandler := func() {\n\t\tuserObj, userRel := tuple.SplitObjectRelation(req.GetUser())\n\t\tuserObjType, userObjID := tuple.SplitObject(userObj)\n\n\t\tvar sourceUserRef reverseexpand.IsUserRef\n\t\tsourceUserRef = &reverseexpand.UserRefObject{\n\t\t\tObject: &openfgav1.Object{\n\t\t\t\tType: userObjType,\n\t\t\t\tId:   userObjID,\n\t\t\t},\n\t\t}\n\n\t\tif tuple.IsTypedWildcard(userObj) {\n\t\t\tsourceUserRef = &reverseexpand.UserRefTypedWildcard{Type: tuple.GetType(userObj)}\n\t\t}\n\n\t\tif userRel != \"\" {\n\t\t\tsourceUserRef = &reverseexpand.UserRefObjectRelation{\n\t\t\t\tObjectRelation: &openfgav1.ObjectRelation{\n\t\t\t\t\tObject:   userObj,\n\t\t\t\t\tRelation: userRel,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treverseExpandResultsChan := make(chan *reverseexpand.ReverseExpandResult, 1)\n\t\tobjectsFound := atomic.Uint32{}\n\n\t\tds := storagewrappers.NewCombinedTupleReader(\n\t\t\tq.datastore,\n\t\t\treq.GetContextualTuples().GetTupleKeys(),\n\t\t)\n\n\t\treverseExpandQuery := reverseexpand.NewReverseExpandQuery(\n\t\t\tds,\n\t\t\ttypesys,\n\t\t\treverseexpand.WithResolveNodeLimit(q.resolveNodeLimit),\n\t\t\treverseexpand.WithResolveNodeBreadthLimit(q.resolveNodeBreadthLimit),\n\t\t\treverseexpand.WithLogger(q.logger),\n\t\t)\n\n\t\tcancelCtx, cancel := context.WithCancel(ctx)\n\n\t\twg := sync.WaitGroup{}\n\n\t\terrChan := make(chan error, 1)\n\n\t\treverseExpandResolutionMetadata := reverseexpand.NewResolutionMetadata()\n\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\n\t\t\terr := reverseExpandQuery.Execute(cancelCtx, &reverseexpand.ReverseExpandRequest{\n\t\t\t\tStoreID:          req.GetStoreId(),\n\t\t\t\tObjectType:       targetObjectType,\n\t\t\t\tRelation:         targetRelation,\n\t\t\t\tUser:             sourceUserRef,\n\t\t\t\tContextualTuples: req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\tContext:          req.GetContext(),\n\t\t\t}, reverseExpandResultsChan, reverseExpandResolutionMetadata)\n\t\t\tif err != nil {\n\t\t\t\terrChan <- err\n\t\t\t}\n\t\t\tatomic.AddUint32(resolutionMetadata.DatastoreQueryCount, *reverseExpandResolutionMetadata.DatastoreQueryCount)\n\t\t\tatomic.AddUint32(resolutionMetadata.DispatchCount, *reverseExpandResolutionMetadata.DispatchCount)\n\t\t}()\n\n\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\t\tctx := storage.ContextWithRelationshipTupleReader(ctx, ds)\n\n\t\tconcurrencyLimiterCh := make(chan struct{}, q.resolveNodeBreadthLimit)\n\n\tConsumerReadLoop:\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tbreak ConsumerReadLoop\n\t\t\tcase res, channelOpen := <-reverseExpandResultsChan:\n\t\t\t\tif !channelOpen {\n\t\t\t\t\tbreak ConsumerReadLoop\n\t\t\t\t}\n\n\t\t\t\tif !(maxResults == 0) && objectsFound.Load() >= maxResults {\n\t\t\t\t\tbreak ConsumerReadLoop\n\t\t\t\t}\n\n\t\t\t\tif res.ResultStatus == reverseexpand.NoFurtherEvalStatus {\n\t\t\t\t\tnoFurtherEvalRequiredCounter.Inc()\n\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfurtherEvalRequiredCounter.Inc()\n\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(res *reverseexpand.ReverseExpandResult) {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\t<-concurrencyLimiterCh\n\t\t\t\t\t\twg.Done()\n\t\t\t\t\t}()\n\n\t\t\t\t\tconcurrencyLimiterCh <- struct{}{}\n\t\t\t\t\tcheckRequestMetadata := graph.NewCheckRequestMetadata(q.resolveNodeLimit)\n\n\t\t\t\t\tresp, err := q.checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\t\t\t\t\tStoreID:              req.GetStoreId(),\n\t\t\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\t\t\t\t\tTupleKey:             tuple.NewTupleKey(res.Object, req.GetRelation(), req.GetUser()),\n\t\t\t\t\t\tContextualTuples:     req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\t\t\tContext:              req.GetContext(),\n\t\t\t\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t\t\t\t})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tatomic.AddUint32(resolutionMetadata.DatastoreQueryCount, resp.GetResolutionMetadata().DatastoreQueryCount)\n\t\t\t\t\tatomic.AddUint32(resolutionMetadata.DispatchCount, checkRequestMetadata.DispatchCounter.Load())\n\n\t\t\t\t\tif resp.Allowed {\n\t\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t\t}\n\t\t\t\t}(res)\n\n\t\t\tcase err := <-errChan:\n\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\terr = serverErrors.AuthorizationModelResolutionTooComplex\n\t\t\t\t}\n\n\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\tbreak ConsumerReadLoop\n\t\t\t}\n\t\t}\n\n\t\tcancel()\n\t\twg.Wait()\n\t\tclose(resultsChan)\n\t}\n\n\tgo handler()\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func RenderDescriptionHTML(\n\trawHTML []byte,\n\turlPrefix string,\n\tmetas map[string]string,\n) ([]byte, error) {\n\tctx := &postProcessCtx{\n\t\tmetas:     metas,\n\t\turlPrefix: urlPrefix,\n\t\tprocs: []processor{\n\t\t\tdescriptionLinkProcessor,\n\t\t},\n\t}\n\treturn ctx.postProcess(rawHTML)\n}", "is_vulnerable": 0}
{"code": "func (s *backupsSuite) TestAuthRequiresClientNotMachine(c *gc.C) {\n\t// Add a machine and try to login.\n\tmachine, err := s.State.AddMachine(\"quantal\", state.JobHostUnits)\n\tc.Assert(err, jc.ErrorIsNil)\n\terr = machine.SetProvisioned(\"foo\", \"\", \"fake_nonce\", nil)\n\tc.Assert(err, jc.ErrorIsNil)\n\tpassword, err := utils.RandomPassword()\n\tc.Assert(err, jc.ErrorIsNil)\n\terr = machine.SetPassword(password)\n\tc.Assert(err, jc.ErrorIsNil)\n\n\tresp := apitesting.SendHTTPRequest(c, apitesting.HTTPRequestParams{\n\t\tTag:      machine.Tag().String(),\n\t\tPassword: password,\n\t\tMethod:   \"GET\",\n\t\tURL:      s.backupURL,\n\t\tNonce:    \"fake_nonce\",\n\t})\n\ts.assertErrorResponse(c, resp, http.StatusInternalServerError, \"tag kind machine not valid\")\n\n\t// Now try a user login.\n\tresp = s.sendHTTPRequest(c, apitesting.HTTPRequestParams{Method: \"POST\", URL: s.backupURL})\n\ts.assertErrorResponse(c, resp, http.StatusMethodNotAllowed, `unsupported method: \"POST\"`)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) HijackDLL(ctx context.Context, in *clientpb.DllHijackReq, opts ...grpc.CallOption) (*clientpb.DllHijack, error) {\n\tout := new(clientpb.DllHijack)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/HijackDLL\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) ListResourcesSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetPinEntryMode(m PinEntryMode) error {\n\terr := handleError(C.gpgme_set_pinentry_mode(c.ctx, C.gpgme_pinentry_mode_t(m)))\n\truntime.KeepAlive(c)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func NewConfigurations(platform platforms.Platform, daprClient scheme.Interface, configPath string) Configurations {\n\tc := configurations{}\n\tc.platform = platform\n\n\tif platform == platforms.Kubernetes {\n\t\tc.getConfigurationsFn = c.getKubernetesConfigurations\n\t\tc.daprClient = daprClient\n\t} else if platform == platforms.Standalone {\n\t\tc.getConfigurationsFn = c.getStandaloneConfigurations\n\t} else if platform == platforms.DockerCompose {\n\t\tc.getConfigurationsFn = c.getDockerComposeConfigurations\n\t\tc.configPath = configPath\n\t}\n\treturn &c\n}", "is_vulnerable": 0}
{"code": "func Main() {\n\tif err := random.Seed(); err != nil {\n\t\tlog.Fatalf(\"Fatal error: %v\", err)\n\t}\n\tsetupRootCommand(Root)\n\tAddBackendFlags()\n\tif err := Root.Execute(); err != nil {\n\t\tlog.Fatalf(\"Fatal error: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client AccountsClient) GetProperties(ctx context.Context, resourceGroupName string, accountName string) (result Account, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/AccountsClient.GetProperties\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: accountName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"accountName\", Name: validation.MaxLength, Rule: 24, Chain: nil},\n\t\t\t\t{Target: \"accountName\", Name: validation.MinLength, Rule: 3, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"storage.AccountsClient\", \"GetProperties\", err.Error())\n\t}\n\n\treq, err := client.GetPropertiesPreparer(ctx, resourceGroupName, accountName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"GetProperties\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.GetPropertiesSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"GetProperties\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.GetPropertiesResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"GetProperties\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (self *Launcher) ScheduleArtifactCollectionFromCollectorArgs(\n\tctx context.Context,\n\tconfig_obj *config_proto.Config,\n\tcollector_request *flows_proto.ArtifactCollectorArgs,\n\tvql_collector_args []*actions_proto.VQLCollectorArgs,\n\tcompletion func()) (string, error) {\n\n\tclient_id := collector_request.ClientId\n\tif client_id == \"\" {\n\t\treturn \"\", errors.New(\"Client id not provided.\")\n\t}\n\n\tif !utils.ValidateClientId(client_id) {\n\t\treturn \"\", errors.New(\"Client id not valid.\")\n\t}\n\n\tdb, err := datastore.GetDB(config_obj)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tclient_manager, err := services.GetClientInfoManager(config_obj)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tsession_id := NewFlowId(client_id)\n\n\t// Compile all the requests into specific tasks to be sent to the\n\t// client.\n\ttasks := []*crypto_proto.VeloMessage{}\n\tfor id, arg := range vql_collector_args {\n\t\t// If sending to the server record who actually launched this.\n\t\tif client_id == \"server\" {\n\t\t\targ.Principal = collector_request.Creator\n\t\t}\n\n\t\t// The task we will schedule for the client.\n\t\ttask := &crypto_proto.VeloMessage{\n\t\t\tQueryId:         uint64(id),\n\t\t\tSessionId:       session_id,\n\t\t\tRequestId:       constants.ProcessVQLResponses,\n\t\t\tVQLClientAction: arg,\n\t\t}\n\n\t\t// Send an urgent request to the client.\n\t\tif collector_request.Urgent {\n\t\t\ttask.Urgent = true\n\t\t}\n\n\t\ttasks = append(tasks, task)\n\t}\n\n\t// Save the collection context first.\n\tflow_path_manager := paths.NewFlowPathManager(client_id, session_id)\n\n\t// Generate a new collection context for this flow.\n\tcollection_context := &flows_proto.ArtifactCollectorContext{\n\t\tSessionId:           session_id,\n\t\tCreateTime:          uint64(time.Now().UnixNano() / 1000),\n\t\tState:               flows_proto.ArtifactCollectorContext_RUNNING,\n\t\tRequest:             collector_request,\n\t\tClientId:            client_id,\n\t\tTotalRequests:       int64(len(tasks)),\n\t\tOutstandingRequests: int64(len(tasks)),\n\t}\n\n\t// Store the collection_context first, then queue all the tasks.\n\terr = db.SetSubjectWithCompletion(config_obj,\n\t\tflow_path_manager.Path(),\n\t\tcollection_context,\n\n\t\tfunc() {\n\t\t\t// Queue and notify the client about the new tasks\n\t\t\tclient_manager.QueueMessagesForClient(\n\t\t\t\tctx, client_id, tasks, true /* notify */)\n\t\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Record the tasks for provenance of what we actually did.\n\terr = db.SetSubjectWithCompletion(config_obj,\n\t\tflow_path_manager.Task(),\n\t\t&api_proto.ApiFlowRequestDetails{Items: tasks}, nil)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn collection_context.SessionId, nil\n}", "is_vulnerable": 0}
{"code": "func (u userService) CreateDefaultUser() error {\n\t_, err := u.repository.FindByUsername(defaultUser)\n\tswitch err {\n\tcase repo.ErrNotFound:\n\t\tbreak\n\tdefault:\n\t\treturn err\n\t}\n\n\tpasswordHash, err := utilities.HashAndSalt(defaultPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn u.repository.Insert(entities.User{\n\t\tUsername: defaultUser,\n\t\tPassword: passwordHash,\n\t})\n}", "is_vulnerable": 1}
{"code": "func (v *View) UserByID(ctx context.Context, userID, instanceID string) (*model.UserView, error) {\n\treturn view.UserByID(ctx, v.Db, userID, instanceID)\n}", "is_vulnerable": 0}
{"code": "func TestProcessResults_whenDifferentPaths_AccumulatesIssues(t *testing.T) {\n\ttestutil.UnitTest(t)\n\tf := NewFolder(\"dummy\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\n\tf.processResults([]snyk.Issue{\n\t\t{ID: \"id1\", AffectedFilePath: \"path1\"},\n\t\t{ID: \"id2\", AffectedFilePath: \"path2\"},\n\t})\n\tf.processResults([]snyk.Issue{{ID: \"id3\", AffectedFilePath: \"path3\"}})\n\n\tassert.Equal(t, 3, f.documentDiagnosticCache.Length())\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path1\"))\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path2\"))\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path3\"))\n}", "is_vulnerable": 1}
{"code": "func generateHMAC(data []byte, key *[32]byte) []byte {\n\th := hmac.New(sha512.New512_256, key[:])\n\th.Write(data)\n\treturn h.Sum(nil)\n}", "is_vulnerable": 1}
{"code": "func TestRuntimeConfiguration(t *testing.T) {\n\ttestCases := []struct {\n\t\tdesc             string\n\t\tserviceConfig    map[string]*dynamic.Service\n\t\trouterConfig     map[string]*dynamic.Router\n\t\tmiddlewareConfig map[string]*dynamic.Middleware\n\t\texpectedError    int\n\t}{\n\t\t{\n\t\t\tdesc: \"No error\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1:8085\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1:8086\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tHealthCheck: &dynamic.ServerHealthCheck{\n\t\t\t\t\t\t\tInterval: \"500ms\",\n\t\t\t\t\t\t\tPath:     \"/health\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 0,\n\t\t},\n\t\t{\n\t\t\tdesc: \"One router with wrong rule\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"All router with wrong rule\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with unknown service\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"wrong-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with broken service\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: nil,\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"admin:admin\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"addPrefixTest\": {\n\t\t\t\t\tAddPrefix: &dynamic.AddPrefix{\n\t\t\t\t\t\tPrefix: \"/toto\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"auth\", \"addPrefixTest\"},\n\t\t\t\t},\n\t\t\t\t\"test\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar.other`)\",\n\t\t\t\t\tMiddlewares: []string{\"addPrefixTest\", \"auth\"},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with unknown middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"admin:admin\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"unknown\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\n\t\t{\n\t\t\tdesc: \"Router with broken middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"foo\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"auth\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tentryPoints := []string{\"web\"}\n\n\t\t\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\t\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\t\t\tServices:    test.serviceConfig,\n\t\t\t\t\tRouters:     test.routerConfig,\n\t\t\t\t\tMiddlewares: test.middlewareConfig,\n\t\t\t\t},\n\t\t\t})\n\n\t\t\troundTripperManager := service.NewRoundTripperManager()\n\t\t\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\t\t\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\t\t\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\t\t\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\n\t\t\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry())\n\n\t\t\t_ = routerManager.BuildHandlers(context.Background(), entryPoints, false)\n\n\t\t\t// even though rtConf was passed by argument to the manager builders above,\n\t\t\t// it's ok to use it as the result we check, because everything worth checking\n\t\t\t// can be accessed by pointers in it.\n\t\t\tvar allErrors int\n\t\t\tfor _, v := range rtConf.Services {\n\t\t\t\tif v.Err != nil {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, v := range rtConf.Routers {\n\t\t\t\tif len(v.Err) > 0 {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, v := range rtConf.Middlewares {\n\t\t\t\tif v.Err != nil {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tassert.Equal(t, test.expectedError, allErrors)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestSafeRedirectURL(t *testing.T) {\n\ttests := map[string]string{\n\t\t\"\":               \"/\",\n\t\t\"/\":              \"/\",\n\t\t\"a@b.com:c\":      \"/\",\n\t\t\"a@b.com/c\":      \"/\",\n\t\t\"//a\":            \"/\",\n\t\t\"http://a.com/b\": \"/b\",\n\t\t\"//a.com/b\":      \"/b\",\n\t\t\"//a@b.com/c\":    \"/c\",\n\t\t\"/a?b\":           \"/a?b\",\n\t}\n\tfor input, want := range tests {\n\t\tgot := SafeRedirectURL(input)\n\t\tif got != want {\n\t\t\tt.Errorf(\"%q: got %q, want %q\", input, got, want)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetJobs(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Jobs, error) {\n\tout := new(clientpb.Jobs)\n\terr := c.cc.Invoke(ctx, SliverRPC_GetJobs_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\treturn func(p Preparer) Preparer {\n\t\treturn PreparerFunc(func(r *http.Request) (*http.Request, error) {\n\t\t\tr, err := p.Prepare(r)\n\t\t\tif err == nil {\n\t\t\t\tif input == nil {\n\t\t\t\t\treturn r, fmt.Errorf(\"Input Bytes was nil\")\n\t\t\t\t}\n\n\t\t\t\tr.ContentLength = int64(len(*input))\n\t\t\t\tr.Body = ioutil.NopCloser(bytes.NewReader(*input))\n\t\t\t}\n\t\t\treturn r, err\n\t\t})\n\t}", "is_vulnerable": 0}
{"code": "func (c *Configurator) verifyIncomingRPC() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\treturn c.base.VerifyIncomingRPC\n}", "is_vulnerable": 0}
{"code": "func (m *NinRepStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field3 = append(m.Field3, &NidOptNative{})\n\t\t\tif err := m.Field3[len(m.Field3)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field4 = append(m.Field4, &NinOptNative{})\n\t\t\tif err := m.Field4[len(m.Field4)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field8 = append(m.Field8, &NidOptNative{})\n\t\t\tif err := m.Field8[len(m.Field8)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field14 = append(m.Field14, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.Field15[len(m.Field15)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *S2IBuilder) Build() error {\n\tif s.build.Spec.Strategy.SourceStrategy == nil {\n\t\treturn fmt.Errorf(\"the source to image builder must be used with the source strategy\")\n\t}\n\n\tvar push bool\n\n\tcontextDir := filepath.Clean(s.build.Spec.Source.ContextDir)\n\tif contextDir == \".\" || contextDir == \"/\" {\n\t\tcontextDir = \"\"\n\t}\n\tbuildDir, err := ioutil.TempDir(\"\", \"s2i-build\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tsrcDir := filepath.Join(buildDir, s2iapi.Source)\n\tif err := os.MkdirAll(srcDir, os.ModePerm); err != nil {\n\t\treturn err\n\t}\n\ttmpDir := filepath.Join(buildDir, \"tmp\")\n\tif err := os.MkdirAll(tmpDir, os.ModePerm); err != nil {\n\t\treturn err\n\t}\n\n\tdownload := &downloader{\n\t\ts:       s,\n\t\tin:      os.Stdin,\n\t\ttimeout: urlCheckTimeout,\n\n\t\tdir:        srcDir,\n\t\tcontextDir: contextDir,\n\t\ttmpDir:     tmpDir,\n\t}\n\t// if there is no output target, set one up so the docker build logic\n\t// (which requires a tag) will still work, but we won't push it at the end.\n\tif s.build.Spec.Output.To == nil || len(s.build.Spec.Output.To.Name) == 0 {\n\t\ts.build.Status.OutputDockerImageReference = s.build.Name\n\t} else {\n\t\tpush = true\n\t}\n\tpushTag := s.build.Status.OutputDockerImageReference\n\tgit := s.build.Spec.Source.Git\n\n\tvar ref string\n\tif s.build.Spec.Revision != nil && s.build.Spec.Revision.Git != nil &&\n\t\tlen(s.build.Spec.Revision.Git.Commit) != 0 {\n\t\tref = s.build.Spec.Revision.Git.Commit\n\t} else if git != nil && len(git.Ref) != 0 {\n\t\tref = git.Ref\n\t}\n\n\tsourceURI := &url.URL{\n\t\tScheme:   \"file\",\n\t\tPath:     srcDir,\n\t\tFragment: ref,\n\t}\n\n\tinjections := s2iapi.InjectionList{}\n\tfor _, s := range s.build.Spec.Source.Secrets {\n\t\tglog.V(3).Infof(\"Injecting secret %q into a build into %q\", s.Secret.Name, filepath.Clean(s.DestinationDir))\n\t\tsecretSourcePath := filepath.Join(strategy.SecretBuildSourceBaseMountPath, s.Secret.Name)\n\t\tinjections = append(injections, s2iapi.InjectPath{\n\t\t\tSourcePath:     secretSourcePath,\n\t\t\tDestinationDir: s.DestinationDir,\n\t\t})\n\t}\n\n\tbuildTag := randomBuildTag(s.build.Namespace, s.build.Name)\n\n\tconfig := &s2iapi.Config{\n\t\tWorkingDir:     buildDir,\n\t\tDockerConfig:   &s2iapi.DockerConfig{Endpoint: s.dockerSocket},\n\t\tDockerCfgPath:  os.Getenv(dockercfg.PullAuthType),\n\t\tLabelNamespace: api.DefaultDockerLabelNamespace,\n\n\t\tScriptsURL: s.build.Spec.Strategy.SourceStrategy.Scripts,\n\n\t\tBuilderImage:       s.build.Spec.Strategy.SourceStrategy.From.Name,\n\t\tIncremental:        s.build.Spec.Strategy.SourceStrategy.Incremental,\n\t\tIncrementalFromTag: pushTag,\n\n\t\tEnvironment:       buildEnvVars(s.build),\n\t\tDockerNetworkMode: getDockerNetworkMode(),\n\n\t\tSource:       sourceURI.String(),\n\t\tTag:          buildTag,\n\t\tContextDir:   s.build.Spec.Source.ContextDir,\n\t\tCGroupLimits: s.cgLimits,\n\t\tInjections:   injections,\n\t}\n\n\tif s.build.Spec.Strategy.SourceStrategy.ForcePull {\n\t\tglog.V(4).Infof(\"With force pull true, setting policies to %s\", s2iapi.PullAlways)\n\t\tconfig.BuilderPullPolicy = s2iapi.PullAlways\n\t} else {\n\t\tglog.V(4).Infof(\"With force pull false, setting policies to %s\", s2iapi.PullIfNotPresent)\n\t\tconfig.BuilderPullPolicy = s2iapi.PullIfNotPresent\n\t}\n\tconfig.PreviousImagePullPolicy = s2iapi.PullAlways\n\n\tallowedUIDs := os.Getenv(api.AllowedUIDs)\n\tglog.V(2).Infof(\"The value of %s is [%s]\", api.AllowedUIDs, allowedUIDs)\n\tif len(allowedUIDs) > 0 {\n\t\terr := config.AllowedUIDs.Set(allowedUIDs)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tdropCaps := os.Getenv(api.DropCapabilities)\n\tglog.V(2).Infof(\"The value of %s is [%s]\", api.DropCapabilities, dropCaps)\n\tif len(dropCaps) > 0 {\n\t\tconfig.DropCapabilities = strings.Split(dropCaps, \",\")\n\t}\n\n\tif errs := s.validator.ValidateConfig(config); len(errs) != 0 {\n\t\tvar buffer bytes.Buffer\n\t\tfor _, ve := range errs {\n\t\t\tbuffer.WriteString(ve.Error())\n\t\t\tbuffer.WriteString(\", \")\n\t\t}\n\t\treturn errors.New(buffer.String())\n\t}\n\n\t// If DockerCfgPath is provided in api.Config, then attempt to read the the\n\t// dockercfg file and get the authentication for pulling the builder image.\n\tconfig.PullAuthentication, _ = dockercfg.NewHelper().GetDockerAuth(config.BuilderImage, dockercfg.PullAuthType)\n\tconfig.IncrementalAuthentication, _ = dockercfg.NewHelper().GetDockerAuth(pushTag, dockercfg.PushAuthType)\n\n\tglog.V(2).Infof(\"Creating a new S2I builder with build config: %#v\\n\", describe.DescribeConfig(config))\n\tbuilder, err := s.builder.Builder(config, s2ibuild.Overrides{Downloader: download})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tglog.V(4).Infof(\"Starting S2I build from %s/%s BuildConfig ...\", s.build.Namespace, s.build.Name)\n\n\tif _, err = builder.Build(config); err != nil {\n\t\treturn err\n\t}\n\n\tcname := containerName(\"s2i\", s.build.Name, s.build.Namespace, \"post-commit\")\n\tif err := execPostCommitHook(s.dockerClient, s.build.Spec.PostCommit, buildTag, cname); err != nil {\n\t\treturn err\n\t}\n\n\tif push {\n\t\tif err := tagImage(s.dockerClient, buildTag, pushTag); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := removeImage(s.dockerClient, buildTag); err != nil {\n\t\tglog.Warningf(\"Failed to remove temporary build tag %v: %v\", buildTag, err)\n\t}\n\n\tif push {\n\t\t// Get the Docker push authentication\n\t\tpushAuthConfig, authPresent := dockercfg.NewHelper().GetDockerAuth(\n\t\t\tpushTag,\n\t\t\tdockercfg.PushAuthType,\n\t\t)\n\t\tif authPresent {\n\t\t\tglog.Infof(\"Using provided push secret for pushing %s image\", pushTag)\n\t\t} else {\n\t\t\tglog.Infof(\"No push secret provided\")\n\t\t}\n\t\tglog.Infof(\"Pushing %s image ...\", pushTag)\n\t\tif err := pushImage(s.dockerClient, pushTag, pushAuthConfig); err != nil {\n\t\t\t// write extended error message to assist in problem resolution\n\t\t\tmsg := fmt.Sprintf(\"Failed to push image. Response from registry is: %v\", err)\n\t\t\tif authPresent {\n\t\t\t\tglog.Infof(\"Registry server Address: %s\", pushAuthConfig.ServerAddress)\n\t\t\t\tglog.Infof(\"Registry server User Name: %s\", pushAuthConfig.Username)\n\t\t\t\tglog.Infof(\"Registry server Email: %s\", pushAuthConfig.Email)\n\t\t\t\tpasswordPresent := \"<<empty>>\"\n\t\t\t\tif len(pushAuthConfig.Password) > 0 {\n\t\t\t\t\tpasswordPresent = \"<<non-empty>>\"\n\t\t\t\t}\n\t\t\t\tglog.Infof(\"Registry server Password: %s\", passwordPresent)\n\t\t\t}\n\t\t\treturn errors.New(msg)\n\t\t}\n\t\tglog.Infof(\"Successfully pushed %s\", pushTag)\n\t\tglog.Flush()\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\t\tfunc(server string) bool {\n\t\t\t\treturn strings.Contains(server, `more_set_headers \"Content-Length: $content_length`) &&\n\t\t\t\t\tstrings.Contains(server, `more_set_headers \"Content-Type: $content_type\";`)\n\t\t\t})", "is_vulnerable": 1}
{"code": "func pathEscapesBaseViaSymlink(base, full string) (bool, error) {\n\tresolveSym, err := filepath.EvalSymlinks(full)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\t// Nomad owns most of the prefix path, which includes the alloc UUID, so\n\t// it's safe to assume that we can do a case insensitive check regardless of\n\t// filesystem, as even if the cluster admin remounted the datadir with a\n\t// slightly different capitalization, you'd only be able to escape into that\n\t// same directory.\n\treturn !hasPrefixCaseInsensitive(resolveSym, base), nil\n}", "is_vulnerable": 0}
{"code": "func TestPageWriterPageBytes(t *testing.T) {\n\tcases := []struct {\n\t\tname        string\n\t\tpageBytes   int\n\t\texpectPanic bool\n\t}{\n\t\t{\n\t\t\tname:        \"normal page bytes\",\n\t\t\tpageBytes:   4096,\n\t\t\texpectPanic: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"negative page bytes\",\n\t\t\tpageBytes:   -1,\n\t\t\texpectPanic: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"zero page bytes\",\n\t\t\tpageBytes:   0,\n\t\t\texpectPanic: true,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdefaultBufferBytes = 1024\n\t\t\tcw := &checkPageWriter{pageBytes: tc.pageBytes, t: t}\n\t\t\tif tc.expectPanic {\n\t\t\t\tassert.Panicsf(t, func() {\n\t\t\t\t\tNewPageWriter(cw, tc.pageBytes, 0)\n\t\t\t\t}, \"expected panic when pageBytes is %d\", tc.pageBytes)\n\t\t\t} else {\n\t\t\t\tpw := NewPageWriter(cw, tc.pageBytes, 0)\n\t\t\t\tassert.NotEqual(t, pw, nil)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t dummyHandler) ServeHTTP(http.ResponseWriter, *http.Request) {}", "is_vulnerable": 0}
{"code": "func (s *Server) ListObjects(ctx context.Context, req *openfgapb.ListObjectsRequest) (*openfgapb.ListObjectsResponse, error) {\n\tstoreID := req.GetStoreId()\n\ttargetObjectType := req.GetType()\n\n\tctx, span := tracer.Start(ctx, \"ListObjects\", trace.WithAttributes(\n\t\tattribute.String(\"object_type\", targetObjectType),\n\t\tattribute.String(\"relation\", req.GetRelation()),\n\t\tattribute.String(\"user\", req.GetUser()),\n\t))\n\tdefer span.End()\n\n\tmodelID := req.GetAuthorizationModelId()\n\n\tmodelID, err := s.resolveAuthorizationModelID(ctx, storeID, modelID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmodel, err := s.datastore.ReadAuthorizationModel(ctx, storeID, modelID)\n\tif err != nil {\n\t\tif errors.Is(err, storage.ErrNotFound) {\n\t\t\treturn nil, serverErrors.AuthorizationModelNotFound(modelID)\n\t\t}\n\n\t\treturn nil, err\n\t}\n\n\ttypesys := typesystem.New(model)\n\n\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\tq := &commands.ListObjectsQuery{\n\t\tDatastore:             s.datastore,\n\t\tLogger:                s.logger,\n\t\tListObjectsDeadline:   s.config.ListObjectsDeadline,\n\t\tListObjectsMaxResults: s.config.ListObjectsMaxResults,\n\t\tResolveNodeLimit:      s.config.ResolveNodeLimit,\n\t}\n\treturn q.Execute(ctx, &openfgapb.ListObjectsRequest{\n\t\tStoreId:              storeID,\n\t\tContextualTuples:     req.GetContextualTuples(),\n\t\tAuthorizationModelId: modelID,\n\t\tType:                 targetObjectType,\n\t\tRelation:             req.Relation,\n\t\tUser:                 req.User,\n\t})\n}", "is_vulnerable": 1}
{"code": "func (c *liveStateCache) getCluster(server string) (clustercache.ClusterCache, error) {\n\tc.lock.RLock()\n\tclusterCache, ok := c.clusters[server]\n\tcacheSettings := c.cacheSettings\n\tc.lock.RUnlock()\n\n\tif ok {\n\t\treturn clusterCache, nil\n\t}\n\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tclusterCache, ok = c.clusters[server]\n\tif ok {\n\t\treturn clusterCache, nil\n\t}\n\n\tcluster, err := c.db.GetCluster(context.Background(), server)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting cluster: %w\", err)\n\t}\n\n\tif !c.canHandleCluster(cluster) {\n\t\treturn nil, fmt.Errorf(\"controller is configured to ignore cluster %s\", cluster.Server)\n\t}\n\n\tresourceCustomLabels, err := c.settingsMgr.GetResourceCustomLabels()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting custom label: %w\", err)\n\t}\n\n\tclusterCacheConfig := cluster.RESTConfig()\n\t// Controller dynamically fetches all resource types available on the cluster\n\t// using a discovery API that may contain deprecated APIs.\n\t// This causes log flooding when managing a large number of clusters.\n\t// https://github.com/argoproj/argo-cd/issues/11973\n\t// However, we can safely suppress deprecation warnings\n\t// because we do not rely on resources with a particular API group or version.\n\t// https://kubernetes.io/blog/2020/09/03/warnings/#customize-client-handling\n\t//\n\t// Completely suppress warning logs only for log levels that are less than Debug.\n\tif log.GetLevel() < log.DebugLevel {\n\t\tclusterCacheConfig.WarningHandler = rest.NoWarnings{}\n\t}\n\n\tclusterCacheOpts := []clustercache.UpdateSettingsFunc{\n\t\tclustercache.SetListSemaphore(semaphore.NewWeighted(clusterCacheListSemaphoreSize)),\n\t\tclustercache.SetListPageSize(clusterCacheListPageSize),\n\t\tclustercache.SetWatchResyncTimeout(clusterCacheWatchResyncDuration),\n\t\tclustercache.SetClusterSyncRetryTimeout(clusterSyncRetryTimeoutDuration),\n\t\tclustercache.SetResyncTimeout(clusterCacheResyncDuration),\n\t\tclustercache.SetSettings(cacheSettings.clusterSettings),\n\t\tclustercache.SetNamespaces(cluster.Namespaces),\n\t\tclustercache.SetClusterResources(cluster.ClusterResources),\n\t\tclustercache.SetPopulateResourceInfoHandler(func(un *unstructured.Unstructured, isRoot bool) (interface{}, bool) {\n\t\t\tres := &ResourceInfo{}\n\t\t\tpopulateNodeInfo(un, res, resourceCustomLabels)\n\t\t\tc.lock.RLock()\n\t\t\tcacheSettings := c.cacheSettings\n\t\t\tc.lock.RUnlock()\n\n\t\t\tres.Health, _ = health.GetResourceHealth(un, cacheSettings.clusterSettings.ResourceHealthOverride)\n\n\t\t\tappName := c.resourceTracking.GetAppName(un, cacheSettings.appInstanceLabelKey, cacheSettings.trackingMethod)\n\t\t\tif isRoot && appName != \"\" {\n\t\t\t\tres.AppName = appName\n\t\t\t}\n\n\t\t\tgvk := un.GroupVersionKind()\n\n\t\t\tif cacheSettings.ignoreResourceUpdatesEnabled && shouldHashManifest(appName, gvk) {\n\t\t\t\thash, err := generateManifestHash(un, nil, cacheSettings.resourceOverrides, c.ignoreNormalizerOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorf(\"Failed to generate manifest hash: %v\", err)\n\t\t\t\t} else {\n\t\t\t\t\tres.manifestHash = hash\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// edge case. we do not label CRDs, so they miss the tracking label we inject. But we still\n\t\t\t// want the full resource to be available in our cache (to diff), so we store all CRDs\n\t\t\treturn res, res.AppName != \"\" || gvk.Kind == kube.CustomResourceDefinitionKind\n\t\t}),\n\t\tclustercache.SetLogr(logutils.NewLogrusLogger(log.WithField(\"server\", cluster.Server))),\n\t\tclustercache.SetRetryOptions(clusterCacheAttemptLimit, clusterCacheRetryUseBackoff, isRetryableError),\n\t}\n\n\tclusterCache = clustercache.NewClusterCache(clusterCacheConfig, clusterCacheOpts...)\n\n\t_ = clusterCache.OnResourceUpdated(func(newRes *clustercache.Resource, oldRes *clustercache.Resource, namespaceResources map[kube.ResourceKey]*clustercache.Resource) {\n\t\ttoNotify := make(map[string]bool)\n\t\tvar ref v1.ObjectReference\n\t\tif newRes != nil {\n\t\t\tref = newRes.Ref\n\t\t} else {\n\t\t\tref = oldRes.Ref\n\t\t}\n\n\t\tc.lock.RLock()\n\t\tcacheSettings := c.cacheSettings\n\t\tc.lock.RUnlock()\n\n\t\tif cacheSettings.ignoreResourceUpdatesEnabled && oldRes != nil && newRes != nil && skipResourceUpdate(resInfo(oldRes), resInfo(newRes)) {\n\t\t\t// Additional check for debug level so we don't need to evaluate the\n\t\t\t// format string in case of non-debug scenarios\n\t\t\tif log.GetLevel() >= log.DebugLevel {\n\t\t\t\tnamespace := ref.Namespace\n\t\t\t\tif ref.Namespace == \"\" {\n\t\t\t\t\tnamespace = \"(cluster-scoped)\"\n\t\t\t\t}\n\t\t\t\tlog.WithFields(log.Fields{\n\t\t\t\t\t\"server\":      cluster.Server,\n\t\t\t\t\t\"namespace\":   namespace,\n\t\t\t\t\t\"name\":        ref.Name,\n\t\t\t\t\t\"api-version\": ref.APIVersion,\n\t\t\t\t\t\"kind\":        ref.Kind,\n\t\t\t\t}).Debug(\"Ignoring change of object because none of the watched resource fields have changed\")\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tfor _, r := range []*clustercache.Resource{newRes, oldRes} {\n\t\t\tif r == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tapp := getApp(r, namespaceResources)\n\t\t\tif app == \"\" || skipAppRequeuing(r.ResourceKey()) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ttoNotify[app] = isRootAppNode(r) || toNotify[app]\n\t\t}\n\t\tc.onObjectUpdated(toNotify, ref)\n\t})\n\n\t_ = clusterCache.OnEvent(func(event watch.EventType, un *unstructured.Unstructured) {\n\t\tgvk := un.GroupVersionKind()\n\t\tc.metricsServer.IncClusterEventsCount(cluster.Server, gvk.Group, gvk.Kind)\n\t})\n\n\tc.clusters[server] = clusterCache\n\n\treturn clusterCache, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) ListWasmExtensions(ctx context.Context, in *sliverpb.ListWasmExtensionsReq, opts ...grpc.CallOption) (*sliverpb.ListWasmExtensions, error) {\n\tout := new(sliverpb.ListWasmExtensions)\n\terr := c.cc.Invoke(ctx, SliverRPC_ListWasmExtensions_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func generateBytes(n int) []byte {\n\tb := make([]byte, n)\n\trand.Read(b)\n\treturn b\n}", "is_vulnerable": 1}
{"code": "func TestParseFilters(t *testing.T) {\n\tfilterExpression := \"eq(foo, 123)+ne(version, TheWorst)+value_in(bar, 4;5;6)\"\n\ttaskFilters, err := ParseFilters(filterExpression, common.Task)\n\tassert.NoError(t, err)\n\n\tassert.Len(t, taskFilters, 3)\n\tactualFilterExpression, _ := taskFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"foo = ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"123\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"version <> ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"TheWorst\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"bar in (?)\", actualFilterExpression.Query)\n\tassert.Equal(t, []interface{}{\"4\", \"5\", \"6\"}, actualFilterExpression.Args)\n\n\tfilterExpression = \"invalid_function(foo,bar)\"\n\t_, err = ParseFilters(filterExpression, common.Task)\n\tassert.Error(t, err)\n\tassert.EqualError(t, err, \"unrecognized filter function: invalid_function\")\n}", "is_vulnerable": 1}
{"code": "func LoadConfig() (Config, error) {\n\tvar authFilters, decorators []*HandlerConfig\n\tif err := mapstructure.Decode(viper.Get(\"peer.handlers.authFilters\"), &authFilters); err != nil {\n\t\treturn Config{}, err\n\t}\n\n\tif err := mapstructure.Decode(viper.Get(\"peer.handlers.decorators\"), &decorators); err != nil {\n\t\treturn Config{}, err\n\t}\n\n\tendorsers, validators := make(PluginMapping), make(PluginMapping)\n\te := viper.GetStringMap(\"peer.handlers.endorsers\")\n\tfor k := range e {\n\t\tname := viper.GetString(\"peer.handlers.endorsers.\" + k + \".name\")\n\t\tlibrary := viper.GetString(\"peer.handlers.endorsers.\" + k + \".library\")\n\t\tendorsers[k] = &HandlerConfig{Name: name, Library: library}\n\t}\n\n\tv := viper.GetStringMap(\"peer.handlers.validators\")\n\tfor k := range v {\n\t\tname := viper.GetString(\"peer.handlers.validators.\" + k + \".name\")\n\t\tlibrary := viper.GetString(\"peer.handlers.validators.\" + k + \".library\")\n\t\tvalidators[k] = &HandlerConfig{Name: name, Library: library}\n\t}\n\n\tauthenticationTimeWindow := viper.GetDuration(\"peer.authentication.timewindow\")\n\tif authenticationTimeWindow == 0 {\n\t\tdefaultTimeWindow := 15 * time.Minute\n\t\tlogger.Warningf(\"`peer.authentication.timewindow` not set; defaulting to %s\", defaultTimeWindow)\n\t\tauthenticationTimeWindow = defaultTimeWindow\n\t}\n\n\treturn Config{\n\t\tAuthFilters:              authFilters,\n\t\tDecorators:               decorators,\n\t\tEndorsers:                endorsers,\n\t\tValidators:               validators,\n\t\tAuthenticationTimeWindow: authenticationTimeWindow,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (t *DTLSTransport) Start(remoteParameters DTLSParameters) error {\n\t// Take lock and prepare connection, we must not hold the lock\n\t// when connecting\n\tprepareTransport := func() (DTLSRole, *dtls.Config, error) {\n\t\tt.lock.Lock()\n\t\tdefer t.lock.Unlock()\n\n\t\tif err := t.ensureICEConn(); err != nil {\n\t\t\treturn DTLSRole(0), nil, err\n\t\t}\n\n\t\tif t.state != DTLSTransportStateNew {\n\t\t\treturn DTLSRole(0), nil, &rtcerr.InvalidStateError{Err: fmt.Errorf(\"%w: %s\", errInvalidDTLSStart, t.state)}\n\t\t}\n\n\t\tt.srtpEndpoint = t.iceTransport.NewEndpoint(mux.MatchSRTP)\n\t\tt.srtcpEndpoint = t.iceTransport.NewEndpoint(mux.MatchSRTCP)\n\t\tt.remoteParameters = remoteParameters\n\n\t\tcert := t.certificates[0]\n\t\tt.onStateChange(DTLSTransportStateConnecting)\n\n\t\treturn t.role(), &dtls.Config{\n\t\t\tCertificates: []tls.Certificate{\n\t\t\t\t{\n\t\t\t\t\tCertificate: [][]byte{cert.x509Cert.Raw},\n\t\t\t\t\tPrivateKey:  cert.privateKey,\n\t\t\t\t},\n\t\t\t},\n\t\t\tSRTPProtectionProfiles: []dtls.SRTPProtectionProfile{dtls.SRTP_AEAD_AES_128_GCM, dtls.SRTP_AES128_CM_HMAC_SHA1_80},\n\t\t\tClientAuth:             dtls.RequireAnyClientCert,\n\t\t\tLoggerFactory:          t.api.settingEngine.LoggerFactory,\n\t\t\tInsecureSkipVerify:     true,\n\t\t}, nil\n\t}\n\n\tvar dtlsConn *dtls.Conn\n\tdtlsEndpoint := t.iceTransport.NewEndpoint(mux.MatchDTLS)\n\trole, dtlsConfig, err := prepareTransport()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif t.api.settingEngine.replayProtection.DTLS != nil {\n\t\tdtlsConfig.ReplayProtectionWindow = int(*t.api.settingEngine.replayProtection.DTLS)\n\t}\n\n\t// Connect as DTLS Client/Server, function is blocking and we\n\t// must not hold the DTLSTransport lock\n\tif role == DTLSRoleClient {\n\t\tdtlsConn, err = dtls.Client(dtlsEndpoint, dtlsConfig)\n\t} else {\n\t\tdtlsConn, err = dtls.Server(dtlsEndpoint, dtlsConfig)\n\t}\n\n\t// Re-take the lock, nothing beyond here is blocking\n\tt.lock.Lock()\n\tdefer t.lock.Unlock()\n\n\tif err != nil {\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn err\n\t}\n\n\tsrtpProfile, ok := dtlsConn.SelectedSRTPProtectionProfile()\n\tif !ok {\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn ErrNoSRTPProtectionProfile\n\t}\n\n\tswitch srtpProfile {\n\tcase dtls.SRTP_AEAD_AES_128_GCM:\n\t\tt.srtpProtectionProfile = srtp.ProtectionProfileAeadAes128Gcm\n\tcase dtls.SRTP_AES128_CM_HMAC_SHA1_80:\n\t\tt.srtpProtectionProfile = srtp.ProtectionProfileAes128CmHmacSha1_80\n\tdefault:\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn ErrNoSRTPProtectionProfile\n\t}\n\n\tif t.api.settingEngine.disableCertificateFingerprintVerification {\n\t\treturn nil\n\t}\n\n\t// Check the fingerprint if a certificate was exchanged\n\tremoteCerts := dtlsConn.ConnectionState().PeerCertificates\n\tif len(remoteCerts) == 0 {\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn errNoRemoteCertificate\n\t}\n\tt.remoteCertificate = remoteCerts[0]\n\n\tparsedRemoteCert, err := x509.ParseCertificate(t.remoteCertificate)\n\tif err != nil {\n\t\tif closeErr := dtlsConn.Close(); closeErr != nil {\n\t\t\tt.log.Error(err.Error())\n\t\t}\n\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn err\n\t}\n\n\tif err = t.validateFingerPrint(parsedRemoteCert); err != nil {\n\t\tif closeErr := dtlsConn.Close(); closeErr != nil {\n\t\t\tt.log.Error(err.Error())\n\t\t}\n\n\t\tt.onStateChange(DTLSTransportStateFailed)\n\t\treturn err\n\t}\n\n\tt.conn = dtlsConn\n\tt.onStateChange(DTLSTransportStateConnected)\n\n\treturn t.startSRTP()\n}", "is_vulnerable": 0}
{"code": "\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\treturn http.ErrUseLastResponse\n\t\t},\n\t}", "is_vulnerable": 0}
{"code": "func mustEncode(buf []byte, err error) []byte {\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn buf\n}", "is_vulnerable": 0}
{"code": "func desiredLoadBalancerService(ci *operatorv1.IngressController, deploymentRef metav1.OwnerReference, platform *configv1.PlatformStatus, proxyNeeded bool) (bool, *corev1.Service, error) {\n\tif ci.Status.EndpointPublishingStrategy.Type != operatorv1.LoadBalancerServiceStrategyType {\n\t\treturn false, nil, nil\n\t}\n\tservice := manifests.LoadBalancerService()\n\n\tname := controller.LoadBalancerServiceName(ci)\n\n\tservice.Namespace = name.Namespace\n\tservice.Name = name.Name\n\n\tif service.Labels == nil {\n\t\tservice.Labels = map[string]string{}\n\t}\n\tservice.Labels[\"router\"] = name.Name\n\tservice.Labels[manifests.OwningIngressControllerLabel] = ci.Name\n\n\tservice.Spec.Selector = controller.IngressControllerDeploymentPodSelector(ci).MatchLabels\n\n\tisInternal := ci.Status.EndpointPublishingStrategy.LoadBalancer == nil || ci.Status.EndpointPublishingStrategy.LoadBalancer.Scope == operatorv1.InternalLoadBalancer\n\n\tif service.Annotations == nil {\n\t\tservice.Annotations = map[string]string{}\n\t}\n\n\tif proxyNeeded {\n\t\tservice.Annotations[awsLBProxyProtocolAnnotation] = \"*\"\n\t}\n\n\tif platform != nil {\n\t\tif isInternal {\n\t\t\tannotation := InternalLBAnnotations[platform.Type]\n\t\t\tfor name, value := range annotation {\n\t\t\t\tservice.Annotations[name] = value\n\t\t\t}\n\t\t}\n\t\tswitch platform.Type {\n\t\tcase configv1.AWSPlatformType:\n\t\t\tif ci.Status.EndpointPublishingStrategy.LoadBalancer != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.Type == operatorv1.AWSLoadBalancerProvider &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.AWS != nil &&\n\t\t\t\tci.Status.EndpointPublishingStrategy.LoadBalancer.ProviderParameters.AWS.Type == operatorv1.AWSNetworkLoadBalancer {\n\t\t\t\tservice.Annotations[AWSLBTypeAnnotation] = AWSNLBAnnotation\n\t\t\t}\n\t\t\t// Set the load balancer for AWS to be as aggressive as Azure (2 fail @ 5s interval, 2 healthy)\n\t\t\tservice.Annotations[awsLBHealthCheckIntervalAnnotation] = awsLBHealthCheckIntervalDefault\n\t\t\tservice.Annotations[awsLBHealthCheckTimeoutAnnotation] = awsLBHealthCheckTimeoutDefault\n\t\t\tservice.Annotations[awsLBHealthCheckUnhealthyThresholdAnnotation] = awsLBHealthCheckUnhealthyThresholdDefault\n\t\t\tservice.Annotations[awsLBHealthCheckHealthyThresholdAnnotation] = awsLBHealthCheckHealthyThresholdDefault\n\t\tcase configv1.IBMCloudPlatformType:\n\t\t\tif !isInternal {\n\t\t\t\tservice.Annotations[iksLBScopeAnnotation] = iksLBScopePublic\n\t\t\t}\n\t\t}\n\t\t// Azure load balancers are not customizable and are set to (2 fail @ 5s interval, 2 healthy)\n\t\t// GCP load balancers are not customizable and are set to (3 fail @ 8s interval, 1 healthy)\n\t}\n\n\tservice.SetOwnerReferences([]metav1.OwnerReference{deploymentRef})\n\tservice.Finalizers = []string{manifests.LoadBalancerServiceFinalizer}\n\treturn true, service, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetVersion(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Version, error) {\n\tout := new(clientpb.Version)\n\terr := c.cc.Invoke(ctx, SliverRPC_GetVersion_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tbackend.Handle(\"/hello\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\t\thttp.Redirect(w, r, \"https://example.com/there\", code)\n\t\t\t\t}))", "is_vulnerable": 0}
{"code": "func (r *runner) doCheckTimeout() error {\n\tcurrent := time.Now()\n\n\tif current.Before(r.timeoutAt) {\n\t\treturn nil\n\t}\n\n\tif r.re.Debug() {\n\t\t//Debug.WriteLine(\"\")\n\t\t//Debug.WriteLine(\"RegEx match timeout occurred!\")\n\t\t//Debug.WriteLine(\"Specified timeout:       \" + TimeSpan.FromMilliseconds(_timeout).ToString())\n\t\t//Debug.WriteLine(\"Timeout check frequency: \" + TimeoutCheckFrequency)\n\t\t//Debug.WriteLine(\"Search pattern:          \" + _runregex._pattern)\n\t\t//Debug.WriteLine(\"Input:                   \" + r.runtext)\n\t\t//Debug.WriteLine(\"About to throw RegexMatchTimeoutException.\")\n\t}\n\n\treturn fmt.Errorf(\"match timeout after %v on input `%v`\", r.timeout, string(r.runtext))\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_CommonTLSConfigLoadCA(t *testing.T) {\n\tc := NewConfigurator(&Config{})\n\ttlsConf, err := c.commonTLSConfig(false)\n\trequire.NoError(t, err)\n\trequire.Nil(t, tlsConf.RootCAs)\n\trequire.Nil(t, tlsConf.ClientCAs)\n\n\tc.Update(&Config{CAFile: \"/something/bogus\"})\n\t_, err = c.commonTLSConfig(false)\n\trequire.Error(t, err)\n\n\tc.Update(&Config{CAPath: \"/something/bogus/\"})\n\t_, err = c.commonTLSConfig(false)\n\trequire.Error(t, err)\n\n\tc.Update(&Config{CAFile: \"../test/ca/root.cer\"})\n\ttlsConf, err = c.commonTLSConfig(false)\n\trequire.NoError(t, err)\n\trequire.Len(t, tlsConf.RootCAs.Subjects(), 1)\n\trequire.Len(t, tlsConf.ClientCAs.Subjects(), 1)\n\n\tc.Update(&Config{CAPath: \"../test/ca_path\"})\n\ttlsConf, err = c.commonTLSConfig(false)\n\trequire.NoError(t, err)\n\trequire.Len(t, tlsConf.RootCAs.Subjects(), 2)\n\trequire.Len(t, tlsConf.ClientCAs.Subjects(), 2)\n\n\tc.Update(&Config{CAFile: \"../test/ca/root.cer\", CAPath: \"../test/ca_path\"})\n\ttlsConf, err = c.commonTLSConfig(false)\n\trequire.NoError(t, err)\n\trequire.Len(t, tlsConf.RootCAs.Subjects(), 1)\n\trequire.Len(t, tlsConf.ClientCAs.Subjects(), 1)\n}", "is_vulnerable": 1}
{"code": "func Test_Replace(t *testing.T) {\n\tt.Run(\"InvailedTemplate\", func(t *testing.T) {\n\t\t_, err := Replace(\"{{\", nil, false)\n\t\tassert.Error(t, err)\n\t})\n\tt.Run(\"Simple\", func(t *testing.T) {\n\t\tt.Run(\"Valid\", func(t *testing.T) {\n\t\t\tr, err := Replace(\"{{foo}}\", map[string]string{\"foo\": \"bar\"}, false)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, \"bar\", r)\n\t\t})\n\t\tt.Run(\"Unresolved\", func(t *testing.T) {\n\t\t\tt.Run(\"Allowed\", func(t *testing.T) {\n\t\t\t\t_, err := Replace(\"{{foo}}\", nil, true)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})\n\t\t\tt.Run(\"Disallowed\", func(t *testing.T) {\n\t\t\t\t_, err := Replace(\"{{foo}}\", nil, false)\n\t\t\t\tassert.EqualError(t, err, \"failed to resolve {{foo}}\")\n\t\t\t})\n\t\t})\n\t})\n\tt.Run(\"Expression\", func(t *testing.T) {\n\t\tt.Run(\"Valid\", func(t *testing.T) {\n\t\t\tr, err := Replace(\"{{=foo}}\", map[string]string{\"foo\": \"bar\"}, false)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, \"bar\", r)\n\t\t})\n\t\tt.Run(\"Unresolved\", func(t *testing.T) {\n\t\t\tt.Run(\"Allowed\", func(t *testing.T) {\n\t\t\t\t_, err := Replace(\"{{=foo}}\", nil, true)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})\n\t\t\tt.Run(\"AllowedRetries\", func(t *testing.T) {\n\t\t\t\treplaced, err := Replace(\"{{=sprig.int(retries)}}\", nil, true)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t\tassert.Equal(t, replaced, \"{{=sprig.int(retries)}}\")\n\t\t\t})\n\t\t\tt.Run(\"Disallowed\", func(t *testing.T) {\n\t\t\t\t_, err := Replace(\"{{=foo}}\", nil, false)\n\t\t\t\tassert.EqualError(t, err, \"failed to evaluate expression \\\"foo\\\"\")\n\t\t\t})\n\t\t})\n\t\tt.Run(\"Error\", func(t *testing.T) {\n\t\t\t_, err := Replace(\"{{=!}}\", nil, false)\n\t\t\tif assert.Error(t, err) {\n\t\t\t\tassert.Contains(t, err.Error(), \"failed to evaluate expression\")\n\t\t\t}\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "\terr := sigRepo.ListSignatures(ctx, targetDesc, func(signatureManifests []ocispec.Descriptor) error {\n\t\tfor _, sigManifestDesc := range signatureManifests {\n\t\t\tif prevDigest != \"\" {\n\t\t\t\t// check and print title\n\t\t\t\tprintTitle()\n\n\t\t\t\t// print each signature digest\n\t\t\t\tfmt.Printf(\"    \u251c\u2500\u2500 %s\\n\", prevDigest)\n\t\t\t}\n\t\t\tprevDigest = sigManifestDesc.Digest\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "func TestStringMatcherWithPrefix(t *testing.T) {\n\ttestCases := []struct {\n\t\tname   string\n\t\tv      string\n\t\tprefix string\n\t\twant   *matcherpb.StringMatcher\n\t}{\n\t\t{\n\t\t\tname:   \"wildcardAsRequired\",\n\t\t\tv:      \"*\",\n\t\t\tprefix: \"abc\",\n\t\t\twant:   StringMatcherRegex(\".+\"),\n\t\t},\n\t\t{\n\t\t\tname:   \"prefix\",\n\t\t\tv:      \"-prefix-*\",\n\t\t\tprefix: \"abc\",\n\t\t\twant: &matcherpb.StringMatcher{\n\t\t\t\tMatchPattern: &matcherpb.StringMatcher_Prefix{\n\t\t\t\t\tPrefix: \"abc-prefix-\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:   \"suffix-empty-prefix\",\n\t\t\tv:      \"*-suffix\",\n\t\t\tprefix: \"\",\n\t\t\twant: &matcherpb.StringMatcher{\n\t\t\t\tMatchPattern: &matcherpb.StringMatcher_Suffix{\n\t\t\t\t\tSuffix: \"-suffix\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:   \"suffix\",\n\t\t\tv:      \"*-suffix\",\n\t\t\tprefix: \"abc\",\n\t\t\twant:   StringMatcherRegex(\"abc.*-suffix\"),\n\t\t},\n\t\t{\n\t\t\tname:   \"exact\",\n\t\t\tv:      \"-exact\",\n\t\t\tprefix: \"abc\",\n\t\t\twant: &matcherpb.StringMatcher{\n\t\t\t\tMatchPattern: &matcherpb.StringMatcher_Exact{\n\t\t\t\t\tExact: \"abc-exact\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := StringMatcherWithPrefix(tc.v, tc.prefix)\n\t\t\tif !reflect.DeepEqual(*actual, *tc.want) {\n\t\t\t\tt.Errorf(\"want %s but got %s\", tc.want.String(), actual.String())\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f *Ufw) RichRules(rule FireInfo, operation string) error {\n\tswitch rule.Strategy {\n\tcase \"accept\":\n\t\trule.Strategy = \"allow\"\n\tcase \"drop\":\n\t\trule.Strategy = \"deny\"\n\tdefault:\n\t\treturn fmt.Errorf(\"unsupport strategy %s\", rule.Strategy)\n\t}\n\n\tif cmd.CheckIllegal(operation, rule.Protocol, rule.Address, rule.Port) {\n\t\treturn buserr.New(constant.ErrCmdIllegal)\n\t}\n\n\truleStr := fmt.Sprintf(\"%s %s \", f.CmdStr, rule.Strategy)\n\tif operation == \"remove\" {\n\t\truleStr = fmt.Sprintf(\"%s delete %s \", f.CmdStr, rule.Strategy)\n\t}\n\tif len(rule.Protocol) != 0 {\n\t\truleStr += fmt.Sprintf(\"proto %s \", rule.Protocol)\n\t}\n\tif strings.Contains(rule.Address, \"-\") {\n\t\truleStr += fmt.Sprintf(\"from %s to %s \", strings.Split(rule.Address, \"-\")[0], strings.Split(rule.Address, \"-\")[1])\n\t} else {\n\t\truleStr += fmt.Sprintf(\"from %s \", rule.Address)\n\t}\n\tif len(rule.Port) != 0 {\n\t\truleStr += fmt.Sprintf(\"to any port %s \", rule.Port)\n\t}\n\n\tstdout, err := cmd.Exec(ruleStr)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s rich rules failed, err: %s\", operation, stdout)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (fs *UnixFS) Close() error {\n\t// Once closed, change dirfd to something invalid to detect when it has been\n\t// closed.\n\tdefer func() {\n\t\tfs.dirfd.Store(-1)\n\t}()\n\treturn unix.Close(int(fs.dirfd.Load()))\n}", "is_vulnerable": 0}
{"code": "\tctx.resolver.Checkpoint = func(_ ContractResolver,\n\t\treports ...*channeldb.ResolverReport) error {\n\n\t\t// Send all of our reports into the channel.\n\t\tfor _, report := range reports {\n\t\t\treportChan <- report\n\t\t}\n\n\t\treturn nil\n\t}", "is_vulnerable": 0}
{"code": "func TestCheckMountDestFalsePositive(t *testing.T) {\n\tdest := \"/rootfs/sysfiles/fs/cgroup\"\n\terr := checkMountDestination(\"/rootfs\", dest)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"healthz route is excluded\", func(t *testing.T) {\n\t\troute := \"v1.0/healthz\"\n\t\texcluded := ExcludedRoute(route)\n\t\tassert.True(t, excluded)\n\t})", "is_vulnerable": 1}
{"code": "func (g DashboardHandler) Append(router *mux.Router) {\n\tif g.Assets == nil {\n\t\tlog.WithoutContext().Error(\"No assets for dashboard\")\n\t\treturn\n\t}\n\n\t// Expose dashboard\n\trouter.Methods(http.MethodGet).\n\t\tPath(\"/\").\n\t\tHandlerFunc(func(resp http.ResponseWriter, req *http.Request) {\n\t\t\thttp.Redirect(resp, req, safePrefix(req)+\"/dashboard/\", http.StatusFound)\n\t\t})\n\n\trouter.Methods(http.MethodGet).\n\t\tPathPrefix(\"/dashboard/\").\n\t\tHandler(http.StripPrefix(\"/dashboard/\", http.FileServer(g.Assets)))\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tcmd := commands.NewWriteAuthorizationModelCommand(datastore, logger)\n\t\t\tresp, err := cmd.Execute(ctx, test.request)\n\t\t\trequire.ErrorIs(t, err, test.err)\n\n\t\t\tif err == nil {\n\t\t\t\t_, err = ulid.Parse(resp.AuthorizationModelId)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func yaml_parser_remove_simple_key(parser *yaml_parser_t) bool {\n\ti := len(parser.simple_keys) - 1\n\tif parser.simple_keys[i].possible {\n\t\t// If the key is required, it is an error.\n\t\tif parser.simple_keys[i].required {\n\t\t\treturn yaml_parser_set_scanner_error(parser,\n\t\t\t\t\"while scanning a simple key\", parser.simple_keys[i].mark,\n\t\t\t\t\"could not find expected ':'\")\n\t\t}\n\t\t// Remove the key from the stack.\n\t\tparser.simple_keys[i].possible = false\n\t\tdelete(parser.simple_keys_by_tok, parser.simple_keys[i].token_number)\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (m *NinRepStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field3 = append(m.Field3, &NidOptNative{})\n\t\t\tif err := m.Field3[len(m.Field3)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field4 = append(m.Field4, &NinOptNative{})\n\t\t\tif err := m.Field4[len(m.Field4)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field8 = append(m.Field8, &NidOptNative{})\n\t\t\tif err := m.Field8[len(m.Field8)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field14 = append(m.Field14, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.Field15[len(m.Field15)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"should inform each user if they were mentioned by a post\", func(t *testing.T) {\n\t\tmessages1, closeWS1 := connectFakeWebSocket(t, th, th.BasicUser.Id, \"\")\n\t\tdefer closeWS1()\n\n\t\tmessages2, closeWS2 := connectFakeWebSocket(t, th, th.BasicUser2.Id, \"\")\n\t\tdefer closeWS2()\n\n\t\t// First post mentioning the whole channel\n\t\tpost := &model.Post{\n\t\t\tUserId:    sender.Id,\n\t\t\tChannelId: th.BasicChannel.Id,\n\t\t\tMessage:   \"@channel\",\n\t\t}\n\t\t_, err := th.App.SendNotifications(th.Context, post, th.BasicTeam, th.BasicChannel, sender, nil, false)\n\t\trequire.NoError(t, err)\n\n\t\treceived1 := <-messages1\n\t\trequire.Equal(t, model.WebsocketEventPosted, received1.EventType())\n\t\tassertUnmarshalsTo(t, []string{th.BasicUser.Id}, received1.GetData()[\"mentions\"])\n\n\t\treceived2 := <-messages2\n\t\trequire.Equal(t, model.WebsocketEventPosted, received2.EventType())\n\t\tassertUnmarshalsTo(t, []string{th.BasicUser2.Id}, received2.GetData()[\"mentions\"])\n\n\t\t// Second post mentioning both users individually\n\t\tpost = &model.Post{\n\t\t\tUserId:    sender.Id,\n\t\t\tChannelId: th.BasicChannel.Id,\n\t\t\tMessage:   fmt.Sprintf(\"@%s @%s\", th.BasicUser.Username, th.BasicUser2.Username),\n\t\t}\n\t\t_, err = th.App.SendNotifications(th.Context, post, th.BasicTeam, th.BasicChannel, sender, nil, false)\n\t\trequire.NoError(t, err)\n\n\t\treceived1 = <-messages1\n\t\trequire.Equal(t, model.WebsocketEventPosted, received1.EventType())\n\t\tassertUnmarshalsTo(t, []string{th.BasicUser.Id}, received1.GetData()[\"mentions\"])\n\n\t\treceived2 = <-messages2\n\t\trequire.Equal(t, model.WebsocketEventPosted, received2.EventType())\n\t\tassertUnmarshalsTo(t, []string{th.BasicUser2.Id}, received2.GetData()[\"mentions\"])\n\n\t\t// Third post mentioning a single user\n\t\tpost = &model.Post{\n\t\t\tUserId:    sender.Id,\n\t\t\tChannelId: th.BasicChannel.Id,\n\t\t\tMessage:   \"@\" + th.BasicUser.Username,\n\t\t}\n\t\t_, err = th.App.SendNotifications(th.Context, post, th.BasicTeam, th.BasicChannel, sender, nil, false)\n\t\trequire.NoError(t, err)\n\n\t\treceived1 = <-messages1\n\t\trequire.Equal(t, model.WebsocketEventPosted, received1.EventType())\n\t\tassertUnmarshalsTo(t, []string{th.BasicUser.Id}, received1.GetData()[\"mentions\"])\n\n\t\treceived2 = <-messages2\n\t\trequire.Equal(t, model.WebsocketEventPosted, received2.EventType())\n\t\tassert.Nil(t, received2.GetData()[\"mentions\"])\n\t})", "is_vulnerable": 0}
{"code": "\tt.Run(fmt.Sprintf(\"%s %s\", desc, url), func(t *testing.T) {\n\t\tt.Cleanup(bus.ClearBusHandlers)\n\n\t\ths := &HTTPServer{\n\t\t\tCfg:             setting.NewCfg(),\n\t\t\tSQLStore:        sqlStore,\n\t\t\tauthInfoService: &mockAuthInfoService{},\n\t\t}\n\n\t\tsc := setupScenarioContext(t, url)\n\t\tsc.defaultHandler = routing.Wrap(func(c *models.ReqContext) response.Response {\n\t\t\tc.Req.Body = mockRequestBody(cmd)\n\t\t\tc.Req.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tsc.context = c\n\t\t\tsc.context.UserId = testUserID\n\t\t\tsc.context.OrgId = testOrgID\n\t\t\tsc.context.OrgRole = role\n\n\t\t\treturn hs.AdminUpdateUserPermissions(c)\n\t\t})\n\n\t\tsc.m.Put(routePattern, sc.defaultHandler)\n\n\t\tfn(sc)\n\t})\n}", "is_vulnerable": 0}
{"code": "func introducerCast(e eval, col collations.ID) (*evalBytes, error) {\n\tif col == collations.CollationBinaryID {\n\t\treturn evalToBinary(e), nil\n\t}\n\n\tvar bytes []byte\n\tif b, ok := e.(*evalBytes); !ok {\n\t\tbytes = b.ToRawBytes()\n\t} else {\n\t\tcs := colldata.Lookup(col).Charset()\n\t\tbytes = b.bytes\n\t\t// We only need to pad here for encodings that have a minimum\n\t\t// character byte width larger than 1, which is all UTF-16\n\t\t// variations and UTF-32.\n\t\tswitch cs.(type) {\n\t\tcase charset.Charset_utf16, charset.Charset_utf16le, charset.Charset_ucs2:\n\t\t\tif len(bytes)%2 != 0 {\n\t\t\t\tbytes = append([]byte{0}, bytes...)\n\t\t\t}\n\t\tcase charset.Charset_utf32:\n\t\t\tif mod := len(bytes) % 4; mod != 0 {\n\t\t\t\tbytes = append(make([]byte, 4-mod), bytes...)\n\t\t\t}\n\t\t}\n\t}\n\ttypedcol := collations.TypedCollation{\n\t\tCollation:    col,\n\t\tCoercibility: collations.CoerceCoercible,\n\t\tRepertoire:   collations.RepertoireASCII,\n\t}\n\treturn newEvalText(bytes, typedcol), nil\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) Get(ctx context.Context, resourceGroupName string, deploymentName string) (result DeploymentExtended, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.DeploymentsClient\", \"Get\", err.Error())\n\t}\n\n\treq, err := client.GetPreparer(ctx, resourceGroupName, deploymentName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Get\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.GetSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Get\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.GetResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Get\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "\ttlsConfig.GetClientCertificate = func(*tls.CertificateRequestInfo) (*tls.Certificate, error) {\n\t\treturn c.cert, nil\n\t}", "is_vulnerable": 0}
{"code": "func (_ *NodeInfo) FillAuthzContext(_ *acl.AuthorizerContext) {}", "is_vulnerable": 1}
{"code": "func TestSignature(t *testing.T) {\n\tlayer, err := random.Layer(300 /* byteSize */, types.DockerLayer)\n\tif err != nil {\n\t\tt.Fatalf(\"random.Layer() = %v\", err)\n\t}\n\tdigest, err := layer.Digest()\n\tif err != nil {\n\t\tt.Fatalf(\"Digest() = %v\", err)\n\t}\n\n\ttests := []struct {\n\t\tname           string\n\t\tl              *sigLayer\n\t\tenv            map[string]string\n\t\twantPayloadErr error\n\t\twantSig        string\n\t\twantSigErr     error\n\t\twantCert       bool\n\t\twantCertErr    error\n\t\twantChain      int\n\t\twantChainErr   error\n\t\twantBundle     *bundle.RekorBundle\n\t\twantBundleErr  error\n\t}{{\n\t\tname: \"just payload and signature\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"blah\",\n\t}, {\n\t\tname: \"with empty other keys\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:    \"blah\",\n\t\t\t\t\tcertkey:   \"\",\n\t\t\t\t\tchainkey:  \"\",\n\t\t\t\t\tBundleKey: \"\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"blah\",\n\t}, {\n\t\tname: \"missing signature\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t},\n\t\t},\n\t\twantSigErr: fmt.Errorf(\"signature layer %s is missing %q annotation\", digest, sigkey),\n\t}, {\n\t\tname: \"min plus bad bundle\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:    \"blah\",\n\t\t\t\t\tBundleKey: `}`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:       \"blah\",\n\t\twantBundleErr: errors.New(`unmarshaling bundle: invalid character '}' looking for beginning of value`),\n\t}, {\n\t\tname: \"min plus bad cert\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:  \"blah\",\n\t\t\t\t\tcertkey: `GARBAGE`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:     \"blah\",\n\t\twantCertErr: errors.New(`error during PEM decoding`),\n\t}, {\n\t\tname: \"min plus bad chain\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:   \"blah\",\n\t\t\t\t\tchainkey: `GARBAGE`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:      \"blah\",\n\t\twantChainErr: errors.New(`error during PEM decoding`),\n\t}, {\n\t\tname: \"min plus bundle\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t\t// This was extracted from gcr.io/distroless/static:nonroot on 2021/09/16.\n\t\t\t\t\t// The Body has been removed for brevity\n\t\t\t\t\tBundleKey: `{\"SignedEntryTimestamp\":\"MEUCIQClUkUqZNf+6dxBc/pxq22JIluTB7Kmip1G0FIF5E0C1wIgLqXm+IM3JYW/P/qjMZSXW+J8bt5EOqNfe3R+0A9ooFE=\",\"Payload\":{\"body\":\"REMOVED\",\"integratedTime\":1631646761,\"logIndex\":693591,\"logID\":\"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\"}}`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"blah\",\n\t\twantBundle: &bundle.RekorBundle{\n\t\t\tSignedEntryTimestamp: mustDecode(\"MEUCIQClUkUqZNf+6dxBc/pxq22JIluTB7Kmip1G0FIF5E0C1wIgLqXm+IM3JYW/P/qjMZSXW+J8bt5EOqNfe3R+0A9ooFE=\"),\n\t\t\tPayload: bundle.RekorPayload{\n\t\t\t\tBody:           \"REMOVED\",\n\t\t\t\tIntegratedTime: 1631646761,\n\t\t\t\tLogIndex:       693591,\n\t\t\t\tLogID:          \"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\",\n\t\t\t},\n\t\t},\n\t}, {\n\t\tname: \"min plus good cert\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t\t// This was extracted from gcr.io/distroless/static:nonroot on 2021/09/16\n\t\t\t\t\tcertkey: `\n-----BEGIN CERTIFICATE-----\nMIICjzCCAhSgAwIBAgITV2heiswW9YldtVEAu98QxDO8TTAKBggqhkjOPQQDAzAq\nMRUwEwYDVQQKEwxzaWdzdG9yZS5kZXYxETAPBgNVBAMTCHNpZ3N0b3JlMB4XDTIx\nMDkxNDE5MTI0MFoXDTIxMDkxNDE5MzIzOVowADBZMBMGByqGSM49AgEGCCqGSM49\nAwEHA0IABMF1AWZcfvubslc4ABNnvGbRjm6GWVHxrJ1RRthTHMCE4FpFmiHQBfGt\n6n80DqszGj77Whb35O33+Dal4Y2po+CjggFBMIIBPTAOBgNVHQ8BAf8EBAMCB4Aw\nEwYDVR0lBAwwCgYIKwYBBQUHAwMwDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQU340G\n3G1ozVNmFC5TBFV0yNuouvowHwYDVR0jBBgwFoAUyMUdAEGaJCkyUSTrDa5K7UoG\n0+wwgY0GCCsGAQUFBwEBBIGAMH4wfAYIKwYBBQUHMAKGcGh0dHA6Ly9wcml2YXRl\nY2EtY29udGVudC02MDNmZTdlNy0wMDAwLTIyMjctYmY3NS1mNGY1ZTgwZDI5NTQu\nc3RvcmFnZS5nb29nbGVhcGlzLmNvbS9jYTM2YTFlOTYyNDJiOWZjYjE0Ni9jYS5j\ncnQwOAYDVR0RAQH/BC4wLIEqa2V5bGVzc0BkaXN0cm9sZXNzLmlhbS5nc2Vydmlj\nZWFjY291bnQuY29tMAoGCCqGSM49BAMDA2kAMGYCMQDcH9cdkxW6ugsbPHqX9qrM\nwlMaprcwnlktS3+5xuABr5icuqwrB/Fj5doFtS7AnM0CMQD9MjSaUmHFFF7zoLMx\nuThR1Z6JuA21HwxtL3GyJ8UQZcEPOlTBV593HrSAwBhiCoY=\n-----END CERTIFICATE-----\n`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:  \"blah\",\n\t\twantCert: true,\n\t}, {\n\t\tname: \"min plus bad chain\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t\t// This was extracted from gcr.io/distroless/static:nonroot on 2021/09/16\n\t\t\t\t\tchainkey: `\n-----BEGIN CERTIFICATE-----\nMIIB+DCCAX6gAwIBAgITNVkDZoCiofPDsy7dfm6geLbuhzAKBggqhkjOPQQDAzAq\nMRUwEwYDVQQKEwxzaWdzdG9yZS5kZXYxETAPBgNVBAMTCHNpZ3N0b3JlMB4XDTIx\nMDMwNzAzMjAyOVoXDTMxMDIyMzAzMjAyOVowKjEVMBMGA1UEChMMc2lnc3RvcmUu\nZGV2MREwDwYDVQQDEwhzaWdzdG9yZTB2MBAGByqGSM49AgEGBSuBBAAiA2IABLSy\nA7Ii5k+pNO8ZEWY0ylemWDowOkNa3kL+GZE5Z5GWehL9/A9bRNA3RbrsZ5i0Jcas\ntaRL7Sp5fp/jD5dxqc/UdTVnlvS16an+2Yfswe/QuLolRUCrcOE2+2iA5+tzd6Nm\nMGQwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8CAQEwHQYDVR0OBBYE\nFMjFHQBBmiQpMlEk6w2uSu1KBtPsMB8GA1UdIwQYMBaAFMjFHQBBmiQpMlEk6w2u\nSu1KBtPsMAoGCCqGSM49BAMDA2gAMGUCMH8liWJfMui6vXXBhjDgY4MwslmN/TJx\nVe/83WrFomwmNf056y1X48F9c4m3a3ozXAIxAKjRay5/aj/jsKKGIkmQatjI8uup\nHr/+CxFvaJWmpYqNkLDGRU+9orzh5hI2RrcuaQ==\n-----END CERTIFICATE-----\n`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:   \"blah\",\n\t\twantChain: 1,\n\t}, {\n\t\tname: \"payload size exceeds default limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: &mockLayer{size: 134217728 + 42}, // 128MB + 42 bytes\n\t\t},\n\t\twantPayloadErr: errors.New(\"size of layer (134217770) exceeded the limit (134217728)\"),\n\t}, {\n\t\tname: \"payload size exceeds overridden limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: &mockLayer{size: 1000000000 + 42}, // 1GB + 42 bytes\n\t\t},\n\t\tenv:            map[string]string{\"COSIGN_MAX_ATTACHMENT_SIZE\": \"1GB\"},\n\t\twantPayloadErr: errors.New(\"size of layer (1000000042) exceeded the limit (1000000000)\"),\n\t}, {\n\t\tname: \"payload size is within overridden limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tenv:     map[string]string{\"COSIGN_MAX_ATTACHMENT_SIZE\": \"5KB\"},\n\t\twantSig: \"blah\",\n\t}}", "is_vulnerable": 0}
{"code": "func (c *Context) TextMode() bool {\n\treturn C.gpgme_get_textmode(c.ctx) != 0\n}", "is_vulnerable": 1}
{"code": "func blobSASStringToSign(signedPermissions, signedStart, signedExpiry, canonicalizedResource, signedIdentifier, signedIP, protocols, signedVersion, signedResource, signedSnapshotTime string, headers OverrideHeaders) (string, error) {\n\trscc := headers.CacheControl\n\trscd := headers.ContentDisposition\n\trsce := headers.ContentEncoding\n\trscl := headers.ContentLanguage\n\trsct := headers.ContentType\n\n\tif signedVersion >= \"2015-02-21\" {\n\t\tcanonicalizedResource = \"/blob\" + canonicalizedResource\n\t}\n\n\t// https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n\tif signedVersion >= \"2018-11-09\" {\n\t\treturn fmt.Sprintf(\"%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\", signedPermissions, signedStart, signedExpiry, canonicalizedResource, signedIdentifier, signedIP, protocols, signedVersion, signedResource, signedSnapshotTime, rscc, rscd, rsce, rscl, rsct), nil\n\t}\n\n\t// https://msdn.microsoft.com/en-us/library/azure/dn140255.aspx#Anchor_12\n\tif signedVersion >= \"2015-04-05\" {\n\t\treturn fmt.Sprintf(\"%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\", signedPermissions, signedStart, signedExpiry, canonicalizedResource, signedIdentifier, signedIP, protocols, signedVersion, rscc, rscd, rsce, rscl, rsct), nil\n\t}\n\n\t// reference: http://msdn.microsoft.com/en-us/library/azure/dn140255.aspx\n\tif signedVersion >= \"2013-08-15\" {\n\t\treturn fmt.Sprintf(\"%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\", signedPermissions, signedStart, signedExpiry, canonicalizedResource, signedIdentifier, signedVersion, rscc, rscd, rsce, rscl, rsct), nil\n\t}\n\n\treturn \"\", errors.New(\"storage: not implemented SAS for versions earlier than 2013-08-15\")\n}", "is_vulnerable": 0}
{"code": "func NewProxy(ctx context.Context, config *v2.Proxy) Proxy {\n\tproxy := &proxy{\n\t\tconfig:         config,\n\t\tclusterManager: cluster.GetClusterMngAdapterInstance().ClusterManager,\n\t\tactiveStreams:  list.New(),\n\t\tstats:          globalStats,\n\t\tcontext:        ctx,\n\t\taccessLogs:     mosnctx.Get(ctx, types.ContextKeyAccessLogs).([]api.AccessLog),\n\t}\n\n\t// proxy level worker pool config\n\tif config.ConcurrencyNum > 0 {\n\t\tproxy.workerpool = mosnsync.NewWorkerPool(config.ConcurrencyNum)\n\t}\n\t// proxy level worker pool config end\n\n\tif len(proxy.config.ExtendConfig) != 0 {\n\t\tproxy.context = mosnctx.WithValue(proxy.context, types.ContextKeyProxyGeneralConfig, proxy.config.ExtendConfig)\n\t\tif log.DefaultLogger.GetLogLevel() >= log.TRACE {\n\t\t\tlog.DefaultLogger.Tracef(\"[proxy] extend config proxyGeneralExtendConfig = %v\", proxy.config.ExtendConfig)\n\t\t}\n\n\t\tif v, ok := proxy.config.ExtendConfig[\"sub_protocol\"]; ok {\n\t\t\tif subProtocol, ok := v.(string); ok {\n\t\t\t\tproxy.context = mosnctx.WithValue(proxy.context, types.ContextSubProtocol, subProtocol)\n\t\t\t\tif log.DefaultLogger.GetLogLevel() >= log.TRACE {\n\t\t\t\t\tlog.DefaultLogger.Tracef(\"[proxy] extend config subprotocol = %v\", subProtocol)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tlistenerName := mosnctx.Get(ctx, types.ContextKeyListenerName).(string)\n\tproxy.listenerStats = newListenerStats(listenerName)\n\n\tif routersWrapper := router.GetRoutersMangerInstance().GetRouterWrapperByName(proxy.config.RouterConfigName); routersWrapper != nil {\n\t\tproxy.routersWrapper = routersWrapper\n\t} else {\n\t\tlog.DefaultLogger.Alertf(\"proxy.config\", \"[proxy] RouterConfigName:%s doesn't exit\", proxy.config.RouterConfigName)\n\t}\n\n\tproxy.downstreamListener = &downstreamCallbacks{\n\t\tproxy: proxy,\n\t}\n\n\tproxy.streamFilterFactory = streamfilter.GetStreamFilterManager().GetStreamFilterFactory(listenerName)\n\tproxy.routeHandlerFactory = router.GetMakeHandlerFunc(proxy.config.RouterHandlerName)\n\n\treturn proxy\n}", "is_vulnerable": 1}
{"code": "func (p *BinaryProtocol) ReadListBegin() (elemType Type, size int, err error) {\n\tb, e := p.ReadByte()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\telemType = Type(b)\n\tsize32, e := p.ReadI32()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\tif size32 < 0 {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tif uint64(size32) > p.trans.RemainingBytes() || p.trans.RemainingBytes() == UnknownRemaining {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tsize = int(size32)\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func NotRegexp(t TestingT, rx interface{}, str interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotRegexp(t, rx, str, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func setCredentials(userName string, pw string, w http.ResponseWriter) {\n\tvalue := map[string]string{\n\t\t\"user\":   userName,\n\t\t\"passwd\": pw,\n\t}\n\tif encoded, err := cookieHandler.Encode(\"Credentials\", value); err == nil {\n\t\tcookie := &http.Cookie{\n\t\t\tName:  \"Credentials\",\n\t\t\tValue: encoded,\n\t\t\tPath:  \"/\",\n\t\t}\n\t\thttp.SetCookie(w, cookie)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *Runtime) setupRootlessNetNS(ctr *Container) (err error) {\n\tpath := r.config.NetworkCmdPath\n\n\tif path == \"\" {\n\t\tvar err error\n\t\tpath, err = exec.LookPath(\"slirp4netns\")\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"could not find slirp4netns, the network namespace won't be configured: %v\", err)\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tsyncR, syncW, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open pipe\")\n\t}\n\tdefer errorhandling.CloseQuiet(syncR)\n\tdefer errorhandling.CloseQuiet(syncW)\n\n\thavePortMapping := len(ctr.Config().PortMappings) > 0\n\tapiSocket := filepath.Join(ctr.runtime.config.TmpDir, fmt.Sprintf(\"%s.net\", ctr.config.ID))\n\tlogPath := filepath.Join(ctr.runtime.config.TmpDir, fmt.Sprintf(\"slirp4netns-%s.log\", ctr.config.ID))\n\n\tcmdArgs := []string{}\n\tif havePortMapping {\n\t\tcmdArgs = append(cmdArgs, \"--api-socket\", apiSocket)\n\t}\n\tdhp, mtu, sandbox, err := checkSlirpFlags(path)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error checking slirp4netns binary %s: %q\", path, err)\n\t}\n\tif dhp {\n\t\tcmdArgs = append(cmdArgs, \"--disable-host-loopback\")\n\t}\n\tif mtu {\n\t\tcmdArgs = append(cmdArgs, \"--mtu\", \"65520\")\n\t}\n\tif sandbox {\n\t\tcmdArgs = append(cmdArgs, \"--enable-sandbox\")\n\t}\n\n\t// the slirp4netns arguments being passed are describes as follows:\n\t// from the slirp4netns documentation: https://github.com/rootless-containers/slirp4netns\n\t// -c, --configure Brings up the tap interface\n\t// -e, --exit-fd=FD specify the FD for terminating slirp4netns\n\t// -r, --ready-fd=FD specify the FD to write to when the initialization steps are finished\n\tcmdArgs = append(cmdArgs, \"-c\", \"-e\", \"3\", \"-r\", \"4\")\n\tif !ctr.config.PostConfigureNetNS {\n\t\tctr.rootlessSlirpSyncR, ctr.rootlessSlirpSyncW, err = os.Pipe()\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to create rootless network sync pipe\")\n\t\t}\n\t\tcmdArgs = append(cmdArgs, \"--netns-type=path\", ctr.state.NetNS.Path(), \"tap0\")\n\t} else {\n\t\tdefer errorhandling.CloseQuiet(ctr.rootlessSlirpSyncR)\n\t\tdefer errorhandling.CloseQuiet(ctr.rootlessSlirpSyncW)\n\t\tcmdArgs = append(cmdArgs, fmt.Sprintf(\"%d\", ctr.state.PID), \"tap0\")\n\t}\n\n\tcmd := exec.Command(path, cmdArgs...)\n\tlogrus.Debugf(\"slirp4netns command: %s\", strings.Join(cmd.Args, \" \"))\n\tcmd.SysProcAttr = &syscall.SysProcAttr{\n\t\tSetpgid: true,\n\t}\n\n\t// workaround for https://github.com/rootless-containers/slirp4netns/pull/153\n\tif sandbox {\n\t\tcmd.SysProcAttr.Cloneflags = syscall.CLONE_NEWNS\n\t\tcmd.SysProcAttr.Unshareflags = syscall.CLONE_NEWNS\n\t}\n\n\t// Leak one end of the pipe in slirp4netns, the other will be sent to conmon\n\tcmd.ExtraFiles = append(cmd.ExtraFiles, ctr.rootlessSlirpSyncR, syncW)\n\n\tlogFile, err := os.Create(logPath)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open slirp4netns log file %s\", logPath)\n\t}\n\tdefer logFile.Close()\n\t// Unlink immediately the file so we won't need to worry about cleaning it up later.\n\t// It is still accessible through the open fd logFile.\n\tif err := os.Remove(logPath); err != nil {\n\t\treturn errors.Wrapf(err, \"delete file %s\", logPath)\n\t}\n\tcmd.Stdout = logFile\n\tcmd.Stderr = logFile\n\tif err := cmd.Start(); err != nil {\n\t\treturn errors.Wrapf(err, \"failed to start slirp4netns process\")\n\t}\n\tdefer func() {\n\t\tif err := cmd.Process.Release(); err != nil {\n\t\t\tlogrus.Errorf(\"unable to release comman process: %q\", err)\n\t\t}\n\t}()\n\n\tb := make([]byte, 16)\n\tfor {\n\t\tif err := syncR.SetDeadline(time.Now().Add(1 * time.Second)); err != nil {\n\t\t\treturn errors.Wrapf(err, \"error setting slirp4netns pipe timeout\")\n\t\t}\n\t\tif _, err := syncR.Read(b); err == nil {\n\t\t\tbreak\n\t\t} else {\n\t\t\tif os.IsTimeout(err) {\n\t\t\t\t// Check if the process is still running.\n\t\t\t\tvar status syscall.WaitStatus\n\t\t\t\tpid, err := syscall.Wait4(cmd.Process.Pid, &status, syscall.WNOHANG, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn errors.Wrapf(err, \"failed to read slirp4netns process status\")\n\t\t\t\t}\n\t\t\t\tif pid != cmd.Process.Pid {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif status.Exited() {\n\t\t\t\t\t// Seek at the beginning of the file and read all its content\n\t\t\t\t\tif _, err := logFile.Seek(0, 0); err != nil {\n\t\t\t\t\t\tlogrus.Errorf(\"could not seek log file: %q\", err)\n\t\t\t\t\t}\n\t\t\t\t\tlogContent, err := ioutil.ReadAll(logFile)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn errors.Wrapf(err, \"slirp4netns failed\")\n\t\t\t\t\t}\n\t\t\t\t\treturn errors.Errorf(\"slirp4netns failed: %q\", logContent)\n\t\t\t\t}\n\t\t\t\tif status.Signaled() {\n\t\t\t\t\treturn errors.New(\"slirp4netns killed by signal\")\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn errors.Wrapf(err, \"failed to read from slirp4netns sync pipe\")\n\t\t}\n\t}\n\n\tif havePortMapping {\n\t\tconst pidWaitTimeout = 60 * time.Second\n\t\tchWait := make(chan error)\n\t\tgo func() {\n\t\t\tinterval := 25 * time.Millisecond\n\t\t\tfor i := time.Duration(0); i < pidWaitTimeout; i += interval {\n\t\t\t\t// Check if the process is still running.\n\t\t\t\tvar status syscall.WaitStatus\n\t\t\t\tpid, err := syscall.Wait4(cmd.Process.Pid, &status, syscall.WNOHANG, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif pid != cmd.Process.Pid {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif status.Exited() || status.Signaled() {\n\t\t\t\t\tchWait <- fmt.Errorf(\"slirp4netns exited with status %d\", status.ExitStatus())\n\t\t\t\t}\n\t\t\t\ttime.Sleep(interval)\n\t\t\t}\n\t\t}()\n\t\tdefer close(chWait)\n\n\t\t// wait that API socket file appears before trying to use it.\n\t\tif _, err := WaitForFile(apiSocket, chWait, pidWaitTimeout); err != nil {\n\t\t\treturn errors.Wrapf(err, \"waiting for slirp4nets to create the api socket file %s\", apiSocket)\n\t\t}\n\n\t\t// for each port we want to add we need to open a connection to the slirp4netns control socket\n\t\t// and send the add_hostfwd command.\n\t\tfor _, i := range ctr.config.PortMappings {\n\t\t\tconn, err := net.Dial(\"unix\", apiSocket)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"cannot open connection to %s\", apiSocket)\n\t\t\t}\n\t\t\tdefer func() {\n\t\t\t\tif err := conn.Close(); err != nil {\n\t\t\t\t\tlogrus.Errorf(\"unable to close connection: %q\", err)\n\t\t\t\t}\n\t\t\t}()\n\t\t\thostIP := i.HostIP\n\t\t\tif hostIP == \"\" {\n\t\t\t\thostIP = \"0.0.0.0\"\n\t\t\t}\n\t\t\tcmd := slirp4netnsCmd{\n\t\t\t\tExecute: \"add_hostfwd\",\n\t\t\t\tArgs: slirp4netnsCmdArg{\n\t\t\t\t\tProto:     i.Protocol,\n\t\t\t\t\tHostAddr:  hostIP,\n\t\t\t\t\tHostPort:  i.HostPort,\n\t\t\t\t\tGuestPort: i.ContainerPort,\n\t\t\t\t},\n\t\t\t}\n\t\t\t// create the JSON payload and send it.  Mark the end of request shutting down writes\n\t\t\t// to the socket, as requested by slirp4netns.\n\t\t\tdata, err := json.Marshal(&cmd)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"cannot marshal JSON for slirp4netns\")\n\t\t\t}\n\t\t\tif _, err := conn.Write([]byte(fmt.Sprintf(\"%s\\n\", data))); err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"cannot write to control socket %s\", apiSocket)\n\t\t\t}\n\t\t\tif err := conn.(*net.UnixConn).CloseWrite(); err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"cannot shutdown the socket %s\", apiSocket)\n\t\t\t}\n\t\t\tbuf := make([]byte, 2048)\n\t\t\treadLength, err := conn.Read(buf)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"cannot read from control socket %s\", apiSocket)\n\t\t\t}\n\t\t\t// if there is no 'error' key in the received JSON data, then the operation was\n\t\t\t// successful.\n\t\t\tvar y map[string]interface{}\n\t\t\tif err := json.Unmarshal(buf[0:readLength], &y); err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"error parsing error status from slirp4netns\")\n\t\t\t}\n\t\t\tif e, found := y[\"error\"]; found {\n\t\t\t\treturn errors.Errorf(\"error from slirp4netns while setting up port redirection: %v\", e)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *SourceContext) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowSourceContext\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: SourceContext: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: SourceContext: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FileName\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowSourceContext\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthSourceContext\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthSourceContext\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FileName = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipSourceContext(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthSourceContext\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (src *Terminate) Encode(dst []byte) []byte {\n\treturn append(dst, 'X', 0, 0, 0, 4)\n}", "is_vulnerable": 1}
{"code": "func (r *Runtime) setupRootlessPortMappingViaRLK(ctr *Container, netnsPath string) error {\n\tsyncR, syncW, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open pipe\")\n\t}\n\tdefer errorhandling.CloseQuiet(syncR)\n\tdefer errorhandling.CloseQuiet(syncW)\n\n\tlogPath := filepath.Join(ctr.runtime.config.Engine.TmpDir, fmt.Sprintf(\"rootlessport-%s.log\", ctr.config.ID))\n\tlogFile, err := os.Create(logPath)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open rootlessport log file %s\", logPath)\n\t}\n\tdefer logFile.Close()\n\t// Unlink immediately the file so we won't need to worry about cleaning it up later.\n\t// It is still accessible through the open fd logFile.\n\tif err := os.Remove(logPath); err != nil {\n\t\treturn errors.Wrapf(err, \"delete file %s\", logPath)\n\t}\n\n\tif !ctr.config.PostConfigureNetNS {\n\t\tctr.rootlessPortSyncR, ctr.rootlessPortSyncW, err = os.Pipe()\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to create rootless port sync pipe\")\n\t\t}\n\t}\n\n\tcfg := rootlessport.Config{\n\t\tMappings:  ctr.config.PortMappings,\n\t\tNetNSPath: netnsPath,\n\t\tExitFD:    3,\n\t\tReadyFD:   4,\n\t\tTmpDir:    ctr.runtime.config.Engine.TmpDir,\n\t\tChildIP:   \"10.0.2.100\",\n\t}\n\tcfgJSON, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcfgR := bytes.NewReader(cfgJSON)\n\tvar stdout bytes.Buffer\n\tcmd := exec.Command(fmt.Sprintf(\"/proc/%d/exe\", os.Getpid()))\n\tcmd.Args = []string{rootlessport.ReexecKey}\n\t// Leak one end of the pipe in rootlessport process, the other will be sent to conmon\n\n\tif ctr.rootlessPortSyncR != nil {\n\t\tdefer errorhandling.CloseQuiet(ctr.rootlessPortSyncR)\n\t}\n\n\tcmd.ExtraFiles = append(cmd.ExtraFiles, ctr.rootlessPortSyncR, syncW)\n\tcmd.Stdin = cfgR\n\t// stdout is for human-readable error, stderr is for debug log\n\tcmd.Stdout = &stdout\n\tcmd.Stderr = io.MultiWriter(logFile, &logrusDebugWriter{\"rootlessport: \"})\n\tcmd.SysProcAttr = &syscall.SysProcAttr{\n\t\tSetpgid: true,\n\t}\n\tif err := cmd.Start(); err != nil {\n\t\treturn errors.Wrapf(err, \"failed to start rootlessport process\")\n\t}\n\tdefer func() {\n\t\tif err := cmd.Process.Release(); err != nil {\n\t\t\tlogrus.Errorf(\"unable to release rootlessport process: %q\", err)\n\t\t}\n\t}()\n\tif err := waitForSync(syncR, cmd, logFile, 3*time.Second); err != nil {\n\t\tstdoutStr := stdout.String()\n\t\tif stdoutStr != \"\" {\n\t\t\t// err contains full debug log and too verbose, so return stdoutStr\n\t\t\tlogrus.Debug(err)\n\t\t\treturn errors.Errorf(\"rootlessport \" + strings.TrimSuffix(stdoutStr, \"\\n\"))\n\t\t}\n\t\treturn err\n\t}\n\tlogrus.Debug(\"rootlessport is ready\")\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerMissingAppsFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: foo\n`\n\td := emptyContainer(c)\n\t// snapdir is empty: no apps\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(d, info, discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n}", "is_vulnerable": 1}
{"code": "\turlForPath := func(absPath string) (string, bool) {\n\t\tif relPath, ok := h.fs.Rel(h.servedir, absPath); ok {\n\t\t\tpublicPath := h.publicPath\n\t\t\tslash := \"/\"\n\t\t\tif publicPath != \"\" && strings.HasSuffix(h.publicPath, \"/\") {\n\t\t\t\tslash = \"\"\n\t\t\t}\n\t\t\treturn fmt.Sprintf(\"%s%s%s\", publicPath, slash, strings.ReplaceAll(relPath, \"\\\\\", \"/\")), true\n\t\t}\n\t\treturn \"\", false\n\t}", "is_vulnerable": 0}
{"code": "func newHashTrie(batch ethdb.Batch) *hashTrie {\n\treturn &hashTrie{tr: trie.NewStackTrie(func(path []byte, hash common.Hash, blob []byte) {\n\t\trawdb.WriteLegacyTrieNode(batch, hash, blob)\n\t})}\n}", "is_vulnerable": 0}
{"code": "\tenableFeatureGate := func(featureGate string) {\n\t\ttestutils.UpdateFakeClusterConfig(configMapInformer, &k8sv1.ConfigMap{\n\t\t\tData: map[string]string{virtconfig.FeatureGatesKey: featureGate},\n\t\t})\n\t}", "is_vulnerable": 0}
{"code": "func (m *NinOptEnumDefault) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptEnumDefault: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptEnumDefault: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v TheTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= TheTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v YetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field2 = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v YetYetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field3 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (config *CreateConfig) createConfigToOCISpec(runtime *libpod.Runtime, userMounts []spec.Mount) (*spec.Spec, error) {\n\tcgroupPerm := \"ro\"\n\tg, err := generate.New(\"linux\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Remove the default /dev/shm mount to ensure we overwrite it\n\tg.RemoveMount(\"/dev/shm\")\n\tg.HostSpecific = true\n\taddCgroup := true\n\tcanMountSys := true\n\n\tisRootless := rootless.IsRootless()\n\tinUserNS := config.User.InNS(isRootless)\n\n\tif inUserNS && config.Network.NetMode.IsHost() {\n\t\tcanMountSys = false\n\t}\n\n\tif config.Security.Privileged && canMountSys {\n\t\tcgroupPerm = \"rw\"\n\t\tg.RemoveMount(\"/sys\")\n\t\tsysMnt := spec.Mount{\n\t\t\tDestination: \"/sys\",\n\t\t\tType:        \"sysfs\",\n\t\t\tSource:      \"sysfs\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", \"rw\"},\n\t\t}\n\t\tg.AddMount(sysMnt)\n\t} else if !canMountSys {\n\t\taddCgroup = false\n\t\tg.RemoveMount(\"/sys\")\n\t\tr := \"ro\"\n\t\tif config.Security.Privileged {\n\t\t\tr = \"rw\"\n\t\t}\n\t\tsysMnt := spec.Mount{\n\t\t\tDestination: \"/sys\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/sys\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", r, \"rbind\"},\n\t\t}\n\t\tg.AddMount(sysMnt)\n\t\tif !config.Security.Privileged && isRootless {\n\t\t\tg.AddLinuxMaskedPaths(\"/sys/kernel\")\n\t\t}\n\t}\n\tvar runtimeConfig *cconfig.Config\n\n\tif runtime != nil {\n\t\truntimeConfig, err = runtime.GetConfig()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tg.Config.Process.Capabilities.Bounding = runtimeConfig.Containers.DefaultCapabilities\n\t\tsysctls, err := util.ValidateSysctls(runtimeConfig.Containers.DefaultSysctls)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor name, val := range config.Security.Sysctl {\n\t\t\tsysctls[name] = val\n\t\t}\n\t\tconfig.Security.Sysctl = sysctls\n\t\tif !util.StringInSlice(\"host\", config.Resources.Ulimit) {\n\t\t\tconfig.Resources.Ulimit = append(runtimeConfig.Containers.DefaultUlimits, config.Resources.Ulimit...)\n\t\t}\n\t\tif config.Resources.PidsLimit < 0 && !config.cgroupDisabled() {\n\t\t\tconfig.Resources.PidsLimit = runtimeConfig.Containers.PidsLimit\n\t\t}\n\n\t} else {\n\t\tg.Config.Process.Capabilities.Bounding = cconfig.DefaultCapabilities\n\t\tif config.Resources.PidsLimit < 0 && !config.cgroupDisabled() {\n\t\t\tconfig.Resources.PidsLimit = cconfig.DefaultPidsLimit\n\t\t}\n\t}\n\n\tgid5Available := true\n\tif isRootless {\n\t\tnGids, err := GetAvailableGids()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tgid5Available = nGids >= 5\n\t}\n\t// When using a different user namespace, check that the GID 5 is mapped inside\n\t// the container.\n\tif gid5Available && len(config.User.IDMappings.GIDMap) > 0 {\n\t\tmappingFound := false\n\t\tfor _, r := range config.User.IDMappings.GIDMap {\n\t\t\tif r.ContainerID <= 5 && 5 < r.ContainerID+r.Size {\n\t\t\t\tmappingFound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !mappingFound {\n\t\t\tgid5Available = false\n\t\t}\n\n\t}\n\tif !gid5Available {\n\t\t// If we have no GID mappings, the gid=5 default option would fail, so drop it.\n\t\tg.RemoveMount(\"/dev/pts\")\n\t\tdevPts := spec.Mount{\n\t\t\tDestination: \"/dev/pts\",\n\t\t\tType:        \"devpts\",\n\t\t\tSource:      \"devpts\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"newinstance\", \"ptmxmode=0666\", \"mode=0620\"},\n\t\t}\n\t\tg.AddMount(devPts)\n\t}\n\n\tif inUserNS && config.Ipc.IpcMode.IsHost() {\n\t\tg.RemoveMount(\"/dev/mqueue\")\n\t\tdevMqueue := spec.Mount{\n\t\t\tDestination: \"/dev/mqueue\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/dev/mqueue\",\n\t\t\tOptions:     []string{\"bind\", \"nosuid\", \"noexec\", \"nodev\"},\n\t\t}\n\t\tg.AddMount(devMqueue)\n\t}\n\tif inUserNS && config.Pid.PidMode.IsHost() {\n\t\tg.RemoveMount(\"/proc\")\n\t\tprocMount := spec.Mount{\n\t\t\tDestination: \"/proc\",\n\t\t\tType:        TypeBind,\n\t\t\tSource:      \"/proc\",\n\t\t\tOptions:     []string{\"rbind\", \"nosuid\", \"noexec\", \"nodev\"},\n\t\t}\n\t\tg.AddMount(procMount)\n\t}\n\n\tif addCgroup {\n\t\tcgroupMnt := spec.Mount{\n\t\t\tDestination: \"/sys/fs/cgroup\",\n\t\t\tType:        \"cgroup\",\n\t\t\tSource:      \"cgroup\",\n\t\t\tOptions:     []string{\"rprivate\", \"nosuid\", \"noexec\", \"nodev\", \"relatime\", cgroupPerm},\n\t\t}\n\t\tg.AddMount(cgroupMnt)\n\t}\n\tg.SetProcessCwd(config.WorkDir)\n\tg.SetProcessArgs(config.Command)\n\tg.SetProcessTerminal(config.Tty)\n\n\tfor key, val := range config.Annotations {\n\t\tg.AddAnnotation(key, val)\n\t}\n\n\taddedResources := false\n\n\t// RESOURCES - MEMORY\n\tif config.Resources.Memory != 0 {\n\t\tg.SetLinuxResourcesMemoryLimit(config.Resources.Memory)\n\t\t// If a swap limit is not explicitly set, also set a swap limit\n\t\t// Default to double the memory limit\n\t\tif config.Resources.MemorySwap == 0 {\n\t\t\tg.SetLinuxResourcesMemorySwap(2 * config.Resources.Memory)\n\t\t}\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemoryReservation != 0 {\n\t\tg.SetLinuxResourcesMemoryReservation(config.Resources.MemoryReservation)\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemorySwap != 0 {\n\t\tg.SetLinuxResourcesMemorySwap(config.Resources.MemorySwap)\n\t\taddedResources = true\n\t}\n\tif config.Resources.KernelMemory != 0 {\n\t\tg.SetLinuxResourcesMemoryKernel(config.Resources.KernelMemory)\n\t\taddedResources = true\n\t}\n\tif config.Resources.MemorySwappiness != -1 {\n\t\tg.SetLinuxResourcesMemorySwappiness(uint64(config.Resources.MemorySwappiness))\n\t\taddedResources = true\n\t}\n\tg.SetLinuxResourcesMemoryDisableOOMKiller(config.Resources.DisableOomKiller)\n\tg.SetProcessOOMScoreAdj(config.Resources.OomScoreAdj)\n\n\t// RESOURCES - CPU\n\tif config.Resources.CPUShares != 0 {\n\t\tg.SetLinuxResourcesCPUShares(config.Resources.CPUShares)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUQuota != 0 {\n\t\tg.SetLinuxResourcesCPUQuota(config.Resources.CPUQuota)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUPeriod != 0 {\n\t\tg.SetLinuxResourcesCPUPeriod(config.Resources.CPUPeriod)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUs != 0 {\n\t\tg.SetLinuxResourcesCPUPeriod(CpuPeriod)\n\t\tg.SetLinuxResourcesCPUQuota(int64(config.Resources.CPUs * CpuPeriod))\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPURtRuntime != 0 {\n\t\tg.SetLinuxResourcesCPURealtimeRuntime(config.Resources.CPURtRuntime)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPURtPeriod != 0 {\n\t\tg.SetLinuxResourcesCPURealtimePeriod(config.Resources.CPURtPeriod)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUsetCPUs != \"\" {\n\t\tg.SetLinuxResourcesCPUCpus(config.Resources.CPUsetCPUs)\n\t\taddedResources = true\n\t}\n\tif config.Resources.CPUsetMems != \"\" {\n\t\tg.SetLinuxResourcesCPUMems(config.Resources.CPUsetMems)\n\t\taddedResources = true\n\t}\n\n\t// Devices\n\tif config.Security.Privileged {\n\t\t// If privileged, we need to add all the host devices to the\n\t\t// spec.  We do not add the user provided ones because we are\n\t\t// already adding them all.\n\t\tif err := AddPrivilegedDevices(&g); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\tfor _, devicePath := range config.Devices {\n\t\t\tif err := DevicesFromPath(&g, devicePath); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tif len(config.Resources.DeviceCgroupRules) != 0 {\n\t\t\tif err := deviceCgroupRules(&g, config.Resources.DeviceCgroupRules); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\taddedResources = true\n\t\t}\n\t}\n\n\tg.SetProcessNoNewPrivileges(config.Security.NoNewPrivs)\n\n\tif !config.Security.Privileged {\n\t\tg.SetProcessApparmorProfile(config.Security.ApparmorProfile)\n\t}\n\n\t// Unless already set via the CLI, check if we need to disable process\n\t// labels or set the defaults.\n\tif len(config.Security.LabelOpts) == 0 && runtimeConfig != nil {\n\t\tif !runtimeConfig.Containers.EnableLabeling {\n\t\t\t// Disabled in the config.\n\t\t\tconfig.Security.LabelOpts = append(config.Security.LabelOpts, \"disable\")\n\t\t} else if err := config.Security.SetLabelOpts(runtime, &config.Pid, &config.Ipc); err != nil {\n\t\t\t// Defaults!\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tBlockAccessToKernelFilesystems(config.Security.Privileged, config.Pid.PidMode.IsHost(), &g)\n\n\t// RESOURCES - PIDS\n\tif config.Resources.PidsLimit > 0 {\n\t\t// if running on rootless on a cgroupv1 machine or using the cgroupfs manager, pids\n\t\t// limit is not supported.  If the value is still the default\n\t\t// then ignore the settings.  If the caller asked for a\n\t\t// non-default, then try to use it.\n\t\tsetPidLimit := true\n\t\tif rootless.IsRootless() {\n\t\t\tcgroup2, err := cgroups.IsCgroup2UnifiedMode()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif (!cgroup2 || (runtimeConfig != nil && runtimeConfig.Engine.CgroupManager != cconfig.SystemdCgroupsManager)) && config.Resources.PidsLimit == sysinfo.GetDefaultPidsLimit() {\n\t\t\t\tsetPidLimit = false\n\t\t\t}\n\t\t}\n\t\tif setPidLimit {\n\t\t\tg.SetLinuxResourcesPidsLimit(config.Resources.PidsLimit)\n\t\t\taddedResources = true\n\t\t}\n\t}\n\n\t// Make sure to always set the default variables unless overridden in the\n\t// config.\n\tvar defaultEnv map[string]string\n\tif runtimeConfig == nil {\n\t\tdefaultEnv = env.DefaultEnvVariables()\n\t} else {\n\t\tdefaultEnv, err = env.ParseSlice(runtimeConfig.Containers.Env)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"Env fields in containers.conf failed ot parse\")\n\t\t}\n\t\tdefaultEnv = env.Join(env.DefaultEnvVariables(), defaultEnv)\n\t}\n\n\tif err := addRlimits(config, &g); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// NAMESPACES\n\n\tif err := config.Pid.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.User.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Network.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Uts.ConfigureGenerator(&g, &config.Network, runtime); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Ipc.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := config.Cgroup.ConfigureGenerator(&g); err != nil {\n\t\treturn nil, err\n\t}\n\n\tconfig.Env = env.Join(defaultEnv, config.Env)\n\tfor name, val := range config.Env {\n\t\tg.AddProcessEnv(name, val)\n\t}\n\tconfigSpec := g.Config\n\n\t// If the container image specifies an label with a\n\t// capabilities.ContainerImageLabel then split the comma separated list\n\t// of capabilities and record them.  This list indicates the only\n\t// capabilities, required to run the container.\n\tvar capRequired []string\n\tfor key, val := range config.Labels {\n\t\tif util.StringInSlice(key, capabilities.ContainerImageLabels) {\n\t\t\tcapRequired = strings.Split(val, \",\")\n\t\t}\n\t}\n\tconfig.Security.CapRequired = capRequired\n\n\tif err := config.Security.ConfigureGenerator(&g, &config.User); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// BIND MOUNTS\n\tconfigSpec.Mounts = SupercedeUserMounts(userMounts, configSpec.Mounts)\n\t// Process mounts to ensure correct options\n\tif err := InitFSMounts(configSpec.Mounts); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// BLOCK IO\n\tblkio, err := config.CreateBlockIO()\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"error creating block io\")\n\t}\n\tif blkio != nil {\n\t\tconfigSpec.Linux.Resources.BlockIO = blkio\n\t\taddedResources = true\n\t}\n\n\tif rootless.IsRootless() {\n\t\tcgroup2, err := cgroups.IsCgroup2UnifiedMode()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !addedResources {\n\t\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\t\t}\n\n\t\tcanUseResources := cgroup2 && runtimeConfig != nil && (runtimeConfig.Engine.CgroupManager == cconfig.SystemdCgroupsManager)\n\n\t\tif addedResources && !canUseResources {\n\t\t\treturn nil, errors.New(\"invalid configuration, cannot specify resource limits without cgroups v2 and --cgroup-manager=systemd\")\n\t\t}\n\t\tif !canUseResources {\n\t\t\t// Force the resources block to be empty instead of having default values.\n\t\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\t\t}\n\t}\n\n\tswitch config.Cgroup.Cgroups {\n\tcase \"disabled\":\n\t\tif addedResources {\n\t\t\treturn nil, errors.New(\"cannot specify resource limits when cgroups are disabled is specified\")\n\t\t}\n\t\tconfigSpec.Linux.Resources = &spec.LinuxResources{}\n\tcase \"enabled\", \"no-conmon\", \"\":\n\t\t// Do nothing\n\tdefault:\n\t\treturn nil, errors.New(\"unrecognized option for cgroups; supported are 'default', 'disabled', 'no-conmon'\")\n\t}\n\n\t// Add annotations\n\tif configSpec.Annotations == nil {\n\t\tconfigSpec.Annotations = make(map[string]string)\n\t}\n\n\tif config.CidFile != \"\" {\n\t\tconfigSpec.Annotations[define.InspectAnnotationCIDFile] = config.CidFile\n\t}\n\n\tif config.Rm {\n\t\tconfigSpec.Annotations[define.InspectAnnotationAutoremove] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationAutoremove] = define.InspectResponseFalse\n\t}\n\n\tif len(config.VolumesFrom) > 0 {\n\t\tconfigSpec.Annotations[define.InspectAnnotationVolumesFrom] = strings.Join(config.VolumesFrom, \",\")\n\t}\n\n\tif config.Security.Privileged {\n\t\tconfigSpec.Annotations[define.InspectAnnotationPrivileged] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationPrivileged] = define.InspectResponseFalse\n\t}\n\n\tif config.Init {\n\t\tconfigSpec.Annotations[define.InspectAnnotationInit] = define.InspectResponseTrue\n\t} else {\n\t\tconfigSpec.Annotations[define.InspectAnnotationInit] = define.InspectResponseFalse\n\t}\n\n\treturn configSpec, nil\n}", "is_vulnerable": 0}
{"code": "func (r *reconciler) finalizeLoadBalancerService(ci *operatorv1.IngressController) (bool, error) {\n\thaveLBS, service, err := r.currentLoadBalancerService(ci)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif !haveLBS {\n\t\treturn false, nil\n\t}\n\t// Mutate a copy to avoid assuming we know where the current one came from\n\t// (i.e. it could have been from a cache).\n\tupdated := service.DeepCopy()\n\tif slice.ContainsString(updated.Finalizers, manifests.LoadBalancerServiceFinalizer) {\n\t\tupdated.Finalizers = slice.RemoveString(updated.Finalizers, manifests.LoadBalancerServiceFinalizer)\n\t\tif err := r.client.Update(context.TODO(), updated); err != nil {\n\t\t\treturn true, fmt.Errorf(\"failed to remove finalizer from service %s/%s for ingress %s/%s: %v\",\n\t\t\t\tservice.Namespace, service.Name, ci.Namespace, ci.Name, err)\n\t\t}\n\t}\n\tlog.Info(\"finalized load balancer service for ingress\", \"namespace\", ci.Namespace, \"name\", ci.Name)\n\treturn true, nil\n}", "is_vulnerable": 1}
{"code": "func ParseRegion(s string) (r Region, err error) {\n\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tr = 0\n\t\t\terr = ErrSyntax\n\t\t}\n\t}()\n\n\tif n := len(s); n < 2 || 3 < n {\n\t\treturn 0, ErrSyntax\n\t}\n\tvar buf [3]byte\n\treturn getRegionID(buf[:copy(buf[:], s)])\n}", "is_vulnerable": 0}
{"code": "func (m *Bar1) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar1: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar1: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Str = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\tpbytes, err := yaml.Marshal(storageGridEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(pbytes)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t})", "is_vulnerable": 1}
{"code": "func dumpdb(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tuser, pw := getCredentials(r)\n\tdatabase := parray[0]\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"show tables\")\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tvar n int = 1\n\tfor rows.Next() {\n\t\tvar field string\n\t\trows.Scan(&field)\n\t\tfmt.Fprint(w, linkDeeper(r.URL.Path, field, \"T[\"+strconv.Itoa(n)+\"]\"))\n\t\tfmt.Fprintln(w, \"  \", field, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "is_vulnerable": 1}
{"code": "func newTrue() *bool {\n\tb := true\n\treturn &b\n}", "is_vulnerable": 1}
{"code": "func WithRelabeledContainerMounts(mountLabel string) oci.SpecOpts {\n\treturn func(ctx context.Context, client oci.Client, _ *containers.Container, s *runtimespec.Spec) (err error) {\n\t\tif mountLabel == \"\" {\n\t\t\treturn nil\n\t\t}\n\t\tfor _, m := range s.Mounts {\n\t\t\tswitch m.Destination {\n\t\t\tcase etcHosts, etcHostname, resolvConfPath:\n\t\t\t\tif err := label.Relabel(m.Source, mountLabel, false); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAccessResponderMockRecorder) SetExpiresIn(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"SetExpiresIn\", reflect.TypeOf((*MockAccessResponder)(nil).SetExpiresIn), arg0)\n}", "is_vulnerable": 0}
{"code": "func TestFilesystem_Delete(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\n\tg.Describe(\"Delete\", func() {\n\t\tg.BeforeEach(func() {\n\t\t\tif err := rfs.CreateServerFileFromString(\"source.txt\", \"test content\"); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, int64(utf8.RuneCountInString(\"test content\")))\n\t\t})\n\n\t\tg.It(\"does not delete files outside the root directory\", func() {\n\t\t\terr := rfs.CreateServerFileFromString(\"/../ext-source.txt\", \"external content\")\n\n\t\t\terr = fs.Delete(\"../ext-source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"does not allow the deletion of the root directory\", func() {\n\t\t\terr := fs.Delete(\"/\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(err.Error()).Equal(\"cannot delete root server directory\")\n\t\t})\n\n\t\tg.It(\"does not return an error if the target does not exist\", func() {\n\t\t\terr := fs.Delete(\"missing.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tst, err := rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(st.Name()).Equal(\"source.txt\")\n\t\t})\n\n\t\tg.It(\"deletes files and subtracts their size from the disk usage\", func() {\n\t\t\terr := fs.Delete(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t_, err = rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, os.ErrNotExist)).IsTrue()\n\n\t\t\tg.Assert(atomic.LoadInt64(&fs.diskUsed)).Equal(int64(0))\n\t\t})\n\n\t\tg.It(\"deletes all items inside a directory if the directory is deleted\", func() {\n\t\t\tsources := []string{\n\t\t\t\t\"foo/source.txt\",\n\t\t\t\t\"foo/bar/source.txt\",\n\t\t\t\t\"foo/bar/baz/source.txt\",\n\t\t\t}\n\n\t\t\terr := os.MkdirAll(filepath.Join(rfs.root, \"/server/foo/bar/baz\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tfor _, s := range sources {\n\t\t\t\terr = rfs.CreateServerFileFromString(s, \"test content\")\n\t\t\t\tg.Assert(err).IsNil()\n\t\t\t}\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, int64(utf8.RuneCountInString(\"test content\")*3))\n\n\t\t\terr = fs.Delete(\"foo\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(atomic.LoadInt64(&fs.diskUsed)).Equal(int64(0))\n\n\t\t\tfor _, s := range sources {\n\t\t\t\t_, err = rfs.StatServerFile(s)\n\t\t\t\tg.Assert(err).IsNotNil()\n\t\t\t\tg.Assert(errors.Is(err, os.ErrNotExist)).IsTrue()\n\t\t\t}\n\t\t})\n\n\t\tg.It(\"deletes a symlink but not it's target within the root directory\", func() {\n\t\t\t// Symlink to a file inside the root directory.\n\t\t\terr := os.Symlink(filepath.Join(rfs.root, \"server/source.txt\"), filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink itself.\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the symlink was deleted.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNotNil()\n\n\t\t\t// Ensure the symlink target still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked outside of the root directory\", func() {\n\t\t\t// Create a file outside the root directory.\n\t\t\terr := rfs.CreateServerFileFromString(\"/../source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a symlink to the file outside the root directory.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"source.txt\"), filepath.Join(rfs.root, \"/server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink. (This should pass as we will delete the symlink itself, not it's target)\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a file inside the directory that is outside the root.\n\t\t\terr = rfs.CreateServerFileFromString(\"/../foo/source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"foo/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"returns an error when trying to delete a non-existent file symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo2\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo2\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.AfterEach(func() {\n\t\t\trfs.reset()\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, 0)\n\t\t\tatomic.StoreInt64(&fs.diskLimit, 0)\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func True(t TestingT, value bool, msgAndArgs ...interface{}) {\n\tif assert.True(t, value, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func isTrustedAddress(addr string, trustedCidrs []string) bool {\n\tip, _, err := net.SplitHostPort(addr)\n\tif err != nil {\n\t\tlog.Warnf(\"peer address %s can not be split in to proper host and port\", addr)\n\t\treturn false\n\t}\n\tfor _, cidr := range trustedCidrs {\n\t\tif isInRange(ip, cidr) {\n\t\t\treturn true\n\t\t}\n\t}\n\t// Always trust local host addresses.\n\treturn net.ParseIP(ip).IsLoopback()\n}", "is_vulnerable": 0}
{"code": "func invokeMarshaler(m logr.Marshaler) (ret any) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tret = fmt.Sprintf(\"<panic: %s>\", r)\n\t\t}\n\t}()\n\treturn m.MarshalLog()\n}", "is_vulnerable": 0}
{"code": "func hostMatchesGlob(host string, domainGlob string) bool {\n\tif host == \"\" {\n\t\treturn false\n\t}\n\n\th := strings.TrimRight(strings.ToLower(host), \".\")\n\tg := strings.TrimRight(strings.ToLower(domainGlob), \".\")\n\n\tif strings.HasPrefix(g, \"*.\") {\n\t\tsuffix := g[1:]\n\t\tif strings.HasSuffix(h, suffix) {\n\t\t\treturn true\n\t\t}\n\t} else if g == h {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (ns *nodeServer) NodeStageVolume(ctx context.Context, req *csi.NodeStageVolumeRequest) (*csi.NodeStageVolumeResponse, error) {\n\t// The lock is to ensure CSI plugin labels the node in correct order\n\tns.mutex.Lock()\n\tdefer ns.mutex.Unlock()\n\tglog.Infof(\"NodeStageVolume: Starting NodeStage with VolumeId: %s, and VolumeContext: %v\", req.GetVolumeId(), req.VolumeContext)\n\n\t// 1. Start SessMgr Pod and wait for ready if FUSE pod requires SessMgr\n\tsessMgrWorkDir := req.GetVolumeContext()[common.VolumeAttrEFCSessMgrWorkDir]\n\tif len(sessMgrWorkDir) != 0 {\n\t\tif err := ns.prepareSessMgr(sessMgrWorkDir); err != nil {\n\t\t\tglog.Errorf(\"NodeStageVolume: fail to prepare SessMgr because: %v\", err)\n\t\t\treturn nil, errors.Wrapf(err, \"NodeStageVolume: fail to prepare SessMgr\")\n\t\t}\n\t}\n\n\t// 2. clean up broken mount point\n\tfluidPath := req.GetVolumeContext()[common.VolumeAttrFluidPath]\n\tif ignoredErr := cleanUpBrokenMountPoint(fluidPath); ignoredErr != nil {\n\t\tglog.Warningf(\"Ignoring error when cleaning up broken mount point %v: %v\", fluidPath, ignoredErr)\n\t}\n\n\t// 3. get runtime namespace and name\n\tnamespace, name, err := ns.getRuntimeNamespacedName(req.GetVolumeContext(), req.GetVolumeId())\n\tif err != nil {\n\t\tglog.Errorf(\"NodeStageVolume: can't get runtime namespace and name given (volumeContext: %v, volumeId: %s): %v\", req.GetVolumeContext(), req.GetVolumeId(), err)\n\t\treturn nil, errors.Wrapf(err, \"NodeStageVolume: can't get namespace and name by volume id %s\", req.GetVolumeId())\n\t}\n\n\t// 4. Label node to launch FUSE Pod\n\tfuseLabelKey := common.LabelAnnotationFusePrefix + namespace + \"-\" + name\n\tvar labelsToModify common.LabelsToModify\n\tlabelsToModify.Add(fuseLabelKey, \"true\")\n\n\tnode, err := ns.getNode()\n\tif err != nil {\n\t\tglog.Errorf(\"NodeStageVolume: can't get node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeStageVolume: can't get node %s\", ns.nodeId)\n\t}\n\n\t// _, err = utils.ChangeNodeLabelWithPatchMode(ns.client, node, labelsToModify)\n\terr = ns.patchNodeWithLabel(node, labelsToModify)\n\tif err != nil {\n\t\tglog.Errorf(\"NodeStageVolume: error when patching labels on node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeStageVolume: error when patching labels on node %s\", ns.nodeId)\n\t}\n\n\tglog.Infof(\"NodeStageVolume: NodeStage succeded with VolumeId: %s, and added NodeLabel: %s\", req.GetVolumeId(), fuseLabelKey)\n\treturn &csi.NodeStageVolumeResponse{}, nil\n}", "is_vulnerable": 0}
{"code": "func (config *ClusterConfig) HostDiskEnabled() bool {\n\treturn config.isFeatureGateEnabled(HostDiskGate)\n}", "is_vulnerable": 0}
{"code": "func Test110Defaults(t *testing.T) {\n\th, err := Create()\n\tif err != nil {\n\t\tt.Fatalf(\"could not create handle: %s\", err)\n\t}\n\tdefer h.Close()\n\n\tname, err := h.GetExportName()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get export name: %s\", err)\n\t}\n\tif *name != \"\" {\n\t\tt.Fatalf(\"unexpected export name: %s\", *name)\n\t}\n\n\tinfo, err := h.GetFullInfo()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get full info state: %s\", err)\n\t}\n\tif info != false {\n\t\tt.Fatalf(\"unexpected full info state\")\n\t}\n\n\ttls, err := h.GetTls()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get tls state: %s\", err)\n\t}\n\tif tls != TLS_DISABLE {\n\t\tt.Fatalf(\"unexpected tls state\")\n\t}\n\n\tsr, err := h.GetRequestStructuredReplies()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get structured replies state: %s\", err)\n\t}\n\tif sr != true {\n\t\tt.Fatalf(\"unexpected structured replies state\")\n\t}\n\n\tinit, err := h.GetPreadInitialize()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get pread initialize state: %s\", err)\n\t}\n\tif init != true {\n\t\tt.Fatalf(\"unexpected pread initialize state\")\n\t}\n\n\tflags, err := h.GetHandshakeFlags()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get handshake flags: %s\", err)\n\t}\n\tif flags != HANDSHAKE_FLAG_MASK {\n\t\tt.Fatalf(\"unexpected handshake flags\")\n\t}\n\n\topt, err := h.GetOptMode()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get opt mode state: %s\", err)\n\t}\n\tif opt != false {\n\t\tt.Fatalf(\"unexpected opt mode state\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestLogGRPC(t *testing.T) {\n\t// SET UP\n\tklog.InitFlags(nil)\n\tif e := flag.Set(\"logtostderr\", \"false\"); e != nil {\n\t\tt.Error(e)\n\t}\n\tif e := flag.Set(\"alsologtostderr\", \"false\"); e != nil {\n\t\tt.Error(e)\n\t}\n\tif e := flag.Set(\"v\", \"100\"); e != nil {\n\t\tt.Error(e)\n\t}\n\tflag.Parse()\n\n\tbuf := new(bytes.Buffer)\n\tklog.SetOutput(buf)\n\n\thandler := func(ctx context.Context, req interface{}) (interface{}, error) { return nil, nil }\n\tinfo := grpc.UnaryServerInfo{\n\t\tFullMethod: \"fake\",\n\t}\n\n\ttests := []struct {\n\t\tname   string\n\t\treq    interface{}\n\t\texpStr string\n\t}{\n\t\t{\n\t\t\t\"with secrets\",\n\t\t\t&csi.NodeStageVolumeRequest{\n\t\t\t\tVolumeId: \"vol_1\",\n\t\t\t\tSecrets: map[string]string{\n\t\t\t\t\t\"account_name\": \"k8s\",\n\t\t\t\t\t\"account_key\":  \"testkey\",\n\t\t\t\t},\n\t\t\t\tXXX_sizecache: 100,\n\t\t\t},\n\t\t\t`GRPC request: {\"secrets\":\"***stripped***\",\"volume_id\":\"vol_1\"}`,\n\t\t},\n\t\t{\n\t\t\t\"without secrets\",\n\t\t\t&csi.ListSnapshotsRequest{\n\t\t\t\tStartingToken: \"testtoken\",\n\t\t\t},\n\t\t\t`GRPC request: {\"starting_token\":\"testtoken\"}`,\n\t\t},\n\t\t{\n\t\t\t\"NodeStageVolumeRequest with service account token\",\n\t\t\t&csi.NodeStageVolumeRequest{\n\t\t\t\tVolumeContext: map[string]string{\n\t\t\t\t\t\"csi.storage.k8s.io/serviceAccount.tokens\": \"testtoken\",\n\t\t\t\t\t\"csi.storage.k8s.io/testfield\":             \"testvalue\",\n\t\t\t\t},\n\t\t\t\tXXX_sizecache: 100,\n\t\t\t},\n\t\t\t`GRPC request: {\"volume_context\":{\"csi.storage.k8s.io/serviceAccount.tokens\":\"***stripped***\",\"csi.storage.k8s.io/testfield\":\"testvalue\"}}`,\n\t\t},\n\t\t{\n\t\t\t\"NodePublishVolumeRequest with service account token\",\n\t\t\t&csi.NodePublishVolumeRequest{\n\t\t\t\tVolumeContext: map[string]string{\n\t\t\t\t\t\"csi.storage.k8s.io/serviceAccount.tokens\": \"testtoken\",\n\t\t\t\t\t\"csi.storage.k8s.io/testfield\":             \"testvalue\",\n\t\t\t\t},\n\t\t\t\tXXX_sizecache: 100,\n\t\t\t},\n\t\t\t`GRPC request: {\"volume_context\":{\"csi.storage.k8s.io/serviceAccount.tokens\":\"***stripped***\",\"csi.storage.k8s.io/testfield\":\"testvalue\"}}`,\n\t\t},\n\t\t{\n\t\t\t\"with secrets and service account token\",\n\t\t\t&csi.NodeStageVolumeRequest{\n\t\t\t\tVolumeId: \"vol_1\",\n\t\t\t\tSecrets: map[string]string{\n\t\t\t\t\t\"account_name\": \"k8s\",\n\t\t\t\t\t\"account_key\":  \"testkey\",\n\t\t\t\t},\n\t\t\t\tVolumeContext: map[string]string{\n\t\t\t\t\t\"csi.storage.k8s.io/serviceAccount.tokens\": \"testtoken\",\n\t\t\t\t\t\"csi.storage.k8s.io/testfield\":             \"testvalue\",\n\t\t\t\t},\n\t\t\t\tXXX_sizecache: 100,\n\t\t\t},\n\t\t\t`GRPC request: {\"secrets\":\"***stripped***\",\"volume_context\":{\"csi.storage.k8s.io/serviceAccount.tokens\":\"***stripped***\",\"csi.storage.k8s.io/testfield\":\"testvalue\"},\"volume_id\":\"vol_1\"}`,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\t// EXECUTE\n\t\t\t_, _ = logGRPC(context.Background(), test.req, &info, handler)\n\t\t\tklog.Flush()\n\n\t\t\t// ASSERT\n\t\t\tassert.Contains(t, buf.String(), \"GRPC call: fake\")\n\t\t\tassert.Contains(t, buf.String(), test.expStr)\n\t\t\tassert.Contains(t, buf.String(), \"GRPC response: null\")\n\n\t\t\t// CLEANUP\n\t\t\tbuf.Reset()\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessResponder) SetExpiresIn(arg0 time.Duration) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"SetExpiresIn\", arg0)\n}", "is_vulnerable": 0}
{"code": "func (src *CopyOutResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'H')\n\n\tdst = append(dst, src.OverallFormat)\n\n\tif len(src.ColumnFormatCodes) > math.MaxUint16 {\n\t\treturn nil, errors.New(\"too many column format codes\")\n\t}\n\tdst = pgio.AppendUint16(dst, uint16(len(src.ColumnFormatCodes)))\n\tfor _, fc := range src.ColumnFormatCodes {\n\t\tdst = pgio.AppendUint16(dst, fc)\n\t}\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "\t\tg.It(\"cannot write to a non-existent file symlinked outside the root\", func() {\n\t\t\tr := bytes.NewReader([]byte(\"testing what the fuck\"))\n\n\t\t\terr := fs.Writefile(\"symlinked_does_not_exist.txt\", r)\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})", "is_vulnerable": 0}
{"code": "func init() {\n\tconf.App.Version = \"0.12.9\"\n}", "is_vulnerable": 0}
{"code": "\t\t\tCheckData: func(data map[string][]byte) error {\n\t\t\t\tif len(data[\"session_secret\"]) != 44 {\n\t\t\t\t\treturn fmt.Errorf(\"session secret should have been 44 bytes long but got %v\", data)\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t},\n\t\t},", "is_vulnerable": 0}
{"code": "func TestHttpGetter_cleanhttp(t *testing.T) {\n\tln := testHttpServer(t)\n\tdefer ln.Close()\n\n\t// break the default http client\n\thttp.DefaultClient.Transport = errRoundTripper{}\n\tdefer func() {\n\t\thttp.DefaultClient.Transport = http.DefaultTransport\n\t}()\n\tctx := context.Background()\n\n\tg := new(HttpGetter)\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/header\"\n\n\treq := &Request{\n\t\tDst:     dst,\n\t\tSrc:     u.String(),\n\t\tu:       &u,\n\t\tGetMode: ModeDir,\n\t}\n\n\t// Get it, which should error because it uses the file protocol.\n\terr := g.Get(ctx, req)\n\tif !strings.Contains(err.Error(), \"download not supported for scheme\") {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\t// But, using a wrapper client with a file getter will work.\n\tc := &Client{\n\t\tGetters: []Getter{\n\t\t\tg,\n\t\t\tnew(FileGetter),\n\t\t},\n\t}\n\n\tif _, err = c.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func NewClient(config *Config) (*Client, error) {\n\treturn NewClientLogger(config, nil, tlsutil.NewConfigurator(config.ToTLSUtilConfig()))\n}", "is_vulnerable": 1}
{"code": "func newControllerClusterRole() *rbacv1.ClusterRole {\n\treturn &rbacv1.ClusterRole{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: \"rbac.authorization.k8s.io/v1\",\n\t\t\tKind:       \"ClusterRole\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: components.ControllerServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRules: []rbacv1.PolicyRule{\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"namespaces\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"policy\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"poddisruptionbudgets\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"delete\", \"create\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"pods\", \"configmaps\", \"endpoints\", \"services\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"delete\", \"update\", \"create\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"events\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"update\", \"create\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"secrets\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"pods/finalizers\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"update\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"pods/eviction\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"pods/status\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"nodes\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"update\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apps\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"daemonsets\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"list\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apps\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"controllerrevisions\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"update\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"persistentvolumeclaims\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"create\", \"update\", \"delete\", \"patch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"snapshot.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"export.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"pool.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"virtualmachinepools\",\n\t\t\t\t\t\"virtualmachinepools/finalizers\",\n\t\t\t\t\t\"virtualmachinepools/status\",\n\t\t\t\t\t\"virtualmachinepools/scale\",\n\t\t\t\t},\n\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t\t\"update\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"get\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"subresources.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"virtualmachineinstances/addvolume\",\n\t\t\t\t\t\"virtualmachineinstances/removevolume\",\n\t\t\t\t\t\"virtualmachineinstances/freeze\",\n\t\t\t\t\t\"virtualmachineinstances/unfreeze\",\n\t\t\t\t\t\"virtualmachineinstances/softreboot\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"update\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"cdi.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"*\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"k8s.cni.cncf.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"network-attachment-definitions\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"apiextensions.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"customresourcedefinitions\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"authorization.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"subjectaccessreviews\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"snapshot.storage.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"volumesnapshotclasses\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"snapshot.storage.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"volumesnapshots\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"update\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"storage.k8s.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"storageclasses\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"instancetype.kubevirt.io\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\tinstancetype.PluralResourceName,\n\t\t\t\t\tinstancetype.ClusterPluralResourceName,\n\t\t\t\t\tinstancetype.PluralPreferenceResourceName,\n\t\t\t\t\tinstancetype.ClusterPluralPreferenceResourceName,\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tmigrations.GroupName,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\tmigrations.ResourceMigrationPolicies,\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tclone.GroupName,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\tclone.ResourceVMClonePlural,\n\t\t\t\t\tclone.ResourceVMClonePlural + \"/status\",\n\t\t\t\t\tclone.ResourceVMClonePlural + \"/finalizers\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\", \"update\", \"patch\", \"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"namespaces\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tfunc() backups.Backups {\n\t\t\treturn s.fake\n\t\t},\n\t)\n}", "is_vulnerable": 1}
{"code": "func (e *ExecCommandError) Error() string {\n\tlastOutput := e.Output\n\tif len(e.Output) > 200 {\n\t\tlastOutput = \"... \" + e.Output[len(e.Output)-200:]\n\t}\n\treturn fmt.Sprintf(\"failed executing %s %v, Error %s, LastOutput \\\"%s\\\"\", e.Command, removePullSecret(e.Args), e.ExitErr, lastOutput)\n}", "is_vulnerable": 0}
{"code": "func (d deviceService) FindAll() ([]entities.Device, error) {\n\tdevices, err := d.repository.FindAll(time.Now().Add(time.Minute * time.Duration(-3)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor index, device := range devices {\n\t\tdevices[index].MacAddressBase64 = utilities.EncodeBase64(device.MacAddress)\n\t}\n\treturn devices, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) RegistryRead(ctx context.Context, in *sliverpb.RegistryReadReq, opts ...grpc.CallOption) (*sliverpb.RegistryRead, error) {\n\tout := new(sliverpb.RegistryRead)\n\terr := c.cc.Invoke(ctx, SliverRPC_RegistryRead_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func ApplyRouteConfigurationPatches(patchContext networking.EnvoyFilter_PatchContext,\n\tproxy *model.Proxy, push *model.PushContext,\n\trouteConfiguration *xdsapi.RouteConfiguration) *xdsapi.RouteConfiguration {\n\n\tenvoyFilterWrappers := push.EnvoyFilters(proxy)\n\tfor _, efw := range envoyFilterWrappers {\n\t\t// only merge is applicable for route configuration.\n\t\tfor _, cp := range efw.Patches[networking.EnvoyFilter_ROUTE_CONFIGURATION] {\n\t\t\tif cp.Operation != networking.EnvoyFilter_Patch_MERGE {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif commonConditionMatch(proxy, patchContext, cp) &&\n\t\t\t\trouteConfigurationMatch(patchContext, routeConfiguration, cp) {\n\t\t\t\tproto.Merge(routeConfiguration, cp.Value)\n\t\t\t}\n\t\t}\n\n\t\tdoVirtualHostListOperation(proxy, patchContext, efw.Patches, routeConfiguration)\n\t}\n\treturn routeConfiguration\n}", "is_vulnerable": 1}
{"code": "func Start(ctx context.Context, httpPort, httpsPort int, localClusterEnabled bool, scaledContext *config.ScaledContext, clusterManager *clustermanager.Manager, auditLogWriter *audit.LogWriter) error {\n\ttokenAPI, err := tokens.NewAPIHandler(ctx, scaledContext)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tpublicAPI, err := publicapi.NewHandler(ctx, scaledContext)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tk8sProxy := k8sProxyPkg.New(scaledContext, scaledContext.Dialer)\n\n\tmanagementAPI, err := managementapi.New(ctx, scaledContext, clusterManager, k8sProxy, localClusterEnabled)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\troot := mux.NewRouter()\n\troot.UseEncodedPath()\n\n\trawAuthedAPIs := newAuthed(tokenAPI, managementAPI, k8sProxy, scaledContext)\n\n\tsar := sar.NewSubjectAccessReview(clusterManager)\n\n\tauthedHandler, err := requests.NewAuthenticationFilter(ctx, scaledContext, rawAuthedAPIs, sar)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tauditHandler := audit.NewAuditLogFilter(ctx, auditLogWriter, authedHandler)\n\n\twebhookHandler := hooks.New(scaledContext)\n\n\tconnectHandler, connectConfigHandler := connectHandlers(scaledContext)\n\n\tsamlRoot := saml.AuthHandler()\n\tchain := responsewriter.NewMiddlewareChain(responsewriter.Gzip, responsewriter.NoCache, responsewriter.DenyFrameOptions, responsewriter.ContentType, ui.UI)\n\tchainGzip := responsewriter.NewMiddlewareChain(responsewriter.Gzip, responsewriter.ContentType)\n\n\troot.Handle(\"/\", chain.Handler(managementAPI))\n\troot.PathPrefix(\"/v3-public\").Handler(publicAPI)\n\troot.Handle(\"/v3/import/{token}.yaml\", http.HandlerFunc(clusterregistrationtokens.ClusterImportHandler))\n\troot.Handle(\"/v3/connect\", connectHandler)\n\troot.Handle(\"/v3/connect/register\", connectHandler)\n\troot.Handle(\"/v3/connect/config\", connectConfigHandler)\n\troot.Handle(\"/v3/settings/cacerts\", rawAuthedAPIs).Methods(http.MethodGet)\n\troot.Handle(\"/v3/settings/first-login\", rawAuthedAPIs).Methods(http.MethodGet)\n\troot.Handle(\"/v3/settings/ui-pl\", rawAuthedAPIs).Methods(http.MethodGet)\n\troot.PathPrefix(\"/v3\").Handler(chainGzip.Handler(auditHandler))\n\troot.PathPrefix(\"/hooks\").Handler(webhookHandler)\n\troot.PathPrefix(\"/k8s/clusters/\").Handler(auditHandler)\n\troot.PathPrefix(\"/meta\").Handler(auditHandler)\n\troot.PathPrefix(\"/v1-telemetry\").Handler(auditHandler)\n\troot.NotFoundHandler = ui.UI(http.NotFoundHandler())\n\troot.PathPrefix(\"/v1-saml\").Handler(samlRoot)\n\n\t// UI\n\tuiContent := responsewriter.NewMiddlewareChain(responsewriter.Gzip, responsewriter.DenyFrameOptions, responsewriter.CacheMiddleware(\"json\", \"js\", \"css\")).Handler(ui.Content())\n\troot.PathPrefix(\"/assets\").Handler(uiContent)\n\troot.PathPrefix(\"/translations\").Handler(uiContent)\n\troot.PathPrefix(\"/ember-fetch\").Handler(uiContent)\n\troot.PathPrefix(\"/engines-dist\").Handler(uiContent)\n\troot.Handle(\"/asset-manifest.json\", uiContent)\n\troot.Handle(\"/crossdomain.xml\", uiContent)\n\troot.Handle(\"/humans.txt\", uiContent)\n\troot.Handle(\"/index.html\", uiContent)\n\troot.Handle(\"/robots.txt\", uiContent)\n\troot.Handle(\"/VERSION.txt\", uiContent)\n\n\t//API UI\n\troot.PathPrefix(\"/api-ui\").Handler(uiContent)\n\n\tregisterHealth(root)\n\n\tdynamiclistener.Start(ctx, scaledContext, httpPort, httpsPort, root)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func runList(ctx context.Context, opts *listOpts) error {\n\t// set log level\n\tctx = opts.LoggingFlagOpts.SetLoggerLevel(ctx)\n\n\t// initialize\n\treference := opts.reference\n\tsigRepo, err := getRepository(ctx, opts.inputType, reference, &opts.SecureFlagOpts, opts.allowReferrersAPI)\n\tif err != nil {\n\t\treturn err\n\t}\n\ttargetDesc, resolvedRef, err := resolveReferenceWithWarning(ctx, opts.inputType, reference, sigRepo, \"list\")\n\tif err != nil {\n\t\treturn err\n\t}\n\t// print all signature manifest digests\n\treturn printSignatureManifestDigests(ctx, targetDesc, sigRepo, resolvedRef)\n}", "is_vulnerable": 1}
{"code": "func (b *BasicEnvoyExtender) Validate(_ *RuntimeConfig) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (src *CopyInResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'G')\n\n\tdst = append(dst, src.OverallFormat)\n\tif len(src.ColumnFormatCodes) > math.MaxUint16 {\n\t\treturn nil, errors.New(\"too many column format codes\")\n\t}\n\tdst = pgio.AppendUint16(dst, uint16(len(src.ColumnFormatCodes)))\n\tfor _, fc := range src.ColumnFormatCodes {\n\t\tdst = pgio.AppendUint16(dst, fc)\n\t}\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) HostRm(ctx context.Context, in *clientpb.Host, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_HostRm_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (src *AuthenticationSASLFinal) Encode(dst []byte) []byte {\n\tdst = append(dst, 'R')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\tdst = pgio.AppendUint32(dst, AuthTypeSASLFinal)\n\n\tdst = append(dst, src.Data...)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (t *TaskManager) ListTasks(ctx context.Context, request admin.ResourceListRequest) (*admin.TaskList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"Invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\tspec := util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}\n\n\tfilters, err := util.GetDbFilters(spec, common.Task)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.TaskColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTasks\", request.Token)\n\t}\n\t// And finally, query the database\n\tlistTasksInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := t.db.TaskRepo().List(ctx, listTasksInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list tasks with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\ttaskList, err := transformers.FromTaskModels(output.Tasks)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform task models [%+v] with err: %v\", output.Tasks, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(taskList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskList))\n\t}\n\treturn &admin.TaskList{\n\t\tTasks: taskList,\n\t\tToken: token,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (s *RedirectionCheckScenario) TestShouldRedirectOnLogoutOnlyWhenDomainIsSafe() {\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cancel()\n\n\tfor url, success := range logoutRedirectionURLs {\n\t\ts.T().Run(url, func(t *testing.T) {\n\t\t\ts.doLogoutWithRedirect(ctx, t, url, !success)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func FsMkdir(c *gin.Context) {\n\tvar req MkdirOrLinkReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\treqPath, err := user.JoinPath(req.Path)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 403)\n\t\treturn\n\t}\n\tif !user.CanWrite() {\n\t\tmeta, err := db.GetNearestMeta(stdpath.Dir(reqPath))\n\t\tif err != nil {\n\t\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif !common.CanWrite(meta, reqPath) {\n\t\t\tcommon.ErrorResp(c, errs.PermissionDenied, 403)\n\t\t\treturn\n\t\t}\n\t}\n\tif err := fs.MakeDir(c, reqPath); err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\tfs.ClearCache(stdpath.Dir(reqPath))\n\tcommon.SuccessResp(c)\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateComponentContainerEmptyButBadPermFails(c *C) {\n\td := c.MkDir()\n\n\tstat, err := os.Stat(d)\n\tc.Assert(err, IsNil)\n\tc.Check(stat.Mode().Perm(), Equals, os.FileMode(0700)) // just to be sure\n\n\tc.Assert(os.Mkdir(filepath.Join(d, \"meta\"), 0755), IsNil)\n\tc.Assert(os.WriteFile(filepath.Join(d, \"meta\", \"component.yaml\"), nil, 0444), IsNil)\n\n\t// snapdir has /meta/component.yaml, but / is 0700\n\n\terr = snap.ValidateComponentContainer(snapdir.New(d), \"empty-snap+comp.comp\", discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 1}
{"code": "func DecompressStream(archive io.Reader) (io.ReadCloser, error) {\n\tp := pools.BufioReader32KPool\n\tbuf := p.Get(archive)\n\tbs, err := buf.Peek(10)\n\tif err != nil && err != io.EOF {\n\t\t// Note: we'll ignore any io.EOF error because there are some odd\n\t\t// cases where the layer.tar file will be empty (zero bytes) and\n\t\t// that results in an io.EOF from the Peek() call. So, in those\n\t\t// cases we'll just treat it as a non-compressed stream and\n\t\t// that means just create an empty layer.\n\t\t// See Issue 18170\n\t\treturn nil, err\n\t}\n\n\tcompression := DetectCompression(bs)\n\tswitch compression {\n\tcase Uncompressed:\n\t\treadBufWrapper := p.NewReadCloserWrapper(buf, buf)\n\t\treturn readBufWrapper, nil\n\tcase Gzip:\n\t\tgzReader, err := gzip.NewReader(buf)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treadBufWrapper := p.NewReadCloserWrapper(buf, gzReader)\n\t\treturn readBufWrapper, nil\n\tcase Bzip2:\n\t\tbz2Reader := bzip2.NewReader(buf)\n\t\treadBufWrapper := p.NewReadCloserWrapper(buf, bz2Reader)\n\t\treturn readBufWrapper, nil\n\tcase Xz:\n\t\txzReader, err := xz.NewReader(buf)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treadBufWrapper := p.NewReadCloserWrapper(buf, xzReader)\n\t\treturn readBufWrapper, nil\n\tcase Zstd:\n\t\treturn zstdReader(buf)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"Unsupported compression format %s\", (&compression).Extension())\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *Profile) writeDown() (pth string, err error) {\n\trootDir, err := utils.GetTempDir()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tpth = filepath.Join(rootDir, p.Id+\"-down.sh\")\n\n\tscript := \"\"\n\tswitch runtime.GOOS {\n\tcase \"darwin\":\n\t\tscript = downScriptDarwin\n\t\tbreak\n\tcase \"linux\":\n\t\tresolved := true\n\n\t\tresolvData, _ := ioutil.ReadFile(\"/etc/resolv.conf\")\n\t\tif resolvData != nil {\n\t\t\tresolvDataStr := string(resolvData)\n\t\t\tif !strings.Contains(resolvDataStr, \"systemd-resolved\") &&\n\t\t\t\t!strings.Contains(resolvDataStr, \"127.0.0.53\") {\n\n\t\t\t\tresolved = false\n\t\t\t}\n\t\t}\n\n\t\tif resolved {\n\t\t\tscript = resolvedScript\n\t\t} else {\n\t\t\tscript = resolvScript\n\t\t}\n\t\tbreak\n\tdefault:\n\t\tpanic(\"profile: Not implemented\")\n\t}\n\n\t_ = os.Remove(pth)\n\terr = ioutil.WriteFile(pth, []byte(script), os.FileMode(0755))\n\tif err != nil {\n\t\terr = &WriteError{\n\t\t\terrors.Wrap(err, \"profile: Failed to write down script\"),\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "\treturn ignoringEINTR(func() error {\n\t\treturn unix.Unlinkat(dirfd, name, flags)\n\t})", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) CompressFiles(dir string, paths []string) (ufs.FileInfo, error) {\n\ta := &Archive{Filesystem: fs, BaseDirectory: dir, Files: paths}\n\td := path.Join(\n\t\tdir,\n\t\tfmt.Sprintf(\"archive-%s.tar.gz\", strings.ReplaceAll(time.Now().Format(time.RFC3339), \":\", \"\")),\n\t)\n\tf, err := fs.unixFS.OpenFile(d, ufs.O_WRONLY|ufs.O_CREATE, 0o644)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\tcw := ufs.NewCountedWriter(f)\n\tif err := a.Stream(context.Background(), cw); err != nil {\n\t\treturn nil, err\n\t}\n\tif !fs.unixFS.CanFit(cw.BytesWritten()) {\n\t\t_ = fs.unixFS.Remove(d)\n\t\treturn nil, newFilesystemError(ErrCodeDiskSpace, nil)\n\t}\n\tfs.unixFS.Add(cw.BytesWritten())\n\treturn f.Stat()\n}", "is_vulnerable": 0}
{"code": "func (m *MockPKCERequestStorage) GetPKCERequestSession(arg0 context.Context, arg1 string, arg2 fosite.Session) (fosite.Requester, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetPKCERequestSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(fosite.Requester)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) genValue(mount datav1alpha1.Mount, tiredStoreLevel *datav1alpha1.Level, value *JuiceFS,\n\tSharedOptions map[string]string, SharedEncryptOptions []datav1alpha1.EncryptOption) (map[string]string, error) {\n\tvalue.Configs.Name = mount.Name\n\toptions := make(map[string]string)\n\tsource := \"\"\n\tvalue.Edition = EnterpriseEdition\n\n\tfor k, v := range SharedOptions {\n\t\tswitch k {\n\t\tcase JuiceStorage:\n\t\t\tvalue.Configs.Storage = v\n\t\t\tcontinue\n\t\tcase JuiceBucket:\n\t\t\tvalue.Configs.Bucket = v\n\t\t\tcontinue\n\t\tdefault:\n\t\t\toptions[k] = v\n\t\t}\n\t}\n\n\tfor k, v := range mount.Options {\n\t\tswitch k {\n\t\tcase JuiceStorage:\n\t\t\tvalue.Configs.Storage = v\n\t\t\tcontinue\n\t\tcase JuiceBucket:\n\t\t\tvalue.Configs.Bucket = v\n\t\t\tcontinue\n\t\tdefault:\n\t\t\toptions[k] = v\n\t\t}\n\t}\n\n\tfor _, encryptOption := range SharedEncryptOptions {\n\t\tkey := encryptOption.Name\n\t\tsecretKeyRef := encryptOption.ValueFrom.SecretKeyRef\n\t\tsecret, err := kubeclient.GetSecret(j.Client, secretKeyRef.Name, j.namespace)\n\t\tif err != nil {\n\t\t\tj.Log.Info(\"can't get the secret\",\n\t\t\t\t\"namespace\", j.namespace,\n\t\t\t\t\"name\", j.name,\n\t\t\t\t\"secretName\", secretKeyRef.Name)\n\t\t\treturn nil, err\n\t\t}\n\n\t\tswitch key {\n\t\tcase JuiceMetaUrl:\n\t\t\tsource = \"${METAURL}\"\n\t\t\tvalue.Configs.MetaUrlSecret = secretKeyRef.Name\n\t\t\tvalue.Configs.MetaUrlSecretKey = secretKeyRef.Key\n\t\t\t_, ok := secret.Data[secretKeyRef.Key]\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get metaurl from secret %s\", secret.Name)\n\t\t\t}\n\t\t\tvalue.Edition = CommunityEdition\n\t\tcase JuiceAccessKey:\n\t\t\tvalue.Configs.AccessKeySecret = secretKeyRef.Name\n\t\t\tvalue.Configs.AccessKeySecretKey = secretKeyRef.Key\n\t\tcase JuiceSecretKey:\n\t\t\tvalue.Configs.SecretKeySecret = secretKeyRef.Name\n\t\t\tvalue.Configs.SecretKeySecretKey = secretKeyRef.Key\n\t\tcase JuiceToken:\n\t\t\tvalue.Configs.TokenSecret = secretKeyRef.Name\n\t\t\tvalue.Configs.TokenSecretKey = secretKeyRef.Key\n\t\t}\n\t}\n\n\tfor _, encryptOption := range mount.EncryptOptions {\n\t\tkey := encryptOption.Name\n\t\tsecretKeyRef := encryptOption.ValueFrom.SecretKeyRef\n\t\tsecret, err := kubeclient.GetSecret(j.Client, secretKeyRef.Name, j.namespace)\n\t\tif err != nil {\n\t\t\tj.Log.Info(\"can't get the secret\",\n\t\t\t\t\"namespace\", j.namespace,\n\t\t\t\t\"name\", j.name,\n\t\t\t\t\"secretName\", secretKeyRef.Name)\n\t\t\treturn nil, err\n\t\t}\n\n\t\tswitch key {\n\t\tcase JuiceMetaUrl:\n\t\t\tsource = \"${METAURL}\"\n\t\t\tvalue.Configs.MetaUrlSecret = secretKeyRef.Name\n\t\t\tvalue.Configs.MetaUrlSecretKey = secretKeyRef.Key\n\t\t\t_, ok := secret.Data[secretKeyRef.Key]\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"can't get metaurl from secret %s\", secret.Name)\n\t\t\t}\n\t\t\tvalue.Edition = CommunityEdition\n\t\tcase JuiceAccessKey:\n\t\t\tvalue.Configs.AccessKeySecret = secretKeyRef.Name\n\t\t\tvalue.Configs.AccessKeySecretKey = secretKeyRef.Key\n\t\tcase JuiceSecretKey:\n\t\t\tvalue.Configs.SecretKeySecret = secretKeyRef.Name\n\t\t\tvalue.Configs.SecretKeySecretKey = secretKeyRef.Key\n\t\tcase JuiceToken:\n\t\t\tvalue.Configs.TokenSecret = secretKeyRef.Name\n\t\t\tvalue.Configs.TokenSecretKey = secretKeyRef.Key\n\t\t}\n\t}\n\n\tif source == \"\" {\n\t\tsource = security.EscapeBashStr(mount.Name)\n\t}\n\n\t// transform source\n\tvalue.Source = source\n\n\t// transform mountPath & subPath\n\tsubPath, err := ParseSubPathFromMountPoint(mount.MountPoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvalue.Fuse.MountPath = j.getMountPoint()\n\tvalue.Worker.MountPath = j.getMountPoint()\n\tvalue.Fuse.HostMountPath = j.getHostMountPoint()\n\tif subPath != \"/\" {\n\t\tvalue.Fuse.SubPath = subPath\n\t\toptions[\"subdir\"] = subPath\n\t}\n\n\tvar storagePath = DefaultCacheDir\n\tvar volumeType = common.VolumeTypeHostPath\n\tif tiredStoreLevel != nil {\n\t\t// juicefs cache-dir use colon (:) to separate multiple paths\n\t\t// community doc: https://juicefs.com/docs/community/command_reference/#juicefs-mount\n\t\t// enterprise doc: https://juicefs.com/docs/cloud/commands_reference#mount\n\t\t// /mnt/disk1/bigboot or /mnt/disk1/bigboot:/mnt/disk2/bigboot\n\t\tstoragePath = tiredStoreLevel.Path\n\t\tif tiredStoreLevel.Quota != nil {\n\t\t\tq := tiredStoreLevel.Quota\n\t\t\t// juicefs cache-size should be integer in MiB\n\t\t\t// community doc: https://juicefs.com/docs/community/command_reference/#juicefs-mount\n\t\t\t// enterprise doc: https://juicefs.com/docs/cloud/commands_reference#mount\n\t\t\tcacheSize := q.Value() >> 20\n\t\t\toptions[\"cache-size\"] = strconv.FormatInt(cacheSize, 10)\n\t\t}\n\t\tif tiredStoreLevel.Low != \"\" {\n\t\t\toptions[\"free-space-ratio\"] = tiredStoreLevel.Low\n\t\t}\n\t\tvolumeType = tiredStoreLevel.VolumeType\n\t}\n\toriginPath := strings.Split(storagePath, \":\")\n\toptions[\"cache-dir\"] = storagePath\n\n\t// transform cacheDir\n\tvalue.CacheDirs = make(map[string]cache)\n\tfor i, v := range originPath {\n\t\tvalue.CacheDirs[strconv.Itoa(i+1)] = cache{\n\t\t\tPath: v,\n\t\t\tType: string(volumeType),\n\t\t}\n\t}\n\n\treturn options, nil\n}", "is_vulnerable": 0}
{"code": "func (iter *ListResultIterator) Next() error {\n\treturn iter.NextWithContext(context.Background())\n}", "is_vulnerable": 0}
{"code": "func Register(mgr manager.Manager, cfg config.Config) error {\n\tclient, err := kubelet.InitNodeAuthorizedClient(cfg.KubeletConfigPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcsiDriver := NewDriver(cfg.NodeId, cfg.Endpoint, mgr.GetClient(), mgr.GetAPIReader(), client)\n\n\tif err := mgr.Add(csiDriver); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (t *TestPodLogsServer) Send(log *application.LogEntry) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\ts.log.Errorw(\"The javascript processor caused an unexpected panic \"+\n\t\t\t\t\"while processing an event. Recovering, but please report this.\",\n\t\t\t\t\"event\", mapstr.M{\"original\": b.Fields.String()},\n\t\t\t\t\"panic\", r,\n\t\t\t\tzap.Stack(\"stack\"))\n\t\t\tif !s.evt.IsCancelled() {\n\t\t\t\tout = b\n\t\t\t}\n\t\t\terr = fmt.Errorf(\"unexpected panic in javascript processor: %v\", r)\n\t\t\tif s.tagOnException != \"\" {\n\t\t\t\tmapstr.AddTags(b.Fields, []string{s.tagOnException})\n\t\t\t}\n\t\t\tappendString(b.Fields, \"error.message\", err.Error(), false)\n\t\t}\n\t}()", "is_vulnerable": 1}
{"code": "\tcheckIdLen := func(id string) {\n\t\tif len(id) > wh.config.WorkerBuildIdSizeLimit() {\n\t\t\terrDeets = append(errDeets, fmt.Sprintf(\" Worker build IDs to be no larger than %v characters\",\n\t\t\t\twh.config.WorkerBuildIdSizeLimit()))\n\t\t}\n\t\tif err := common.ValidateUTF8String(\"BuildId\", id); err != nil {\n\t\t\terrDeets = append(errDeets, err.Error())\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func (t *TargetAPI) Ping() {\n\treq := struct {\n\t\tID       *int64  `json:\"id\"`\n\t\tEndpoint *string `json:\"endpoint\"`\n\t\tUsername *string `json:\"username\"`\n\t\tPassword *string `json:\"password\"`\n\t\tInsecure *bool   `json:\"insecure\"`\n\t}{}\n\tt.DecodeJSONReq(&req)\n\n\ttarget := &models.RepTarget{}\n\tif req.ID != nil {\n\t\tvar err error\n\t\ttarget, err = dao.GetRepTarget(*req.ID)\n\t\tif err != nil {\n\t\t\tt.HandleInternalServerError(fmt.Sprintf(\"failed to get target %d: %v\", *req.ID, err))\n\t\t\treturn\n\t\t}\n\t\tif target == nil {\n\t\t\tt.HandleNotFound(fmt.Sprintf(\"target %d not found\", *req.ID))\n\t\t\treturn\n\t\t}\n\t\tif len(target.Password) != 0 {\n\t\t\ttarget.Password, err = utils.ReversibleDecrypt(target.Password, t.secretKey)\n\t\t\tif err != nil {\n\t\t\t\tt.HandleInternalServerError(fmt.Sprintf(\"failed to decrypt password: %v\", err))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tif req.Endpoint != nil {\n\t\ttarget.URL = *req.Endpoint\n\t}\n\tif req.Username != nil {\n\t\ttarget.Username = *req.Username\n\t}\n\tif req.Password != nil {\n\t\ttarget.Password = *req.Password\n\t}\n\tif req.Insecure != nil {\n\t\ttarget.Insecure = *req.Insecure\n\t}\n\n\tif len(target.URL) == 0 {\n\t\tt.HandleBadRequest(\"empty endpoint\")\n\t\treturn\n\t}\n\n\tt.ping(target.URL, target.Username, target.Password, target.Insecure)\n}", "is_vulnerable": 1}
{"code": "func TestAES_GCM_NIST_gcmEncryptExtIV256_PTLen_104_Test_3(t *testing.T) {\n\tiv, _ := hex.DecodeString(\"4742357c335913153ff0eb0f\")\n\tkey, _ := hex.DecodeString(\"e5a0eb92cc2b064e1bc80891faf1fab5e9a17a9c3a984e25416720e30e6c2b21\")\n\tplaintext, _ := hex.DecodeString(\"8499893e16b0ba8b007d54665a\")\n\texpected, _ := hex.DecodeString(\"eb8e6175f1fe38eb1acf95fd51\")\n\ttag, _ := hex.DecodeString(\"88a8b74bb74fda553e91020a23deed45\")\n\taesgcmTest(t, iv, key, plaintext, expected, tag)\n}", "is_vulnerable": 0}
{"code": "func MakeFilterGenerators(serviceInfo *ci.ServiceInfo) ([]FilterGenerator, error) {\n\treturn []FilterGenerator{\n\t\t&filtergen.HeaderSanitizerGenerator{},\n\t\tfiltergen.NewCORSGenerator(serviceInfo),\n\n\t\t// Health check filter is behind Path Matcher filter, since Service Control\n\t\t// filter needs to get the corresponding rule for health check in order to skip Report\n\t\tfiltergen.NewHealthCheckGenerator(serviceInfo),\n\t\tfiltergen.NewCompressorGenerator(serviceInfo, filtergen.GzipCompressor),\n\t\tfiltergen.NewCompressorGenerator(serviceInfo, filtergen.BrotliCompressor),\n\t\tfiltergen.NewJwtAuthnGenerator(serviceInfo),\n\t\tfiltergen.NewServiceControlGenerator(serviceInfo),\n\n\t\t// grpc-web filter should be before grpc transcoder filter.\n\t\t// It converts content-type application/grpc-web to application/grpc and\n\t\t// grpc transcoder will bypass requests with application/grpc content type.\n\t\t// Otherwise grpc transcoder will try to transcode a grpc-web request which\n\t\t// will fail.\n\t\tfiltergen.NewGRPCWebGenerator(serviceInfo),\n\t\tfiltergen.NewGRPCTranscoderGenerator(serviceInfo),\n\n\t\tfiltergen.NewBackendAuthGenerator(serviceInfo),\n\t\tfiltergen.NewPathRewriteGenerator(serviceInfo),\n\t\tfiltergen.NewGRPCMetadataScrubberGenerator(serviceInfo),\n\n\t\t// Add Envoy Router filter so requests are routed upstream.\n\t\t// Router filter should be the last.\n\t\t&filtergen.RouterGenerator{},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func podHasContainerWithName(pod *api.Pod, containerName string) bool {\n\tfor _, c := range pod.Spec.Containers {\n\t\tif c.Name == containerName {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (d *Driver) getLower(parent string) (string, error) {\n\tparentDir := d.dir(parent)\n\n\t// Ensure parent exists\n\tif _, err := os.Lstat(parentDir); err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// Read Parent link fileA\n\tparentLink, err := ioutil.ReadFile(path.Join(parentDir, \"link\"))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tlowers := []string{path.Join(linkDir, string(parentLink))}\n\n\tparentLower, err := ioutil.ReadFile(path.Join(parentDir, lowerFile))\n\tif err == nil {\n\t\tparentLowers := strings.Split(string(parentLower), \":\")\n\t\tlowers = append(lowers, parentLowers...)\n\t}\n\treturn strings.Join(lowers, \":\"), nil\n}", "is_vulnerable": 1}
{"code": "\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tctx := c.Context()\n\n\t\t\tvers := common.GetVersion()\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\t\t\tvers.LogStartupInfo(\n\t\t\t\t\"ArgoCD API Server\",\n\t\t\t\tmap[string]any{\n\t\t\t\t\t\"namespace\": namespace,\n\t\t\t\t\t\"port\":      listenPort,\n\t\t\t\t},\n\t\t\t)\n\n\t\t\tcli.SetLogFormat(cmdutil.LogFormat)\n\t\t\tcli.SetLogLevel(cmdutil.LogLevel)\n\t\t\tcli.SetGLogLevel(glogLevel)\n\n\t\t\tconfig, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\terrors.CheckError(v1alpha1.SetK8SConfigDefaults(config))\n\n\t\t\ttlsConfigCustomizer, err := tlsConfigCustomizerSrc()\n\t\t\terrors.CheckError(err)\n\t\t\tcache, err := cacheSrc()\n\t\t\terrors.CheckError(err)\n\n\t\t\tkubeclientset := kubernetes.NewForConfigOrDie(config)\n\n\t\t\tappclientsetConfig, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\terrors.CheckError(v1alpha1.SetK8SConfigDefaults(appclientsetConfig))\n\t\t\tconfig.UserAgent = fmt.Sprintf(\"argocd-server/%s (%s)\", vers.Version, vers.Platform)\n\n\t\t\tif failureRetryCount > 0 {\n\t\t\t\tappclientsetConfig = kube.AddFailureRetryWrapper(appclientsetConfig, failureRetryCount, failureRetryPeriodMilliSeconds)\n\t\t\t}\n\t\t\tappClientSet := appclientset.NewForConfigOrDie(appclientsetConfig)\n\t\t\ttlsConfig := apiclient.TLSConfiguration{\n\t\t\t\tDisableTLS:       repoServerPlaintext,\n\t\t\t\tStrictValidation: repoServerStrictTLS,\n\t\t\t}\n\n\t\t\t// Load CA information to use for validating connections to the\n\t\t\t// repository server, if strict TLS validation was requested.\n\t\t\tif !repoServerPlaintext && repoServerStrictTLS {\n\t\t\t\tpool, err := tls.LoadX509CertPool(\n\t\t\t\t\tfmt.Sprintf(\"%s/server/tls/tls.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t\tfmt.Sprintf(\"%s/server/tls/ca.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t\t}\n\t\t\t\ttlsConfig.Certificates = pool\n\t\t\t}\n\n\t\t\tdexTlsConfig := &dex.DexTLSConfig{\n\t\t\t\tDisableTLS:       dexServerPlaintext,\n\t\t\t\tStrictValidation: dexServerStrictTLS,\n\t\t\t}\n\n\t\t\tif !dexServerPlaintext && dexServerStrictTLS {\n\t\t\t\tpool, err := tls.LoadX509CertPool(\n\t\t\t\t\tfmt.Sprintf(\"%s/dex/tls/ca.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t\t}\n\t\t\t\tdexTlsConfig.RootCAs = pool\n\t\t\t\tcert, err := tls.LoadX509Cert(\n\t\t\t\t\tfmt.Sprintf(\"%s/dex/tls/tls.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t\t}\n\t\t\t\tdexTlsConfig.Certificate = cert.Raw\n\t\t\t}\n\n\t\t\trepoclientset := apiclient.NewRepoServerClientset(repoServerAddress, repoServerTimeoutSeconds, tlsConfig)\n\t\t\tif rootPath != \"\" {\n\t\t\t\tif baseHRef != \"\" && baseHRef != rootPath {\n\t\t\t\t\tlog.Warnf(\"--basehref and --rootpath had conflict: basehref: %s rootpath: %s\", baseHRef, rootPath)\n\t\t\t\t}\n\t\t\t\tbaseHRef = rootPath\n\t\t\t}\n\n\t\t\targoCDOpts := server.ArgoCDServerOpts{\n\t\t\t\tInsecure:              insecure,\n\t\t\t\tListenPort:            listenPort,\n\t\t\t\tListenHost:            listenHost,\n\t\t\t\tMetricsPort:           metricsPort,\n\t\t\t\tMetricsHost:           metricsHost,\n\t\t\t\tNamespace:             namespace,\n\t\t\t\tBaseHRef:              baseHRef,\n\t\t\t\tRootPath:              rootPath,\n\t\t\t\tKubeClientset:         kubeclientset,\n\t\t\t\tAppClientset:          appClientSet,\n\t\t\t\tRepoClientset:         repoclientset,\n\t\t\t\tDexServerAddr:         dexServerAddress,\n\t\t\t\tDexTLSConfig:          dexTlsConfig,\n\t\t\t\tDisableAuth:           disableAuth,\n\t\t\t\tContentTypes:          strings.Split(contentTypes, \";\"),\n\t\t\t\tEnableGZip:            enableGZip,\n\t\t\t\tTLSConfigCustomizer:   tlsConfigCustomizer,\n\t\t\t\tCache:                 cache,\n\t\t\t\tXFrameOptions:         frameOptions,\n\t\t\t\tContentSecurityPolicy: contentSecurityPolicy,\n\t\t\t\tRedisClient:           redisClient,\n\t\t\t\tStaticAssetsDir:       staticAssetsDir,\n\t\t\t\tApplicationNamespaces: applicationNamespaces,\n\t\t\t\tEnableProxyExtension:  enableProxyExtension,\n\t\t\t}\n\n\t\t\tstats.RegisterStackDumper()\n\t\t\tstats.StartStatsTicker(10 * time.Minute)\n\t\t\tstats.RegisterHeapDumper(\"memprofile\")\n\t\t\targocd := server.NewServer(ctx, argoCDOpts)\n\t\t\targocd.Init(ctx)\n\t\t\tlns, err := argocd.Listen()\n\t\t\terrors.CheckError(err)\n\t\t\tfor {\n\t\t\t\tvar closer func()\n\t\t\t\tctx, cancel := context.WithCancel(ctx)\n\t\t\t\tif otlpAddress != \"\" {\n\t\t\t\t\tcloser, err = traceutil.InitTracer(ctx, \"argocd-server\", otlpAddress)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Fatalf(\"failed to initialize tracing: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\targocd.Run(ctx, lns)\n\t\t\t\tcancel()\n\t\t\t\tif closer != nil {\n\t\t\t\t\tcloser()\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t}\n\n\tclientConfig = cli.AddKubectlFlagsToCmd(command)\n\tcommand.Flags().BoolVar(&insecure, \"insecure\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_INSECURE\", false), \"Run server without TLS\")\n\tcommand.Flags().StringVar(&staticAssetsDir, \"staticassets\", env.StringFromEnv(\"ARGOCD_SERVER_STATIC_ASSETS\", \"/shared/app\"), \"Directory path that contains additional static assets\")\n\tcommand.Flags().StringVar(&baseHRef, \"basehref\", env.StringFromEnv(\"ARGOCD_SERVER_BASEHREF\", \"/\"), \"Value for base href in index.html. Used if Argo CD is running behind reverse proxy under subpath different from /\")\n\tcommand.Flags().StringVar(&rootPath, \"rootpath\", env.StringFromEnv(\"ARGOCD_SERVER_ROOTPATH\", \"\"), \"Used if Argo CD is running behind reverse proxy under subpath different from /\")\n\tcommand.Flags().StringVar(&cmdutil.LogFormat, \"logformat\", env.StringFromEnv(\"ARGOCD_SERVER_LOGFORMAT\", \"text\"), \"Set the logging format. One of: text|json\")\n\tcommand.Flags().StringVar(&cmdutil.LogLevel, \"loglevel\", env.StringFromEnv(\"ARGOCD_SERVER_LOG_LEVEL\", \"info\"), \"Set the logging level. One of: debug|info|warn|error\")\n\tcommand.Flags().IntVar(&glogLevel, \"gloglevel\", 0, \"Set the glog logging level\")\n\tcommand.Flags().StringVar(&repoServerAddress, \"repo-server\", env.StringFromEnv(\"ARGOCD_SERVER_REPO_SERVER\", common.DefaultRepoServerAddr), \"Repo server address\")\n\tcommand.Flags().StringVar(&dexServerAddress, \"dex-server\", env.StringFromEnv(\"ARGOCD_SERVER_DEX_SERVER\", common.DefaultDexServerAddr), \"Dex server address\")\n\tcommand.Flags().BoolVar(&disableAuth, \"disable-auth\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_DISABLE_AUTH\", false), \"Disable client authentication\")\n\tcommand.Flags().StringVar(&contentTypes, \"api-content-types\", \"application/json\", \"Semicolon separated list of allowed content types for non GET api requests. Any content type is allowed if empty.\")\n\tcommand.Flags().BoolVar(&enableGZip, \"enable-gzip\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_ENABLE_GZIP\", true), \"Enable GZIP compression\")\n\tcommand.AddCommand(cli.NewVersionCmd(cliName))\n\tcommand.Flags().StringVar(&listenHost, \"address\", env.StringFromEnv(\"ARGOCD_SERVER_LISTEN_ADDRESS\", common.DefaultAddressAPIServer), \"Listen on given address\")\n\tcommand.Flags().IntVar(&listenPort, \"port\", common.DefaultPortAPIServer, \"Listen on given port\")\n\tcommand.Flags().StringVar(&metricsHost, env.StringFromEnv(\"ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\", \"metrics-address\"), common.DefaultAddressAPIServerMetrics, \"Listen for metrics on given address\")\n\tcommand.Flags().IntVar(&metricsPort, \"metrics-port\", common.DefaultPortArgoCDAPIServerMetrics, \"Start metrics on given port\")\n\tcommand.Flags().StringVar(&otlpAddress, \"otlp-address\", env.StringFromEnv(\"ARGOCD_SERVER_OTLP_ADDRESS\", \"\"), \"OpenTelemetry collector address to send traces to\")\n\tcommand.Flags().IntVar(&repoServerTimeoutSeconds, \"repo-server-timeout-seconds\", env.ParseNumFromEnv(\"ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\", 60, 0, math.MaxInt64), \"Repo server RPC call timeout seconds.\")\n\tcommand.Flags().StringVar(&frameOptions, \"x-frame-options\", env.StringFromEnv(\"ARGOCD_SERVER_X_FRAME_OPTIONS\", \"sameorigin\"), \"Set X-Frame-Options header in HTTP responses to `value`. To disable, set to \\\"\\\".\")\n\tcommand.Flags().StringVar(&contentSecurityPolicy, \"content-security-policy\", env.StringFromEnv(\"ARGOCD_SERVER_CONTENT_SECURITY_POLICY\", \"frame-ancestors 'self';\"), \"Set Content-Security-Policy header in HTTP responses to `value`. To disable, set to \\\"\\\".\")\n\tcommand.Flags().BoolVar(&repoServerPlaintext, \"repo-server-plaintext\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\", false), \"Use a plaintext client (non-TLS) to connect to repository server\")\n\tcommand.Flags().BoolVar(&repoServerStrictTLS, \"repo-server-strict-tls\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\", false), \"Perform strict validation of TLS certificates when connecting to repo server\")\n\tcommand.Flags().BoolVar(&dexServerPlaintext, \"dex-server-plaintext\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\", false), \"Use a plaintext client (non-TLS) to connect to dex server\")\n\tcommand.Flags().BoolVar(&dexServerStrictTLS, \"dex-server-strict-tls\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\", false), \"Perform strict validation of TLS certificates when connecting to dex server\")\n\tcommand.Flags().StringSliceVar(&applicationNamespaces, \"application-namespaces\", env.StringsFromEnv(\"ARGOCD_APPLICATION_NAMESPACES\", []string{}, \",\"), \"List of additional namespaces where application resources can be managed in\")\n\tcommand.Flags().BoolVar(&enableProxyExtension, \"enable-proxy-extension\", env.ParseBoolFromEnv(\"ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\", false), \"Enable Proxy Extension feature\")\n\ttlsConfigCustomizerSrc = tls.AddTLSFlagsToCmd(command)\n\tcacheSrc = servercache.AddCacheFlagsToCmd(command, func(client *redis.Client) {\n\t\tredisClient = client\n\t})\n\treturn command\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(fmt.Sprintf(\"case=%d/description=%s\", k, c.description), func(t *testing.T) {\n\t\t\tc.mock()\n\t\t\terr := h.RevokeToken(nil, token, tokenType, c.client)\n\n\t\t\tif c.expectErr != nil {\n\t\t\t\trequire.EqualError(t, err, c.expectErr.Error())\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "\t\tsrv := a.CreateSASL(\"PLAIN\", &net.TCPAddr{}, func(id string) error {\n\t\t\tif id != \"user1\" {\n\t\t\t\tt.Fatal(\"Wrong auth. identities passed to callback:\", id)\n\t\t\t}\n\t\t\treturn nil\n\t\t})", "is_vulnerable": 0}
{"code": "func TestUpstreamHashBy(t *testing.T) {\n\tec := NewAnnotationExtractor(mockCfg{})\n\ting := buildIngress()\n\n\tfooAnns := []struct {\n\t\tannotations map[string]string\n\t\ter          string\n\t}{\n\t\t{map[string]string{annotationUpstreamHashBy: \"$request_uri\"}, \"$request_uri\"},\n\t\t{map[string]string{annotationUpstreamHashBy: \"false\"}, \"false\"},\n\t\t{map[string]string{annotationUpstreamHashBy + \"_no\": \"true\"}, \"\"},\n\t\t{map[string]string{}, \"\"},\n\t\t{nil, \"\"},\n\t}\n\n\tfor _, foo := range fooAnns {\n\t\ting.SetAnnotations(foo.annotations)\n\t\tr := ec.Extract(ing).UpstreamHashBy.UpstreamHashBy\n\t\tif r != foo.er {\n\t\t\tt.Errorf(\"Returned %v but expected %v\", r, foo.er)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(fmt.Sprintf(\"thanos engine enabled=%t\", thanosEngine), func(t *testing.T) {\n\t\t\tvar queryEngine v1.QueryEngine\n\t\t\tif thanosEngine {\n\t\t\t\tqueryEngine = engine.New(engine.Opts{\n\t\t\t\t\tEngineOpts:        opts,\n\t\t\t\t\tLogicalOptimizers: logicalplan.AllOptimizers,\n\t\t\t\t})\n\t\t\t} else {\n\t\t\t\tqueryEngine = promql.NewEngine(opts)\n\t\t\t}\n\t\t\t// Mock the finder to simulate we need to query two blocks.\n\t\t\tfinder := &blocksFinderMock{\n\t\t\t\tService: services.NewIdleService(nil, nil),\n\t\t\t}\n\t\t\tfinder.On(\"GetBlocks\", mock.Anything, \"user-1\", mock.Anything, mock.Anything).Return(bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t}, map[ulid.ULID]*bucketindex.BlockDeletionMark(nil), error(nil))\n\n\t\t\t// Mock the store to simulate each block is queried from a different store-gateway.\n\t\t\tgateway1 := &storeGatewayClientMock{remoteAddr: \"1.1.1.1\", mockedSeriesResponses: []*storepb.SeriesResponse{\n\t\t\t\t{\n\t\t\t\t\tResult: &storepb.SeriesResponse_Series{\n\t\t\t\t\t\tSeries: &storepb.Series{\n\t\t\t\t\t\t\tLabels: series1,\n\t\t\t\t\t\t\tChunks: []storepb.AggrChunk{\n\t\t\t\t\t\t\t\tcreateAggrChunkWithSamples(series1Samples[:3]...), // First half.\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, {\n\t\t\t\t\tResult: &storepb.SeriesResponse_Series{\n\t\t\t\t\t\tSeries: &storepb.Series{\n\t\t\t\t\t\t\tLabels: series2,\n\t\t\t\t\t\t\tChunks: []storepb.AggrChunk{\n\t\t\t\t\t\t\t\tcreateAggrChunkWithSamples(series2Samples[:3]...),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tmockHintsResponse(block1),\n\t\t\t}}\n\n\t\t\tgateway2 := &storeGatewayClientMock{remoteAddr: \"2.2.2.2\", mockedSeriesResponses: []*storepb.SeriesResponse{\n\t\t\t\t{\n\t\t\t\t\tResult: &storepb.SeriesResponse_Series{\n\t\t\t\t\t\tSeries: &storepb.Series{\n\t\t\t\t\t\t\tLabels: series1,\n\t\t\t\t\t\t\tChunks: []storepb.AggrChunk{\n\t\t\t\t\t\t\t\tcreateAggrChunkWithSamples(series1Samples[3:]...), // Second half.\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, {\n\t\t\t\t\tResult: &storepb.SeriesResponse_Series{\n\t\t\t\t\t\tSeries: &storepb.Series{\n\t\t\t\t\t\t\tLabels: series2,\n\t\t\t\t\t\t\tChunks: []storepb.AggrChunk{\n\t\t\t\t\t\t\t\tcreateAggrChunkWithSamples(series2Samples[3:]...),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tmockHintsResponse(block2),\n\t\t\t}}\n\n\t\t\tstores := &blocksStoreSetMock{\n\t\t\t\tService: services.NewIdleService(nil, nil),\n\t\t\t\tmockedResponses: []interface{}{\n\t\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t\tgateway1: {block1},\n\t\t\t\t\t\tgateway2: {block2},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\t// Instance the querier that will be executed to run the query.\n\t\t\tqueryable, err := NewBlocksStoreQueryable(stores, finder, NewBlocksConsistencyChecker(0, 0, logger, nil), &blocksStoreLimitsMock{}, 0, logger, nil)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, services.StartAndAwaitRunning(context.Background(), queryable))\n\t\t\tdefer services.StopAndAwaitTerminated(context.Background(), queryable) // nolint:errcheck\n\n\t\t\t// Run a query.\n\t\t\tctx := user.InjectOrgID(context.Background(), \"user-1\")\n\t\t\tq, err := queryEngine.NewRangeQuery(ctx, queryable, nil, `{__name__=~\"metric.*\"}`, time.Unix(1589759955, 0), time.Unix(1589760030, 0), 15*time.Second)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tres := q.Exec(ctx)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, res.Err)\n\n\t\t\tmatrix, err := res.Matrix()\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.Len(t, matrix, 2)\n\n\t\t\tassert.Equal(t, labelpb.ZLabelsToPromLabels(series1), matrix[0].Metric)\n\t\t\tassert.Equal(t, labelpb.ZLabelsToPromLabels(series2), matrix[1].Metric)\n\t\t\tassert.Equal(t, series1Samples, matrix[0].Floats)\n\t\t\tassert.Equal(t, series2Samples, matrix[1].Floats)\n\t\t})", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateContainerSnapYamlNonRegularFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\td := c.MkDir()\n\tc.Assert(os.Chmod(d, 0755), IsNil)\n\tc.Assert(os.Mkdir(filepath.Join(d, \"meta\"), 0755), IsNil)\n\tc.Assert(syscall.Mkfifo(filepath.Join(d, \"meta\", \"snap.yaml\"), 0444), IsNil)\n\n\t// snapdir's / and /meta are 0755 (i.e. OK),\n\t// /meta/snap.yaml exists, is readable, but isn't a file\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(snapdir.New(d), info, discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 1}
{"code": "\treturn func() {\n\t\tfor _, p := range paths {\n\t\t\tst, err := os.Lstat(p)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif st.IsDir() {\n\t\t\t\tentries, err := os.ReadDir(p)\n\t\t\t\tif err != nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif len(entries) != 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} else if st.Size() != 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Back up the timestamps of the dir for reproducible builds\n\t\t\t// https://github.com/moby/buildkit/issues/3148\n\t\t\tdir := filepath.Dir(p)\n\t\t\tdirSt, err := os.Stat(dir)\n\t\t\tif err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to stat %q (parent of mount stub %q)\", dir, p)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tmtime := dirSt.ModTime()\n\t\t\tatime, err := system.Atime(dirSt)\n\t\t\tif err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to stat atime of %q (parent of mount stub %q)\", dir, p)\n\t\t\t\tatime = mtime\n\t\t\t}\n\n\t\t\tif err := os.Remove(p); err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to remove mount stub %q\", p)\n\t\t\t}\n\n\t\t\t// Restore the timestamps of the dir\n\t\t\tif err := os.Chtimes(dir, atime, mtime); err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to restore time time mount stub timestamp (os.Chtimes(%q, %v, %v))\", dir, atime, mtime)\n\t\t\t}\n\t\t}\n\t}", "is_vulnerable": 1}
{"code": "func EqualValues(t TestingT, expected interface{}, actual interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.EqualValues(t, expected, actual, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\t\t\tValidate: func(ingresses []*ingress.Ingress, upstreams []*ingress.Backend, servers []*ingress.Server) {\n\t\t\t\tif len(servers) != 2 {\n\t\t\t\t\tt.Errorf(\"servers count should be 2, got %d\", len(servers))\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\ts := servers[1]\n\n\t\t\t\tif s.ServerSnippet != \"\" {\n\t\t\t\t\tt.Errorf(\"server snippet should be empty, got '%s'\", s.ServerSnippet)\n\t\t\t\t}\n\n\t\t\t\tif s.Locations[0].ConfigurationSnippet != \"\" {\n\t\t\t\t\tt.Errorf(\"config snippet should be empty, got '%s'\", s.Locations[0].ConfigurationSnippet)\n\t\t\t\t}\n\n\t\t\t\tif len(s.Locations[0].Allowlist.CIDR) != 1 || s.Locations[0].Allowlist.CIDR[0] != \"10.0.0.0/24\" {\n\t\t\t\t\tt.Errorf(\"allow list was incorrectly dropped, len should be 1 and contain 10.0.0.0/24\")\n\t\t\t\t}\n\n\t\t\t},", "is_vulnerable": 0}
{"code": "func TestFunctionCall_EncodeDecode(t *testing.T) {\n\ttype fields struct {\n\t\tFunction         uint32\n\t\tArgFormatCodes   []uint16\n\t\tArguments        [][]byte\n\t\tResultFormatCode uint16\n\t}\n\ttests := []struct {\n\t\tname    string\n\t\tfields  fields\n\t\twantErr bool\n\t}{\n\t\t{\"valid\", fields{uint32(123), []uint16{0, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(1)}, false},\n\t\t{\"invalid format code\", fields{uint32(123), []uint16{2, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(0)}, true},\n\t\t{\"invalid result format code\", fields{uint32(123), []uint16{1, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(2)}, true},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tsrc := &FunctionCall{\n\t\t\t\tFunction:         tt.fields.Function,\n\t\t\t\tArgFormatCodes:   tt.fields.ArgFormatCodes,\n\t\t\t\tArguments:        tt.fields.Arguments,\n\t\t\t\tResultFormatCode: tt.fields.ResultFormatCode,\n\t\t\t}\n\t\t\tencoded := src.Encode([]byte{})\n\t\t\tdst := &FunctionCall{}\n\t\t\t// Check the header\n\t\t\tmsgTypeCode := encoded[0]\n\t\t\tif msgTypeCode != 'F' {\n\t\t\t\tt.Errorf(\"msgTypeCode %v should be 'F'\", msgTypeCode)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Check length, does not include type code character\n\t\t\tl := binary.BigEndian.Uint32(encoded[1:5])\n\t\t\tif int(l) != (len(encoded) - 1) {\n\t\t\t\tt.Errorf(\"Incorrect message length, got = %v, wanted = %v\", l, len(encoded))\n\t\t\t}\n\t\t\t// Check decoding works as expected\n\t\t\terr := dst.Decode(encoded[5:])\n\t\t\tif err != nil {\n\t\t\t\tif !tt.wantErr {\n\t\t\t\t\tt.Errorf(\"FunctionCall.Decode() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(src, dst) {\n\t\t\t\tt.Error(\"difference after encode / decode cycle\")\n\t\t\t\tt.Errorf(\"src = %v\", src)\n\t\t\t\tt.Errorf(\"dst = %v\", dst)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func updateVersionApplication(configDBSession *gorm.DB) bool {\n\n\tvar err error\n\tvar saveConfig = false\n\trecordApp := model.TableApplications{}\n\trecordApp.VersionApplication = getVersion()\n\trecordApp.NameApplication = getName()\n\n\trecordApp.HostApplication = viper.GetString(\"system_settings.hostname\")\n\tif recordApp.HostApplication == \"\" {\n\t\trecordApp.HostApplication, err = os.Hostname()\n\t\tif err != nil {\n\t\t\trecordApp.HostApplication = \"unknown\"\n\t\t}\n\t\tviper.Set(\"system_settings.hostname\", recordApp.HostApplication)\n\t\tsaveConfig = true\n\n\t}\n\n\trecordApp.GUID = viper.GetString(\"system_settings.uuid\")\n\tif recordApp.GUID == \"\" {\n\t\trecordApp.GUID = uuid.NewV4().String()\n\t\tviper.Set(\"system_settings.uuid\", recordApp.GUID)\n\t\tsaveConfig = true\n\t}\n\n\t//generate JWT\n\tconfig.Setting.AUTH_SETTINGS.JwtSecret = viper.GetString(\"auth_settings.jwt_secret\")\n\tif config.Setting.AUTH_SETTINGS.JwtSecret == \"\" {\n\t\tconfig.Setting.AUTH_SETTINGS.JwtSecret = uuid.NewV4().String()\n\t\tviper.Set(\"auth_settings.jwt_secret\", config.Setting.AUTH_SETTINGS.JwtSecret)\n\t\tsaveConfig = true\n\t}\n\n\tif saveConfig {\n\t\terr := viper.WriteConfig()\n\t\tif err != nil {\n\t\t\tfmt.Println(\"No configuration file loaded: \", err)\n\t\t\tlogger.Error(\"No configuration file loaded - using defaults\")\n\t\t\treturn false\n\t\t}\n\t}\n\n\tif err := configDBSession.Debug().Set(\n\t\t\"gorm:insert_option\",\n\t\tfmt.Sprintf(\"ON CONFLICT (name,host) DO UPDATE SET version = EXCLUDED.version, guid = EXCLUDED.guid\"),\n\t).Table(\"applications\").Create(&recordApp).Error; err != nil {\n\t\tlogger.Error(\"Error by updating application table\", err)\n\t\treturn false\n\t}\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func GetBoolAnnotation(name string, ing *networking.Ingress, fields AnnotationFields) (bool, error) {\n\tv, err := checkAnnotation(name, ing, fields)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn ingAnnotations(ing.GetAnnotations()).parseBool(v)\n}", "is_vulnerable": 0}
{"code": "func TestServer_DeltaAggregatedResources_v3_BasicProtocol_TCP(t *testing.T) {\n\taclResolve := func(id string) (acl.Authorizer, error) {\n\t\t// Allow all\n\t\treturn acl.RootAuthorizer(\"manage\"), nil\n\t}\n\tscenario := newTestServerDeltaScenario(t, aclResolve, \"web-sidecar-proxy\", \"\", 0)\n\tmgr, errCh, envoy := scenario.mgr, scenario.errCh, scenario.envoy\n\n\tsid := structs.NewServiceID(\"web-sidecar-proxy\", nil)\n\n\t// Register the proxy to create state needed to Watch() on\n\tmgr.RegisterProxy(t, sid)\n\n\tvar snap *proxycfg.ConfigSnapshot\n\n\ttestutil.RunStep(t, \"initial setup\", func(t *testing.T) {\n\t\tsnap = newTestSnapshot(t, nil, \"\", &structs.ProxyConfigEntry{\n\t\t\tKind: structs.ProxyDefaults,\n\t\t\tName: structs.ProxyConfigGlobal,\n\t\t\tEnvoyExtensions: []structs.EnvoyExtension{\n\t\t\t\t{\n\t\t\t\t\tName: api.BuiltinLuaExtension,\n\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\"ProxyType\": \"connect-proxy\",\n\t\t\t\t\t\t\"Listener\":  \"inbound\",\n\t\t\t\t\t\t\"Script\":    \"x = 0\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\n\t\t// Send initial cluster discover. We'll assume we are testing a partial\n\t\t// reconnect and include some initial resource versions that will be\n\t\t// cleaned up.\n\t\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tInitialResourceVersions: mustMakeVersionMap(t,\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// Check no response sent yet\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\trequireProtocolVersionGauge(t, scenario, \"v3\", 1)\n\n\t\t// Deliver a new snapshot (tcp with one tcp upstream)\n\t\tmgr.DeliverConfig(t, sid, snap)\n\t})\n\n\ttestutil.RunStep(t, \"first sync\", func(t *testing.T) {\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ClusterType,\n\t\t\tNonce:   hexString(1),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:local_app\"),\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:db\"),\n\t\t\t\t// SAME_AS_INITIAL_VERSION: makeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// Envoy then tries to discover endpoints for those clusters.\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\t// We'll assume we are testing a partial \"reconnect\"\n\t\t\tInitialResourceVersions: mustMakeVersionMap(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t\t// \"geo-cache.default.dc1.query.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t\t//\n\t\t\t\t// Include \"fake-endpoints\" here to test subscribing to an unknown\n\t\t\t\t// thing and have consul tell us there's no data for it.\n\t\t\t\t\"fake-endpoints\",\n\t\t\t},\n\t\t})\n\n\t\t// We should get a response immediately since the config is already present in\n\t\t// the server for endpoints. Note that this should not be racy if the server\n\t\t// is behaving well since the Cluster send above should be blocked until we\n\t\t// deliver a new config version.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.EndpointType,\n\t\t\tNonce:   hexString(2),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:db\"),\n\t\t\t\t// SAME_AS_INITIAL_VERSION: makeTestEndpoints(t, snap, \"tcp:geo-cache\"),\n\t\t\t\t// SAME_AS_INITIAL_VERSION: \"fake-endpoints\",\n\t\t\t),\n\t\t})\n\n\t\t// After receiving the endpoints Envoy sends an ACK for the cluster\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ClusterType, 1)\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// Envoy now sends listener request\n\t\tenvoy.SendDeltaReq(t, xdscommon.ListenerType, nil)\n\n\t\t// It also (in parallel) issues the endpoint ACK\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 2)\n\n\t\t// And should get a response immediately.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ListenerType,\n\t\t\tNonce:   hexString(3),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestListener(t, snap, \"tcp:public_listener\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:db\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// ACKs the listener\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ListenerType, 3)\n\n\t\t// If Envoy re-subscribes to something even if there are no changes we send a\n\t\t// fresh copy.\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"geo-cache.default.dc1.query.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t},\n\t\t})\n\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.EndpointType,\n\t\t\tNonce:   hexString(4),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 4)\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\trequireExtensionMetrics(t, scenario, api.BuiltinLuaExtension, sid, nil)\n\t})\n\n\tdeleteAllButOneEndpoint := func(snap *proxycfg.ConfigSnapshot, uid proxycfg.UpstreamID, targetID string) {\n\t\tsnap.ConnectProxy.ConfigSnapshotUpstreams.WatchedUpstreamEndpoints[uid][targetID] =\n\t\t\tsnap.ConnectProxy.ConfigSnapshotUpstreams.WatchedUpstreamEndpoints[uid][targetID][0:1]\n\t}\n\n\ttestutil.RunStep(t, \"avoid sending config for unsubscribed resource\", func(t *testing.T) {\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesUnsubscribe: []string{\n\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t},\n\t\t})\n\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// now reconfigure the snapshot and JUST edit the endpoints to strike one of the two current endpoints for db.\n\t\tsnap = newTestSnapshot(t, snap, \"\")\n\t\tdeleteAllButOneEndpoint(snap, UID(\"db\"), \"db.default.default.dc1\")\n\t\tmgr.DeliverConfig(t, sid, snap)\n\n\t\t// We never send an EDS reply about this change because Envoy is not subscribed to db anymore.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\ttestutil.RunStep(t, \"restore endpoint subscription\", func(t *testing.T) {\n\t\t// Restore db's deleted endpoints by generating a new snapshot.\n\t\tsnap = newTestSnapshot(t, snap, \"\")\n\t\tmgr.DeliverConfig(t, sid, snap)\n\n\t\t// We never send an EDS reply about this change because Envoy is still not subscribed to db.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// When Envoy re-subscribes to db we send the endpoints for it.\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t},\n\t\t})\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.EndpointType,\n\t\t\tNonce:   hexString(5),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:db\"),\n\t\t\t),\n\t\t})\n\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 5)\n\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\t// NOTE: this has to be the last subtest since it kills the stream\n\ttestutil.RunStep(t, \"simulate an envoy error sending an update to envoy\", func(t *testing.T) {\n\t\t// Force sends to fail\n\t\tenvoy.SetSendErr(errors.New(\"test error\"))\n\n\t\t// Trigger only an EDS update by deleting endpoints again.\n\t\tdeleteAllButOneEndpoint(snap, UID(\"db\"), \"db.default.default.dc1\")\n\n\t\t// We never send any replies about this change because we died.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\tenvoy.Close()\n\tselect {\n\tcase err := <-errCh:\n\t\trequire.NoError(t, err)\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatalf(\"timed out waiting for handler to finish\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (con adminSystemController) GetDir(c *gin.Context) {\n\n\ttype FileNode struct {\n\t\tName string `json:\"name\"`\n\t\tPath string `json:\"path\"`\n\t\tType string `json:\"type\"`\n\t}\n\n\tvar (\n\t\tpath      string\n\t\terr       error\n\t\tfileSlice []FileNode\n\t\tfiles     []fs.FileInfo\n\t)\n\n\tfileSlice = make([]FileNode, 0)\n\tpath = gstrings.JoinStr(configs.RootPath, c.Query(\"path\"))\n\n\tfiles, err = ioutil.ReadDir(path)\n\tif err != nil {\n\t\tcon.Error(c, \"\u83b7\u53d6\u76ee\u5f55\u5931\u8d25\")\n\t\treturn\n\t}\n\n\tfor _, v := range files {\n\t\tvar fileType string\n\t\tif v.IsDir() {\n\t\t\tfileType = \"dir\"\n\t\t} else {\n\t\t\tfileType = \"file\"\n\t\t}\n\t\tfileSlice = append(fileSlice, FileNode{\n\t\t\tName: v.Name(),\n\t\t\tPath: gstrings.JoinStr(c.Query(\"path\"), string(filepath.Separator), v.Name()),\n\t\t\tType: fileType,\n\t\t})\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{\n\t\t\"data\": fileSlice,\n\t})\n}", "is_vulnerable": 1}
{"code": "func Test_CORS_AllowOriginScheme(t *testing.T) {\n\tt.Parallel()\n\ttests := []struct {\n\t\treqOrigin, pattern string\n\t\tshouldAllowOrigin  bool\n\t}{\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"https://example.com\",\n\t\t\treqOrigin:         \"https://example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"https://example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://bbb.aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.aaa.example.com\",\n\t\t\treqOrigin:         \"http://bbb.aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com:8080\",\n\t\t\treqOrigin:         \"http://aaa.example.com:8080\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://gofiber.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.aaa.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"https://*--aaa.bbb.com\",\n\t\t\treqOrigin:         \"https://prod-preview--aaa.bbb.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://foo.[a-z]*.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tapp := fiber.New()\n\t\tapp.Use(\"/\", New(Config{AllowOrigins: tt.pattern}))\n\n\t\thandler := app.Handler()\n\n\t\tctx := &fasthttp.RequestCtx{}\n\t\tctx.Request.SetRequestURI(\"/\")\n\t\tctx.Request.Header.SetMethod(fiber.MethodOptions)\n\t\tctx.Request.Header.Set(fiber.HeaderOrigin, tt.reqOrigin)\n\n\t\thandler(ctx)\n\n\t\tif tt.shouldAllowOrigin {\n\t\t\tutils.AssertEqual(t, tt.reqOrigin, string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\t\t} else {\n\t\t\tutils.AssertEqual(t, \"\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn inTransaction(func(sess *DBSession) error {\n\t\torgId, err := getOrgIdForNewUser(cmd, sess)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif cmd.Email == \"\" {\n\t\t\tcmd.Email = cmd.Login\n\t\t}\n\n\t\t// create user\n\t\tuser := m.User{\n\t\t\tEmail:         cmd.Email,\n\t\t\tName:          cmd.Name,\n\t\t\tLogin:         cmd.Login,\n\t\t\tCompany:       cmd.Company,\n\t\t\tIsAdmin:       cmd.IsAdmin,\n\t\t\tOrgId:         orgId,\n\t\t\tEmailVerified: cmd.EmailVerified,\n\t\t\tCreated:       time.Now(),\n\t\t\tUpdated:       time.Now(),\n\t\t\tLastSeenAt:    time.Now().AddDate(-10, 0, 0),\n\t\t}\n\n\t\tuser.Salt = util.GetRandomString(10)\n\t\tuser.Rands = util.GetRandomString(10)\n\n\t\tif len(cmd.Password) > 0 {\n\t\t\tuser.Password = util.EncodePassword(cmd.Password, user.Salt)\n\t\t}\n\n\t\tsess.UseBool(\"is_admin\")\n\n\t\tif _, err := sess.Insert(&user); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tsess.publishAfterCommit(&events.UserCreated{\n\t\t\tTimestamp: user.Created,\n\t\t\tId:        user.Id,\n\t\t\tName:      user.Name,\n\t\t\tLogin:     user.Login,\n\t\t\tEmail:     user.Email,\n\t\t})\n\n\t\tcmd.Result = user\n\n\t\t// create org user link\n\t\tif !cmd.SkipOrgSetup {\n\t\t\torgUser := m.OrgUser{\n\t\t\t\tOrgId:   orgId,\n\t\t\t\tUserId:  user.Id,\n\t\t\t\tRole:    m.ROLE_ADMIN,\n\t\t\t\tCreated: time.Now(),\n\t\t\t\tUpdated: time.Now(),\n\t\t\t}\n\n\t\t\tif setting.AutoAssignOrg && !user.IsAdmin {\n\t\t\t\tif len(cmd.DefaultOrgRole) > 0 {\n\t\t\t\t\torgUser.Role = m.RoleType(cmd.DefaultOrgRole)\n\t\t\t\t} else {\n\t\t\t\t\torgUser.Role = m.RoleType(setting.AutoAssignOrgRole)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif _, err = sess.Insert(&orgUser); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (m *NidRepEnum) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepEnum: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepEnum: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v TheTestEnum\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= TheTestEnum(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field1 = append(m.Field1, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]TheTestEnum, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v TheTestEnum\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= TheTestEnum(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field1 = append(m.Field1, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v YetAnotherTestEnum\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field2 = append(m.Field2, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]YetAnotherTestEnum, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v YetAnotherTestEnum\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field2 = append(m.Field2, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v YetYetAnotherTestEnum\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]YetYetAnotherTestEnum, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v YetYetAnotherTestEnum\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (f *ConfigurationFile) parsePropertiesFile(path string) error {\n\tvar s strings.Builder\n\t// Open the file and attempt to load any comments that currenty exist at the start\n\t// of the file. This is kind of a hack, but should work for a majority of users for\n\t// the time being.\n\tif fd, err := os.Open(path); err != nil {\n\t\treturn errors.Wrap(err, \"parser: could not open file for reading\")\n\t} else {\n\t\tscanner := bufio.NewScanner(fd)\n\t\t// Scan until we hit a line that is not a comment that actually has content\n\t\t// on it. Keep appending the comments until that time.\n\t\tfor scanner.Scan() {\n\t\t\ttext := scanner.Text()\n\t\t\tif len(text) > 0 && text[0] != '#' {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ts.WriteString(text + \"\\n\")\n\t\t}\n\t\t_ = fd.Close()\n\t\tif err := scanner.Err(); err != nil {\n\t\t\treturn errors.WithStackIf(err)\n\t\t}\n\t}\n\n\tp, err := properties.LoadFile(path, properties.UTF8)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"parser: could not load properties file for configuration update\")\n\t}\n\n\t// Replace any values that need to be replaced.\n\tfor _, replace := range f.Replace {\n\t\tdata, err := f.LookupConfigurationValue(replace)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"parser: failed to lookup configuration value\")\n\t\t}\n\n\t\tv, ok := p.Get(replace.Match)\n\t\t// Don't attempt to replace the value if we're looking for a specific value and\n\t\t// it does not match. If there was no match at all in the file for this key but\n\t\t// we're doing an IfValue match, do nothing.\n\t\tif replace.IfValue != \"\" && (!ok || (ok && v != replace.IfValue)) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif _, _, err := p.Set(replace.Match, data); err != nil {\n\t\t\treturn errors.Wrap(err, \"parser: failed to set replacement value\")\n\t\t}\n\t}\n\n\t// Add the new file content to the string builder.\n\tfor _, key := range p.Keys() {\n\t\tvalue, ok := p.Get(key)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\t// This escape is intentional!\n\t\t//\n\t\t// See the docblock for this function for more details, do not change this\n\t\t// or you'll cause a flood of new issue reports no one wants to deal with.\n\t\ts.WriteString(key + \"=\" + strings.Trim(strconv.QuoteToASCII(value), \"\\\"\") + \"\\n\")\n\t}\n\n\t// Open the file for writing.\n\tw, err := os.OpenFile(path, os.O_CREATE|os.O_WRONLY|os.O_TRUNC, 0o644)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer w.Close()\n\n\t// Write the data to the file.\n\tif _, err := w.Write([]byte(s.String())); err != nil {\n\t\treturn errors.Wrap(err, \"parser: failed to write properties file to disk\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (g *Getter) GetFile(ctx context.Context, req *getter.Request) error {\n\n\tif g.Timeout > 0 {\n\t\tvar cancel context.CancelFunc\n\t\tctx, cancel = context.WithTimeout(ctx, g.Timeout)\n\t\tdefer cancel()\n\t}\n\n\tregion, bucket, path, version, creds, err := g.parseUrl(req.URL())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tclient, err := g.newS3Client(region, req.URL(), creds)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn g.getObject(ctx, client, req, req.Dst, bucket, path, version)\n}", "is_vulnerable": 0}
{"code": "\tak.IterateAccounts(ctx, func(account accounttypes.AccountI) bool {\n\t\tif vestAcc, ok := account.(*vestingtypes.ClawbackVestingAccount); ok {\n\t\t\t// if DelegatedVesting == 0, skip it\n\t\t\tif !vestAcc.DelegatedVesting.IsAllPositive() {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// add DelegatedVesting to DelegatedFree,\n\t\t\t// because it is not possible to delegate vesting coins.\n\t\t\t// ONLY vested (free) coins can be delegated\n\t\t\tvestAcc.DelegatedFree = vestAcc.DelegatedFree.Add(vestAcc.DelegatedVesting...)\n\t\t\tvestAcc.DelegatedVesting = sdk.NewCoins()\n\n\t\t\tak.SetAccount(ctx, vestAcc)\n\t\t}\n\n\t\treturn false\n\t})", "is_vulnerable": 0}
{"code": "\tif rf, ok := ret.Get(0).(func(string, kube.ResourceKey, func(v1alpha1.ResourceNode, string)) error); ok {\n\t\tr0 = rf(server, key, action)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}", "is_vulnerable": 1}
{"code": "func runCmd(ctx *cli.Context) error {\n\tglogger := log.NewGlogHandler(log.StreamHandler(os.Stderr, log.TerminalFormat(false)))\n\tglogger.Verbosity(log.Lvl(ctx.GlobalInt(VerbosityFlag.Name)))\n\tlog.Root().SetHandler(glogger)\n\tlogconfig := &vm.LogConfig{\n\t\tDisableMemory: ctx.GlobalBool(DisableMemoryFlag.Name),\n\t\tDisableStack:  ctx.GlobalBool(DisableStackFlag.Name),\n\t\tDebug:         ctx.GlobalBool(DebugFlag.Name),\n\t}\n\n\tvar (\n\t\ttracer      vm.Tracer\n\t\tdebugLogger *vm.StructLogger\n\t\tstatedb     *state.StateDB\n\t\tchainConfig *params.ChainConfig\n\t\tsender      = common.BytesToAddress([]byte(\"sender\"))\n\t\treceiver    = common.BytesToAddress([]byte(\"receiver\"))\n\t\tblockNumber uint64\n\t)\n\tif ctx.GlobalBool(MachineFlag.Name) {\n\t\ttracer = NewJSONLogger(logconfig, os.Stdout)\n\t} else if ctx.GlobalBool(DebugFlag.Name) {\n\t\tdebugLogger = vm.NewStructLogger(logconfig)\n\t\ttracer = debugLogger\n\t} else {\n\t\tdebugLogger = vm.NewStructLogger(logconfig)\n\t}\n\tif ctx.GlobalString(GenesisFlag.Name) != \"\" {\n\t\tgen := readGenesis(ctx.GlobalString(GenesisFlag.Name))\n\t\tdb := ethdb.NewMemDatabase()\n\t\tgenesis := gen.ToBlock(db)\n\t\tstatedb, _ = state.New(genesis.Root(), state.NewDatabase(db))\n\t\tchainConfig = gen.Config\n\t\tblockNumber = gen.Number\n\t} else {\n\t\tstatedb, _ = state.New(common.Hash{}, state.NewDatabase(ethdb.NewMemDatabase()))\n\t}\n\tif ctx.GlobalString(SenderFlag.Name) != \"\" {\n\t\tsender = common.HexToAddress(ctx.GlobalString(SenderFlag.Name))\n\t}\n\tstatedb.CreateAccount(sender)\n\n\tif ctx.GlobalString(ReceiverFlag.Name) != \"\" {\n\t\treceiver = common.HexToAddress(ctx.GlobalString(ReceiverFlag.Name))\n\t}\n\n\tvar (\n\t\tcode []byte\n\t\tret  []byte\n\t\terr  error\n\t)\n\t// The '--code' or '--codefile' flag overrides code in state\n\tif ctx.GlobalString(CodeFileFlag.Name) != \"\" {\n\t\tvar hexcode []byte\n\t\tvar err error\n\t\t// If - is specified, it means that code comes from stdin\n\t\tif ctx.GlobalString(CodeFileFlag.Name) == \"-\" {\n\t\t\t//Try reading from stdin\n\t\t\tif hexcode, err = ioutil.ReadAll(os.Stdin); err != nil {\n\t\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"Could not load code from stdin: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t} else {\n\t\t\t// Codefile with hex assembly\n\t\t\tif hexcode, err = ioutil.ReadFile(ctx.GlobalString(CodeFileFlag.Name)); err != nil {\n\t\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"Could not load code from file: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t}\n\t\tcode = common.Hex2Bytes(string(bytes.TrimRight(hexcode, \"\\n\")))\n\n\t} else if ctx.GlobalString(CodeFlag.Name) != \"\" {\n\t\tcode = common.Hex2Bytes(ctx.GlobalString(CodeFlag.Name))\n\t} else if fn := ctx.Args().First(); len(fn) > 0 {\n\t\t// EASM-file to compile\n\t\tsrc, err := ioutil.ReadFile(fn)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tbin, err := compiler.Compile(fn, src, false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcode = common.Hex2Bytes(bin)\n\t}\n\n\tinitialGas := ctx.GlobalUint64(GasFlag.Name)\n\truntimeConfig := runtime.Config{\n\t\tOrigin:      sender,\n\t\tState:       statedb,\n\t\tGasLimit:    initialGas,\n\t\tGasPrice:    utils.GlobalBig(ctx, PriceFlag.Name),\n\t\tValue:       utils.GlobalBig(ctx, ValueFlag.Name),\n\t\tBlockNumber: new(big.Int).SetUint64(blockNumber),\n\t\tEVMConfig: vm.Config{\n\t\t\tTracer: tracer,\n\t\t\tDebug:  ctx.GlobalBool(DebugFlag.Name) || ctx.GlobalBool(MachineFlag.Name),\n\t\t},\n\t}\n\n\tif cpuProfilePath := ctx.GlobalString(CPUProfileFlag.Name); cpuProfilePath != \"\" {\n\t\tf, err := os.Create(cpuProfilePath)\n\t\tif err != nil {\n\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"could not create CPU profile: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err := pprof.StartCPUProfile(f); err != nil {\n\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"could not start CPU profile: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tdefer pprof.StopCPUProfile()\n\t}\n\n\tif chainConfig != nil {\n\t\truntimeConfig.ChainConfig = chainConfig\n\t}\n\ttstart := time.Now()\n\tvar leftOverGas uint64\n\tif ctx.GlobalBool(CreateFlag.Name) {\n\t\tinput := append(code, common.Hex2Bytes(ctx.GlobalString(InputFlag.Name))...)\n\t\tret, _, leftOverGas, err = runtime.Create(input, &runtimeConfig)\n\t} else {\n\t\tif len(code) > 0 {\n\t\t\tstatedb.SetCode(receiver, code)\n\t\t}\n\t\tret, leftOverGas, err = runtime.Call(receiver, common.Hex2Bytes(ctx.GlobalString(InputFlag.Name)), &runtimeConfig)\n\t}\n\texecTime := time.Since(tstart)\n\n\tif ctx.GlobalBool(DumpFlag.Name) {\n\t\tstatedb.IntermediateRoot(true)\n\t\tfmt.Fprintln(ctx.App.Writer, string(statedb.Dump()))\n\t}\n\n\tif memProfilePath := ctx.GlobalString(MemProfileFlag.Name); memProfilePath != \"\" {\n\t\tf, err := os.Create(memProfilePath)\n\t\tif err != nil {\n\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"could not create memory profile: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err := pprof.WriteHeapProfile(f); err != nil {\n\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \"could not create memory profile: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tf.Close()\n\t}\n\n\tif ctx.GlobalBool(DebugFlag.Name) {\n\t\tif debugLogger != nil {\n\t\t\tfmt.Fprintln(ctx.App.ErrWriter, \"#### TRACE ####\")\n\t\t\tvm.WriteTrace(ctx.App.ErrWriter, debugLogger.StructLogs())\n\t\t}\n\t\tfmt.Fprintln(ctx.App.ErrWriter, \"#### LOGS ####\")\n\t\tvm.WriteLogs(ctx.App.ErrWriter, statedb.Logs())\n\t}\n\n\tif ctx.GlobalBool(StatDumpFlag.Name) {\n\t\tvar mem goruntime.MemStats\n\t\tgoruntime.ReadMemStats(&mem)\n\t\tfmt.Fprintf(ctx.App.ErrWriter, `evm execution time: %v\nheap objects:       %d\nallocations:        %d\ntotal allocations:  %d\nGC calls:           %d\nGas used:           %d\n\n`, execTime, mem.HeapObjects, mem.Alloc, mem.TotalAlloc, mem.NumGC, initialGas-leftOverGas)\n\t}\n\tif tracer == nil {\n\t\tfmt.Fprintf(ctx.App.Writer, \"0x%x\\n\", ret)\n\t\tif err != nil {\n\t\t\tfmt.Fprintf(ctx.App.ErrWriter, \" error: %v\\n\", err)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestHttpGetter_metaSubdirGlob(t *testing.T) {\n\tln := testHttpServer(t)\n\tdefer ln.Close()\n\tctx := context.Background()\n\n\tg := new(HttpGetter)\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/meta-subdir-glob\"\n\n\treq := &Request{\n\t\tDst:     dst,\n\t\tSrc:     u.String(),\n\t\tu:       &u,\n\t\tGetMode: ModeDir,\n\t}\n\n\t// Get it, which should error because it uses the file protocol.\n\terr := g.Get(ctx, req)\n\tif !strings.Contains(err.Error(), \"error downloading\") {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n\t// But, using a wrapper client with a file getter will work.\n\tc := &Client{\n\t\tGetters: []Getter{\n\t\t\tg,\n\t\t\tnew(FileGetter),\n\t\t},\n\t}\n\n\tif _, err = c.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\t// Verify the main file exists\n\tmainPath := filepath.Join(dst, \"sub.tf\")\n\tif _, err := os.Stat(mainPath); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn serverSnippet{\n\t\tr:                r,\n\t\tannotationConfig: serverSnippetAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *DroppedWithoutGetters) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypedecl\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: DroppedWithoutGetters: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: DroppedWithoutGetters: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Height\", wireType)\n\t\t\t}\n\t\t\tm.Height = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypedecl\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Height |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Width\", wireType)\n\t\t\t}\n\t\t\tm.Width = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypedecl\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Width |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypedecl(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypedecl\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (rfs *rootFs) reset() {\n\tif err := os.RemoveAll(filepath.Join(rfs.root, \"/server\")); err != nil {\n\t\tif !os.IsNotExist(err) {\n\t\t\tpanic(err)\n\t\t}\n\t}\n\n\tif err := os.Mkdir(filepath.Join(rfs.root, \"/server\"), 0o755); err != nil {\n\t\tpanic(err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func NewReconcileCommand(clientOpts *argocdclient.ClientOptions) *cobra.Command {\n\tvar (\n\t\tclientConfig      clientcmd.ClientConfig\n\t\tselector          string\n\t\trepoServerAddress string\n\t\toutputFormat      string\n\t\trefresh           bool\n\t)\n\n\tvar command = &cobra.Command{\n\t\tUse:   \"get-reconcile-results PATH\",\n\t\tShort: \"Reconcile all applications and stores reconciliation summary in the specified file.\",\n\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tctx := c.Context()\n\n\t\t\t// get rid of logging error handler\n\t\t\truntime.ErrorHandlers = runtime.ErrorHandlers[1:]\n\n\t\t\tif len(args) != 1 {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\toutputPath := args[0]\n\n\t\t\terrors.CheckError(os.Setenv(v1alpha1.EnvVarFakeInClusterConfig, \"true\"))\n\t\t\tcfg, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\n\t\t\tvar result []appReconcileResult\n\t\t\tif refresh {\n\t\t\t\tif repoServerAddress == \"\" {\n\t\t\t\t\tprintLine(\"Repo server is not provided, trying to port-forward to argocd-repo-server pod.\")\n\t\t\t\t\toverrides := clientcmd.ConfigOverrides{}\n\t\t\t\t\trepoServerPodLabelSelector := common.LabelKeyAppName + \"=\" + clientOpts.RepoServerName\n\t\t\t\t\trepoServerPort, err := kubeutil.PortForward(8081, namespace, &overrides, repoServerPodLabelSelector)\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\trepoServerAddress = fmt.Sprintf(\"localhost:%d\", repoServerPort)\n\t\t\t\t}\n\t\t\t\trepoServerClient := reposerverclient.NewRepoServerClientset(repoServerAddress, 60, reposerverclient.TLSConfiguration{DisableTLS: false, StrictValidation: false})\n\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tkubeClientset := kubernetes.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = reconcileApplications(ctx, kubeClientset, appClientset, namespace, repoServerClient, selector, newLiveStateCache)\n\t\t\t\terrors.CheckError(err)\n\t\t\t} else {\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = getReconcileResults(ctx, appClientset, namespace, selector)\n\t\t\t}\n\n\t\t\terrors.CheckError(saveToFile(err, outputFormat, reconcileResults{Applications: result}, outputPath))\n\t\t},\n\t}\n\tclientConfig = cli.AddKubectlFlagsToCmd(command)\n\tcommand.Flags().StringVar(&repoServerAddress, \"repo-server\", \"\", \"Repo server address.\")\n\tcommand.Flags().StringVar(&selector, \"l\", \"\", \"Label selector\")\n\tcommand.Flags().StringVar(&outputFormat, \"o\", \"yaml\", \"Output format (yaml|json)\")\n\tcommand.Flags().BoolVar(&refresh, \"refresh\", false, \"If set to true then recalculates apps reconciliation\")\n\n\treturn command\n}", "is_vulnerable": 1}
{"code": "func (client TagsClient) CreateOrUpdateSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func normaliseElementName(str string) string {\n\t// that useful QuoteToASCII put quote marks at the start and end\n\t// so those are trimmed off\n\treturn strings.TrimSuffix(\n\t\tstrings.TrimPrefix(\n\t\t\tstrings.ToLower(\n\t\t\t\tstrconv.QuoteToASCII(str),\n\t\t\t),\n\t\t\t`\"`),\n\t\t`\"`,\n\t)\n}", "is_vulnerable": 0}
{"code": "func PDFHasImage(path string) bool {\n\tcmd := \"pdffonts -l 5 %s | tail -n +3 | cut -d' ' -f1 | sort | uniq\"\n\tout, err := exec.Command(\"bash\", \"-c\", fmt.Sprintf(cmd, shellEscape(path))).CombinedOutput()\n\n\tif err != nil {\n\t\tlog.Println(err)\n\t\treturn false\n\t}\n\tif string(out) == \"\" {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func TestAuth(t *testing.T) {\n\ta, b, err := netPipe()\n\tif err != nil {\n\t\tt.Fatalf(\"netPipe: %v\", err)\n\t}\n\n\tdefer a.Close()\n\tdefer b.Close()\n\n\tagent, _, cleanup := startAgent(t)\n\tdefer cleanup()\n\n\tif err := agent.Add(AddedKey{PrivateKey: testPrivateKeys[\"rsa\"], Comment: \"comment\"}); err != nil {\n\t\tt.Errorf(\"Add: %v\", err)\n\t}\n\n\tserverConf := ssh.ServerConfig{}\n\tserverConf.AddHostKey(testSigners[\"rsa\"])\n\tserverConf.PublicKeyCallback = func(c ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\t\tif bytes.Equal(key.Marshal(), testPublicKeys[\"rsa\"].Marshal()) {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\treturn nil, errors.New(\"pubkey rejected\")\n\t}\n\n\tgo func() {\n\t\tconn, _, _, err := ssh.NewServerConn(a, &serverConf)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Server: %v\", err)\n\t\t}\n\t\tconn.Close()\n\t}()\n\n\tconf := ssh.ClientConfig{\n\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\n\t}\n\tconf.Auth = append(conf.Auth, ssh.PublicKeysCallback(agent.Signers))\n\tconn, _, _, err := ssh.NewClientConn(b, \"\", &conf)\n\tif err != nil {\n\t\tt.Fatalf(\"NewClientConn: %v\", err)\n\t}\n\tconn.Close()\n}", "is_vulnerable": 0}
{"code": "func (w *CountedWriter) ReadFrom(r io.Reader) (n int64, err error) {\n\tcr := NewCountedReader(r)\n\tn, err = w.File.ReadFrom(cr)\n\tw.counter.Add(n)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (acl *ACL) ValidateDomainGlobs(svc string, globs []string) error {\n\tfor _, glob := range globs {\n\t\tif glob == \"\" {\n\t\t\treturn fmt.Errorf(\"glob cannot be empty\")\n\t\t}\n\n\t\tif glob == \"*\" || glob == \"*.\" {\n\t\t\treturn fmt.Errorf(\"%v: %v: domain glob must not match everything\", svc, glob)\n\t\t}\n\n\t\tif !strings.HasPrefix(glob, \"*.\") && strings.HasPrefix(glob, \"*\") {\n\t\t\treturn fmt.Errorf(\"%v: %v: domain glob must represent a full prefix (sub)domain\", svc, glob)\n\t\t}\n\n\t\tdomainToCheck := strings.TrimPrefix(glob, \"*\")\n\t\tif strings.Contains(domainToCheck, \"*\") {\n\t\t\treturn fmt.Errorf(\"%v: %v: domain globs are only supported as prefix\", svc, glob)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (p *pluginConfig) asyncDataSource(rtCfg *extensioncommon.RuntimeConfig) (*envoy_core_v3.AsyncDataSource, error) {\n\n\t// Local data source\n\tif filename := p.VmConfig.Code.Local.Filename; filename != \"\" {\n\t\treturn &envoy_core_v3.AsyncDataSource{\n\t\t\tSpecifier: &envoy_core_v3.AsyncDataSource_Local{\n\t\t\t\tLocal: &envoy_core_v3.DataSource{\n\t\t\t\t\tSpecifier: &envoy_core_v3.DataSource_Filename{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\t// Remote data source\n\t// For a remote file, ensure there is an upstream cluster for the host specified in the URL.\n\t// Envoy requires an explicit cluster in order to perform the DNS lookup required to actually\n\t// fetch the data from the upstream source.\n\tremote := &p.VmConfig.Code.Remote\n\tclusterSNI := \"\"\n\tfor service, upstream := range rtCfg.Upstreams {\n\t\tif service == remote.HttpURI.Service {\n\t\t\tfor sni := range upstream.SNI {\n\t\t\t\tclusterSNI = sni\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tif clusterSNI == \"\" {\n\t\treturn nil, fmt.Errorf(\"no upstream found for remote service %q\", remote.HttpURI.Service.Name)\n\t}\n\n\td := time.Second\n\tif remote.HttpURI.timeout > 0 {\n\t\td = remote.HttpURI.timeout\n\t}\n\ttimeout := &durationpb.Duration{Seconds: int64(d.Seconds())}\n\n\treturn &envoy_core_v3.AsyncDataSource{\n\t\tSpecifier: &envoy_core_v3.AsyncDataSource_Remote{\n\t\t\tRemote: &envoy_core_v3.RemoteDataSource{\n\t\t\t\tSha256: remote.SHA256,\n\t\t\t\tHttpUri: &envoy_core_v3.HttpUri{\n\t\t\t\t\tUri: remote.HttpURI.URI,\n\t\t\t\t\tHttpUpstreamType: &envoy_core_v3.HttpUri_Cluster{\n\t\t\t\t\t\tCluster: clusterSNI,\n\t\t\t\t\t},\n\t\t\t\t\tTimeout: timeout,\n\t\t\t\t},\n\t\t\t\tRetryPolicy: p.retryPolicy(),\n\t\t\t},\n\t\t},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func isTestError(err error) bool {\n\t_, ok := err.(testError)\n\treturn ok\n}", "is_vulnerable": 0}
{"code": "func SubdirGlob(dst, subDir string) (string, error) {\n\tpattern := filepath.Join(dst, subDir)\n\n\tmatches, err := filepath.Glob(pattern)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(matches) == 0 {\n\t\treturn \"\", fmt.Errorf(\"subdir %q not found\", subDir)\n\t}\n\n\tif len(matches) > 1 {\n\t\treturn \"\", fmt.Errorf(\"subdir %q matches multiple paths\", subDir)\n\t}\n\n\treturn matches[0], nil\n}", "is_vulnerable": 0}
{"code": "func (s *IntegrationTestSuite) TestCLITxGrantAuthorization() {\n\tval := s.network.Validators[0]\n\tgrantee := s.grantee\n\n\ttwoHours := time.Now().Add(time.Minute * time.Duration(120)).Unix()\n\tpastHour := time.Now().Add(time.Minute * time.Duration(-60)).Unix()\n\n\ttestCases := []struct {\n\t\tname         string\n\t\targs         []string\n\t\texpectedCode uint32\n\t\texpectErr    bool\n\t}{\n\t\t{\n\t\t\t\"Invalid granter Address\",\n\t\t\t[]string{\n\t\t\t\t\"grantee_addr\",\n\t\t\t\t\"send\",\n\t\t\t\tfmt.Sprintf(\"--%s=100steak\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, \"granter\"),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagGenerateOnly),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t},\n\t\t\t0,\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t\"Invalid grantee Address\",\n\t\t\t[]string{\n\t\t\t\t\"grantee_addr\",\n\t\t\t\t\"send\",\n\t\t\t\tfmt.Sprintf(\"--%s=100steak\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagGenerateOnly),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t},\n\t\t\t0,\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t\"Invalid expiration time\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"send\",\n\t\t\t\tfmt.Sprintf(\"--%s=100steak\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, pastHour),\n\t\t\t},\n\t\t\t0xd,\n\t\t\tfalse, // TODO: enable in v0.45\n\t\t},\n\t\t{\n\t\t\t\"fail with error invalid msg-type\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"generic\",\n\t\t\t\tfmt.Sprintf(\"--%s=invalid-msg-type\", cli.FlagMsgType),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t},\n\t\t\t0x1d,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"failed with error both validators not allowed\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"delegate\",\n\t\t\t\tfmt.Sprintf(\"--%s=100stake\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagAllowedValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagDenyValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t\"valid tx delegate authorization allowed validators\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"delegate\",\n\t\t\t\tfmt.Sprintf(\"--%s=100stake\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagAllowedValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"valid tx delegate authorization deny validators\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"delegate\",\n\t\t\t\tfmt.Sprintf(\"--%s=100stake\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagDenyValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"valid tx undelegate authorization\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"unbond\",\n\t\t\t\tfmt.Sprintf(\"--%s=100stake\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagAllowedValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"valid tx redelegate authorization\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"redelegate\",\n\t\t\t\tfmt.Sprintf(\"--%s=100stake\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagAllowedValidators, val.ValAddress.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"Valid tx send authorization\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"send\",\n\t\t\t\tfmt.Sprintf(\"--%s=100steak\", cli.FlagSpendLimit),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"Valid tx generic authorization\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"generic\",\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagMsgType, typeMsgVote),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"Valid tx with amino\",\n\t\t\t[]string{\n\t\t\t\tgrantee.String(),\n\t\t\t\t\"generic\",\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", cli.FlagMsgType, typeMsgVote),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFrom, val.Address.String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagBroadcastMode, flags.BroadcastBlock),\n\t\t\t\tfmt.Sprintf(\"--%s=%d\", cli.FlagExpiration, twoHours),\n\t\t\t\tfmt.Sprintf(\"--%s=true\", flags.FlagSkipConfirmation),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagFees, sdk.NewCoins(sdk.NewCoin(s.cfg.BondDenom, sdk.NewInt(10))).String()),\n\t\t\t\tfmt.Sprintf(\"--%s=%s\", flags.FlagSignMode, flags.SignModeLegacyAminoJSON),\n\t\t\t},\n\t\t\t0,\n\t\t\tfalse,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\t\ts.Run(tc.name, func() {\n\t\t\tclientCtx := val.ClientCtx\n\t\t\tout, err := ExecGrant(\n\t\t\t\tval,\n\t\t\t\ttc.args,\n\t\t\t)\n\t\t\tif tc.expectErr {\n\t\t\t\ts.Require().Error(err)\n\t\t\t} else {\n\t\t\t\tvar txResp sdk.TxResponse\n\t\t\t\ts.Require().NoError(err)\n\t\t\t\ts.Require().NoError(clientCtx.Codec.UnmarshalJSON(out.Bytes(), &txResp), out.String())\n\t\t\t\ts.Require().Equal(tc.expectedCode, txResp.Code, out.String())\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewDefault() Configuration {\n\tdefIPCIDR := make([]string, 0)\n\tdefBindAddress := make([]string, 0)\n\tdefBlockEntity := make([]string, 0)\n\tdefNginxStatusIpv4Whitelist := make([]string, 0)\n\tdefNginxStatusIpv6Whitelist := make([]string, 0)\n\tdefResponseHeaders := make([]string, 0)\n\tdefIPCIDR = append(defIPCIDR, \"0.0.0.0/0\")\n\tdefNginxStatusIpv4Whitelist = append(defNginxStatusIpv4Whitelist, \"127.0.0.1\")\n\tdefNginxStatusIpv6Whitelist = append(defNginxStatusIpv6Whitelist, \"::1\")\n\tdefProxyDeadlineDuration := time.Duration(5) * time.Second\n\tdefGlobalExternalAuth := GlobalExternalAuth{\"\", \"\", \"\", \"\", \"\", append(defResponseHeaders, \"\"), \"\", \"\", \"\", []string{}, map[string]string{}, false}\n\n\tcfg := Configuration{\n\t\tAllowSnippetAnnotations:          true,\n\t\tAllowCrossNamespaceResources:     true,\n\t\tAllowBackendServerHeader:         false,\n\t\tAnnotationValueWordBlocklist:     \"\",\n\t\tAnnotationsRiskLevel:             \"Critical\",\n\t\tAccessLogPath:                    \"/var/log/nginx/access.log\",\n\t\tAccessLogParams:                  \"\",\n\t\tEnableAccessLogForDefaultBackend: false,\n\t\tWorkerCPUAffinity:                \"\",\n\t\tErrorLogPath:                     \"/var/log/nginx/error.log\",\n\t\tBlockCIDRs:                       defBlockEntity,\n\t\tBlockUserAgents:                  defBlockEntity,\n\t\tBlockReferers:                    defBlockEntity,\n\t\tBrotliLevel:                      4,\n\t\tBrotliMinLength:                  20,\n\t\tBrotliTypes:                      brotliTypes,\n\t\tClientHeaderBufferSize:           \"1k\",\n\t\tClientHeaderTimeout:              60,\n\t\tClientBodyBufferSize:             \"8k\",\n\t\tClientBodyTimeout:                60,\n\t\tEnableUnderscoresInHeaders:       false,\n\t\tErrorLogLevel:                    errorLevel,\n\t\tUseForwardedHeaders:              false,\n\t\tEnableRealIp:                     false,\n\t\tForwardedForHeader:               \"X-Forwarded-For\",\n\t\tComputeFullForwardedFor:          false,\n\t\tProxyAddOriginalURIHeader:        false,\n\t\tGenerateRequestID:                true,\n\t\tHTTP2MaxFieldSize:                \"\",\n\t\tHTTP2MaxHeaderSize:               \"\",\n\t\tHTTP2MaxRequests:                 0,\n\t\tHTTP2MaxConcurrentStreams:        128,\n\t\tHTTPRedirectCode:                 308,\n\t\tHSTS:                             true,\n\t\tHSTSIncludeSubdomains:            true,\n\t\tHSTSMaxAge:                       hstsMaxAge,\n\t\tHSTSPreload:                      false,\n\t\tIgnoreInvalidHeaders:             true,\n\t\tGzipLevel:                        1,\n\t\tGzipMinLength:                    256,\n\t\tGzipTypes:                        gzipTypes,\n\t\tKeepAlive:                        75,\n\t\tKeepAliveRequests:                1000,\n\t\tLargeClientHeaderBuffers:         \"4 8k\",\n\t\tLogFormatEscapeJSON:              false,\n\t\tLogFormatStream:                  logFormatStream,\n\t\tLogFormatUpstream:                logFormatUpstream,\n\t\tEnableMultiAccept:                true,\n\t\tMaxWorkerConnections:             16384,\n\t\tMaxWorkerOpenFiles:               0,\n\t\tMapHashBucketSize:                64,\n\t\tNginxStatusIpv4Whitelist:         defNginxStatusIpv4Whitelist,\n\t\tNginxStatusIpv6Whitelist:         defNginxStatusIpv6Whitelist,\n\t\tProxyRealIPCIDR:                  defIPCIDR,\n\t\tProxyProtocolHeaderTimeout:       defProxyDeadlineDuration,\n\t\tServerNameHashMaxSize:            1024,\n\t\tProxyHeadersHashMaxSize:          512,\n\t\tProxyHeadersHashBucketSize:       64,\n\t\tProxyStreamResponses:             1,\n\t\tReusePort:                        true,\n\t\tShowServerTokens:                 false,\n\t\tSSLBufferSize:                    sslBufferSize,\n\t\tSSLCiphers:                       sslCiphers,\n\t\tSSLECDHCurve:                     \"auto\",\n\t\tSSLProtocols:                     sslProtocols,\n\t\tSSLEarlyData:                     sslEarlyData,\n\t\tSSLRejectHandshake:               false,\n\t\tSSLSessionCache:                  true,\n\t\tSSLSessionCacheSize:              sslSessionCacheSize,\n\t\tSSLSessionTickets:                false,\n\t\tSSLSessionTimeout:                sslSessionTimeout,\n\t\tEnableBrotli:                     false,\n\t\tUseGzip:                          false,\n\t\tUseGeoIP:                         true,\n\t\tUseGeoIP2:                        false,\n\t\tWorkerProcesses:                  strconv.Itoa(runtime.NumCPU()),\n\t\tWorkerShutdownTimeout:            \"240s\",\n\t\tVariablesHashBucketSize:          256,\n\t\tVariablesHashMaxSize:             2048,\n\t\tUseHTTP2:                         true,\n\t\tProxyStreamTimeout:               \"600s\",\n\t\tProxyStreamNextUpstream:          true,\n\t\tProxyStreamNextUpstreamTimeout:   \"600s\",\n\t\tProxyStreamNextUpstreamTries:     3,\n\t\tBackend: defaults.Backend{\n\t\t\tProxyBodySize:            bodySize,\n\t\t\tProxyConnectTimeout:      5,\n\t\t\tProxyReadTimeout:         60,\n\t\t\tProxySendTimeout:         60,\n\t\t\tProxyBuffersNumber:       4,\n\t\t\tProxyBufferSize:          \"4k\",\n\t\t\tProxyCookieDomain:        \"off\",\n\t\t\tProxyCookiePath:          \"off\",\n\t\t\tProxyNextUpstream:        \"error timeout\",\n\t\t\tProxyNextUpstreamTimeout: 0,\n\t\t\tProxyNextUpstreamTries:   3,\n\t\t\tProxyRequestBuffering:    \"on\",\n\t\t\tProxyRedirectFrom:        \"off\",\n\t\t\tProxyRedirectTo:          \"off\",\n\t\t\tPreserveTrailingSlash:    false,\n\t\t\tSSLRedirect:              true,\n\t\t\tCustomHTTPErrors:         []int{},\n\t\t\tDenylistSourceRange:      []string{},\n\t\t\tWhitelistSourceRange:     []string{},\n\t\t\tSkipAccessLogURLs:        []string{},\n\t\t\tLimitRate:                0,\n\t\t\tLimitRateAfter:           0,\n\t\t\tProxyBuffering:           \"off\",\n\t\t\tProxyHTTPVersion:         \"1.1\",\n\t\t\tProxyMaxTempFileSize:     \"1024m\",\n\t\t\tServiceUpstream:          false,\n\t\t},\n\t\tUpstreamKeepaliveConnections:           320,\n\t\tUpstreamKeepaliveTime:                  \"1h\",\n\t\tUpstreamKeepaliveTimeout:               60,\n\t\tUpstreamKeepaliveRequests:              10000,\n\t\tLimitConnZoneVariable:                  defaultLimitConnZoneVariable,\n\t\tBindAddressIpv4:                        defBindAddress,\n\t\tBindAddressIpv6:                        defBindAddress,\n\t\tOpentracingTrustIncomingSpan:           true,\n\t\tOpentelemetryTrustIncomingSpan:         true,\n\t\tOpentelemetryConfig:                    \"/etc/nginx/opentelemetry.toml\",\n\t\tOtlpCollectorPort:                      \"4317\",\n\t\tOtelServiceName:                        \"nginx\",\n\t\tOtelSampler:                            \"AlwaysOn\",\n\t\tOtelSamplerRatio:                       0.01,\n\t\tOtelSamplerParentBased:                 true,\n\t\tOtelScheduleDelayMillis:                5000,\n\t\tOtelMaxExportBatchSize:                 512,\n\t\tOtelMaxQueueSize:                       2048,\n\t\tZipkinCollectorPort:                    9411,\n\t\tZipkinServiceName:                      \"nginx\",\n\t\tZipkinSampleRate:                       1.0,\n\t\tJaegerCollectorPort:                    6831,\n\t\tJaegerPropagationFormat:                \"jaeger\",\n\t\tJaegerServiceName:                      \"nginx\",\n\t\tJaegerSamplerType:                      \"const\",\n\t\tJaegerSamplerParam:                     \"1\",\n\t\tJaegerSamplerPort:                      5778,\n\t\tJaegerSamplerHost:                      \"http://127.0.0.1\",\n\t\tDatadogServiceName:                     \"nginx\",\n\t\tDatadogEnvironment:                     \"prod\",\n\t\tDatadogCollectorPort:                   8126,\n\t\tDatadogOperationNameOverride:           \"nginx.handle\",\n\t\tDatadogSampleRate:                      nil,\n\t\tLimitReqStatusCode:                     503,\n\t\tLimitConnStatusCode:                    503,\n\t\tSyslogPort:                             514,\n\t\tNoTLSRedirectLocations:                 \"/.well-known/acme-challenge\",\n\t\tNoAuthLocations:                        \"/.well-known/acme-challenge\",\n\t\tGlobalExternalAuth:                     defGlobalExternalAuth,\n\t\tProxySSLLocationOnly:                   false,\n\t\tDefaultType:                            \"text/html\",\n\t\tGlobalRateLimitMemcachedPort:           11211,\n\t\tGlobalRateLimitMemcachedConnectTimeout: 50,\n\t\tGlobalRateLimitMemcachedMaxIdleTimeout: 10000,\n\t\tGlobalRateLimitMemcachedPoolSize:       50,\n\t\tGlobalRateLimitStatucCode:              429,\n\t\tDebugConnections:                       []string{},\n\t\tStrictValidatePathType:                 false, // TODO: This will be true in future releases\n\t}\n\n\tif klog.V(5).Enabled() {\n\t\tcfg.ErrorLogLevel = \"debug\"\n\t}\n\n\treturn cfg\n}", "is_vulnerable": 0}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either repositories or organizations is required\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"github.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Github)\n\n\tfor name, value := range eventSource.Spec.Github {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGithubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e *Engine) findOrCreate(p peer.ID) *ledger {\n\t// Take a read lock (as it's less expensive) to check if we have a ledger\n\t// for the peer\n\te.lock.RLock()\n\tl, ok := e.ledgerMap[p]\n\te.lock.RUnlock()\n\tif ok {\n\t\treturn l\n\t}\n\n\t// There's no ledger, so take a write lock, then check again and create the\n\t// ledger if necessary\n\te.lock.Lock()\n\tdefer e.lock.Unlock()\n\tl, ok = e.ledgerMap[p]\n\tif !ok {\n\t\tl = newLedger(p)\n\t\te.ledgerMap[p] = l\n\t}\n\treturn l\n}", "is_vulnerable": 1}
{"code": "func TestDAGStatus(t *testing.T) {\n\n\ttype testcase struct {\n\t\tobjs                []interface{}\n\t\tfallbackCertificate *types.NamespacedName\n\t\twant                map[types.NamespacedName]contour_api_v1.DetailedCondition\n\t}\n\n\trun := func(t *testing.T, desc string, tc testcase) {\n\t\tt.Helper()\n\t\tt.Run(desc, func(t *testing.T) {\n\t\t\tt.Helper()\n\t\t\tbuilder := Builder{\n\t\t\t\tSource: KubernetesCache{\n\t\t\t\t\tRootNamespaces: []string{\"roots\", \"marketing\"},\n\t\t\t\t\tFieldLogger:    fixture.NewTestLogger(t),\n\t\t\t\t},\n\t\t\t\tProcessors: []Processor{\n\t\t\t\t\t&IngressProcessor{\n\t\t\t\t\t\tFieldLogger: fixture.NewTestLogger(t),\n\t\t\t\t\t},\n\t\t\t\t\t&HTTPProxyProcessor{\n\t\t\t\t\t\tFallbackCertificate: tc.fallbackCertificate,\n\t\t\t\t\t},\n\t\t\t\t\t&GatewayAPIProcessor{\n\t\t\t\t\t\tFieldLogger: fixture.NewTestLogger(t),\n\t\t\t\t\t},\n\t\t\t\t\t&ListenerProcessor{},\n\t\t\t\t},\n\t\t\t}\n\t\t\tfor _, o := range tc.objs {\n\t\t\t\tbuilder.Source.Insert(o)\n\t\t\t}\n\t\t\tdag := builder.Build()\n\t\t\tt.Logf(\"%#v\\n\", dag.StatusCache)\n\n\t\t\tgot := make(map[types.NamespacedName]contour_api_v1.DetailedCondition)\n\t\t\tfor _, pu := range dag.StatusCache.GetProxyUpdates() {\n\t\t\t\tgot[pu.Fullname] = *pu.Conditions[status.ValidCondition]\n\t\t\t}\n\n\t\t\tassert.Equal(t, tc.want, got)\n\t\t})\n\t}\n\n\t// proxyNoFQDN is invalid because it does not specify and FQDN\n\tproxyNoFQDN := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"parent\",\n\t\t\tGeneration: 23,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"foo\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\t// Tests using common fixtures\n\trun(t, \"root proxy does not specify FQDN\", testcase{\n\t\tobjs: []interface{}{proxyNoFQDN},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyNoFQDN.Name, Namespace: proxyNoFQDN.Namespace}: fixture.NewValidCondition().WithGeneration(proxyNoFQDN.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"FQDNNotSpecified\", \"Spec.VirtualHost.Fqdn must be specified\"),\n\t\t},\n\t})\n\n\t// Simple Valid HTTPProxy\n\tproxyValidHomeService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"example\",\n\t\t\tGeneration: 24,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"valid proxy\", testcase{\n\t\tobjs: []interface{}{proxyValidHomeService, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyValidHomeService.Name, Namespace: proxyValidHomeService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidHomeService.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\t// Multiple Includes, one invalid\n\tproxyMultiIncludeOneInvalid := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"parent\",\n\t\t\tGeneration: 45,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName: \"validChild\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}, {\n\t\t\t\tName: \"invalidChild\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/bar\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyIncludeValidChild := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"parentvalidchild\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName: \"validChild\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyChildValidFoo2 := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"validChild\",\n\t\t\tGeneration: 1,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"foo2\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyChildInvalidBadPort := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"invalidChild\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"foo3\",\n\t\t\t\t\tPort: 12345678,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy has multiple includes, one is invalid\", testcase{\n\t\tobjs: []interface{}{proxyMultiIncludeOneInvalid, proxyChildValidFoo2, proxyChildInvalidBadPort, fixture.ServiceRootsFoo2, fixture.ServiceRootsFoo3InvalidPort},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyChildValidFoo2.Name, Namespace: proxyChildValidFoo2.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyChildValidFoo2.Generation).\n\t\t\t\tValid(),\n\t\t\t{Name: proxyChildInvalidBadPort.Name, Namespace: proxyChildInvalidBadPort.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyChildInvalidBadPort.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServicePortInvalid\", `service \"foo3\": port must be in the range 1-65535`),\n\t\t\t{Name: proxyMultiIncludeOneInvalid.Name, Namespace: proxyMultiIncludeOneInvalid.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyMultiIncludeOneInvalid.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\trun(t, \"multi-parent child is not orphaned when one of the parents is invalid\", testcase{\n\t\tobjs: []interface{}{proxyNoFQDN, proxyChildValidFoo2, proxyIncludeValidChild, fixture.ServiceRootsKuard, fixture.ServiceRootsFoo2},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyNoFQDN.Name, Namespace: proxyNoFQDN.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyNoFQDN.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"FQDNNotSpecified\", \"Spec.VirtualHost.Fqdn must be specified\"),\n\t\t\t{Name: proxyChildValidFoo2.Name, Namespace: proxyChildValidFoo2.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyChildValidFoo2.Generation).\n\t\t\t\tValid(),\n\t\t\t{Name: proxyIncludeValidChild.Name, Namespace: proxyIncludeValidChild.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludeValidChild.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tingressSharedService := &networking_v1.Ingress{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"nginx\",\n\t\t\tNamespace: fixture.ServiceRootsNginx.Namespace,\n\t\t},\n\t\tSpec: networking_v1.IngressSpec{\n\t\t\tTLS: []networking_v1.IngressTLS{{\n\t\t\t\tHosts:      []string{\"example.com\"},\n\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t}},\n\t\t\tRules: []networking_v1.IngressRule{{\n\t\t\t\tHost:             \"example.com\",\n\t\t\t\tIngressRuleValue: ingressrulev1value(backendv1(fixture.ServiceRootsNginx.Name, intstr.FromInt(80))),\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyTCPSharedService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"nginx\",\n\t\t\tNamespace: fixture.ServiceRootsNginx.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsNginx.Name,\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\t// issue 1399\n\trun(t, \"service shared across ingress and httpproxy tcpproxy\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.SecretRootsCert, fixture.ServiceRootsNginx, ingressSharedService, proxyTCPSharedService,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPSharedService.Name, Namespace: proxyTCPSharedService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyTCPSharedService.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tproxyDelegatedTCPTLS := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"app-with-tls-delegation\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"app-with-tls-delegation.127.0.0.1.nip.io\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretProjectContourCert.Namespace + \"/\" + fixture.SecretProjectContourCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"sample-app\",\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\t// issue 1347\n\trun(t, \"tcpproxy with tls delegation failure\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.SecretProjectContourCert,\n\t\t\tproxyDelegatedTCPTLS,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyDelegatedTCPTLS.Name, Namespace: proxyDelegatedTCPTLS.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyDelegatedTCPTLS.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"DelegationNotPermitted\", `Spec.VirtualHost.TLS Secret \"projectcontour/default-ssl-cert\" certificate delegation not permitted`),\n\t\t},\n\t})\n\n\tproxyDelegatedTLS := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"app-with-tls-delegation\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"app-with-tls-delegation.127.0.0.1.nip.io\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretProjectContourCert.Namespace + \"/\" + fixture.SecretProjectContourCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"sample-app\",\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\t// issue 1348\n\trun(t, \"routes with tls delegation failure\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.SecretProjectContourCert,\n\t\t\tproxyDelegatedTLS,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyDelegatedTLS.Name, Namespace: proxyDelegatedTLS.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyDelegatedTCPTLS.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"DelegationNotPermitted\", `Spec.VirtualHost.TLS Secret \"projectcontour/default-ssl-cert\" certificate delegation not permitted`),\n\t\t},\n\t})\n\n\tserviceTLSPassthrough := &v1.Service{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"tls-passthrough\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: v1.ServiceSpec{\n\t\t\tPorts: []v1.ServicePort{{\n\t\t\t\tName:       \"https\",\n\t\t\t\tProtocol:   \"TCP\",\n\t\t\t\tPort:       443,\n\t\t\t\tTargetPort: intstr.FromInt(443),\n\t\t\t}, {\n\t\t\t\tName:       \"http\",\n\t\t\t\tProtocol:   \"TCP\",\n\t\t\t\tPort:       80,\n\t\t\t\tTargetPort: intstr.FromInt(80),\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyPassthroughProxyNonSecure := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"kuard-tcp\",\n\t\t\tNamespace: serviceTLSPassthrough.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"kuard.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: serviceTLSPassthrough.Name,\n\t\t\t\t\tPort: 80, // proxy non secure traffic to port 80\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: serviceTLSPassthrough.Name,\n\t\t\t\t\tPort: 443, // ssl passthrough to secure port\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\t// issue 910\n\trun(t, \"non tls routes can be combined with tcp proxy\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tserviceTLSPassthrough,\n\t\t\tproxyPassthroughProxyNonSecure,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyPassthroughProxyNonSecure.Name, Namespace: proxyPassthroughProxyNonSecure.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyPassthroughProxyNonSecure.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tproxyMultipleIncludersSite1 := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"site1\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"site1.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"www\",\n\t\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyMultipleIncludersSite2 := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"site2\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"site2.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"www\",\n\t\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyMultiIncludeChild := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"kuard\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"two root httpproxies with different hostnames delegated to the same object are valid\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.ServiceRootsKuard, proxyMultipleIncludersSite1, proxyMultipleIncludersSite2, proxyMultiIncludeChild,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyMultipleIncludersSite1.Name, Namespace: proxyMultipleIncludersSite1.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyMultipleIncludersSite1.Generation).\n\t\t\t\tValid(),\n\t\t\t{Name: proxyMultipleIncludersSite2.Name, Namespace: proxyMultipleIncludersSite2.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyMultipleIncludersSite2.Generation).\n\t\t\t\tValid(),\n\t\t\t{Name: proxyMultiIncludeChild.Name, Namespace: proxyMultiIncludeChild.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyMultiIncludeChild.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\t// proxyInvalidNegativePortHomeService is invalid because it contains a service with negative port\n\tproxyInvalidNegativePortHomeService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: -80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"invalid port in service\", testcase{\n\t\tobjs: []interface{}{proxyInvalidNegativePortHomeService},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidNegativePortHomeService.Name, Namespace: proxyInvalidNegativePortHomeService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidNegativePortHomeService.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServicePortInvalid\", `service \"home\": port must be in the range 1-65535`),\n\t\t},\n\t})\n\n\t// proxyInvalidOutsideRootNamespace is invalid because it lives outside the roots namespace\n\tproxyInvalidOutsideRootNamespace := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"finance\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foobar\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"root proxy outside of roots namespace\", testcase{\n\t\tobjs: []interface{}{proxyInvalidOutsideRootNamespace},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidOutsideRootNamespace.Name, Namespace: proxyInvalidOutsideRootNamespace.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidNegativePortHomeService.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRootNamespaceError, \"RootProxyNotAllowedInNamespace\", \"root HTTPProxy cannot be defined in this namespace\"),\n\t\t},\n\t})\n\n\t// proxyInvalidIncludeCycle is invalid because it delegates to itself, producing a cycle\n\tproxyInvalidIncludeCycle := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"self\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"self\",\n\t\t\t\tNamespace: \"roots\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"green\",\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy self-edge produces a cycle\", testcase{\n\t\tobjs: []interface{}{proxyInvalidIncludeCycle, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidIncludeCycle.Name, Namespace: proxyInvalidIncludeCycle.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidIncludeCycle.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"RootIncludesRoot\", \"root httpproxy cannot include another root httpproxy\"),\n\t\t},\n\t})\n\n\t// proxyIncludesProxyWithIncludeCycle delegates to proxy8, which is invalid because proxy8 delegates back to proxy8\n\tproxyIncludesProxyWithIncludeCycle := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"parent\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"child\",\n\t\t\t\tNamespace: \"roots\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyIncludedChildInvalidIncludeCycle := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"child\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"child\",\n\t\t\t\tNamespace: \"roots\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy child delegates to itself, producing a cycle\", testcase{\n\t\tobjs: []interface{}{proxyIncludesProxyWithIncludeCycle, proxyIncludedChildInvalidIncludeCycle},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyIncludesProxyWithIncludeCycle.Name, Namespace: proxyIncludesProxyWithIncludeCycle.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludesProxyWithIncludeCycle.Generation).Valid(),\n\t\t\t{Name: proxyIncludedChildInvalidIncludeCycle.Name, Namespace: proxyIncludedChildInvalidIncludeCycle.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludedChildInvalidIncludeCycle.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"IncludeCreatesCycle\", \"include creates an include cycle: roots/parent -> roots/child -> roots/child\"),\n\t\t},\n\t})\n\n\trun(t, \"proxy orphaned route\", testcase{\n\t\tobjs: []interface{}{proxyIncludedChildInvalidIncludeCycle},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyIncludedChildInvalidIncludeCycle.Name, Namespace: proxyIncludedChildInvalidIncludeCycle.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludedChildInvalidIncludeCycle.Generation).\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\tproxyIncludedChildValid := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"validChild\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"foo2\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\t// proxyNotRootIncludeRootProxy delegates to proxyWildCardFQDN but it is invalid because it is missing fqdn\n\tproxyNotRootIncludeRootProxy := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"invalidParent\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"validChild\",\n\t\t\t\tNamespace: \"roots\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy invalid parent orphans child\", testcase{\n\t\tobjs: []interface{}{proxyNotRootIncludeRootProxy, proxyIncludedChildValid},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyNotRootIncludeRootProxy.Name, Namespace: proxyNotRootIncludeRootProxy.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyNotRootIncludeRootProxy.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"FQDNNotSpecified\", \"Spec.VirtualHost.Fqdn must be specified\"),\n\t\t\t{Name: proxyIncludedChildValid.Name, Namespace: proxyIncludedChildValid.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludedChildValid.Generation).\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\t// proxyWildCardFQDN is invalid because it contains a wildcarded fqdn\n\tproxyWildCardFQDN := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.*.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy invalid FQDN contains wildcard\", testcase{\n\t\tobjs: []interface{}{proxyWildCardFQDN},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyWildCardFQDN.Name, Namespace: proxyWildCardFQDN.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyWildCardFQDN.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"WildCardNotAllowed\", `Spec.VirtualHost.Fqdn \"example.*.com\" cannot use wildcards`),\n\t\t},\n\t})\n\n\t// proxyInvalidServiceInvalid is invalid because it references an invalid service\n\tproxyInvalidServiceInvalid := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"invalidir\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"invalid\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy missing service is invalid\", testcase{\n\t\tobjs: []interface{}{proxyInvalidServiceInvalid},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidServiceInvalid.Name, Namespace: proxyInvalidServiceInvalid.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidServiceInvalid.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServiceUnresolvedReference\", `Spec.Routes unresolved service reference: service \"roots/invalid\" not found`),\n\t\t},\n\t})\n\n\t// proxyInvalidServicePortInvalid is invalid because it references an invalid port on a service\n\tproxyInvalidServicePortInvalid := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"invalidir\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 9999,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with service missing port is invalid\", testcase{\n\t\tobjs: []interface{}{proxyInvalidServicePortInvalid, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidServicePortInvalid.Name, Namespace: proxyInvalidServicePortInvalid.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidServiceInvalid.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServiceUnresolvedReference\", `Spec.Routes unresolved service reference: port \"9999\" on service \"roots/home\" not matched`),\n\t\t},\n\t})\n\n\tproxyValidExampleCom := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"example-com\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"kuard\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyValidReuseExampleCom := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"other-example\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"kuard\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyValidReuseCaseExampleCom := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"case-example\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"EXAMPLE.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"kuard\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"conflicting proxies due to fqdn reuse\", testcase{\n\t\tobjs: []interface{}{proxyValidExampleCom, proxyValidReuseExampleCom},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyValidExampleCom.Name, Namespace: proxyValidExampleCom.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidExampleCom.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"example.com\" is used in multiple HTTPProxies: roots/example-com, roots/other-example`),\n\t\t\t{Name: proxyValidReuseExampleCom.Name, Namespace: proxyValidReuseExampleCom.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidReuseExampleCom.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"example.com\" is used in multiple HTTPProxies: roots/example-com, roots/other-example`),\n\t\t},\n\t})\n\n\trun(t, \"conflicting proxies due to fqdn reuse with uppercase/lowercase\", testcase{\n\t\tobjs: []interface{}{proxyValidExampleCom, proxyValidReuseCaseExampleCom},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyValidExampleCom.Name, Namespace: proxyValidExampleCom.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidExampleCom.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"example.com\" is used in multiple HTTPProxies: roots/case-example, roots/example-com`),\n\t\t\t{Name: proxyValidReuseCaseExampleCom.Name, Namespace: proxyValidReuseCaseExampleCom.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidReuseCaseExampleCom.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"example.com\" is used in multiple HTTPProxies: roots/case-example, roots/example-com`),\n\t\t},\n\t})\n\n\tproxyRootIncludesRoot := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"root-blog\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"blog.containersteve.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: \"blog-containersteve-com\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"blog\",\n\t\t\t\tNamespace: \"marketing\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyRootIncludedByRoot := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"blog\",\n\t\t\tNamespace: fixture.ServiceMarketingGreen.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"blog.containersteve.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: \"blog-containersteve-com\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceMarketingGreen.Name,\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"root proxy including another root\", testcase{\n\t\tobjs: []interface{}{proxyRootIncludesRoot, proxyRootIncludedByRoot},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyRootIncludesRoot.Name, Namespace: proxyRootIncludesRoot.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyRootIncludesRoot.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"blog.containersteve.com\" is used in multiple HTTPProxies: marketing/blog, roots/root-blog`),\n\t\t\t{Name: proxyRootIncludedByRoot.Name, Namespace: proxyRootIncludedByRoot.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyRootIncludedByRoot.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeVirtualHostError, \"DuplicateVhost\", `fqdn \"blog.containersteve.com\" is used in multiple HTTPProxies: marketing/blog, roots/root-blog`),\n\t\t},\n\t})\n\n\tproxyIncludesRootDifferentFQDN := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"root-blog\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"blog.containersteve.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"blog\",\n\t\t\t\tNamespace: \"marketing\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyRootIncludedByRootDiffFQDN := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"blog\",\n\t\t\tNamespace: fixture.ServiceMarketingGreen.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"www.containersteve.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceMarketingGreen.Name,\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"root proxy including another root w/ different hostname\", testcase{\n\t\tobjs: []interface{}{proxyIncludesRootDifferentFQDN, proxyRootIncludedByRootDiffFQDN, fixture.ServiceMarketingGreen},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyIncludesRootDifferentFQDN.Name, Namespace: proxyIncludesRootDifferentFQDN.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyIncludesRootDifferentFQDN.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"RootIncludesRoot\", \"root httpproxy cannot include another root httpproxy\"),\n\t\t\t{Name: proxyRootIncludedByRootDiffFQDN.Name, Namespace: proxyRootIncludedByRootDiffFQDN.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyRootIncludedByRootDiffFQDN.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tproxyValidIncludeBlogMarketing := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"blog\",\n\t\t\tNamespace: fixture.ServiceMarketingGreen.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceMarketingGreen.Name,\n\t\t\t\t\tPort: 80,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyRootValidIncludesBlogMarketing := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"root-blog\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      proxyValidIncludeBlogMarketing.Name,\n\t\t\t\tNamespace: proxyValidIncludeBlogMarketing.Namespace,\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy includes another\", testcase{\n\t\tobjs: []interface{}{proxyValidIncludeBlogMarketing, proxyRootValidIncludesBlogMarketing, fixture.ServiceRootsKuard, fixture.ServiceMarketingGreen},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyValidIncludeBlogMarketing.Name, Namespace: proxyValidIncludeBlogMarketing.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidIncludeBlogMarketing.Generation).\n\t\t\t\tValid(),\n\t\t\t{Name: proxyRootValidIncludesBlogMarketing.Name, Namespace: proxyRootValidIncludesBlogMarketing.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyRootValidIncludesBlogMarketing.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tproxyValidWithMirror := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}, {\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}, {\n\t\t\t\t\tName:   fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort:   8080,\n\t\t\t\t\tMirror: true,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with mirror\", testcase{\n\t\tobjs: []interface{}{proxyValidWithMirror, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyValidWithMirror.Name, Namespace: proxyValidWithMirror.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidWithMirror.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n\n\tproxyInvalidTwoMirrors := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}, {\n\t\t\t\t\tName:   fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort:   8080,\n\t\t\t\t\tMirror: true,\n\t\t\t\t}, {\n\t\t\t\t\tName:   fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort:   8080,\n\t\t\t\t\tMirror: true,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with two mirrors\", testcase{\n\t\tobjs: []interface{}{proxyInvalidTwoMirrors, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidTwoMirrors.Name, Namespace: proxyInvalidTwoMirrors.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidTwoMirrors.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"OnlyOneMirror\", \"only one service per route may be nominated as mirror\"),\n\t\t},\n\t})\n\n\tproxyInvalidDuplicateMatchConditionHeaders := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:  \"x-header\",\n\t\t\t\t\t\tExact: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:  \"x-header\",\n\t\t\t\t\t\tExact: \"1234\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate route condition headers\", testcase{\n\t\tobjs: []interface{}{proxyInvalidDuplicateMatchConditionHeaders, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidDuplicateMatchConditionHeaders.Name, Namespace: proxyInvalidDuplicateMatchConditionHeaders.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidDuplicateMatchConditionHeaders.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"HeaderMatchConditionsNotValid\", \"cannot specify duplicate header 'exact match' conditions in the same route\"),\n\t\t},\n\t})\n\n\tproxyInvalidDuplicateIncludeCondtionHeaders := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"delegated\",\n\t\t\t\tNamespace: \"roots\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:  \"x-header\",\n\t\t\t\t\t\tExact: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:  \"x-header\",\n\t\t\t\t\t\tExact: \"1234\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\tproxyValidDelegatedRoots := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"delegated\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate include condition headers\", testcase{\n\t\tobjs: []interface{}{proxyInvalidDuplicateIncludeCondtionHeaders, proxyValidDelegatedRoots, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidDuplicateIncludeCondtionHeaders.Name,\n\t\t\t\tNamespace: proxyInvalidDuplicateIncludeCondtionHeaders.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidDuplicateIncludeCondtionHeaders.Generation).Valid(),\n\t\t\t{Name: proxyValidDelegatedRoots.Name,\n\t\t\t\tNamespace: proxyValidDelegatedRoots.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidDelegatedRoots.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"HeaderMatchConditionsNotValid\", \"cannot specify duplicate header 'exact match' conditions in the same route\"),\n\t\t},\n\t})\n\n\tproxyInvalidRouteConditionHeaders := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tNotExact: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}, {\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tNotExact: \"1234\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate valid route condition headers\", testcase{\n\t\tobjs: []interface{}{proxyInvalidRouteConditionHeaders, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidRouteConditionHeaders.Name, Namespace: proxyInvalidRouteConditionHeaders.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidRouteConditionHeaders.Generation).Valid(),\n\t\t},\n\t})\n\n\tproxyInvalidMultiplePrefixes := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{\n\t\t\t\t\t{\n\t\t\t\t\t\tPrefix: \"/api\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tPrefix: \"/v1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with two prefix conditions on route\", testcase{\n\t\tobjs: []interface{}{proxyInvalidMultiplePrefixes, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidMultiplePrefixes.Name, Namespace: proxyInvalidMultiplePrefixes.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidMultiplePrefixes.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"PathMatchConditionsNotValid\", \"route: more than one prefix is not allowed in a condition block\"),\n\t\t},\n\t})\n\n\tproxyInvalidTwoPrefixesWithInclude := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"child\",\n\t\t\t\tNamespace: \"teama\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{\n\t\t\t\t\t{\n\t\t\t\t\t\tPrefix: \"/api\",\n\t\t\t\t\t}, {\n\t\t\t\t\t\tPrefix: \"/v1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyValidChildTeamA := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"child\",\n\t\t\tNamespace: \"teama\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with two prefix conditions orphans include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidTwoPrefixesWithInclude, proxyValidChildTeamA, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidTwoPrefixesWithInclude.Name, Namespace: proxyInvalidTwoPrefixesWithInclude.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidTwoPrefixesWithInclude.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"PathMatchConditionsNotValid\", \"include: more than one prefix is not allowed in a condition block\"),\n\t\t\t{Name: proxyValidChildTeamA.Name, Namespace: proxyValidChildTeamA.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyValidChildTeamA.Generation).\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\tproxyInvalidPrefixNoSlash := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{\n\t\t\t\t\t{\n\t\t\t\t\t\tPrefix: \"api\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with prefix conditions on route that does not start with slash\", testcase{\n\t\tobjs: []interface{}{proxyInvalidPrefixNoSlash, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidPrefixNoSlash.Name, Namespace: proxyInvalidPrefixNoSlash.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(proxyInvalidPrefixNoSlash.Generation).\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"PathMatchConditionsNotValid\", \"route: prefix conditions must start with /, api was supplied\"),\n\t\t},\n\t})\n\n\tproxyInvalidIncludePrefixNoSlash := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"www\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"child\",\n\t\t\t\tNamespace: \"teama\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{\n\t\t\t\t\t{\n\t\t\t\t\t\tPrefix: \"api\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"proxy with include prefix that does not start with slash\", testcase{\n\t\tobjs: []interface{}{proxyInvalidIncludePrefixNoSlash, proxyValidChildTeamA, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidIncludePrefixNoSlash.Name, Namespace: proxyInvalidIncludePrefixNoSlash.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"PathMatchConditionsNotValid\", \"include: prefix conditions must start with /, api was supplied\"),\n\t\t\t{Name: proxyValidChildTeamA.Name, Namespace: proxyValidChildTeamA.Namespace}: fixture.NewValidCondition().\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\tproxyInvalidTCPProxyIncludeAndService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"simple\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"passthrough.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tInclude: &contour_api_v1.TCPProxyInclude{\n\t\t\t\t\tName:      \"foo\",\n\t\t\t\t\tNamespace: \"roots\",\n\t\t\t\t},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy cannot specify services and include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidTCPProxyIncludeAndService, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidTCPProxyIncludeAndService.Name, Namespace: proxyInvalidTCPProxyIncludeAndService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyError, \"NoServicesAndInclude\", \"cannot specify services and include in the same httpproxy\"),\n\t\t},\n\t})\n\n\tproxyTCPNoServiceOrInclusion := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"simple\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"passthrough.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy empty\", testcase{\n\t\tobjs: []interface{}{proxyTCPNoServiceOrInclusion, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPNoServiceOrInclusion.Name, Namespace: proxyTCPNoServiceOrInclusion.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyError, \"NothingDefined\", \"either services or inclusion must be specified\"),\n\t\t},\n\t})\n\n\tproxyTCPIncludesFoo := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"simple\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"passthrough.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tInclude: &contour_api_v1.TCPProxyInclude{\n\t\t\t\t\tName:      \"foo\",\n\t\t\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy w/ missing include\", testcase{\n\t\tobjs: []interface{}{proxyTCPIncludesFoo, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPIncludesFoo.Name, Namespace: proxyTCPIncludesFoo.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyIncludeError, \"IncludeNotFound\", \"include roots/foo not found\"),\n\t\t},\n\t})\n\n\tproxyValidTCPRoot := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"foo\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"www.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy includes another root\", testcase{\n\t\tobjs: []interface{}{proxyTCPIncludesFoo, proxyValidTCPRoot, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPIncludesFoo.Name, Namespace: proxyTCPIncludesFoo.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyIncludeError, \"RootIncludesRoot\", \"root httpproxy cannot include another root httpproxy\"),\n\t\t\t{Name: proxyValidTCPRoot.Name, Namespace: proxyValidTCPRoot.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t},\n\t})\n\n\tproxyTCPValidChildFoo := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"foo\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy includes valid child\", testcase{\n\t\tobjs: []interface{}{proxyTCPIncludesFoo, proxyTCPValidChildFoo, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPIncludesFoo.Name, Namespace: proxyTCPIncludesFoo.Namespace}:     fixture.NewValidCondition().Valid(),\n\t\t\t{Name: proxyTCPValidChildFoo.Name, Namespace: proxyTCPValidChildFoo.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t},\n\t})\n\n\tproxyInvalidConflictingIncludeConditions := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"blogteama\",\n\t\t\t\tNamespace: \"teama\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t}},\n\t\t\t}, {\n\t\t\t\tName:      \"blogteamb\",\n\t\t\t\tNamespace: \"teamb\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyValidBlogTeamA := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"blogteama\",\n\t\t\tName:      \"teama\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceTeamAKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\tproxyValidBlogTeamB := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"blogteamb\",\n\t\t\tName:      \"teamb\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceTeamBKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate path conditions on an include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidConflictingIncludeConditions, proxyValidBlogTeamA, proxyValidBlogTeamB, fixture.ServiceRootsHome, fixture.ServiceTeamAKuard, fixture.ServiceTeamBKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidConflictingIncludeConditions.Name,\n\t\t\t\tNamespace: proxyInvalidConflictingIncludeConditions.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"DuplicateMatchConditions\", \"duplicate conditions defined on an include\"),\n\t\t\t{Name: proxyValidBlogTeamA.Name, Namespace: proxyValidBlogTeamA.Namespace}: fixture.NewValidCondition().\n\t\t\t\tOrphaned(),\n\t\t\t{Name: proxyValidBlogTeamB.Name, Namespace: proxyValidBlogTeamB.Namespace}: fixture.NewValidCondition().\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\tproxyInvalidConflictHeaderConditions := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"blogteama\",\n\t\t\t\tNamespace: \"teama\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tContains: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t}, {\n\t\t\t\tName:      \"blogteamb\",\n\t\t\t\tNamespace: \"teamb\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tContains: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate header conditions on an include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidConflictHeaderConditions, proxyValidBlogTeamA, proxyValidBlogTeamB, fixture.ServiceRootsHome, fixture.ServiceTeamAKuard, fixture.ServiceTeamBKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidConflictHeaderConditions.Name,\n\t\t\t\tNamespace: proxyInvalidConflictHeaderConditions.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"DuplicateMatchConditions\", \"duplicate conditions defined on an include\"),\n\t\t\t{Name: proxyValidBlogTeamA.Name,\n\t\t\t\tNamespace: proxyValidBlogTeamA.Namespace}: fixture.NewValidCondition().Orphaned(),\n\t\t\t{Name: proxyValidBlogTeamB.Name,\n\t\t\t\tNamespace: proxyValidBlogTeamB.Namespace}: fixture.NewValidCondition().Orphaned(),\n\t\t},\n\t})\n\n\tproxyInvalidDuplicateHeaderAndPathConditions := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName:      \"blogteama\",\n\t\t\t\tNamespace: \"teama\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tContains: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t}, {\n\t\t\t\tName:      \"blogteamb\",\n\t\t\t\tNamespace: \"teamb\",\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/blog\",\n\t\t\t\t\tHeader: &contour_api_v1.HeaderMatchCondition{\n\t\t\t\t\t\tName:     \"x-header\",\n\t\t\t\t\t\tContains: \"abc\",\n\t\t\t\t\t},\n\t\t\t\t}},\n\t\t\t}},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"duplicate header+path conditions on an include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidDuplicateHeaderAndPathConditions, proxyValidBlogTeamA, proxyValidBlogTeamB, fixture.ServiceRootsHome, fixture.ServiceTeamAKuard, fixture.ServiceTeamBKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidDuplicateHeaderAndPathConditions.Name,\n\t\t\t\tNamespace: proxyInvalidDuplicateHeaderAndPathConditions.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"DuplicateMatchConditions\", \"duplicate conditions defined on an include\"),\n\t\t\t{Name: proxyValidBlogTeamA.Name,\n\t\t\t\tNamespace: proxyValidBlogTeamA.Namespace}: fixture.NewValidCondition().\n\t\t\t\tOrphaned(),\n\t\t\t{Name: proxyValidBlogTeamB.Name,\n\t\t\t\tNamespace: proxyValidBlogTeamB.Namespace}: fixture.NewValidCondition().\n\t\t\t\tOrphaned(),\n\t\t},\n\t})\n\n\tproxyInvalidMissingInclude := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tIncludes: []contour_api_v1.Include{{\n\t\t\t\tName: \"child\",\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ missing include\", testcase{\n\t\tobjs: []interface{}{proxyInvalidMissingInclude, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidMissingInclude.Name, Namespace: proxyInvalidMissingInclude.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeIncludeError, \"IncludeNotFound\", \"include roots/child not found\"),\n\t\t},\n\t})\n\n\tproxyTCPInvalidMissingService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"missing-tcp-proxy-service\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"not-found\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ tcpproxy w/ missing service\", testcase{\n\t\tobjs: []interface{}{proxyTCPInvalidMissingService},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPInvalidMissingService.Name, Namespace: proxyTCPInvalidMissingService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyError, \"ServiceUnresolvedReference\", `Spec.TCPProxy unresolved service reference: service \"roots/not-found\" not found`),\n\t\t},\n\t})\n\n\tproxyTCPInvalidPortNotMatched := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"tcp-proxy-service-missing-port\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 9999,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ tcpproxy w/ service missing port\", testcase{\n\t\tobjs: []interface{}{proxyTCPInvalidPortNotMatched, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPInvalidPortNotMatched.Name, Namespace: proxyTCPInvalidPortNotMatched.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyError, \"ServiceUnresolvedReference\", `Spec.TCPProxy unresolved service reference: port \"9999\" on service \"roots/kuard\" not matched`),\n\t\t},\n\t})\n\n\tproxyTCPInvalidMissingTLS := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"missing-tls\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ tcpproxy missing tls\", testcase{\n\t\tobjs: []interface{}{proxyTCPInvalidMissingTLS},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPInvalidMissingTLS.Name, Namespace: proxyTCPInvalidMissingTLS.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTCPProxyError, \"TLSMustBeConfigured\", \"Spec.TCPProxy requires that either Spec.TLS.Passthrough or Spec.TLS.SecretName be set\"),\n\t\t},\n\t})\n\n\tproxyInvalidMissingServiceWithTCPProxy := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"missing-route-service\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t{Name: \"missing\", Port: 9000},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ tcpproxy missing service\", testcase{\n\t\tobjs: []interface{}{fixture.SecretRootsCert, fixture.ServiceRootsKuard, proxyInvalidMissingServiceWithTCPProxy},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidMissingServiceWithTCPProxy.Name, Namespace: proxyInvalidMissingServiceWithTCPProxy.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServiceUnresolvedReference\", `Spec.Routes unresolved service reference: service \"roots/missing\" not found`),\n\t\t},\n\t})\n\n\tproxyRoutePortNotMatchedWithTCP := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"missing-route-service-port\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t{Name: fixture.ServiceRootsKuard.Name, Port: 9999},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy route unmatched service port\", testcase{\n\t\tobjs: []interface{}{fixture.SecretRootsCert, fixture.ServiceRootsKuard, proxyRoutePortNotMatchedWithTCP},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyRoutePortNotMatchedWithTCP.Name, Namespace: proxyRoutePortNotMatchedWithTCP.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ServiceUnresolvedReference\", `Spec.Routes unresolved service reference: port \"9999\" on service \"roots/kuard\" not matched`),\n\t\t},\n\t})\n\n\tproxyTCPValidIncludeChild := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"validtcpproxy\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tInclude: &contour_api_v1.TCPProxyInclude{\n\t\t\t\t\tName:      \"child\",\n\t\t\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tproxyTCPValidIncludesChild := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"validtcpproxy\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName: fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tIncludesDeprecated: &contour_api_v1.TCPProxyInclude{\n\t\t\t\t\tName:      \"child\",\n\t\t\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tproxyTCPValidChild := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"child\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"valid HTTPProxy.TCPProxy - plural\", testcase{\n\t\tobjs: []interface{}{proxyTCPValidIncludesChild, proxyTCPValidChild, fixture.ServiceRootsKuard, fixture.SecretRootsCert},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPValidIncludesChild.Name,\n\t\t\t\tNamespace: proxyTCPValidIncludesChild.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t\t{Name: proxyTCPValidChild.Name,\n\t\t\t\tNamespace: proxyTCPValidChild.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t},\n\t})\n\n\trun(t, \"valid HTTPProxy.TCPProxy\", testcase{\n\t\tobjs: []interface{}{proxyTCPValidIncludeChild, proxyTCPValidChild, fixture.ServiceRootsKuard, fixture.SecretRootsCert},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyTCPValidIncludeChild.Name,\n\t\t\t\tNamespace: proxyTCPValidIncludeChild.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t\t{Name: proxyTCPValidChild.Name,\n\t\t\t\tNamespace: proxyTCPValidChild.Namespace}: fixture.NewValidCondition().Valid(),\n\t\t},\n\t})\n\n\t// issue 2309\n\tproxyInvalidNoServices := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"missing-service\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"missing-service.example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/\",\n\t\t\t\t}},\n\t\t\t\tServices: nil, // missing\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"invalid HTTPProxy due to empty route.service\", testcase{\n\t\tobjs: []interface{}{proxyInvalidNoServices, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyInvalidNoServices.Name, Namespace: proxyInvalidNoServices.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"NoServicesPresent\", \"route.services must have at least one entry\"),\n\t\t},\n\t})\n\n\tfallbackCertificate := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName:                \"ssl-cert\",\n\t\t\t\t\tEnableFallbackCertificate: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"invalid fallback certificate passed to contour\", testcase{\n\t\tfallbackCertificate: &types.NamespacedName{\n\t\t\tName:      \"invalid\",\n\t\t\tNamespace: \"invalid\",\n\t\t},\n\t\tobjs: []interface{}{fallbackCertificate, fixture.SecretRootsFallback, fixture.SecretRootsCert, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: fallbackCertificate.Name,\n\t\t\t\tNamespace: fallbackCertificate.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"FallbackNotValid\", `Spec.Virtualhost.TLS Secret \"invalid/invalid\" fallback certificate is invalid: Secret not found`),\n\t\t},\n\t})\n\n\trun(t, \"fallback certificate requested but cert not configured in contour\", testcase{\n\t\tobjs: []interface{}{fallbackCertificate, fixture.SecretRootsFallback, fixture.SecretRootsCert, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: fallbackCertificate.Name,\n\t\t\t\tNamespace: fallbackCertificate.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"FallbackNotPresent\", \"Spec.Virtualhost.TLS enabled fallback but the fallback Certificate Secret is not configured in Contour configuration file\"),\n\t\t},\n\t})\n\n\tfallbackCertificateWithClientValidationNoCA := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName:       \"ssl-cert\",\n\t\t\t\t\tClientValidation: &contour_api_v1.DownstreamValidation{},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"clientValidation missing CA\", testcase{\n\t\tobjs: []interface{}{fallbackCertificateWithClientValidationNoCA, fixture.SecretRootsFallback, fixture.SecretRootsCert, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: fallbackCertificateWithClientValidationNoCA.Name,\n\t\t\t\tNamespace: fallbackCertificateWithClientValidationNoCA.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"ClientValidationInvalid\", \"Spec.VirtualHost.TLS client validation is invalid: CA Secret must be specified\"),\n\t\t},\n\t})\n\n\tfallbackCertificateWithClientValidation := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: \"roots\",\n\t\t\tName:      \"example\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName:                \"ssl-cert\",\n\t\t\t\t\tEnableFallbackCertificate: true,\n\t\t\t\t\tClientValidation: &contour_api_v1.DownstreamValidation{\n\t\t\t\t\t\tCACertificate: \"something\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"fallback certificate requested and clientValidation also configured\", testcase{\n\t\tobjs: []interface{}{fallbackCertificateWithClientValidation, fixture.SecretRootsFallback, fixture.SecretRootsCert, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: fallbackCertificateWithClientValidation.Name,\n\t\t\t\tNamespace: fallbackCertificateWithClientValidation.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"TLSIncompatibleFeatures\", \"Spec.Virtualhost.TLS fallback & client validation are incompatible\"),\n\t\t},\n\t})\n\n\ttlsPassthroughAndValidation := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalid\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t\tClientValidation: &contour_api_v1.DownstreamValidation{\n\t\t\t\t\t\tCACertificate: \"aCAcert\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{},\n\t\t},\n\t}\n\n\trun(t, \"passthrough and client auth are incompatible tlsPassthroughAndValidation\", testcase{\n\t\tobjs: []interface{}{fixture.SecretRootsCert, tlsPassthroughAndValidation},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: tlsPassthroughAndValidation.Name, Namespace: tlsPassthroughAndValidation.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"TLSIncompatibleFeatures\", \"Spec.VirtualHost.TLS passthrough cannot be combined with tls.clientValidation\"),\n\t\t},\n\t})\n\n\ttlsPassthroughAndSecretName := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalid\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: true,\n\t\t\t\t\tSecretName:  fixture.SecretRootsCert.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{},\n\t\t},\n\t}\n\n\trun(t, \"tcpproxy with TLS passthrough and secret name both specified\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.SecretRootsCert,\n\t\t\ttlsPassthroughAndSecretName,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: \"invalid\", Namespace: fixture.ServiceRootsKuard.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"TLSConfigNotValid\", \"Spec.VirtualHost.TLS: both Passthrough and SecretName were specified\"),\n\t\t},\n\t})\n\n\ttlsNoPassthroughOrSecretName := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalid\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"tcpproxy.example.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough: false,\n\t\t\t\t\tSecretName:  \"\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tTCPProxy: &contour_api_v1.TCPProxy{},\n\t\t},\n\t}\n\n\trun(t, \"httpproxy w/ tcpproxy with neither TLS passthrough nor secret name specified\", testcase{\n\t\tobjs: []interface{}{\n\t\t\tfixture.SecretRootsCert,\n\t\t\ttlsNoPassthroughOrSecretName,\n\t\t},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: \"invalid\", Namespace: fixture.ServiceRootsKuard.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"TLSConfigNotValid\", \"Spec.VirtualHost.TLS: neither Passthrough nor SecretName were specified\"),\n\t\t},\n\t})\n\n\temptyProxy := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"empty\",\n\t\t\tNamespace: \"roots\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"proxy with no routes, includes, or tcpproxy is invalid\", testcase{\n\t\tobjs: []interface{}{emptyProxy},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: emptyProxy.Name, Namespace: emptyProxy.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeSpecError, \"NothingDefined\", \"HTTPProxy.Spec must have at least one Route, Include, or a TCPProxy\"),\n\t\t},\n\t})\n\n\tinvalidRequestHeadersPolicyService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalidRHPService\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\t\tPort: 8080,\n\t\t\t\t\t\tRequestHeadersPolicy: &contour_api_v1.HeadersPolicy{\n\t\t\t\t\t\t\tSet: []contour_api_v1.HeaderValue{{\n\t\t\t\t\t\t\t\tName:  \"Host\",\n\t\t\t\t\t\t\t\tValue: \"external.com\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"requestHeadersPolicy, Host header invalid on Service\", testcase{\n\t\tobjs: []interface{}{invalidRequestHeadersPolicyService, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: invalidRequestHeadersPolicyService.Name, Namespace: invalidRequestHeadersPolicyService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"RequestHeadersPolicyInvalid\", `rewriting \"Host\" header is not supported on request headers`),\n\t\t},\n\t})\n\n\tinvalidResponseHeadersPolicyService := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalidRHPService\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\t\tPort: 8080,\n\t\t\t\t\t\tResponseHeadersPolicy: &contour_api_v1.HeadersPolicy{\n\t\t\t\t\t\t\tSet: []contour_api_v1.HeaderValue{{\n\t\t\t\t\t\t\t\tName:  \"Host\",\n\t\t\t\t\t\t\t\tValue: \"external.com\",\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"responseHeadersPolicy, Host header invalid on Service\", testcase{\n\t\tobjs: []interface{}{invalidResponseHeadersPolicyService, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: invalidResponseHeadersPolicyService.Name, Namespace: invalidResponseHeadersPolicyService.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeServiceError, \"ResponseHeadersPolicyInvalid\", `rewriting \"Host\" header is not supported on response headers`),\n\t\t},\n\t})\n\n\tinvalidResponseHeadersPolicyRoute := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"invalidRHPRoute\",\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\t\tPort: 8080,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResponseHeadersPolicy: &contour_api_v1.HeadersPolicy{\n\t\t\t\t\tSet: []contour_api_v1.HeaderValue{{\n\t\t\t\t\t\tName:  \"Host\",\n\t\t\t\t\t\tValue: \"external.com\",\n\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"responseHeadersPolicy, Host header invalid on Route\", testcase{\n\t\tobjs: []interface{}{invalidResponseHeadersPolicyRoute, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: invalidResponseHeadersPolicyRoute.Name, Namespace: invalidResponseHeadersPolicyRoute.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeRouteError, \"ResponseHeaderPolicyInvalid\", `rewriting \"Host\" header is not supported on response headers`),\n\t\t},\n\t})\n\n\tproxyAuthFallback := fixture.NewProxy(\"roots/fallback-incompat\").\n\t\tWithSpec(contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"invalid.com\",\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tSecretName:                \"ssl-cert\",\n\t\t\t\t\tEnableFallbackCertificate: true,\n\t\t\t\t},\n\t\t\t\tAuthorization: &contour_api_v1.AuthorizationServer{\n\t\t\t\t\tExtensionServiceRef: contour_api_v1.ExtensionServiceReference{\n\t\t\t\t\t\tNamespace: \"auth\",\n\t\t\t\t\t\tName:      \"extension\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tServices: []contour_api_v1.Service{{Name: \"app-server\", Port: 80}},\n\t\t\t}},\n\t\t})\n\n\trun(t, \"fallback and client auth is invalid\", testcase{\n\t\tobjs: []interface{}{fixture.SecretRootsCert, proxyAuthFallback},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: proxyAuthFallback.Name, Namespace: proxyAuthFallback.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithError(contour_api_v1.ConditionTypeTLSError, \"TLSIncompatibleFeatures\", \"Spec.Virtualhost.TLS fallback & client authorization are incompatible\"),\n\t\t},\n\t})\n\n\tinvalidResponseTimeout := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\tName:      \"invalid-timeouts\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{\n\t\t\t\t{\n\t\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTimeoutPolicy: &contour_api_v1.TimeoutPolicy{\n\t\t\t\t\t\tResponse: \"invalid-val\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"proxy with invalid response timeout value is invalid\", testcase{\n\t\tobjs: []interface{}{invalidResponseTimeout, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{\n\t\t\t\tName:      invalidResponseTimeout.Name,\n\t\t\t\tNamespace: invalidResponseTimeout.Namespace,\n\t\t\t}: fixture.NewValidCondition().WithError(contour_api_v1.ConditionTypeRouteError, \"TimeoutPolicyNotValid\",\n\t\t\t\t`route.timeoutPolicy failed to parse: error parsing response timeout: unable to parse timeout string \"invalid-val\": time: invalid duration \"invalid-val\"`),\n\t\t},\n\t})\n\n\tinvalidIdleTimeout := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: fixture.ServiceRootsKuard.Namespace,\n\t\t\tName:      \"invalid-timeouts\",\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{\n\t\t\t\t{\n\t\t\t\t\tServices: []contour_api_v1.Service{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: fixture.ServiceRootsKuard.Name,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTimeoutPolicy: &contour_api_v1.TimeoutPolicy{\n\t\t\t\t\t\tIdle: \"invalid-val\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trun(t, \"proxy with invalid idle timeout value is invalid\", testcase{\n\t\tobjs: []interface{}{invalidIdleTimeout, fixture.ServiceRootsKuard},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{\n\t\t\t\tName:      invalidIdleTimeout.Name,\n\t\t\t\tNamespace: invalidIdleTimeout.Namespace,\n\t\t\t}: fixture.NewValidCondition().WithError(contour_api_v1.ConditionTypeRouteError, \"TimeoutPolicyNotValid\",\n\t\t\t\t`route.timeoutPolicy failed to parse: error parsing idle timeout: unable to parse timeout string \"invalid-val\": time: invalid duration \"invalid-val\"`),\n\t\t},\n\t})\n\n\t// issue 3197: Fallback and passthrough HTTPProxy directive should emit a config error\n\ttlsPassthroughAndFallback := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"example\",\n\t\t\tGeneration: 24,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough:               true,\n\t\t\t\t\tEnableFallbackCertificate: true,\n\t\t\t\t},\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"TLS with passthrough and fallback cert enabled is invalid\", testcase{\n\t\tobjs: []interface{}{tlsPassthroughAndFallback, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: tlsPassthroughAndFallback.Name, Namespace: tlsPassthroughAndFallback.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(tlsPassthroughAndFallback.Generation).WithError(\n\t\t\t\tcontour_api_v1.ConditionTypeTLSError, \"TLSIncompatibleFeatures\",\n\t\t\t\t`Spec.VirtualHost.TLS: both Passthrough and enableFallbackCertificate were specified`,\n\t\t\t),\n\t\t},\n\t})\n\ttlsPassthrough := &contour_api_v1.HTTPProxy{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace:  \"roots\",\n\t\t\tName:       \"example\",\n\t\t\tGeneration: 24,\n\t\t},\n\t\tSpec: contour_api_v1.HTTPProxySpec{\n\t\t\tVirtualHost: &contour_api_v1.VirtualHost{\n\t\t\t\tTLS: &contour_api_v1.TLS{\n\t\t\t\t\tPassthrough:               true,\n\t\t\t\t\tEnableFallbackCertificate: false,\n\t\t\t\t},\n\t\t\t\tFqdn: \"example.com\",\n\t\t\t},\n\t\t\tRoutes: []contour_api_v1.Route{{\n\t\t\t\tConditions: []contour_api_v1.MatchCondition{{\n\t\t\t\t\tPrefix: \"/foo\",\n\t\t\t\t}},\n\t\t\t\tServices: []contour_api_v1.Service{{\n\t\t\t\t\tName: \"home\",\n\t\t\t\t\tPort: 8080,\n\t\t\t\t}},\n\t\t\t}},\n\t\t},\n\t}\n\n\trun(t, \"valid TLS passthrough\", testcase{\n\t\tobjs: []interface{}{tlsPassthrough, fixture.ServiceRootsHome},\n\t\twant: map[types.NamespacedName]contour_api_v1.DetailedCondition{\n\t\t\t{Name: tlsPassthrough.Name, Namespace: tlsPassthrough.Namespace}: fixture.NewValidCondition().\n\t\t\t\tWithGeneration(tlsPassthrough.Generation).\n\t\t\t\tValid(),\n\t\t},\n\t})\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) CreateOrUpdatePreparer(ctx context.Context, resourceGroupName string, parameters Group) (*http.Request, error) {\n\tpathParameters := map[string]interface{}{\n\t\t\"resourceGroupName\": autorest.Encode(\"path\", resourceGroupName),\n\t\t\"subscriptionId\":    autorest.Encode(\"path\", client.SubscriptionID),\n\t}\n\n\tconst APIVersion = \"2016-02-01\"\n\tqueryParameters := map[string]interface{}{\n\t\t\"api-version\": APIVersion,\n\t}\n\n\tparameters.ID = nil\n\tpreparer := autorest.CreatePreparer(\n\t\tautorest.AsContentType(\"application/json; charset=utf-8\"),\n\t\tautorest.AsPut(),\n\t\tautorest.WithBaseURL(client.BaseURI),\n\t\tautorest.WithPathParameters(\"/subscriptions/{subscriptionId}/resourcegroups/{resourceGroupName}\", pathParameters),\n\t\tautorest.WithJSON(parameters),\n\t\tautorest.WithQueryParameters(queryParameters))\n\treturn preparer.Prepare((&http.Request{}).WithContext(ctx))\n}", "is_vulnerable": 0}
{"code": "func (c *immuClient) verifyDualProof(\n\tctx context.Context,\n\tdualProof *store.DualProof,\n\tsourceID uint64,\n\ttargetID uint64,\n\tsourceAlh [sha256.Size]byte,\n\ttargetAlh [sha256.Size]byte,\n) error {\n\terr := schema.FillMissingLinearAdvanceProof(\n\t\tctx, dualProof, sourceID, targetID, c.ServiceClient,\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tverifies := store.VerifyDualProof(\n\t\tdualProof,\n\t\tsourceID,\n\t\ttargetID,\n\t\tsourceAlh,\n\t\ttargetAlh,\n\t)\n\tif !verifies {\n\t\treturn store.ErrCorruptedData\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestRuntimeConfig_EnvoyID(t *testing.T) {\n\trc := makeTestRuntimeConfig()\n\trequire.Equal(t, \"eid\", rc.EnvoyID())\n}", "is_vulnerable": 1}
{"code": "func RunTestDeleteWithSuggestion(ctx context.Context, t *testing.T, store storage.Interface) {\n\tkey, originalPod := testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"name\"}})\n\n\tout := &example.Pod{}\n\tif err := store.Delete(ctx, key, out, nil, storage.ValidateAllObjectFunc, originalPod); err != nil {\n\t\tt.Errorf(\"Unexpected failure during deletion: %v\", err)\n\t}\n\n\tif err := store.Get(ctx, key, storage.GetOptions{}, &example.Pod{}); !storage.IsNotFound(err) {\n\t\tt.Errorf(\"Unexpected error on reading object: %v\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestParseAnnotationsWithDefaultConfig(t *testing.T) {\n\ting := buildIngress()\n\n\tmockBackend := mockBackend{}\n\n\ttests := map[string]struct {\n\t\tnet        string\n\t\texpectCidr []string\n\t\texpectErr  bool\n\t\terrOut     string\n\t}{\n\t\t\"test parse a valid net\": {\n\t\t\tnet:        \"10.0.0.0/24\",\n\t\t\texpectCidr: []string{\"10.0.0.0/24\"},\n\t\t\texpectErr:  false,\n\t\t},\n\t\t\"test parse a invalid net\": {\n\t\t\tnet:       \"ww\",\n\t\t\texpectErr: true,\n\t\t\terrOut:    \"the annotation does not contain a valid IP address or network: invalid CIDR address: ww\",\n\t\t},\n\t\t\"test parse a empty net\": {\n\t\t\tnet:       \"\",\n\t\t\texpectErr: true,\n\t\t\terrOut:    \"the annotation does not contain a valid IP address or network: invalid CIDR address: \",\n\t\t},\n\t\t\"test parse multiple valid cidr\": {\n\t\t\tnet:        \"2.2.2.2/32,1.1.1.1/32,3.3.3.0/24\",\n\t\t\texpectCidr: []string{\"1.1.1.1/32\", \"2.2.2.2/32\", \"3.3.3.0/24\"},\n\t\t\texpectErr:  false,\n\t\t},\n\t}\n\n\tfor testName, test := range tests {\n\t\tdata := map[string]string{}\n\t\tdata[parser.GetAnnotationWithPrefix(\"whitelist-source-range\")] = test.net\n\t\ting.SetAnnotations(data)\n\t\tp := NewParser(mockBackend)\n\t\ti, err := p.Parse(ing)\n\t\tif err != nil && !test.expectErr {\n\t\t\tt.Errorf(\"%v:unexpected error: %v\", testName, err)\n\t\t}\n\t\tif test.expectErr {\n\t\t\tif err.Error() != test.errOut {\n\t\t\t\tt.Errorf(\"%v:expected error: %v but %v return\", testName, test.errOut, err.Error())\n\t\t\t}\n\t\t}\n\t\tif !test.expectErr {\n\t\t\tsr, ok := i.(*SourceRange)\n\t\t\tif !ok {\n\t\t\t\tt.Errorf(\"%v:expected a SourceRange type\", testName)\n\t\t\t}\n\t\t\tif !strsEquals(sr.CIDR, test.expectCidr) {\n\t\t\t\tt.Errorf(\"%v:expected %v CIDR but %v returned\", testName, test.expectCidr, sr.CIDR)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestUpdateSavedSearchPermissions(t *testing.T) {\n\tuser1 := &types.User{ID: 42}\n\tuser2 := &types.User{ID: 43}\n\tadmin := &types.User{ID: 44, SiteAdmin: true}\n\torg1 := &types.Org{ID: 42}\n\torg2 := &types.Org{ID: 43}\n\n\tcases := []struct {\n\t\texecUser *types.User\n\t\tssUserID *int32\n\t\tssOrgID  *int32\n\t\terrIs    error\n\t}{{\n\t\texecUser: user1,\n\t\tssUserID: &user1.ID,\n\t\terrIs:    nil,\n\t}, {\n\t\texecUser: user1,\n\t\tssUserID: &user2.ID,\n\t\terrIs:    &backend.InsufficientAuthorizationError{},\n\t}, {\n\t\texecUser: user1,\n\t\tssOrgID:  &org1.ID,\n\t\terrIs:    nil,\n\t}, {\n\t\texecUser: user1,\n\t\tssOrgID:  &org2.ID,\n\t\terrIs:    backend.ErrNotAnOrgMember,\n\t}, {\n\t\texecUser: admin,\n\t\tssOrgID:  &user1.ID,\n\t\terrIs:    nil,\n\t}, {\n\t\texecUser: admin,\n\t\tssOrgID:  &org1.ID,\n\t\terrIs:    nil,\n\t}}\n\n\tfor _, tt := range cases {\n\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tctx := actor.WithActor(context.Background(), actor.FromUser(tt.execUser.ID))\n\t\t\tusers := database.NewMockUserStore()\n\t\t\tusers.GetByCurrentAuthUserFunc.SetDefaultHook(func(ctx context.Context) (*types.User, error) {\n\t\t\t\tswitch actor.FromContext(ctx).UID {\n\t\t\t\tcase user1.ID:\n\t\t\t\t\treturn user1, nil\n\t\t\t\tcase user2.ID:\n\t\t\t\t\treturn user2, nil\n\t\t\t\tcase admin.ID:\n\t\t\t\t\treturn admin, nil\n\t\t\t\tdefault:\n\t\t\t\t\tpanic(\"bad actor\")\n\t\t\t\t}\n\t\t\t})\n\n\t\t\tsavedSearches := database.NewMockSavedSearchStore()\n\t\t\tsavedSearches.UpdateFunc.SetDefaultHook(func(_ context.Context, ss *types.SavedSearch) (*types.SavedSearch, error) {\n\t\t\t\treturn ss, nil\n\t\t\t})\n\t\t\tsavedSearches.GetByIDFunc.SetDefaultReturn(&api.SavedQuerySpecAndConfig{\n\t\t\t\tConfig: api.ConfigSavedQuery{\n\t\t\t\t\tUserID: tt.ssUserID,\n\t\t\t\t\tOrgID:  tt.ssOrgID,\n\t\t\t\t},\n\t\t\t}, nil)\n\n\t\t\torgMembers := database.NewMockOrgMemberStore()\n\t\t\torgMembers.GetByOrgIDAndUserIDFunc.SetDefaultHook(func(_ context.Context, orgID int32, userID int32) (*types.OrgMembership, error) {\n\t\t\t\tif orgID == userID {\n\t\t\t\t\treturn &types.OrgMembership{}, nil\n\t\t\t\t}\n\t\t\t\treturn nil, nil\n\t\t\t})\n\n\t\t\tdb := database.NewMockDB()\n\t\t\tdb.UsersFunc.SetDefaultReturn(users)\n\t\t\tdb.SavedSearchesFunc.SetDefaultReturn(savedSearches)\n\t\t\tdb.OrgMembersFunc.SetDefaultReturn(orgMembers)\n\n\t\t\t_, err := (&schemaResolver{db: db}).UpdateSavedSearch(ctx, &struct {\n\t\t\t\tID          graphql.ID\n\t\t\t\tDescription string\n\t\t\t\tQuery       string\n\t\t\t\tNotifyOwner bool\n\t\t\t\tNotifySlack bool\n\t\t\t\tOrgID       *graphql.ID\n\t\t\t\tUserID      *graphql.ID\n\t\t\t}{\n\t\t\t\tID:    marshalSavedSearchID(1),\n\t\t\t\tQuery: \"patterntype:literal\",\n\t\t\t})\n\t\t\tif tt.errIs == nil {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t} else {\n\t\t\t\trequire.ErrorAs(t, err, &tt.errIs)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (svc *Service) ModifyGlobalScheduledQueries(ctx context.Context, id uint, query fleet.ScheduledQueryPayload) (*fleet.ScheduledQuery, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.Pack{}, fleet.ActionWrite); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgp, err := svc.ds.EnsureGlobalPack(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tquery.PackID = ptr.Uint(gp.ID)\n\n\treturn svc.ModifyScheduledQuery(ctx, id, query)\n}", "is_vulnerable": 1}
{"code": "\tcidr := func(s string) *net.IPNet {\n\t\t_, n, _ := net.ParseCIDR(s)\n\t\treturn n\n\t}\n\n\tflagSrc := []string{`-dev`}\n\tsrc := map[string]string{\n\t\t\"json\": `{\n\t\t\t\"acl_agent_master_token\": \"furuQD0b\",\n\t\t\t\"acl_agent_token\": \"cOshLOQ2\",\n\t\t\t\"acl_datacenter\": \"m3urck3z\",\n\t\t\t\"acl_default_policy\": \"ArK3WIfE\",\n\t\t\t\"acl_down_policy\": \"vZXMfMP0\",\n\t\t\t\"acl_enable_key_list_policy\": true,\n\t\t\t\"acl_master_token\": \"C1Q1oIwh\",\n\t\t\t\"acl_replication_token\": \"LMmgy5dO\",\n\t\t\t\"acl_token\": \"O1El0wan\",\n\t\t\t\"acl_ttl\": \"18060s\",\n\t\t\t\"acl\" : {\n\t\t\t\t\"enabled\" : true,\n\t\t\t\t\"down_policy\" : \"03eb2aee\",\n\t\t\t\t\"default_policy\" : \"72c2e7a0\",\n\t\t\t\t\"enable_key_list_policy\": true,\n\t\t\t\t\"enable_token_persistence\": true,\n\t\t\t\t\"policy_ttl\": \"1123s\",\n\t\t\t\t\"role_ttl\": \"9876s\",\n\t\t\t\t\"token_ttl\": \"3321s\",\n\t\t\t\t\"enable_token_replication\" : true,\n\t\t\t\t\"msp_disable_bootstrap\": true,\n\t\t\t\t\"tokens\" : {\n\t\t\t\t\t\"master\" : \"8a19ac27\",\n\t\t\t\t\t\"agent_master\" : \"64fd0e08\",\n\t\t\t\t\t\"replication\" : \"5795983a\",\n\t\t\t\t\t\"agent\" : \"bed2377c\",\n\t\t\t\t\t\"default\" : \"418fdff1\",\n\t\t\t\t\t\"managed_service_provider\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"accessor_id\": \"first\", \n\t\t\t\t\t\t\t\"secret_id\": \"fb0cee1f-2847-467c-99db-a897cff5fd4d\"\n\t\t\t\t\t\t}, \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"accessor_id\": \"second\", \n\t\t\t\t\t\t\t\"secret_id\": \"1046c8da-e166-4667-897a-aefb343db9db\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"addresses\": {\n\t\t\t\t\"dns\": \"93.95.95.81\",\n\t\t\t\t\"http\": \"83.39.91.39\",\n\t\t\t\t\"https\": \"95.17.17.19\",\n\t\t\t\t\"grpc\": \"32.31.61.91\"\n\t\t\t},\n\t\t\t\"advertise_addr\": \"17.99.29.16\",\n\t\t\t\"advertise_addr_wan\": \"78.63.37.19\",\n\t\t\t\"audit\": {\n\t\t\t\t\"enabled\": false\n\t\t\t},\n\t\t\t\"autopilot\": {\n\t\t\t\t\"cleanup_dead_servers\": true,\n\t\t\t\t\"disable_upgrade_migration\": true,\n\t\t\t\t\"last_contact_threshold\": \"12705s\",\n\t\t\t\t\"max_trailing_logs\": 17849,\n\t\t\t\t\"min_quorum\":\t\t 3,\n\t\t\t\t\"redundancy_zone_tag\": \"3IsufDJf\",\n\t\t\t\t\"server_stabilization_time\": \"23057s\",\n\t\t\t\t\"upgrade_version_tag\": \"W9pDwFAL\"\n\t\t\t},\n\t\t\t\"bind_addr\": \"16.99.34.17\",\n\t\t\t\"bootstrap\": true,\n\t\t\t\"bootstrap_expect\": 53,\n\t\t\t\"ca_file\": \"erA7T0PM\",\n\t\t\t\"ca_path\": \"mQEN1Mfp\",\n\t\t\t\"cert_file\": \"7s4QAzDk\",\n\t\t\t\"check\": {\n\t\t\t\t\"id\": \"fZaCAXww\",\n\t\t\t\t\"name\": \"OOM2eo0f\",\n\t\t\t\t\"notes\": \"zXzXI9Gt\",\n\t\t\t\t\"service_id\": \"L8G0QNmR\",\n\t\t\t\t\"token\": \"oo4BCTgJ\",\n\t\t\t\t\"status\": \"qLykAl5u\",\n\t\t\t\t\"args\": [\"f3BemRjy\", \"e5zgpef7\"],\n\t\t\t\t\"http\": \"29B93haH\",\n\t\t\t\t\"header\": {\n\t\t\t\t\t\"hBq0zn1q\": [ \"2a9o9ZKP\", \"vKwA5lR6\" ],\n\t\t\t\t\t\"f3r6xFtM\": [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t},\n\t\t\t\t\"method\": \"Dou0nGT5\",\n\t\t\t\t\"body\": \"5PBQd2OT\",\n\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\"tcp\": \"JY6fTTcw\",\n\t\t\t\t\"interval\": \"18714s\",\n\t\t\t\t\"docker_container_id\": \"qF66POS9\",\n\t\t\t\t\"shell\": \"sOnDy228\",\n\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\"timeout\": \"5954s\",\n\t\t\t\t\"ttl\": \"30044s\",\n\t\t\t\t\"deregister_critical_service_after\": \"13209s\"\n\t\t\t},\n\t\t\t\"checks\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"uAjE6m9Z\",\n\t\t\t\t\t\"name\": \"QsZRGpYr\",\n\t\t\t\t\t\"notes\": \"VJ7Sk4BY\",\n\t\t\t\t\t\"service_id\": \"lSulPcyz\",\n\t\t\t\t\t\"token\": \"toO59sh8\",\n\t\t\t\t\t\"status\": \"9RlWsXMV\",\n\t\t\t\t\t\"args\": [\"4BAJttck\", \"4D2NPtTQ\"],\n\t\t\t\t\t\"http\": \"dohLcyQ2\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"ZBfTin3L\": [ \"1sDbEqYG\", \"lJGASsWK\" ],\n\t\t\t\t\t\t\"Ui0nU99X\": [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"aldrIQ4l\",\n\t\t\t\t\t\"body\": \"wSjTy7dg\",\n\t\t\t\t\t\"tcp\": \"RJQND605\",\n\t\t\t\t\t\"interval\": \"22164s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\"shell\": \"qAeOYy0M\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"1813s\",\n\t\t\t\t\t\"ttl\": \"21743s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Cqq95BhP\",\n\t\t\t\t\t\"name\": \"3qXpkS0i\",\n\t\t\t\t\t\"notes\": \"sb5qLTex\",\n\t\t\t\t\t\"service_id\": \"CmUUcRna\",\n\t\t\t\t\t\"token\": \"a3nQzHuy\",\n\t\t\t\t\t\"status\": \"irj26nf3\",\n\t\t\t\t\t\"args\": [\"9s526ogY\", \"gSlOHj1w\"],\n\t\t\t\t\t\"http\": \"yzhgsQ7Y\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"zcqwA8dO\": [ \"qb1zx0DL\", \"sXCxPFsD\" ],\n\t\t\t\t\t\t\"qxvdnSE9\": [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"gLrztrNw\",\n\t\t\t\t\t\"body\": \"0jkKgGUC\",\n\t\t\t\t\t\"tcp\": \"4jG5casb\",\n\t\t\t\t\t\"interval\": \"28767s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"THW6u7rL\",\n\t\t\t\t\t\"shell\": \"C1Zt3Zwh\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"18506s\",\n\t\t\t\t\t\"ttl\": \"31006s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"2366s\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"check_update_interval\": \"16507s\",\n\t\t\t\"client_addr\": \"93.83.18.19\",\n\t\t\t\"config_entries\": {\n\t\t\t\t\"bootstrap\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"kind\": \"proxy-defaults\",\n\t\t\t\t\t\t\"name\": \"global\",\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t\t\t\"bar\": 1.0\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t]\n                        },\n\t\t\t\"auto_encrypt\": {\n\t\t\t\t\"tls\": false,\n\t\t\t\t\"dns_san\": [\"a.com\", \"b.com\"],\n\t\t\t\t\"ip_san\": [\"192.168.4.139\", \"192.168.4.140\"],\n\t\t\t\t\"allow_tls\": true\n\t\t\t},\n\t\t\t\"connect\": {\n\t\t\t\t\"ca_provider\": \"consul\",\n\t\t\t\t\"ca_config\": {\n\t\t\t\t\t\"rotation_period\": \"90h\",\n\t\t\t\t\t\"intermediate_cert_ttl\": \"8760h\",\n\t\t\t\t\t\"leaf_cert_ttl\": \"1h\",\n\t\t\t\t\t\"csr_max_per_second\": 100,\n\t\t\t\t\t\"csr_max_concurrent\": 2\n\t\t\t\t},\n\t\t\t\t\"enable_mesh_gateway_wan_federation\": false,\n\t\t\t\t\"enabled\": true\n\t\t\t},\n\t\t\t\"gossip_lan\" : {\n\t\t\t\t\"gossip_nodes\": 6,\n\t\t\t\t\"gossip_interval\" : \"25252s\",\n\t\t\t\t\"retransmit_mult\" : 1234,\n\t\t\t\t\"suspicion_mult\"  : 1235,\n\t\t\t\t\"probe_interval\"  : \"101ms\",\n\t\t\t\t\"probe_timeout\"   : \"102ms\"\n\t\t\t},\n\t\t\t\"gossip_wan\" : {\n\t\t\t\t\"gossip_nodes\" : 2,\n\t\t\t\t\"gossip_interval\" : \"6966s\",\n\t\t\t\t\"retransmit_mult\" : 16384,\n\t\t\t\t\"suspicion_mult\"  : 16385,\n\t\t\t\t\"probe_interval\" : \"103ms\",\n\t\t\t\t\"probe_timeout\"  : \"104ms\"\n\t\t\t},\n\t\t\t\"data_dir\": \"` + dataDir + `\",\n\t\t\t\"datacenter\": \"rzo029wg\",\n\t\t\t\"default_query_time\": \"16743s\",\n\t\t\t\"disable_anonymous_signature\": true,\n\t\t\t\"disable_coordinates\": true,\n\t\t\t\"disable_host_node_id\": true,\n\t\t\t\"disable_http_unprintable_char_filter\": true,\n\t\t\t\"disable_keyring_file\": true,\n\t\t\t\"disable_remote_exec\": true,\n\t\t\t\"disable_update_check\": true,\n\t\t\t\"discard_check_output\": true,\n\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\"domain\": \"7W1xXSqd\",\n\t\t\t\"alt_domain\": \"1789hsd\",\n\t\t\t\"dns_config\": {\n\t\t\t\t\"allow_stale\": true,\n\t\t\t\t\"a_record_limit\": 29907,\n\t\t\t\t\"disable_compression\": true,\n\t\t\t\t\"enable_truncate\": true,\n\t\t\t\t\"max_stale\": \"29685s\",\n\t\t\t\t\"node_ttl\": \"7084s\",\n\t\t\t\t\"only_passing\": true,\n\t\t\t\t\"recursor_timeout\": \"4427s\",\n\t\t\t\t\"service_ttl\": {\n\t\t\t\t\t\"*\": \"32030s\"\n\t\t\t\t},\n\t\t\t\t\"udp_answer_limit\": 29909,\n\t\t\t\t\"use_cache\": true,\n\t\t\t\t\"cache_max_age\": \"5m\",\n\t\t\t\t\"prefer_namespace\": true\n\t\t\t},\n\t\t\t\"enable_acl_replication\": true,\n\t\t\t\"enable_agent_tls_for_checks\": true,\n\t\t\t\"enable_central_service_config\": true,\n\t\t\t\"enable_debug\": true,\n\t\t\t\"enable_script_checks\": true,\n\t\t\t\"enable_local_script_checks\": true,\n\t\t\t\"enable_syslog\": true,\n\t\t\t\"encrypt\": \"A4wELWqH\",\n\t\t\t\"encrypt_verify_incoming\": true,\n\t\t\t\"encrypt_verify_outgoing\": true,\n\t\t\t\"http_config\": {\n\t\t\t\t\"block_endpoints\": [ \"RBvAFcGD\", \"fWOWFznh\" ],\n\t\t\t\t\"allow_write_http_from\": [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ],\n\t\t\t\t\"response_headers\": {\n\t\t\t\t\t\"M6TKa9NP\": \"xjuxjOzQ\",\n\t\t\t\t\t\"JRCrHZed\": \"rl0mTx81\"\n\t\t\t\t},\n\t\t\t\t\"use_cache\": false\n\t\t\t},\n\t\t\t\"key_file\": \"IEkkwgIA\",\n\t\t\t\"leave_on_terminate\": true,\n\t\t\t\"limits\": {\n\t\t\t\t\"http_max_conns_per_client\": 100,\n\t\t\t\t\"https_handshake_timeout\": \"2391ms\",\n\t\t\t\t\"rpc_handshake_timeout\": \"1932ms\",\n\t\t\t\t\"rpc_rate\": 12029.43,\n\t\t\t\t\"rpc_max_burst\": 44848,\n\t\t\t\t\"rpc_max_conns_per_client\": 2954,\n\t\t\t\t\"kv_max_value_size\": 1234567800000000,\n\t\t\t\t\"txn_max_req_len\": 5678000000000000\n\t\t\t},\n\t\t\t\"log_level\": \"k1zo9Spt\",\n\t\t\t\"log_json\": true,\n\t\t\t\"max_query_time\": \"18237s\",\n\t\t\t\"node_id\": \"AsUIlw99\",\n\t\t\t\"node_meta\": {\n\t\t\t\t\"5mgGQMBk\": \"mJLtVMSG\",\n\t\t\t\t\"A7ynFMJB\": \"0Nx6RGab\"\n\t\t\t},\n\t\t\t\"node_name\": \"otlLxGaI\",\n\t\t\t\"non_voting_server\": true,\n\t\t\t\"performance\": {\n\t\t\t\t\"leave_drain_time\": \"8265s\",\n\t\t\t\t\"raft_multiplier\": 5,\n\t\t\t\t\"rpc_hold_timeout\": \"15707s\"\n\t\t\t},\n\t\t\t\"pid_file\": \"43xN80Km\",\n\t\t\t\"ports\": {\n\t\t\t\t\"dns\": 7001,\n\t\t\t\t\"http\": 7999,\n\t\t\t\t\"https\": 15127,\n\t\t\t\t\"server\": 3757,\n\t\t\t\t\"grpc\": 4881,\n\t\t\t\t\"sidecar_min_port\": 8888,\n\t\t\t\t\"sidecar_max_port\": 9999,\n\t\t\t\t\"expose_min_port\": 1111,\n\t\t\t\t\"expose_max_port\": 2222\n\t\t\t},\n\t\t\t\"protocol\": 30793,\n\t\t\t\"primary_datacenter\": \"ejtmd43d\",\n\t\t\t\"primary_gateways\": [ \"aej8eeZo\", \"roh2KahS\" ],\n\t\t\t\"primary_gateways_interval\": \"18866s\",\n\t\t\t\"raft_protocol\": 19016,\n\t\t\t\"raft_snapshot_threshold\": 16384,\n\t\t\t\"raft_snapshot_interval\": \"30s\",\n\t\t\t\"raft_trailing_logs\": 83749,\n\t\t\t\"reconnect_timeout\": \"23739s\",\n\t\t\t\"reconnect_timeout_wan\": \"26694s\",\n\t\t\t\"recursors\": [ \"63.38.39.58\", \"92.49.18.18\" ],\n\t\t\t\"rejoin_after_leave\": true,\n\t\t\t\"retry_interval\": \"8067s\",\n\t\t\t\"retry_interval_wan\": \"28866s\",\n\t\t\t\"retry_join\": [ \"pbsSFY7U\", \"l0qLtWij\" ],\n\t\t\t\"retry_join_wan\": [ \"PFsR02Ye\", \"rJdQIhER\" ],\n\t\t\t\"retry_max\": 913,\n\t\t\t\"retry_max_wan\": 23160,\n\t\t\t\"segment\": \"BC2NhTDi\",\n\t\t\t\"segments\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"PExYMe2E\",\n\t\t\t\t\t\"bind\": \"36.73.36.19\",\n\t\t\t\t\t\"port\": 38295,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"UzCvJgup\",\n\t\t\t\t\t\"bind\": \"37.58.38.19\",\n\t\t\t\t\t\"port\": 39292,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"serf_lan\": \"99.43.63.15\",\n\t\t\t\"serf_wan\": \"67.88.33.19\",\n\t\t\t\"server\": true,\n\t\t\t\"server_name\": \"Oerr9n1G\",\n\t\t\t\"service\": {\n\t\t\t\t\"id\": \"dLOXpSCI\",\n\t\t\t\t\"name\": \"o1ynPkp0\",\n\t\t\t\t\"meta\": {\n\t\t\t\t\t\"mymeta\": \"data\"\n\t\t\t\t},\n\t\t\t\t\"tagged_addresses\": {\n\t\t\t\t\t\"lan\": {\n\t\t\t\t\t\t\"address\": \"2d79888a\",\n\t\t\t\t\t\t\"port\": 2143\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": {\n\t\t\t\t\t\t\"address\": \"d4db85e2\",\n\t\t\t\t\t\t\"port\": 6109\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"tags\": [\"nkwshvM5\", \"NTDWn3ek\"],\n\t\t\t\t\"address\": \"cOlSOhbp\",\n\t\t\t\t\"token\": \"msy7iWER\",\n\t\t\t\t\"port\": 24237,\n\t\t\t\t\"weights\": {\n\t\t\t\t\t\"passing\": 100,\n\t\t\t\t\t\"warning\": 1\n\t\t\t\t},\n\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\"check\": {\n\t\t\t\t\t\"id\": \"RMi85Dv8\",\n\t\t\t\t\t\"name\": \"iehanzuq\",\n\t\t\t\t\t\"status\": \"rCvn53TH\",\n\t\t\t\t\t\"notes\": \"fti5lfF3\",\n\t\t\t\t\t\"args\": [\"16WRUmwS\", \"QWk7j7ae\"],\n\t\t\t\t\t\"http\": \"dl3Fgme3\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"rjm4DEd3\": [\"2m3m2Fls\"],\n\t\t\t\t\t\t\"l4HwQ112\": [\"fk56MNlo\", \"dhLK56aZ\"]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"9afLm3Mj\",\n\t\t\t\t\t\"body\": \"wVVL2V6f\",\n\t\t\t\t\t\"tcp\": \"fjiLFqVd\",\n\t\t\t\t\t\"interval\": \"23926s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"dO5TtRHk\",\n\t\t\t\t\t\"shell\": \"e6q2ttES\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"38483s\",\n\t\t\t\t\t\"ttl\": \"10943s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"68787s\"\n\t\t\t\t},\n\t\t\t\t\"checks\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"Zv99e9Ka\",\n\t\t\t\t\t\t\"name\": \"sgV4F7Pk\",\n\t\t\t\t\t\t\"notes\": \"yP5nKbW0\",\n\t\t\t\t\t\t\"status\": \"7oLMEyfu\",\n\t\t\t\t\t\t\"args\": [\"5wEZtZpv\", \"0Ihyk8cS\"],\n\t\t\t\t\t\t\"http\": \"KyDjGY9H\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"gv5qefTz\": [ \"5Olo2pMG\", \"PvvKWQU5\" ],\n\t\t\t\t\t\t\t\"SHOVq1Vv\": [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"T66MFBfR\",\n\t\t\t\t\t\t\"body\": \"OwGjTFQi\",\n\t\t\t\t\t\t\"tcp\": \"bNnNfx2A\",\n\t\t\t\t\t\t\"interval\": \"22224s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\t\"shell\": \"omVZq7Sz\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"18913s\",\n\t\t\t\t\t\t\"ttl\": \"44743s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"G79O6Mpr\",\n\t\t\t\t\t\t\"name\": \"IEqrzrsd\",\n\t\t\t\t\t\t\"notes\": \"SVqApqeM\",\n\t\t\t\t\t\t\"status\": \"XXkVoZXt\",\n\t\t\t\t\t\t\"args\": [\"wD05Bvao\", \"rLYB7kQC\"],\n\t\t\t\t\t\t\"http\": \"kyICZsn8\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"4ebP5vL4\": [ \"G20SrL5Q\", \"DwPKlMbo\" ],\n\t\t\t\t\t\t\t\"p2UI34Qz\": [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"ciYHWors\",\n\t\t\t\t\t\t\"body\": \"lUVLGYU7\",\n\t\t\t\t\t\t\"tcp\": \"FfvCwlqH\",\n\t\t\t\t\t\t\"interval\": \"12356s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"HBndBU6R\",\n\t\t\t\t\t\t\"shell\": \"hVI33JjA\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38282s\",\n\t\t\t\t\t\t\"ttl\": \"1181s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"connect\": {\n\t\t\t\t\t\"native\": true\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"services\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"wI1dzxS4\",\n\t\t\t\t\t\"name\": \"7IszXMQ1\",\n\t\t\t\t\t\"tags\": [\"0Zwg8l6v\", \"zebELdN5\"],\n\t\t\t\t\t\"address\": \"9RhqPSPB\",\n\t\t\t\t\t\"token\": \"myjKJkWH\",\n\t\t\t\t\t\"port\": 72219,\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"check\": {\n\t\t\t\t\t\t\"id\": \"qmfeO5if\",\n\t\t\t\t\t\t\"name\": \"atDGP7n5\",\n\t\t\t\t\t\t\"status\": \"pDQKEhWL\",\n\t\t\t\t\t\t\"notes\": \"Yt8EDLev\",\n\t\t\t\t\t\t\"args\": [\"81EDZLPa\", \"bPY5X8xd\"],\n\t\t\t\t\t\t\"http\": \"qzHYvmJO\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"UkpmZ3a3\": [\"2dfzXuxZ\"],\n\t\t\t\t\t\t\t\"cVFpko4u\": [\"gGqdEB6k\", \"9LsRo22u\"]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"X5DrovFc\",\n\t\t\t\t\t\t\"body\": \"WeikigLh\",\n\t\t\t\t\t\t\"tcp\": \"ICbxkpSF\",\n\t\t\t\t\t\t\"interval\": \"24392s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ZKXr68Yb\",\n\t\t\t\t\t\t\"shell\": \"CEfzx0Fo\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38333s\",\n\t\t\t\t\t\t\"ttl\": \"57201s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"44214s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"connect\": {\n\t\t\t\t\t\t\"sidecar_service\": {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"MRHVMZuD\",\n\t\t\t\t\t\"name\": \"6L6BVfgH\",\n\t\t\t\t\t\"tags\": [\"7Ale4y6o\", \"PMBW08hy\"],\n\t\t\t\t\t\"address\": \"R6H6g8h0\",\n\t\t\t\t\t\"token\": \"ZgY8gjMI\",\n\t\t\t\t\t\"port\": 38292,\n\t\t\t\t\t\"weights\": {\n\t\t\t\t\t\t\"passing\": 1979,\n\t\t\t\t\t\t\"warning\": 6\n\t\t\t\t\t},\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"checks\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"GTti9hCo\",\n\t\t\t\t\t\t\t\"name\": \"9OOS93ne\",\n\t\t\t\t\t\t\t\"notes\": \"CQy86DH0\",\n\t\t\t\t\t\t\t\"status\": \"P0SWDvrk\",\n\t\t\t\t\t\t\t\"args\": [\"EXvkYIuG\", \"BATOyt6h\"],\n\t\t\t\t\t\t\t\"http\": \"u97ByEiW\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"MUlReo8L\": [ \"AUZG7wHG\", \"gsN0Dc2N\" ],\n\t\t\t\t\t\t\t\t\"1UJXjVrT\": [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"5wkAxCUE\",\n\t\t\t\t\t\t\t\"body\": \"7CRjCJyz\",\n\t\t\t\t\t\t\t\"tcp\": \"MN3oA9D2\",\n\t\t\t\t\t\t\t\"interval\": \"32718s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"cU15LMet\",\n\t\t\t\t\t\t\t\"shell\": \"nEz9qz2l\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"34738s\",\n\t\t\t\t\t\t\t\"ttl\": \"22773s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"UHsDeLxG\",\n\t\t\t\t\t\t\t\"name\": \"PQSaPWlT\",\n\t\t\t\t\t\t\t\"notes\": \"jKChDOdl\",\n\t\t\t\t\t\t\t\"status\": \"5qFz6OZn\",\n\t\t\t\t\t\t\t\"args\": [\"NMtYWlT9\", \"vj74JXsm\"],\n\t\t\t\t\t\t\t\"http\": \"1LBDJhw4\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\": [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\": [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"wzByP903\",\n\t\t\t\t\t\t\t\"body\": \"4I8ucZgZ\",\n\t\t\t\t\t\t\t\"tcp\": \"2exjZIGE\",\n\t\t\t\t\t\t\t\"interval\": \"5656s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"5tDBWpfA\",\n\t\t\t\t\t\t\t\"shell\": \"rlTpLM8s\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"4868s\",\n\t\t\t\t\t\t\t\"ttl\": \"11222s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"connect\": {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Kh81CPF6\",\n\t\t\t\t\t\"kind\": \"connect-proxy\",\n\t\t\t\t\t\"name\": \"Kh81CPF6-proxy\",\n\t\t\t\t\t\"port\": 31471,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"destination_service_id\": \"6L6BVfgH-id\",\n\t\t\t\t\t\t\"destination_service_name\": \"6L6BVfgH\",\n\t\t\t\t\t\t\"local_service_address\": \"127.0.0.2\",\n\t\t\t\t\t\t\"local_service_port\": 23759,\n\t\t\t\t\t\t\"expose\": {\n\t\t\t\t\t\t\t\"checks\": true,\n\t\t\t\t\t\t\t\"paths\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"path\": \"/health\",\n\t\t\t\t\t\t\t\t\t\"local_path_port\": 8080,\n\t\t\t\t\t\t\t\t\t\"listener_port\": 21500,\n\t\t\t\t\t\t\t\t\t\"protocol\": \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"upstreams\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KPtAj2cb\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 4051,\n\t\t\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KSd8HsRl\",\n\t\t\t\t\t\t\t\t\"destination_namespace\": \"9nakw0td\",\n\t\t\t\t\t\t\t\t\"destination_type\": \"prepared_query\",\n\t\t\t\t\t\t\t\t\"local_bind_address\": \"127.24.88.0\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 11884\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"kvVqbwSE\",\n\t\t\t\t\t\"kind\": \"mesh-gateway\",\n\t\t\t\t\t\"name\": \"gw-primary-dc\",\n\t\t\t\t\t\"port\": 27147,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"1CuJHVfw\" : \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"session_ttl_min\": \"26627s\",\n\t\t\t\"skip_leave_on_interrupt\": true,\n\t\t\t\"start_join\": [ \"LR3hGDoG\", \"MwVpZ4Up\" ],\n\t\t\t\"start_join_wan\": [ \"EbFSc3nA\", \"kwXTh623\" ],\n\t\t\t\"syslog_facility\": \"hHv79Uia\",\n\t\t\t\"tagged_addresses\": {\n\t\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\"\n\t\t\t},\n\t\t\t\"telemetry\": {\n\t\t\t\t\"circonus_api_app\": \"p4QOTe9j\",\n\t\t\t\t\"circonus_api_token\": \"E3j35V23\",\n\t\t\t\t\"circonus_api_url\": \"mEMjHpGg\",\n\t\t\t\t\"circonus_broker_id\": \"BHlxUhed\",\n\t\t\t\t\"circonus_broker_select_tag\": \"13xy1gHm\",\n\t\t\t\t\"circonus_check_display_name\": \"DRSlQR6n\",\n\t\t\t\t\"circonus_check_force_metric_activation\": \"Ua5FGVYf\",\n\t\t\t\t\"circonus_check_id\": \"kGorutad\",\n\t\t\t\t\"circonus_check_instance_id\": \"rwoOL6R4\",\n\t\t\t\t\"circonus_check_search_tag\": \"ovT4hT4f\",\n\t\t\t\t\"circonus_check_tags\": \"prvO4uBl\",\n\t\t\t\t\"circonus_submission_interval\": \"DolzaflP\",\n\t\t\t\t\"circonus_submission_url\": \"gTcbS93G\",\n\t\t\t\t\"disable_hostname\": true,\n\t\t\t\t\"dogstatsd_addr\": \"0wSndumK\",\n\t\t\t\t\"dogstatsd_tags\": [ \"3N81zSUB\",\"Xtj8AnXZ\" ],\n\t\t\t\t\"filter_default\": true,\n\t\t\t\t\"prefix_filter\": [ \"+oJotS8XJ\",\"-cazlEhGn\" ],\n\t\t\t\t\"metrics_prefix\": \"ftO6DySn\",\n\t\t\t\t\"prometheus_retention_time\": \"15s\",\n\t\t\t\t\"statsd_address\": \"drce87cy\",\n\t\t\t\t\"statsite_address\": \"HpFwKB8R\"\n\t\t\t},\n\t\t\t\"tls_cipher_suites\": \"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256\",\n\t\t\t\"tls_min_version\": \"pAOWafkR\",\n\t\t\t\"tls_prefer_server_cipher_suites\": true,\n\t\t\t\"translate_wan_addrs\": true,\n\t\t\t\"ui\": true,\n\t\t\t\"ui_dir\": \"11IFzAUn\",\n\t\t\t\"ui_content_path\": \"consul\",\n\t\t\t\"unix_sockets\": {\n\t\t\t\t\"group\": \"8pFodrV8\",\n\t\t\t\t\"mode\": \"E8sAwOv4\",\n\t\t\t\t\"user\": \"E0nB1DwA\"\n\t\t\t},\n\t\t\t\"verify_incoming\": true,\n\t\t\t\"verify_incoming_https\": true,\n\t\t\t\"verify_incoming_rpc\": true,\n\t\t\t\"verify_outgoing\": true,\n\t\t\t\"verify_server_hostname\": true,\n\t\t\t\"watches\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"key\",\n\t\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\t\"key\": \"j9lF1Tve\",\n\t\t\t\t\t\"handler\": \"90N7S4LN\"\n\t\t\t\t}, {\n\t\t\t\t\t\"type\": \"keyprefix\",\n\t\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\t\"key\": \"sl3Dffu7\",\n\t\t\t\t\t\"args\": [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t\t}\n\t\t\t]\n\t\t}`,\n\t\t\"hcl\": `\n\t\t\tacl_agent_master_token = \"furuQD0b\"\n\t\t\tacl_agent_token = \"cOshLOQ2\"\n\t\t\tacl_datacenter = \"m3urck3z\"\n\t\t\tacl_default_policy = \"ArK3WIfE\"\n\t\t\tacl_down_policy = \"vZXMfMP0\"\n\t\t\tacl_enable_key_list_policy = true\n\t\t\tacl_master_token = \"C1Q1oIwh\"\n\t\t\tacl_replication_token = \"LMmgy5dO\"\n\t\t\tacl_token = \"O1El0wan\"\n\t\t\tacl_ttl = \"18060s\"\n\t\t\tacl = {\n\t\t\t\tenabled = true\n\t\t\t\tdown_policy = \"03eb2aee\"\n\t\t\t\tdefault_policy = \"72c2e7a0\"\n\t\t\t\tenable_key_list_policy = true\n\t\t\t\tenable_token_persistence = true\n\t\t\t\tpolicy_ttl = \"1123s\"\n\t\t\t\trole_ttl = \"9876s\"\n\t\t\t\ttoken_ttl = \"3321s\"\n\t\t\t\tenable_token_replication = true\n\t\t\t\tmsp_disable_bootstrap = true\n\t\t\t\ttokens = {\n\t\t\t\t\tmaster = \"8a19ac27\",\n\t\t\t\t\tagent_master = \"64fd0e08\",\n\t\t\t\t\treplication = \"5795983a\",\n\t\t\t\t\tagent = \"bed2377c\",\n\t\t\t\t\tdefault = \"418fdff1\",\n\t\t\t\t\tmanaged_service_provider = [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\taccessor_id = \"first\", \n\t\t\t\t\t\t\tsecret_id = \"fb0cee1f-2847-467c-99db-a897cff5fd4d\"\n\t\t\t\t\t\t}, \n\t\t\t\t\t\t{\n\t\t\t\t\t\t\taccessor_id = \"second\", \n\t\t\t\t\t\t\tsecret_id = \"1046c8da-e166-4667-897a-aefb343db9db\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t}\n\t\t\taddresses = {\n\t\t\t\tdns = \"93.95.95.81\"\n\t\t\t\thttp = \"83.39.91.39\"\n\t\t\t\thttps = \"95.17.17.19\"\n\t\t\t\tgrpc = \"32.31.61.91\"\n\t\t\t}\n\t\t\tadvertise_addr = \"17.99.29.16\"\n\t\t\tadvertise_addr_wan = \"78.63.37.19\"\n\t\t\taudit = {\n\t\t\t\tenabled = false\n\t\t\t}\n\t\t\tautopilot = {\n\t\t\t\tcleanup_dead_servers = true\n\t\t\t\tdisable_upgrade_migration = true\n\t\t\t\tlast_contact_threshold = \"12705s\"\n\t\t\t\tmax_trailing_logs = 17849\n\t\t\t\tmin_quorum = 3\n\t\t\t\tredundancy_zone_tag = \"3IsufDJf\"\n\t\t\t\tserver_stabilization_time = \"23057s\"\n\t\t\t\tupgrade_version_tag = \"W9pDwFAL\"\n\t\t\t}\n\t\t\tbind_addr = \"16.99.34.17\"\n\t\t\tbootstrap = true\n\t\t\tbootstrap_expect = 53\n\t\t\tca_file = \"erA7T0PM\"\n\t\t\tca_path = \"mQEN1Mfp\"\n\t\t\tcert_file = \"7s4QAzDk\"\n\t\t\tcheck = {\n\t\t\t\tid = \"fZaCAXww\"\n\t\t\t\tname = \"OOM2eo0f\"\n\t\t\t\tnotes = \"zXzXI9Gt\"\n\t\t\t\tservice_id = \"L8G0QNmR\"\n\t\t\t\ttoken = \"oo4BCTgJ\"\n\t\t\t\tstatus = \"qLykAl5u\"\n\t\t\t\targs = [\"f3BemRjy\", \"e5zgpef7\"]\n\t\t\t\thttp = \"29B93haH\"\n\t\t\t\theader = {\n\t\t\t\t\thBq0zn1q = [ \"2a9o9ZKP\", \"vKwA5lR6\" ]\n\t\t\t\t\tf3r6xFtM = [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t}\n\t\t\t\tmethod = \"Dou0nGT5\"\n\t\t\t\tbody = \"5PBQd2OT\"\n\t\t\t\ttcp = \"JY6fTTcw\"\n\t\t\t\tinterval = \"18714s\"\n\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\tdocker_container_id = \"qF66POS9\"\n\t\t\t\tshell = \"sOnDy228\"\n\t\t\t\ttls_skip_verify = true\n\t\t\t\ttimeout = \"5954s\"\n\t\t\t\tttl = \"30044s\"\n\t\t\t\tderegister_critical_service_after = \"13209s\"\n\t\t\t},\n\t\t\tchecks = [\n\t\t\t\t{\n\t\t\t\t\tid = \"uAjE6m9Z\"\n\t\t\t\t\tname = \"QsZRGpYr\"\n\t\t\t\t\tnotes = \"VJ7Sk4BY\"\n\t\t\t\t\tservice_id = \"lSulPcyz\"\n\t\t\t\t\ttoken = \"toO59sh8\"\n\t\t\t\t\tstatus = \"9RlWsXMV\"\n\t\t\t\t\targs = [\"4BAJttck\", \"4D2NPtTQ\"]\n\t\t\t\t\thttp = \"dohLcyQ2\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"ZBfTin3L\" = [ \"1sDbEqYG\", \"lJGASsWK\" ]\n\t\t\t\t\t\t\"Ui0nU99X\" = [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"aldrIQ4l\"\n\t\t\t\t\tbody = \"wSjTy7dg\"\n\t\t\t\t\ttcp = \"RJQND605\"\n\t\t\t\t\tinterval = \"22164s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\tshell = \"qAeOYy0M\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"1813s\"\n\t\t\t\t\tttl = \"21743s\"\n\t\t\t\t\tderegister_critical_service_after = \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Cqq95BhP\"\n\t\t\t\t\tname = \"3qXpkS0i\"\n\t\t\t\t\tnotes = \"sb5qLTex\"\n\t\t\t\t\tservice_id = \"CmUUcRna\"\n\t\t\t\t\ttoken = \"a3nQzHuy\"\n\t\t\t\t\tstatus = \"irj26nf3\"\n\t\t\t\t\targs = [\"9s526ogY\", \"gSlOHj1w\"]\n\t\t\t\t\thttp = \"yzhgsQ7Y\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"zcqwA8dO\" = [ \"qb1zx0DL\", \"sXCxPFsD\" ]\n\t\t\t\t\t\t\"qxvdnSE9\" = [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"gLrztrNw\"\n\t\t\t\t\tbody = \"0jkKgGUC\"\n\t\t\t\t\ttcp = \"4jG5casb\"\n\t\t\t\t\tinterval = \"28767s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"THW6u7rL\"\n\t\t\t\t\tshell = \"C1Zt3Zwh\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"18506s\"\n\t\t\t\t\tttl = \"31006s\"\n\t\t\t\t\tderegister_critical_service_after = \"2366s\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tcheck_update_interval = \"16507s\"\n\t\t\tclient_addr = \"93.83.18.19\"\n\t\t\tconfig_entries {\n\t\t\t\t# This is using the repeated block-to-array HCL magic\n\t\t\t\tbootstrap {\n\t\t\t\t\tkind = \"proxy-defaults\"\n\t\t\t\t\tname = \"global\"\n\t\t\t\t\tconfig {\n\t\t\t\t\t\tfoo = \"bar\"\n\t\t\t\t\t\tbar = 1.0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto_encrypt = {\n\t\t\t\ttls = false\n\t\t\t\tdns_san = [\"a.com\", \"b.com\"]\n\t\t\t\tip_san = [\"192.168.4.139\", \"192.168.4.140\"]\n\t\t\t\tallow_tls = true\n\t\t\t}\n\t\t\tconnect {\n\t\t\t\tca_provider = \"consul\"\n\t\t\t\tca_config {\n\t\t\t\t\trotation_period = \"90h\"\n\t\t\t\t\tintermediate_cert_ttl = \"8760h\"\n\t\t\t\t\tleaf_cert_ttl = \"1h\"\n\t\t\t\t\t# hack float since json parses numbers as float and we have to\n\t\t\t\t\t# assert against the same thing\n\t\t\t\t\tcsr_max_per_second = 100.0\n\t\t\t\t\tcsr_max_concurrent = 2.0\n\t\t\t\t}\n\t\t\t\tenable_mesh_gateway_wan_federation = false\n\t\t\t\tenabled = true\n\t\t\t}\n\t\t\tgossip_lan {\n\t\t\t\tgossip_nodes    = 6\n\t\t\t\tgossip_interval = \"25252s\"\n\t\t\t\tretransmit_mult = 1234\n\t\t\t\tsuspicion_mult  = 1235\n\t\t\t\tprobe_interval  = \"101ms\"\n\t\t\t\tprobe_timeout   = \"102ms\"\n\t\t\t}\n\t\t\tgossip_wan {\n\t\t\t\tgossip_nodes    = 2\n\t\t\t\tgossip_interval = \"6966s\"\n\t\t\t\tretransmit_mult = 16384\n\t\t\t\tsuspicion_mult  = 16385\n\t\t\t\tprobe_interval  = \"103ms\"\n\t\t\t\tprobe_timeout   = \"104ms\"\n\t\t\t}\n\t\t\tdata_dir = \"` + dataDir + `\"\n\t\t\tdatacenter = \"rzo029wg\"\n\t\t\tdefault_query_time = \"16743s\"\n\t\t\tdisable_anonymous_signature = true\n\t\t\tdisable_coordinates = true\n\t\t\tdisable_host_node_id = true\n\t\t\tdisable_http_unprintable_char_filter = true\n\t\t\tdisable_keyring_file = true\n\t\t\tdisable_remote_exec = true\n\t\t\tdisable_update_check = true\n\t\t\tdiscard_check_output = true\n\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\tdomain = \"7W1xXSqd\"\n\t\t\talt_domain = \"1789hsd\"\n\t\t\tdns_config {\n\t\t\t\tallow_stale = true\n\t\t\t\ta_record_limit = 29907\n\t\t\t\tdisable_compression = true\n\t\t\t\tenable_truncate = true\n\t\t\t\tmax_stale = \"29685s\"\n\t\t\t\tnode_ttl = \"7084s\"\n\t\t\t\tonly_passing = true\n\t\t\t\trecursor_timeout = \"4427s\"\n\t\t\t\tservice_ttl = {\n\t\t\t\t\t\"*\" = \"32030s\"\n\t\t\t\t}\n\t\t\t\tudp_answer_limit = 29909\n\t\t\t\tuse_cache = true\n\t\t\t\tcache_max_age = \"5m\"\n\t\t\t\tprefer_namespace = true\n\t\t\t}\n\t\t\tenable_acl_replication = true\n\t\t\tenable_agent_tls_for_checks = true\n\t\t\tenable_central_service_config = true\n\t\t\tenable_debug = true\n\t\t\tenable_script_checks = true\n\t\t\tenable_local_script_checks = true\n\t\t\tenable_syslog = true\n\t\t\tencrypt = \"A4wELWqH\"\n\t\t\tencrypt_verify_incoming = true\n\t\t\tencrypt_verify_outgoing = true\n\t\t\thttp_config {\n\t\t\t\tblock_endpoints = [ \"RBvAFcGD\", \"fWOWFznh\" ]\n\t\t\t\tallow_write_http_from = [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ]\n\t\t\t\tresponse_headers = {\n\t\t\t\t\t\"M6TKa9NP\" = \"xjuxjOzQ\"\n\t\t\t\t\t\"JRCrHZed\" = \"rl0mTx81\"\n\t\t\t\t}\n\t\t\t\tuse_cache = false\n\t\t\t}\n\t\t\tkey_file = \"IEkkwgIA\"\n\t\t\tleave_on_terminate = true\n\t\t\tlimits {\n\t\t\t\thttp_max_conns_per_client = 100\n\t\t\t\thttps_handshake_timeout = \"2391ms\"\n\t\t\t\trpc_handshake_timeout = \"1932ms\"\n\t\t\t\trpc_rate = 12029.43\n\t\t\t\trpc_max_burst = 44848\n\t\t\t\trpc_max_conns_per_client = 2954\n\t\t\t\tkv_max_value_size = 1234567800000000\n\t\t\t\ttxn_max_req_len = 5678000000000000\n\t\t\t}\n\t\t\tlog_level = \"k1zo9Spt\"\n\t\t\tlog_json = true\n\t\t\tmax_query_time = \"18237s\"\n\t\t\tnode_id = \"AsUIlw99\"\n\t\t\tnode_meta {\n\t\t\t\t\"5mgGQMBk\" = \"mJLtVMSG\"\n\t\t\t\t\"A7ynFMJB\" = \"0Nx6RGab\"\n\t\t\t}\n\t\t\tnode_name = \"otlLxGaI\"\n\t\t\tnon_voting_server = true\n\t\t\tperformance {\n\t\t\t\tleave_drain_time = \"8265s\"\n\t\t\t\traft_multiplier = 5\n\t\t\t\trpc_hold_timeout = \"15707s\"\n\t\t\t}\n\t\t\tpid_file = \"43xN80Km\"\n\t\t\tports {\n\t\t\t\tdns = 7001\n\t\t\t\thttp = 7999\n\t\t\t\thttps = 15127\n\t\t\t\tserver = 3757\n\t\t\t\tgrpc = 4881\n\t\t\t\tproxy_min_port = 2000\n\t\t\t\tproxy_max_port = 3000\n\t\t\t\tsidecar_min_port = 8888\n\t\t\t\tsidecar_max_port = 9999\n\t\t\t\texpose_min_port = 1111\n\t\t\t\texpose_max_port = 2222\n\t\t\t}\n\t\t\tprotocol = 30793\n\t\t\tprimary_datacenter = \"ejtmd43d\"\n\t\t\tprimary_gateways = [ \"aej8eeZo\", \"roh2KahS\" ]\n\t\t\tprimary_gateways_interval = \"18866s\"\n\t\t\traft_protocol = 19016\n\t\t\traft_snapshot_threshold = 16384\n\t\t\traft_snapshot_interval = \"30s\"\n\t\t\traft_trailing_logs = 83749\n\t\t\treconnect_timeout = \"23739s\"\n\t\t\treconnect_timeout_wan = \"26694s\"\n\t\t\trecursors = [ \"63.38.39.58\", \"92.49.18.18\" ]\n\t\t\trejoin_after_leave = true\n\t\t\tretry_interval = \"8067s\"\n\t\t\tretry_interval_wan = \"28866s\"\n\t\t\tretry_join = [ \"pbsSFY7U\", \"l0qLtWij\" ]\n\t\t\tretry_join_wan = [ \"PFsR02Ye\", \"rJdQIhER\" ]\n\t\t\tretry_max = 913\n\t\t\tretry_max_wan = 23160\n\t\t\tsegment = \"BC2NhTDi\"\n\t\t\tsegments = [\n\t\t\t\t{\n\t\t\t\t\tname = \"PExYMe2E\"\n\t\t\t\t\tbind = \"36.73.36.19\"\n\t\t\t\t\tport = 38295\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tname = \"UzCvJgup\"\n\t\t\t\t\tbind = \"37.58.38.19\"\n\t\t\t\t\tport = 39292\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tserf_lan = \"99.43.63.15\"\n\t\t\tserf_wan = \"67.88.33.19\"\n\t\t\tserver = true\n\t\t\tserver_name = \"Oerr9n1G\"\n\t\t\tservice = {\n\t\t\t\tid = \"dLOXpSCI\"\n\t\t\t\tname = \"o1ynPkp0\"\n\t\t\t\tmeta = {\n\t\t\t\t\tmymeta = \"data\"\n\t\t\t\t}\n\t\t\t\ttagged_addresses = {\n\t\t\t\t\tlan = {\n\t\t\t\t\t\taddress = \"2d79888a\"\n\t\t\t\t\t\tport = 2143\n\t\t\t\t\t}\n\t\t\t\t\twan = {\n\t\t\t\t\t\taddress = \"d4db85e2\"\n\t\t\t\t\t\tport = 6109\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttags = [\"nkwshvM5\", \"NTDWn3ek\"]\n\t\t\t\taddress = \"cOlSOhbp\"\n\t\t\t\ttoken = \"msy7iWER\"\n\t\t\t\tport = 24237\n\t\t\t\tweights = {\n\t\t\t\t\tpassing = 100,\n\t\t\t\t\twarning = 1\n\t\t\t\t}\n\t\t\t\tenable_tag_override = true\n\t\t\t\tcheck = {\n\t\t\t\t\tid = \"RMi85Dv8\"\n\t\t\t\t\tname = \"iehanzuq\"\n\t\t\t\t\tstatus = \"rCvn53TH\"\n\t\t\t\t\tnotes = \"fti5lfF3\"\n\t\t\t\t\targs = [\"16WRUmwS\", \"QWk7j7ae\"]\n\t\t\t\t\thttp = \"dl3Fgme3\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\trjm4DEd3 = [ \"2m3m2Fls\" ]\n\t\t\t\t\t\tl4HwQ112 = [ \"fk56MNlo\", \"dhLK56aZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"9afLm3Mj\"\n\t\t\t\t\tbody = \"wVVL2V6f\"\n\t\t\t\t\ttcp = \"fjiLFqVd\"\n\t\t\t\t\tinterval = \"23926s\"\n\t\t\t\t\tdocker_container_id = \"dO5TtRHk\"\n\t\t\t\t\tshell = \"e6q2ttES\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"38483s\"\n\t\t\t\t\tttl = \"10943s\"\n\t\t\t\t\tderegister_critical_service_after = \"68787s\"\n\t\t\t\t}\n\t\t\t\tchecks = [\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"Zv99e9Ka\"\n\t\t\t\t\t\tname = \"sgV4F7Pk\"\n\t\t\t\t\t\tnotes = \"yP5nKbW0\"\n\t\t\t\t\t\tstatus = \"7oLMEyfu\"\n\t\t\t\t\t\targs = [\"5wEZtZpv\", \"0Ihyk8cS\"]\n\t\t\t\t\t\thttp = \"KyDjGY9H\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"gv5qefTz\" = [ \"5Olo2pMG\", \"PvvKWQU5\" ]\n\t\t\t\t\t\t\t\"SHOVq1Vv\" = [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"T66MFBfR\"\n\t\t\t\t\t\tbody = \"OwGjTFQi\"\n\t\t\t\t\t\ttcp = \"bNnNfx2A\"\n\t\t\t\t\t\tinterval = \"22224s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\t\tshell = \"omVZq7Sz\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"18913s\"\n\t\t\t\t\t\tttl = \"44743s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"G79O6Mpr\"\n\t\t\t\t\t\tname = \"IEqrzrsd\"\n\t\t\t\t\t\tnotes = \"SVqApqeM\"\n\t\t\t\t\t\tstatus = \"XXkVoZXt\"\n\t\t\t\t\t\targs = [\"wD05Bvao\", \"rLYB7kQC\"]\n\t\t\t\t\t\thttp = \"kyICZsn8\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"4ebP5vL4\" = [ \"G20SrL5Q\", \"DwPKlMbo\" ]\n\t\t\t\t\t\t\t\"p2UI34Qz\" = [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"ciYHWors\"\n\t\t\t\t\t\tbody = \"lUVLGYU7\"\n\t\t\t\t\t\ttcp = \"FfvCwlqH\"\n\t\t\t\t\t\tinterval = \"12356s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"HBndBU6R\"\n\t\t\t\t\t\tshell = \"hVI33JjA\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38282s\"\n\t\t\t\t\t\tttl = \"1181s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t\tconnect {\n\t\t\t\t\tnative = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tservices = [\n\t\t\t\t{\n\t\t\t\t\tid = \"wI1dzxS4\"\n\t\t\t\t\tname = \"7IszXMQ1\"\n\t\t\t\t\ttags = [\"0Zwg8l6v\", \"zebELdN5\"]\n\t\t\t\t\taddress = \"9RhqPSPB\"\n\t\t\t\t\ttoken = \"myjKJkWH\"\n\t\t\t\t\tport = 72219\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tcheck = {\n\t\t\t\t\t\tid = \"qmfeO5if\"\n\t\t\t\t\t\tname = \"atDGP7n5\"\n\t\t\t\t\t\tstatus = \"pDQKEhWL\"\n\t\t\t\t\t\tnotes = \"Yt8EDLev\"\n\t\t\t\t\t\targs = [\"81EDZLPa\", \"bPY5X8xd\"]\n\t\t\t\t\t\thttp = \"qzHYvmJO\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\tUkpmZ3a3 = [ \"2dfzXuxZ\" ]\n\t\t\t\t\t\t\tcVFpko4u = [ \"gGqdEB6k\", \"9LsRo22u\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"X5DrovFc\"\n\t\t\t\t\t\tbody = \"WeikigLh\"\n\t\t\t\t\t\ttcp = \"ICbxkpSF\"\n\t\t\t\t\t\tinterval = \"24392s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ZKXr68Yb\"\n\t\t\t\t\t\tshell = \"CEfzx0Fo\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38333s\"\n\t\t\t\t\t\tttl = \"57201s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"44214s\"\n\t\t\t\t\t}\n\t\t\t\t\tconnect {\n\t\t\t\t\t\tsidecar_service {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"MRHVMZuD\"\n\t\t\t\t\tname = \"6L6BVfgH\"\n\t\t\t\t\ttags = [\"7Ale4y6o\", \"PMBW08hy\"]\n\t\t\t\t\taddress = \"R6H6g8h0\"\n\t\t\t\t\ttoken = \"ZgY8gjMI\"\n\t\t\t\t\tport = 38292\n\t\t\t\t\tweights = {\n\t\t\t\t\t\tpassing = 1979,\n\t\t\t\t\t\twarning = 6\n\t\t\t\t\t}\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tchecks = [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"GTti9hCo\"\n\t\t\t\t\t\t\tname = \"9OOS93ne\"\n\t\t\t\t\t\t\tnotes = \"CQy86DH0\"\n\t\t\t\t\t\t\tstatus = \"P0SWDvrk\"\n\t\t\t\t\t\t\targs = [\"EXvkYIuG\", \"BATOyt6h\"]\n\t\t\t\t\t\t\thttp = \"u97ByEiW\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"MUlReo8L\" = [ \"AUZG7wHG\", \"gsN0Dc2N\" ]\n\t\t\t\t\t\t\t\t\"1UJXjVrT\" = [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"5wkAxCUE\"\n\t\t\t\t\t\t\tbody = \"7CRjCJyz\"\n\t\t\t\t\t\t\ttcp = \"MN3oA9D2\"\n\t\t\t\t\t\t\tinterval = \"32718s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"cU15LMet\"\n\t\t\t\t\t\t\tshell = \"nEz9qz2l\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"34738s\"\n\t\t\t\t\t\t\tttl = \"22773s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"UHsDeLxG\"\n\t\t\t\t\t\t\tname = \"PQSaPWlT\"\n\t\t\t\t\t\t\tnotes = \"jKChDOdl\"\n\t\t\t\t\t\t\tstatus = \"5qFz6OZn\"\n\t\t\t\t\t\t\targs = [\"NMtYWlT9\", \"vj74JXsm\"]\n\t\t\t\t\t\t\thttp = \"1LBDJhw4\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\" = [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\" = [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"wzByP903\"\n\t\t\t\t\t\t\tbody = \"4I8ucZgZ\"\n\t\t\t\t\t\t\ttcp = \"2exjZIGE\"\n\t\t\t\t\t\t\tinterval = \"5656s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"5tDBWpfA\"\n\t\t\t\t\t\t\tshell = \"rlTpLM8s\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"4868s\"\n\t\t\t\t\t\t\tttl = \"11222s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t\tconnect {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Kh81CPF6\"\n\t\t\t\t\tname = \"Kh81CPF6-proxy\"\n\t\t\t\t\tport = 31471\n\t\t\t\t\tkind = \"connect-proxy\"\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tdestination_service_name = \"6L6BVfgH\"\n\t\t\t\t\t\tdestination_service_id = \"6L6BVfgH-id\"\n\t\t\t\t\t\tlocal_service_address = \"127.0.0.2\"\n\t\t\t\t\t\tlocal_service_port = 23759\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\tcedGGtZf = \"pWrUNiWw\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tupstreams = [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_name = \"KPtAj2cb\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 4051\n\t\t\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\t\tkzRnZOyd = \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_type = \"prepared_query\"\n\t\t\t\t\t\t\t\tdestination_namespace = \"9nakw0td\"\n\t\t\t\t\t\t\t\tdestination_name = \"KSd8HsRl\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 11884\n\t\t\t\t\t\t\t\tlocal_bind_address = \"127.24.88.0\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t]\n\t\t\t\t\t\texpose {\n\t\t\t\t\t\t\tchecks = true\n\t\t\t\t\t\t\tpaths = [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tpath = \"/health\"\n\t\t\t\t\t\t\t\t\tlocal_path_port = 8080\n\t\t\t\t\t\t\t\t\tlistener_port = 21500\n\t\t\t\t\t\t\t\t\tprotocol = \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"kvVqbwSE\"\n\t\t\t\t\tkind = \"mesh-gateway\"\n\t\t\t\t\tname = \"gw-primary-dc\"\n\t\t\t\t\tport = 27147\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\"1CuJHVfw\" = \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t\tsession_ttl_min = \"26627s\"\n\t\t\tskip_leave_on_interrupt = true\n\t\t\tstart_join = [ \"LR3hGDoG\", \"MwVpZ4Up\" ]\n\t\t\tstart_join_wan = [ \"EbFSc3nA\", \"kwXTh623\" ]\n\t\t\tsyslog_facility = \"hHv79Uia\"\n\t\t\ttagged_addresses = {\n\t\t\t\t\"7MYgHrYH\" = \"dALJAhLD\"\n\t\t\t\t\"h6DdBy6K\" = \"ebrr9zZ8\"\n\t\t\t}\n\t\t\ttelemetry {\n\t\t\t\tcirconus_api_app = \"p4QOTe9j\"\n\t\t\t\tcirconus_api_token = \"E3j35V23\"\n\t\t\t\tcirconus_api_url = \"mEMjHpGg\"\n\t\t\t\tcirconus_broker_id = \"BHlxUhed\"\n\t\t\t\tcirconus_broker_select_tag = \"13xy1gHm\"\n\t\t\t\tcirconus_check_display_name = \"DRSlQR6n\"\n\t\t\t\tcirconus_check_force_metric_activation = \"Ua5FGVYf\"\n\t\t\t\tcirconus_check_id = \"kGorutad\"\n\t\t\t\tcirconus_check_instance_id = \"rwoOL6R4\"\n\t\t\t\tcirconus_check_search_tag = \"ovT4hT4f\"\n\t\t\t\tcirconus_check_tags = \"prvO4uBl\"\n\t\t\t\tcirconus_submission_interval = \"DolzaflP\"\n\t\t\t\tcirconus_submission_url = \"gTcbS93G\"\n\t\t\t\tdisable_hostname = true\n\t\t\t\tdogstatsd_addr = \"0wSndumK\"\n\t\t\t\tdogstatsd_tags = [ \"3N81zSUB\",\"Xtj8AnXZ\" ]\n\t\t\t\tfilter_default = true\n\t\t\t\tprefix_filter = [ \"+oJotS8XJ\",\"-cazlEhGn\" ]\n\t\t\t\tmetrics_prefix = \"ftO6DySn\"\n\t\t\t\tprometheus_retention_time = \"15s\"\n\t\t\t\tstatsd_address = \"drce87cy\"\n\t\t\t\tstatsite_address = \"HpFwKB8R\"\n\t\t\t}\n\t\t\ttls_cipher_suites = \"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256\"\n\t\t\ttls_min_version = \"pAOWafkR\"\n\t\t\ttls_prefer_server_cipher_suites = true\n\t\t\ttranslate_wan_addrs = true\n\t\t\tui = true\n\t\t\tui_dir = \"11IFzAUn\"\n\t\t\tui_content_path = \"consul\"\n\t\t\tunix_sockets = {\n\t\t\t\tgroup = \"8pFodrV8\"\n\t\t\t\tmode = \"E8sAwOv4\"\n\t\t\t\tuser = \"E0nB1DwA\"\n\t\t\t}\n\t\t\tverify_incoming = true\n\t\t\tverify_incoming_https = true\n\t\t\tverify_incoming_rpc = true\n\t\t\tverify_outgoing = true\n\t\t\tverify_server_hostname = true\n\t\t\twatches = [{\n\t\t\t\ttype = \"key\"\n\t\t\t\tdatacenter = \"GyE6jpeW\"\n\t\t\t\tkey = \"j9lF1Tve\"\n\t\t\t\thandler = \"90N7S4LN\"\n\t\t\t}, {\n\t\t\t\ttype = \"keyprefix\"\n\t\t\t\tdatacenter = \"fYrl3F5d\"\n\t\t\t\tkey = \"sl3Dffu7\"\n\t\t\t\targs = [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t}]\n\t\t`}\n\n\ttail := map[string][]Source{\n\t\t\"json\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"acl_disabled_ttl\": \"957s\",\n\t\t\t\t\t\"acl\" : {\n\t\t\t\t\t\t\"disabled_ttl\" : \"957s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"ae_interval\": \"10003s\",\n\t\t\t\t\t\"check_deregister_interval_min\": \"27870s\",\n\t\t\t\t\t\"check_reap_interval\": \"10662s\",\n\t\t\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\t\t\"segment_limit\": 24705,\n\t\t\t\t\t\"segment_name_limit\": 27046,\n\t\t\t\t\t\"sync_coordinate_interval_min\": \"27983s\",\n\t\t\t\t\t\"sync_coordinate_rate_target\": 137.81\n\t\t\t\t}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"consul\": {\n\t\t\t\t\t\t\"coordinate\": {\n\t\t\t\t\t\t\t\"update_batch_size\": 9244,\n\t\t\t\t\t\t\t\"update_max_batches\": 15164,\n\t\t\t\t\t\t\t\"update_period\": \"25093s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"raft\": {\n\t\t\t\t\t\t\t\"election_timeout\": \"31947s\",\n\t\t\t\t\t\t\t\"heartbeat_timeout\": \"25699s\",\n\t\t\t\t\t\t\t\"leader_lease_timeout\": \"15351s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"server\": {\n\t\t\t\t\t\t\t\"health_interval\": \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}`,\n\t\t\t},\n\t\t},\n\t\t\"hcl\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tacl_disabled_ttl = \"957s\"\n\t\t\t\t\tacl = {\n\t\t\t\t\t\tdisabled_ttl = \"957s\"\n\t\t\t\t\t}\n\t\t\t\t\tae_interval = \"10003s\"\n\t\t\t\t\tcheck_deregister_interval_min = \"27870s\"\n\t\t\t\t\tcheck_reap_interval = \"10662s\"\n\t\t\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\t\t\tsegment_limit = 24705\n\t\t\t\t\tsegment_name_limit = 27046\n\t\t\t\t\tsync_coordinate_interval_min = \"27983s\"\n\t\t\t\t\tsync_coordinate_rate_target = 137.81\n\t\t\t\t`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tconsul = {\n\t\t\t\t\t\tcoordinate = {\n\t\t\t\t\t\t\tupdate_batch_size = 9244\n\t\t\t\t\t\t\tupdate_max_batches = 15164\n\t\t\t\t\t\t\tupdate_period = \"25093s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\traft = {\n\t\t\t\t\t\t\telection_timeout = \"31947s\"\n\t\t\t\t\t\t\theartbeat_timeout = \"25699s\"\n\t\t\t\t\t\t\tleader_lease_timeout = \"15351s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tserver = {\n\t\t\t\t\t\t\thealth_interval = \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t`,\n\t\t\t},\n\t\t},\n\t}\n\n\twant := RuntimeConfig{\n\t\t// non-user configurable values\n\t\tACLDisabledTTL:             957 * time.Second,\n\t\tAEInterval:                 10003 * time.Second,\n\t\tCheckDeregisterIntervalMin: 27870 * time.Second,\n\t\tCheckReapInterval:          10662 * time.Second,\n\t\tSegmentLimit:               24705,\n\t\tSegmentNameLimit:           27046,\n\t\tSyncCoordinateIntervalMin:  27983 * time.Second,\n\t\tSyncCoordinateRateTarget:   137.81,\n\n\t\tRevision:          \"JNtPSav3\",\n\t\tVersion:           \"R909Hblt\",\n\t\tVersionPrerelease: \"ZT1JOQLn\",\n\n\t\t// consul configuration\n\t\tConsulCoordinateUpdateBatchSize:  9244,\n\t\tConsulCoordinateUpdateMaxBatches: 15164,\n\t\tConsulCoordinateUpdatePeriod:     25093 * time.Second,\n\t\tConsulRaftElectionTimeout:        5 * 31947 * time.Second,\n\t\tConsulRaftHeartbeatTimeout:       5 * 25699 * time.Second,\n\t\tConsulRaftLeaderLeaseTimeout:     5 * 15351 * time.Second,\n\t\tGossipLANGossipInterval:          25252 * time.Second,\n\t\tGossipLANGossipNodes:             6,\n\t\tGossipLANProbeInterval:           101 * time.Millisecond,\n\t\tGossipLANProbeTimeout:            102 * time.Millisecond,\n\t\tGossipLANSuspicionMult:           1235,\n\t\tGossipLANRetransmitMult:          1234,\n\t\tGossipWANGossipInterval:          6966 * time.Second,\n\t\tGossipWANGossipNodes:             2,\n\t\tGossipWANProbeInterval:           103 * time.Millisecond,\n\t\tGossipWANProbeTimeout:            104 * time.Millisecond,\n\t\tGossipWANSuspicionMult:           16385,\n\t\tGossipWANRetransmitMult:          16384,\n\t\tConsulServerHealthInterval:       17455 * time.Second,\n\n\t\t// user configurable values\n\n\t\tACLAgentMasterToken:              \"64fd0e08\",\n\t\tACLAgentToken:                    \"bed2377c\",\n\t\tACLsEnabled:                      true,\n\t\tACLDatacenter:                    \"ejtmd43d\",\n\t\tACLDefaultPolicy:                 \"72c2e7a0\",\n\t\tACLDownPolicy:                    \"03eb2aee\",\n\t\tACLEnableKeyListPolicy:           true,\n\t\tACLEnableTokenPersistence:        true,\n\t\tACLMasterToken:                   \"8a19ac27\",\n\t\tACLReplicationToken:              \"5795983a\",\n\t\tACLTokenTTL:                      3321 * time.Second,\n\t\tACLPolicyTTL:                     1123 * time.Second,\n\t\tACLRoleTTL:                       9876 * time.Second,\n\t\tACLToken:                         \"418fdff1\",\n\t\tACLTokenReplication:              true,\n\t\tAdvertiseAddrLAN:                 ipAddr(\"17.99.29.16\"),\n\t\tAdvertiseAddrWAN:                 ipAddr(\"78.63.37.19\"),\n\t\tAutopilotCleanupDeadServers:      true,\n\t\tAutopilotDisableUpgradeMigration: true,\n\t\tAutopilotLastContactThreshold:    12705 * time.Second,\n\t\tAutopilotMaxTrailingLogs:         17849,\n\t\tAutopilotMinQuorum:               3,\n\t\tAutopilotRedundancyZoneTag:       \"3IsufDJf\",\n\t\tAutopilotServerStabilizationTime: 23057 * time.Second,\n\t\tAutopilotUpgradeVersionTag:       \"W9pDwFAL\",\n\t\tBindAddr:                         ipAddr(\"16.99.34.17\"),\n\t\tBootstrap:                        true,\n\t\tBootstrapExpect:                  53,\n\t\tCAFile:                           \"erA7T0PM\",\n\t\tCAPath:                           \"mQEN1Mfp\",\n\t\tCertFile:                         \"7s4QAzDk\",\n\t\tCheckOutputMaxSize:               checks.DefaultBufSize,\n\t\tChecks: []*structs.CheckDefinition{\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"uAjE6m9Z\",\n\t\t\t\tName:       \"QsZRGpYr\",\n\t\t\t\tNotes:      \"VJ7Sk4BY\",\n\t\t\t\tServiceID:  \"lSulPcyz\",\n\t\t\t\tToken:      \"toO59sh8\",\n\t\t\t\tStatus:     \"9RlWsXMV\",\n\t\t\t\tScriptArgs: []string{\"4BAJttck\", \"4D2NPtTQ\"},\n\t\t\t\tHTTP:       \"dohLcyQ2\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"ZBfTin3L\": []string{\"1sDbEqYG\", \"lJGASsWK\"},\n\t\t\t\t\t\"Ui0nU99X\": []string{\"LMccm3Qe\", \"k5H5RggQ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"aldrIQ4l\",\n\t\t\t\tBody:                           \"wSjTy7dg\",\n\t\t\t\tTCP:                            \"RJQND605\",\n\t\t\t\tInterval:                       22164 * time.Second,\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\tShell:                          \"qAeOYy0M\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        1813 * time.Second,\n\t\t\t\tTTL:                            21743 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 14232 * time.Second,\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"Cqq95BhP\",\n\t\t\t\tName:       \"3qXpkS0i\",\n\t\t\t\tNotes:      \"sb5qLTex\",\n\t\t\t\tServiceID:  \"CmUUcRna\",\n\t\t\t\tToken:      \"a3nQzHuy\",\n\t\t\t\tStatus:     \"irj26nf3\",\n\t\t\t\tScriptArgs: []string{\"9s526ogY\", \"gSlOHj1w\"},\n\t\t\t\tHTTP:       \"yzhgsQ7Y\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"zcqwA8dO\": []string{\"qb1zx0DL\", \"sXCxPFsD\"},\n\t\t\t\t\t\"qxvdnSE9\": []string{\"6wBPUYdF\", \"YYh8wtSZ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"gLrztrNw\",\n\t\t\t\tBody:                           \"0jkKgGUC\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"4jG5casb\",\n\t\t\t\tInterval:                       28767 * time.Second,\n\t\t\t\tDockerContainerID:              \"THW6u7rL\",\n\t\t\t\tShell:                          \"C1Zt3Zwh\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        18506 * time.Second,\n\t\t\t\tTTL:                            31006 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 2366 * time.Second,\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"fZaCAXww\",\n\t\t\t\tName:       \"OOM2eo0f\",\n\t\t\t\tNotes:      \"zXzXI9Gt\",\n\t\t\t\tServiceID:  \"L8G0QNmR\",\n\t\t\t\tToken:      \"oo4BCTgJ\",\n\t\t\t\tStatus:     \"qLykAl5u\",\n\t\t\t\tScriptArgs: []string{\"f3BemRjy\", \"e5zgpef7\"},\n\t\t\t\tHTTP:       \"29B93haH\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"hBq0zn1q\": {\"2a9o9ZKP\", \"vKwA5lR6\"},\n\t\t\t\t\t\"f3r6xFtM\": {\"RyuIdDWv\", \"QbxEcIUM\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"Dou0nGT5\",\n\t\t\t\tBody:                           \"5PBQd2OT\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"JY6fTTcw\",\n\t\t\t\tInterval:                       18714 * time.Second,\n\t\t\t\tDockerContainerID:              \"qF66POS9\",\n\t\t\t\tShell:                          \"sOnDy228\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        5954 * time.Second,\n\t\t\t\tTTL:                            30044 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 13209 * time.Second,\n\t\t\t},\n\t\t},\n\t\tCheckUpdateInterval: 16507 * time.Second,\n\t\tClientAddrs:         []*net.IPAddr{ipAddr(\"93.83.18.19\")},\n\t\tConfigEntryBootstrap: []structs.ConfigEntry{\n\t\t\t&structs.ProxyConfigEntry{\n\t\t\t\tKind: structs.ProxyDefaults,\n\t\t\t\tName: structs.ProxyConfigGlobal,\n\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t// has to be a float due to being a map[string]interface\n\t\t\t\t\t\"bar\": float64(1),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tAutoEncryptTLS:        false,\n\t\tAutoEncryptDNSSAN:     []string{\"a.com\", \"b.com\"},\n\t\tAutoEncryptIPSAN:      []net.IP{net.ParseIP(\"192.168.4.139\"), net.ParseIP(\"192.168.4.140\")},\n\t\tAutoEncryptAllowTLS:   true,\n\t\tConnectEnabled:        true,\n\t\tConnectSidecarMinPort: 8888,\n\t\tConnectSidecarMaxPort: 9999,\n\t\tExposeMinPort:         1111,\n\t\tExposeMaxPort:         2222,\n\t\tConnectCAProvider:     \"consul\",\n\t\tConnectCAConfig: map[string]interface{}{\n\t\t\t\"RotationPeriod\":      \"90h\",\n\t\t\t\"IntermediateCertTTL\": \"8760h\",\n\t\t\t\"LeafCertTTL\":         \"1h\",\n\t\t\t\"CSRMaxPerSecond\":     float64(100),\n\t\t\t\"CSRMaxConcurrent\":    float64(2),\n\t\t},\n\t\tConnectMeshGatewayWANFederationEnabled: false,\n\t\tDNSAddrs:                               []net.Addr{tcpAddr(\"93.95.95.81:7001\"), udpAddr(\"93.95.95.81:7001\")},\n\t\tDNSARecordLimit:                        29907,\n\t\tDNSAllowStale:                          true,\n\t\tDNSDisableCompression:                  true,\n\t\tDNSDomain:                              \"7W1xXSqd\",\n\t\tDNSAltDomain:                           \"1789hsd\",\n\t\tDNSEnableTruncate:                      true,\n\t\tDNSMaxStale:                            29685 * time.Second,\n\t\tDNSNodeTTL:                             7084 * time.Second,\n\t\tDNSOnlyPassing:                         true,\n\t\tDNSPort:                                7001,\n\t\tDNSRecursorTimeout:                     4427 * time.Second,\n\t\tDNSRecursors:                           []string{\"63.38.39.58\", \"92.49.18.18\"},\n\t\tDNSSOA:                                 RuntimeSOAConfig{Refresh: 3600, Retry: 600, Expire: 86400, Minttl: 0},\n\t\tDNSServiceTTL:                          map[string]time.Duration{\"*\": 32030 * time.Second},\n\t\tDNSUDPAnswerLimit:                      29909,\n\t\tDNSNodeMetaTXT:                         true,\n\t\tDNSUseCache:                            true,\n\t\tDNSCacheMaxAge:                         5 * time.Minute,\n\t\tDataDir:                                dataDir,\n\t\tDatacenter:                             \"rzo029wg\",\n\t\tDefaultQueryTime:                       16743 * time.Second,\n\t\tDevMode:                                true,\n\t\tDisableAnonymousSignature:              true,\n\t\tDisableCoordinates:                     true,\n\t\tDisableHostNodeID:                      true,\n\t\tDisableHTTPUnprintableCharFilter:       true,\n\t\tDisableKeyringFile:                     true,\n\t\tDisableRemoteExec:                      true,\n\t\tDisableUpdateCheck:                     true,\n\t\tDiscardCheckOutput:                     true,\n\t\tDiscoveryMaxStale:                      5 * time.Second,\n\t\tEnableAgentTLSForChecks:                true,\n\t\tEnableCentralServiceConfig:             true,\n\t\tEnableDebug:                            true,\n\t\tEnableRemoteScriptChecks:               true,\n\t\tEnableLocalScriptChecks:                true,\n\t\tEnableSyslog:                           true,\n\t\tEnableUI:                               true,\n\t\tEncryptKey:                             \"A4wELWqH\",\n\t\tEncryptVerifyIncoming:                  true,\n\t\tEncryptVerifyOutgoing:                  true,\n\t\tGRPCPort:                               4881,\n\t\tGRPCAddrs:                              []net.Addr{tcpAddr(\"32.31.61.91:4881\")},\n\t\tHTTPAddrs:                              []net.Addr{tcpAddr(\"83.39.91.39:7999\")},\n\t\tHTTPBlockEndpoints:                     []string{\"RBvAFcGD\", \"fWOWFznh\"},\n\t\tAllowWriteHTTPFrom:                     []*net.IPNet{cidr(\"127.0.0.0/8\"), cidr(\"22.33.44.55/32\"), cidr(\"0.0.0.0/0\")},\n\t\tHTTPPort:                               7999,\n\t\tHTTPResponseHeaders:                    map[string]string{\"M6TKa9NP\": \"xjuxjOzQ\", \"JRCrHZed\": \"rl0mTx81\"},\n\t\tHTTPSAddrs:                             []net.Addr{tcpAddr(\"95.17.17.19:15127\")},\n\t\tHTTPMaxConnsPerClient:                  100,\n\t\tHTTPSHandshakeTimeout:                  2391 * time.Millisecond,\n\t\tHTTPSPort:                              15127,\n\t\tHTTPUseCache:                           false,\n\t\tKeyFile:                                \"IEkkwgIA\",\n\t\tKVMaxValueSize:                         1234567800000000,\n\t\tLeaveDrainTime:                         8265 * time.Second,\n\t\tLeaveOnTerm:                            true,\n\t\tLogLevel:                               \"k1zo9Spt\",\n\t\tLogJSON:                                true,\n\t\tMaxQueryTime:                           18237 * time.Second,\n\t\tNodeID:                                 types.NodeID(\"AsUIlw99\"),\n\t\tNodeMeta:                               map[string]string{\"5mgGQMBk\": \"mJLtVMSG\", \"A7ynFMJB\": \"0Nx6RGab\"},\n\t\tNodeName:                               \"otlLxGaI\",\n\t\tNonVotingServer:                        true,\n\t\tPidFile:                                \"43xN80Km\",\n\t\tPrimaryDatacenter:                      \"ejtmd43d\",\n\t\tPrimaryGateways:                        []string{\"aej8eeZo\", \"roh2KahS\"},\n\t\tPrimaryGatewaysInterval:                18866 * time.Second,\n\t\tRPCAdvertiseAddr:                       tcpAddr(\"17.99.29.16:3757\"),\n\t\tRPCBindAddr:                            tcpAddr(\"16.99.34.17:3757\"),\n\t\tRPCHandshakeTimeout:                    1932 * time.Millisecond,\n\t\tRPCHoldTimeout:                         15707 * time.Second,\n\t\tRPCProtocol:                            30793,\n\t\tRPCRateLimit:                           12029.43,\n\t\tRPCMaxBurst:                            44848,\n\t\tRPCMaxConnsPerClient:                   2954,\n\t\tRaftProtocol:                           19016,\n\t\tRaftSnapshotThreshold:                  16384,\n\t\tRaftSnapshotInterval:                   30 * time.Second,\n\t\tRaftTrailingLogs:                       83749,\n\t\tReconnectTimeoutLAN:                    23739 * time.Second,\n\t\tReconnectTimeoutWAN:                    26694 * time.Second,\n\t\tRejoinAfterLeave:                       true,\n\t\tRetryJoinIntervalLAN:                   8067 * time.Second,\n\t\tRetryJoinIntervalWAN:                   28866 * time.Second,\n\t\tRetryJoinLAN:                           []string{\"pbsSFY7U\", \"l0qLtWij\"},\n\t\tRetryJoinMaxAttemptsLAN:                913,\n\t\tRetryJoinMaxAttemptsWAN:                23160,\n\t\tRetryJoinWAN:                           []string{\"PFsR02Ye\", \"rJdQIhER\"},\n\t\tSegmentName:                            \"BC2NhTDi\",\n\t\tSegments: []structs.NetworkSegment{\n\t\t\t{\n\t\t\t\tName:        \"PExYMe2E\",\n\t\t\t\tBind:        tcpAddr(\"36.73.36.19:38295\"),\n\t\t\t\tAdvertise:   tcpAddr(\"63.39.19.18:38295\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:        \"UzCvJgup\",\n\t\t\t\tBind:        tcpAddr(\"37.58.38.19:39292\"),\n\t\t\t\tAdvertise:   tcpAddr(\"83.58.26.27:39292\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t},\n\t\tSerfPortLAN: 8301,\n\t\tSerfPortWAN: 8302,\n\t\tServerMode:  true,\n\t\tServerName:  \"Oerr9n1G\",\n\t\tServerPort:  3757,\n\t\tServices: []*structs.ServiceDefinition{\n\t\t\t{\n\t\t\t\tID:      \"wI1dzxS4\",\n\t\t\t\tName:    \"7IszXMQ1\",\n\t\t\t\tTags:    []string{\"0Zwg8l6v\", \"zebELdN5\"},\n\t\t\t\tAddress: \"9RhqPSPB\",\n\t\t\t\tToken:   \"myjKJkWH\",\n\t\t\t\tPort:    72219,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: []*structs.CheckType{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"qmfeO5if\",\n\t\t\t\t\t\tName:       \"atDGP7n5\",\n\t\t\t\t\t\tStatus:     \"pDQKEhWL\",\n\t\t\t\t\t\tNotes:      \"Yt8EDLev\",\n\t\t\t\t\t\tScriptArgs: []string{\"81EDZLPa\", \"bPY5X8xd\"},\n\t\t\t\t\t\tHTTP:       \"qzHYvmJO\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"UkpmZ3a3\": {\"2dfzXuxZ\"},\n\t\t\t\t\t\t\t\"cVFpko4u\": {\"gGqdEB6k\", \"9LsRo22u\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"X5DrovFc\",\n\t\t\t\t\t\tBody:                           \"WeikigLh\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"ICbxkpSF\",\n\t\t\t\t\t\tInterval:                       24392 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ZKXr68Yb\",\n\t\t\t\t\t\tShell:                          \"CEfzx0Fo\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38333 * time.Second,\n\t\t\t\t\t\tTTL:                            57201 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 44214 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t// Note that although this SidecarService is only syntax sugar for\n\t\t\t\t// registering another service, that has to happen in the agent code so\n\t\t\t\t// it can make intelligent decisions about automatic port assignments\n\t\t\t\t// etc. So we expect config just to pass it through verbatim.\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tSidecarService: &structs.ServiceDefinition{\n\t\t\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\t\t\tPassing: 1,\n\t\t\t\t\t\t\tWarning: 1,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:      \"MRHVMZuD\",\n\t\t\t\tName:    \"6L6BVfgH\",\n\t\t\t\tTags:    []string{\"7Ale4y6o\", \"PMBW08hy\"},\n\t\t\t\tAddress: \"R6H6g8h0\",\n\t\t\t\tToken:   \"ZgY8gjMI\",\n\t\t\t\tPort:    38292,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1979,\n\t\t\t\t\tWarning: 6,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"GTti9hCo\",\n\t\t\t\t\t\tName:       \"9OOS93ne\",\n\t\t\t\t\t\tNotes:      \"CQy86DH0\",\n\t\t\t\t\t\tStatus:     \"P0SWDvrk\",\n\t\t\t\t\t\tScriptArgs: []string{\"EXvkYIuG\", \"BATOyt6h\"},\n\t\t\t\t\t\tHTTP:       \"u97ByEiW\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"MUlReo8L\": {\"AUZG7wHG\", \"gsN0Dc2N\"},\n\t\t\t\t\t\t\t\"1UJXjVrT\": {\"OJgxzTfk\", \"xZZrFsq7\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"5wkAxCUE\",\n\t\t\t\t\t\tBody:                           \"7CRjCJyz\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"MN3oA9D2\",\n\t\t\t\t\t\tInterval:                       32718 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"cU15LMet\",\n\t\t\t\t\t\tShell:                          \"nEz9qz2l\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        34738 * time.Second,\n\t\t\t\t\t\tTTL:                            22773 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 84282 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"UHsDeLxG\",\n\t\t\t\t\t\tName:       \"PQSaPWlT\",\n\t\t\t\t\t\tNotes:      \"jKChDOdl\",\n\t\t\t\t\t\tStatus:     \"5qFz6OZn\",\n\t\t\t\t\t\tScriptArgs: []string{\"NMtYWlT9\", \"vj74JXsm\"},\n\t\t\t\t\t\tHTTP:       \"1LBDJhw4\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"cXPmnv1M\": {\"imDqfaBx\", \"NFxZ1bQe\"},\n\t\t\t\t\t\t\t\"vr7wY7CS\": {\"EtCoNPPL\", \"9vAarJ5s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"wzByP903\",\n\t\t\t\t\t\tBody:                           \"4I8ucZgZ\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"2exjZIGE\",\n\t\t\t\t\t\tInterval:                       5656 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"5tDBWpfA\",\n\t\t\t\t\t\tShell:                          \"rlTpLM8s\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        4868 * time.Second,\n\t\t\t\t\t\tTTL:                            11222 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tConnect: &structs.ServiceConnect{},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"Kh81CPF6\",\n\t\t\t\tName: \"Kh81CPF6-proxy\",\n\t\t\t\tPort: 31471,\n\t\t\t\tKind: \"connect-proxy\",\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tDestinationServiceName: \"6L6BVfgH\",\n\t\t\t\t\tDestinationServiceID:   \"6L6BVfgH-id\",\n\t\t\t\t\tLocalServiceAddress:    \"127.0.0.2\",\n\t\t\t\t\tLocalServicePort:       23759,\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\",\n\t\t\t\t\t},\n\t\t\t\t\tUpstreams: structs.Upstreams{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType: \"service\", // Default should be explicitly filled\n\t\t\t\t\t\t\tDestinationName: \"KPtAj2cb\",\n\t\t\t\t\t\t\tLocalBindPort:   4051,\n\t\t\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType:      \"prepared_query\",\n\t\t\t\t\t\t\tDestinationNamespace: \"9nakw0td\",\n\t\t\t\t\t\t\tDestinationName:      \"KSd8HsRl\",\n\t\t\t\t\t\t\tLocalBindPort:        11884,\n\t\t\t\t\t\t\tLocalBindAddress:     \"127.24.88.0\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tExpose: structs.ExposeConfig{\n\t\t\t\t\t\tChecks: true,\n\t\t\t\t\t\tPaths: []structs.ExposePath{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tPath:          \"/health\",\n\t\t\t\t\t\t\t\tLocalPathPort: 8080,\n\t\t\t\t\t\t\t\tListenerPort:  21500,\n\t\t\t\t\t\t\t\tProtocol:      \"http\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"kvVqbwSE\",\n\t\t\t\tKind: \"mesh-gateway\",\n\t\t\t\tName: \"gw-primary-dc\",\n\t\t\t\tPort: 27147,\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"1CuJHVfw\": \"Kzqsa7yc\",\n\t\t\t\t\t},\n\t\t\t\t\tUpstreams: structs.Upstreams{},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"dLOXpSCI\",\n\t\t\t\tName: \"o1ynPkp0\",\n\t\t\t\tTaggedAddresses: map[string]structs.ServiceAddress{\n\t\t\t\t\t\"lan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"2d79888a\",\n\t\t\t\t\t\tPort:    2143,\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"d4db85e2\",\n\t\t\t\t\t\tPort:    6109,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tTags:    []string{\"nkwshvM5\", \"NTDWn3ek\"},\n\t\t\t\tAddress: \"cOlSOhbp\",\n\t\t\t\tToken:   \"msy7iWER\",\n\t\t\t\tMeta:    map[string]string{\"mymeta\": \"data\"},\n\t\t\t\tPort:    24237,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 100,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tNative: true,\n\t\t\t\t},\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"Zv99e9Ka\",\n\t\t\t\t\t\tName:       \"sgV4F7Pk\",\n\t\t\t\t\t\tNotes:      \"yP5nKbW0\",\n\t\t\t\t\t\tStatus:     \"7oLMEyfu\",\n\t\t\t\t\t\tScriptArgs: []string{\"5wEZtZpv\", \"0Ihyk8cS\"},\n\t\t\t\t\t\tHTTP:       \"KyDjGY9H\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"gv5qefTz\": {\"5Olo2pMG\", \"PvvKWQU5\"},\n\t\t\t\t\t\t\t\"SHOVq1Vv\": {\"jntFhyym\", \"GYJh32pp\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"T66MFBfR\",\n\t\t\t\t\t\tBody:                           \"OwGjTFQi\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"bNnNfx2A\",\n\t\t\t\t\t\tInterval:                       22224 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\t\t\tShell:                          \"omVZq7Sz\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        18913 * time.Second,\n\t\t\t\t\t\tTTL:                            44743 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 8482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"G79O6Mpr\",\n\t\t\t\t\t\tName:       \"IEqrzrsd\",\n\t\t\t\t\t\tNotes:      \"SVqApqeM\",\n\t\t\t\t\t\tStatus:     \"XXkVoZXt\",\n\t\t\t\t\t\tScriptArgs: []string{\"wD05Bvao\", \"rLYB7kQC\"},\n\t\t\t\t\t\tHTTP:       \"kyICZsn8\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"4ebP5vL4\": {\"G20SrL5Q\", \"DwPKlMbo\"},\n\t\t\t\t\t\t\t\"p2UI34Qz\": {\"UsG1D0Qh\", \"NHhRiB6s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"ciYHWors\",\n\t\t\t\t\t\tBody:                           \"lUVLGYU7\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"FfvCwlqH\",\n\t\t\t\t\t\tInterval:                       12356 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"HBndBU6R\",\n\t\t\t\t\t\tShell:                          \"hVI33JjA\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38282 * time.Second,\n\t\t\t\t\t\tTTL:                            1181 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 4992 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"RMi85Dv8\",\n\t\t\t\t\t\tName:       \"iehanzuq\",\n\t\t\t\t\t\tStatus:     \"rCvn53TH\",\n\t\t\t\t\t\tNotes:      \"fti5lfF3\",\n\t\t\t\t\t\tScriptArgs: []string{\"16WRUmwS\", \"QWk7j7ae\"},\n\t\t\t\t\t\tHTTP:       \"dl3Fgme3\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"rjm4DEd3\": {\"2m3m2Fls\"},\n\t\t\t\t\t\t\t\"l4HwQ112\": {\"fk56MNlo\", \"dhLK56aZ\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"9afLm3Mj\",\n\t\t\t\t\t\tBody:                           \"wVVL2V6f\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"fjiLFqVd\",\n\t\t\t\t\t\tInterval:                       23926 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"dO5TtRHk\",\n\t\t\t\t\t\tShell:                          \"e6q2ttES\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38483 * time.Second,\n\t\t\t\t\t\tTTL:                            10943 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68787 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tSerfAdvertiseAddrLAN: tcpAddr(\"17.99.29.16:8301\"),\n\t\tSerfAdvertiseAddrWAN: tcpAddr(\"78.63.37.19:8302\"),\n\t\tSerfBindAddrLAN:      tcpAddr(\"99.43.63.15:8301\"),\n\t\tSerfBindAddrWAN:      tcpAddr(\"67.88.33.19:8302\"),\n\t\tSerfAllowedCIDRsLAN:  []net.IPNet{},\n\t\tSerfAllowedCIDRsWAN:  []net.IPNet{},\n\t\tSessionTTLMin:        26627 * time.Second,\n\t\tSkipLeaveOnInt:       true,\n\t\tStartJoinAddrsLAN:    []string{\"LR3hGDoG\", \"MwVpZ4Up\"},\n\t\tStartJoinAddrsWAN:    []string{\"EbFSc3nA\", \"kwXTh623\"},\n\t\tSyslogFacility:       \"hHv79Uia\",\n\t\tTelemetry: lib.TelemetryConfig{\n\t\t\tCirconusAPIApp:                     \"p4QOTe9j\",\n\t\t\tCirconusAPIToken:                   \"E3j35V23\",\n\t\t\tCirconusAPIURL:                     \"mEMjHpGg\",\n\t\t\tCirconusBrokerID:                   \"BHlxUhed\",\n\t\t\tCirconusBrokerSelectTag:            \"13xy1gHm\",\n\t\t\tCirconusCheckDisplayName:           \"DRSlQR6n\",\n\t\t\tCirconusCheckForceMetricActivation: \"Ua5FGVYf\",\n\t\t\tCirconusCheckID:                    \"kGorutad\",\n\t\t\tCirconusCheckInstanceID:            \"rwoOL6R4\",\n\t\t\tCirconusCheckSearchTag:             \"ovT4hT4f\",\n\t\t\tCirconusCheckTags:                  \"prvO4uBl\",\n\t\t\tCirconusSubmissionInterval:         \"DolzaflP\",\n\t\t\tCirconusSubmissionURL:              \"gTcbS93G\",\n\t\t\tDisableHostname:                    true,\n\t\t\tDogstatsdAddr:                      \"0wSndumK\",\n\t\t\tDogstatsdTags:                      []string{\"3N81zSUB\", \"Xtj8AnXZ\"},\n\t\t\tFilterDefault:                      true,\n\t\t\tAllowedPrefixes:                    []string{\"oJotS8XJ\"},\n\t\t\tBlockedPrefixes:                    []string{\"cazlEhGn\"},\n\t\t\tMetricsPrefix:                      \"ftO6DySn\",\n\t\t\tPrometheusRetentionTime:            15 * time.Second,\n\t\t\tStatsdAddr:                         \"drce87cy\",\n\t\t\tStatsiteAddr:                       \"HpFwKB8R\",\n\t\t},\n\t\tTLSCipherSuites:             []uint16{tls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, tls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256},\n\t\tTLSMinVersion:               \"pAOWafkR\",\n\t\tTLSPreferServerCipherSuites: true,\n\t\tTaggedAddresses: map[string]string{\n\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\",\n\t\t\t\"lan\":      \"17.99.29.16\",\n\t\t\t\"lan_ipv4\": \"17.99.29.16\",\n\t\t\t\"wan\":      \"78.63.37.19\",\n\t\t\t\"wan_ipv4\": \"78.63.37.19\",\n\t\t},\n\t\tTranslateWANAddrs:    true,\n\t\tTxnMaxReqLen:         5678000000000000,\n\t\tUIContentPath:        \"/consul/\",\n\t\tUIDir:                \"11IFzAUn\",\n\t\tUnixSocketUser:       \"E0nB1DwA\",\n\t\tUnixSocketGroup:      \"8pFodrV8\",\n\t\tUnixSocketMode:       \"E8sAwOv4\",\n\t\tVerifyIncoming:       true,\n\t\tVerifyIncomingHTTPS:  true,\n\t\tVerifyIncomingRPC:    true,\n\t\tVerifyOutgoing:       true,\n\t\tVerifyServerHostname: true,\n\t\tWatches: []map[string]interface{}{\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"key\",\n\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\"key\":        \"j9lF1Tve\",\n\t\t\t\t\"handler\":    \"90N7S4LN\",\n\t\t\t},\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"keyprefix\",\n\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\"key\":        \"sl3Dffu7\",\n\t\t\t\t\"args\":       []interface{}{\"dltjDJ2a\", \"flEa7C2d\"},\n\t\t\t},\n\t\t},\n\t\tEnterpriseRuntimeConfig: entFullRuntimeConfig,\n\t}\n\n\twarns := []string{\n\t\t`The 'acl_datacenter' field is deprecated. Use the 'primary_datacenter' field instead.`,\n\t\t`bootstrap_expect > 0: expecting 53 servers`,\n\t}\n\n\twarns = append(warns, enterpriseConfigKeyWarnings...)\n\n\t// ensure that all fields are set to unique non-zero values\n\t// todo(fs): This currently fails since ServiceDefinition.Check is not used\n\t// todo(fs): not sure on how to work around this. Possible options are:\n\t// todo(fs):  * move first check into the Check field\n\t// todo(fs):  * ignore the Check field\n\t// todo(fs): both feel like a hack\n\tif err := nonZero(\"RuntimeConfig\", nil, want); err != nil {\n\t\tt.Log(err)\n\t}\n\n\tfor format, data := range src {\n\t\tt.Run(format, func(t *testing.T) {\n\t\t\t// parse the flags since this is the only way we can set the\n\t\t\t// DevMode flag\n\t\t\tvar flags Flags\n\t\t\tfs := flag.NewFlagSet(\"\", flag.ContinueOnError)\n\t\t\tAddFlags(fs, &flags)\n\t\t\tif err := fs.Parse(flagSrc); err != nil {\n\t\t\t\tt.Fatalf(\"ParseFlags: %s\", err)\n\t\t\t}\n\n\t\t\t// ensure that all fields are set to unique non-zero values\n\t\t\t// if err := nonZero(\"Config\", nil, c); err != nil {\n\t\t\t// \tt.Fatal(err)\n\t\t\t// }\n\n\t\t\tb, err := NewBuilder(flags)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"NewBuilder: %s\", err)\n\t\t\t}\n\t\t\tb.Sources = append(b.Sources, Source{Name: \"full.\" + format, Data: data})\n\t\t\tb.Tail = append(b.Tail, tail[format]...)\n\t\t\tb.Tail = append(b.Tail, VersionSource(\"JNtPSav3\", \"R909Hblt\", \"ZT1JOQLn\"))\n\n\t\t\t// construct the runtime config\n\t\t\trt, err := b.Build()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Build: %s\", err)\n\t\t\t}\n\n\t\t\trequire.Equal(t, want, rt)\n\n\t\t\t// at this point we have confirmed that the parsing worked\n\t\t\t// for all fields but the validation will fail since certain\n\t\t\t// combinations are not allowed. Since it is not possible to have\n\t\t\t// all fields with non-zero values and to have a valid configuration\n\t\t\t// we are patching a handful of safe fields to make validation pass.\n\t\t\trt.Bootstrap = false\n\t\t\trt.DevMode = false\n\t\t\trt.EnableUI = false\n\t\t\trt.SegmentName = \"\"\n\t\t\trt.Segments = nil\n\n\t\t\t// validate the runtime config\n\t\t\tif err := b.Validate(rt); err != nil {\n\t\t\t\tt.Fatalf(\"Validate: %s\", err)\n\t\t\t}\n\n\t\t\t// check the warnings\n\t\t\trequire.ElementsMatch(t, warns, b.Warnings, \"Warnings: %v\", b.Warnings)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetTokenClaimsIfValid(tokenString string) (*IanaClaims, error) {\n\ttoken, err := jwt.ParseWithClaims(tokenString, &IanaClaims{}, func(token *jwt.Token) (interface{}, error) {\n\t\treturn []byte(Get().LoginToken.SigningKey), nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\treturn nil, fmt.Errorf(\"unexpected signing method: %s\", token.Header[\"alg\"])\n\t}\n\n\tif token.Valid {\n\t\tcfg := Get()\n\t\tclaims := token.Claims.(*IanaClaims)\n\n\t\tif claims.Issuer != AuthStrategyLoginIssuer && claims.Issuer != AuthStrategyOpenshiftIssuer && claims.Issuer != AuthStrategyTokenIssuer {\n\t\t\treturn nil, errors.New(\"token has invalid issuer (auth strategy)\")\n\t\t}\n\t\tif claims.Issuer == AuthStrategyLoginIssuer && cfg.Auth.Strategy != AuthStrategyLogin {\n\t\t\treturn nil, errors.New(\"token is invalid because of authentication strategy mismatch\")\n\t\t}\n\t\tif claims.Issuer == AuthStrategyOpenshiftIssuer && cfg.Auth.Strategy != AuthStrategyOpenshift {\n\t\t\treturn nil, errors.New(\"token is invalid because of authentication strategy mismatch\")\n\t\t}\n\t\tif claims.Issuer == AuthStrategyTokenIssuer && cfg.Auth.Strategy != AuthStrategyToken {\n\t\t\treturn nil, errors.New(\"token is invalid because of authentication strategy mismatch\")\n\t\t}\n\n\t\treturn token.Claims.(*IanaClaims), nil\n\t}\n\n\treturn nil, errors.New(\"invalid token\")\n}", "is_vulnerable": 1}
{"code": "func prepareBindMount(m *configs.Mount, rootfs string, mountFd *int) error {\n\tsource := m.Source\n\tif mountFd != nil {\n\t\tsource = \"/proc/self/fd/\" + strconv.Itoa(*mountFd)\n\t}\n\n\tstat, err := os.Stat(source)\n\tif err != nil {\n\t\t// error out if the source of a bind mount does not exist as we will be\n\t\t// unable to bind anything to it.\n\t\treturn err\n\t}\n\t// ensure that the destination of the bind mount is resolved of symlinks at mount time because\n\t// any previous mounts can invalidate the next mount's destination.\n\t// this can happen when a user specifies mounts within other mounts to cause breakouts or other\n\t// evil stuff to try to escape the container's rootfs.\n\tvar dest string\n\tif dest, err = securejoin.SecureJoin(rootfs, m.Destination); err != nil {\n\t\treturn err\n\t}\n\tif err := checkProcMount(rootfs, dest, m, source); err != nil {\n\t\treturn err\n\t}\n\tif err := createIfNotExists(dest, stat.IsDir()); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func fsFile(c Context, file string, filesystem fs.FS) error {\n\tf, err := filesystem.Open(file)\n\tif err != nil {\n\t\treturn ErrNotFound\n\t}\n\tdefer f.Close()\n\n\tfi, _ := f.Stat()\n\tif fi.IsDir() {\n\t\tfile = filepath.ToSlash(filepath.Join(file, indexPage)) // ToSlash is necessary for Windows. fs.Open and os.Open are different in that aspect.\n\t\tf, err = filesystem.Open(file)\n\t\tif err != nil {\n\t\t\treturn ErrNotFound\n\t\t}\n\t\tdefer f.Close()\n\t\tif fi, err = f.Stat(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tff, ok := f.(io.ReadSeeker)\n\tif !ok {\n\t\treturn errors.New(\"file does not implement io.ReadSeeker\")\n\t}\n\thttp.ServeContent(c.Response(), c.Request(), fi.Name(), fi.ModTime(), ff)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *KeyAgentTestSuite) TestHostCertVerification(c *check.C) {\n\t// Make a new local agent.\n\tkeystore, err := NewFSLocalKeyStore(s.keyDir)\n\tc.Assert(err, check.IsNil)\n\tlka, err := NewLocalAgent(keystore, s.hostname, s.username, AddKeysToAgentAuto)\n\tc.Assert(err, check.IsNil)\n\n\t// By default user has not refused any hosts.\n\tc.Assert(lka.UserRefusedHosts(), check.Equals, false)\n\n\t// Create a CA, generate a keypair for the CA, and add it to the known\n\t// hosts cache (done by \"tsh login\").\n\tkeygen := testauthority.New()\n\tcaPriv, caPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\tcaSigner, err := ssh.ParsePrivateKey(caPriv)\n\tc.Assert(err, check.IsNil)\n\tcaPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(caPub)\n\tc.Assert(err, check.IsNil)\n\terr = lka.keyStore.AddKnownHostKeys(\"example.com\", s.hostname, []ssh.PublicKey{caPublicKey})\n\tc.Assert(err, check.IsNil)\n\n\t// Generate a host certificate for node with role \"node\".\n\t_, hostPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\troles, err := types.ParseTeleportRoles(\"node\")\n\tc.Assert(err, check.IsNil)\n\thostCertBytes, err := keygen.GenerateHostCert(services.HostCertParams{\n\t\tCASigner:      caSigner,\n\t\tCASigningAlg:  defaults.CASignatureAlgorithm,\n\t\tPublicHostKey: hostPub,\n\t\tHostID:        \"5ff40d80-9007-4f28-8f49-7d4fda2f574d\",\n\t\tNodeName:      \"server01\",\n\t\tPrincipals: []string{\n\t\t\t\"127.0.0.1\",\n\t\t},\n\t\tClusterName: \"example.com\",\n\t\tRoles:       roles,\n\t\tTTL:         1 * time.Hour,\n\t})\n\tc.Assert(err, check.IsNil)\n\thostPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(hostCertBytes)\n\tc.Assert(err, check.IsNil)\n\n\ttests := []struct {\n\t\tinAddr   string\n\t\toutError bool\n\t}{\n\t\t// Correct DNS is valid.\n\t\t{\n\t\t\tinAddr:   \"server01.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Hostname only is valid.\n\t\t{\n\t\t\tinAddr:   \"server01:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// IP is valid.\n\t\t{\n\t\t\tinAddr:   \"127.0.0.1:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// UUID is valid.\n\t\t{\n\t\t\tinAddr:   \"5ff40d80-9007-4f28-8f49-7d4fda2f574d.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Wrong DNS name is invalid.\n\t\t{\n\t\t\tinAddr:   \"server02.example.com:3022\",\n\t\t\toutError: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\terr = lka.CheckHostSignature(tt.inAddr, nil, hostPublicKey)\n\t\tif tt.outError {\n\t\t\tc.Assert(err, check.NotNil)\n\t\t} else {\n\t\t\tc.Assert(err, check.IsNil)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (ec RuntimeConfig) EnvoyID() string {\n\tu := ec.Upstreams[ec.ServiceName]\n\treturn u.EnvoyID\n}", "is_vulnerable": 1}
{"code": "func (m *TaskExecutionManager) ListTaskExecutions(\n\tctx context.Context, request admin.TaskExecutionListRequest) (*admin.TaskExecutionList, error) {\n\tif err := validation.ValidateTaskExecutionListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListTaskExecutions request [%+v] is invalid: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getNodeExecutionContext(ctx, request.NodeExecutionId)\n\n\tidentifierFilters, err := util.GetNodeExecutionIdentifierFilters(ctx, *request.NodeExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfilters, err := util.AddRequestFilters(request.Filters, common.TaskExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTaskExecutions\", request.Token)\n\t}\n\n\toutput, err := m.db.TaskExecutionRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tOffset:        offset,\n\t\tLimit:         int(request.Limit),\n\t\tSortParameter: sortParameter,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list task executions with request [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\n\t// Use default transformer options so that error messages shown for task execution attempts in the console sidebar show the full error stack trace.\n\ttaskExecutionList, err := transformers.FromTaskExecutionModels(output.TaskExecutions, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform task execution models for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(taskExecutionList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskExecutionList))\n\t}\n\treturn &admin.TaskExecutionList{\n\t\tTaskExecutions: taskExecutionList,\n\t\tToken:          token,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeResponder) AddQuery(arg0, arg1 string) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"AddQuery\", arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleLock(w http.ResponseWriter, r *http.Request) (retStatus int, retErr error) {\n\tduration, err := parseTimeout(r.Header.Get(\"Timeout\"))\n\tif err != nil {\n\t\treturn http.StatusBadRequest, err\n\t}\n\tli, status, err := readLockInfo(r.Body)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\ttoken, ld, now, created := \"\", LockDetails{}, time.Now(), false\n\tif li == (lockInfo{}) {\n\t\t// An empty lockInfo means to refresh the lock.\n\t\tih, ok := parseIfHeader(r.Header.Get(\"If\"))\n\t\tif !ok {\n\t\t\treturn http.StatusBadRequest, errInvalidIfHeader\n\t\t}\n\t\tif len(ih.lists) == 1 && len(ih.lists[0].conditions) == 1 {\n\t\t\ttoken = ih.lists[0].conditions[0].Token\n\t\t}\n\t\tif token == \"\" {\n\t\t\treturn http.StatusBadRequest, errInvalidLockToken\n\t\t}\n\t\tld, err = h.LockSystem.Refresh(now, token, duration)\n\t\tif err != nil {\n\t\t\tif err == ErrNoSuchLock {\n\t\t\t\treturn http.StatusPreconditionFailed, err\n\t\t\t}\n\t\t\treturn http.StatusInternalServerError, err\n\t\t}\n\n\t} else {\n\t\t// Section 9.10.3 says that \"If no Depth header is submitted on a LOCK request,\n\t\t// then the request MUST act as if a \"Depth:infinity\" had been submitted.\"\n\t\tdepth := infiniteDepth\n\t\tif hdr := r.Header.Get(\"Depth\"); hdr != \"\" {\n\t\t\tdepth = parseDepth(hdr)\n\t\t\tif depth != 0 && depth != infiniteDepth {\n\t\t\t\t// Section 9.10.3 says that \"Values other than 0 or infinity must not be\n\t\t\t\t// used with the Depth header on a LOCK method\".\n\t\t\t\treturn http.StatusBadRequest, errInvalidDepth\n\t\t\t}\n\t\t}\n\t\treqPath, status, err := h.stripPrefix(r.URL.Path)\n\t\treqPath = path.Join(user.BasePath, reqPath)\n\t\tif err != nil {\n\t\t\treturn status, err\n\t\t}\n\t\tld = LockDetails{\n\t\t\tRoot:      reqPath,\n\t\t\tDuration:  duration,\n\t\t\tOwnerXML:  li.Owner.InnerXML,\n\t\t\tZeroDepth: depth == 0,\n\t\t}\n\t\ttoken, err = h.LockSystem.Create(now, ld)\n\t\tif err != nil {\n\t\t\tif err == ErrLocked {\n\t\t\t\treturn StatusLocked, err\n\t\t\t}\n\t\t\treturn http.StatusInternalServerError, err\n\t\t}\n\t\tdefer func() {\n\t\t\tif retErr != nil {\n\t\t\t\th.LockSystem.Unlock(now, token)\n\t\t\t}\n\t\t}()\n\n\t\t// ??? Why create resource here?\n\t\t//// Create the resource if it didn't previously exist.\n\t\t//if _, err := h.FileSystem.Stat(ctx, reqPath); err != nil {\n\t\t//\tf, err := h.FileSystem.OpenFile(ctx, reqPath, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666)\n\t\t//\tif err != nil {\n\t\t//\t\t// TODO: detect missing intermediate dirs and return http.StatusConflict?\n\t\t//\t\treturn http.StatusInternalServerError, err\n\t\t//\t}\n\t\t//\tf.Close()\n\t\t//\tcreated = true\n\t\t//}\n\n\t\t// http://www.webdav.org/specs/rfc4918.html#HEADER_Lock-Token says that the\n\t\t// Lock-Token value is a Coded-URL. We add angle brackets.\n\t\tw.Header().Set(\"Lock-Token\", \"<\"+token+\">\")\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/xml; charset=utf-8\")\n\tif created {\n\t\t// This is \"w.WriteHeader(http.StatusCreated)\" and not \"return\n\t\t// http.StatusCreated, nil\" because we write our own (XML) response to w\n\t\t// and Handler.ServeHTTP would otherwise write \"Created\".\n\t\tw.WriteHeader(http.StatusCreated)\n\t}\n\twriteLockInfo(w, token, ld)\n\treturn 0, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Hosts(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.AllHosts, error) {\n\tout := new(clientpb.AllHosts)\n\terr := c.cc.Invoke(ctx, SliverRPC_Hosts_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func openRB(t *testing.T, filename string) *FileBasedRingBuffer {\n\tconfig_obj := config.GetDefaultConfig()\n\tconfig_obj.Client.LocalBuffer.FilenameLinux = filename\n\tconfig_obj.Client.LocalBuffer.FilenameWindows = filename\n\tconfig_obj.Client.LocalBuffer.FilenameDarwin = filename\n\n\tnull_logger, new_hook := test.NewNullLogger()\n\tlogger := &logging.LogContext{null_logger}\n\thook = new_hook\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tring_buffer, err := OpenFileBasedRingBuffer(ctx, config_obj, logger)\n\tassert.NoError(t, err)\n\n\treturn ring_buffer\n}", "is_vulnerable": 0}
{"code": "func (m *mockViewUser) UserByID(context.Context, string, string) (*user_view_model.UserView, error) {\n\treturn &user_view_model.UserView{\n\t\tState:    int32(user_model.UserStateActive),\n\t\tUserName: \"UserName\",\n\t\tHumanView: &user_view_model.HumanView{\n\t\t\tFirstName:                \"FirstName\",\n\t\t\tInitRequired:             m.InitRequired,\n\t\t\tPasswordInitRequired:     m.PasswordInitRequired,\n\t\t\tPasswordSet:              m.PasswordSet,\n\t\t\tPasswordChangeRequired:   m.PasswordChangeRequired,\n\t\t\tIsEmailVerified:          m.IsEmailVerified,\n\t\t\tOTPState:                 m.OTPState,\n\t\t\tMFAMaxSetUp:              m.MFAMaxSetUp,\n\t\t\tMFAInitSkipped:           m.MFAInitSkipped,\n\t\t\tPasswordlessInitRequired: m.PasswordlessInitRequired,\n\t\t\tPasswordlessTokens:       m.PasswordlessTokens,\n\t\t},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func MakeEmailPrimary(userID int64, email *EmailAddress) error {\n\thas, err := x.Get(email)\n\tif err != nil {\n\t\treturn err\n\t} else if !has {\n\t\treturn errors.EmailNotFound{Email: email.Email}\n\t}\n\n\tif email.UID != userID {\n\t\treturn errors.New(\"not the owner of the email\")\n\t}\n\n\tif !email.IsActivated {\n\t\treturn errors.EmailNotVerified{Email: email.Email}\n\t}\n\n\tuser := &User{ID: email.UID}\n\thas, err = x.Get(user)\n\tif err != nil {\n\t\treturn err\n\t} else if !has {\n\t\treturn errors.UserNotExist{UserID: email.UID}\n\t}\n\n\t// Make sure the former primary email doesn't disappear.\n\tformerPrimaryEmail := &EmailAddress{Email: user.Email}\n\thas, err = x.Get(formerPrimaryEmail)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsess := x.NewSession()\n\tdefer sess.Close()\n\tif err = sess.Begin(); err != nil {\n\t\treturn err\n\t}\n\n\tif !has {\n\t\tformerPrimaryEmail.UID = user.ID\n\t\tformerPrimaryEmail.IsActivated = user.IsActive\n\t\tif _, err = sess.Insert(formerPrimaryEmail); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tuser.Email = email.Email\n\tif _, err = sess.ID(user.ID).AllCols().Update(user); err != nil {\n\t\treturn err\n\t}\n\n\treturn sess.Commit()\n}", "is_vulnerable": 0}
{"code": "func (c *CommonController) SetTitle(title string) {\n\tc.SetData(\"Title\", title+\" - Bifrost\")\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) Chown(path string) error {\n\tcleaned, err := fs.SafePath(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn fs.unsafeChown(cleaned)\n}", "is_vulnerable": 1}
{"code": "func NewDeploymentListResultIterator(page DeploymentListResultPage) DeploymentListResultIterator {\n\treturn original.NewDeploymentListResultIterator(page)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) ImplantBuilds(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.ImplantBuilds, error) {\n\tout := new(clientpb.ImplantBuilds)\n\terr := c.cc.Invoke(ctx, SliverRPC_ImplantBuilds_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (fs *UnixFS) Lchown(name string, uid, gid int) error {\n\t// With AT_SYMLINK_NOFOLLOW, Fchownat acts like Lchown but allows us to\n\t// pass a dirfd.\n\treturn fs.fchown(name, uid, gid, AT_SYMLINK_NOFOLLOW)\n}", "is_vulnerable": 0}
{"code": "func Implementsf(t TestingT, interfaceObject interface{}, object interface{}, msg string, args ...interface{}) {\n\tif assert.Implementsf(t, interfaceObject, object, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func encryptSymmetric(\n\tcipher_properties *crypto_proto.CipherProperties,\n\tplain_text []byte,\n\tiv []byte) ([]byte, error) {\n\tif len(cipher_properties.Key) != 16 {\n\t\treturn nil, errors.New(\"Incorrect key length provided.\")\n\t}\n\n\t// Add padding. See\n\t// https://tools.ietf.org/html/rfc5246#section-6.2.3.2 for\n\t// details.\n\tpadding := aes.BlockSize - (len(plain_text) % aes.BlockSize)\n\tfor i := 0; i < padding; i++ {\n\t\tplain_text = append(plain_text, byte(padding))\n\t}\n\n\tbase_crypter, err := aes.NewCipher(cipher_properties.Key)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tmode := cipher.NewCBCEncrypter(base_crypter, iv)\n\tcipher_text := make([]byte, len(plain_text))\n\tmode.CryptBlocks(cipher_text, plain_text)\n\n\treturn cipher_text, nil\n}", "is_vulnerable": 1}
{"code": "func opCallCode(pc *uint64, interpreter *EVMInterpreter, callContext *callCtx) ([]byte, error) {\n\t// Pop gas. The actual gas is in interpreter.evm.callGasTemp.\n\tstack := callContext.stack\n\t// We use it as a temporary value\n\ttemp := stack.pop()\n\tgas := interpreter.evm.callGasTemp\n\t// Pop other call parameters.\n\taddr, value, inOffset, inSize, retOffset, retSize := stack.pop(), stack.pop(), stack.pop(), stack.pop(), stack.pop(), stack.pop()\n\ttoAddr := common.Address(addr.Bytes20())\n\t// Get arguments from the memory.\n\targs := callContext.memory.GetPtr(int64(inOffset.Uint64()), int64(inSize.Uint64()))\n\n\t//TODO: use uint256.Int instead of converting with toBig()\n\tvar bigVal = big0\n\tif !value.IsZero() {\n\t\tgas += params.CallStipend\n\t\tbigVal = value.ToBig()\n\t}\n\n\tret, returnGas, err := interpreter.evm.CallCode(callContext.contract, toAddr, args, gas, bigVal)\n\tif err != nil {\n\t\ttemp.Clear()\n\t} else {\n\t\ttemp.SetOne()\n\t}\n\tstack.push(&temp)\n\tif err == nil || err == ErrExecutionReverted {\n\t\tcallContext.memory.Set(retOffset.Uint64(), retSize.Uint64(), ret)\n\t}\n\tcallContext.contract.Gas += returnGas\n\n\treturn ret, nil\n}", "is_vulnerable": 0}
{"code": "func (m Map) Exclude(exclude []string) Map {\n\texcluded := make(Map)\n\tfor k, v := range m {\n\t\tif !contains(exclude, k) {\n\t\t\texcluded[k] = v\n\t\t}\n\t}\n\treturn excluded\n}", "is_vulnerable": 0}
{"code": "\tpcAnswer.OnDataChannel(func(_ *DataChannel) {\n\t\tt.Fatal(\"A DataChannel must not be created when Fingerprint verification fails\")\n\t})", "is_vulnerable": 0}
{"code": "func (m *Bar2) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar2: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar2: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Str = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func doesPolicySignatureV4Match(formValues http.Header) (auth.Credentials, APIErrorCode) {\n\t// Server region.\n\tregion := globalServerRegion\n\n\t// Parse credential tag.\n\tcredHeader, s3Err := parseCredentialHeader(\"Credential=\"+formValues.Get(xhttp.AmzCredential), region, serviceS3)\n\tif s3Err != ErrNone {\n\t\treturn auth.Credentials{}, s3Err\n\t}\n\n\tcred, _, s3Err := checkKeyValid(credHeader.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\n\t// Get signing key.\n\tsigningKey := getSigningKey(cred.SecretKey, credHeader.scope.date, credHeader.scope.region, serviceS3)\n\n\t// Get signature.\n\tnewSignature := getSignature(signingKey, formValues.Get(\"Policy\"))\n\n\t// Verify signature.\n\tif !compareSignatureV4(newSignature, formValues.Get(xhttp.AmzSignature)) {\n\t\treturn cred, ErrSignatureDoesNotMatch\n\t}\n\n\t// Success.\n\treturn cred, ErrNone\n}", "is_vulnerable": 0}
{"code": "func (m *AllMapsOrdered) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: AllMapsOrdered: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: AllMapsOrdered: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringToDoubleMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringToDoubleMap == nil {\n\t\t\t\tm.StringToDoubleMap = make(map[string]float64)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue float64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvaluetemp = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tmapvalue = math.Float64frombits(mapvaluetemp)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringToDoubleMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringToFloatMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringToFloatMap == nil {\n\t\t\t\tm.StringToFloatMap = make(map[string]float32)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue float32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvaluetemp = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tmapvalue = math.Float32frombits(mapvaluetemp)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringToFloatMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Int32Map == nil {\n\t\t\t\tm.Int32Map = make(map[int32]int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue int32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int32Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int64Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Int64Map == nil {\n\t\t\t\tm.Int64Map = make(map[int64]int64)\n\t\t\t}\n\t\t\tvar mapkey int64\n\t\t\tvar mapvalue int64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int64Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint32Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Uint32Map == nil {\n\t\t\t\tm.Uint32Map = make(map[uint32]uint32)\n\t\t\t}\n\t\t\tvar mapkey uint32\n\t\t\tvar mapvalue uint32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint32Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint64Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Uint64Map == nil {\n\t\t\t\tm.Uint64Map = make(map[uint64]uint64)\n\t\t\t}\n\t\t\tvar mapkey uint64\n\t\t\tvar mapvalue uint64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint64Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sint32Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Sint32Map == nil {\n\t\t\t\tm.Sint32Map = make(map[int32]int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue int32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar mapkeytemp int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkeytemp |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapkeytemp = int32((uint32(mapkeytemp) >> 1) ^ uint32(((mapkeytemp&1)<<31)>>31))\n\t\t\t\t\tmapkey = int32(mapkeytemp)\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvaluetemp |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapvaluetemp = int32((uint32(mapvaluetemp) >> 1) ^ uint32(((mapvaluetemp&1)<<31)>>31))\n\t\t\t\t\tmapvalue = int32(mapvaluetemp)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Sint32Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sint64Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Sint64Map == nil {\n\t\t\t\tm.Sint64Map = make(map[int64]int64)\n\t\t\t}\n\t\t\tvar mapkey int64\n\t\t\tvar mapvalue int64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar mapkeytemp uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkeytemp |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapkeytemp = (mapkeytemp >> 1) ^ uint64((int64(mapkeytemp&1)<<63)>>63)\n\t\t\t\t\tmapkey = int64(mapkeytemp)\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvaluetemp |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapvaluetemp = (mapvaluetemp >> 1) ^ uint64((int64(mapvaluetemp&1)<<63)>>63)\n\t\t\t\t\tmapvalue = int64(mapvaluetemp)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Sint64Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fixed32Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Fixed32Map == nil {\n\t\t\t\tm.Fixed32Map = make(map[uint32]uint32)\n\t\t\t}\n\t\t\tvar mapkey uint32\n\t\t\tvar mapvalue uint32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Fixed32Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sfixed32Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Sfixed32Map == nil {\n\t\t\t\tm.Sfixed32Map = make(map[int32]int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue int32\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Sfixed32Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fixed64Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Fixed64Map == nil {\n\t\t\t\tm.Fixed64Map = make(map[uint64]uint64)\n\t\t\t}\n\t\t\tvar mapkey uint64\n\t\t\tvar mapvalue uint64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Fixed64Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sfixed64Map\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Sfixed64Map == nil {\n\t\t\t\tm.Sfixed64Map = make(map[int64]int64)\n\t\t\t}\n\t\t\tvar mapkey int64\n\t\t\tvar mapvalue int64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Sfixed64Map[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field BoolMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.BoolMap == nil {\n\t\t\t\tm.BoolMap = make(map[bool]bool)\n\t\t\t}\n\t\t\tvar mapkey bool\n\t\t\tvar mapvalue bool\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar mapkeytemp int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkeytemp |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = bool(mapkeytemp != 0)\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvaluetemp |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = bool(mapvaluetemp != 0)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.BoolMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringMap == nil {\n\t\t\t\tm.StringMap = make(map[string]string)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue string\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar stringLenmapvalue uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapvalue |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapvalue := int(stringLenmapvalue)\n\t\t\t\t\tif intStringLenmapvalue < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapvalue := iNdEx + intStringLenmapvalue\n\t\t\t\t\tif postStringIndexmapvalue < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapvalue > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])\n\t\t\t\t\tiNdEx = postStringIndexmapvalue\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringToBytesMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringToBytesMap == nil {\n\t\t\t\tm.StringToBytesMap = make(map[string][]byte)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tmapvalue := []byte{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = make([]byte, mapbyteLen)\n\t\t\t\t\tcopy(mapvalue, dAtA[iNdEx:postbytesIndex])\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringToBytesMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringToEnumMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringToEnumMap == nil {\n\t\t\t\tm.StringToEnumMap = make(map[string]MapEnum)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue MapEnum\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= MapEnum(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringToEnumMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StringToMsgMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.StringToMsgMap == nil {\n\t\t\t\tm.StringToMsgMap = make(map[string]*FloatingPoint)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue *FloatingPoint\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &FloatingPoint{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.StringToMsgMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tp.CustomHttpRoundTripperWrap = func(original http.RoundTripper) http.RoundTripper {\n\t\t\treturn original\n\t\t}\n\t}\n\n\ttr := &http.Transport{\n\t\tDialContext: newSkipperDialer(net.Dialer{\n\t\t\tTimeout:   p.Timeout,\n\t\t\tKeepAlive: p.KeepAlive,\n\t\t\tDualStack: p.DualStack,\n\t\t}).DialContext,\n\t\tTLSHandshakeTimeout:   p.TLSHandshakeTimeout,\n\t\tResponseHeaderTimeout: p.ResponseHeaderTimeout,\n\t\tExpectContinueTimeout: p.ExpectContinueTimeout,\n\t\tMaxIdleConns:          p.MaxIdleConns,\n\t\tMaxIdleConnsPerHost:   p.IdleConnectionsPerHost,\n\t\tIdleConnTimeout:       p.CloseIdleConnsPeriod,\n\t\tDisableKeepAlives:     p.DisableHTTPKeepalives,\n\t\tProxy:                 proxyFromContext,\n\t}\n\n\tquit := make(chan struct{})\n\t// We need this to reliably fade on DNS change, which is right\n\t// now not fixed with IdleConnTimeout in the http.Transport.\n\t// https://github.com/golang/go/issues/23427\n\tif p.CloseIdleConnsPeriod > 0 {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-time.After(p.CloseIdleConnsPeriod):\n\t\t\t\t\ttr.CloseIdleConnections()\n\t\t\t\tcase <-quit:\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tif p.ClientTLS != nil {\n\t\ttr.TLSClientConfig = p.ClientTLS\n\t}\n\n\tif p.Flags.Insecure() {\n\t\tif tr.TLSClientConfig == nil {\n\t\t\t/* #nosec */\n\t\t\ttr.TLSClientConfig = &tls.Config{InsecureSkipVerify: true}\n\t\t} else {\n\t\t\t/* #nosec */\n\t\t\ttr.TLSClientConfig.InsecureSkipVerify = true\n\t\t}\n\t}\n\n\tm := metrics.Default\n\tif p.Flags.Debug() {\n\t\tm = metrics.Void\n\t}\n\n\tif p.MaxLoopbacks == 0 {\n\t\tp.MaxLoopbacks = DefaultMaxLoopbacks\n\t} else if p.MaxLoopbacks < 0 {\n\t\tp.MaxLoopbacks = 0\n\t}\n\n\tdefaultHTTPStatus := http.StatusNotFound\n\n\tif p.DefaultHTTPStatus >= http.StatusContinue && p.DefaultHTTPStatus <= http.StatusNetworkAuthenticationRequired {\n\t\tdefaultHTTPStatus = p.DefaultHTTPStatus\n\t}\n\n\thostname := os.Getenv(\"HOSTNAME\")\n\n\treturn &Proxy{\n\t\trouting:                  p.Routing,\n\t\troundTripper:             p.CustomHttpRoundTripperWrap(tr),\n\t\tpriorityRoutes:           p.PriorityRoutes,\n\t\tflags:                    p.Flags,\n\t\tmetrics:                  m,\n\t\tquit:                     quit,\n\t\tflushInterval:            p.FlushInterval,\n\t\texperimentalUpgrade:      p.ExperimentalUpgrade,\n\t\texperimentalUpgradeAudit: p.ExperimentalUpgradeAudit,\n\t\tmaxLoops:                 p.MaxLoopbacks,\n\t\tbreakers:                 p.CircuitBreakers,\n\t\tlb:                       p.LoadBalancer,\n\t\tlimiters:                 p.RateLimiters,\n\t\tlog:                      &logging.DefaultLog{},\n\t\tdefaultHTTPStatus:        defaultHTTPStatus,\n\t\ttracing:                  newProxyTracing(p.OpenTracing),\n\t\taccessLogDisabled:        p.AccessLogDisabled,\n\t\tupgradeAuditLogOut:       os.Stdout,\n\t\tupgradeAuditLogErr:       os.Stderr,\n\t\tclientTLS:                tr.TLSClientConfig,\n\t\thostname:                 hostname,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (src *PasswordMessage) Encode(dst []byte) []byte {\n\tdst = append(dst, 'p')\n\tdst = pgio.AppendInt32(dst, int32(4+len(src.Password)+1))\n\n\tdst = append(dst, src.Password...)\n\tdst = append(dst, 0)\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func inotifyInit() (fd int, err error) {\n\tr0, _, e1 := RawSyscall(SYS_INOTIFY_INIT, 0, 0, 0)\n\tfd = int(r0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func getRandomNonce() ([]byte, error) {\n\tkey := make([]byte, 24)\n\n\t_, err := rand.Read(key)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"error getting random bytes\")\n\t}\n\treturn key, nil\n}", "is_vulnerable": 0}
{"code": "func (m *MockRefreshTokenStrategy) ValidateRefreshToken(arg0 context.Context, arg1 fosite.Requester, arg2 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"ValidateRefreshToken\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func childTextNodesAreLiteral(n *Node) bool {\n\t// Per WHATWG HTML 13.3, if the parent of the current node is a style,\n\t// script, xmp, iframe, noembed, noframes, or plaintext element, and the\n\t// current node is a text node, append the value of the node's data\n\t// literally. The specification is not explicit about it, but we only\n\t// enforce this if we are in the HTML namespace (i.e. when the namespace is\n\t// \"\").\n\t// NOTE: we also always include noscript elements, although the\n\t// specification states that they should only be rendered as such if\n\t// scripting is enabled for the node (which is not something we track).\n\tif n.Namespace != \"\" {\n\t\treturn false\n\t}\n\tswitch n.Data {\n\tcase \"iframe\", \"noembed\", \"noframes\", \"noscript\", \"plaintext\", \"script\", \"style\", \"xmp\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "is_vulnerable": 0}
{"code": "func afterHeadIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase TextToken:\n\t\ts := strings.TrimLeft(p.tok.Data, whitespace)\n\t\tif len(s) < len(p.tok.Data) {\n\t\t\t// Add the initial whitespace to the current node.\n\t\t\tp.addText(p.tok.Data[:len(p.tok.Data)-len(s)])\n\t\t\tif s == \"\" {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tp.tok.Data = s\n\t\t}\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\treturn inBodyIM(p)\n\t\tcase a.Body:\n\t\t\tp.addElement()\n\t\t\tp.framesetOK = false\n\t\t\tp.im = inBodyIM\n\t\t\treturn true\n\t\tcase a.Frameset:\n\t\t\tp.addElement()\n\t\t\tp.im = inFramesetIM\n\t\t\treturn true\n\t\tcase a.Base, a.Basefont, a.Bgsound, a.Link, a.Meta, a.Noframes, a.Script, a.Style, a.Title:\n\t\t\tp.oe = append(p.oe, p.head)\n\t\t\tdefer p.oe.remove(p.head)\n\t\t\treturn inHeadIM(p)\n\t\tcase a.Head:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Body, a.Html, a.Br:\n\t\t\t// Drop down to creating an implied <body> tag.\n\t\tdefault:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\t\treturn true\n\tcase DoctypeToken:\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\n\tp.parseImpliedToken(StartTagToken, a.Body, a.Body.String())\n\tp.framesetOK = true\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func GetIntAnnotation(name string, ing *networking.Ingress) (int, error) {\n\tv := GetAnnotationWithPrefix(name)\n\terr := checkAnnotation(v, ing)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn ingAnnotations(ing.GetAnnotations()).parseInt(v)\n}", "is_vulnerable": 1}
{"code": "func (client Client) Update(ctx context.Context, resourceGroupName string, resourceProviderNamespace string, parentResourcePath string, resourceType string, resourceName string, parameters GenericResource) (result UpdateFuture, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/Client.Update\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response() != nil {\n\t\t\t\tsc = result.Response().StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"Update\", err.Error())\n\t}\n\n\treq, err := client.UpdatePreparer(ctx, resourceGroupName, resourceProviderNamespace, parentResourcePath, resourceType, resourceName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Update\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresult, err = client.UpdateSender(req)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Update\", result.Response(), \"Failure sending request\")\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func TestFloat64PrecisionStability(t *testing.T) {\n\tconst (\n\t\tnumRuns       = 100\n\t\tnumRegistries = 100\n\t\tcardinality   = 20\n\t)\n\n\t// Randomise the seed but log it in case we need to reproduce the test on failure.\n\tseed := time.Now().UnixNano()\n\trand.New(rand.NewSource(seed))\n\tt.Log(\"random generator seed:\", seed)\n\n\t// Generate a large number of registries with different metrics each.\n\tregistries := NewUserRegistries()\n\tfor userID := 1; userID <= numRegistries; userID++ {\n\t\treg := prometheus.NewRegistry()\n\t\tlabelNames := []string{\"label_one\", \"label_two\"}\n\n\t\tg := promauto.With(reg).NewGaugeVec(prometheus.GaugeOpts{Name: \"test_gauge\"}, labelNames)\n\t\tfor i := 0; i < cardinality; i++ {\n\t\t\tg.WithLabelValues(\"a\", strconv.Itoa(i)).Set(rand.Float64())\n\t\t}\n\n\t\tc := promauto.With(reg).NewCounterVec(prometheus.CounterOpts{Name: \"test_counter\"}, labelNames)\n\t\tfor i := 0; i < cardinality; i++ {\n\t\t\tc.WithLabelValues(\"a\", strconv.Itoa(i)).Add(rand.Float64())\n\t\t}\n\n\t\th := promauto.With(reg).NewHistogramVec(prometheus.HistogramOpts{Name: \"test_histogram\", Buckets: []float64{0.1, 0.5, 1}}, labelNames)\n\t\tfor i := 0; i < cardinality; i++ {\n\t\t\th.WithLabelValues(\"a\", strconv.Itoa(i)).Observe(rand.Float64())\n\t\t}\n\n\t\ts := promauto.With(reg).NewSummaryVec(prometheus.SummaryOpts{Name: \"test_summary\"}, labelNames)\n\t\tfor i := 0; i < cardinality; i++ {\n\t\t\ts.WithLabelValues(\"a\", strconv.Itoa(i)).Observe(rand.Float64())\n\t\t}\n\n\t\tregistries.AddUserRegistry(strconv.Itoa(userID), reg)\n\t}\n\n\t// Ensure multiple runs always return the same exact results.\n\texpected := map[string][]*dto.Metric{}\n\n\tfor run := 0; run < numRuns; run++ {\n\t\tmf := registries.BuildMetricFamiliesPerUser()\n\n\t\tgauge := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfGauges(out, prometheus.NewDesc(\"test_gauge\", \"\", nil, nil), \"test_gauge\")\n\t\t})\n\t\tgaugeWithLabels := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfGaugesWithLabels(out, prometheus.NewDesc(\"test_gauge\", \"\", []string{\"label_one\"}, nil), \"test_gauge\", \"label_one\")\n\t\t})\n\n\t\tcounter := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfCounters(out, prometheus.NewDesc(\"test_counter\", \"\", nil, nil), \"test_counter\")\n\t\t})\n\t\tcounterWithLabels := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfCountersWithLabels(out, prometheus.NewDesc(\"test_counter\", \"\", []string{\"label_one\"}, nil), \"test_counter\", \"label_one\")\n\t\t})\n\n\t\thistogram := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfHistograms(out, prometheus.NewDesc(\"test_histogram\", \"\", nil, nil), \"test_histogram\")\n\t\t})\n\t\thistogramWithLabels := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfHistogramsWithLabels(out, prometheus.NewDesc(\"test_histogram\", \"\", []string{\"label_one\"}, nil), \"test_histogram\", \"label_one\")\n\t\t})\n\n\t\tsummary := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfSummaries(out, prometheus.NewDesc(\"test_summary\", \"\", nil, nil), \"test_summary\")\n\t\t})\n\t\tsummaryWithLabels := collectMetrics(t, func(out chan prometheus.Metric) {\n\t\t\tmf.SendSumOfSummariesWithLabels(out, prometheus.NewDesc(\"test_summary\", \"\", []string{\"label_one\"}, nil), \"test_summary\", \"label_one\")\n\t\t})\n\n\t\t// The first run we just store the expected value.\n\t\tif run == 0 {\n\t\t\texpected[\"gauge\"] = gauge\n\t\t\texpected[\"gauge_with_labels\"] = gaugeWithLabels\n\t\t\texpected[\"counter\"] = counter\n\t\t\texpected[\"counter_with_labels\"] = counterWithLabels\n\t\t\texpected[\"histogram\"] = histogram\n\t\t\texpected[\"histogram_with_labels\"] = histogramWithLabels\n\t\t\texpected[\"summary\"] = summary\n\t\t\texpected[\"summary_with_labels\"] = summaryWithLabels\n\t\t\tcontinue\n\t\t}\n\n\t\t// All subsequent runs we assert the actual metric with the expected one.\n\t\trequire.Equal(t, expected[\"gauge\"], gauge)\n\t\trequire.Equal(t, expected[\"gauge_with_labels\"], gaugeWithLabels)\n\t\trequire.Equal(t, expected[\"counter\"], counter)\n\t\trequire.Equal(t, expected[\"counter_with_labels\"], counterWithLabels)\n\t\trequire.Equal(t, expected[\"histogram\"], histogram)\n\t\trequire.Equal(t, expected[\"histogram_with_labels\"], histogramWithLabels)\n\t\trequire.Equal(t, expected[\"summary\"], summary)\n\t\trequire.Equal(t, expected[\"summary_with_labels\"], summaryWithLabels)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (o *CopyOptions) untarAll(src fileSpec, reader io.Reader, destDir, prefix string) error {\n\tsymlinkWarningPrinted := false\n\t// TODO: use compression here?\n\ttarReader := tar.NewReader(reader)\n\tfor {\n\t\theader, err := tarReader.Next()\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t// All the files will start with the prefix, which is the directory where\n\t\t// they were located on the pod, we need to strip down that prefix, but\n\t\t// if the prefix is missing it means the tar was tempered with.\n\t\t// For the case where prefix is empty we need to ensure that the path\n\t\t// is not absolute, which also indicates the tar file was tempered with.\n\t\tif !strings.HasPrefix(header.Name, prefix) {\n\t\t\treturn fmt.Errorf(\"tar contents corrupted\")\n\t\t}\n\n\t\t// basic file information\n\t\tmode := header.FileInfo().Mode()\n\t\tdestFileName := filepath.Join(destDir, header.Name[len(prefix):])\n\n\t\tif !isDestRelative(destDir, destFileName) {\n\t\t\tfmt.Fprintf(o.IOStreams.ErrOut, \"warning: file %q is outside target destination, skipping\\n\", destFileName)\n\t\t\tcontinue\n\t\t}\n\n\t\tbaseName := filepath.Dir(destFileName)\n\t\tif err := os.MkdirAll(baseName, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif header.FileInfo().IsDir() {\n\t\t\tif err := os.MkdirAll(destFileName, 0755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif mode&os.ModeSymlink != 0 {\n\t\t\tif !symlinkWarningPrinted && len(o.ExecParentCmdName) > 0 {\n\t\t\t\tfmt.Fprintf(o.IOStreams.ErrOut, \"warning: file %q is a symlink, skipping (consider using \\\"%s exec -n %q %q -- tar cf - %q | tar xf -\\\")\\n\", destFileName, o.ExecParentCmdName, src.PodNamespace, src.PodName, src.File)\n\t\t\t\tsymlinkWarningPrinted = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfmt.Fprintf(o.IOStreams.ErrOut, \"warning: skipping symlink: %q -> %q\\n\", destFileName, header.Linkname)\n\t\t\tcontinue\n\t\t}\n\t\toutFile, err := os.Create(destFileName)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer outFile.Close()\n\t\tif _, err := io.Copy(outFile, tarReader); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := outFile.Close(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (b *BearerTokenAuth) Authenticate(ctx context.Context, headers map[string][]string) (context.Context, error) {\n\tauth, ok := headers[\"authorization\"]\n\tif !ok {\n\t\tauth, ok = headers[\"Authorization\"]\n\t}\n\tif !ok || len(auth) == 0 {\n\t\treturn ctx, errors.New(\"missing or empty authorization header\")\n\t}\n\ttoken := auth[0]\n\texpect := b.authorizationValue()\n\tif subtle.ConstantTimeCompare([]byte(expect), []byte(token)) == 0 {\n\t\treturn ctx, fmt.Errorf(\"scheme or token does not match: %s\", token)\n\t}\n\treturn ctx, nil\n}", "is_vulnerable": 0}
{"code": "func (e *Engine) ReceivedBlocks(from peer.ID, blks []blocks.Block) {\n\tif len(blks) == 0 {\n\t\treturn\n\t}\n\n\tl := e.findOrCreate(from)\n\n\t// Record how many bytes were received in the ledger\n\tl.lk.Lock()\n\tdefer l.lk.Unlock()\n\tfor _, blk := range blks {\n\t\tlog.Debugw(\"Bitswap engine <- block\", \"local\", e.self, \"from\", from, \"cid\", blk.Cid(), \"size\", len(blk.RawData()))\n\t\te.scoreLedger.AddToReceivedBytes(l.Partner, len(blk.RawData()))\n\t}\n}", "is_vulnerable": 1}
{"code": "func (t Repository) Resolve(ctx context.Context, reference string) (ocispec.Descriptor, error) {\n\tif t.MissMatchDigest {\n\t\treturn ocispec.Descriptor{\n\t\t\tMediaType:   \"application/vnd.docker.distribution.manifest.v2+json\",\n\t\t\tDigest:      ZeroDigest,\n\t\t\tSize:        528,\n\t\t\tAnnotations: Annotations,\n\t\t}, nil\n\t}\n\treturn t.ResolveResponse, t.ResolveError\n}", "is_vulnerable": 0}
{"code": "func (m *MockClientCredentialsGrantStorage) GetAccessTokenSession(arg0 context.Context, arg1 string, arg2 fosite.Session) (fosite.Requester, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetAccessTokenSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(fosite.Requester)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func (c *Configurator) enableAgentTLSForChecks() bool {\n\tc.RLock()\n\tdefer c.RUnlock()\n\treturn c.base.EnableAgentTLSForChecks\n}", "is_vulnerable": 0}
{"code": "func (wds *WebDriverSession) verifyURLIs(ctx context.Context, t *testing.T, url string) {\n\terr := wds.Wait(ctx, func(driver selenium.WebDriver) (bool, error) {\n\t\tcurrentURL, err := driver.CurrentURL()\n\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\treturn currentURL == url, nil\n\t})\n\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn connection{r}\n}", "is_vulnerable": 1}
{"code": "func (f *FileStorage) Delete(contentID string) error {\n\tp, err := f.storagePathFor(contentID)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.Remove(p)\n}", "is_vulnerable": 0}
{"code": "func TestHostSquareBrackets(t *testing.T) {\n\tfor _, testCase := range hostSquareBracketsCases {\n\t\tt.Run(testCase.scheme, func(t *testing.T) {\n\t\t\ta := assert.New(t)\n\t\t\tr := require.New(t)\n\n\t\t\tcfg, err := testConfig(\"test-open-srv\")\n\t\t\trequire.NoError(t, err)\n\t\t\tlogHook := proxyLogHook(cfg)\n\n\t\t\tproxySrv := proxyServer(cfg)\n\t\t\tdefer proxySrv.Close()\n\n\t\t\t// Create a http.Client that uses our proxy\n\t\t\tclient, err := proxyClient(proxySrv.URL)\n\t\t\tr.NoError(err)\n\n\t\t\tresp, err := client.Get(fmt.Sprintf(\"%s://[stripe.com]\", testCase.scheme))\n\t\t\tif err != nil {\n\t\t\t\tr.Contains(err.Error(), \"Request rejected by proxy\")\n\t\t\t} else {\n\t\t\t\tr.Equal(http.StatusProxyAuthRequired, resp.StatusCode)\n\t\t\t}\n\n\t\t\tentry := findCanonicalProxyDecision(logHook.AllEntries())\n\t\t\tr.NotNil(entry)\n\n\t\t\tif a.Contains(entry.Data, \"allow\") {\n\t\t\t\ta.Equal(false, entry.Data[\"allow\"])\n\t\t\t\ta.Equal(\"host matched rule in global deny list\", entry.Data[\"decision_reason\"])\n\t\t\t}\n\t\t\tif a.Contains(entry.Data, \"proxy_type\") {\n\t\t\t\ta.Contains(entry.Data[\"proxy_type\"], testCase.proxyType)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_OutgoingTLS_MissingCA(t *testing.T) {\n\tconf := &Config{\n\t\tVerifyOutgoing: true,\n\t}\n\tc := NewConfigurator(conf)\n\ttlsConf, err := c.OutgoingRPCConfig()\n\trequire.Error(t, err)\n\trequire.Nil(t, tlsConf)\n}", "is_vulnerable": 1}
{"code": "func (s *connectionState) readPacket(r *bufio.Reader) ([]byte, error) {\n\tpacket, err := s.packetCipher.readCipherPacket(s.seqNum, r)\n\ts.seqNum++\n\tif err == nil && len(packet) == 0 {\n\t\terr = errors.New(\"ssh: zero length packet\")\n\t}\n\n\tif len(packet) > 0 {\n\t\tswitch packet[0] {\n\t\tcase msgNewKeys:\n\t\t\tselect {\n\t\t\tcase cipher := <-s.pendingKeyChange:\n\t\t\t\ts.packetCipher = cipher\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.New(\"ssh: got bogus newkeys message\")\n\t\t\t}\n\n\t\tcase msgDisconnect:\n\t\t\t// Transform a disconnect message into an\n\t\t\t// error. Since this is lowest level at which\n\t\t\t// we interpret message types, doing it here\n\t\t\t// ensures that we don't have to handle it\n\t\t\t// elsewhere.\n\t\t\tvar msg disconnectMsg\n\t\t\tif err := Unmarshal(packet, &msg); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn nil, &msg\n\t\t}\n\t}\n\n\t// The packet may point to an internal buffer, so copy the\n\t// packet out here.\n\tfresh := make([]byte, len(packet))\n\tcopy(fresh, packet)\n\n\treturn fresh, err\n}", "is_vulnerable": 1}
{"code": "func renderObject(value interface{}) string {\n\tserialized := \"\"\n\tswitch t := value.(type) {\n\tcase vfilter.Null, *vfilter.Null:\n\t\treturn \"\"\n\n\tcase string:\n\t\treturn t\n\n\tcase int, int64, int32, int16, int8,\n\t\tuint64, uint32, uint16, uint8,\n\t\tfloat64, float32, bool:\n\t\treturn fmt.Sprintf(\"%v\", value)\n\n\tdefault:\n\t\tserialized = \"<pre>\" + json.StringIndent(value) + \"</pre>\"\n\t}\n\treturn serialized\n}", "is_vulnerable": 1}
{"code": "func TestBuilder_BuildBootstrapStaticResources(t *testing.T) {\n\tt.Run(\"valid\", func(t *testing.T) {\n\t\tb := New(\"localhost:1111\", \"localhost:2222\", \"localhost:3333\", filemgr.NewManager(), nil)\n\t\tstaticCfg, err := b.BuildBootstrapStaticResources()\n\t\tassert.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"clusters\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"name\": \"pomerium-control-plane-grpc\",\n\t\t\t\t\t\t\"type\": \"STATIC\",\n\t\t\t\t\t\t\"connectTimeout\": \"5s\",\n\t\t\t\t\t\t\"http2ProtocolOptions\": {},\n\t\t\t\t\t\t\"loadAssignment\": {\n\t\t\t\t\t\t\t\"clusterName\": \"pomerium-control-plane-grpc\",\n\t\t\t\t\t\t\t\"endpoints\": [{\n\t\t\t\t\t\t\t\t\"lbEndpoints\": [{\n\t\t\t\t\t\t\t\t\t\"endpoint\": {\n\t\t\t\t\t\t\t\t\t\t\"address\": {\n\t\t\t\t\t\t\t\t\t\t\t\"socketAddress\":{\n\t\t\t\t\t\t\t\t\t\t\t\t\"address\": \"127.0.0.1\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"portValue\": 1111\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}]\n\t\t\t\t\t\t\t}]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t}\n\t\t`, staticCfg)\n\t})\n\tt.Run(\"bad gRPC address\", func(t *testing.T) {\n\t\tb := New(\"xyz:zyx\", \"localhost:2222\", \"localhost:3333\", filemgr.NewManager(), nil)\n\t\t_, err := b.BuildBootstrapStaticResources()\n\t\tassert.Error(t, err)\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestIssue192(t *testing.T) {\n\tassert(t, squash(`\"000\"hello`) == `\"000\"`)\n\tassert(t, squash(`\"000\"`) == `\"000\"`)\n\tassert(t, squash(`\"000`) == `\"000`)\n\tassert(t, squash(`\"`) == `\"`)\n\n\tassert(t, squash(`[000]hello`) == `[000]`)\n\tassert(t, squash(`[000]`) == `[000]`)\n\tassert(t, squash(`[000`) == `[000`)\n\tassert(t, squash(`[`) == `[`)\n\tassert(t, squash(`]`) == `]`)\n\n\ttestJSON := `0.#[[{}]].@valid:\"000`\n\tGet(testJSON, testJSON)\n}\n\nfunc TestIssue195(t *testing.T) {\n\ttestJSON := `\\************************************` +\n\t\t`**********{**\",**,,**,**,**,**,\"\",**,**,**,**,**,**,**,**,**,**]`\n\tGet(testJSON, testJSON)\n}", "is_vulnerable": 0}
{"code": "func TestStringList(t *testing.T) {\n\tcases := []struct {\n\t\tin          string\n\t\texpect      model.StringList\n\t\tnoRoundTrip bool\n\t}{\n\t\t{in: `\"a,b,c\"`, expect: []string{\"a\", \"b\", \"c\"}},\n\t\t{in: `\"a\"`, expect: []string{\"a\"}},\n\t\t{in: `\"\"`, expect: []string{}},\n\t\t{in: `\"123,@#$#,abcdef\"`, expect: []string{\"123\", \"@#$#\", \"abcdef\"}},\n\t\t{in: `1`, expect: []string{}, noRoundTrip: true},\n\t}\n\tfor _, tt := range cases {\n\t\tt.Run(tt.in, func(t *testing.T) {\n\t\t\tvar out model.StringList\n\t\t\tif err := json.Unmarshal([]byte(tt.in), &out); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(out, tt.expect) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.expect, out)\n\t\t\t}\n\t\t\tb, err := json.Marshal(out)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif tt.noRoundTrip {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(string(b), tt.in) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.in, string(b))\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func saveAdminTOTPConfig(username string, r *http.Request, recoveryCodes []dataprovider.RecoveryCode) error {\n\tadmin, err := dataprovider.AdminExists(username)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcurrentTOTPSecret := admin.Filters.TOTPConfig.Secret\n\tadmin.Filters.TOTPConfig.Secret = nil\n\terr = render.DecodeJSON(r.Body, &admin.Filters.TOTPConfig)\n\tif err != nil {\n\t\treturn util.NewValidationError(fmt.Sprintf(\"unable to decode JSON body: %v\", err))\n\t}\n\tif admin.Filters.TOTPConfig.Enabled {\n\t\tif admin.CountUnusedRecoveryCodes() < 5 && admin.Filters.TOTPConfig.Enabled {\n\t\t\tadmin.Filters.RecoveryCodes = recoveryCodes\n\t\t}\n\t} else {\n\t\tadmin.Filters.RecoveryCodes = nil\n\t}\n\tif admin.Filters.TOTPConfig.Secret == nil || !admin.Filters.TOTPConfig.Secret.IsPlain() {\n\t\tadmin.Filters.TOTPConfig.Secret = currentTOTPSecret\n\t}\n\treturn dataprovider.UpdateAdmin(&admin, dataprovider.ActionExecutorSelf, util.GetIPFromRemoteAddress(r.RemoteAddr))\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"Update permissions\", func(t *testing.T) {\n\t\tctx, db, s := newTestStore(t)\n\t\tuid1 := insertTestUser(ctx, t, db, \"u1\", false)\n\t\tctx1 := actor.WithActor(ctx, actor.FromUser(uid1))\n\t\tuid2 := insertTestUser(ctx, t, db, \"u2\", false)\n\t\tctx2 := actor.WithActor(ctx, actor.FromUser(uid2))\n\t\tfixtures := s.insertTestMonitor(ctx1, t)\n\n\t\twa, err := s.CreateSlackWebhookAction(ctx1, fixtures.monitor.ID, true, true, \"https://true.com\")\n\t\trequire.NoError(t, err)\n\n\t\t// User1 can update it\n\t\t_, err = s.UpdateSlackWebhookAction(ctx1, wa.ID, true, true, \"https://false.com\")\n\t\trequire.NoError(t, err)\n\n\t\t// User2 cannot update it\n\t\t_, err = s.UpdateSlackWebhookAction(ctx2, wa.ID, true, true, \"https://truer.com\")\n\t\trequire.Error(t, err)\n\n\t\twa, err = s.GetSlackWebhookAction(ctx1, wa.ID)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, wa.URL, \"https://false.com\")\n\t})", "is_vulnerable": 0}
{"code": "func TestAuthMethodFallback(t *testing.T) {\n\tvar passwordCalled bool\n\tconfig := &ClientConfig{\n\t\tUser: \"testuser\",\n\t\tAuth: []AuthMethod{\n\t\t\tPublicKeys(testSigners[\"rsa\"]),\n\t\t\tPasswordCallback(\n\t\t\t\tfunc() (string, error) {\n\t\t\t\t\tpasswordCalled = true\n\t\t\t\t\treturn \"WRONG\", nil\n\t\t\t\t}),\n\t\t},\n\t\tHostKeyCallback: InsecureIgnoreHostKey(),\n\t}\n\n\tif err := tryAuth(t, config); err != nil {\n\t\tt.Fatalf(\"unable to dial remote side: %s\", err)\n\t}\n\n\tif passwordCalled {\n\t\tt.Errorf(\"password auth tried before public-key auth.\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Chown(ctx context.Context, in *sliverpb.ChownReq, opts ...grpc.CallOption) (*sliverpb.Chown, error) {\n\tout := new(sliverpb.Chown)\n\terr := c.cc.Invoke(ctx, SliverRPC_Chown_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"templates-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/test\", tempdir, true)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})", "is_vulnerable": 1}
{"code": "func TestVerifyUserMetadata(t *testing.T) {\n\tpolicyDocument := dummyPolicyDocument()\n\tpolicyDocument.TrustPolicies[0].SignatureVerification.VerificationLevel = trustpolicy.LevelAudit.Name\n\n\tpluginManager := mock.PluginManager{}\n\tpluginManager.GetPluginError = errors.New(\"plugin should not be invoked when verification plugin is not specified in the signature\")\n\tpluginManager.PluginRunnerLoadError = errors.New(\"plugin should not be invoked when verification plugin is not specified in the signature\")\n\n\tverifier := verifier{\n\t\ttrustPolicyDoc: &policyDocument,\n\t\ttrustStore:     truststore.NewX509TrustStore(dir.ConfigFS()),\n\t\tpluginManager:  pluginManager,\n\t}\n\n\ttests := []struct {\n\t\tmetadata map[string]string\n\t\twantErr  bool\n\t}{\n\t\t{map[string]string{}, false},\n\t\t{map[string]string{\"io.wabbit-networks.buildId\": \"123\"}, false},\n\t\t{map[string]string{\"io.wabbit-networks.buildId\": \"321\"}, true},\n\t\t{map[string]string{\"io.wabbit-networks.buildId\": \"123\", \"io.wabbit-networks.buildTime\": \"1672944615\"}, false},\n\t\t{map[string]string{\"io.wabbit-networks.buildId\": \"123\", \"io.wabbit-networks.buildTime\": \"1\"}, true},\n\t}\n\n\tfor i, tt := range tests {\n\t\tt.Run(strconv.Itoa(i), func(t *testing.T) {\n\t\t\t_, err := verifier.Verify(\n\t\t\t\tcontext.Background(),\n\t\t\t\tmock.MetadataSigEnvDescriptor,\n\t\t\t\tmock.MockSigEnvWithMetadata,\n\t\t\t\tnotation.VerifyOptions{\n\t\t\t\t\tArtifactReference:  mock.SampleArtifactUri,\n\t\t\t\t\tSignatureMediaType: \"application/jose+json\",\n\t\t\t\t\tUserMetadata:       tt.metadata,\n\t\t\t\t},\n\t\t\t)\n\n\t\t\tif tt.wantErr != (err != nil) {\n\t\t\t\tt.Fatalf(\"TestVerifyUserMetadata Error: %q WantErr: %v\", err, tt.wantErr)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestSignaturesRef(t *testing.T) {\n\tsig := \"a==\"\n\tb64sig := \"YT09\"\n\ttests := []struct {\n\t\tdescription string\n\t\tsigRef      string\n\t\tshouldErr   bool\n\t}{\n\t\t{\n\t\t\tdescription: \"raw sig\",\n\t\t\tsigRef:      sig,\n\t\t},\n\t\t{\n\t\t\tdescription: \"encoded sig\",\n\t\t\tsigRef:      b64sig,\n\t\t}, {\n\t\t\tdescription: \"empty ref\",\n\t\t\tshouldErr:   true,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.description, func(t *testing.T) {\n\t\t\tgotSig, err := signatures(test.sigRef, \"\")\n\t\t\tif test.shouldErr && err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif test.shouldErr {\n\t\t\t\tt.Fatal(\"should have received an error\")\n\t\t\t}\n\t\t\tif gotSig != sig {\n\t\t\t\tt.Fatalf(\"unexpected signature, expected: %s got: %s\", sig, gotSig)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (h *backupHandler) ServeHTTP(resp http.ResponseWriter, req *http.Request) {\n\t// Validate before authenticate because the authentication is dependent\n\t// on the state connection that is determined during the validation.\n\tst, err := h.ctxt.stateForRequestAuthenticatedUser(req)\n\tif err != nil {\n\t\th.sendError(resp, err)\n\t\treturn\n\t}\n\tdefer st.Release()\n\n\tif !st.IsController() {\n\t\th.sendError(resp, errors.New(\"requested model is not the controller model\"))\n\t\treturn\n\t}\n\n\tswitch req.Method {\n\tcase \"GET\":\n\t\tlogger.Infof(\"handling backups download request\")\n\t\tmodel, err := st.Model()\n\t\tif err != nil {\n\t\t\th.sendError(resp, err)\n\t\t\treturn\n\t\t}\n\t\tmodelConfig, err := model.ModelConfig()\n\t\tif err != nil {\n\t\t\th.sendError(resp, err)\n\t\t\treturn\n\t\t}\n\t\tbackupDir := modelConfig.BackupDir()\n\t\tif backupDir == \"\" {\n\t\t\tbackupDir = os.TempDir()\n\t\t}\n\n\t\tpaths := &backups.Paths{\n\t\t\tBackupDir: backupDir,\n\t\t}\n\t\tid, err := h.download(newBackups(paths), resp, req)\n\t\tif err != nil {\n\t\t\th.sendError(resp, err)\n\t\t\treturn\n\t\t}\n\t\tlogger.Infof(\"backups download request successful for %q\", id)\n\tdefault:\n\t\th.sendError(resp, errors.MethodNotAllowedf(\"unsupported method: %q\", req.Method))\n\t}\n}", "is_vulnerable": 0}
{"code": "\tvalidate := func(index int, header *types.Header) error {\n\t\tif types.DeriveSha(types.Transactions(txLists[index]), new(trie.Trie)) != header.TxHash {\n\t\t\treturn errInvalidBody\n\t\t}\n\t\tif types.CalcUncleHash(uncleLists[index]) != header.UncleHash {\n\t\t\treturn errInvalidBody\n\t\t}\n\t\treturn nil\n\t}", "is_vulnerable": 0}
{"code": "func TestRuntimeConfiguration(t *testing.T) {\n\ttestCases := []struct {\n\t\tdesc             string\n\t\tserviceConfig    map[string]*dynamic.Service\n\t\trouterConfig     map[string]*dynamic.Router\n\t\tmiddlewareConfig map[string]*dynamic.Middleware\n\t\ttlsOptions       map[string]tls.Options\n\t\texpectedError    int\n\t}{\n\t\t{\n\t\t\tdesc: \"No error\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1:8085\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1:8086\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tHealthCheck: &dynamic.ServerHealthCheck{\n\t\t\t\t\t\t\tInterval: \"500ms\",\n\t\t\t\t\t\t\tPath:     \"/health\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 0,\n\t\t},\n\t\t{\n\t\t\tdesc: \"One router with wrong rule\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"All router with wrong rule\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"WrongRule(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with unknown service\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"wrong-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with broken service\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: nil,\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"admin:admin\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t\"addPrefixTest\": {\n\t\t\t\t\tAddPrefix: &dynamic.AddPrefix{\n\t\t\t\t\t\tPrefix: \"/toto\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"auth\", \"addPrefixTest\"},\n\t\t\t\t},\n\t\t\t\t\"test\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar.other`)\",\n\t\t\t\t\tMiddlewares: []string{\"addPrefixTest\", \"auth\"},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with unknown middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"admin:admin\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"unknown\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with broken middleware\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{\n\t\t\t\t\"auth\": {\n\t\t\t\t\tBasicAuth: &dynamic.BasicAuth{\n\t\t\t\t\t\tUsers: []string{\"foo\"},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tMiddlewares: []string{\"auth\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 2,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with broken tlsOption\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tTLS: &dynamic.RouterTLSConfig{\n\t\t\t\t\t\tOptions: \"broken-tlsOption\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttlsOptions: map[string]tls.Options{\n\t\t\t\t\"broken-tlsOption\": {\n\t\t\t\t\tClientAuth: tls.ClientAuth{\n\t\t\t\t\t\tClientAuthType: \"foobar\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t\t{\n\t\t\tdesc: \"Router with broken default tlsOption\",\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: \"http://127.0.0.1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tmiddlewareConfig: map[string]*dynamic.Middleware{},\n\t\t\trouterConfig: map[string]*dynamic.Router{\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t\tTLS:         &dynamic.RouterTLSConfig{},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttlsOptions: map[string]tls.Options{\n\t\t\t\t\"default\": {\n\t\t\t\t\tClientAuth: tls.ClientAuth{\n\t\t\t\t\t\tClientAuthType: \"foobar\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedError: 1,\n\t\t},\n\t}\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tentryPoints := []string{\"web\"}\n\n\t\t\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\t\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\t\t\tServices:    test.serviceConfig,\n\t\t\t\t\tRouters:     test.routerConfig,\n\t\t\t\t\tMiddlewares: test.middlewareConfig,\n\t\t\t\t},\n\t\t\t\tTLS: &dynamic.TLSConfiguration{\n\t\t\t\t\tOptions: test.tlsOptions,\n\t\t\t\t},\n\t\t\t})\n\n\t\t\troundTripperManager := service.NewRoundTripperManager()\n\t\t\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\t\t\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\t\t\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\t\t\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\t\t\ttlsManager := tls.NewManager()\n\t\t\ttlsManager.UpdateConfigs(context.Background(), nil, test.tlsOptions, nil)\n\n\t\t\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry(), tlsManager)\n\n\t\t\t_ = routerManager.BuildHandlers(context.Background(), entryPoints, false)\n\t\t\t_ = routerManager.BuildHandlers(context.Background(), entryPoints, true)\n\n\t\t\t// even though rtConf was passed by argument to the manager builders above,\n\t\t\t// it's ok to use it as the result we check, because everything worth checking\n\t\t\t// can be accessed by pointers in it.\n\t\t\tvar allErrors int\n\t\t\tfor _, v := range rtConf.Services {\n\t\t\t\tif v.Err != nil {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, v := range rtConf.Routers {\n\t\t\t\tif len(v.Err) > 0 {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, v := range rtConf.Middlewares {\n\t\t\t\tif v.Err != nil {\n\t\t\t\t\tallErrors++\n\t\t\t\t}\n\t\t\t}\n\t\t\tassert.Equal(t, test.expectedError, allErrors)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestGetIntAnnotation(t *testing.T) {\n\ting := buildIngress()\n\n\t_, err := GetIntAnnotation(\"\", nil, nil)\n\tif err == nil {\n\t\tt.Errorf(\"expected error but retuned nil\")\n\t}\n\n\ttests := []struct {\n\t\tname   string\n\t\tfield  string\n\t\tvalue  string\n\t\texp    int\n\t\texpErr bool\n\t}{\n\t\t{\"valid - A\", \"string\", \"1\", 1, false},\n\t\t{\"valid - B\", \"string\", \"2\", 2, false},\n\t}\n\n\tdata := map[string]string{}\n\ting.SetAnnotations(data)\n\n\tfor _, test := range tests {\n\t\tdata[GetAnnotationWithPrefix(test.field)] = test.value\n\n\t\ts, err := GetIntAnnotation(test.field, ing, nil)\n\t\tif test.expErr {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"%v: expected error but retuned nil\", test.name)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif s != test.exp {\n\t\t\tt.Errorf(\"%v: expected \\\"%v\\\" but \\\"%v\\\" was returned\", test.name, test.exp, s)\n\t\t}\n\n\t\tdelete(data, test.field)\n\t}\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tcmdFunc = unsquashfsCmd\n}", "is_vulnerable": 0}
{"code": "func (i *Identity) SSHClientConfig(fips bool) (*ssh.ClientConfig, error) {\n\tcallback, err := apisshutils.NewHostKeyCallback(\n\t\tapisshutils.HostKeyCallbackConfig{\n\t\t\tGetHostCheckers: i.getSSHCheckers,\n\t\t\tFIPS:            fips,\n\t\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn &ssh.ClientConfig{\n\t\tUser:            i.ID.HostUUID,\n\t\tAuth:            []ssh.AuthMethod{ssh.PublicKeys(i.KeySigner)},\n\t\tHostKeyCallback: callback,\n\t\tTimeout:         apidefaults.DefaultDialTimeout,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (odr *testOdr) Retrieve(ctx context.Context, req OdrRequest) error {\n\tif odr.disable {\n\t\treturn ErrOdrDisabled\n\t}\n\tswitch req := req.(type) {\n\tcase *BlockRequest:\n\t\tnumber := rawdb.ReadHeaderNumber(odr.sdb, req.Hash)\n\t\tif number != nil {\n\t\t\treq.Rlp = rawdb.ReadBodyRLP(odr.sdb, req.Hash, *number)\n\t\t}\n\tcase *ReceiptsRequest:\n\t\tnumber := rawdb.ReadHeaderNumber(odr.sdb, req.Hash)\n\t\tif number != nil {\n\t\t\treq.Receipts = rawdb.ReadRawReceipts(odr.sdb, req.Hash, *number)\n\t\t}\n\tcase *TrieRequest:\n\t\tt, _ := trie.New(req.Id.Root, trie.NewDatabase(odr.sdb))\n\t\tnodes := NewNodeSet()\n\t\tt.Prove(req.Key, 0, nodes)\n\t\treq.Proof = nodes\n\tcase *CodeRequest:\n\t\treq.Data, _ = odr.sdb.Get(req.Hash[:])\n\t}\n\treq.StoreResult(odr.ldb)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestValidateWebRoot(t *testing.T) {\n\t// create a base config that we know is valid\n\trand.Seed(time.Now().UnixNano())\n\tconf := config.NewConfig()\n\tconf.LoginToken.SigningKey = util.RandomString(10)\n\tconf.Server.StaticContentRootDirectory = \".\"\n\tconf.Auth.Strategy = \"anonymous\"\n\n\t// now test some web roots, both valid ones and invalid ones\n\tvalidWebRoots := []string{\n\t\t\"/\",\n\t\t\"/kiali\",\n\t\t\"/abc/clustername/api/v1/namespaces/istio-system/services/kiali:80/proxy/kiali\",\n\t\t\"/a/0/-/./_/~/!/$/&/'/(/)/*/+/,/;/=/:/@/%aa\",\n\t\t\"/kiali0-._~!$&'()*+,;=:@%aa\",\n\t}\n\tinvalidWebRoots := []string{\n\t\t\"/kiali/\",\n\t\t\"kiali/\",\n\t\t\"/^kiali\",\n\t\t\"/foo/../bar\",\n\t\t\"/../bar\",\n\t\t\"../bar\",\n\t}\n\n\tfor _, webroot := range validWebRoots {\n\t\tconf.Server.WebRoot = webroot\n\t\tconfig.Set(conf)\n\t\tif err := validateConfig(); err != nil {\n\t\t\tt.Errorf(\"Web root validation should have succeeded for [%v]: %v\", conf.Server.WebRoot, err)\n\t\t}\n\t}\n\n\tfor _, webroot := range invalidWebRoots {\n\t\tconf.Server.WebRoot = webroot\n\t\tconfig.Set(conf)\n\t\tif err := validateConfig(); err == nil {\n\t\t\tt.Errorf(\"Web root validation should have failed [%v]\", conf.Server.WebRoot)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (a *Agent) connect() (conn *ssh.Client, err error) {\n\tfor _, authMethod := range a.authMethods {\n\t\t// Create a dialer (that respects HTTP proxies) and connect to remote host.\n\t\tdialer := proxy.DialerFromEnvironment(a.Addr.Addr)\n\t\tpconn, err := dialer.DialTimeout(a.Addr.AddrNetwork, a.Addr.Addr, defaults.DefaultDialTimeout)\n\t\tif err != nil {\n\t\t\ta.Debugf(\"Dial to %v failed: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tcallback, err := sshutils.NewHostKeyCallback(\n\t\t\tsshutils.HostKeyCallbackConfig{\n\t\t\t\tGetHostCheckers: a.getHostCheckers,\n\t\t\t\tOnCheckCert: func(cert *ssh.Certificate) {\n\t\t\t\t\ta.setPrincipals(cert.ValidPrincipals)\n\t\t\t\t},\n\t\t\t\tFIPS: a.FIPS,\n\t\t\t})\n\t\tif err != nil {\n\t\t\ta.Debugf(\"Failed to create host key callback for %v: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Build a new client connection. This is done to get access to incoming\n\t\t// global requests which dialer.Dial would not provide.\n\t\tconn, chans, reqs, err := ssh.NewClientConn(pconn, a.Addr.Addr, &ssh.ClientConfig{\n\t\t\tUser:            a.Username,\n\t\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\t\tHostKeyCallback: callback,\n\t\t\tTimeout:         defaults.DefaultDialTimeout,\n\t\t})\n\t\tif err != nil {\n\t\t\ta.Debugf(\"Failed to create client to %v: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create an empty channel and close it right away. This will prevent\n\t\t// ssh.NewClient from attempting to process any incoming requests.\n\t\temptyCh := make(chan *ssh.Request)\n\t\tclose(emptyCh)\n\n\t\tclient := ssh.NewClient(conn, chans, emptyCh)\n\n\t\t// Start a goroutine to process global requests from the server.\n\t\tgo a.handleGlobalRequests(a.ctx, reqs)\n\n\t\treturn client, nil\n\t}\n\treturn nil, trace.BadParameter(\"failed to dial: all auth methods failed\")\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) PivotGraph(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.PivotGraph, error) {\n\tout := new(clientpb.PivotGraph)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/PivotGraph\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(\"Not signed in should return 404\", func(t *testing.T) {\n\t\t\tcmd := &dashboardimport.ImportDashboardRequest{}\n\t\t\tjsonBytes, err := json.Marshal(cmd)\n\t\t\trequire.NoError(t, err)\n\t\t\treq := s.NewRequest(http.MethodPost, \"/api/dashboards/import\", bytes.NewReader(jsonBytes))\n\t\t\treq.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tresp, err := s.Send(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\trequire.Equal(t, http.StatusUnauthorized, resp.StatusCode)\n\t\t})", "is_vulnerable": 0}
{"code": "\tt.Cleanup(func() { authServer.Close() })", "is_vulnerable": 0}
{"code": "func sendBody(inURL string, header http.Header) bool {\n\tu, err := url.Parse(inURL)\n\t// Assume no if the URL cannot be parsed - an empty request will still be forwarded to the plugin and should be rejected\n\tif err != nil {\n\t\treturn false\n\t}\n\n\t// Skip body for auth endpoint\n\tisAuth, err := isAuthEndpoint(u.Path)\n\tif isAuth || err != nil {\n\t\treturn false\n\t}\n\n\t// body is sent only for text or json messages\n\tcontentType, _, err := mime.ParseMediaType(header.Get(\"Content-Type\"))\n\tif err != nil {\n\t\treturn false\n\t}\n\n\treturn contentType == \"application/json\"\n}", "is_vulnerable": 0}
{"code": "func changeOnExec(name string) error {\n\tvalue := \"exec \" + name\n\tif err := setprocattr(\"exec\", value); err != nil {\n\t\treturn fmt.Errorf(\"apparmor failed to apply profile: %s\", err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func maskFields(b []byte, fieldNames []string) ([]byte, error) {\n\tvar data map[string]interface{}\n\n\tif err := json.Unmarshal(b, &data); err != nil {\n\t\treturn nil, err\n\t}\n\n\tmask(data, fieldNames)\n\n\t// MarshalIndent is used to make the output more readable.\n\treturn json.MarshalIndent(data, \"\", ident)\n}", "is_vulnerable": 0}
{"code": "func mdFilepath(mdFilename string) string {\n\treturn filepath.Clean(filepath.Join(\"/\", fmt.Sprintf(\"%s.md\", mdFilename)))\n}", "is_vulnerable": 0}
{"code": "func (q *ListObjectsQuery) evaluate(\n\tctx context.Context,\n\treq listObjectsRequest,\n\tresultsChan chan<- ListObjectsResult,\n\tmaxResults uint32,\n\tresolutionMetadata *reverseexpand.ResolutionMetadata,\n) error {\n\n\ttargetObjectType := req.GetType()\n\ttargetRelation := req.GetRelation()\n\n\ttypesys, ok := typesystem.TypesystemFromContext(ctx)\n\tif !ok {\n\t\tpanic(\"typesystem missing in context\")\n\t}\n\n\tif !typesystem.IsSchemaVersionSupported(typesys.GetSchemaVersion()) {\n\t\treturn serverErrors.ValidationError(typesystem.ErrInvalidSchemaVersion)\n\t}\n\n\tfor _, ctxTuple := range req.GetContextualTuples().GetTupleKeys() {\n\t\tif err := validation.ValidateTuple(typesys, ctxTuple); err != nil {\n\t\t\treturn serverErrors.HandleTupleValidateError(err)\n\t\t}\n\t}\n\n\t_, err := typesys.GetRelation(targetObjectType, targetRelation)\n\tif err != nil {\n\t\tif errors.Is(err, typesystem.ErrObjectTypeUndefined) {\n\t\t\treturn serverErrors.TypeNotFound(targetObjectType)\n\t\t}\n\n\t\tif errors.Is(err, typesystem.ErrRelationUndefined) {\n\t\t\treturn serverErrors.RelationNotFound(targetRelation, targetObjectType, nil)\n\t\t}\n\n\t\treturn serverErrors.NewInternalError(\"\", err)\n\t}\n\n\tif err := validation.ValidateUser(typesys, req.GetUser()); err != nil {\n\t\treturn serverErrors.ValidationError(fmt.Errorf(\"invalid 'user' value: %s\", err))\n\t}\n\n\thandler := func() {\n\t\tuserObj, userRel := tuple.SplitObjectRelation(req.GetUser())\n\t\tuserObjType, userObjID := tuple.SplitObject(userObj)\n\n\t\tvar sourceUserRef reverseexpand.IsUserRef\n\t\tsourceUserRef = &reverseexpand.UserRefObject{\n\t\t\tObject: &openfgav1.Object{\n\t\t\t\tType: userObjType,\n\t\t\t\tId:   userObjID,\n\t\t\t},\n\t\t}\n\n\t\tif tuple.IsTypedWildcard(userObj) {\n\t\t\tsourceUserRef = &reverseexpand.UserRefTypedWildcard{Type: tuple.GetType(userObj)}\n\n\t\t}\n\n\t\tif userRel != \"\" {\n\t\t\tsourceUserRef = &reverseexpand.UserRefObjectRelation{\n\t\t\t\tObjectRelation: &openfgav1.ObjectRelation{\n\t\t\t\t\tObject:   userObj,\n\t\t\t\t\tRelation: userRel,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treverseExpandResultsChan := make(chan *reverseexpand.ReverseExpandResult, 1)\n\t\tvar objectsFound = new(uint32)\n\n\t\treverseExpandQuery := reverseexpand.NewReverseExpandQuery(q.datastore, typesys,\n\t\t\treverseexpand.WithResolveNodeLimit(q.resolveNodeLimit),\n\t\t\treverseexpand.WithResolveNodeBreadthLimit(q.resolveNodeBreadthLimit),\n\t\t)\n\n\t\tgo func() {\n\t\t\terr = reverseExpandQuery.Execute(ctx, &reverseexpand.ReverseExpandRequest{\n\t\t\t\tStoreID:          req.GetStoreId(),\n\t\t\t\tObjectType:       targetObjectType,\n\t\t\t\tRelation:         targetRelation,\n\t\t\t\tUser:             sourceUserRef,\n\t\t\t\tContextualTuples: req.GetContextualTuples().GetTupleKeys(),\n\t\t\t}, reverseExpandResultsChan, resolutionMetadata)\n\t\t\tif err != nil {\n\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t}\n\n\t\t\t// this is necessary to terminate the range loop below\n\t\t\tclose(reverseExpandResultsChan)\n\t\t}()\n\n\t\tcheckResolver := graph.NewLocalChecker(\n\t\t\tstoragewrappers.NewCombinedTupleReader(q.datastore, req.GetContextualTuples().GetTupleKeys()),\n\t\t\tq.checkOptions...,\n\t\t)\n\t\tdefer checkResolver.Close()\n\n\t\tconcurrencyLimiterCh := make(chan struct{}, q.resolveNodeBreadthLimit)\n\n\t\twg := sync.WaitGroup{}\n\n\t\tfor res := range reverseExpandResultsChan {\n\t\t\tif atomic.LoadUint32(objectsFound) >= maxResults {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif res.ResultStatus == reverseexpand.NoFurtherEvalStatus {\n\t\t\t\tnoFurtherEvalRequiredCounter.Inc()\n\t\t\t\ttrySendObject(res.Object, objectsFound, maxResults, resultsChan)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfurtherEvalRequiredCounter.Inc()\n\n\t\t\twg.Add(1)\n\t\t\tgo func(res *reverseexpand.ReverseExpandResult) {\n\t\t\t\tdefer func() {\n\t\t\t\t\t<-concurrencyLimiterCh\n\t\t\t\t\twg.Done()\n\t\t\t\t}()\n\n\t\t\t\tconcurrencyLimiterCh <- struct{}{}\n\n\t\t\t\tresp, err := checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\t\t\t\tStoreID:              req.GetStoreId(),\n\t\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\t\t\t\tTupleKey:             tuple.NewTupleKey(res.Object, req.GetRelation(), req.GetUser()),\n\t\t\t\t\tContextualTuples:     req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\t\tResolutionMetadata: &graph.ResolutionMetadata{\n\t\t\t\t\t\tDepth: q.resolveNodeLimit,\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t\tif err != nil {\n\t\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\n\t\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tatomic.AddUint32(resolutionMetadata.QueryCount, resp.GetResolutionMetadata().DatastoreQueryCount)\n\n\t\t\t\tif resp.Allowed {\n\t\t\t\t\ttrySendObject(res.Object, objectsFound, maxResults, resultsChan)\n\t\t\t\t}\n\t\t\t}(res)\n\t\t}\n\n\t\twg.Wait()\n\n\t\tclose(resultsChan)\n\t}\n\n\tgo handler()\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func NewDecoder() *Decoder {\n\treturn &Decoder{cache: newCache()}\n}", "is_vulnerable": 1}
{"code": "func ReadMessageFromTunnel(r io.Reader) (*Message, error) {\n\tbuf := bufio.NewReader(r)\n\tconnectID, err := binary.ReadUvarint(buf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmessageType, err := binary.ReadUvarint(buf)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdata, err := io.ReadAll(io.LimitReader(buf, constants.MaxRespBodyLength))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklog.V(6).Infof(\"Receive Tunnel message connectID %d messageType %s data:%v string:[%v]\",\n\t\tconnectID, MessageType(messageType), data, string(data))\n\treturn &Message{\n\t\tConnectID:   connectID,\n\t\tMessageType: MessageType(messageType),\n\t\tData:        data,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (iv *ImageVerifier) verifyAttestation(statements []map[string]interface{}, attestation kyvernov1.Attestation, imageInfo apiutils.ImageInfo) error {\n\tif attestation.Type == \"\" && attestation.PredicateType == \"\" {\n\t\treturn fmt.Errorf(\"a type is required\")\n\t}\n\timage := imageInfo.String()\n\tstatementsByPredicate, types := buildStatementMap(statements)\n\tiv.logger.V(4).Info(\"checking attestations\", \"predicates\", types, \"image\", image)\n\tstatements = statementsByPredicate[attestation.Type]\n\tif statements == nil {\n\t\tiv.logger.Info(\"no attestations found for predicate\", \"type\", attestation.Type, \"predicates\", types, \"image\", imageInfo.String())\n\t\treturn fmt.Errorf(\"attestions not found for predicate type %s\", attestation.Type)\n\t}\n\tfor _, s := range statements {\n\t\tiv.logger.Info(\"checking attestation\", \"predicates\", types, \"image\", imageInfo.String())\n\t\tval, msg, err := iv.checkAttestations(attestation, s)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to check attestations: %w\", err)\n\t\t}\n\t\tif !val {\n\t\t\treturn fmt.Errorf(\"attestation checks failed for %s and predicate %s: %s\", imageInfo.String(), attestation.Type, msg)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func init() {\n\thttpGetter := &HttpGetter{\n\t\tNetrc: true,\n\t}\n\n\t// The order of the Getters in the list may affect the result\n\t// depending if the Request.Src is detected as valid by multiple getters\n\tGetters = []Getter{\n\t\t&GitGetter{[]Detector{\n\t\t\tnew(GitHubDetector),\n\t\t\tnew(GitDetector),\n\t\t\tnew(BitBucketDetector),\n\t\t\tnew(GitLabDetector),\n\t\t},\n\t\t},\n\t\tnew(HgGetter),\n\t\tnew(SmbClientGetter),\n\t\tnew(SmbMountGetter),\n\t\thttpGetter,\n\t\tnew(FileGetter),\n\t}\n}", "is_vulnerable": 1}
{"code": "func (future *MoveResourcesFuture) Result(client Client) (ar autorest.Response, err error) {\n\tvar done bool\n\tdone, err = future.Done(client)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.MoveResourcesFuture\", \"Result\", future.Response(), \"Polling failure\")\n\t\treturn\n\t}\n\tif !done {\n\t\terr = azure.NewAsyncOpIncompleteError(\"resources.MoveResourcesFuture\")\n\t\treturn\n\t}\n\tar.Response = future.Response()\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestStrictKEXResetSeqSuccessiveKEX(t *testing.T) {\n\tif runtime.GOOS == \"plan9\" {\n\t\tt.Skip(\"see golang.org/issue/7237\")\n\t}\n\n\tchecker := &syncChecker{\n\t\twaitCall: make(chan int, 10),\n\t\tcalled:   make(chan int, 10),\n\t}\n\n\tchecker.waitCall <- 1\n\ttrC, trS, err := handshakePair(&ClientConfig{HostKeyCallback: checker.Check}, \"addr\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"handshakePair: %v\", err)\n\t}\n\t<-checker.called\n\n\tt.Cleanup(func() {\n\t\ttrC.Close()\n\t\ttrS.Close()\n\t})\n\n\t// Throw away the msgExtInfo packet sent during the handshake by the server\n\t_, err = trC.readPacket()\n\tif err != nil {\n\t\tt.Fatalf(\"readPacket failed: %s\", err)\n\t}\n\n\t// write and read five packets on either side to bump the sequence numbers\n\tfor i := 0; i < 5; i++ {\n\t\tif err := trC.writePacket([]byte{msgRequestSuccess}); err != nil {\n\t\t\tt.Fatalf(\"writePacket failed: %s\", err)\n\t\t}\n\t\tif _, err := trS.readPacket(); err != nil {\n\t\t\tt.Fatalf(\"readPacket failed: %s\", err)\n\t\t}\n\t\tif err := trS.writePacket([]byte{msgRequestSuccess}); err != nil {\n\t\t\tt.Fatalf(\"writePacket failed: %s\", err)\n\t\t}\n\t\tif _, err := trC.readPacket(); err != nil {\n\t\t\tt.Fatalf(\"readPacket failed: %s\", err)\n\t\t}\n\t}\n\n\t// Request a key exchange, which should cause the sequence numbers to reset\n\tchecker.waitCall <- 1\n\ttrC.requestKeyExchange()\n\t<-checker.called\n\n\t// write a packet on the client, and then read it, to verify the key change has actually happened, since\n\t// the HostKeyCallback is called _during_ the handshake, so isn't actually indicative of the handshake\n\t// finishing.\n\tdummyPacket := []byte{99}\n\tif err := trS.writePacket(dummyPacket); err != nil {\n\t\tt.Fatalf(\"writePacket failed: %s\", err)\n\t}\n\tif p, err := trC.readPacket(); err != nil {\n\t\tt.Fatalf(\"readPacket failed: %s\", err)\n\t} else if !bytes.Equal(p, dummyPacket) {\n\t\tt.Fatalf(\"unexpected packet: got %x, want %x\", p, dummyPacket)\n\t}\n\n\t// close the handshake transports before checking the sequence number to\n\t// avoid races.\n\ttrC.Close()\n\ttrS.Close()\n\n\tif trC.conn.(*transport).reader.seqNum != 2 || trC.conn.(*transport).writer.seqNum != 0 ||\n\t\ttrS.conn.(*transport).reader.seqNum != 1 || trS.conn.(*transport).writer.seqNum != 1 {\n\t\tt.Errorf(\n\t\t\t\"unexpected sequence counters:\\nclient: reader %d (expected 2), writer %d (expected 0)\\nserver: reader %d (expected 1), writer %d (expected 1)\",\n\t\t\ttrC.conn.(*transport).reader.seqNum,\n\t\t\ttrC.conn.(*transport).writer.seqNum,\n\t\t\ttrS.conn.(*transport).reader.seqNum,\n\t\t\ttrS.conn.(*transport).writer.seqNum,\n\t\t)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleMkcol(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\treqPath, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\trelease, status, err := h.confirmLocks(r, reqPath, \"\")\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\treqPath, err = user.JoinPath(reqPath)\n\tif err != nil {\n\t\treturn 403, err\n\t}\n\n\tif r.ContentLength > 0 {\n\t\treturn http.StatusUnsupportedMediaType, nil\n\t}\n\tif err := fs.MakeDir(ctx, reqPath); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn http.StatusConflict, err\n\t\t}\n\t\treturn http.StatusMethodNotAllowed, err\n\t}\n\tfs.ClearCache(path.Dir(reqPath))\n\treturn http.StatusCreated, nil\n}", "is_vulnerable": 0}
{"code": "func TestArtifactUploadBlobUnsafePath(t *testing.T) {\n\tassert := assert.New(t)\n\n\tvar memfs = fstest.MapFS(map[string]*fstest.MapFile{})\n\n\trouter := httprouter.New()\n\tuploads(router, \"artifact/server/path\", writeMapFS{memfs})\n\n\treq, _ := http.NewRequest(\"PUT\", \"http://localhost/upload/1?itemPath=../../some/file\", strings.NewReader(\"content\"))\n\trr := httptest.NewRecorder()\n\n\trouter.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tassert.Fail(\"Wrong status\")\n\t}\n\n\tresponse := ResponseMessage{}\n\terr := json.Unmarshal(rr.Body.Bytes(), &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tassert.Equal(\"success\", response.Message)\n\tassert.Equal(\"content\", string(memfs[\"artifact/server/path/1/some/file\"].Data))\n}", "is_vulnerable": 0}
{"code": "func (g *Git) LsRemote(branch string, commit string) (string, error) {\n\tif changed, err := g.remoteSHAChanged(branch, commit); err != nil || !changed {\n\t\treturn commit, err\n\t}\n\n\toutput := &bytes.Buffer{}\n\tif err := g.gitCmd(output, \"ls-remote\", \"--\", g.URL, formatRefForBranch(branch)); err != nil {\n\t\treturn \"\", err\n\t}\n\n\tvar lines []string\n\ts := bufio.NewScanner(output)\n\tfor s.Scan() {\n\t\tlines = append(lines, s.Text())\n\t}\n\n\treturn firstField(lines, fmt.Sprintf(\"no commit for branch: %s\", branch))\n}", "is_vulnerable": 0}
{"code": "func NewParser(resolver resolver.Resolver) parser.IngressAnnotation {\n\treturn modSecurity{resolver}\n}", "is_vulnerable": 1}
{"code": "\t\tconnConstructor: func(ctx context.Context, token auth.Token) (gitpod.APIInterface, error) {\n\t\t\topts := gitpod.ConnectToServerOpts{\n\t\t\t\t// We're using Background context as we want the connection to persist beyond the lifecycle of a single request\n\t\t\t\tContext: context.Background(),\n\t\t\t\tLog:     log.Log,\n\t\t\t\tOrigin:  origin.FromContext(ctx),\n\t\t\t\tCloseHandler: func(_ error) {\n\t\t\t\t\tcache.Remove(token)\n\t\t\t\t\tconnectionPoolSize.Dec()\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tswitch token.Type {\n\t\t\tcase auth.AccessTokenType:\n\t\t\t\topts.Token = token.Value\n\t\t\tcase auth.CookieTokenType:\n\t\t\t\topts.Cookie = token.Value\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.New(\"unknown token type\")\n\t\t\t}\n\n\t\t\tendpoint, err := getEndpointBasedOnToken(token, address)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to construct endpoint: %w\", err)\n\t\t\t}\n\n\t\t\tconn, err := gitpod.ConnectToServer(endpoint, opts)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to create new connection to server: %w\", err)\n\t\t\t}\n\n\t\t\treturn conn, nil\n\t\t},", "is_vulnerable": 0}
{"code": "func Dup2(oldfd, newfd int) error {\n\t// Android O and newer blocks dup2; riscv and arm64 don't implement dup2.\n\tif runtime.GOOS == \"android\" || runtime.GOARCH == \"riscv64\" || runtime.GOARCH == \"arm64\" {\n\t\treturn Dup3(oldfd, newfd, 0)\n\t}\n\treturn dup2(oldfd, newfd)\n}", "is_vulnerable": 1}
{"code": "func (s *TestSuite) TestDecrypt_PBSE2_HS512_A256KW_A256CBC_HS512_MaxIterationViolation(c *C) {\n\t//given\n\tpbes2Hs512 := DeregisterJwa(PBES2_HS512_A256KW)\n\tRegisterJwa(NewPbse2HmacAesKWAlg(256, 8000, 0))\n\ttoken := \"eyJhbGciOiJQQkVTMi1IUzUxMitBMjU2S1ciLCJlbmMiOiJBMjU2Q0JDLUhTNTEyIiwicDJjIjo4MTkyLCJwMnMiOiJCUlkxQ1M3VXNpaTZJNzhkIn0.ovjAL7yRnB_XdJbK8lAaUDRZ-CyVeio8f4pnqOt1FPj1PoQAdEX3S5x6DlzR8aqN_WR5LUwdqDSyUDYhSurnmq8VLfzd3AEe.YAjH6g_zekXJIlPN4Ooo5Q.tutaltxpeVyayXZ9pQovGXTWTf_GWWvtu25Jeg9jgoH0sUX9KCnL00A69e4GJR6EMxalmWsa45AItffbwjUBmwdyklC4ZbTgaovVRs-UwqsZFBO2fpEb7qLajjwra7o4OegzgXDD0jhrKrUusvRWGBvenvumb5euibUxmIfBUcVF1JbdfYxx7ztFeS-QKJpDkE00zyEkViq-QxfrMVl5p7LGmTz8hMrFL3LXLokypZSDgFBfsUzChJf3mlYzxiGaGUqhs7NksQJDoUYf6prPow.XwRVfVTTPogO74RnxZD_9Mse26fTSehna1pbWy4VHfY\"\n\n\t//when\n\ttest, headers, err := Decode(token, \"top secret\")\n\tfmt.Printf(\"\\np2c max iteration err= %v\\n\", err)\n\n\t//then\n\tRegisterJwa(pbes2Hs512)\n\tc.Assert(err, NotNil)\n\tc.Assert(test, Equals, \"\")\n\tc.Assert(headers, IsNil)\n}", "is_vulnerable": 0}
{"code": "func TestOptionIdent(t *testing.T) {\n\trequire.Equal(t, \"WithCEK\", identCEK{}.String())\n\trequire.Equal(t, \"WithCompress\", identCompress{}.String())\n\trequire.Equal(t, \"WithContentEncryption\", identContentEncryptionAlgorithm{}.String())\n\trequire.Equal(t, \"WithFS\", identFS{}.String())\n\trequire.Equal(t, \"WithKey\", identKey{}.String())\n\trequire.Equal(t, \"WithKeyProvider\", identKeyProvider{}.String())\n\trequire.Equal(t, \"WithKeyUsed\", identKeyUsed{}.String())\n\trequire.Equal(t, \"WithMaxPBES2Count\", identMaxPBES2Count{}.String())\n\trequire.Equal(t, \"WithMergeProtectedHeaders\", identMergeProtectedHeaders{}.String())\n\trequire.Equal(t, \"WithMessage\", identMessage{}.String())\n\trequire.Equal(t, \"WithPerRecipientHeaders\", identPerRecipientHeaders{}.String())\n\trequire.Equal(t, \"WithPretty\", identPretty{}.String())\n\trequire.Equal(t, \"WithProtectedHeaders\", identProtectedHeaders{}.String())\n\trequire.Equal(t, \"WithRequireKid\", identRequireKid{}.String())\n\trequire.Equal(t, \"WithSerialization\", identSerialization{}.String())\n}", "is_vulnerable": 0}
{"code": "func (u systemInfoServiceImpl) Init(ctx context.Context) error {\n\tinfo, err := u.Get(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsignedKey = info.SignedKey\n\t_, err = initDexConfig(ctx, u.KubeClient, \"http://velaux.com\")\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (t *Teler) checkCustomRules(r *http.Request) error {\n\t// Converts map of headers to RAW string\n\theaders := headersToRawString(r.Header)\n\n\t// Decode the URL-encoded and unescape HTML entities request URI of the URL\n\turi := stringDeUnescape(r.URL.RequestURI())\n\n\t// Declare byte slice for request body.\n\tvar body string\n\n\t// Initialize buffer to hold request body.\n\tbuf := &bytes.Buffer{}\n\n\t// Use io.Copy to copy the request body to the buffer.\n\t_, err := io.Copy(buf, r.Body)\n\tif err == nil {\n\t\t// If the read not fails, replace the request body\n\t\t// with a new io.ReadCloser that reads from the buffer.\n\t\tr.Body = io.NopCloser(buf)\n\n\t\t// Convert the buffer to a string.\n\t\tbody = buf.String()\n\t}\n\n\t// Decode the URL-encoded and unescape HTML entities of body\n\tbody = stringDeUnescape(body)\n\n\t// Iterate over the Customs field of the Teler struct, which is a slice of custom rules\n\tfor _, rule := range t.opt.Customs {\n\t\t// Initialize the found match counter to zero\n\t\tf := 0\n\n\t\t// Iterate over the Rules field of the current custom rule, which is a slice of rule conditions\n\t\tfor _, cond := range rule.Rules {\n\t\t\tok := false\n\n\t\t\t// Check if the Method field of the current rule condition matches the request method\n\t\t\t// If the Method field is ALL, match any request method\n\t\t\tswitch {\n\t\t\tcase cond.Method == request.ALL:\n\t\t\tcase string(cond.Method) == r.Method:\n\t\t\t\tok = true\n\t\t\t}\n\n\t\t\t// If the request method doesn't match, skip the current rule condition\n\t\t\tif !ok {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tok = false\n\n\t\t\t// Get the compiled regex pattern for the current rule condition\n\t\t\tpattern := cond.patternRegex\n\n\t\t\t// Check if the Element field of the current rule condition matches the request URI, headers, body, or any of them\n\t\t\t// If it matches, set ok to true\n\t\t\tswitch cond.Element {\n\t\t\tcase request.URI:\n\t\t\t\tok = pattern.MatchString(uri)\n\t\t\tcase request.Headers:\n\t\t\t\tok = pattern.MatchString(headers)\n\t\t\tcase request.Body:\n\t\t\t\tok = pattern.MatchString(body)\n\t\t\tcase request.Any:\n\t\t\t\tok = (pattern.MatchString(uri) || pattern.MatchString(headers) || pattern.MatchString(body))\n\t\t\t}\n\n\t\t\t// If the rule condition is satisfied, increment the found match counter\n\t\t\tif ok {\n\t\t\t\t// If the rule condition \"or\", return an error with the Name field of the custom rule as the message\n\t\t\t\t// If the rule condition is \"and\", increment the found match counter\n\t\t\t\tswitch rule.Condition {\n\t\t\t\tcase \"or\":\n\t\t\t\t\treturn errors.New(rule.Name)\n\t\t\t\tcase \"and\":\n\t\t\t\t\tf++\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// If the rule condition is \"and\", and number of found matches is equal to the number of rule conditions,\n\t\t// return an error with the Name field of the custom rule as the message\n\t\tif rule.Condition == \"and\" && f >= len(rule.Rules) {\n\t\t\treturn errors.New(rule.Name)\n\t\t}\n\t}\n\n\t// If no custom rules were violated, return nil\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func unsetSyncRunningOperationState(t *testing.T, appServer *Server) {\n\tappIf := appServer.appclientset.ArgoprojV1alpha1().Applications(\"default\")\n\tapp, err := appIf.Get(context.Background(), \"test\", metav1.GetOptions{})\n\trequire.NoError(t, err)\n\tapp.Operation = nil\n\tapp.Status.OperationState = nil\n\t_, err = appIf.Update(context.Background(), app, metav1.UpdateOptions{})\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func (t *TestServerStream) SetHeader(metadata.MD) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tctx, cancel := context.WithCancel(context.Background())\n\t\t\tdefer cancel()\n\n\t\t\tln := testHttpServerWithXTerraformGetConfiguredGettersBypass(t)\n\n\t\t\tvar u url.URL\n\t\t\tu.Scheme = \"http\"\n\t\t\tu.Host = ln.Addr().String()\n\t\t\tu.Path = \"/start\"\n\n\t\t\tdst := testing_helper.TempDir(t)\n\n\t\t\trt := hookableHTTPRoundTripper{\n\t\t\t\tbefore: func(req *http.Request) {\n\t\t\t\t\tt.Logf(\"making request\")\n\t\t\t\t},\n\t\t\t\tRoundTripper: http.DefaultTransport,\n\t\t\t}\n\n\t\t\tg := new(HttpGetter)\n\t\t\tg.XTerraformGetLimit = 10\n\t\t\tg.Client = &http.Client{\n\t\t\t\tTransport: &rt,\n\t\t\t}\n\n\t\t\tclient := &Client{\n\t\t\t\tGetters: []Getter{g},\n\t\t\t}\n\t\t\tclient.Getters = append(client.Getters, tt.configuredGetters...)\n\n\t\t\tt.Logf(\"%v\", u.String())\n\n\t\t\treq := Request{\n\t\t\t\tDst:     dst,\n\t\t\t\tSrc:     u.String(),\n\t\t\t\tGetMode: ModeDir,\n\t\t\t}\n\n\t\t\t_, err := client.Get(ctx, &req)\n\t\t\t// For configured getters that support git, the git repository doesn't exist so error will not be nil.\n\t\t\t// If we get a nil error when we expect one other than the git error git exited with -1 we should fail.\n\t\t\tif tt.errExpected && err == nil {\n\t\t\t\tt.Fatalf(\"error expected\")\n\t\t\t}\n\t\t\t// We only care about the error messages that indicate that we can download the git header URL\n\t\t\tif tt.errExpected && err != nil {\n\t\t\t\tif !strings.Contains(err.Error(), \"download not supported for scheme\") {\n\t\t\t\t\tt.Fatalf(\"expected download not supported for scheme, got: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func NewReader(src io.Reader, size int64, md5Hex, sha256Hex string) (*Reader, error) {\n\tif _, ok := src.(*Reader); ok {\n\t\treturn nil, errNestedReader\n\t}\n\n\tsha256sum, err := hex.DecodeString(sha256Hex)\n\tif err != nil {\n\t\treturn nil, SHA256Mismatch{}\n\t}\n\n\tmd5sum, err := hex.DecodeString(md5Hex)\n\tif err != nil {\n\t\treturn nil, BadDigest{}\n\t}\n\n\tvar sha256Hash hash.Hash\n\tif len(sha256sum) != 0 {\n\t\tsha256Hash = sha256.New()\n\t}\n\n\treturn &Reader{\n\t\tmd5sum:     md5sum,\n\t\tsha256sum:  sha256sum,\n\t\tsrc:        io.LimitReader(src, size),\n\t\tsize:       size,\n\t\tmd5Hash:    md5.New(),\n\t\tsha256Hash: sha256Hash,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func saveAdminTOTPConfig(username string, r *http.Request, recoveryCodes []dataprovider.RecoveryCode) error {\n\tadmin, err := dataprovider.AdminExists(username)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcurrentTOTPSecret := admin.Filters.TOTPConfig.Secret\n\tadmin.Filters.TOTPConfig.Secret = nil\n\terr = render.DecodeJSON(r.Body, &admin.Filters.TOTPConfig)\n\tif err != nil {\n\t\treturn util.NewValidationError(fmt.Sprintf(\"unable to decode JSON body: %v\", err))\n\t}\n\tif admin.CountUnusedRecoveryCodes() < 5 && admin.Filters.TOTPConfig.Enabled {\n\t\tadmin.Filters.RecoveryCodes = recoveryCodes\n\t}\n\tif admin.Filters.TOTPConfig.Secret == nil || !admin.Filters.TOTPConfig.Secret.IsPlain() {\n\t\tadmin.Filters.TOTPConfig.Secret = currentTOTPSecret\n\t}\n\treturn dataprovider.UpdateAdmin(&admin, dataprovider.ActionExecutorSelf, util.GetIPFromRemoteAddress(r.RemoteAddr))\n}", "is_vulnerable": 1}
{"code": "func InClusterConfig() (*Config, error) {\n\tconst (\n\t\ttokenFile  = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n\t\trootCAFile = \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n\t)\n\thost, port := os.Getenv(\"KUBERNETES_SERVICE_HOST\"), os.Getenv(\"KUBERNETES_SERVICE_PORT\")\n\tif len(host) == 0 || len(port) == 0 {\n\t\treturn nil, ErrNotInCluster\n\t}\n\n\tts := NewCachedFileTokenSource(tokenFile)\n\n\tif _, err := ts.Token(); err != nil {\n\t\treturn nil, err\n\t}\n\n\ttlsClientConfig := TLSClientConfig{}\n\n\tif _, err := certutil.NewPool(rootCAFile); err != nil {\n\t\tklog.Errorf(\"Expected to load root CA config from %s, but got err: %v\", rootCAFile, err)\n\t} else {\n\t\ttlsClientConfig.CAFile = rootCAFile\n\t}\n\n\treturn &Config{\n\t\t// TODO: switch to using cluster DNS.\n\t\tHost:            \"https://\" + net.JoinHostPort(host, port),\n\t\tTLSClientConfig: tlsClientConfig,\n\t\tWrapTransport:   TokenSourceWrapTransport(ts),\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CurrentTokenOwner(ctx context.Context, in *sliverpb.CurrentTokenOwnerReq, opts ...grpc.CallOption) (*sliverpb.CurrentTokenOwner, error) {\n\tout := new(sliverpb.CurrentTokenOwner)\n\terr := c.cc.Invoke(ctx, SliverRPC_CurrentTokenOwner_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (acl *ACL) Add(svc string, r Rule) error {\n\terr := acl.PolicyDisabled(svc, r.Policy)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = acl.ValidateDomains(r.DomainGlobs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := acl.Rules[svc]; ok {\n\t\treturn fmt.Errorf(\"rule already exists for service %v\", svc)\n\t}\n\tacl.Rules[svc] = r\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) updateCachedDiskUsage() (int64, error) {\n\t// Obtain an exclusive lock on this process so that we don't unintentionally run it at the same\n\t// time as another running process. Once the lock is available it'll read from the cache for the\n\t// second call rather than hitting the disk in parallel.\n\tfs.mu.Lock()\n\tdefer fs.mu.Unlock()\n\n\t// Signal that we're currently updating the disk size so that other calls to the disk checking\n\t// functions can determine if they should queue up additional calls to this function. Ensure that\n\t// we always set this back to \"false\" when this process is done executing.\n\tfs.lookupInProgress.Store(true)\n\tdefer fs.lookupInProgress.Store(false)\n\n\t// If there is no size its either because there is no data (in which case running this function\n\t// will have effectively no impact), or there is nothing in the cache, in which case we need to\n\t// grab the size of their data directory. This is a taxing operation, so we want to store it in\n\t// the cache once we've gotten it.\n\tsize, err := fs.DirectorySize(\"/\")\n\n\t// Always cache the size, even if there is an error. We want to always return that value\n\t// so that we don't cause an endless loop of determining the disk size if there is a temporary\n\t// error encountered.\n\tfs.lastLookupTime.Set(time.Now())\n\n\tfs.unixFS.SetUsage(size)\n\n\treturn size, err\n}", "is_vulnerable": 0}
{"code": "\t\tfunc(transformer *PrefixTransformer) value.Transformer {\n\t\t\treturn NewPrefixTransformer([]byte(\"otherprefix!\"), false)\n\t\t})\n\tfor i, ps := range preset[1:] {\n\t\tpreset[1:][i].storedObj = &example.Pod{}\n\t\terr := store.Create(ctx, ps.key, ps.obj, preset[1:][i].storedObj, 0)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Set failed: %v\", err)\n\t\t}\n\t}\n\trevertTransformer()\n\n\t// List should fail\n\tvar got example.PodList\n\tstorageOpts := storage.ListOptions{\n\t\tPredicate: storage.Everything,\n\t\tRecursive: true,\n\t}\n\tif err := store.GetList(ctx, \"/\", storageOpts, &got); !storage.IsInternalError(err) {\n\t\tt.Errorf(\"Unexpected error %v\", err)\n\t}\n\n\t// Get should fail\n\tif err := store.Get(ctx, preset[1].key, storage.GetOptions{}, &example.Pod{}); !storage.IsInternalError(err) {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n\n\tupdateFunc := func(input runtime.Object, res storage.ResponseMeta) (runtime.Object, *uint64, error) {\n\t\treturn input, nil, nil\n\t}\n\t// GuaranteedUpdate without suggestion should return an error\n\tif err := store.GuaranteedUpdate(ctx, preset[1].key, &example.Pod{}, false, nil, updateFunc, nil); !storage.IsInternalError(err) {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n\t// GuaranteedUpdate with suggestion should return an error if we don't change the object\n\tif err := store.GuaranteedUpdate(ctx, preset[1].key, &example.Pod{}, false, nil, updateFunc, preset[1].obj); err == nil {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n\n\t// Delete fails with internal error.\n\tif err := store.Delete(ctx, preset[1].key, &example.Pod{}, nil, storage.ValidateAllObjectFunc, nil); !storage.IsInternalError(err) {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n\tif err := store.Get(ctx, preset[1].key, storage.GetOptions{}, &example.Pod{}); !storage.IsInternalError(err) {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func newLegacyCosmosAnteHandlerEip712(options HandlerOptions) sdk.AnteHandler {\n\treturn sdk.ChainAnteDecorators(\n\t\tcosmosante.RejectMessagesDecorator{}, // reject MsgEthereumTxs\n\t\tcosmosante.NewAuthzLimiterDecorator( // disable the Msg types that cannot be included on an authz.MsgExec msgs field\n\t\t\tsdk.MsgTypeURL(&evmtypes.MsgEthereumTx{}),\n\t\t\tsdk.MsgTypeURL(&sdkvesting.MsgCreateVestingAccount{}),\n\t\t),\n\t\tante.NewSetUpContextDecorator(),\n\t\tante.NewValidateBasicDecorator(),\n\t\tante.NewTxTimeoutHeightDecorator(),\n\t\tcosmosante.NewMinGasPriceDecorator(options.FeeMarketKeeper, options.EvmKeeper),\n\t\tante.NewValidateMemoDecorator(options.AccountKeeper),\n\t\tante.NewConsumeGasForTxSizeDecorator(options.AccountKeeper),\n\t\tcosmosante.NewDeductFeeDecorator(options.AccountKeeper, options.BankKeeper, options.DistributionKeeper, options.FeegrantKeeper, options.StakingKeeper, options.TxFeeChecker),\n\t\tcosmosante.NewVestingDelegationDecorator(options.AccountKeeper, options.StakingKeeper, options.BankKeeper, options.Cdc),\n\t\t// SetPubKeyDecorator must be called before all signature verification decorators\n\t\tante.NewSetPubKeyDecorator(options.AccountKeeper),\n\t\tante.NewValidateSigCountDecorator(options.AccountKeeper),\n\t\tante.NewSigGasConsumeDecorator(options.AccountKeeper, options.SigGasConsumer),\n\t\t// Note: signature verification uses EIP instead of the cosmos signature validator\n\t\t//nolint: staticcheck\n\t\tcosmosante.NewLegacyEip712SigVerificationDecorator(options.AccountKeeper, options.SignModeHandler),\n\t\tante.NewIncrementSequenceDecorator(options.AccountKeeper),\n\t\tibcante.NewRedundantRelayDecorator(options.IBCKeeper),\n\t\tevmante.NewGasWantedDecorator(options.EvmKeeper, options.FeeMarketKeeper),\n\t)\n}", "is_vulnerable": 1}
{"code": "func uuid(e models.LogEntryAnon) string {\n\tentryBytes, err := base64.StdEncoding.DecodeString(e.Body.(string))\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn hex.EncodeToString(rfc6962.DefaultHasher.HashLeaf(entryBytes))\n}", "is_vulnerable": 1}
{"code": "func (t *pathTrie) deleteAccountNode(path []byte, inner bool) {\n\tif inner {\n\t\taccountInnerLookupGauge.Inc(1)\n\t} else {\n\t\taccountOuterLookupGauge.Inc(1)\n\t}\n\tif !rawdb.ExistsAccountTrieNode(t.db, path) {\n\t\treturn\n\t}\n\tif inner {\n\t\taccountInnerDeleteGauge.Inc(1)\n\t} else {\n\t\taccountOuterDeleteGauge.Inc(1)\n\t}\n\trawdb.DeleteAccountTrieNode(t.batch, path)\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) ListResourcesSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (kp kmsKeyHandler) GenerateCipherDataWithCEKAlgWithContext(ctx aws.Context, keySize int, ivSize int, cekAlgorithm string) (CipherData, error) {\n\tmd := kp.CipherData.MaterialDescription\n\n\twrapAlgorithm := KMSWrap\n\tif kp.withContext {\n\t\twrapAlgorithm = KMSContextWrap\n\t\tif len(cekAlgorithm) == 0 {\n\t\t\treturn CipherData{}, fmt.Errorf(\"CEK algorithm identifier must not be empty\")\n\t\t}\n\t\tmd[\"aws:\"+cekAlgorithmHeader] = &cekAlgorithm\n\t}\n\n\tout, err := kp.kms.GenerateDataKeyWithContext(ctx,\n\t\t&kms.GenerateDataKeyInput{\n\t\t\tEncryptionContext: md,\n\t\t\tKeyId:             kp.cmkID,\n\t\t\tKeySpec:           aws.String(\"AES_256\"),\n\t\t})\n\tif err != nil {\n\t\treturn CipherData{}, err\n\t}\n\n\tiv, err := generateBytes(ivSize)\n\tif err != nil {\n\t\treturn CipherData{}, err\n\t}\n\n\tcd := CipherData{\n\t\tKey:                 out.Plaintext,\n\t\tIV:                  iv,\n\t\tWrapAlgorithm:       wrapAlgorithm,\n\t\tMaterialDescription: md,\n\t\tEncryptedKey:        out.CiphertextBlob,\n\t}\n\treturn cd, nil\n}", "is_vulnerable": 0}
{"code": "func DelayForBackoff(backoff time.Duration, attempt int, cancel <-chan struct{}) bool {\n\tselect {\n\tcase <-time.After(time.Duration(backoff.Seconds()*math.Pow(2, float64(attempt))) * time.Second):\n\t\treturn true\n\tcase <-cancel:\n\t\treturn false\n\t}\n}", "is_vulnerable": 1}
{"code": "func (k *Key) ClientSSHConfig() (*ssh.ClientConfig, error) {\n\tusername, err := k.CertUsername()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to extract username from SSH certificate\")\n\t}\n\tauthMethod, err := k.AsAuthMethod()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert identity file to auth method\")\n\t}\n\thostKeyCallback, err := k.HostKeyCallback(false)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert identity file to HostKeyCallback\")\n\t}\n\treturn &ssh.ClientConfig{\n\t\tUser:            username,\n\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\tHostKeyCallback: hostKeyCallback,\n\t\tTimeout:         defaults.DefaultDialTimeout,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestReconcileError(t *testing.T) {\n\tg := NewWithT(t)\n\n\ttests := []struct {\n\t\tname                                  string\n\t\trotationPollInterval                  time.Duration\n\t\tsecretProviderClassPodStatusToProcess *v1alpha1.SecretProviderClassPodStatus\n\t\tsecretProviderClassToAdd              *v1alpha1.SecretProviderClass\n\t\tpodToAdd                              *v1.Pod\n\t\tsocketPath                            string\n\t\tsecretToAdd                           *v1.Secret\n\t\texpectedObjectVersions                map[string]string\n\t\texpectedErr                           bool\n\t\texpectedErrorEvents                   bool\n\t}{\n\t\t{\n\t\t\tname:                 \"secret provider class not found\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{},\n\t\t\tpodToAdd:                 &v1.Pod{},\n\t\t\tsocketPath:               getTempTestDir(t),\n\t\t\tsecretToAdd:              &v1.Secret{},\n\t\t\texpectedErr:              true,\n\t\t},\n\t\t{\n\t\t\tname:                 \"failed to get pod\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tSpec: v1alpha1.SecretProviderClassSpec{\n\t\t\t\t\tSecretObjects: []*v1alpha1.SecretObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tData: []*v1alpha1.SecretObjectData{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tObjectName: \"object1\",\n\t\t\t\t\t\t\t\t\tKey:        \"foo\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tpodToAdd:    &v1.Pod{},\n\t\t\tsocketPath:  getTempTestDir(t),\n\t\t\tsecretToAdd: &v1.Secret{},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:                 \"failed to get NodePublishSecretRef secret\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t\tTargetPath:              getTestTargetPath(t, \"foo\", \"csi-volume\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tSpec: v1alpha1.SecretProviderClassSpec{\n\t\t\t\t\tSecretObjects: []*v1alpha1.SecretObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tData: []*v1alpha1.SecretObjectData{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tObjectName: \"object1\",\n\t\t\t\t\t\t\t\t\tKey:        \"foo\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tProvider: \"provider1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tpodToAdd: &v1.Pod{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tUID:       types.UID(\"foo\"),\n\t\t\t\t},\n\t\t\t\tSpec: v1.PodSpec{\n\t\t\t\t\tVolumes: []v1.Volume{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"csi-volume\",\n\t\t\t\t\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\t\t\t\t\tCSI: &v1.CSIVolumeSource{\n\t\t\t\t\t\t\t\t\tDriver:           \"secrets-store.csi.k8s.io\",\n\t\t\t\t\t\t\t\t\tVolumeAttributes: map[string]string{\"secretProviderClass\": \"spc1\"},\n\t\t\t\t\t\t\t\t\tNodePublishSecretRef: &v1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\tName: \"secret1\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsocketPath:          getTempTestDir(t),\n\t\t\tsecretToAdd:         &v1.Secret{},\n\t\t\texpectedErr:         true,\n\t\t\texpectedErrorEvents: true,\n\t\t},\n\t\t{\n\t\t\tname:                 \"failed to validate targetpath UID\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t\tTargetPath:              getTestTargetPath(t, \"bad-uid\", \"csi-volume\"),\n\t\t\t\t\tObjects: []v1alpha1.SecretProviderClassObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tID:      \"secret/object1\",\n\t\t\t\t\t\t\tVersion: \"v1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tSpec: v1alpha1.SecretProviderClassSpec{\n\t\t\t\t\tSecretObjects: []*v1alpha1.SecretObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tData: []*v1alpha1.SecretObjectData{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tObjectName: \"object1\",\n\t\t\t\t\t\t\t\t\tKey:        \"foo\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tProvider: \"provider1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tpodToAdd: &v1.Pod{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tUID:       types.UID(\"foo\"),\n\t\t\t\t},\n\t\t\t\tSpec: v1.PodSpec{\n\t\t\t\t\tVolumes: []v1.Volume{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"csi-volume\",\n\t\t\t\t\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\t\t\t\t\tCSI: &v1.CSIVolumeSource{\n\t\t\t\t\t\t\t\t\tDriver:           \"secrets-store.csi.k8s.io\",\n\t\t\t\t\t\t\t\t\tVolumeAttributes: map[string]string{\"secretProviderClass\": \"spc1\"},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsocketPath: getTempTestDir(t),\n\t\t\tsecretToAdd: &v1.Secret{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:            \"object1\",\n\t\t\t\t\tNamespace:       \"default\",\n\t\t\t\t\tResourceVersion: \"rv1\",\n\t\t\t\t},\n\t\t\t\tData: map[string][]byte{\"foo\": []byte(\"olddata\")},\n\t\t\t},\n\t\t\texpectedObjectVersions: map[string]string{\"secret/object1\": \"v2\"},\n\t\t\texpectedErr:            true,\n\t\t\texpectedErrorEvents:    false,\n\t\t},\n\t\t{\n\t\t\tname:                 \"failed to validate targetpath volume name\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t\tTargetPath:              getTestTargetPath(t, \"foo\", \"bad-volume-name\"),\n\t\t\t\t\tObjects: []v1alpha1.SecretProviderClassObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tID:      \"secret/object1\",\n\t\t\t\t\t\t\tVersion: \"v1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tSpec: v1alpha1.SecretProviderClassSpec{\n\t\t\t\t\tSecretObjects: []*v1alpha1.SecretObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tData: []*v1alpha1.SecretObjectData{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tObjectName: \"object1\",\n\t\t\t\t\t\t\t\t\tKey:        \"foo\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tProvider: \"provider1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tpodToAdd: &v1.Pod{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tUID:       types.UID(\"foo\"),\n\t\t\t\t},\n\t\t\t\tSpec: v1.PodSpec{\n\t\t\t\t\tVolumes: []v1.Volume{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"csi-volume\",\n\t\t\t\t\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\t\t\t\t\tCSI: &v1.CSIVolumeSource{\n\t\t\t\t\t\t\t\t\tDriver:           \"secrets-store.csi.k8s.io\",\n\t\t\t\t\t\t\t\t\tVolumeAttributes: map[string]string{\"secretProviderClass\": \"spc1\"},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsocketPath: getTempTestDir(t),\n\t\t\tsecretToAdd: &v1.Secret{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:            \"object1\",\n\t\t\t\t\tNamespace:       \"default\",\n\t\t\t\t\tResourceVersion: \"rv1\",\n\t\t\t\t},\n\t\t\t\tData: map[string][]byte{\"foo\": []byte(\"olddata\")},\n\t\t\t},\n\t\t\texpectedObjectVersions: map[string]string{\"secret/object1\": \"v2\"},\n\t\t\texpectedErr:            true,\n\t\t\texpectedErrorEvents:    false,\n\t\t},\n\t\t{\n\t\t\tname:                 \"failed to create provider client\",\n\t\t\trotationPollInterval: 60 * time.Second,\n\t\t\tsecretProviderClassPodStatusToProcess: &v1alpha1.SecretProviderClassPodStatus{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1-default-spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tLabels:    map[string]string{v1alpha1.InternalNodeLabel: \"nodeName\"},\n\t\t\t\t},\n\t\t\t\tStatus: v1alpha1.SecretProviderClassPodStatusStatus{\n\t\t\t\t\tSecretProviderClassName: \"spc1\",\n\t\t\t\t\tPodName:                 \"pod1\",\n\t\t\t\t\tTargetPath:              getTestTargetPath(t, \"foo\", \"csi-volume\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tsecretProviderClassToAdd: &v1alpha1.SecretProviderClass{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"spc1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tSpec: v1alpha1.SecretProviderClassSpec{\n\t\t\t\t\tSecretObjects: []*v1alpha1.SecretObject{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tData: []*v1alpha1.SecretObjectData{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tObjectName: \"object1\",\n\t\t\t\t\t\t\t\t\tKey:        \"foo\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tProvider: \"wrongprovider\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tpodToAdd: &v1.Pod{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"pod1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t\tUID:       types.UID(\"foo\"),\n\t\t\t\t},\n\t\t\t\tSpec: v1.PodSpec{\n\t\t\t\t\tVolumes: []v1.Volume{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"csi-volume\",\n\t\t\t\t\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\t\t\t\t\tCSI: &v1.CSIVolumeSource{\n\t\t\t\t\t\t\t\t\tDriver:           \"secrets-store.csi.k8s.io\",\n\t\t\t\t\t\t\t\t\tVolumeAttributes: map[string]string{\"secretProviderClass\": \"spc1\"},\n\t\t\t\t\t\t\t\t\tNodePublishSecretRef: &v1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\tName: \"secret1\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tsocketPath: getTempTestDir(t),\n\t\t\tsecretToAdd: &v1.Secret{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"secret1\",\n\t\t\t\t\tNamespace: \"default\",\n\t\t\t\t},\n\t\t\t\tData: map[string][]byte{\"clientid\": []byte(\"clientid\")},\n\t\t\t},\n\t\t\texpectedErr:         true,\n\t\t\texpectedErrorEvents: true,\n\t\t},\n\t}\n\n\tscheme, err := setupScheme()\n\tg.Expect(err).NotTo(HaveOccurred())\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tkubeClient := fake.NewSimpleClientset(test.podToAdd, test.secretToAdd)\n\t\t\tcrdClient := secretsStoreFakeClient.NewSimpleClientset(test.secretProviderClassPodStatusToProcess, test.secretProviderClassToAdd)\n\t\t\tctrlClient := ctrlRuntimeFake.NewFakeClientWithScheme(scheme)\n\n\t\t\ttestReconciler, err := newTestReconciler(scheme, kubeClient, crdClient, ctrlClient, test.rotationPollInterval, test.socketPath)\n\t\t\tg.Expect(err).NotTo(HaveOccurred())\n\t\t\terr = testReconciler.store.Run(wait.NeverStop)\n\t\t\tg.Expect(err).NotTo(HaveOccurred())\n\n\t\t\tserverEndpoint := fmt.Sprintf(\"%s/%s.sock\", test.socketPath, \"provider1\")\n\t\t\tdefer os.Remove(serverEndpoint)\n\n\t\t\tserver, err := providerfake.NewMocKCSIProviderServer(serverEndpoint)\n\t\t\tg.Expect(err).NotTo(HaveOccurred())\n\t\t\tserver.SetObjects(test.expectedObjectVersions)\n\t\t\tserver.Start()\n\n\t\t\terr = testReconciler.reconcile(context.TODO(), test.secretProviderClassPodStatusToProcess)\n\t\t\tg.Expect(err).To(HaveOccurred())\n\t\t\tif test.expectedErrorEvents {\n\t\t\t\tg.Expect(len(fakeRecorder.Events)).ToNot(BeNumerically(\"==\", 0))\n\t\t\t\tfor len(fakeRecorder.Events) > 0 {\n\t\t\t\t\tfmt.Println(<-fakeRecorder.Events)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *Manager) buildRouterHandler(ctx context.Context, routerName string, routerConfig *runtime.RouterInfo) (http.Handler, error) {\n\tif handler, ok := m.routerHandlers[routerName]; ok {\n\t\treturn handler, nil\n\t}\n\n\tif routerConfig.TLS != nil {\n\t\t// Don't build the router if the TLSOptions configuration is invalid.\n\t\ttlsOptionsName := tls.DefaultTLSConfigName\n\t\tif len(routerConfig.TLS.Options) > 0 && routerConfig.TLS.Options != tls.DefaultTLSConfigName {\n\t\t\ttlsOptionsName = provider.GetQualifiedName(ctx, routerConfig.TLS.Options)\n\t\t}\n\t\tif _, err := m.tlsManager.Get(tls.DefaultTLSStoreName, tlsOptionsName); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"building router handler: %w\", err)\n\t\t}\n\t}\n\n\thandler, err := m.buildHTTPHandler(ctx, routerConfig, routerName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thandlerWithAccessLog, err := alice.New(func(next http.Handler) (http.Handler, error) {\n\t\treturn accesslog.NewFieldHandler(next, accesslog.RouterName, routerName, nil), nil\n\t}).Then(handler)\n\tif err != nil {\n\t\tlog.FromContext(ctx).Error(err)\n\t\tm.routerHandlers[routerName] = handler\n\t} else {\n\t\tm.routerHandlers[routerName] = handlerWithAccessLog\n\t}\n\n\treturn m.routerHandlers[routerName], nil\n}", "is_vulnerable": 0}
{"code": "func getRemoteOpts(authenticator authn.Authenticator) ([]gcrremote.Option, error) {\n\tremoteOpts := []gcrremote.Option{}\n\tremoteOpts = append(remoteOpts, gcrremote.WithAuth(authenticator))\n\n\tpusher, err := gcrremote.NewPusher(remoteOpts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tremoteOpts = append(remoteOpts, gcrremote.Reuse(pusher))\n\n\tpuller, err := gcrremote.NewPuller(remoteOpts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tremoteOpts = append(remoteOpts, gcrremote.Reuse(puller))\n\n\treturn remoteOpts, nil\n}", "is_vulnerable": 0}
{"code": "func (f *framerI) AppendControlFrames(frames []ackhandler.Frame, maxLen protocol.ByteCount, v protocol.VersionNumber) ([]ackhandler.Frame, protocol.ByteCount) {\n\tvar length protocol.ByteCount\n\tf.controlFrameMutex.Lock()\n\tfor len(f.controlFrames) > 0 {\n\t\tframe := f.controlFrames[len(f.controlFrames)-1]\n\t\tframeLen := frame.Length(v)\n\t\tif length+frameLen > maxLen {\n\t\t\tbreak\n\t\t}\n\t\tframes = append(frames, ackhandler.Frame{Frame: frame})\n\t\tlength += frameLen\n\t\tf.controlFrames = f.controlFrames[:len(f.controlFrames)-1]\n\t}\n\tf.controlFrameMutex.Unlock()\n\treturn frames, length\n}", "is_vulnerable": 1}
{"code": "func newHandlerRoleBinding(namespace string) *rbacv1.RoleBinding {\n\treturn &rbacv1.RoleBinding{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"RoleBinding\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: namespace,\n\t\t\tName:      components.HandlerServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: \"rbac.authorization.k8s.io\",\n\t\t\tKind:     \"Role\",\n\t\t\tName:     components.HandlerServiceAccountName,\n\t\t},\n\t\tSubjects: []rbacv1.Subject{\n\t\t\t{\n\t\t\t\tKind:      \"ServiceAccount\",\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      components.HandlerServiceAccountName,\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *state) WriteRsyncFileOnDisk(path string, data []byte, withdraw bool) error {\n\tfPath, err := syncpki.GetDownloadPath(path, true)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = os.MkdirAll(filepath.Join(s.Basepath, fPath), os.ModePerm)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfPath, err = syncpki.GetDownloadPath(path, false)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// GHSA-cqh2-vc2f-q4fh: Prevent parent directory writes outside of Basepath\n\tfPath = strings.ReplaceAll(fPath, \"../\", \"\")\n\n\tf, err := os.Create(filepath.Join(s.Basepath, fPath))\n\tif err != nil {\n\t\treturn err\n\t}\n\tf.Write(data)\n\tf.Close()\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeEndpointHandlerMockRecorder) HandleAuthorizeEndpointRequest(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"HandleAuthorizeEndpointRequest\", reflect.TypeOf((*MockAuthorizeEndpointHandler)(nil).HandleAuthorizeEndpointRequest), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func (k *Key) IssuerName() string {\n\treturn C.GoString(k.k.issuer_name)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GenerateExternal(ctx context.Context, in *clientpb.ExternalGenerateReq, opts ...grpc.CallOption) (*clientpb.ExternalImplantConfig, error) {\n\tout := new(clientpb.ExternalImplantConfig)\n\terr := c.cc.Invoke(ctx, SliverRPC_GenerateExternal_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (ns *nodeServer) NodeUnstageVolume(ctx context.Context, req *csi.NodeUnstageVolumeRequest) (*csi.NodeUnstageVolumeResponse, error) {\n\t// The lock is to ensure CSI plugin labels the node in correct order\n\tns.mutex.Lock()\n\tdefer ns.mutex.Unlock()\n\n\t// 1. get runtime namespace and name\n\t// A nil volumeContext is passed because unlike csi.NodeStageVolumeRequest, csi.NodeUnstageVolumeRequest has\n\t// no volume context attribute.\n\tnamespace, name, err := ns.getRuntimeNamespacedName(nil, req.GetVolumeId())\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: can't get runtime namespace and name given (volumeContext: nil, volumeId: %s): %v\", req.GetVolumeId(), err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: can't get namespace and name by volume id %s\", req.GetVolumeId())\n\t}\n\n\t// 2. Check fuse clean policy. If clean policy is set to OnRuntimeDeleted, there is no\n\t// need to clean fuse eagerly.\n\truntimeInfo, err := base.GetRuntimeInfo(ns.client, name, namespace)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"NodeUnstageVolume: can't get fuse clean policy\")\n\t}\n\n\tvar shouldCleanFuse bool\n\tcleanPolicy := runtimeInfo.GetFuseCleanPolicy()\n\tglog.Infof(\"Using %s clean policy for runtime %s in namespace %s\", cleanPolicy, runtimeInfo.GetName(), runtimeInfo.GetNamespace())\n\tswitch cleanPolicy {\n\tcase v1alpha1.OnDemandCleanPolicy:\n\t\tshouldCleanFuse = true\n\tcase v1alpha1.OnRuntimeDeletedCleanPolicy:\n\t\tshouldCleanFuse = false\n\tdefault:\n\t\treturn nil, errors.Errorf(\"Unknown Fuse clean policy: %s\", cleanPolicy)\n\t}\n\n\tif !shouldCleanFuse {\n\t\treturn &csi.NodeUnstageVolumeResponse{}, nil\n\t}\n\n\t// 3. check if the path is mounted\n\tinUse, err := checkMountInUse(req.GetVolumeId())\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"NodeUnstageVolume: can't check mount in use\")\n\t}\n\tif inUse {\n\t\treturn nil, fmt.Errorf(\"NodeUnstageVolume: can't stop fuse cause it's in use\")\n\t}\n\n\t// 4. remove label on node\n\t// Once the label is removed, fuse pod on corresponding node will be terminated\n\t// since node selector in the fuse daemonSet no longer matches.\n\t// TODO: move all the label keys into a util func\n\tfuseLabelKey := common.LabelAnnotationFusePrefix + namespace + \"-\" + name\n\tvar labelsToModify common.LabelsToModify\n\tlabelsToModify.Delete(fuseLabelKey)\n\n\tnode, err := ns.getNode()\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: can't get node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: can't get node %s\", ns.nodeId)\n\t}\n\n\t_, err = utils.ChangeNodeLabelWithPatchMode(ns.client, node, labelsToModify)\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: error when patching labels on node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: error when patching labels on node %s\", ns.nodeId)\n\t}\n\n\treturn &csi.NodeUnstageVolumeResponse{}, nil\n}", "is_vulnerable": 1}
{"code": "func (p *printer) printExprCommentsAtLoc(loc logger.Loc) {\n\tif p.options.MinifyWhitespace {\n\t\treturn\n\t}\n\tif comments := p.exprComments[loc]; comments != nil && !p.printedExprComments[loc] {\n\t\tflags := p.saveExprStartFlags()\n\n\t\t// We must never generate a newline before certain expressions. For example,\n\t\t// generating a newline before the expression in a \"return\" statement will\n\t\t// cause a semicolon to be inserted, which would change the code's behavior.\n\t\tif p.noLeadingNewlineHere == len(p.js) {\n\t\t\tfor _, comment := range comments {\n\t\t\t\tif strings.HasPrefix(comment, \"//\") {\n\t\t\t\t\tp.print(\"/*\")\n\t\t\t\t\tp.print(comment[2:])\n\t\t\t\t\tif strings.HasPrefix(comment, \"// \") {\n\t\t\t\t\t\tp.print(\" \")\n\t\t\t\t\t}\n\t\t\t\t\tp.print(\"*/\")\n\t\t\t\t} else {\n\t\t\t\t\tp.print(strings.Join(strings.Split(comment, \"\\n\"), \"\"))\n\t\t\t\t}\n\t\t\t\tp.printSpace()\n\t\t\t}\n\t\t} else {\n\t\t\tfor _, comment := range comments {\n\t\t\t\tp.printIndentedComment(comment)\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t}\n\n\t\t// Mark these comments as printed so we don't print them again\n\t\tp.printedExprComments[loc] = true\n\n\t\tp.restoreExprStartFlags(flags)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestValueBinder_DurationsError(t *testing.T) {\n\tvar testCases = []struct {\n\t\tname            string\n\t\tgivenFailFast   bool\n\t\tgivenBindErrors []error\n\t\twhenURL         string\n\t\twhenMust        bool\n\t\texpectValue     []time.Duration\n\t\texpectError     string\n\t}{\n\t\t{\n\t\t\tname:          \"nok, fail fast without binding value\",\n\t\t\tgivenFailFast: true,\n\t\t\twhenURL:       \"/search?param=1&param=100\",\n\t\t\texpectValue:   []time.Duration(nil),\n\t\t\texpectError:   \"code=400, message=failed to bind field value to Duration, internal=time: missing unit in duration \\\"1\\\", field=param\",\n\t\t},\n\t\t{\n\t\t\tname:        \"nok, conversion fails, value is not changed\",\n\t\t\twhenURL:     \"/search?param=nope&param=100\",\n\t\t\texpectValue: []time.Duration(nil),\n\t\t\texpectError: \"code=400, message=failed to bind field value to Duration, internal=time: invalid duration \\\"nope\\\", field=param\",\n\t\t},\n\t\t{\n\t\t\tname:        \"nok (must), conversion fails, value is not changed\",\n\t\t\twhenMust:    true,\n\t\t\twhenURL:     \"/search?param=nope&param=100\",\n\t\t\texpectValue: []time.Duration(nil),\n\t\t\texpectError: \"code=400, message=failed to bind field value to Duration, internal=time: invalid duration \\\"nope\\\", field=param\",\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tc := createTestContext(tc.whenURL, nil, nil)\n\t\t\tb := QueryParamsBinder(c).FailFast(tc.givenFailFast)\n\t\t\tb.errors = tc.givenBindErrors\n\n\t\t\tvar dest []time.Duration\n\t\t\tvar err error\n\t\t\tif tc.whenMust {\n\t\t\t\terr = b.MustDurations(\"param\", &dest).BindError()\n\t\t\t} else {\n\t\t\t\terr = b.Durations(\"param\", &dest).BindError()\n\t\t\t}\n\n\t\t\tassert.Equal(t, tc.expectValue, dest)\n\t\t\tif tc.expectError != \"\" {\n\t\t\t\tassert.EqualError(t, err, tc.expectError)\n\t\t\t} else {\n\t\t\t\tassert.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (handler *Handler) deployComposeStack(config *composeStackDeploymentConfig) error {\n\tsettings, err := handler.SettingsService.Settings()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tisAdminOrEndpointAdmin, err := handler.userIsAdminOrEndpointAdmin(config.user, config.endpoint.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif (!settings.AllowBindMountsForRegularUsers ||\n\t\t!settings.AllowPrivilegedModeForRegularUsers ||\n\t\t!settings.AllowHostNamespaceForRegularUsers ||\n\t\t!settings.AllowDeviceMappingForRegularUsers ||\n\t\t!settings.AllowContainerCapabilitiesForRegularUsers) && !isAdminOrEndpointAdmin {\n\n\t\tcomposeFilePath := path.Join(config.stack.ProjectPath, config.stack.EntryPoint)\n\n\t\tstackContent, err := handler.FileService.GetFileContent(composeFilePath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = handler.isValidStackFile(stackContent, settings)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\thandler.stackCreationMutex.Lock()\n\tdefer handler.stackCreationMutex.Unlock()\n\n\thandler.SwarmStackManager.Login(config.dockerhub, config.registries, config.endpoint)\n\n\terr = handler.ComposeStackManager.Up(config.stack, config.endpoint)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn handler.SwarmStackManager.Logout(config.endpoint)\n}", "is_vulnerable": 0}
{"code": "\treturn func(opts *options) {\n\t\topts.passCredentialsAll = pass\n\t}", "is_vulnerable": 0}
{"code": "func (m *NidNestedStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidNestedStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidNestedStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Field1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field2 = append(m.Field2, NidRepStruct{})\n\t\t\tif err := m.Field2[len(m.Field2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (p *pluginConfig) asyncDataSource(rtCfg *extensioncommon.RuntimeConfig) (*envoy_core_v3.AsyncDataSource, error) {\n\n\t// Local data source\n\tif filename := p.VmConfig.Code.Local.Filename; filename != \"\" {\n\t\treturn &envoy_core_v3.AsyncDataSource{\n\t\t\tSpecifier: &envoy_core_v3.AsyncDataSource_Local{\n\t\t\t\tLocal: &envoy_core_v3.DataSource{\n\t\t\t\t\tSpecifier: &envoy_core_v3.DataSource_Filename{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\t// Remote data source\n\t// For a remote file, ensure there is an upstream cluster for the host specified in the URL.\n\t// Envoy requires an explicit cluster in order to perform the DNS lookup required to actually\n\t// fetch the data from the upstream source.\n\tremote := &p.VmConfig.Code.Remote\n\tclusterSNI := \"\"\n\tfor service, upstream := range rtCfg.LocalUpstreams {\n\t\tif service == remote.HttpURI.Service {\n\t\t\tfor sni := range upstream.SNI {\n\t\t\t\tclusterSNI = sni\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tif clusterSNI == \"\" {\n\t\treturn nil, fmt.Errorf(\"no upstream found for remote service %q\", remote.HttpURI.Service.Name)\n\t}\n\n\td := time.Second\n\tif remote.HttpURI.timeout > 0 {\n\t\td = remote.HttpURI.timeout\n\t}\n\ttimeout := &durationpb.Duration{Seconds: int64(d.Seconds())}\n\n\treturn &envoy_core_v3.AsyncDataSource{\n\t\tSpecifier: &envoy_core_v3.AsyncDataSource_Remote{\n\t\t\tRemote: &envoy_core_v3.RemoteDataSource{\n\t\t\t\tSha256: remote.SHA256,\n\t\t\t\tHttpUri: &envoy_core_v3.HttpUri{\n\t\t\t\t\tUri: remote.HttpURI.URI,\n\t\t\t\t\tHttpUpstreamType: &envoy_core_v3.HttpUri_Cluster{\n\t\t\t\t\t\tCluster: clusterSNI,\n\t\t\t\t\t},\n\t\t\t\t\tTimeout: timeout,\n\t\t\t\t},\n\t\t\t\tRetryPolicy: p.retryPolicy(),\n\t\t\t},\n\t\t},\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func NewClient(config *Config) (*Client, error) {\n\tc, err := tlsutil.NewConfigurator(config.ToTLSUtilConfig(), nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn NewClientLogger(config, nil, c)\n}", "is_vulnerable": 0}
{"code": "func (ctx *PfCtxS) CheckPermsT(what string, permstr string) (ok bool, err error) {\n\tvar perms Perm\n\n\terr = perms.FromString(permstr)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn ctx.CheckPerms(what, perms)\n}", "is_vulnerable": 1}
{"code": "func (m *MineOwner) GetPool(keyid int64) (bool, error) {\r\n\treturn isFound(DBConn.Where(\"keyid = ? and type = ? \", keyid, 2).Order(\"id DESC\").First(m))\r\n}\r", "is_vulnerable": 0}
{"code": "func intFromInterface(selector interface{}) int {\n\tvar value int\n\tswitch selector.(type) {\n\tcase int:\n\t\tvalue = selector.(int)\n\tcase int8:\n\t\tvalue = int(selector.(int8))\n\tcase int16:\n\t\tvalue = int(selector.(int16))\n\tcase int32:\n\t\tvalue = int(selector.(int32))\n\tcase int64:\n\t\tvalue = int(selector.(int64))\n\tcase uint:\n\t\tvalue = int(selector.(uint))\n\tcase uint8:\n\t\tvalue = int(selector.(uint8))\n\tcase uint16:\n\t\tvalue = int(selector.(uint16))\n\tcase uint32:\n\t\tvalue = int(selector.(uint32))\n\tcase uint64:\n\t\tvalue = int(selector.(uint64))\n\tdefault:\n\t\tpanic(\"objx: array access argument is not an integer type (this should never happen)\")\n\t}\n\treturn value\n}", "is_vulnerable": 1}
{"code": "func (k *Key) CheckCert() error {\n\tcert, err := k.SSHCert()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\t// A valid principal is always passed in because the principals are not being\n\t// checked here, but rather the validity period, signature, and algorithms.\n\tcertChecker := sshutils.CertChecker{\n\t\tFIPS: isFIPS(),\n\t}\n\terr = certChecker.CheckCert(cert.ValidPrincipals[0], cert)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleDelete(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\treqPath, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\trelease, status, err := h.confirmLocks(r, reqPath, \"\")\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\treqPath, err = user.JoinPath(reqPath)\n\tif err != nil {\n\t\treturn 403, err\n\t}\n\t// TODO: return MultiStatus where appropriate.\n\n\t// \"godoc os RemoveAll\" says that \"If the path does not exist, RemoveAll\n\t// returns nil (no error).\" WebDAV semantics are that it should return a\n\t// \"404 Not Found\". We therefore have to Stat before we RemoveAll.\n\tif _, err := fs.Get(ctx, reqPath); err != nil {\n\t\tif errs.IsObjectNotFound(err) {\n\t\t\treturn http.StatusNotFound, err\n\t\t}\n\t\treturn http.StatusMethodNotAllowed, err\n\t}\n\tif err := fs.Remove(ctx, reqPath); err != nil {\n\t\treturn http.StatusMethodNotAllowed, err\n\t}\n\t//fs.ClearCache(path.Dir(reqPath))\n\treturn http.StatusNoContent, nil\n}", "is_vulnerable": 0}
{"code": "func SanitizeDescription(s string) string {\n\tNewSanitizer()\n\treturn sanitizer.descriptionPolicy.Sanitize(s)\n}", "is_vulnerable": 1}
{"code": "func (b *Builder) buildPomeriumHTTPRoutes(\n\toptions *config.Options,\n\thost string,\n\trequireStrictTransportSecurity bool,\n) ([]*envoy_config_route_v3.Route, error) {\n\tvar routes []*envoy_config_route_v3.Route\n\n\t// if this is the pomerium proxy in front of the the authenticate service, don't add\n\t// these routes since they will be handled by authenticate\n\tisFrontingAuthenticate, err := isProxyFrontingAuthenticate(options, host)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !isFrontingAuthenticate {\n\t\troutes = append(routes,\n\t\t\t// enable ext_authz\n\t\t\tb.buildControlPlanePathRoute(options, \"/.pomerium/jwt\", true, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePathRoute(options, urlutil.WebAuthnURLPath, true, requireStrictTransportSecurity),\n\t\t\t// disable ext_authz and passthrough to proxy handlers\n\t\t\tb.buildControlPlanePathRoute(options, \"/ping\", false, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePathRoute(options, \"/healthz\", false, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePathRoute(options, \"/.pomerium\", false, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePrefixRoute(options, \"/.pomerium/\", false, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePathRoute(options, \"/.well-known/pomerium\", false, requireStrictTransportSecurity),\n\t\t\tb.buildControlPlanePrefixRoute(options, \"/.well-known/pomerium/\", false, requireStrictTransportSecurity),\n\t\t)\n\t\t// per #837, only add robots.txt if there are no unauthenticated routes\n\t\tif !hasPublicPolicyMatchingURL(options, url.URL{Scheme: \"https\", Host: host, Path: \"/robots.txt\"}) {\n\t\t\troutes = append(routes, b.buildControlPlanePathRoute(options, \"/robots.txt\", false, requireStrictTransportSecurity))\n\t\t}\n\t}\n\n\tauthRoutes, err := b.buildPomeriumAuthenticateHTTPRoutes(options, host, requireStrictTransportSecurity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\troutes = append(routes, authRoutes...)\n\treturn routes, nil\n}", "is_vulnerable": 1}
{"code": "func getReportedServices(cfg *config.Config) ([]*pb.Service, error) {\n\tif cfg.Options.MetricsAddr == \"\" {\n\t\treturn nil, nil\n\t}\n\n\tmu, err := metricsURL(*cfg.Options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn []*pb.Service{\n\t\t{Kind: pb.ServiceKind_PROMETHEUS_METRICS, Endpoint: mu.String()},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (m *Message) UnmarshalJSON(buf []byte) error {\n\tm.payload = nil\n\tm.signatures = nil\n\tm.b64 = true\n\n\tvar mup messageUnmarshalProbe\n\tmup.Header = NewHeaders()\n\tif err := json.Unmarshal(buf, &mup); err != nil {\n\t\treturn fmt.Errorf(`failed to unmarshal into temporary structure: %w`, err)\n\t}\n\n\tb64 := true\n\tif mup.Signature == nil { // flattened signature is NOT present\n\t\tif len(mup.Signatures) == 0 {\n\t\t\treturn fmt.Errorf(`required field \"signatures\" not present`)\n\t\t}\n\n\t\tm.signatures = make([]*Signature, 0, len(mup.Signatures))\n\t\tfor i, rawsig := range mup.Signatures {\n\t\t\tvar sig Signature\n\t\t\tsig.SetDecodeCtx(m.DecodeCtx())\n\t\t\tif err := json.Unmarshal(rawsig, &sig); err != nil {\n\t\t\t\treturn fmt.Errorf(`failed to unmarshal signature #%d: %w`, i+1, err)\n\t\t\t}\n\t\t\tsig.SetDecodeCtx(nil)\n\n\t\t\tif sig.protected == nil {\n\t\t\t\t// Instead of barfing on a nil protected header, use an empty header\n\t\t\t\tsig.protected = NewHeaders()\n\t\t\t}\n\n\t\t\tif i == 0 {\n\t\t\t\tif !getB64Value(sig.protected) {\n\t\t\t\t\tb64 = false\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif b64 != getB64Value(sig.protected) {\n\t\t\t\t\treturn fmt.Errorf(`b64 value must be the same for all signatures`)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tm.signatures = append(m.signatures, &sig)\n\t\t}\n\t} else { // .signature is present, it's a flattened structure\n\t\tif len(mup.Signatures) != 0 {\n\t\t\treturn fmt.Errorf(`invalid format (\"signatures\" and \"signature\" keys cannot both be present)`)\n\t\t}\n\n\t\tvar sig Signature\n\t\tsig.headers = mup.Header\n\t\tif src := mup.Protected; src != nil {\n\t\t\tdecoded, err := base64.DecodeString(*src)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(`failed to base64 decode flattened protected headers: %w`, err)\n\t\t\t}\n\t\t\tprt := NewHeaders()\n\t\t\t//nolint:forcetypeassert\n\t\t\tprt.(*stdHeaders).SetDecodeCtx(m.DecodeCtx())\n\t\t\tif err := json.Unmarshal(decoded, prt); err != nil {\n\t\t\t\treturn fmt.Errorf(`failed to unmarshal flattened protected headers: %w`, err)\n\t\t\t}\n\t\t\t//nolint:forcetypeassert\n\t\t\tprt.(*stdHeaders).SetDecodeCtx(nil)\n\t\t\tsig.protected = prt\n\t\t}\n\n\t\tif sig.protected == nil {\n\t\t\t// Instead of barfing on a nil protected header, use an empty header\n\t\t\tsig.protected = NewHeaders()\n\t\t}\n\n\t\tdecoded, err := base64.DecodeString(*mup.Signature)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(`failed to base64 decode flattened signature: %w`, err)\n\t\t}\n\t\tsig.signature = decoded\n\n\t\tm.signatures = []*Signature{&sig}\n\t\tb64 = getB64Value(sig.protected)\n\t}\n\n\tif mup.Payload != nil {\n\t\tif !b64 { // NOT base64 encoded\n\t\t\tm.payload = []byte(*mup.Payload)\n\t\t} else {\n\t\t\tdecoded, err := base64.DecodeString(*mup.Payload)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(`failed to base64 decode payload: %w`, err)\n\t\t\t}\n\t\t\tm.payload = decoded\n\t\t}\n\t}\n\tm.b64 = b64\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tpluginJSONCreate func(t *testing.T)\n\t\tcfg              Config\n\t\texpectedCfg      Config\n\t\texpectedArgs     []string\n\t\twantErr          assert.ErrorAssertionFunc\n\t}{\n\t\t{\n\t\t\tname: \"Happy path\",\n\t\t\tcfg: Config{\n\t\t\t\tOS:             \"darwin\",\n\t\t\t\tArch:           \"arm64\",\n\t\t\t\tEnv:            make(map[string]string),\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobar-datasource\"),\n\t\t\t},\n\t\t\tpluginJSONCreate: func(t *testing.T) {\n\t\t\t\tt.Helper()\n\t\t\t\tcreatePluginJSON(t, filepath.Join(tmpDir, \"foobar-datasource\"), \"gpx_foo\")\n\t\t\t},\n\t\t\texpectedCfg: Config{\n\t\t\t\tOS:             \"darwin\",\n\t\t\t\tArch:           \"arm64\",\n\t\t\t\tEnv:            map[string]string{\"CGO_ENABLED\": \"0\", \"GOARCH\": \"arm64\", \"GOOS\": \"darwin\"},\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobar-datasource\"),\n\t\t\t},\n\t\t\texpectedArgs: []string{\"build\", \"-o\", filepath.Join(defaultOutputBinaryPath, \"gpx_foo_darwin_arm64\"), \"-ldflags\", \"-w -s -extldflags \\\"-static\\\" -X 'github.com/grafana/grafana-plugin-sdk-go/build.buildInfoJSON={.*}'\", \"./pkg\"},\n\t\t\twantErr:      assert.NoError,\n\t\t},\n\t\t{\n\t\t\tname: \"Happy path with nested datasource\",\n\t\t\tcfg: Config{\n\t\t\t\tOS:             \"darwin\",\n\t\t\t\tArch:           \"arm64\",\n\t\t\t\tEnv:            make(map[string]string),\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobar-app\"),\n\t\t\t},\n\t\t\tpluginJSONCreate: func(t *testing.T) {\n\t\t\t\tt.Helper()\n\t\t\t\tcreatePluginJSON(t, filepath.Join(tmpDir, \"foobar-app\", defaultNestedDataSourcePath), \"gpx_foo\")\n\t\t\t},\n\t\t\texpectedCfg: Config{\n\t\t\t\tOS:             \"darwin\",\n\t\t\t\tArch:           \"arm64\",\n\t\t\t\tEnv:            map[string]string{\"CGO_ENABLED\": \"0\", \"GOARCH\": \"arm64\", \"GOOS\": \"darwin\"},\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobar-app\"),\n\t\t\t},\n\t\t\texpectedArgs: []string{\"build\", \"-o\", filepath.Join(defaultOutputBinaryPath, defaultNestedDataSourcePath, \"gpx_foo_darwin_arm64\"), \"-ldflags\", \"-w -s -extldflags \\\"-static\\\" -X 'github.com/grafana/grafana-plugin-sdk-go/build.buildInfoJSON={.*}'\", \"./pkg\"},\n\t\t\twantErr:      assert.NoError,\n\t\t},\n\t\t{\n\t\t\tname: \"Happy path with nested datasource that has executable path in root directory\",\n\t\t\tcfg: Config{\n\t\t\t\tOS:             \"windows\",\n\t\t\t\tArch:           \"amd64\",\n\t\t\t\tEnv:            make(map[string]string),\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobarbaz-app\"),\n\t\t\t},\n\t\t\tpluginJSONCreate: func(t *testing.T) {\n\t\t\t\tt.Helper()\n\t\t\t\tcreatePluginJSON(t, filepath.Join(tmpDir, \"foobarbaz-app\", defaultNestedDataSourcePath), \"../gpx_foobarbaz\")\n\t\t\t},\n\t\t\texpectedCfg: Config{\n\t\t\t\tOS:             \"windows\",\n\t\t\t\tArch:           \"amd64\",\n\t\t\t\tEnv:            map[string]string{\"CGO_ENABLED\": \"0\", \"GOARCH\": \"amd64\", \"GOOS\": \"windows\"},\n\t\t\t\tPluginJSONPath: filepath.Join(tmpDir, \"foobarbaz-app\"),\n\t\t\t},\n\t\t\texpectedArgs: []string{\"build\", \"-o\", filepath.Join(defaultOutputBinaryPath, \"gpx_foobarbaz_windows_amd64.exe\"), \"-ldflags\", \"-w -s -extldflags \\\"-static\\\" -X 'github.com/grafana/grafana-plugin-sdk-go/build.buildInfoJSON={.*}'\", \"./pkg\"},\n\t\t\twantErr:      assert.NoError,\n\t\t},\n\t}\n\n\tfor _, tc := range tcs {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\ttc.pluginJSONCreate(t)\n\n\t\t\tcfg, args, err := getBuildBackendCmdInfo(tc.cfg)\n\t\t\tif !tc.wantErr(t, err, fmt.Sprintf(\"getBuildBackendCmdInfo(%v)\", tc.cfg)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tassert.Equalf(t, tc.expectedCfg, cfg, \"getBuildBackendCmdInfo(%v)\", tc.cfg)\n\n\t\t\t// check if expected build arg regex matches against actual build arg\n\t\t\tbuildArg := strings.Join(args, \" \")\n\t\t\texpectedBuildArg := strings.Join(tc.expectedArgs, \" \")\n\t\t\tassert.Regexp(t, expectedBuildArg, buildArg, \"getBuildBackendCmdInfo(%v)\", tc.cfg)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func tryLoginUsingRememberCookie(c *middleware.Context) bool {\n\t// Check auto-login.\n\tuname := c.GetCookie(setting.CookieUserName)\n\tif len(uname) == 0 {\n\t\treturn false\n\t}\n\n\tisSucceed := false\n\tdefer func() {\n\t\tif !isSucceed {\n\t\t\tlog.Trace(\"auto-login cookie cleared: %s\", uname)\n\t\t\tc.SetCookie(setting.CookieUserName, \"\", -1, setting.AppSubUrl+\"/\")\n\t\t\tc.SetCookie(setting.CookieRememberName, \"\", -1, setting.AppSubUrl+\"/\")\n\t\t\treturn\n\t\t}\n\t}()\n\n\tuserQuery := m.GetUserByLoginQuery{LoginOrEmail: uname}\n\tif err := bus.Dispatch(&userQuery); err != nil {\n\t\treturn false\n\t}\n\n\tuser := userQuery.Result\n\n\t// validate remember me cookie\n\tsigningKey := user.Rands + user.Password\n\tif len(signingKey) < 10 {\n\t\tc.Logger.Error(\"Invalid user signingKey\")\n\t\treturn false\n\t}\n\n\n\tif val, _ := c.GetSuperSecureCookie(signingKey, setting.CookieRememberName); val != user.Login {\n\t\treturn false\n\t}\n\n\tisSucceed = true\n\tloginUserWithUser(user, c)\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (m *mockLayer) Digest() (v1.Hash, error)             { panic(\"not implemented\") }", "is_vulnerable": 0}
{"code": "\treturn func(s *grpc.Server) {\n\t\ttestpb.RegisterTestServiceServer(s, &pingServer{\n\t\t\tch: ch,\n\t\t})\n\t}, ch", "is_vulnerable": 0}
{"code": "func TestJobEndpointConnect_groupConnectHook_MeshGateway(t *testing.T) {\n\tt.Parallel()\n\n\t// Test that the connect mesh gateway task is inserted if a gateway service\n\t// exists and since this is a bridge network, will rewrite the default gateway\n\t// proxy block with correct configuration, injecting a dynamic port for use\n\t// by the envoy lan listener.\n\tjob := mock.ConnectMeshGatewayJob(\"bridge\", false)\n\tjob.Meta = map[string]string{\n\t\t\"gateway_name\": \"my-gateway\",\n\t}\n\tjob.TaskGroups[0].Services[0].Name = \"${NOMAD_META_gateway_name}\"\n\n\t// setup expectations\n\texpTG := job.TaskGroups[0].Copy()\n\texpTG.Tasks = []*structs.Task{\n\t\t// inject the gateway task\n\t\tnewConnectGatewayTask(structs.ConnectMeshPrefix, \"my-gateway\", false),\n\t}\n\texpTG.Services[0].Name = \"my-gateway\"\n\texpTG.Services[0].PortLabel = \"public_port\"\n\texpTG.Networks[0].DynamicPorts = []structs.Port{{\n\t\tLabel:       \"connect-mesh-my-gateway-lan\",\n\t\tValue:       0,\n\t\tTo:          -1,\n\t\tHostNetwork: \"default\",\n\t}}\n\texpTG.Tasks[0].Canonicalize(job, expTG)\n\texpTG.Networks[0].Canonicalize()\n\n\t// rewrite the service gateway proxy configuration\n\texpTG.Services[0].Connect.Gateway.Proxy = gatewayProxy(expTG.Services[0].Connect.Gateway, \"bridge\")\n\n\trequire.NoError(t, groupConnectHook(job, job.TaskGroups[0]))\n\trequire.Exactly(t, expTG, job.TaskGroups[0])\n\n\t// Test that the hook is idempotent\n\trequire.NoError(t, groupConnectHook(job, job.TaskGroups[0]))\n\trequire.Exactly(t, expTG, job.TaskGroups[0])\n}", "is_vulnerable": 0}
{"code": "func FsList(c *gin.Context) {\n\tvar req ListReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\treq.Validate()\n\tuser := c.MustGet(\"user\").(*model.User)\n\treqPath, err := user.JoinPath(req.Path)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 403)\n\t\treturn\n\t}\n\tmeta, err := db.GetNearestMeta(reqPath)\n\tif err != nil {\n\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\treturn\n\t\t}\n\t}\n\tc.Set(\"meta\", meta)\n\tif !common.CanAccess(user, meta, reqPath, req.Password) {\n\t\tcommon.ErrorStrResp(c, \"password is incorrect\", 403)\n\t\treturn\n\t}\n\tif !user.CanWrite() && !common.CanWrite(meta, reqPath) && req.Refresh {\n\t\tcommon.ErrorStrResp(c, \"Refresh without permission\", 403)\n\t\treturn\n\t}\n\tobjs, err := fs.List(c, reqPath, req.Refresh)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\ttotal, objs := pagination(objs, &req.PageReq)\n\tprovider := \"unknown\"\n\tstorage, err := fs.GetStorage(reqPath)\n\tif err == nil {\n\t\tprovider = storage.GetStorage().Driver\n\t}\n\tcommon.SuccessResp(c, FsListResp{\n\t\tContent:  toObjsResp(objs, reqPath, isEncrypt(meta, reqPath)),\n\t\tTotal:    int64(total),\n\t\tReadme:   getReadme(meta, reqPath),\n\t\tWrite:    user.CanWrite() || common.CanWrite(meta, reqPath),\n\t\tProvider: provider,\n\t})\n}", "is_vulnerable": 0}
{"code": "func newDecoder(r io.Reader) (*decoder, error) {\n\td := &decoder{\n\t\tr:        newReaderAt(r),\n\t\tfeatures: make(map[int][]uint),\n\t}\n\n\tp := make([]byte, 8)\n\tif _, err := d.r.ReadAt(p, 0); err != nil {\n\t\tif err == io.EOF {\n\t\t\terr = io.ErrUnexpectedEOF\n\t\t}\n\t\treturn nil, err\n\t}\n\tswitch string(p[0:4]) {\n\tcase leHeader:\n\t\td.byteOrder = binary.LittleEndian\n\tcase beHeader:\n\t\td.byteOrder = binary.BigEndian\n\tdefault:\n\t\treturn nil, FormatError(\"malformed header\")\n\t}\n\n\tifdOffset := int64(d.byteOrder.Uint32(p[4:8]))\n\n\t// The first two bytes contain the number of entries (12 bytes each).\n\tif _, err := d.r.ReadAt(p[0:2], ifdOffset); err != nil {\n\t\treturn nil, err\n\t}\n\tnumItems := int(d.byteOrder.Uint16(p[0:2]))\n\n\t// All IFD entries are read in one chunk.\n\tvar err error\n\tp, err = safeReadAt(d.r, uint64(ifdLen*numItems), ifdOffset+2)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tprevTag := -1\n\tfor i := 0; i < len(p); i += ifdLen {\n\t\ttag, err := d.parseIFD(p[i : i+ifdLen])\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif tag <= prevTag {\n\t\t\treturn nil, FormatError(\"tags are not sorted in ascending order\")\n\t\t}\n\t\tprevTag = tag\n\t}\n\n\td.config.Width = int(d.firstVal(tImageWidth))\n\td.config.Height = int(d.firstVal(tImageLength))\n\n\tif _, ok := d.features[tBitsPerSample]; !ok {\n\t\t// Default is 1 per specification.\n\t\td.features[tBitsPerSample] = []uint{1}\n\t}\n\td.bpp = d.firstVal(tBitsPerSample)\n\tswitch d.bpp {\n\tcase 0:\n\t\treturn nil, FormatError(\"BitsPerSample must not be 0\")\n\tcase 1, 8, 16:\n\t\t// Nothing to do, these are accepted by this implementation.\n\tdefault:\n\t\treturn nil, UnsupportedError(fmt.Sprintf(\"BitsPerSample of %v\", d.bpp))\n\t}\n\n\t// Determine the image mode.\n\tswitch d.firstVal(tPhotometricInterpretation) {\n\tcase pRGB:\n\t\tif d.bpp == 16 {\n\t\t\tfor _, b := range d.features[tBitsPerSample] {\n\t\t\t\tif b != 16 {\n\t\t\t\t\treturn nil, FormatError(\"wrong number of samples for 16bit RGB\")\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tfor _, b := range d.features[tBitsPerSample] {\n\t\t\t\tif b != 8 {\n\t\t\t\t\treturn nil, FormatError(\"wrong number of samples for 8bit RGB\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// RGB images normally have 3 samples per pixel.\n\t\t// If there are more, ExtraSamples (p. 31-32 of the spec)\n\t\t// gives their meaning (usually an alpha channel).\n\t\t//\n\t\t// This implementation does not support extra samples\n\t\t// of an unspecified type.\n\t\tswitch len(d.features[tBitsPerSample]) {\n\t\tcase 3:\n\t\t\td.mode = mRGB\n\t\t\tif d.bpp == 16 {\n\t\t\t\td.config.ColorModel = color.RGBA64Model\n\t\t\t} else {\n\t\t\t\td.config.ColorModel = color.RGBAModel\n\t\t\t}\n\t\tcase 4:\n\t\t\tswitch d.firstVal(tExtraSamples) {\n\t\t\tcase 1:\n\t\t\t\td.mode = mRGBA\n\t\t\t\tif d.bpp == 16 {\n\t\t\t\t\td.config.ColorModel = color.RGBA64Model\n\t\t\t\t} else {\n\t\t\t\t\td.config.ColorModel = color.RGBAModel\n\t\t\t\t}\n\t\t\tcase 2:\n\t\t\t\td.mode = mNRGBA\n\t\t\t\tif d.bpp == 16 {\n\t\t\t\t\td.config.ColorModel = color.NRGBA64Model\n\t\t\t\t} else {\n\t\t\t\t\td.config.ColorModel = color.NRGBAModel\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn nil, FormatError(\"wrong number of samples for RGB\")\n\t\t\t}\n\t\tdefault:\n\t\t\treturn nil, FormatError(\"wrong number of samples for RGB\")\n\t\t}\n\tcase pPaletted:\n\t\td.mode = mPaletted\n\t\td.config.ColorModel = color.Palette(d.palette)\n\tcase pWhiteIsZero:\n\t\td.mode = mGrayInvert\n\t\tif d.bpp == 16 {\n\t\t\td.config.ColorModel = color.Gray16Model\n\t\t} else {\n\t\t\td.config.ColorModel = color.GrayModel\n\t\t}\n\tcase pBlackIsZero:\n\t\td.mode = mGray\n\t\tif d.bpp == 16 {\n\t\t\td.config.ColorModel = color.Gray16Model\n\t\t} else {\n\t\t\td.config.ColorModel = color.GrayModel\n\t\t}\n\tdefault:\n\t\treturn nil, UnsupportedError(\"color model\")\n\t}\n\tif d.firstVal(tPhotometricInterpretation) != pRGB {\n\t\tif len(d.features[tBitsPerSample]) != 1 {\n\t\t\treturn nil, UnsupportedError(\"extra samples\")\n\t\t}\n\t}\n\n\treturn d, nil\n}", "is_vulnerable": 0}
{"code": "func TestRuntimeConfig_IsUpstream(t *testing.T) {\n\trc := makeTestRuntimeConfig()\n\trequire.True(t, rc.IsUpstream())\n\tdelete(rc.Upstreams, rc.ServiceName)\n\trequire.False(t, rc.IsUpstream())\n}", "is_vulnerable": 1}
{"code": "func ExampleHostKeyCheck() {\n\t// Every client must provide a host key check.  Here is a\n\t// simple-minded parse of OpenSSH's known_hosts file\n\thost := \"hostname\"\n\tfile, err := os.Open(filepath.Join(os.Getenv(\"HOME\"), \".ssh\", \"known_hosts\"))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer file.Close()\n\n\tscanner := bufio.NewScanner(file)\n\tvar hostKey ssh.PublicKey\n\tfor scanner.Scan() {\n\t\tfields := strings.Split(scanner.Text(), \" \")\n\t\tif len(fields) != 3 {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.Contains(fields[0], host) {\n\t\t\tvar err error\n\t\t\thostKey, _, _, _, err = ssh.ParseAuthorizedKey(scanner.Bytes())\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"error parsing %q: %v\", fields[2], err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif hostKey == nil {\n\t\tlog.Fatalf(\"no hostkey for %s\", host)\n\t}\n\n\tconfig := ssh.ClientConfig{\n\t\tUser:            os.Getenv(\"USER\"),\n\t\tHostKeyCallback: ssh.FixedHostKey(hostKey),\n\t}\n\n\t_, err = ssh.Dial(\"tcp\", host+\":22\", &config)\n\tlog.Println(err)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Websites(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Websites, error) {\n\tout := new(clientpb.Websites)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Websites\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (p *provider) RenderComponent(ctx wfContext.Context, v *value.Value, act wfTypes.Action) error {\n\tcomp, patcher, clusterName, overrideNamespace, env, err := lookUpValues(v, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\tworkload, traits, err := p.render(*comp, patcher, clusterName, overrideNamespace, env)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif workload != nil {\n\t\tif err := v.FillObject(workload.Object, \"output\"); err != nil {\n\t\t\treturn errors.WithMessage(err, \"FillOutput\")\n\t\t}\n\t}\n\n\tfor _, trait := range traits {\n\t\tname := trait.GetLabels()[oam.TraitResource]\n\t\tif name != \"\" {\n\t\t\tif err := v.FillObject(trait.Object, \"outputs\", name); err != nil {\n\t\t\t\treturn errors.WithMessage(err, \"FillOutputs\")\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func JSONEq(t TestingT, expected string, actual string, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.JSONEq(t, expected, actual, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func InitAuth(dbFilename string, users []webUser, sessionTTL uint32, rateLimiter *authRateLimiter) *Auth {\n\tlog.Info(\"Initializing auth module: %s\", dbFilename)\n\n\ta := &Auth{\n\t\tsessionTTL:  sessionTTL,\n\t\traleLimiter: rateLimiter,\n\t\tsessions:    make(map[string]*session),\n\t\tusers:       users,\n\t}\n\tvar err error\n\ta.db, err = bbolt.Open(dbFilename, 0o644, nil)\n\tif err != nil {\n\t\tlog.Error(\"auth: open DB: %s: %s\", dbFilename, err)\n\t\tif err.Error() == \"invalid argument\" {\n\t\t\tlog.Error(\"AdGuard Home cannot be initialized due to an incompatible file system.\\nPlease read the explanation here: https://github.com/AdguardTeam/AdGuardHome/wiki/Getting-Started#limitations\")\n\t\t}\n\n\t\treturn nil\n\t}\n\ta.loadSessions()\n\tlog.Info(\"auth: initialized.  users:%d  sessions:%d\", len(a.users), len(a.sessions))\n\n\treturn a\n}", "is_vulnerable": 0}
{"code": "func (m *R) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowExample\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: R: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: R: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Recognized\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowExample\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Recognized = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipExample(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthExample\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *CommonController) GetRemoteIp() string {\n\t// \u8fd9\u91cc\u4e5f\u53ef\u4ee5\u901a\u8fc7X-Forwarded-For\u8bf7\u6c42\u5934\u7684\u7b2c\u4e00\u4e2a\u503c\u4f5c\u4e3a\u7528\u6237\u7684ip\n\t// \u4f46\u662f\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e24\u4e2a\u8bf7\u6c42\u5934\u4ee3\u8868\u7684ip\u90fd\u6709\u53ef\u80fd\u662f\u4f2a\u9020\u7684\n\tip := c.Ctx.Request.Header.Get(\"X-Real-IP\")\n\tif ip == \"\" {\n\t\t// \u5f53\u8bf7\u6c42\u5934\u4e0d\u5b58\u5728\u5373\u4e0d\u5b58\u5728\u4ee3\u7406\u65f6\u76f4\u63a5\u83b7\u53d6ip\n\t\tip = strings.Split(c.Ctx.Request.RemoteAddr, \":\")[0]\n\t}\n\treturn ip\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GrantAudience(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GrantAudience\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GrantAudience), arg0)\n}", "is_vulnerable": 0}
{"code": "func (s *PrecompileTestSuite) prepareStakingRewards(stkRs ...stakingRewards) {\n\tfor _, r := range stkRs {\n\t\t// fund account to make delegation\n\t\terr := evmosutil.FundAccountWithBaseDenom(s.ctx, s.app.BankKeeper, r.Delegator, r.RewardAmt.Int64())\n\t\ts.Require().NoError(err)\n\t\t// set distribution module account balance which pays out the rewards\n\t\tdistrAcc := s.app.DistrKeeper.GetDistributionAccount(s.ctx)\n\t\terr = evmosutil.FundModuleAccount(s.ctx, s.app.BankKeeper, distrAcc.GetName(), sdk.NewCoins(sdk.NewCoin(s.bondDenom, r.RewardAmt)))\n\t\ts.Require().NoError(err)\n\n\t\t// make a delegation\n\t\t_, err = s.app.StakingKeeper.Delegate(s.ctx, r.Delegator, r.RewardAmt, stakingtypes.Unspecified, r.Validator, true)\n\t\ts.Require().NoError(err)\n\n\t\t// end block to bond validator and increase block height\n\t\tsdkstaking.EndBlocker(s.ctx, &s.app.StakingKeeper)\n\t\t// allocate rewards to validator (of these 50% will be paid out to the delegator)\n\t\tallocatedRewards := sdk.NewDecCoins(sdk.NewDecCoin(s.bondDenom, r.RewardAmt.Mul(math.NewInt(2))))\n\t\ts.app.DistrKeeper.AllocateTokensToValidator(s.ctx, r.Validator, allocatedRewards)\n\t}\n\ts.NextBlock()\n}", "is_vulnerable": 1}
{"code": "func TestPermMFADisabled(t *testing.T) {\n\tu := getTestUser()\n\tu.Filters.WebClient = []string{sdk.WebClientMFADisabled}\n\tuser, _, err := httpdtest.AddUser(u, http.StatusCreated)\n\tassert.NoError(t, err)\n\n\tconfigName, _, secret, _, err := mfa.GenerateTOTPSecret(mfa.GetAvailableTOTPConfigNames()[0], user.Username)\n\tassert.NoError(t, err)\n\ttoken, err := getJWTAPIUserTokenFromTestServer(defaultUsername, defaultPassword)\n\tassert.NoError(t, err)\n\tuserTOTPConfig := dataprovider.UserTOTPConfig{\n\t\tEnabled:    true,\n\t\tConfigName: configName,\n\t\tSecret:     kms.NewPlainSecret(secret),\n\t\tProtocols:  []string{common.ProtocolSSH},\n\t}\n\tasJSON, err := json.Marshal(userTOTPConfig)\n\tassert.NoError(t, err)\n\treq, err := http.NewRequest(http.MethodPost, userTOTPSavePath, bytes.NewBuffer(asJSON))\n\tassert.NoError(t, err)\n\tsetBearerForReq(req, token)\n\trr := executeRequest(req)\n\tcheckResponseCode(t, http.StatusForbidden, rr) // MFA is disabled for this user\n\n\tuser.Filters.WebClient = []string{sdk.WebClientWriteDisabled}\n\tuser, _, err = httpdtest.UpdateUser(user, http.StatusOK, \"\")\n\tassert.NoError(t, err)\n\n\ttoken, err = getJWTAPIUserTokenFromTestServer(defaultUsername, defaultPassword)\n\tassert.NoError(t, err)\n\treq, err = http.NewRequest(http.MethodPost, userTOTPSavePath, bytes.NewBuffer(asJSON))\n\tassert.NoError(t, err)\n\tsetBearerForReq(req, token)\n\trr = executeRequest(req)\n\tcheckResponseCode(t, http.StatusOK, rr)\n\t// now we cannot disable MFA for this user\n\tuser.Filters.WebClient = []string{sdk.WebClientMFADisabled}\n\t_, resp, err := httpdtest.UpdateUser(user, http.StatusBadRequest, \"\")\n\tassert.NoError(t, err)\n\tassert.Contains(t, string(resp), \"two-factor authentication cannot be disabled for a user with an active configuration\")\n\n\tsaveReq := make(map[string]bool)\n\tsaveReq[\"enabled\"] = false\n\tasJSON, err = json.Marshal(saveReq)\n\tassert.NoError(t, err)\n\treq, err = http.NewRequest(http.MethodPost, userTOTPSavePath, bytes.NewBuffer(asJSON))\n\tassert.NoError(t, err)\n\tsetBearerForReq(req, token)\n\trr = executeRequest(req)\n\tcheckResponseCode(t, http.StatusOK, rr)\n\n\treq, err = http.NewRequest(http.MethodGet, user2FARecoveryCodesPath, nil)\n\tassert.NoError(t, err)\n\tsetBearerForReq(req, token)\n\trr = executeRequest(req)\n\tcheckResponseCode(t, http.StatusForbidden, rr)\n\n\treq, err = http.NewRequest(http.MethodPost, user2FARecoveryCodesPath, nil)\n\tassert.NoError(t, err)\n\tsetBearerForReq(req, token)\n\trr = executeRequest(req)\n\tcheckResponseCode(t, http.StatusForbidden, rr)\n\n\t_, err = httpdtest.RemoveUser(user, http.StatusOK)\n\tassert.NoError(t, err)\n\terr = os.RemoveAll(user.GetHomeDir())\n\tassert.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func (m *NinNestedStructUnion) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinNestedStructUnion: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinNestedStructUnion: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field1 == nil {\n\t\t\t\tm.Field1 = &NinOptNativeUnion{}\n\t\t\t}\n\t\t\tif err := m.Field1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field2 == nil {\n\t\t\t\tm.Field2 = &NinOptStructUnion{}\n\t\t\t}\n\t\t\tif err := m.Field2.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field3 == nil {\n\t\t\t\tm.Field3 = &NinEmbeddedStructUnion{}\n\t\t\t}\n\t\t\tif err := m.Field3.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func FailNowf(t TestingT, failureMessage string, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.FailNowf(t, failureMessage, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\treq.Handlers.Unmarshal.PushBack(func(r *request.Request) {\n\t\tenv, err := c.LoadStrategy.Load(r)\n\t\tif err != nil {\n\t\t\tr.Error = err\n\t\t\tout.Body.Close()\n\t\t\treturn\n\t\t}\n\n\t\t// If KMS should return the correct CEK algorithm with the proper\n\t\t// KMS key provider\n\t\tcipher, err := c.contentCipherFromEnvelope(r.Context(), env)\n\t\tif err != nil {\n\t\t\tr.Error = err\n\t\t\tout.Body.Close()\n\t\t\treturn\n\t\t}\n\n\t\treader, err := cipher.DecryptContents(out.Body)\n\t\tif err != nil {\n\t\t\tr.Error = err\n\t\t\tout.Body.Close()\n\t\t\treturn\n\t\t}\n\t\tout.Body = reader\n\t})", "is_vulnerable": 1}
{"code": "func (f *Framework) newIngressController(namespace string, namespaceOverlay string) error {\n\t// Creates an nginx deployment\n\tisChroot, ok := os.LookupEnv(\"IS_CHROOT\")\n\tif !ok {\n\t\tisChroot = \"false\"\n\t}\n\n\tenableAnnotationValidations, ok := os.LookupEnv(\"ENABLE_VALIDATIONS\")\n\tif !ok {\n\t\tenableAnnotationValidations = \"false\"\n\t}\n\tcmd := exec.Command(\"./wait-for-nginx.sh\", namespace, namespaceOverlay, isChroot, enableAnnotationValidations)\n\tout, err := cmd.CombinedOutput()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unexpected error waiting for ingress controller deployment: %v.\\nLogs:\\n%v\", err, string(out))\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (ep *Endpoint) SetIsHost(isHost bool) {\n\tep.isHost = isHost\n}", "is_vulnerable": 0}
{"code": "func (mkcp *MesheryK8sContextPersister) GetMesheryK8sContexts(search, order string, page, pageSize uint64) ([]byte, error) {\n\torder = SanitizeOrderInput(order, []string{\"created_at\", \"updated_at\", \"name\"})\n\n\tif order == \"\" {\n\t\torder = \"updated_at desc\"\n\t}\n\n\tcount := int64(0)\n\tcontexts := []*K8sContext{}\n\n\tquery := mkcp.DB.Order(order)\n\n\tif search != \"\" {\n\t\tlike := \"%\" + strings.ToLower(search) + \"%\"\n\t\tquery = query.Where(\"(lower(name) like ?)\", like)\n\t}\n\n\tquery.Model(K8sContext{}).Count(&count)\n\n\tPaginate(uint(page), uint(pageSize))(query).Find(&contexts)\n\n\tmesheryK8sContextPage := MesheryK8sContextPage{\n\t\tPage:       page,\n\t\tPageSize:   pageSize,\n\t\tTotalCount: int(count),\n\t\tContexts:   contexts,\n\t}\n\n\tresp, _ := json.Marshal(mesheryK8sContextPage)\n\treturn resp, nil\n}", "is_vulnerable": 0}
{"code": "func newTestAppServer(t *testing.T, objects ...runtime.Object) *Server {\n\tf := func(enf *rbac.Enforcer) {\n\t\t_ = enf.SetBuiltinPolicy(assets.BuiltinPolicyCSV)\n\t\tenf.SetDefaultRole(\"role:admin\")\n\t}\n\treturn newTestAppServerWithEnforcerConfigure(f, t, objects...)\n}", "is_vulnerable": 0}
{"code": "func bindMountContainerRootfs(ctx context.Context, sharedDir, sandboxID, cID, cRootFs string, readonly bool) error {\n\tspan, _ := trace(ctx, \"bindMountContainerRootfs\")\n\tdefer span.Finish()\n\n\trootfsDest := filepath.Join(sharedDir, sandboxID, cID, rootfsDir)\n\n\treturn bindMount(ctx, cRootFs, rootfsDest, readonly, \"private\")\n}", "is_vulnerable": 1}
{"code": "func isTrustedAddress(addr string, trustedCidrs []string) bool {\n\tfor _, cidr := range trustedCidrs {\n\t\tif isInRange(addr, cidr) {\n\t\t\treturn true\n\t\t}\n\t}\n\t// Always trust local host addresses.\n\treturn net.ParseIP(addr).IsLoopback()\n}", "is_vulnerable": 1}
{"code": "func (s *StdoutSink) Process(ctx context.Context, e *eventlogger.Event) (*eventlogger.Event, error) {\n\tconst op = \"event.(StdoutSink).Process\"\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\tif e == nil {\n\t\treturn nil, fmt.Errorf(\"%s: event is nil: %w\", op, ErrInvalidParameter)\n\t}\n\n\tformattedBytes, found := e.Format(s.requiredFormat)\n\tif !found {\n\t\treturn nil, fmt.Errorf(\"%s: unable to retrieve event formatted as %q\", op, s.requiredFormat)\n\t}\n\n\t_, err := os.Stdout.Write(formattedBytes)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: error writing to stdout: %w\", op, err)\n\t}\n\n\t// Return nil, nil to indicate the pipeline is complete.\n\treturn nil, nil\n}", "is_vulnerable": 0}
{"code": "func inSelectInTableIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase StartTagToken, EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Caption, a.Table, a.Tbody, a.Tfoot, a.Thead, a.Tr, a.Td, a.Th:\n\t\t\tif p.tok.Type == StartTagToken || p.elementInScope(tableScope, p.tok.DataAtom) {\n\t\t\t\tp.parseImpliedToken(EndTagToken, a.Select, a.Select.String())\n\t\t\t\treturn false\n\t\t\t} else {\n\t\t\t\t// Ignore the token.\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn inSelectIM(p)\n}", "is_vulnerable": 1}
{"code": "func TestJQPathExpressionReturnsHelpfulError(t *testing.T) {\n\tnormalizer, err := NewIgnoreNormalizer([]v1alpha1.ResourceIgnoreDifferences{{\n\t\tKind: \"ConfigMap\",\n\t\t// This is a really wild expression, but it does trigger the desired error.\n\t\tJQPathExpressions: []string{`.nothing) | .data[\"config.yaml\"] |= (fromjson | del(.auth) | tojson`},\n\t}}, nil)\n\n\tassert.NoError(t, err)\n\n\tconfigMap := test.NewConfigMap()\n\trequire.NoError(t, err)\n\n\tout := test.CaptureLogEntries(func() {\n\t\terr = normalizer.Normalize(configMap)\n\t\trequire.NoError(t, err)\n\t})\n\tassert.Contains(t, out, \"fromjson cannot be applied\")\n}", "is_vulnerable": 1}
{"code": "func beIncubator(args []string) error {\n\tia := parseIncubatorArgs(args)\n\tif ia.isSFTP && ia.isShell {\n\t\treturn fmt.Errorf(\"--sftp and --shell are mutually exclusive\")\n\t}\n\n\tlogf := logger.Discard\n\tif debugIncubator {\n\t\t// We don't own stdout or stderr, so the only place we can log is syslog.\n\t\tif sl, err := syslog.New(syslog.LOG_INFO|syslog.LOG_DAEMON, \"tailscaled-ssh\"); err == nil {\n\t\t\tlogf = log.New(sl, \"\", 0).Printf\n\t\t}\n\t}\n\n\teuid := uint64(os.Geteuid())\n\trunningAsRoot := euid == 0\n\tif runningAsRoot && ia.loginCmdPath != \"\" {\n\t\t// Check if we can exec into the login command instead of trying to\n\t\t// incubate ourselves.\n\t\tif la := ia.loginArgs(); la != nil {\n\t\t\treturn unix.Exec(ia.loginCmdPath, la, os.Environ())\n\t\t}\n\t}\n\n\t// Inform the system that we are about to log someone in.\n\t// We can only do this if we are running as root.\n\t// This is best effort to still allow running on machines where\n\t// we don't support starting sessions, e.g. darwin.\n\tsessionCloser, err := maybeStartLoginSession(logf, ia)\n\tif err == nil && sessionCloser != nil {\n\t\tdefer sessionCloser()\n\t}\n\n\tvar groupIDs []int\n\tfor _, g := range strings.Split(ia.groups, \",\") {\n\t\tgid, err := strconv.ParseInt(g, 10, 32)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tgroupIDs = append(groupIDs, int(gid))\n\t}\n\n\tif err := dropPrivileges(logf, int(ia.uid), ia.gid, groupIDs); err != nil {\n\t\treturn err\n\t}\n\n\tif ia.isSFTP {\n\t\tlogf(\"handling sftp\")\n\n\t\tserver, err := sftp.NewServer(stdRWC{})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn server.Serve()\n\t}\n\n\tcmd := exec.Command(ia.cmdName, ia.cmdArgs...)\n\tcmd.Stdin = os.Stdin\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\tcmd.Env = os.Environ()\n\n\tif ia.hasTTY {\n\t\t// If we were launched with a tty then we should\n\t\t// mark that as the ctty of the child. However,\n\t\t// as the ctty is being passed from the parent\n\t\t// we set the child to foreground instead which\n\t\t// also passes the ctty.\n\t\t// However, we can not do this if never had a tty to\n\t\t// begin with.\n\t\tcmd.SysProcAttr = &syscall.SysProcAttr{\n\t\t\tForeground: true,\n\t\t}\n\t}\n\terr = cmd.Run()\n\tif ee, ok := err.(*exec.ExitError); ok {\n\t\tps := ee.ProcessState\n\t\tcode := ps.ExitCode()\n\t\tif code < 0 {\n\t\t\t// TODO(bradfitz): do we need to also check the syscall.WaitStatus\n\t\t\t// and make our process look like it also died by signal/same signal\n\t\t\t// as our child process? For now we just do the exit code.\n\t\t\tfmt.Fprintf(os.Stderr, \"[tailscale-ssh: process died: %v]\\n\", ps.String())\n\t\t\tcode = 1 // for now. so we don't exit with negative\n\t\t}\n\t\tos.Exit(code)\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func TestClusterBroadcastHooks(t *testing.T) {\n\tt.Run(\"should send broadcast hook information across cluster\", func(t *testing.T) {\n\t\ttestCluster := &testlib.FakeClusterInterface{}\n\n\t\tth := SetupWithCluster(t, testCluster)\n\t\tdefer th.TearDown()\n\n\t\thookID := broadcastTest\n\t\thookArgs := map[string]any{\n\t\t\t\"makes_changes\": true,\n\t\t}\n\n\t\tevent := model.NewWebSocketEvent(model.WebsocketEventPosted, \"\", \"\", \"\", nil, \"\")\n\t\tevent.GetBroadcast().AddHook(hookID, hookArgs)\n\n\t\tth.Service.Publish(event)\n\n\t\treceived, err := model.WebSocketEventFromJSON(bytes.NewReader(testCluster.GetMessages()[0].Data))\n\n\t\trequire.NoError(t, err)\n\t\tassert.Equal(t, []string{hookID}, received.GetBroadcast().BroadcastHooks)\n\t\tassert.Equal(t, []map[string]any{hookArgs}, received.GetBroadcast().BroadcastHookArgs)\n\t})\n\n\tt.Run(\"should not preserve type information for args\", func(t *testing.T) {\n\t\t// This behaviour isn't ideal, but this test confirms that it hasn't changed\n\t\ttestCluster := &testlib.FakeClusterInterface{}\n\n\t\tth := SetupWithCluster(t, testCluster)\n\t\tdefer th.TearDown()\n\n\t\thookID := \"test_broadcast_hook_with_args\"\n\t\thookArgs := map[string]any{\n\t\t\t\"user\":  &model.User{Id: \"user1\"},\n\t\t\t\"array\": []string{\"a\", \"b\", \"c\"},\n\t\t}\n\n\t\tevent := model.NewWebSocketEvent(model.WebsocketEventPosted, \"\", \"\", \"\", nil, \"\")\n\t\tevent.GetBroadcast().AddHook(hookID, hookArgs)\n\n\t\tth.Service.Publish(event)\n\n\t\treceived, err := model.WebSocketEventFromJSON(bytes.NewReader(testCluster.GetMessages()[0].Data))\n\n\t\trequire.NoError(t, err)\n\t\tassert.Equal(t, []string{hookID}, received.GetBroadcast().BroadcastHooks)\n\t\tassert.IsType(t, map[string]any{}, received.GetBroadcast().BroadcastHookArgs[0][\"user\"])\n\t\tassert.IsType(t, []any{}, received.GetBroadcast().BroadcastHookArgs[0][\"array\"])\n\t})\n}", "is_vulnerable": 0}
{"code": "func checkInitLabelsPolicy(cnp *unstructured.Unstructured) error {\n\tcnpBytes, err := cnp.MarshalJSON()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresCNP := cilium_v2.CiliumNetworkPolicy{}\n\terr = json.Unmarshal(cnpBytes, &resCNP)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, spec := range append(resCNP.Specs, resCNP.Spec) {\n\t\tif spec == nil {\n\t\t\tcontinue\n\t\t}\n\t\tpodInitLbl := labels.LabelSourceReservedKeyPrefix + labels.IDNameInit\n\t\tif spec.EndpointSelector.HasKey(podInitLbl) {\n\t\t\tlogOnce.Do(func() {\n\t\t\t\tlog.WithFields(logrus.Fields{\n\t\t\t\t\tlogfields.CiliumNetworkPolicyName: cnp.GetName(),\n\t\t\t\t}).Error(logInitPolicyCNP)\n\t\t\t})\n\t\t\treturn errInitPolicyCNP\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *CAServer) CreateCertificate(ctx context.Context, request *pb.IstioCertificateRequest) (\n\t*pb.IstioCertificateResponse, error,\n) {\n\tcaServerLog.Infof(\"received CSR request\")\n\tif s.shouldReject() {\n\t\tcaServerLog.Info(\"force rejecting CSR request\")\n\t\treturn nil, status.Error(codes.Unavailable, \"CA server is not available\")\n\t}\n\tif s.sendEmpty() {\n\t\tcaServerLog.Info(\"force sending empty cert chain in CSR response\")\n\t\tresponse := &pb.IstioCertificateResponse{\n\t\t\tCertChain: []string{},\n\t\t}\n\t\treturn response, nil\n\t}\n\tid := []string{\"client-identity\"}\n\tif len(s.Authenticators) > 0 {\n\t\tam := security.AuthenticationManager{Authenticators: s.Authenticators}\n\t\tcaller := am.Authenticate(ctx)\n\t\tif caller == nil {\n\t\t\tcaServerLog.Errorf(\"Failed to authenticate client from %s: %s\", security.GetConnectionAddress(ctx), am.FailedMessages())\n\t\t\treturn nil, status.Error(codes.Unauthenticated, \"request authenticate failure\")\n\t\t}\n\t\tid = caller.Identities\n\t}\n\tcert, err := s.sign([]byte(request.Csr), id, time.Duration(request.ValidityDuration)*time.Second, false)\n\tif err != nil {\n\t\tcaServerLog.Errorf(\"failed to sign CSR: %+v\", err)\n\t\treturn nil, status.Errorf(err.(*caerror.Error).HTTPErrorCode(), \"CSR signing error: %+v\", err.(*caerror.Error))\n\t}\n\trespCertChain := []string{string(cert)}\n\trespCertChain = append(respCertChain, string(s.certPem))\n\tresponse := &pb.IstioCertificateResponse{\n\t\tCertChain: respCertChain,\n\t}\n\tcaServerLog.Info(\"send back CSR success response\")\n\treturn response, nil\n}", "is_vulnerable": 0}
{"code": "func (mr *MockTokenRevocationStorageMockRecorder) DeleteAccessTokenSession(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DeleteAccessTokenSession\", reflect.TypeOf((*MockTokenRevocationStorage)(nil).DeleteAccessTokenSession), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func TestCheckPermissionOverSchema(t *testing.T) {\n\ttestCases := []struct {\n\t\tname                      string\n\t\tschema                    string\n\t\trelationships             []*core.RelationTuple\n\t\tresource                  *core.ObjectAndRelation\n\t\tsubject                   *core.ObjectAndRelation\n\t\texpectedPermissionship    v1.ResourceCheckResult_Membership\n\t\texpectedCaveat            *core.CaveatExpression\n\t\talternativeExpectedCaveat *core.CaveatExpression\n\t}{\n\t\t{\n\t\t\t\"basic union\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic intersection\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer & editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#editor@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic exclusion\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic union, multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#editor@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic union no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic intersection no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer & editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic exclusion no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation banned: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - banned\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#banned@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"exclusion with multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation banned: user\n\t\t\t \tpermission view = member - banned\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#banned@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"intersection with multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation other: user\n\t\t\t \tpermission view = member & other\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#other@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"exclusion with multiple branches no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation banned: user\n\t\t\t \tpermission view = member - banned\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#banned@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#banned@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"intersection with multiple branches no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation other: user\n\t\t\t \tpermission view = member & other\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic arrow\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs->member\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic any arrow\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.any(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow negative\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive with different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow negative over different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@someotherresource:other\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive over different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@someotherresource:other\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"someotherresource:other#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"all arrow for single org\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"all arrow for no orgs\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_all negative\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n    permission view_by_any = team.any(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"threeteams\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_any positive\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n\trelation viewer: user\n    permission view_by_all = team.all(member) + viewer\n    permission view_by_any = team.any(member) + viewer\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#viewer@user:rachel\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"threeteams\", \"view_by_any\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_any positive directly\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n\trelation viewer: user\n    permission view_by_all = team.all(member) + viewer\n    permission view_by_any = team.any(member) + viewer\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#viewer@user:rachel\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_any\"),\n\t\t\tONR(\"user\", \"rachel\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first[somecaveat]\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"intersection arrow with caveated member\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom[somecaveat]\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with caveated member\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom[somecaveat]\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first[somecaveat]\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with caveated member, different context\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with anothercaveat\n    permission member = direct_member\n  }\n\n  caveat anothercaveat(someparam int) {\n    someparam == 43\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom[anothercaveat:{\"someparam\": 43}]`),\n\t\t\t\ttuple.MustParse(`resource:oneteam#team@team:first[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"anothercaveat\", map[string]any{\"someparam\": int64(43)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with multiple caveated branches\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first[somecaveat:{\"someparam\": 41}]`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second[somecaveat:{\"someparam\": 42}]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(41)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with multiple caveated members\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom[somecaveat:{\"someparam\": 41}]`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(41)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with one caveated branch\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat | team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second[somecaveat:{\"someparam\": 42}]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with one caveated member\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow multiple paths to the same subject\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat | team#direct_member with somecaveat\n    permission view_by_all = team.all(member) // Note: this points to the same team twice\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first#direct_member[somecaveat]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow positive result\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow negative result\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow negative result due to recursion missing a folder\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root3\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated over multiple branches\",\n\t\t\t`\n\t\t\t caveat somecaveat(somevalue int) {\n\t\t\t    somevalue == 42\n\t\t\t }\n\n  definition user {}\n\n  definition role {\n    relation member: user\n  }\n\n  definition resource {\n      relation viewer: role#member with somecaveat\n      permission view = viewer\n  }\n\t\t\t`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`role:firstrole#member@user:tom[somecaveat:{\"somevalue\":40}]`),\n\t\t\t\ttuple.MustParse(`role:secondrole#member@user:tom[somecaveat:{\"somevalue\":42}]`),\n\t\t\t\ttuple.MustParse(`resource:doc1#viewer@role:firstrole#member`),\n\t\t\t\ttuple.MustParse(`resource:doc1#viewer@role:secondrole#member`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatOr(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(40)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(42)}),\n\t\t\t),\n\t\t\tcaveatOr(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(42)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(40)}),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\t\"caveated over multiple branches reversed\",\n\t\t\t`\n\t\t\t caveat somecaveat(somevalue int) {\n\t\t\t    somevalue == 42\n\t\t\t }\n\n  definition user {}\n  \n  definition role {\n    relation member: user\n  }\n\n  definition resource {\n      relation viewer: role#member with somecaveat\n      permission view = viewer\n  }\n\t\t\t`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`role:secondrole#member@user:tom[somecaveat:{\"somevalue\":42}]`),\n\t\t\t\ttuple.MustParse(`role:firstrole#member@user:tom[somecaveat:{\"somevalue\":40}]`),\n\t\t\t\ttuple.MustParse(`resource:doc1#viewer@role:secondrole#member`),\n\t\t\t\ttuple.MustParse(`resource:doc1#viewer@role:firstrole#member`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatOr(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(40)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(42)}),\n\t\t\t),\n\t\t\tcaveatOr(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(42)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"somevalue\": int64(40)}),\n\t\t\t),\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\tdispatcher := NewLocalOnlyDispatcher(10, 100)\n\n\t\t\tds, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\t\t\trequire.NoError(err)\n\n\t\t\tds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(ds, tc.schema, tc.relationships, require)\n\n\t\t\tctx := datastoremw.ContextWithHandle(context.Background())\n\t\t\trequire.NoError(datastoremw.SetInContext(ctx, ds))\n\n\t\t\tresp, err := dispatcher.DispatchCheck(ctx, &v1.DispatchCheckRequest{\n\t\t\t\tResourceRelation: RR(tc.resource.Namespace, tc.resource.Relation),\n\t\t\t\tResourceIds:      []string{tc.resource.ObjectId},\n\t\t\t\tSubject:          tc.subject,\n\t\t\t\tMetadata: &v1.ResolverMeta{\n\t\t\t\t\tAtRevision:     revision.String(),\n\t\t\t\t\tDepthRemaining: 50,\n\t\t\t\t},\n\t\t\t\tResultsSetting: v1.DispatchCheckRequest_ALLOW_SINGLE_RESULT,\n\t\t\t})\n\t\t\trequire.NoError(err)\n\n\t\t\tmembership := v1.ResourceCheckResult_NOT_MEMBER\n\t\t\tif r, ok := resp.ResultsByResourceId[tc.resource.ObjectId]; ok {\n\t\t\t\tmembership = r.Membership\n\t\t\t}\n\n\t\t\trequire.Equal(tc.expectedPermissionship, membership)\n\n\t\t\tif tc.expectedCaveat != nil && tc.alternativeExpectedCaveat == nil {\n\t\t\t\trequire.NotEmpty(resp.ResultsByResourceId[tc.resource.ObjectId].Expression)\n\t\t\t\ttestutil.RequireProtoEqual(t, tc.expectedCaveat, resp.ResultsByResourceId[tc.resource.ObjectId].Expression, \"mismatch in caveat\")\n\t\t\t}\n\n\t\t\tif tc.expectedCaveat != nil && tc.alternativeExpectedCaveat != nil {\n\t\t\t\trequire.NotEmpty(resp.ResultsByResourceId[tc.resource.ObjectId].Expression)\n\n\t\t\t\tif testutil.AreProtoEqual(tc.expectedCaveat, resp.ResultsByResourceId[tc.resource.ObjectId].Expression, \"mismatch in caveat\") != nil {\n\t\t\t\t\ttestutil.RequireProtoEqual(t, tc.alternativeExpectedCaveat, resp.ResultsByResourceId[tc.resource.ObjectId].Expression, \"mismatch in caveat\")\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func checkAllowlist(r *library.Repo, allowlist []string) bool {\n\t// check if all repos are allowed to be enabled\n\tif len(allowlist) == 1 && allowlist[0] == \"*\" {\n\t\treturn true\n\t}\n\n\tfor _, repo := range allowlist {\n\t\t// allow all repos in org\n\t\tif strings.Contains(repo, \"/*\") {\n\t\t\tif strings.HasPrefix(repo, r.GetOrg()) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\n\t\t// allow specific repo within org\n\t\tif repo == r.GetFullName() {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (mr *MockERC20BridgeViewMockRecorder) FindBridgeStopped(arg0, arg1, arg2, arg3 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"FindBridgeStopped\", reflect.TypeOf((*MockERC20BridgeView)(nil).FindBridgeStopped), arg0, arg1, arg2, arg3)\n}", "is_vulnerable": 0}
{"code": "\t\tKeyFunc: func(ctx api.Context, name string) (string, error) {\n\t\t\treturn path.Join(prefix, name), nil\n\t\t},", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) DiskUsage(allowStaleValue bool) (int64, error) {\n\t// A disk check interval of 0 means this functionality is completely disabled.\n\tif fs.diskCheckInterval == 0 {\n\t\treturn 0, nil\n\t}\n\n\tif !fs.lastLookupTime.Get().After(time.Now().Add(time.Second * fs.diskCheckInterval * -1)) {\n\t\t// If we are now allowing a stale response go ahead  and perform the lookup and return the fresh\n\t\t// value. This is a blocking operation to the calling process.\n\t\tif !allowStaleValue {\n\t\t\treturn fs.updateCachedDiskUsage()\n\t\t} else if !fs.lookupInProgress.Load() {\n\t\t\t// Otherwise, if we allow a stale value and there isn't a valid item in the cache and we aren't\n\t\t\t// currently performing a lookup, just do the disk usage calculation in the background.\n\t\t\tgo func(fs *Filesystem) {\n\t\t\t\tif _, err := fs.updateCachedDiskUsage(); err != nil {\n\t\t\t\t\tlog.WithField(\"root\", fs.root).WithField(\"error\", err).Warn(\"failed to update fs disk usage from within routine\")\n\t\t\t\t}\n\t\t\t}(fs)\n\t\t}\n\t}\n\n\t// Return the currently cached value back to the calling function.\n\treturn atomic.LoadInt64(&fs.diskUsed), nil\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn customhttperrors{\n\t\tr:                r,\n\t\tannotationConfig: customHTTPErrorsAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (w wasm) CanApply(config *extensioncommon.RuntimeConfig) bool {\n\treturn config.IsLocal() && w.wasmConfig.ListenerType == \"inbound\" &&\n\t\tconfig.Kind == w.wasmConfig.ProxyType\n\n}", "is_vulnerable": 1}
{"code": "func TestInferResourcesStatusHealth(t *testing.T) {\n\tcacheClient := cacheutil.NewCache(cacheutil.NewInMemoryCache(1 * time.Hour))\n\n\ttestApp := newTestApp()\n\ttestApp.Status.ResourceHealthSource = appsv1.ResourceHealthLocationAppTree\n\ttestApp.Status.Resources = []appsv1.ResourceStatus{{\n\t\tGroup:     \"apps\",\n\t\tKind:      \"Deployment\",\n\t\tName:      \"guestbook\",\n\t\tNamespace: \"default\",\n\t}, {\n\t\tGroup:     \"apps\",\n\t\tKind:      \"StatefulSet\",\n\t\tName:      \"guestbook-stateful\",\n\t\tNamespace: \"default\",\n\t}}\n\tappServer := newTestAppServer(testApp)\n\tappStateCache := appstate.NewCache(cacheClient, time.Minute)\n\terr := appStateCache.SetAppResourcesTree(testApp.Name, &appsv1.ApplicationTree{Nodes: []appsv1.ResourceNode{{\n\t\tResourceRef: appsv1.ResourceRef{\n\t\t\tGroup:     \"apps\",\n\t\t\tKind:      \"Deployment\",\n\t\t\tName:      \"guestbook\",\n\t\t\tNamespace: \"default\",\n\t\t},\n\t\tHealth: &appsv1.HealthStatus{\n\t\t\tStatus: health.HealthStatusDegraded,\n\t\t},\n\t}}})\n\n\trequire.NoError(t, err)\n\n\tappServer.cache = servercache.NewCache(appStateCache, time.Minute, time.Minute, time.Minute)\n\n\tappServer.inferResourcesStatusHealth(testApp)\n\n\tassert.Equal(t, health.HealthStatusDegraded, testApp.Status.Resources[0].Health.Status)\n\tassert.Nil(t, testApp.Status.Resources[1].Health)\n}", "is_vulnerable": 1}
{"code": "func (self *Compress) Call(ctx context.Context,\n\tscope vfilter.Scope,\n\targs *ordereddict.Dict) vfilter.Any {\n\n\terr := vql_subsystem.CheckAccess(scope, acls.FILESYSTEM_WRITE)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\n\targ := &CompressArgs{}\n\terr = arg_parser.ExtractArgsWithContext(ctx, scope, args, arg)\n\tif err != nil {\n\t\tscope.Log(\"compress: %s\", err.Error())\n\t\treturn vfilter.Null{}\n\t}\n\n\tfd, err := os.Open(arg.Path)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\tdefer fd.Close()\n\n\tout_fd, err := os.OpenFile(arg.Output,\n\t\tos.O_RDWR|os.O_CREATE|os.O_TRUNC, 0660)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\tdefer out_fd.Close()\n\n\tzw := gzip.NewWriter(out_fd)\n\tdefer zw.Close()\n\n\tzw.Name = strings.TrimPrefix(arg.Path, \"/\")\n\n\t_, err = utils.Copy(ctx, zw, fd)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\terr2 := os.Remove(arg.Output)\n\t\tif err2 != nil {\n\t\t\tscope.Log(\"compress: cleaning up %v (%v)\", err2, err)\n\t\t}\n\t\treturn vfilter.Null{}\n\t}\n\n\treturn arg.Output\n}", "is_vulnerable": 1}
{"code": "func (e *Environment) resources() container.Resources {\n\tl := e.Configuration.Limits()\n\tpids := l.ProcessLimit()\n\n\treturn container.Resources{\n\t\tMemory:            l.BoundedMemoryLimit(),\n\t\tMemoryReservation: l.MemoryLimit * 1_000_000,\n\t\tMemorySwap:        l.ConvertedSwap(),\n\t\tCPUQuota:          l.ConvertedCpuLimit(),\n\t\tCPUPeriod:         100_000,\n\t\tCPUShares:         1024,\n\t\tBlkioWeight:       l.IoWeight,\n\t\tOomKillDisable:    &l.OOMDisabled,\n\t\tCpusetCpus:        l.Threads,\n\t\tPidsLimit:         &pids,\n\t}\n}", "is_vulnerable": 0}
{"code": "func computeNodeIPsecKey(globalKey, srcNodeIP, dstNodeIP, srcBootID, dstBootID []byte) []byte {\n\tinputLen := len(globalKey) + len(srcNodeIP) + len(dstNodeIP) + len(srcBootID) + len(dstBootID)\n\tinput := make([]byte, 0, inputLen)\n\tinput = append(input, globalKey...)\n\tinput = append(input, srcNodeIP...)\n\tinput = append(input, dstNodeIP...)\n\tinput = append(input, srcBootID[:36]...)\n\tinput = append(input, dstBootID[:36]...)\n\toutput := sha256.Sum256(input)\n\treturn output[:len(globalKey)]\n}", "is_vulnerable": 0}
{"code": "func mask(data map[string]interface{}, fieldNames []string) {\n\tfor k, v := range data {\n\t\tif contains(fieldNames, k) {\n\t\t\tdata[k] = redacted\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch t := v.(type) {\n\t\tcase map[string]interface{}:\n\t\t\tmask(t, fieldNames)\n\t\tcase []interface{}:\n\t\t\tfor i, item := range t {\n\t\t\t\tif subData, ok := item.(map[string]interface{}); ok {\n\t\t\t\t\tmask(subData, fieldNames)\n\t\t\t\t\tt[i] = subData\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func isChunked(r *http.Request) bool {\n\t//RFC 7230 specifies that content length is to be ignored if Transfer-Encoding is chunked\n\tif strings.EqualFold(r.Header.Get(\"Transfer-Encoding\"), \"chunked\") {\n\t\treturn true\n\t}\n\tfor _, v := range r.TransferEncoding {\n\t\tif strings.EqualFold(v, \"chunked\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (c *Container) shareFiles(m Mount, idx int, hostSharedDir, guestSharedDir string) (string, bool, error) {\n\trandBytes, err := utils.GenerateRandomBytes(8)\n\tif err != nil {\n\t\treturn \"\", false, err\n\t}\n\n\tfilename := fmt.Sprintf(\"%s-%s-%s\", c.id, hex.EncodeToString(randBytes), filepath.Base(m.Destination))\n\tguestDest := filepath.Join(guestSharedDir, filename)\n\n\t// copy file to contaier's rootfs if filesystem sharing is not supported, otherwise\n\t// bind mount it in the shared directory.\n\tcaps := c.sandbox.hypervisor.capabilities()\n\tif !caps.IsFsSharingSupported() {\n\t\tc.Logger().Debug(\"filesystem sharing is not supported, files will be copied\")\n\n\t\tfileInfo, err := os.Stat(m.Source)\n\t\tif err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\n\t\t// Ignore the mount if this is not a regular file (excludes\n\t\t// directory, socket, device, ...) as it cannot be handled by\n\t\t// a simple copy. But this should not be treated as an error,\n\t\t// only as a limitation.\n\t\tif !fileInfo.Mode().IsRegular() {\n\t\t\tc.Logger().WithField(\"ignored-file\", m.Source).Debug(\"Ignoring non-regular file as FS sharing not supported\")\n\t\t\treturn \"\", true, nil\n\t\t}\n\n\t\tif err := c.sandbox.agent.copyFile(m.Source, guestDest); err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\t} else {\n\t\t// These mounts are created in the shared dir\n\t\tmountDest := filepath.Join(hostSharedDir, filename)\n\t\tif err := bindMount(c.ctx, m.Source, mountDest, false, \"private\"); err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\t\t// Save HostPath mount value into the mount list of the container.\n\t\tc.mounts[idx].HostPath = mountDest\n\t}\n\n\treturn guestDest, false, nil\n}", "is_vulnerable": 0}
{"code": "func CreateClientSets(config *restclient.Config) (kubeClient kubernetes.Interface, userClient userv1.UserV1Interface, coreClient v1beta1.EnmasseV1beta1Interface, err error) {\n\tkubeClient, err = kubernetes.NewForConfig(config)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tuserClient, err = userv1.NewForConfig(config)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tcoreClient, err = v1beta1.NewForConfig(config)\n\tif err != nil {\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func Decode(data []byte) (b *Block, rest []byte) {\n\t// start begins with a newline. However, at the very beginning of\n\t// the byte array, we'll accept the start string without it.\n\trest = data\n\tif bytes.HasPrefix(data, start[1:]) {\n\t\trest = rest[len(start)-1:]\n\t} else if i := bytes.Index(data, start); i >= 0 {\n\t\trest = rest[i+len(start):]\n\t} else {\n\t\treturn nil, data\n\t}\n\n\t// Consume the start line.\n\t_, rest = getLine(rest)\n\n\tvar line []byte\n\tb = &Block{\n\t\tHeaders: make(textproto.MIMEHeader),\n\t}\n\n\t// Next come a series of header lines.\n\tfor {\n\t\t// This loop terminates because getLine's second result is\n\t\t// always smaller than its argument.\n\t\tif len(rest) == 0 {\n\t\t\treturn nil, data\n\t\t}\n\t\t// An empty line marks the end of the headers.\n\t\tif line, rest = getLine(rest); len(line) == 0 {\n\t\t\tbreak\n\t\t}\n\n\t\ti := bytes.Index(line, []byte{':'})\n\t\tif i == -1 {\n\t\t\treturn nil, data\n\t\t}\n\n\t\tkey, val := line[0:i], line[i+1:]\n\t\tkey = bytes.TrimSpace(key)\n\t\tval = bytes.TrimSpace(val)\n\t\tb.Headers.Add(string(key), string(val))\n\t}\n\n\tfirstLine := true\n\tfor {\n\t\tstart := rest\n\n\t\tline, rest = getLine(rest)\n\t\tif len(line) == 0 && len(rest) == 0 {\n\t\t\t// No armored data was found, so this isn't a complete message.\n\t\t\treturn nil, data\n\t\t}\n\t\tif bytes.Equal(line, endText) {\n\t\t\t// Back up to the start of the line because armor expects to see the\n\t\t\t// header line.\n\t\t\trest = start\n\t\t\tbreak\n\t\t}\n\n\t\t// The final CRLF isn't included in the hash so we don't write it until\n\t\t// we've seen the next line.\n\t\tif firstLine {\n\t\t\tfirstLine = false\n\t\t} else {\n\t\t\tb.Bytes = append(b.Bytes, crlf...)\n\t\t}\n\n\t\tif bytes.HasPrefix(line, dashEscape) {\n\t\t\tline = line[2:]\n\t\t}\n\t\tline = bytes.TrimRight(line, \" \\t\")\n\t\tb.Bytes = append(b.Bytes, line...)\n\n\t\tb.Plaintext = append(b.Plaintext, line...)\n\t\tb.Plaintext = append(b.Plaintext, lf)\n\t}\n\n\t// We want to find the extent of the armored data (including any newlines at\n\t// the end).\n\ti := bytes.Index(rest, end)\n\tif i == -1 {\n\t\treturn nil, data\n\t}\n\ti += len(end)\n\tfor i < len(rest) && (rest[i] == '\\r' || rest[i] == '\\n') {\n\t\ti++\n\t}\n\tarmored := rest[:i]\n\trest = rest[i:]\n\n\tvar err error\n\tb.ArmoredSignature, err = armor.Decode(bytes.NewBuffer(armored))\n\tif err != nil {\n\t\treturn nil, data\n\t}\n\n\treturn b, rest\n}", "is_vulnerable": 1}
{"code": "func (r *reconciler) updateLoadBalancerService(current, desired *corev1.Service, platform *configv1.PlatformStatus) (bool, error) {\n\tchanged, updated, needRecreate := loadBalancerServiceChanged(current, desired, platform)\n\tif !changed {\n\t\treturn false, nil\n\t}\n\n\tif needRecreate {\n\t\tlog.Info(\"load balancer scope changed, which requires deleting and recreating the load balancer\", \"namespace\", updated.Namespace, \"name\", updated.Name, \"platform\", platform.Type)\n\t\tforeground := metav1.DeletePropagationForeground\n\t\tdeleteOptions := crclient.DeleteOptions{PropagationPolicy: &foreground}\n\t\tif err := r.deleteLoadBalancerService(current, &deleteOptions); err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif err := r.createLoadBalancerService(updated); err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn true, nil\n\t}\n\n\tif err := r.client.Update(context.TODO(), updated); err != nil {\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "is_vulnerable": 1}
{"code": "func SnapshotFileMetaEqual(actual data.SnapshotFileMeta, expected data.SnapshotFileMeta) error {\n\t// TUF-1.0 no longer considers the length and hashes to be a required\n\t// member of snapshots. However they are considering requiring hashes\n\t// for delegated roles to avoid an attack described in Section 5.6 of\n\t// the Mercury paper:\n\t// https://github.com/theupdateframework/specification/pull/40\n\tif expected.Length != 0 && actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\n\tif len(expected.Hashes) != 0 {\n\t\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (t *TestResourceTreeServer) Send(tree *appsv1.ApplicationTree) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func GetImage(urlStr string) (*Image, error) {\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn nil, err\n\t}\n\n\tresponse, err := http.Get(urlStr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer response.Body.Close()\n\n\tmediatype, err := getMediatype(response)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !strings.HasPrefix(mediatype, \"image/\") {\n\t\treturn nil, errors.New(\"Wrong image mediatype\")\n\t}\n\n\tbodyBytes, err := io.ReadAll(response.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tbodyBytes, err = SanitizeContent(bodyBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\timage := &Image{\n\t\tBlob:      bodyBytes,\n\t\tMediatype: mediatype,\n\t}\n\treturn image, nil\n}", "is_vulnerable": 0}
{"code": "\tf.Fuzz(func(t *testing.T, data []byte) {\n\t\tif len(data) > LegacyPayloadSize {\n\t\t\treturn\n\t\t}\n\n\t\tr := bytes.NewReader(data)\n\n\t\tvar hopData1, hopData2 sphinx.HopData\n\n\t\tif err := hopData1.Decode(r); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tvar b bytes.Buffer\n\t\trequire.NoError(t, hopData1.Encode(&b))\n\t\trequire.NoError(t, hopData2.Decode(&b))\n\n\t\trequire.Equal(t, hopData1, hopData2)\n\t})", "is_vulnerable": 0}
{"code": "func (l Logger) Info(msg string, keysAndValues ...interface{}) {\n\tif l.sink == nil {\n\t\treturn\n\t}\n\tif l.Enabled() {\n\t\tif withHelper, ok := l.sink.(CallStackHelperLogSink); ok {\n\t\t\twithHelper.GetCallStackHelper()()\n\t\t}\n\t\tl.sink.Info(l.level, msg, keysAndValues...)\n\t}\n}", "is_vulnerable": 1}
{"code": "func NoNamespaceKeyFunc(ctx api.Context, prefix string, name string) (string, error) {\n\tif len(name) == 0 {\n\t\treturn \"\", kubeerr.NewBadRequest(\"Name parameter required.\")\n\t}\n\tif ok, msg := validation.ValidatePathSegmentName(name, false); !ok {\n\t\treturn \"\", kubeerr.NewBadRequest(fmt.Sprintf(\"Name parameter invalid: %v.\", msg))\n\t}\n\tkey := prefix + \"/\" + name\n\treturn key, nil\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_VerifyIncomingRPC(t *testing.T) {\n\tc := Configurator{base: &Config{\n\t\tVerifyIncomingRPC: true,\n\t}}\n\tverify := c.verifyIncomingRPC()\n\trequire.Equal(t, c.base.VerifyIncomingRPC, verify)\n}", "is_vulnerable": 0}
{"code": "func (s *store) PutLayer(id, parent string, names []string, mountLabel string, writeable bool, options *LayerOptions, diff io.Reader) (*Layer, int64, error) {\n\tvar parentLayer *Layer\n\trlstore, err := s.LayerStore()\n\tif err != nil {\n\t\treturn nil, -1, err\n\t}\n\trlstores, err := s.ROLayerStores()\n\tif err != nil {\n\t\treturn nil, -1, err\n\t}\n\trcstore, err := s.ContainerStore()\n\tif err != nil {\n\t\treturn nil, -1, err\n\t}\n\trlstore.Lock()\n\tdefer rlstore.Unlock()\n\tif modified, err := rlstore.Modified(); modified || err != nil {\n\t\tif err = rlstore.Load(); err != nil {\n\t\t\treturn nil, -1, err\n\t\t}\n\t}\n\trcstore.Lock()\n\tdefer rcstore.Unlock()\n\tif modified, err := rcstore.Modified(); modified || err != nil {\n\t\tif err = rcstore.Load(); err != nil {\n\t\t\treturn nil, -1, err\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = stringid.GenerateRandomID()\n\t}\n\tif options == nil {\n\t\toptions = &LayerOptions{}\n\t}\n\tif options.HostUIDMapping {\n\t\toptions.UIDMap = nil\n\t}\n\tif options.HostGIDMapping {\n\t\toptions.GIDMap = nil\n\t}\n\tuidMap := options.UIDMap\n\tgidMap := options.GIDMap\n\tif parent != \"\" {\n\t\tvar ilayer *Layer\n\t\tfor _, l := range append([]ROLayerStore{rlstore}, rlstores...) {\n\t\t\tlstore := l\n\t\t\tif lstore != rlstore {\n\t\t\t\tlstore.RLock()\n\t\t\t\tdefer lstore.Unlock()\n\t\t\t\tif modified, err := lstore.Modified(); modified || err != nil {\n\t\t\t\t\tif err = lstore.Load(); err != nil {\n\t\t\t\t\t\treturn nil, -1, err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif l, err := lstore.Get(parent); err == nil && l != nil {\n\t\t\t\tilayer = l\n\t\t\t\tparent = ilayer.ID\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif ilayer == nil {\n\t\t\treturn nil, -1, ErrLayerUnknown\n\t\t}\n\t\tparentLayer = ilayer\n\t\tcontainers, err := rcstore.Containers()\n\t\tif err != nil {\n\t\t\treturn nil, -1, err\n\t\t}\n\t\tfor _, container := range containers {\n\t\t\tif container.LayerID == parent {\n\t\t\t\treturn nil, -1, ErrParentIsContainer\n\t\t\t}\n\t\t}\n\t\tif !options.HostUIDMapping && len(options.UIDMap) == 0 {\n\t\t\tuidMap = ilayer.UIDMap\n\t\t}\n\t\tif !options.HostGIDMapping && len(options.GIDMap) == 0 {\n\t\t\tgidMap = ilayer.GIDMap\n\t\t}\n\t} else {\n\t\tif !options.HostUIDMapping && len(options.UIDMap) == 0 {\n\t\t\tuidMap = s.uidMap\n\t\t}\n\t\tif !options.HostGIDMapping && len(options.GIDMap) == 0 {\n\t\t\tgidMap = s.gidMap\n\t\t}\n\t}\n\tvar layerOptions *LayerOptions\n\tif s.graphDriver.SupportsShifting() {\n\t\tlayerOptions = &LayerOptions{IDMappingOptions: IDMappingOptions{HostUIDMapping: true, HostGIDMapping: true, UIDMap: nil, GIDMap: nil}}\n\t} else {\n\t\tlayerOptions = &LayerOptions{\n\t\t\tIDMappingOptions: IDMappingOptions{\n\t\t\t\tHostUIDMapping: options.HostUIDMapping,\n\t\t\t\tHostGIDMapping: options.HostGIDMapping,\n\t\t\t\tUIDMap:         copyIDMap(uidMap),\n\t\t\t\tGIDMap:         copyIDMap(gidMap),\n\t\t\t},\n\t\t}\n\t}\n\treturn rlstore.Put(id, parentLayer, names, mountLabel, nil, layerOptions, writeable, nil, diff)\n}", "is_vulnerable": 1}
{"code": "func testSTICreateBuildPod(t *testing.T, rootAllowed bool) {\n\tstrategy := &SourceBuildStrategy{\n\t\tImage:                \"sti-test-image\",\n\t\tTempDirectoryCreator: &FakeTempDirCreator{},\n\t\tCodec:                kapi.Codecs.LegacyCodec(buildapi.SchemeGroupVersion),\n\t\tAdmissionControl:     &FakeAdmissionControl{admit: rootAllowed},\n\t}\n\n\texpected := mockSTIBuild()\n\tactual, err := strategy.CreateBuildPod(expected)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error: %v\", err)\n\t}\n\n\tif expected, actual := buildutil.GetBuildPodName(expected), actual.ObjectMeta.Name; expected != actual {\n\t\tt.Errorf(\"Expected %s, but got %s!\", expected, actual)\n\t}\n\tif !reflect.DeepEqual(map[string]string{buildapi.BuildLabel: expected.Name}, actual.Labels) {\n\t\tt.Errorf(\"Pod Labels does not match Build Labels!\")\n\t}\n\tcontainer := actual.Spec.Containers[0]\n\tif container.Name != \"sti-build\" {\n\t\tt.Errorf(\"Expected sti-build, but got %s!\", container.Name)\n\t}\n\tif container.Image != strategy.Image {\n\t\tt.Errorf(\"Expected %s image, got %s!\", container.Image, strategy.Image)\n\t}\n\tif container.ImagePullPolicy != kapi.PullIfNotPresent {\n\t\tt.Errorf(\"Expected %v, got %v\", kapi.PullIfNotPresent, container.ImagePullPolicy)\n\t}\n\tif actual.Spec.RestartPolicy != kapi.RestartPolicyNever {\n\t\tt.Errorf(\"Expected never, got %#v\", actual.Spec.RestartPolicy)\n\t}\n\t// strategy ENV is whitelisted into the container environment, and not all\n\t// the values are allowed, so only expect 10 not 11 values.\n\texpectedEnvCount := 10\n\tif !rootAllowed {\n\t\texpectedEnvCount = 11\n\t}\n\tif len(container.Env) != expectedEnvCount {\n\t\tvar keys []string\n\t\tfor _, env := range container.Env {\n\t\t\tkeys = append(keys, env.Name)\n\t\t}\n\t\tt.Fatalf(\"Expected 11 elements in Env table, got %d:\\n%s\", len(container.Env), strings.Join(keys, \", \"))\n\t}\n\tif len(container.VolumeMounts) != 4 {\n\t\tt.Fatalf(\"Expected 4 volumes in container, got %d\", len(container.VolumeMounts))\n\t}\n\tfor i, expected := range []string{dockerSocketPath, DockerPushSecretMountPath, DockerPullSecretMountPath, sourceSecretMountPath} {\n\t\tif container.VolumeMounts[i].MountPath != expected {\n\t\t\tt.Fatalf(\"Expected %s in VolumeMount[%d], got %s\", expected, i, container.VolumeMounts[i].MountPath)\n\t\t}\n\t}\n\tif len(actual.Spec.Volumes) != 4 {\n\t\tt.Fatalf(\"Expected 4 volumes in Build pod, got %d\", len(actual.Spec.Volumes))\n\t}\n\tif *actual.Spec.ActiveDeadlineSeconds != 60 {\n\t\tt.Errorf(\"Expected ActiveDeadlineSeconds 60, got %d\", *actual.Spec.ActiveDeadlineSeconds)\n\t}\n\tif !kapi.Semantic.DeepEqual(container.Resources, expected.Spec.Resources) {\n\t\tt.Fatalf(\"Expected actual=expected, %v != %v\", container.Resources, expected.Spec.Resources)\n\t}\n\tfound := false\n\tfoundIllegal := false\n\tfoundAllowedUIDs := false\n\tfor _, v := range container.Env {\n\t\tif v.Name == \"BUILD_LOGLEVEL\" && v.Value == \"bar\" {\n\t\t\tfound = true\n\t\t}\n\t\tif v.Name == \"ILLEGAL\" {\n\t\t\tfoundIllegal = true\n\t\t}\n\t\tif v.Name == \"ALLOWED_UIDS\" && v.Value == \"1-\" {\n\t\t\tfoundAllowedUIDs = true\n\t\t}\n\t}\n\tif !found {\n\t\tt.Fatalf(\"Expected variable BUILD_LOGLEVEL be defined for the container\")\n\t}\n\tif foundIllegal {\n\t\tt.Fatalf(\"Found illegal environment variable 'ILLEGAL' defined on container\")\n\t}\n\tif foundAllowedUIDs && rootAllowed {\n\t\tt.Fatalf(\"Did not expect ALLOWED_UIDS when root is allowed\")\n\t}\n\tif !foundAllowedUIDs && !rootAllowed {\n\t\tt.Fatalf(\"Expected ALLLOWED_UIDS when root is not allowed\")\n\t}\n\tbuildJSON, _ := runtime.Encode(kapi.Codecs.LegacyCodec(buildapi.SchemeGroupVersion), expected)\n\terrorCases := map[int][]string{\n\t\t0: {\"BUILD\", string(buildJSON)},\n\t}\n\tfor index, exp := range errorCases {\n\t\tif e := container.Env[index]; e.Name != exp[0] || e.Value != exp[1] {\n\t\t\tt.Errorf(\"Expected %s:%s, got %s:%s!\\n\", exp[0], exp[1], e.Name, e.Value)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *Store) Get(c *fiber.Ctx) (*Session, error) {\n\tvar rawData []byte\n\tvar err error\n\n\tid, ok := c.Locals(sessionIDContextKey).(string)\n\tif !ok {\n\t\tid = s.getSessionID(c)\n\t}\n\n\tfresh := ok // Assume the session is fresh if the ID is found in locals\n\n\t// Attempt to fetch session data if an ID is provided\n\tif id != \"\" {\n\t\trawData, err = s.Storage.Get(id)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif rawData == nil {\n\t\t\t// Data not found, prepare to generate a new session\n\t\t\tid = \"\"\n\t\t}\n\t}\n\n\t// Generate a new ID if needed\n\tif id == \"\" {\n\t\tfresh = true // The session is fresh if a new ID is generated\n\t\tid = s.KeyGenerator()\n\t\tc.Locals(sessionIDContextKey, id)\n\t}\n\n\t// Create session object\n\tsess := acquireSession()\n\n\tsess.mu.Lock()\n\tdefer sess.mu.Unlock()\n\n\tsess.ctx = c\n\tsess.config = s\n\tsess.id = id\n\tsess.fresh = fresh\n\n\t// Decode session data if found\n\tif rawData != nil {\n\t\tsess.data.Lock()\n\t\tdefer sess.data.Unlock()\n\t\tif err := sess.decodeSessionData(rawData); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to decode session data: %w\", err)\n\t\t}\n\t}\n\n\treturn sess, nil\n}", "is_vulnerable": 0}
{"code": "\tsanitizer.init.Do(func() {\n\t\tInitializeSanitizer()\n\t})", "is_vulnerable": 1}
{"code": "func authentication(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tauthenticationHandler(w, r)\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "is_vulnerable": 1}
{"code": "func (proxy *PluginProxy) hasAccessToRoute(route *plugins.Route) bool {\n\tuseRBAC := proxy.features.IsEnabled(proxy.ctx.Req.Context(), featuremgmt.FlagAccessControlOnCall) && route.ReqAction != \"\"\n\tif useRBAC {\n\t\trouteEval := pluginac.GetPluginRouteEvaluator(proxy.ps.PluginID, route.ReqAction)\n\t\thasAccess := ac.HasAccess(proxy.accessControl, proxy.ctx)(routeEval)\n\t\tif !hasAccess {\n\t\t\tproxy.ctx.Logger.Debug(\"plugin route is covered by RBAC, user doesn't have access\", \"route\", proxy.ctx.Req.URL.Path)\n\t\t}\n\t\treturn hasAccess\n\t}\n\tif route.ReqRole.IsValid() {\n\t\treturn proxy.ctx.HasUserRole(route.ReqRole)\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (ng *AlertNG) init() error {\n\tvar err error\n\n\t// AlertNG should be initialized before the cancellation deadline of initCtx\n\tinitCtx, cancelFunc := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cancelFunc()\n\n\tstore := &store.DBstore{\n\t\tCfg:              ng.Cfg.UnifiedAlerting,\n\t\tFeatureToggles:   ng.FeatureToggles,\n\t\tSQLStore:         ng.SQLStore,\n\t\tLogger:           ng.Log,\n\t\tFolderService:    ng.folderService,\n\t\tAccessControl:    ng.accesscontrol,\n\t\tDashboardService: ng.dashboardService,\n\t}\n\tng.store = store\n\n\tdecryptFn := ng.SecretsService.GetDecryptedValue\n\tmultiOrgMetrics := ng.Metrics.GetMultiOrgAlertmanagerMetrics()\n\tng.MultiOrgAlertmanager, err = notifier.NewMultiOrgAlertmanager(ng.Cfg, store, store, ng.KVStore, store, decryptFn, multiOrgMetrics, ng.NotificationService, log.New(\"ngalert.multiorg.alertmanager\"), ng.SecretsService)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\timageService, err := image.NewScreenshotImageServiceFromCfg(ng.Cfg, store, ng.dashboardService, ng.renderService, ng.Metrics.Registerer)\n\tif err != nil {\n\t\treturn err\n\t}\n\tng.imageService = imageService\n\n\t// Let's make sure we're able to complete an initial sync of Alertmanagers before we start the alerting components.\n\tif err := ng.MultiOrgAlertmanager.LoadAndSyncAlertmanagersForOrgs(initCtx); err != nil {\n\t\treturn fmt.Errorf(\"failed to initialize alerting because multiorg alertmanager manager failed to warm up: %w\", err)\n\t}\n\n\tappUrl, err := url.Parse(ng.Cfg.AppURL)\n\tif err != nil {\n\t\tng.Log.Error(\"Failed to parse application URL. Continue without it.\", \"error\", err)\n\t\tappUrl = nil\n\t}\n\n\tclk := clock.New()\n\n\talertsRouter := sender.NewAlertsRouter(ng.MultiOrgAlertmanager, store, clk, appUrl, ng.Cfg.UnifiedAlerting.DisabledOrgs,\n\t\tng.Cfg.UnifiedAlerting.AdminConfigPollInterval, ng.DataSourceService, ng.SecretsService)\n\n\t// Make sure we sync at least once as Grafana starts to get the router up and running before we start sending any alerts.\n\tif err := alertsRouter.SyncAndApplyConfigFromDatabase(); err != nil {\n\t\treturn fmt.Errorf(\"failed to initialize alerting because alert notifications router failed to warm up: %w\", err)\n\t}\n\n\tng.AlertsRouter = alertsRouter\n\n\tevalFactory := eval.NewEvaluatorFactory(ng.Cfg.UnifiedAlerting, ng.DataSourceCache, ng.ExpressionService, ng.pluginsStore)\n\tschedCfg := schedule.SchedulerCfg{\n\t\tMaxAttempts:          ng.Cfg.UnifiedAlerting.MaxAttempts,\n\t\tC:                    clk,\n\t\tBaseInterval:         ng.Cfg.UnifiedAlerting.BaseInterval,\n\t\tMinRuleInterval:      ng.Cfg.UnifiedAlerting.MinInterval,\n\t\tDisableGrafanaFolder: ng.Cfg.UnifiedAlerting.ReservedLabels.IsReservedLabelDisabled(models.FolderTitleLabel),\n\t\tAppURL:               appUrl,\n\t\tEvaluatorFactory:     evalFactory,\n\t\tRuleStore:            store,\n\t\tMetrics:              ng.Metrics.GetSchedulerMetrics(),\n\t\tAlertSender:          alertsRouter,\n\t\tTracer:               ng.tracer,\n\t}\n\n\thistory, err := configureHistorianBackend(initCtx, ng.Cfg.UnifiedAlerting.StateHistory, ng.annotationsRepo, ng.dashboardService, ng.store, ng.Metrics.GetHistorianMetrics())\n\tif err != nil {\n\t\treturn err\n\t}\n\tcfg := state.ManagerCfg{\n\t\tMetrics:              ng.Metrics.GetStateMetrics(),\n\t\tExternalURL:          appUrl,\n\t\tInstanceStore:        store,\n\t\tImages:               ng.imageService,\n\t\tClock:                clk,\n\t\tHistorian:            history,\n\t\tDoNotSaveNormalState: ng.FeatureToggles.IsEnabled(featuremgmt.FlagAlertingNoNormalState),\n\t}\n\tstateManager := state.NewManager(cfg)\n\tscheduler := schedule.NewScheduler(schedCfg, stateManager)\n\n\t// if it is required to include folder title to the alerts, we need to subscribe to changes of alert title\n\tif !ng.Cfg.UnifiedAlerting.ReservedLabels.IsReservedLabelDisabled(models.FolderTitleLabel) {\n\t\tsubscribeToFolderChanges(context.Background(), ng.Log, ng.bus, store, scheduler)\n\t}\n\n\tng.stateManager = stateManager\n\tng.schedule = scheduler\n\n\t// Provisioning\n\tpolicyService := provisioning.NewNotificationPolicyService(store, store, store, ng.Cfg.UnifiedAlerting, ng.Log)\n\tcontactPointService := provisioning.NewContactPointService(store, ng.SecretsService, store, store, ng.Log)\n\ttemplateService := provisioning.NewTemplateService(store, store, store, ng.Log)\n\tmuteTimingService := provisioning.NewMuteTimingService(store, store, store, ng.Log)\n\talertRuleService := provisioning.NewAlertRuleService(store, store, ng.dashboardService, ng.QuotaService, store,\n\t\tint64(ng.Cfg.UnifiedAlerting.DefaultRuleEvaluationInterval.Seconds()),\n\t\tint64(ng.Cfg.UnifiedAlerting.BaseInterval.Seconds()), ng.Log)\n\n\tapi := api.API{\n\t\tCfg:                  ng.Cfg,\n\t\tDatasourceCache:      ng.DataSourceCache,\n\t\tDatasourceService:    ng.DataSourceService,\n\t\tRouteRegister:        ng.RouteRegister,\n\t\tSchedule:             ng.schedule,\n\t\tDataProxy:            ng.DataProxy,\n\t\tQuotaService:         ng.QuotaService,\n\t\tTransactionManager:   store,\n\t\tRuleStore:            store,\n\t\tAlertingStore:        store,\n\t\tAdminConfigStore:     store,\n\t\tProvenanceStore:      store,\n\t\tMultiOrgAlertmanager: ng.MultiOrgAlertmanager,\n\t\tStateManager:         ng.stateManager,\n\t\tAccessControl:        ng.accesscontrol,\n\t\tPolicies:             policyService,\n\t\tContactPointService:  contactPointService,\n\t\tTemplates:            templateService,\n\t\tMuteTimings:          muteTimingService,\n\t\tAlertRules:           alertRuleService,\n\t\tAlertsRouter:         alertsRouter,\n\t\tEvaluatorFactory:     evalFactory,\n\t\tFeatureManager:       ng.FeatureToggles,\n\t\tAppUrl:               appUrl,\n\t\tHistorian:            history,\n\t}\n\tapi.RegisterAPIEndpoints(ng.Metrics.GetAPIMetrics())\n\n\tdefaultLimits, err := readQuotaConfig(ng.Cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := ng.QuotaService.RegisterQuotaReporter(&quota.NewUsageReporter{\n\t\tTargetSrv:     models.QuotaTargetSrv,\n\t\tDefaultLimits: defaultLimits,\n\t\tReporter:      api.Usage,\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tlog.RegisterContextualLogProvider(func(ctx context.Context) ([]interface{}, bool) {\n\t\tkey, ok := models.RuleKeyFromContext(ctx)\n\t\tif !ok {\n\t\t\treturn nil, false\n\t\t}\n\t\treturn key.LogContext(), true\n\t})\n\n\treturn DeclareFixedRoles(ng.accesscontrolService)\n}", "is_vulnerable": 1}
{"code": "func extractCerts(e *models.LogEntryAnon) ([]*x509.Certificate, error) {\n\teimpl, _, _, err := unmarshalEntryImpl(e.Body.(string))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar publicKeyB64 []byte\n\tswitch e := eimpl.(type) {\n\tcase *rekord_v001.V001Entry:\n\t\tpublicKeyB64, err = e.RekordObj.Signature.PublicKey.Content.MarshalText()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tcase *hashedrekord_v001.V001Entry:\n\t\tpublicKeyB64, err = e.HashedRekordObj.Signature.PublicKey.Content.MarshalText()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tdefault:\n\t\treturn nil, errors.New(\"unexpected tlog entry type\")\n\t}\n\n\tpublicKey, err := base64.StdEncoding.DecodeString(string(publicKeyB64))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcerts, err := cryptoutils.UnmarshalCertificatesFromPEM(publicKey)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(certs) == 0 {\n\t\treturn nil, errors.New(\"no certs found in pem tlog\")\n\t}\n\n\treturn certs, err\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tassert.Panicsf(t, func() {\n\t\t\t\t\tNewPageWriter(cw, tc.pageBytes, 0)\n\t\t\t\t}, \"expected panic when pageBytes is %d\", tc.pageBytes)", "is_vulnerable": 0}
{"code": "func TestDoesClientWhiteListRedirect(t *testing.T) {\n\tfor k, c := range []struct {\n\t\tclient   Client\n\t\turl      string\n\t\tisError  bool\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"\"}},\n\t\t\turl:     \"https://foo.com/cb\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"wta://auth\"}},\n\t\t\turl:      \"wta://auth\",\n\t\t\texpected: \"wta://auth\",\n\t\t\tisError:  false,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"wta:///auth\"}},\n\t\t\turl:      \"wta:///auth\",\n\t\t\texpected: \"wta:///auth\",\n\t\t\tisError:  false,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"wta://foo/auth\"}},\n\t\t\turl:      \"wta://foo/auth\",\n\t\t\texpected: \"wta://foo/auth\",\n\t\t\tisError:  false,\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"https://bar.com/cb\"}},\n\t\t\turl:     \"https://foo.com/cb\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"https://bar.com/cb\"}},\n\t\t\turl:      \"\",\n\t\t\tisError:  false,\n\t\t\texpected: \"https://bar.com/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"\"}},\n\t\t\turl:     \"\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"https://bar.com/cb\"}},\n\t\t\turl:      \"https://bar.com/cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"https://bar.com/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"https://bar.Com/cb\"}},\n\t\t\turl:      \"https://bar.com/cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"https://bar.com/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"https://bar.com/cb\"}},\n\t\t\turl:      \"https://bar.Com/cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"https://bar.Com/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"https://bar.com/cb\"}},\n\t\t\turl:     \"https://bar.com/cb123\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://[::1]\"}},\n\t\t\turl:      \"http://[::1]:1024\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://[::1]:1024\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"http://[::1]\"}},\n\t\t\turl:     \"http://[::1]:1024/cb\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://[::1]/cb\"}},\n\t\t\turl:      \"http://[::1]:1024/cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://[::1]:1024/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"http://[::1]\"}},\n\t\t\turl:     \"http://foo.bar/bar\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1\"}},\n\t\t\turl:      \"http://127.0.0.1:1024\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://127.0.0.1:1024\",\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1/cb\"}},\n\t\t\turl:      \"http://127.0.0.1:64000/cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://127.0.0.1:64000/cb\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1\"}},\n\t\t\turl:     \"http://127.0.0.1:64000/cb\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1\"}},\n\t\t\turl:      \"http://127.0.0.1\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://127.0.0.1\",\n\t\t},\n\t\t{\n\t\t\tclient:   &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1/Cb\"}},\n\t\t\turl:      \"http://127.0.0.1:8080/Cb\",\n\t\t\tisError:  false,\n\t\t\texpected: \"http://127.0.0.1:8080/Cb\",\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1\"}},\n\t\t\turl:     \"http://foo.bar/bar\",\n\t\t\tisError: true,\n\t\t},\n\t\t{\n\t\t\tclient:  &DefaultClient{RedirectURIs: []string{\"http://127.0.0.1\"}},\n\t\t\turl:     \":/invalid.uri)bar\",\n\t\t\tisError: true,\n\t\t},\n\t} {\n\t\tredir, err := MatchRedirectURIWithClientRedirectURIs(c.url, c.client)\n\t\tassert.Equal(t, c.isError, err != nil, \"%d: %s\", k, err)\n\t\tif err == nil {\n\t\t\trequire.NotNil(t, redir, \"%d\", k)\n\t\t\tassert.Equal(t, c.expected, redir.String(), \"%d\", k)\n\t\t}\n\t\tt.Logf(\"Passed test case %d\", k)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *OAuthProxy) SignInPage(rw http.ResponseWriter, req *http.Request, code int) {\n\tp.ClearCookie(rw, req)\n\trw.WriteHeader(code)\n\n\tredirect_url := req.URL.RequestURI()\n\tif redirect_url == p.SignInPath {\n\t\tredirect_url = \"/\"\n\t}\n\n\tt := struct {\n\t\tProviderName  string\n\t\tSignInMessage string\n\t\tCustomLogin   bool\n\t\tRedirect      string\n\t\tVersion       string\n\t\tProxyPrefix   string\n\t\tFooter        template.HTML\n\t}{\n\t\tProviderName:  p.provider.Data().ProviderName,\n\t\tSignInMessage: p.SignInMessage,\n\t\tCustomLogin:   p.displayCustomLoginForm(),\n\t\tRedirect:      redirect_url,\n\t\tVersion:       VERSION,\n\t\tProxyPrefix:   p.ProxyPrefix,\n\t\tFooter:        template.HTML(p.Footer),\n\t}\n\tp.templates.ExecuteTemplate(rw, \"sign_in.html\", t)\n}", "is_vulnerable": 1}
{"code": "func TestVerifyBlobAttestation(t *testing.T) {\n\tctx := context.Background()\n\ttd := t.TempDir()\n\tdefer os.RemoveAll(td)\n\n\tblobPath := writeBlobFile(t, td, blobContents, \"blob\")\n\tanotherBlobPath := writeBlobFile(t, td, anotherBlobContents, \"other-blob\")\n\thugeBlobPath := writeBlobFile(t, td, hugeBlobContents, \"huge-blob\")\n\tkeyRef := writeBlobFile(t, td, pubkey, \"cosign.pub\")\n\n\ttests := []struct {\n\t\tdescription   string\n\t\tblobPath      string\n\t\tsignature     string\n\t\tpredicateType string\n\t\tenv           map[string]string\n\t\tshouldErr     bool\n\t}{\n\t\t{\n\t\t\tdescription:   \"verify a slsaprovenance predicate\",\n\t\t\tpredicateType: \"slsaprovenance\",\n\t\t\tblobPath:      blobPath,\n\t\t\tsignature:     blobSLSAProvenanceSignature,\n\t\t}, {\n\t\t\tdescription:   \"fail with incorrect predicate\",\n\t\t\tsignature:     blobSLSAProvenanceSignature,\n\t\t\tblobPath:      blobPath,\n\t\t\tpredicateType: \"custom\",\n\t\t\tshouldErr:     true,\n\t\t}, {\n\t\t\tdescription: \"fail with incorrect blob\",\n\t\t\tsignature:   blobSLSAProvenanceSignature,\n\t\t\tblobPath:    anotherBlobPath,\n\t\t\tshouldErr:   true,\n\t\t}, {\n\t\t\tdescription: \"dsse envelope predicate has no subject\",\n\t\t\tsignature:   dssePredicateEmptySubject,\n\t\t\tblobPath:    blobPath,\n\t\t\tshouldErr:   true,\n\t\t}, {\n\t\t\tdescription: \"dsse envelope predicate missing sha256 digest\",\n\t\t\tsignature:   dssePredicateMissingSha256,\n\t\t\tblobPath:    blobPath,\n\t\t\tshouldErr:   true,\n\t\t}, {\n\t\t\tdescription:   \"dsse envelope has multiple subjects, one is valid\",\n\t\t\tpredicateType: \"slsaprovenance\",\n\t\t\tsignature:     dssePredicateMultipleSubjects,\n\t\t\tblobPath:      blobPath,\n\t\t}, {\n\t\t\tdescription:   \"dsse envelope has multiple subjects, one is valid, but we are looking for different predicatetype\",\n\t\t\tpredicateType: \"notreallyslsaprovenance\",\n\t\t\tsignature:     dssePredicateMultipleSubjects,\n\t\t\tblobPath:      blobPath,\n\t\t\tshouldErr:     true,\n\t\t}, {\n\t\t\tdescription:   \"dsse envelope has multiple subjects, none has correct sha256 digest\",\n\t\t\tpredicateType: \"slsaprovenance\",\n\t\t\tsignature:     dssePredicateMultipleSubjectsInvalid,\n\t\t\tblobPath:      blobPath,\n\t\t\tshouldErr:     true,\n\t\t}, {\n\t\t\tdescription: \"override file size limit\",\n\t\t\tsignature:   blobSLSAProvenanceSignature,\n\t\t\tblobPath:    hugeBlobPath,\n\t\t\tenv:         map[string]string{\"COSIGN_MAX_ATTACHMENT_SIZE\": \"128\"},\n\t\t\tshouldErr:   true,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.description, func(t *testing.T) {\n\t\t\tfor k, v := range test.env {\n\t\t\t\tt.Setenv(k, v)\n\t\t\t}\n\t\t\tdecodedSig, err := base64.StdEncoding.DecodeString(test.signature)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tsigRef := writeBlobFile(t, td, string(decodedSig), \"signature\")\n\n\t\t\tcmd := VerifyBlobAttestationCommand{\n\t\t\t\tKeyOpts:       options.KeyOpts{KeyRef: keyRef},\n\t\t\t\tSignaturePath: sigRef,\n\t\t\t\tIgnoreTlog:    true,\n\t\t\t\tCheckClaims:   true,\n\t\t\t\tPredicateType: test.predicateType,\n\t\t\t}\n\t\t\terr = cmd.Exec(ctx, test.blobPath)\n\n\t\t\tif (err != nil) != test.shouldErr {\n\t\t\t\tt.Fatalf(\"verifyBlobAttestation()= %s, expected shouldErr=%t \", err, test.shouldErr)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\tSubscribe(ch chan *appv1.ApplicationWatchEvent, filters ...func(event *appv1.ApplicationWatchEvent) bool) func()\n\tOnAdd(interface{})\n\tOnUpdate(interface{}, interface{})", "is_vulnerable": 0}
{"code": "func addLdapGroupMember(t *testing.T, cfg *ldaputil.ConfigEntry, groupCN, userCN string) {\n\tuserDN := fmt.Sprintf(\"cn=%s,ou=people,dc=planetexpress,dc=com\", userCN)\n\tgroupDN := fmt.Sprintf(\"cn=%s,ou=people,dc=planetexpress,dc=com\", groupCN)\n\tldapreq := ldap.ModifyRequest{DN: groupDN}\n\tldapreq.Add(\"member\", []string{userDN})\n\taddRemoveLdapGroupMember(t, cfg, userCN, &ldapreq)\n}", "is_vulnerable": 0}
{"code": "func (m mockGenerator) DecryptKey(key []byte) ([]byte, error) {\n\treturn make([]byte, 16), nil\n\n}", "is_vulnerable": 1}
{"code": "func (p *CompactProtocol) ReadListBegin() (elemType Type, size int, err error) {\n\tsize_and_type, err := p.readByteDirect()\n\tif err != nil {\n\t\treturn\n\t}\n\tsize = int((size_and_type >> 4) & 0x0f)\n\tif size == 15 {\n\t\tsize2, e := p.readVarint32()\n\t\tif e != nil {\n\t\t\terr = NewProtocolException(e)\n\t\t\treturn\n\t\t}\n\t\tif size2 < 0 {\n\t\t\terr = invalidDataLength\n\t\t\treturn\n\t\t}\n\t\tsize = int(size2)\n\t}\n\tif uint64(size) > p.trans.RemainingBytes() || p.trans.RemainingBytes() == UnknownRemaining {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\n\telemType, e := p.getType(compactType(size_and_type))\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_IncomingHTTPS_NoVerify(t *testing.T) {\n\tconf := &Config{}\n\tc := NewConfigurator(conf)\n\ttlsConf, err := c.IncomingHTTPSConfig()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, tlsConf)\n\trequire.Nil(t, tlsConf.ClientCAs)\n\trequire.Equal(t, tlsConf.ClientAuth, tls.NoClientCert)\n\trequire.Empty(t, tlsConf.Certificates)\n}", "is_vulnerable": 1}
{"code": "func (context *DatabaseContext) QuerySequences(sequences []uint64) (sgbucket.QueryResultIterator, error) {\n\n\tif len(sequences) == 0 {\n\t\treturn nil, errors.New(\"No sequences specified for QueryChannelsForSequences\")\n\t}\n\n\tif context.Options.UseViews {\n\t\topts := changesViewForSequencesOptions(sequences)\n\t\treturn context.ViewQueryWithStats(DesignDocSyncGateway(), ViewChannels, opts)\n\t}\n\n\t// N1QL Query\n\t// Standard channel index/query doesn't support the star channel.  For star channel queries, QueryStarChannel\n\t// (which is backed by IndexAllDocs) is used.  The QueryStarChannel result schema is a subset of the\n\t// QueryChannels result schema (removal handling isn't needed for the star channel).\n\tsequenceQueryStatement := replaceSyncTokensQuery(QuerySequences.statement, context.UseXattrs())\n\n\tparams := make(map[string]interface{})\n\tparams[QueryParamInSequences] = sequences\n\n\treturn context.N1QLQueryWithStats(QuerySequences.name, sequenceQueryStatement, params, gocb.RequestPlus, QueryChannels.adhoc)\n}", "is_vulnerable": 0}
{"code": "func (us *UserService) UserRegisterByEmail(ctx context.Context, registerUserInfo *schema.UserRegisterReq) (\n\tresp *schema.UserLoginResp, errFields []*validator.FormErrorField, err error,\n) {\n\t_, has, err := us.userRepo.GetByEmail(ctx, registerUserInfo.Email)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif has {\n\t\terrFields = append(errFields, &validator.FormErrorField{\n\t\t\tErrorField: \"e_mail\",\n\t\t\tErrorMsg:   reason.EmailDuplicate,\n\t\t})\n\t\treturn nil, errFields, errors.BadRequest(reason.EmailDuplicate)\n\t}\n\n\tuserInfo := &entity.User{}\n\tuserInfo.EMail = registerUserInfo.Email\n\tuserInfo.DisplayName = registerUserInfo.Name\n\tuserInfo.Pass, err = us.encryptPassword(ctx, registerUserInfo.Pass)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tuserInfo.Username, err = us.userCommonService.MakeUsername(ctx, registerUserInfo.Name)\n\tif err != nil {\n\t\terrFields = append(errFields, &validator.FormErrorField{\n\t\t\tErrorField: \"name\",\n\t\t\tErrorMsg:   reason.UsernameInvalid,\n\t\t})\n\t\treturn nil, errFields, err\n\t}\n\tuserInfo.IPInfo = registerUserInfo.IP\n\tuserInfo.MailStatus = entity.EmailStatusToBeVerified\n\tuserInfo.Status = entity.UserStatusAvailable\n\tuserInfo.LastLoginDate = time.Now()\n\terr = us.userRepo.AddUser(ctx, userInfo)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif err := us.userNotificationConfigService.SetDefaultUserNotificationConfig(ctx, []string{userInfo.ID}); err != nil {\n\t\tlog.Errorf(\"set default user notification config failed, err: %v\", err)\n\t}\n\n\t// send email\n\tdata := &schema.EmailCodeContent{\n\t\tEmail:  registerUserInfo.Email,\n\t\tUserID: userInfo.ID,\n\t}\n\tcode := uuid.NewString()\n\tverifyEmailURL := fmt.Sprintf(\"%s/users/account-activation?code=%s\", us.getSiteUrl(ctx), code)\n\ttitle, body, err := us.emailService.RegisterTemplate(ctx, verifyEmailURL)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tgo us.emailService.SendAndSaveCode(ctx, userInfo.EMail, title, body, code, data.ToJSONString())\n\n\troleID, err := us.userRoleService.GetUserRole(ctx, userInfo.ID)\n\tif err != nil {\n\t\tlog.Error(err)\n\t}\n\n\t// return user info and token\n\tresp = &schema.UserLoginResp{}\n\tresp.ConvertFromUserEntity(userInfo)\n\tresp.Avatar = us.siteInfoService.FormatAvatar(ctx, userInfo.Avatar, userInfo.EMail, userInfo.Status).GetURL()\n\tuserCacheInfo := &entity.UserCacheInfo{\n\t\tUserID:      userInfo.ID,\n\t\tEmailStatus: userInfo.MailStatus,\n\t\tUserStatus:  userInfo.Status,\n\t\tRoleID:      roleID,\n\t}\n\tresp.AccessToken, resp.VisitToken, err = us.authService.SetUserCacheInfo(ctx, userCacheInfo)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tresp.RoleID = userCacheInfo.RoleID\n\tif resp.RoleID == role.RoleAdminID {\n\t\terr = us.authService.SetAdminUserCacheInfo(ctx, resp.AccessToken, &entity.UserCacheInfo{UserID: userInfo.ID})\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\treturn resp, nil, nil\n}", "is_vulnerable": 1}
{"code": "func (db *Database) Commit(node common.Hash, report bool, callback func(common.Hash)) error {\n\t// Create a database batch to flush persistent data out. It is important that\n\t// outside code doesn't see an inconsistent state (referenced data removed from\n\t// memory cache during commit but not yet in persistent storage). This is ensured\n\t// by only uncaching existing data when the database write finalizes.\n\tstart := time.Now()\n\tbatch := db.diskdb.NewBatch()\n\n\t// We reuse an ephemeral buffer for the keys. The batch Put operation\n\t// copies it internally, so we can reuse it.\n\tvar keyBuf [secureKeyLength]byte\n\tcopy(keyBuf[:], secureKeyPrefix)\n\n\t// Move all of the accumulated preimages into a write batch\n\tfor hash, preimage := range db.preimages {\n\t\tcopy(keyBuf[secureKeyPrefixLength:], hash[:])\n\t\tif err := batch.Put(keyBuf[:], preimage); err != nil {\n\t\t\tlog.Error(\"Failed to commit preimage from trie database\", \"err\", err)\n\t\t\treturn err\n\t\t}\n\t\t// If the batch is too large, flush to disk\n\t\tif batch.ValueSize() > ethdb.IdealBatchSize {\n\t\t\tif err := batch.Write(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tbatch.Reset()\n\t\t}\n\t}\n\t// Since we're going to replay trie node writes into the clean cache, flush out\n\t// any batched pre-images before continuing.\n\tif err := batch.Write(); err != nil {\n\t\treturn err\n\t}\n\tbatch.Reset()\n\n\t// Move the trie itself into the batch, flushing if enough data is accumulated\n\tnodes, storage := len(db.dirties), db.dirtiesSize\n\n\tuncacher := &cleaner{db}\n\tif err := db.commit(node, batch, uncacher, callback); err != nil {\n\t\tlog.Error(\"Failed to commit trie from trie database\", \"err\", err)\n\t\treturn err\n\t}\n\t// Trie mostly committed to disk, flush any batch leftovers\n\tif err := batch.Write(); err != nil {\n\t\tlog.Error(\"Failed to write trie to disk\", \"err\", err)\n\t\treturn err\n\t}\n\t// Uncache any leftovers in the last batch\n\tdb.lock.Lock()\n\tdefer db.lock.Unlock()\n\n\tbatch.Replay(uncacher)\n\tbatch.Reset()\n\n\t// Reset the storage counters and bumpd metrics\n\tdb.preimages = make(map[common.Hash][]byte)\n\tdb.preimagesSize = 0\n\n\tmemcacheCommitTimeTimer.Update(time.Since(start))\n\tmemcacheCommitSizeMeter.Mark(int64(storage - db.dirtiesSize))\n\tmemcacheCommitNodesMeter.Mark(int64(nodes - len(db.dirties)))\n\n\tlogger := log.Info\n\tif !report {\n\t\tlogger = log.Debug\n\t}\n\tlogger(\"Persisted trie from memory database\", \"nodes\", nodes-len(db.dirties)+int(db.flushnodes), \"size\", storage-db.dirtiesSize+db.flushsize, \"time\", time.Since(start)+db.flushtime,\n\t\t\"gcnodes\", db.gcnodes, \"gcsize\", db.gcsize, \"gctime\", db.gctime, \"livenodes\", len(db.dirties), \"livesize\", db.dirtiesSize)\n\n\t// Reset the garbage collection statistics\n\tdb.gcnodes, db.gcsize, db.gctime = 0, 0, 0\n\tdb.flushnodes, db.flushsize, db.flushtime = 0, 0, 0\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (u *Upgrade) prepareUpgrade(name string, chart *chart.Chart, vals map[string]interface{}) (*release.Release, *release.Release, error) {\n\tif chart == nil {\n\t\treturn nil, nil, errMissingChart\n\t}\n\n\t// finds the last non-deleted release with the given name\n\tlastRelease, err := u.cfg.Releases.Last(name)\n\tif err != nil {\n\t\t// to keep existing behavior of returning the \"%q has no deployed releases\" error when an existing release does not exist\n\t\tif errors.Is(err, driver.ErrReleaseNotFound) {\n\t\t\treturn nil, nil, driver.NewErrNoDeployedReleases(name)\n\t\t}\n\t\treturn nil, nil, err\n\t}\n\n\t// Concurrent `helm upgrade`s will either fail here with `errPending` or when creating the release with \"already exists\". This should act as a pessimistic lock.\n\tif lastRelease.Info.Status.IsPending() {\n\t\treturn nil, nil, errPending\n\t}\n\n\tvar currentRelease *release.Release\n\tif lastRelease.Info.Status == release.StatusDeployed {\n\t\t// no need to retrieve the last deployed release from storage as the last release is deployed\n\t\tcurrentRelease = lastRelease\n\t} else {\n\t\t// finds the deployed release with the given name\n\t\tcurrentRelease, err = u.cfg.Releases.Deployed(name)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, driver.ErrNoDeployedReleases) &&\n\t\t\t\t(lastRelease.Info.Status == release.StatusFailed || lastRelease.Info.Status == release.StatusSuperseded) {\n\t\t\t\tcurrentRelease = lastRelease\n\t\t\t} else {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\t// determine if values will be reused\n\tvals, err = u.reuseValues(chart, currentRelease, vals)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif err := chartutil.ProcessDependencies(chart, vals); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Increment revision count. This is passed to templates, and also stored on\n\t// the release object.\n\trevision := lastRelease.Version + 1\n\n\toptions := chartutil.ReleaseOptions{\n\t\tName:      name,\n\t\tNamespace: currentRelease.Namespace,\n\t\tRevision:  revision,\n\t\tIsUpgrade: true,\n\t}\n\n\tcaps, err := u.cfg.getCapabilities()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvaluesToRender, err := chartutil.ToRenderValues(chart, vals, options, caps)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\thooks, manifestDoc, notesTxt, err := u.cfg.renderResources(chart, valuesToRender, \"\", \"\", u.SubNotes, false, false, u.PostRenderer, u.DryRun)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Store an upgraded release.\n\tupgradedRelease := &release.Release{\n\t\tName:      name,\n\t\tNamespace: currentRelease.Namespace,\n\t\tChart:     chart,\n\t\tConfig:    vals,\n\t\tInfo: &release.Info{\n\t\t\tFirstDeployed: currentRelease.Info.FirstDeployed,\n\t\t\tLastDeployed:  Timestamper(),\n\t\t\tStatus:        release.StatusPendingUpgrade,\n\t\t\tDescription:   \"Preparing upgrade\", // This should be overwritten later.\n\t\t},\n\t\tVersion:  revision,\n\t\tManifest: manifestDoc.String(),\n\t\tHooks:    hooks,\n\t}\n\n\tif len(notesTxt) > 0 {\n\t\tupgradedRelease.Info.Notes = notesTxt\n\t}\n\terr = validateManifest(u.cfg.KubeClient, manifestDoc.Bytes(), !u.DisableOpenAPIValidation)\n\treturn currentRelease, upgradedRelease, err\n}", "is_vulnerable": 1}
{"code": "func (c *Context) Decrypt(ciphertext, plaintext *Data) error {\n\terr := handleError(C.gpgme_op_decrypt(c.ctx, ciphertext.dh, plaintext.dh))\n\truntime.KeepAlive(ciphertext)\n\truntime.KeepAlive(plaintext)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func makeStreamDistributedQueryCampaignResultsHandler(svc kolide.Service, jwtKey string, logger kitlog.Logger) http.Handler {\n\topt := sockjs.DefaultOptions\n\topt.Websocket = true\n\topt.RawWebsocket = true\n\treturn sockjs.NewHandler(\"/api/v1/kolide/results\", opt, func(session sockjs.Session) {\n\t\tconn := &websocket.Conn{Session: session}\n\t\tdefer func() {\n\t\t\tif p := recover(); p != nil {\n\t\t\t\tlogger.Log(\"err\", p, \"msg\", \"panic in result handler\")\n\t\t\t\tconn.WriteJSONError(\"panic in result handler\")\n\t\t\t}\n\t\t\tsession.Close(0, \"none\")\n\t\t}()\n\n\t\t// Receive the auth bearer token\n\t\ttoken, err := conn.ReadAuthToken()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"failed to read auth token\")\n\t\t\treturn\n\t\t}\n\n\t\t// Authenticate with the token\n\t\tvc, err := authViewer(context.Background(), jwtKey, token, svc)\n\t\tif err != nil || !vc.CanPerformActions() {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unauthorized viewer\")\n\t\t\tconn.WriteJSONError(\"unauthorized\")\n\t\t\treturn\n\t\t}\n\n\t\tctx := viewer.NewContext(context.Background(), *vc)\n\n\t\tmsg, err := conn.ReadJSONMessage()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"reading select_campaign JSON\")\n\t\t\tconn.WriteJSONError(\"error reading select_campaign\")\n\t\t\treturn\n\t\t}\n\t\tif msg.Type != \"select_campaign\" {\n\t\t\tlogger.Log(\"err\", \"unexpected msg type, expected select_campaign\", \"msg-type\", msg.Type)\n\t\t\tconn.WriteJSONError(\"expected select_campaign\")\n\t\t\treturn\n\t\t}\n\n\t\tvar info struct {\n\t\t\tCampaignID uint `json:\"campaign_id\"`\n\t\t}\n\t\terr = json.Unmarshal(*(msg.Data.(*json.RawMessage)), &info)\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unmarshaling select_campaign data\")\n\t\t\tconn.WriteJSONError(\"error unmarshaling select_campaign data\")\n\t\t\treturn\n\t\t}\n\t\tif info.CampaignID == 0 {\n\t\t\tlogger.Log(\"err\", \"campaign ID not set\")\n\t\t\tconn.WriteJSONError(\"0 is not a valid campaign ID\")\n\t\t\treturn\n\t\t}\n\n\t\tsvc.StreamCampaignResults(ctx, conn, info.CampaignID)\n\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestPluginSigner_SignWithAnnotations_Valid(t *testing.T) {\n\tfor _, envelopeType := range signature.RegisteredEnvelopeTypes() {\n\t\tfor _, keyCert := range keyCertPairCollections {\n\t\t\tt.Run(fmt.Sprintf(\"external plugin,envelopeType=%v_keySpec=%v\", envelopeType, keyCert.keySpecName), func(t *testing.T) {\n\t\t\t\tkeySpec, _ := proto.DecodeKeySpec(proto.KeySpec(keyCert.keySpecName))\n\t\t\t\tannts := map[string]string{\"key\": \"value\"}\n\t\t\t\tpluginSigner := pluginSigner{\n\t\t\t\t\tplugin: &mockPlugin{\n\t\t\t\t\t\tkey:         keyCert.key,\n\t\t\t\t\t\tcerts:       keyCert.certs,\n\t\t\t\t\t\tkeySpec:     keySpec,\n\t\t\t\t\t\tannotations:  map[string]string{\"key\": \"value\"},\n\t\t\t\t\t\twantEnvelope: true,\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tbasicSignTest(t, &pluginSigner, envelopeType, &validMetadata)\n\t\t\t\tif !reflect.DeepEqual(pluginSigner.PluginAnnotations(), annts) {\n\t\t\t\t\tfmt.Println(pluginSigner.PluginAnnotations())\n\t\t\t\t\tt.Errorf(\"mismatch in annotations returned from PluginAnnotations()\")\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (expr *IntroducerExpr) eval(env *ExpressionEnv) (eval, error) {\n\te, err := expr.Inner.eval(env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn introducerCast(e, expr.TypedCollation.Collation)\n}", "is_vulnerable": 0}
{"code": "func TestHtlcIncomingResolverFwdPreimageKnown(t *testing.T) {\n\tt.Parallel()\n\tdefer timeout(t)()\n\n\tctx := newIncomingResolverTestContext(t, false)\n\tctx.witnessBeacon.lookupPreimage[testResHash] = testResPreimage\n\tctx.resolve()\n\tctx.waitForResult(true)\n}", "is_vulnerable": 0}
{"code": "func NewAccountChangePasswordNoContent() *AccountChangePasswordNoContent {\n\n\treturn &AccountChangePasswordNoContent{}\n}", "is_vulnerable": 0}
{"code": "func (e *EmailAPI) Ping() {\n\tvar host, username, password, identity string\n\tvar port int\n\tvar ssl, insecure bool\n\tbody := e.Ctx.Input.CopyBody(1 << 32)\n\tif body == nil || len(body) == 0 {\n\t\tcfg, err := config.Email()\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"failed to get email configurations: %v\", err)\n\t\t\te.CustomAbort(http.StatusInternalServerError,\n\t\t\t\thttp.StatusText(http.StatusInternalServerError))\n\t\t}\n\t\thost = cfg.Host\n\t\tport = cfg.Port\n\t\tusername = cfg.Username\n\t\tpassword = cfg.Password\n\t\tidentity = cfg.Identity\n\t\tssl = cfg.SSL\n\t\tinsecure = cfg.Insecure\n\t} else {\n\t\tsettings := &struct {\n\t\t\tHost     string  `json:\"email_host\"`\n\t\t\tPort     *int    `json:\"email_port\"`\n\t\t\tUsername string  `json:\"email_username\"`\n\t\t\tPassword *string `json:\"email_password\"`\n\t\t\tSSL      bool    `json:\"email_ssl\"`\n\t\t\tIdentity string  `json:\"email_identity\"`\n\t\t\tInsecure bool    `json:\"email_insecure\"`\n\t\t}{}\n\t\te.DecodeJSONReq(&settings)\n\n\t\tif len(settings.Host) == 0 || settings.Port == nil {\n\t\t\te.CustomAbort(http.StatusBadRequest, \"empty host or port\")\n\t\t}\n\n\t\tif settings.Password == nil {\n\t\t\tcfg, err := config.Email()\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"failed to get email configurations: %v\", err)\n\t\t\t\te.CustomAbort(http.StatusInternalServerError,\n\t\t\t\t\thttp.StatusText(http.StatusInternalServerError))\n\t\t\t}\n\n\t\t\tsettings.Password = &cfg.Password\n\t\t}\n\n\t\thost = settings.Host\n\t\tport = *settings.Port\n\t\tusername = settings.Username\n\t\tpassword = *settings.Password\n\t\tidentity = settings.Identity\n\t\tssl = settings.SSL\n\t\tinsecure = settings.Insecure\n\t}\n\n\taddr := net.JoinHostPort(host, strconv.Itoa(port))\n\tif err := email.Ping(addr, identity, username,\n\t\tpassword, pingEmailTimeout, ssl, insecure); err != nil {\n\t\tlog.Debugf(\"ping %s failed: %v\", addr, err)\n\t\te.CustomAbort(http.StatusBadRequest, err.Error())\n\t}\n}", "is_vulnerable": 1}
{"code": "func NewQUICServer(addr, password, domain string, tcpTimeout, udpTimeout int, withoutbrook bool) (*QUICServer, error) {\n\tif err := limits.Raise(); err != nil {\n\t\tLog(&Error{\"when\": \"try to raise system limits\", \"warning\": err.Error()})\n\t}\n\tif runtime.GOOS == \"linux\" {\n\t\tc := exec.Command(\"sysctl\", \"-w\", \"net.core.rmem_max=2500000\")\n\t\tb, err := c.CombinedOutput()\n\t\tif err != nil {\n\t\t\tLog(&Error{\"when\": \"try to raise UDP Receive Buffer Size\", \"warning\": string(b)})\n\t\t}\n\t}\n\tif runtime.GOOS == \"darwin\" {\n\t\tc := exec.Command(\"sysctl\", \"-w\", \"kern.ipc.maxsockbuf=3014656\")\n\t\tb, err := c.CombinedOutput()\n\t\tif err != nil {\n\t\t\tLog(&Error{\"when\": \"try to raise UDP Receive Buffer Size\", \"warning\": string(b)})\n\t\t}\n\t}\n\tvar p []byte\n\tvar f UDPServerConnFactory\n\tif !withoutbrook {\n\t\tp = []byte(password)\n\t\tf = NewPacketServerConnFactory()\n\t}\n\tif withoutbrook {\n\t\tvar err error\n\t\tp, err = crypto1.SHA256Bytes([]byte(password))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tf = NewSimplePacketServerConnFactory()\n\t}\n\ts := &QUICServer{\n\t\tPassword:             p,\n\t\tDomain:               domain,\n\t\tAddr:                 addr,\n\t\tTCPTimeout:           tcpTimeout,\n\t\tUDPTimeout:           udpTimeout,\n\t\tUDPServerConnFactory: f,\n\t\tRunnerGroup:          runnergroup.New(),\n\t\tWithoutBrook:         withoutbrook,\n\t}\n\treturn s, nil\n}", "is_vulnerable": 0}
{"code": "func forceMime(parent http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Prevent directory listings.\n\t\tif strings.HasSuffix(r.URL.Path, \"/\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\n\t\tw.Header().Set(\"Content-Type\", \"binary/octet-stream\")\n\t\tparent.ServeHTTP(w, r)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (v *notaryVerifier) FetchAttestations(ctx context.Context, opts images.Options) (*images.Response, error) {\n\tv.log.V(2).Info(\"fetching attestations\", \"reference\", opts.ImageRef, \"opts\", opts)\n\n\tref, err := name.ParseReference(opts.ImageRef)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to parse image reference: %s\", opts.ImageRef)\n\t}\n\tauthenticator, err := getAuthenticator(ctx, opts.ImageRef, opts.RegistryClient)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to parse authenticator: %s\", opts.ImageRef)\n\t}\n\tcraneOpts := crane.WithAuth(*authenticator)\n\n\tremoteOpts, err := getRemoteOpts(*authenticator)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tv.log.V(4).Info(\"client setup done\", \"repo\", ref)\n\n\trepoDesc, err := crane.Head(opts.ImageRef, craneOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tv.log.V(4).Info(\"fetched repository\", \"repoDesc\", repoDesc)\n\n\treferrers, err := remote.Referrers(ref.Context().Digest(repoDesc.Digest.String()), remoteOpts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treferrersDescs, err := referrers.IndexManifest()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tv.log.V(4).Info(\"fetched referrers\", \"referrers\", referrersDescs)\n\n\tvar statements []map[string]interface{}\n\n\tfor _, referrer := range referrersDescs.Manifests {\n\t\tmatch, _, err := matchArtifactType(referrer, opts.Type)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif !match {\n\t\t\tv.log.V(6).Info(\"type doesn't match, continue\", \"expected\", opts.Type, \"received\", referrer.ArtifactType)\n\t\t\tcontinue\n\t\t}\n\n\t\ttargetDesc, err := verifyAttestators(ctx, v, ref, opts, referrer)\n\t\tif err != nil {\n\t\t\tmsg := err.Error()\n\t\t\tv.log.V(4).Info(msg, \"failed to verify referrer %s\", targetDesc.Digest.String())\n\t\t\treturn nil, err\n\t\t}\n\n\t\tv.log.V(4).Info(\"extracting statements\", \"desc\", referrer, \"repo\", ref)\n\t\tstatements, err = extractStatements(ctx, ref, referrer, craneOpts)\n\t\tif err != nil {\n\t\t\tmsg := err.Error()\n\t\t\tv.log.V(4).Info(\"failed to extract statements %s\", \"err\", msg)\n\t\t\treturn nil, err\n\t\t}\n\n\t\tv.log.V(4).Info(\"verified attestators\", \"digest\", targetDesc.Digest.String())\n\n\t\tif len(statements) == 0 {\n\t\t\treturn nil, fmt.Errorf(\"failed to fetch attestations\")\n\t\t}\n\t\tv.log.V(6).Info(\"sending response\")\n\t\treturn &images.Response{Digest: repoDesc.Digest.String(), Statements: statements}, nil\n\t}\n\n\treturn nil, fmt.Errorf(\"failed to fetch attestations %s\", err)\n}", "is_vulnerable": 0}
{"code": "func TestSecrets_GenerateKeyTTLOverride(t *testing.T) {\n\tsecretType := SecretTypeKey\n\trsName := \"test-genkey\"\n\n\ttd := setupTest(t, \"1h\", \"2h\")\n\tdefer cleanup(t, td, rsName, testRoles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create new role set\n\texpectedBinds := ResourceBindings{projRes: testRoles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"secret_type\": secretType,\n\t\t\t\"project\":     td.Project,\n\t\t\t\"bindings\":    bindsRaw,\n\t\t})\n\tsa := getRoleSetAccount(t, td, rsName)\n\n\t// expect error for trying to read token from key roleset\n\ttestGetTokenFail(t, td, rsName)\n\n\t// call the POST endpoint of /gcp/key/:roleset with updated TTL\n\tcreds, resp := testPostKey(t, td, rsName, \"60s\")\n\tif int(resp.Secret.LeaseTotal().Seconds()) != 60 {\n\t\tt.Fatalf(\"expected lease duration %d, got %d\", 60, int(resp.Secret.LeaseTotal().Seconds()))\n\t}\n\n\t// Confirm calls with key work\n\tkeyHttpC := oauth2.NewClient(context.Background(), creds.TokenSource)\n\tcheckSecretPermissions(t, td, keyHttpC)\n\n\tkeyName := resp.Secret.InternalData[\"key_name\"].(string)\n\tif keyName == \"\" {\n\t\tt.Fatalf(\"expected internal data to include key name\")\n\t}\n\n\t_, err = td.IamAdmin.Projects.ServiceAccounts.Keys.Get(keyName).Do()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get key from given internal 'key_name': %v\", err)\n\t}\n\n\ttestRenewSecretKey(t, td, resp.Secret)\n\ttestRevokeSecretKey(t, td, resp.Secret)\n\n\tk, err := td.IamAdmin.Projects.ServiceAccounts.Keys.Get(keyName).Do()\n\n\tif k != nil {\n\t\tt.Fatalf(\"expected error as revoked key was deleted, instead got key: %v\", k)\n\t}\n\tif err == nil || !isGoogleAccountKeyNotFoundErr(err) {\n\t\tt.Fatalf(\"expected 404 error from getting deleted key, instead got error: %v\", err)\n\t}\n\n\t// Cleanup: Delete role set\n\ttestRoleSetDelete(t, td, rsName, sa.Name)\n\tverifyProjectBindingsRemoved(t, td, sa.Email, testRoles)\n}", "is_vulnerable": 0}
{"code": "\t\treturn middleware.ResponderFunc(func(w http.ResponseWriter, p runtime.Producer) {\n\t\t\tcookie := NewSessionCookieForConsole(changePasswordResponse.SessionID)\n\t\t\thttp.SetCookie(w, &cookie)\n\t\t\tuser_api.NewLoginNoContent().WriteResponse(w, p)\n\t\t})", "is_vulnerable": 0}
{"code": "func HTTPBodyContains(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, str interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.HTTPBodyContains(t, handler, method, url, values, str, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetKeyListMode(m KeyListMode) error {\n\terr := handleError(C.gpgme_set_keylist_mode(c.ctx, C.gpgme_keylist_mode_t(m)))\n\truntime.KeepAlive(c)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func TestListObjects_Unoptimized_UnhappyPaths(t *testing.T) {\n\tctx := context.Background()\n\tlogger := logger.NewNoopLogger()\n\ttransport := gateway.NewNoopTransport()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgapb.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: parser.MustParse(`\n\t\ttype user\n\n\t\ttype repo\n\t\t  relations\n\t\t    define allowed: [user] as self\n\t\t    define viewer: [user] as self and allowed\n\t\t`),\n\t}, nil)\n\tmockDatastore.EXPECT().ListObjectsByType(gomock.Any(), store, \"repo\").AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := New(&Dependencies{\n\t\tDatastore: mockDatastore,\n\t\tTransport: transport,\n\t\tLogger:    logger,\n\t}, &Config{\n\t\tResolveNodeLimit:      test.DefaultResolveNodeLimit,\n\t\tListObjectsDeadline:   5 * time.Second,\n\t\tListObjectsMaxResults: 1000,\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\tres, err := s.ListObjects(ctx, &openfgapb.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"repo\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t})\n\n\t\trequire.Nil(t, res)\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgapb.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"repo\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t}, NewMockStreamServer())\n\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n}", "is_vulnerable": 0}
{"code": "\t\t\terrChk: func(t testing.TB, err error) {\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"Expected no err, got: %s\", err)\n\t\t\t\t}\n\t\t\t},", "is_vulnerable": 0}
{"code": "func (t *Teler) checkBadIPAddress(r *http.Request) error {\n\t// Get the client's IP address\n\tclientIP := getClientIP(r)\n\n\t// Check if the client IP address is in BadIPAddress index\n\tif t.inThreatIndex(threat.BadIPAddress, clientIP) {\n\t\t// Return an error indicating a bad IP address has been detected\n\t\treturn errors.New(\"bad IP address\")\n\t}\n\n\t// Return nil if the remote address is not found in the index\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestS3SaveStrategy(t *testing.T) {\n\tcases := []struct {\n\t\tenv      s3crypto.Envelope\n\t\texpected s3crypto.Envelope\n\t}{\n\t\t{\n\t\t\ts3crypto.Envelope{\n\t\t\t\tCipherKey:             \"Foo\",\n\t\t\t\tIV:                    \"Bar\",\n\t\t\t\tMatDesc:               \"{}\",\n\t\t\t\tWrapAlg:               s3crypto.KMSWrap,\n\t\t\t\tCEKAlg:                s3crypto.AESGCMNoPadding,\n\t\t\t\tTagLen:                \"128\",\n\t\t\t\tUnencryptedMD5:        \"hello\",\n\t\t\t\tUnencryptedContentLen: \"0\",\n\t\t\t},\n\t\t\ts3crypto.Envelope{\n\t\t\t\tCipherKey:             \"Foo\",\n\t\t\t\tIV:                    \"Bar\",\n\t\t\t\tMatDesc:               \"{}\",\n\t\t\t\tWrapAlg:               s3crypto.KMSWrap,\n\t\t\t\tCEKAlg:                s3crypto.AESGCMNoPadding,\n\t\t\t\tTagLen:                \"128\",\n\t\t\t\tUnencryptedContentLen: \"0\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\ts3crypto.Envelope{\n\t\t\t\tCipherKey:             \"Foo\",\n\t\t\t\tIV:                    \"Bar\",\n\t\t\t\tMatDesc:               \"{}\",\n\t\t\t\tWrapAlg:               s3crypto.KMSWrap,\n\t\t\t\tCEKAlg:                s3crypto.AESGCMNoPadding,\n\t\t\t\tUnencryptedMD5:        \"hello\",\n\t\t\t\tUnencryptedContentLen: \"0\",\n\t\t\t},\n\t\t\ts3crypto.Envelope{\n\t\t\t\tCipherKey:             \"Foo\",\n\t\t\t\tIV:                    \"Bar\",\n\t\t\t\tMatDesc:               \"{}\",\n\t\t\t\tWrapAlg:               s3crypto.KMSWrap,\n\t\t\t\tCEKAlg:                s3crypto.AESGCMNoPadding,\n\t\t\t\tUnencryptedContentLen: \"0\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, c := range cases {\n\t\tparams := &s3.PutObjectInput{\n\t\t\tBucket: aws.String(\"fooBucket\"),\n\t\t\tKey:    aws.String(\"barKey\"),\n\t\t}\n\t\treq := &request.Request{\n\t\t\tParams: params,\n\t\t}\n\n\t\tclient := s3.New(unit.Session)\n\n\t\tclient.Handlers.Send.Clear()\n\t\tclient.Handlers.Unmarshal.Clear()\n\t\tclient.Handlers.UnmarshalMeta.Clear()\n\t\tclient.Handlers.UnmarshalError.Clear()\n\t\tclient.Handlers.Send.PushBack(func(r *request.Request) {\n\t\t\tbodyBytes, err := ioutil.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\t\tStatusCode: 500,\n\t\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(err.Error()))),\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar actual s3crypto.Envelope\n\t\t\terr = json.Unmarshal(bodyBytes, &actual)\n\t\t\tif err != nil {\n\t\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\t\tStatusCode: 500,\n\t\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(err.Error()))),\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif e, a := c.expected, actual; !reflect.DeepEqual(e, a) {\n\t\t\t\tt.Errorf(\"expected %v, got %v\", e, a)\n\t\t\t}\n\n\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\tStatusCode: 200,\n\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(\"\"))),\n\t\t\t}\n\t\t})\n\n\t\tstrat := s3crypto.S3SaveStrategy{Client: client}\n\t\terr := strat.Save(c.env, req)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (i *IDMappings) ToContainer(pair IDPair) (int, int, error) {\n\tuid, err := RawToContainer(pair.UID, i.uids)\n\tif err != nil {\n\t\treturn -1, -1, err\n\t}\n\tgid, err := RawToContainer(pair.GID, i.gids)\n\treturn uid, gid, err\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Mkdir(ctx context.Context, in *sliverpb.MkdirReq, opts ...grpc.CallOption) (*sliverpb.Mkdir, error) {\n\tout := new(sliverpb.Mkdir)\n\terr := c.cc.Invoke(ctx, SliverRPC_Mkdir_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (o *Options) Update() error {\n\t// keep a slice of messages to print at the end of the update to help users diagnose non-fatal problems\n\tvar printMessages []string\n\tpackagesToUpdate := make(map[string]string)\n\tvar errorMessages []string\n\n\t// clone the melange config git repo into a temp folder so we can work with it\n\ttempDir, err := os.MkdirTemp(\"\", \"wolfictl\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create temporary folder to clone package configs into: %w\", err)\n\t}\n\tif o.DryRun {\n\t\to.Logger.Printf(\"using working directory %s\", tempDir)\n\t} else {\n\t\tdefer os.Remove(tempDir)\n\t}\n\n\trepo, err := git.PlainClone(tempDir, false, &git.CloneOptions{\n\t\tURL:      o.RepoURI,\n\t\tProgress: os.Stdout,\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to clone repository %s into %s: %w\", o.RepoURI, tempDir, err)\n\t}\n\n\t// first, let's get the melange package(s) from the target git repo, that we want to check for updates\n\to.PackageConfigs, err = melange.ReadPackageConfigs(o.PackageNames, tempDir)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get package configs: %w\", err)\n\t}\n\n\t// second, get package mapping data that we use to lookup if new versions exist\n\to.MapperData, err = o.getMonitorServiceData()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed getting release monitor service mapping data: %w\", err)\n\t}\n\n\tif o.GithubReleaseQuery {\n\t\t// let's get any versions that use GITHUB first as we can do that using reduced graphql requests\n\t\tg := NewGitHubReleaseOptions(o.MapperData, o.PackageConfigs, o.GitGraphQLClient)\n\t\tpackagesToUpdate, errorMessages, err = g.getLatestGitHubVersions()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed getting github releases: %w\", err)\n\t\t}\n\t\tprintMessages = append(printMessages, errorMessages...)\n\t}\n\n\tif o.ReleaseMonitoringQuery {\n\t\t// get latest versions from https://release-monitoring.org/\n\t\tm := MonitorService{\n\t\t\tClient:           o.Client,\n\t\t\tGitHubHTTPClient: o.GitHubHTTPClient,\n\t\t\tLogger:           o.Logger,\n\t\t}\n\t\tnewReleaseMonitorVersions, errorMessages, err := m.getLatestReleaseMonitorVersions(o.MapperData, o.PackageConfigs)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed release monitor versions: %w\", err)\n\t\t}\n\t\tprintMessages = append(printMessages, errorMessages...)\n\n\t\tmaps.Copy(packagesToUpdate, newReleaseMonitorVersions)\n\t}\n\n\t// update melange configs in our cloned git repository with any new package versions\n\terrorMessages, err = o.updatePackagesGitRepository(repo, packagesToUpdate, tempDir)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to update packages in git repository: %w\", err)\n\t}\n\n\tprintMessages = append(printMessages, errorMessages...)\n\n\t// certain errors should not halt the updates, print them at the end\n\tfor _, message := range printMessages {\n\t\to.Logger.Printf(message)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\terr := s.Walk(filePath, func(path string, info os.FileInfo, err error) error {\n\t\tif filePath == path {\n\t\t\tfileInfo = info\n\t\t}\n\t\treturn err\n\t})", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) HasSpaceAvailable(allowStaleValue bool) bool {\n\tsize, err := fs.DiskUsage(allowStaleValue)\n\tif err != nil {\n\t\tlog.WithField(\"root\", fs.Path()).WithField(\"error\", err).Warn(\"failed to determine root fs directory size\")\n\t}\n\n\t// If space is -1 or 0 just return true, means they're allowed unlimited.\n\t//\n\t// Technically we could skip disk space calculation because we don't need to check if the\n\t// server exceeds its limit but because this method caches the disk usage it would be best\n\t// to calculate the disk usage and always return true.\n\tif fs.MaxDisk() == 0 {\n\t\treturn true\n\t}\n\n\treturn size <= fs.MaxDisk()\n}", "is_vulnerable": 0}
{"code": "func (d *decoder) unmarshal(n *node, out reflect.Value) (good bool) {\n\td.decodeCount++\n\tif d.aliasDepth > 0 {\n\t\td.aliasCount++\n\t}\n\tif d.aliasCount > 100 && d.decodeCount > 1000 && float64(d.aliasCount)/float64(d.decodeCount) > allowedAliasRatio(d.decodeCount) {\n\t\tfailf(\"document contains excessive aliasing\")\n\t}\n\tswitch n.kind {\n\tcase documentNode:\n\t\treturn d.document(n, out)\n\tcase aliasNode:\n\t\treturn d.alias(n, out)\n\t}\n\tout, unmarshaled, good := d.prepare(n, out)\n\tif unmarshaled {\n\t\treturn good\n\t}\n\tswitch n.kind {\n\tcase scalarNode:\n\t\tgood = d.scalar(n, out)\n\tcase mappingNode:\n\t\tgood = d.mapping(n, out)\n\tcase sequenceNode:\n\t\tgood = d.sequence(n, out)\n\tdefault:\n\t\tpanic(\"internal error: unknown node kind: \" + strconv.Itoa(n.kind))\n\t}\n\treturn good\n}", "is_vulnerable": 0}
{"code": "\terr = b.Restore(s.Context(), reader, func(file string, info fs.FileInfo, r io.ReadCloser) error {\n\t\tdefer r.Close()\n\t\ts.Events().Publish(DaemonMessageEvent, \"(restoring): \"+file)\n\t\t// TODO: since this will be called a lot, it may be worth adding an optimized\n\t\t// Write with Chtimes method to the UnixFS that is able to re-use the\n\t\t// same dirfd and file name.\n\t\tif err := s.Filesystem().Write(file, r, info.Size(), info.Mode()); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tatime := info.ModTime()\n\t\treturn s.Filesystem().Chtimes(file, atime, atime)\n\t})", "is_vulnerable": 0}
{"code": "func ProxyClientSSHConfig(sshCert, privKey []byte, caCerts [][]byte) (*ssh.ClientConfig, error) {\n\tcert, err := ParseCertificate(sshCert)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to extract username from SSH certificate\")\n\t}\n\n\tauthMethod, err := AsAuthMethod(cert, privKey)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert key pair to auth method\")\n\t}\n\n\thostKeyCallback, err := HostKeyCallback(caCerts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert certificate authorities to HostKeyCallback\")\n\t}\n\n\t// The KeyId is not always a valid principal, so we use the first valid principal instead.\n\tuser := cert.KeyId\n\tif len(cert.ValidPrincipals) > 0 {\n\t\tuser = cert.ValidPrincipals[0]\n\t}\n\n\treturn &ssh.ClientConfig{\n\t\tUser:            user,\n\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\tHostKeyCallback: hostKeyCallback,\n\t\tTimeout:         defaults.DefaultDialTimeout,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func NotPanicsf(t TestingT, f assert.PanicTestFunc, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotPanicsf(t, f, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func TestSignatureWithTSAAnnotation(t *testing.T) {\n\tlayer, err := random.Layer(300 /* byteSize */, types.DockerLayer)\n\tif err != nil {\n\t\tt.Fatalf(\"random.Layer() = %v\", err)\n\t}\n\tdigest, err := layer.Digest()\n\tif err != nil {\n\t\tt.Fatalf(\"Digest() = %v\", err)\n\t}\n\n\ttests := []struct {\n\t\tname           string\n\t\tl              *sigLayer\n\t\tenv            map[string]string\n\t\twantPayloadErr error\n\t\twantSig        string\n\t\twantSigErr     error\n\t\twantCert       bool\n\t\twantCertErr    error\n\t\twantChain      int\n\t\twantChainErr   error\n\t\twantBundle     *bundle.RFC3161Timestamp\n\t\twantBundleErr  error\n\t}{{\n\t\tname: \"just payload and signature\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"blah\",\n\t}, {\n\t\tname: \"with empty other keys\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:              \"blah\",\n\t\t\t\t\tcertkey:             \"\",\n\t\t\t\t\tchainkey:            \"\",\n\t\t\t\t\tRFC3161TimestampKey: \"\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"blah\",\n\t}, {\n\t\tname: \"missing signature\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t},\n\t\t},\n\t\twantSigErr: fmt.Errorf(\"signature layer %s is missing %q annotation\", digest, sigkey),\n\t}, {\n\t\tname: \"min plus bad RFC3161 timestamp bundle\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:              \"blah\",\n\t\t\t\t\tRFC3161TimestampKey: `}`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:       \"blah\",\n\t\twantBundleErr: errors.New(`unmarshaling RFC3161 timestamp bundle: invalid character '}' looking for beginning of value`),\n\t}, {\n\t\tname: \"min plus bad cert\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:  \"blah\",\n\t\t\t\t\tcertkey: `GARBAGE`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:     \"blah\",\n\t\twantCertErr: errors.New(`error during PEM decoding`),\n\t}, {\n\t\tname: \"min plus bad chain\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey:   \"blah\",\n\t\t\t\t\tchainkey: `GARBAGE`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig:      \"blah\",\n\t\twantChainErr: errors.New(`error during PEM decoding`),\n\t}, {\n\t\tname: \"min plus RFC3161 timestamp bundle\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"tsa blah\",\n\t\t\t\t\t// This was extracted from gcr.io/distroless/static:nonroot on 2021/09/16.\n\t\t\t\t\t// The Body has been removed for brevity\n\t\t\t\t\tRFC3161TimestampKey: `{\"SignedRFC3161Timestamp\":\"MEUCIQClUkUqZNf+6dxBc/pxq22JIluTB7Kmip1G0FIF5E0C1wIgLqXm+IM3JYW/P/qjMZSXW+J8bt5EOqNfe3R+0A9ooFE=\",\"Payload\":{\"body\":\"REMOVED\",\"integratedTime\":1631646761,\"logIndex\":693591,\"logID\":\"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\"}}`,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\twantSig: \"tsa blah\",\n\t\twantBundle: &bundle.RFC3161Timestamp{\n\t\t\tSignedRFC3161Timestamp: mustDecode(\"MEUCIQClUkUqZNf+6dxBc/pxq22JIluTB7Kmip1G0FIF5E0C1wIgLqXm+IM3JYW/P/qjMZSXW+J8bt5EOqNfe3R+0A9ooFE=\"),\n\t\t},\n\t}, {\n\t\tname: \"payload size exceeds default limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: &mockLayer{size: 134217728 + 42}, // 128MiB + 42 bytes\n\t\t},\n\t\twantPayloadErr: errors.New(\"size of layer (134217770) exceeded the limit (134217728)\"),\n\t}, {\n\t\tname: \"payload size exceeds overridden limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: &mockLayer{size: 1000000000 + 42}, // 1GB + 42 bytes\n\t\t},\n\t\tenv:            map[string]string{\"COSIGN_MAX_ATTACHMENT_SIZE\": \"1GB\"},\n\t\twantPayloadErr: errors.New(\"size of layer (1000000042) exceeded the limit (1000000000)\"),\n\t}, {\n\t\tname: \"payload size is within overridden limit\",\n\t\tl: &sigLayer{\n\t\t\tLayer: layer,\n\t\t\tdesc: v1.Descriptor{\n\t\t\t\tDigest: digest,\n\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\tsigkey: \"blah\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tenv:     map[string]string{\"COSIGN_MAX_ATTACHMENT_SIZE\": \"5KB\"},\n\t\twantSig: \"blah\",\n\t}}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Portfwd(ctx context.Context, in *sliverpb.PortfwdReq, opts ...grpc.CallOption) (*sliverpb.Portfwd, error) {\n\tout := new(sliverpb.Portfwd)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Portfwd\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestGetFloatAnnotation(t *testing.T) {\n\ting := buildIngress()\n\n\t_, err := GetFloatAnnotation(\"\", nil, nil)\n\tif err == nil {\n\t\tt.Errorf(\"expected error but retuned nil\")\n\t}\n\n\ttests := []struct {\n\t\tname   string\n\t\tfield  string\n\t\tvalue  string\n\t\texp    float32\n\t\texpErr bool\n\t}{\n\t\t{\"valid - A\", \"string\", \"1.5\", 1.5, false},\n\t\t{\"valid - B\", \"string\", \"2\", 2, false},\n\t\t{\"valid - C\", \"string\", \"100.0\", 100, false},\n\t}\n\n\tdata := map[string]string{}\n\ting.SetAnnotations(data)\n\n\tfor _, test := range tests {\n\t\tdata[GetAnnotationWithPrefix(test.field)] = test.value\n\n\t\ts, err := GetFloatAnnotation(test.field, ing, nil)\n\t\tif test.expErr {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"%v: expected error but retuned nil\", test.name)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif s != test.exp {\n\t\t\tt.Errorf(\"%v: expected \\\"%v\\\" but \\\"%v\\\" was returned\", test.name, test.exp, s)\n\t\t}\n\n\t\tdelete(data, test.field)\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetTLSConfig(config *apicommon.TLSConfig) (*tls.Config, error) {\n\tif config == nil {\n\t\treturn nil, errors.New(\"TLSConfig is nil\")\n\t}\n\n\tif config.InsecureSkipVerify {\n\t\ttlsConfig := &tls.Config{\n\t\t\tInsecureSkipVerify: true,\n\t\t\tClientAuth:         0,\n\t\t}\n\t\treturn tlsConfig, nil\n\t}\n\n\tvar caCertPath, clientCertPath, clientKeyPath string\n\tvar err error\n\tif config.CACertSecret != nil {\n\t\tcaCertPath, err = GetSecretVolumePath(config.CACertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientCertSecret != nil {\n\t\tclientCertPath, err = GetSecretVolumePath(config.ClientCertSecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif config.ClientKeySecret != nil {\n\t\tclientKeyPath, err = GetSecretVolumePath(config.ClientKeySecret)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif len(caCertPath)+len(clientCertPath)+len(clientKeyPath) == 0 {\n\t\t// None of 3 is configured\n\t\treturn nil, errors.New(\"invalid tls config, neither of caCertSecret, clientCertSecret and clientKeySecret is configured\")\n\t}\n\n\tif len(clientCertPath)+len(clientKeyPath) > 0 && len(clientCertPath)*len(clientKeyPath) == 0 {\n\t\t// Only one of clientCertSecret and clientKeySecret is configured\n\t\treturn nil, errors.New(\"invalid tls config, both of clientCertSecret and clientKeySecret need to be configured\")\n\t}\n\n\tc := &tls.Config{}\n\tif len(caCertPath) > 0 {\n\t\tcaCert, err := os.ReadFile(caCertPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to read ca cert file %s\", caCertPath)\n\t\t}\n\t\tpool := x509.NewCertPool()\n\t\tpool.AppendCertsFromPEM(caCert)\n\t\tc.RootCAs = pool\n\t}\n\n\tif len(clientCertPath) > 0 && len(clientKeyPath) > 0 {\n\t\tclientCert, err := tls.LoadX509KeyPair(clientCertPath, clientKeyPath)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to load client cert key pair %s\", caCertPath)\n\t\t}\n\t\tc.Certificates = []tls.Certificate{clientCert}\n\t}\n\treturn c, nil\n}", "is_vulnerable": 0}
{"code": "func TestInteractionHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an interaction event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an interaction action message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tactionString := `{\"type\":\"block_actions\",\"team\":{\"id\":\"T9TK3CUKW\",\"domain\":\"example\"},\"user\":{\"id\":\"UA8RXUSPL\",\"username\":\"jtorrance\",\"team_id\":\"T9TK3CUKW\"},\"api_app_id\":\"AABA1ABCD\",\"token\":\"9s8d9as89d8as9d8as989\",\"container\":{\"type\":\"message_attachment\",\"message_ts\":\"1548261231.000200\",\"attachment_id\":1,\"channel_id\":\"CBR2V3XEX\",\"is_ephemeral\":false,\"is_app_unfurl\":false},\"trigger_id\":\"12321423423.333649436676.d8c1bb837935619ccad0f624c448ffb3\",\"channel\":{\"id\":\"CBR2V3XEX\",\"name\":\"review-updates\"},\"message\":{\"bot_id\":\"BAH5CA16Z\",\"type\":\"message\",\"text\":\"This content can't be displayed.\",\"user\":\"UAJ2RU415\",\"ts\":\"1548261231.000200\"},\"response_url\":\"https://hooks.slack.com/actions/AABA1ABCD/1232321423432/D09sSasdasdAS9091209\",\"actions\":[{\"action_id\":\"WaXA\",\"block_id\":\"=qXel\",\"text\":{\"type\":\"plain_text\",\"text\":\"View\",\"emoji\":true},\"value\":\"click_me_123\",\"type\":\"button\",\"action_ts\":\"1548426417.840180\"}]}`\n\t\t\tpayload := []byte(`payload=` + actionString)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   ioutil.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"type\\\":\\\"block_actions\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"9s8d9as89d8as9d8as989\\\"\")\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func (r *replayer) decode(key []byte, value []byte) {\n\taccount := rawdb.IsAccountTrieNode(key)\n\tstorage := rawdb.IsStorageTrieNode(key)\n\tif !account && !storage {\n\t\tr.unknowns += 1\n\t\treturn\n\t}\n\tvar path []byte\n\tif account {\n\t\t_, path = rawdb.ResolveAccountTrieNodeKey(key)\n\t} else {\n\t\t_, owner, inner := rawdb.ResolveStorageTrieNode(key)\n\t\tpath = append(owner.Bytes(), inner...)\n\t}\n\tr.paths = append(r.paths, string(path))\n\n\tif len(value) == 0 {\n\t\tr.hashes = append(r.hashes, common.Hash{})\n\t} else {\n\t\tr.hashes = append(r.hashes, crypto.Keccak256Hash(value))\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tb, err := json.Marshal(tt.statement)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tpayloadHash := sha256.Sum256(b)\n\t\t\tv := V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: createRekorEnvelope(envelope(t, key, b), [][]byte{pub}),\n\t\t\t\t\t\tHash: &models.IntotoV002SchemaContentHash{\n\t\t\t\t\t\t\tAlgorithm: swag.String(models.IntotoV001SchemaContentHashAlgorithmSha256),\n\t\t\t\t\t\t\tValue:     swag.String(envelopeHash(t, envelope(t, key, b))),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPayloadHash: &models.IntotoV002SchemaContentPayloadHash{\n\t\t\t\t\t\t\tAlgorithm: swag.String(models.IntotoV001SchemaContentHashAlgorithmSha256),\n\t\t\t\t\t\t\tValue:     swag.String(hex.EncodeToString(payloadHash[:])),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *envelope(t, key, b),\n\t\t\t}\n\t\t\twant := []string{}\n\t\t\tfor _, sig := range v.IntotoObj.Content.Envelope.Signatures {\n\t\t\t\tkeyHash := sha256.Sum256(*sig.PublicKey)\n\t\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(keyHash[:]))\n\t\t\t}\n\n\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(payloadHash[:]))\n\n\t\t\twant = append(want, tt.want...)\n\t\t\tgot, _ := v.IndexKeys()\n\t\t\tsort.Strings(got)\n\t\t\tsort.Strings(want)\n\t\t\tif !cmp.Equal(got, want) {\n\t\t\t\tt.Errorf(\"V001Entry.IndexKeys() = %v, want %v\", got, want)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func TestConfigurator_IncomingHTTPS_TLSMinVersion(t *testing.T) {\n\ttlsVersions := []string{\"tls10\", \"tls11\", \"tls12\"}\n\tfor _, version := range tlsVersions {\n\t\tconf := &Config{\n\t\t\tVerifyIncoming: true,\n\t\t\tCAFile:         \"../test/ca/root.cer\",\n\t\t\tCertFile:       \"../test/key/ourdomain.cer\",\n\t\t\tKeyFile:        \"../test/key/ourdomain.key\",\n\t\t\tTLSMinVersion:  version,\n\t\t}\n\t\tc := NewConfigurator(conf)\n\t\ttlsConf, err := c.IncomingHTTPSConfig()\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, tlsConf)\n\t\trequire.Equal(t, tlsConf.MinVersion, TLSLookup[version])\n\t}\n}", "is_vulnerable": 1}
{"code": "func (page *GroupListResultPage) NextWithContext(ctx context.Context) (err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupListResultPage.NextWithContext\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif page.Response().Response.Response != nil {\n\t\t\t\tsc = page.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tnext, err := page.fn(ctx, page.glr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpage.glr = next\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tg.POST(\"/user\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing auth session\")\n\t\t}\n\t\tcurrentUser, err := s.Store.FindUser(ctx, &api.UserFind{\n\t\t\tID: &userID,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to find user by id\").SetInternal(err)\n\t\t}\n\t\tif currentUser.Role != api.Host {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Only Host user can create member\")\n\t\t}\n\n\t\tuserCreate := &api.UserCreate{}\n\t\tif err := json.NewDecoder(c.Request().Body).Decode(userCreate); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Malformatted post user request\").SetInternal(err)\n\t\t}\n\t\tif userCreate.Role == api.Host {\n\t\t\treturn echo.NewHTTPError(http.StatusForbidden, \"Could not create host user\")\n\t\t}\n\t\tuserCreate.OpenID = common.GenUUID()\n\n\t\tif err := userCreate.Validate(); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Invalid user create format\").SetInternal(err)\n\t\t}\n\n\t\tpasswordHash, err := bcrypt.GenerateFromPassword([]byte(userCreate.Password), bcrypt.DefaultCost)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to generate password hash\").SetInternal(err)\n\t\t}\n\n\t\tuserCreate.PasswordHash = string(passwordHash)\n\t\tuser, err := s.Store.CreateUser(ctx, userCreate)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to create user\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"user created\",\n\t\t})\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(user)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode user response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (m *IndexQuery) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIndex\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: IndexQuery: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: IndexQuery: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Key\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIndex\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIndex\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIndex\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Key = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIndex\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIndex\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIndex\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Value = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIndex(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIndex\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tdb.auth = NewAuthorizer(db.client, func(a string) (string, string, error) {\n\t\treturn \"Authorize\", \"Basic blah\", nil\n\t})", "is_vulnerable": 0}
{"code": "func EscapeBashStr(s string) string {\n\tif !containsOne(s, []rune{'$', '`', '&', ';', '>', '|', '(', ')'}) {\n\t\treturn s\n\t}\n\ts = strings.ReplaceAll(s, `\\`, `\\\\`)\n\ts = strings.ReplaceAll(s, `'`, `\\'`)\n\tif strings.Contains(s, `\\\\`) {\n\t\ts = strings.ReplaceAll(s, `\\\\\\\\`, `\\\\`)\n\t\ts = strings.ReplaceAll(s, `\\\\\\'`, `\\'`)\n\t\ts = strings.ReplaceAll(s, `\\\\\"`, `\\\"`)\n\t\ts = strings.ReplaceAll(s, `\\\\a`, `\\a`)\n\t\ts = strings.ReplaceAll(s, `\\\\b`, `\\b`)\n\t\ts = strings.ReplaceAll(s, `\\\\e`, `\\e`)\n\t\ts = strings.ReplaceAll(s, `\\\\E`, `\\E`)\n\t\ts = strings.ReplaceAll(s, `\\\\n`, `\\n`)\n\t\ts = strings.ReplaceAll(s, `\\\\r`, `\\r`)\n\t\ts = strings.ReplaceAll(s, `\\\\t`, `\\t`)\n\t\ts = strings.ReplaceAll(s, `\\\\v`, `\\v`)\n\t\ts = strings.ReplaceAll(s, `\\\\?`, `\\?`)\n\t}\n\treturn fmt.Sprintf(`$'%s'`, s)\n}", "is_vulnerable": 0}
{"code": "\thf := func(w http.ResponseWriter, r *http.Request) {\n\t\tif r.URL.Path == \"/.well-known/oauth-authorization-server\" {\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t\t_, err := io.WriteString(w, strings.ReplaceAll(`{\n\t\t\t\t\"issuer\": \"https://whatever.okta.com\",\n\t\t\t\t\"authorization_endpoint\": \"https://example.com/auth\",\n\t\t\t\t\"token_endpoint\": \"https://example.com/token\",\n\t\t\t\t\"jwks_uri\": \"{URL}/keys\",\n\t\t\t\t\"id_token_signing_alg_values_supported\": [\"RS256\"]\n\t\t\t}`, \"{URL}\", *serverURL))\n\n\t\t\tif !assert.NoError(t, err) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\n\t\t\treturn\n\t\t} else if r.URL.Path == \"/keys\" {\n\t\t\tkeys := jwk.NewSet()\n\t\t\tkey := jwk.NewRSAPublicKey()\n\t\t\terr := key.FromRaw(&publicKey)\n\t\t\tif err != nil {\n\t\t\t\thttp.Error(w, err.Error(), 400)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tkeys.Add(key)\n\t\t\traw, err := json.Marshal(keys)\n\t\t\tif err != nil {\n\t\t\t\thttp.Error(w, err.Error(), 400)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t\t_, err = io.WriteString(w, string(raw))\n\n\t\t\tif !assert.NoError(t, err) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\n\t\t\treturn\n\t\t}\n\n\t\thttp.NotFound(w, r)\n\t}", "is_vulnerable": 0}
{"code": "func (sc *scenarioContext) fakeReqNoAssertionsWithCookie(method, url string, cookie http.Cookie) *scenarioContext {\n\tsc.resp = httptest.NewRecorder()\n\thttp.SetCookie(sc.resp, &cookie)\n\n\treq, _ := http.NewRequest(method, url, nil)\n\treq.Header = http.Header{\"Cookie\": sc.resp.Header()[\"Set-Cookie\"]}\n\treq.Header.Add(\"Content-Type\", \"application/json\")\n\tsc.req = req\n\n\treturn sc\n}", "is_vulnerable": 0}
{"code": "func (m *Stats) GetFetchedChunkBytes() uint64 {\n\tif m != nil {\n\t\treturn m.FetchedChunkBytes\n\t}\n\treturn 0\n}", "is_vulnerable": 0}
{"code": "func newMockResourceServer(t testing.TB) ResourceServer {\n\tctx := context.Background()\n\tdummy := \"\"\n\tserverURL := &dummy\n\thf := func(w http.ResponseWriter, r *http.Request) {\n\t\tif r.URL.Path == \"/.well-known/oauth-authorization-server\" {\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t\t_, err := io.WriteString(w, strings.ReplaceAll(`{\n\t\t\t\t\"issuer\": \"https://dev-14186422.okta.com\",\n\t\t\t\t\"authorization_endpoint\": \"https://example.com/auth\",\n\t\t\t\t\"token_endpoint\": \"https://example.com/token\",\n\t\t\t\t\"jwks_uri\": \"URL/keys\",\n\t\t\t\t\"id_token_signing_alg_values_supported\": [\"RS256\"]\n\t\t\t}`, \"URL\", *serverURL))\n\n\t\t\tif !assert.NoError(t, err) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\n\t\t\treturn\n\t\t} else if r.URL.Path == \"/keys\" {\n\t\t\tkeys := jwk.NewSet()\n\t\t\traw, err := json.Marshal(keys)\n\t\t\tif err != nil {\n\t\t\t\thttp.Error(w, err.Error(), 400)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t\t_, err = io.WriteString(w, string(raw))\n\n\t\t\tif !assert.NoError(t, err) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\t\t}\n\n\t\thttp.NotFound(w, r)\n\t}\n\n\ts := httptest.NewServer(http.HandlerFunc(hf))\n\tdefer s.Close()\n\n\t*serverURL = s.URL\n\n\thttp.DefaultClient = s.Client()\n\n\tr, err := NewOAuth2ResourceServer(ctx, authConfig.ExternalAuthorizationServer{\n\t\tBaseURL: stdlibConfig.URL{URL: *config.MustParseURL(s.URL)},\n\t}, stdlibConfig.URL{})\n\tif !assert.NoError(t, err) {\n\t\tt.FailNow()\n\t}\n\n\treturn r\n}", "is_vulnerable": 1}
{"code": "func exclusion(ctx context.Context, concurrencyLimit uint32, handlers ...CheckHandlerFunc) (*ResolveCheckResponse, error) {\n\tif len(handlers) != 2 {\n\t\tpanic(fmt.Sprintf(\"expected two rewrite operands for exclusion operator, but got '%d'\", len(handlers)))\n\t}\n\n\tspan := trace.SpanFromContext(ctx)\n\n\tlimiter := make(chan struct{}, concurrencyLimit)\n\n\tctx, cancel := context.WithCancel(ctx)\n\tbaseChan := make(chan checkOutcome, 1)\n\tsubChan := make(chan checkOutcome, 1)\n\n\tvar wg sync.WaitGroup\n\n\tdefer func() {\n\t\tcancel()\n\t\twg.Wait()\n\t\tclose(baseChan)\n\t\tclose(subChan)\n\t}()\n\n\tbaseHandler := handlers[0]\n\tsubHandler := handlers[1]\n\n\tlimiter <- struct{}{}\n\twg.Add(1)\n\tgo func() {\n\t\tresp, err := baseHandler(ctx)\n\t\tbaseChan <- checkOutcome{resp, err}\n\t\t<-limiter\n\t\twg.Done()\n\t}()\n\n\tlimiter <- struct{}{}\n\twg.Add(1)\n\tgo func() {\n\t\tresp, err := subHandler(ctx)\n\t\tsubChan <- checkOutcome{resp, err}\n\t\t<-limiter\n\t\twg.Done()\n\t}()\n\n\tresponse := &ResolveCheckResponse{\n\t\tAllowed: false,\n\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\tDatastoreQueryCount: 0,\n\t\t},\n\t}\n\n\tvar baseErr error\n\tvar subErr error\n\n\tvar dbReads uint32\n\tfor i := 0; i < len(handlers); i++ {\n\t\tselect {\n\t\tcase baseResult := <-baseChan:\n\t\t\tif baseResult.err != nil {\n\t\t\t\tspan.RecordError(baseResult.err)\n\n\t\t\t\tif errors.Is(baseResult.err, ErrCycleDetected) {\n\t\t\t\t\treturn &ResolveCheckResponse{\n\t\t\t\t\t\tAllowed: false,\n\t\t\t\t\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\t\t\t\t\tDatastoreQueryCount: dbReads,\n\t\t\t\t\t\t},\n\t\t\t\t\t}, nil\n\t\t\t\t}\n\n\t\t\t\tbaseErr = baseResult.err\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdbReads += baseResult.resp.GetResolutionMetadata().DatastoreQueryCount\n\n\t\t\tif !baseResult.resp.GetAllowed() {\n\t\t\t\tresponse.GetResolutionMetadata().DatastoreQueryCount = dbReads\n\t\t\t\treturn response, nil\n\t\t\t}\n\n\t\tcase subResult := <-subChan:\n\t\t\tif subResult.err != nil {\n\t\t\t\tspan.RecordError(subResult.err)\n\n\t\t\t\tif !errors.Is(subResult.err, ErrCycleDetected) {\n\t\t\t\t\tsubErr = subResult.err\n\t\t\t\t}\n\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdbReads += subResult.resp.GetResolutionMetadata().DatastoreQueryCount\n\n\t\t\tif subResult.resp.GetAllowed() {\n\t\t\t\tresponse.GetResolutionMetadata().DatastoreQueryCount = dbReads\n\t\t\t\treturn response, nil\n\t\t\t}\n\t\tcase <-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\t}\n\t}\n\n\tif baseErr != nil && subErr != nil {\n\t\treturn &ResolveCheckResponse{\n\t\t\tAllowed: false,\n\t\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\t\tDatastoreQueryCount: 0,\n\t\t\t},\n\t\t}, errors.Join(baseErr, subErr)\n\t}\n\n\treturn &ResolveCheckResponse{\n\t\tAllowed: true,\n\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\tDatastoreQueryCount: dbReads,\n\t\t},\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func unmarshalEntryImpl(e string) (types.EntryImpl, string, string, error) {\n\tb, err := base64.StdEncoding.DecodeString(e)\n\tif err != nil {\n\t\treturn nil, \"\", \"\", err\n\t}\n\n\tpe, err := models.UnmarshalProposedEntry(bytes.NewReader(b), runtime.JSONConsumer())\n\tif err != nil {\n\t\treturn nil, \"\", \"\", err\n\t}\n\n\tentry, err := types.NewEntry(pe)\n\tif err != nil {\n\t\treturn nil, \"\", \"\", err\n\t}\n\treturn entry, pe.Kind(), entry.APIVersion(), nil\n}", "is_vulnerable": 0}
{"code": "func (m *NidRepStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field3 = append(m.Field3, NidOptNative{})\n\t\t\tif err := m.Field3[len(m.Field3)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field4 = append(m.Field4, NinOptNative{})\n\t\t\tif err := m.Field4[len(m.Field4)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field8 = append(m.Field8, NidOptNative{})\n\t\t\tif err := m.Field8[len(m.Field8)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field14 = append(m.Field14, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.Field15[len(m.Field15)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (sc *scenarioContext) fakeReqNoAssertions(method, url string) *scenarioContext {\n\tsc.resp = httptest.NewRecorder()\n\treq, _ := http.NewRequest(method, url, nil)\n\treq.Header.Add(\"Content-Type\", \"application/json\")\n\tsc.req = req\n\n\treturn sc\n}", "is_vulnerable": 0}
{"code": "func newApiServerRoleBinding(namespace string) *rbacv1.RoleBinding {\n\treturn &rbacv1.RoleBinding{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"RoleBinding\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: namespace,\n\t\t\tName:      ApiServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: VersionName,\n\t\t\tKind:     \"Role\",\n\t\t\tName:     ApiServiceAccountName,\n\t\t},\n\t\tSubjects: []rbacv1.Subject{\n\t\t\t{\n\t\t\t\tKind:      \"ServiceAccount\",\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      ApiServiceAccountName,\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestReverseExpandRespectsContextCancellation(t *testing.T) {\n\tdefer goleak.VerifyNone(t)\n\n\tstore := ulid.Make().String()\n\n\tmodel := testutils.MustTransformDSLToProtoWithID(`model\n  schema 1.1\ntype user\ntype document\n  relations\n\tdefine viewer: [user]`)\n\n\ttypeSystem := typesystem.New(model)\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tvar tuples []*openfgav1.Tuple\n\tfor i := 0; i < 100; i++ {\n\t\tobj := fmt.Sprintf(\"document:%s\", strconv.Itoa(i))\n\t\ttuples = append(tuples, &openfgav1.Tuple{Key: tuple.NewTupleKey(obj, \"viewer\", \"user:maria\")})\n\t}\n\n\tmockDatastore := mocks.NewMockOpenFGADatastore(mockController)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, gomock.Any()).\n\t\tTimes(1).\n\t\tDoAndReturn(func(_ context.Context, _ string, _ storage.ReadStartingWithUserFilter) (storage.TupleIterator, error) {\n\t\t\t// simulate many goroutines trying to write to the results channel\n\t\t\titerator := storage.NewStaticTupleIterator(tuples)\n\t\t\tt.Logf(\"returning tuple iterator\")\n\t\t\treturn iterator, nil\n\t\t})\n\tctx, cancelFunc := context.WithCancel(context.Background())\n\n\tresultChan := make(chan *ReverseExpandResult)\n\terrChan := make(chan error, 1)\n\n\t// process query in one goroutine, but it will be cancelled almost right away\n\tgo func() {\n\t\treverseExpandQuery := NewReverseExpandQuery(mockDatastore, typeSystem)\n\t\tt.Logf(\"before execute reverse expand\")\n\t\terr := reverseExpandQuery.Execute(ctx, &ReverseExpandRequest{\n\t\t\tStoreID:    store,\n\t\t\tObjectType: \"document\",\n\t\t\tRelation:   \"viewer\",\n\t\t\tUser: &UserRefObject{\n\t\t\t\tObject: &openfgav1.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"maria\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tContextualTuples: []*openfgav1.TupleKey{},\n\t\t}, resultChan, NewResolutionMetadata())\n\t\tt.Logf(\"after execute reverse expand\")\n\n\t\tif err != nil {\n\t\t\terrChan <- err\n\t\t}\n\t}()\n\tgo func() {\n\t\t// simulate max_results=1\n\t\tt.Logf(\"before receive one result\")\n\t\tres := <-resultChan\n\t\tt.Logf(\"after receive one result\")\n\t\tcancelFunc()\n\t\tt.Logf(\"after send cancellation\")\n\t\trequire.NotNil(t, res.Object)\n\t}()\n\n\tselect {\n\tcase err := <-errChan:\n\t\trequire.Error(t, err)\n\tcase <-time.After(30 * time.Millisecond):\n\t\trequire.FailNow(t, \"unexpected timeout on channel receive, expected receive on error channel\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewMockHandler(reactor *reactorDef, applicationNamespaces []string, objects ...runtime.Object) *ArgoCDWebhookHandler {\n\tappClientset := appclientset.NewSimpleClientset(objects...)\n\tif reactor != nil {\n\t\tdefaultReactor := appClientset.ReactionChain[0]\n\t\tappClientset.ReactionChain = nil\n\t\tappClientset.AddReactor(\"list\", \"*\", func(action kubetesting.Action) (handled bool, ret runtime.Object, err error) {\n\t\t\treturn defaultReactor.React(action)\n\t\t})\n\t\tappClientset.AddReactor(reactor.verb, reactor.resource, reactor.reaction)\n\t}\n\tcacheClient := cacheutil.NewCache(cacheutil.NewInMemoryCache(1 * time.Hour))\n\n\treturn NewHandler(\"argocd\", applicationNamespaces, appClientset, &settings.ArgoCDSettings{}, &fakeSettingsSrc{}, cache.NewCache(\n\t\tcacheClient,\n\t\t1*time.Minute,\n\t\t1*time.Minute,\n\t), servercache.NewCache(appstate.NewCache(cacheClient, time.Minute), time.Minute, time.Minute, time.Minute), &mocks.ArgoDB{})\n}", "is_vulnerable": 1}
{"code": "func TestRenderComponent(t *testing.T) {\n\tr := require.New(t)\n\tp := &provider{\n\t\trender: func(comp common.ApplicationComponent, patcher *value.Value, clusterName string, overrideNamespace string, _ string) (*unstructured.Unstructured, []*unstructured.Unstructured, error) {\n\t\t\treturn &unstructured.Unstructured{\n\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\"apiVersion\": \"apps/v1\",\n\t\t\t\t\t\t\"kind\":       \"Deployment\",\n\t\t\t\t\t},\n\t\t\t\t}, []*unstructured.Unstructured{\n\t\t\t\t\t{\n\t\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\t\"apiVersion\": \"core.oam.dev/v1alpha2\",\n\t\t\t\t\t\t\t\"kind\":       \"ManualScalerTrait\",\n\t\t\t\t\t\t\t\"metadata\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\"labels\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\t\"trait.oam.dev/resource\": \"scaler\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"spec\": map[string]interface{}{\"replicaCount\": int64(10)},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, nil\n\t\t},\n\t}\n\tv, err := value.NewValue(`value: {}`, nil, \"\")\n\tr.NoError(err)\n\terr = p.RenderComponent(nil, v, nil)\n\tr.NoError(err)\n\ts, err := v.String()\n\tr.NoError(err)\n\tr.Equal(s, `value: {}\noutput: {\n\tapiVersion: \"apps/v1\"\n\tkind:       \"Deployment\"\n}\noutputs: {\n\tscaler: {\n\t\tapiVersion: \"core.oam.dev/v1alpha2\"\n\t\tkind:       \"ManualScalerTrait\"\n\t\tmetadata: {\n\t\t\tlabels: {\n\t\t\t\t\"trait.oam.dev/resource\": \"scaler\"\n\t\t\t}\n\t\t}\n\t\tspec: {\n\t\t\treplicaCount: 10\n\t\t}\n\t}\n}\n`)\n}", "is_vulnerable": 1}
{"code": "func (p *parser) inBodyEndTagFormatting(tagAtom a.Atom) {\n\t// This is the \"adoption agency\" algorithm, described at\n\t// https://html.spec.whatwg.org/multipage/syntax.html#adoptionAgency\n\n\t// TODO: this is a fairly literal line-by-line translation of that algorithm.\n\t// Once the code successfully parses the comprehensive test suite, we should\n\t// refactor this code to be more idiomatic.\n\n\t// Steps 1-4. The outer loop.\n\tfor i := 0; i < 8; i++ {\n\t\t// Step 5. Find the formatting element.\n\t\tvar formattingElement *Node\n\t\tfor j := len(p.afe) - 1; j >= 0; j-- {\n\t\t\tif p.afe[j].Type == scopeMarkerNode {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif p.afe[j].DataAtom == tagAtom {\n\t\t\t\tformattingElement = p.afe[j]\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif formattingElement == nil {\n\t\t\tp.inBodyEndTagOther(tagAtom)\n\t\t\treturn\n\t\t}\n\t\tfeIndex := p.oe.index(formattingElement)\n\t\tif feIndex == -1 {\n\t\t\tp.afe.remove(formattingElement)\n\t\t\treturn\n\t\t}\n\t\tif !p.elementInScope(defaultScope, tagAtom) {\n\t\t\t// Ignore the tag.\n\t\t\treturn\n\t\t}\n\n\t\t// Steps 9-10. Find the furthest block.\n\t\tvar furthestBlock *Node\n\t\tfor _, e := range p.oe[feIndex:] {\n\t\t\tif isSpecialElement(e) {\n\t\t\t\tfurthestBlock = e\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif furthestBlock == nil {\n\t\t\te := p.oe.pop()\n\t\t\tfor e != formattingElement {\n\t\t\t\te = p.oe.pop()\n\t\t\t}\n\t\t\tp.afe.remove(e)\n\t\t\treturn\n\t\t}\n\n\t\t// Steps 11-12. Find the common ancestor and bookmark node.\n\t\tcommonAncestor := p.oe[feIndex-1]\n\t\tbookmark := p.afe.index(formattingElement)\n\n\t\t// Step 13. The inner loop. Find the lastNode to reparent.\n\t\tlastNode := furthestBlock\n\t\tnode := furthestBlock\n\t\tx := p.oe.index(node)\n\t\t// Steps 13.1-13.2\n\t\tfor j := 0; j < 3; j++ {\n\t\t\t// Step 13.3.\n\t\t\tx--\n\t\t\tnode = p.oe[x]\n\t\t\t// Step 13.4 - 13.5.\n\t\t\tif p.afe.index(node) == -1 {\n\t\t\t\tp.oe.remove(node)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Step 13.6.\n\t\t\tif node == formattingElement {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// Step 13.7.\n\t\t\tclone := node.clone()\n\t\t\tp.afe[p.afe.index(node)] = clone\n\t\t\tp.oe[p.oe.index(node)] = clone\n\t\t\tnode = clone\n\t\t\t// Step 13.8.\n\t\t\tif lastNode == furthestBlock {\n\t\t\t\tbookmark = p.afe.index(node) + 1\n\t\t\t}\n\t\t\t// Step 13.9.\n\t\t\tif lastNode.Parent != nil {\n\t\t\t\tlastNode.Parent.RemoveChild(lastNode)\n\t\t\t}\n\t\t\tnode.AppendChild(lastNode)\n\t\t\t// Step 13.10.\n\t\t\tlastNode = node\n\t\t}\n\n\t\t// Step 14. Reparent lastNode to the common ancestor,\n\t\t// or for misnested table nodes, to the foster parent.\n\t\tif lastNode.Parent != nil {\n\t\t\tlastNode.Parent.RemoveChild(lastNode)\n\t\t}\n\t\tswitch commonAncestor.DataAtom {\n\t\tcase a.Table, a.Tbody, a.Tfoot, a.Thead, a.Tr:\n\t\t\tp.fosterParent(lastNode)\n\t\tcase a.Template:\n\t\t\t// TODO: remove namespace checking\n\t\t\tif commonAncestor.Namespace == \"html\" {\n\t\t\t\tcommonAncestor = commonAncestor.LastChild\n\t\t\t}\n\t\t\tfallthrough\n\t\tdefault:\n\t\t\tcommonAncestor.AppendChild(lastNode)\n\t\t}\n\n\t\t// Steps 15-17. Reparent nodes from the furthest block's children\n\t\t// to a clone of the formatting element.\n\t\tclone := formattingElement.clone()\n\t\treparentChildren(clone, furthestBlock)\n\t\tfurthestBlock.AppendChild(clone)\n\n\t\t// Step 18. Fix up the list of active formatting elements.\n\t\tif oldLoc := p.afe.index(formattingElement); oldLoc != -1 && oldLoc < bookmark {\n\t\t\t// Move the bookmark with the rest of the list.\n\t\t\tbookmark--\n\t\t}\n\t\tp.afe.remove(formattingElement)\n\t\tp.afe.insert(bookmark, clone)\n\n\t\t// Step 19. Fix up the stack of open elements.\n\t\tp.oe.remove(formattingElement)\n\t\tp.oe.insert(p.oe.index(furthestBlock)+1, clone)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (de *dirent) reset() {\n\tde.name = \"\"\n\tde.path = \"\"\n\tde.modeType = 0\n}", "is_vulnerable": 0}
{"code": "\t\tfile, err := func() (WritableFile, error) {\n\t\t\tcontentRange := req.Header.Get(\"Content-Range\")\n\t\t\tif contentRange != \"\" && !strings.HasPrefix(contentRange, \"bytes 0-\") {\n\t\t\t\treturn fsys.OpenAppendable(safePath)\n\t\t\t}\n\t\t\treturn fsys.OpenWritable(safePath)\n\t\t}()", "is_vulnerable": 0}
{"code": "\t\toptions = NewStackTrieOptions().WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\trawdb.WriteTrieNode(spongeB, common.Hash{}, path, hash, blob, dbB.Scheme())\n\t\t})", "is_vulnerable": 1}
{"code": "func parseStreamConfig(ctx context.Context) StreamConfig {\n\tstreamConfig := defaultStreamConfig\n\t// get extend config from ctx\n\tpgc := mosnctx.Get(ctx, types.ContextKeyProxyGeneralConfig)\n\tif cfg, ok := pgc.(StreamConfig); ok {\n\t\tstreamConfig = cfg\n\t}\n\treturn streamConfig\n}", "is_vulnerable": 0}
{"code": "func TestCheckForUNCPath(t *testing.T) {\n\tcases := []struct {\n\t\tinput   string\n\t\twantErr bool\n\t\terr     error\n\t}{\n\t\t{\n\t\t\tinput:   \"c:/foo\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tinput:   \"file:///c:/a/b\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tinput:   `\\\\localhost\\c$`,\n\t\t\twantErr: true,\n\t\t\terr:     fmt.Errorf(\"UNC path read is not allowed: \\\\\\\\localhost\\\\c$\"),\n\t\t},\n\t\t{\n\t\t\tinput:   `\\\\\\\\localhost\\c$`,\n\t\t\twantErr: true,\n\t\t\terr:     fmt.Errorf(\"UNC path read is not allowed: \\\\\\\\\\\\\\\\localhost\\\\c$\"),\n\t\t},\n\t\t{\n\t\t\tinput:   `//localhost/foo`,\n\t\t\twantErr: true,\n\t\t\terr:     fmt.Errorf(\"UNC path read is not allowed: //localhost/foo\"),\n\t\t},\n\t\t{\n\t\t\tinput:   `file:///a/b/c`,\n\t\t\twantErr: false,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.input, func(t *testing.T) {\n\t\t\terr := checkForUNCPath(tc.input)\n\t\t\tif tc.wantErr {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Fatal(\"Expected error but got nil\")\n\t\t\t\t}\n\n\t\t\t\tif tc.err != nil && tc.err.Error() != err.Error() {\n\t\t\t\t\tt.Fatalf(\"Expected error message %v but got %v\", tc.err.Error(), err.Error())\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Unexpected error %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAgentPathAPI(t *testing.T) {\n\tassert := assert.New(t)\n\n\tk1 := &kataAgent{}\n\tk2 := &kataAgent{}\n\tid := \"foobar\"\n\n\t// getSharePath\n\tpath1 := k1.getSharePath(id)\n\tpath2 := k2.getSharePath(id)\n\tassert.Equal(path1, path2)\n}", "is_vulnerable": 1}
{"code": "func fetchArgs(remoteURL string, ref string) []string {\n\targs := []string{\"fetch\"}\n\n\tif supportsShallowClone(remoteURL) {\n\t\targs = append(args, \"--depth\", \"1\")\n\t}\n\n\treturn append(args, \"origin\", ref)\n}", "is_vulnerable": 1}
{"code": "func (m *LaunchPlanManager) ListLaunchPlanIds(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.LaunchPlanColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid pagination token %s\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().ListLaunchPlanIdentifiers(ctx, listLaunchPlansInput)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plan ids for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: transformers.FromLaunchPlanModelsToIdentifiers(output.LaunchPlans),\n\t\tToken:    token,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_OutgoingTLSConfigForChecks(t *testing.T) {\n\tc := Configurator{base: &Config{\n\t\tTLSMinVersion:           \"tls12\",\n\t\tEnableAgentTLSForChecks: false,\n\t}}\n\ttlsConf := c.OutgoingTLSConfigForCheck(true)\n\trequire.Equal(t, true, tlsConf.InsecureSkipVerify)\n\trequire.Equal(t, uint16(0), tlsConf.MinVersion)\n\n\tc.base.EnableAgentTLSForChecks = true\n\tc.base.ServerName = \"servername\"\n\ttlsConf = c.OutgoingTLSConfigForCheck(true)\n\trequire.Equal(t, true, tlsConf.InsecureSkipVerify)\n\trequire.Equal(t, TLSLookup[c.base.TLSMinVersion], tlsConf.MinVersion)\n\trequire.Equal(t, c.base.ServerName, tlsConf.ServerName)\n}", "is_vulnerable": 0}
{"code": "func (m *CustomNameNinRepNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNinRepNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNinRepNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.FieldA = append(m.FieldA, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.FieldA) == 0 {\n\t\t\t\t\tm.FieldA = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.FieldA = append(m.FieldA, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldA\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.FieldB = append(m.FieldB, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.FieldB) == 0 {\n\t\t\t\t\tm.FieldB = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.FieldB = append(m.FieldB, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldB\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.FieldC = append(m.FieldC, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldC) == 0 {\n\t\t\t\t\tm.FieldC = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.FieldC = append(m.FieldC, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldC\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.FieldD = append(m.FieldD, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldD) == 0 {\n\t\t\t\t\tm.FieldD = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.FieldD = append(m.FieldD, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldD\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.FieldE = append(m.FieldE, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldE) == 0 {\n\t\t\t\t\tm.FieldE = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.FieldE = append(m.FieldE, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldE\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.FieldF = append(m.FieldF, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldF) == 0 {\n\t\t\t\t\tm.FieldF = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.FieldF = append(m.FieldF, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldF\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.FieldG = append(m.FieldG, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldG) == 0 {\n\t\t\t\t\tm.FieldG = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.FieldG = append(m.FieldG, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldG\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.FieldH = append(m.FieldH, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.FieldH) == 0 {\n\t\t\t\t\tm.FieldH = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.FieldH = append(m.FieldH, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldH\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.FieldI = append(m.FieldI, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.FieldI) == 0 {\n\t\t\t\t\tm.FieldI = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.FieldI = append(m.FieldI, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldI\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.FieldJ = append(m.FieldJ, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.FieldJ) == 0 {\n\t\t\t\t\tm.FieldJ = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.FieldJ = append(m.FieldJ, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldJ\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.FieldK = append(m.FieldK, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.FieldK) == 0 {\n\t\t\t\t\tm.FieldK = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.FieldK = append(m.FieldK, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldK\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.FieldL = append(m.FieldL, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.FieldL) == 0 {\n\t\t\t\t\tm.FieldL = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.FieldL = append(m.FieldL, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldL\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.FieldM = append(m.FieldM, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.FieldM) == 0 {\n\t\t\t\t\tm.FieldM = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.FieldM = append(m.FieldM, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldM\", wireType)\n\t\t\t}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldN\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldN = append(m.FieldN, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldO\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.FieldO = append(m.FieldO, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.FieldO[len(m.FieldO)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (j JuiceFileUtils) GetFileCount(juiceSubPath string) (fileCount int64, err error) {\n\tvar (\n\t\t//strs    = \"du -ah juiceSubPath |grep ^- |wc -l \"\n\t\tstrs    = fmt.Sprintf(\"ls -lR %s |grep ^- |wc -l \", juiceSubPath)\n\t\tcommand = []string{\"bash\", \"-c\", strs}\n\t\tstdout  string\n\t\tstderr  string\n\t)\n\n\tstdout, stderr, err = j.exec(command)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"execute command %v with expectedErr: %v stdout %s and stderr %s\", command, err, stdout, stderr)\n\t\treturn\n\t}\n\n\t// eg: Master.FilesCompleted  (Type: COUNTER, Value: 6,367,897)\n\tstr := strings.Split(stdout, \"\\n\")\n\n\tif len(str) != 1 {\n\t\terr = fmt.Errorf(\"failed to parse %s in Count method\", str)\n\t\treturn\n\t}\n\n\tdata := strings.Fields(str[0])\n\tif len(data) != 1 {\n\t\terr = fmt.Errorf(\"failed to parse %s in Count method\", data)\n\t\treturn\n\t}\n\n\tfileCount, err = strconv.ParseInt(data[0], 10, 64)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn fileCount, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Method) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowApi\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Method: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Method: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RequestTypeUrl\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.RequestTypeUrl = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RequestStreaming\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.RequestStreaming = bool(v != 0)\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field ResponseTypeUrl\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.ResponseTypeUrl = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field ResponseStreaming\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.ResponseStreaming = bool(v != 0)\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Options\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Options = append(m.Options, &Option{})\n\t\t\tif err := m.Options[len(m.Options)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Syntax\", wireType)\n\t\t\t}\n\t\t\tm.Syntax = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowApi\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Syntax |= Syntax(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipApi(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthApi\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\t_, err := NewAndValidate(test.model)\n\t\t\trequire.NoError(t, err)\n\t\t})", "is_vulnerable": 1}
{"code": "\t_, err = db.Exec(\"SELECT sql FROM sqlite_schema;\", nil, func(stmt *sql.Statement) bool {\n\t\tsql := stmt.ColumnText(0)\n\t\tsql = strings.Join(strings.Fields(sql), \" \") // remove whitespace\n\t\tsqls1 = append(sqls1, sql)\n\t\treturn true\n\t})", "is_vulnerable": 0}
{"code": "func TestPathRoleSet_RotateTokenRoleSet(t *testing.T) {\n\trsName := \"test-rotatetokenrs\"\n\troles := util.StringSet{\n\t\t\"roles/viewer\": struct{}{},\n\t}\n\n\t// Initial test set up - backend, initial config, test resources in project\n\ttd := setupTest(t, \"0s\", \"2h\")\n\tdefer cleanup(t, td, rsName, roles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create role set\n\texpectedBinds := ResourceBindings{projRes: roles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":      td.Project,\n\t\t\t\"secret_type\":  SecretTypeAccessToken,\n\t\t\t\"bindings\":     bindsRaw,\n\t\t\t\"token_scopes\": []string{\"https://www.googleapis.com/auth/cloud-platform\"},\n\t\t})\n\n\t// Verify initial role set.\n\trespData := testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\tinitSa := getServiceAccount(t, td.IamAdmin, respData)\n\tverifyProjectBinding(t, td, initSa.Email, roles)\n\n\t// Rotate account and verify is new account.\n\ttestRoleSetRotate(t, td, rsName)\n\tnewSa := getServiceAccount(t, td.IamAdmin, testRoleSetRead(t, td, rsName))\n\tif newSa.Name == initSa.Name {\n\t\tt.Fatalf(\"expected role set to have new service account after rotation (update)\")\n\t}\n\tverifyProjectBinding(t, td, newSa.Email, roles)\n\n\t// Verify old account/bindings deleted.\n\tverifyServiceAccountDeleted(t, td.IamAdmin, initSa.Name)\n\tverifyProjectBindingsRemoved(t, td, initSa.Email, roles)\n\n\t// Get RoleSet object for confirming key rotation:\n\toldK := verifyRoleSetTokenKey(t, td, rsName)\n\n\t// Rotate key only - should only change key, not service account\n\ttestRoleSetRotateKey(t, td, rsName)\n\tsaAfterRotate := getServiceAccount(t, td.IamAdmin, testRoleSetRead(t, td, rsName))\n\tif saAfterRotate.Name != newSa.Name {\n\t\tt.Fatalf(\"expected same service account (%s) after rotate key, instead got new account: %s\", newSa.Name, saAfterRotate.Name)\n\t}\n\n\t// Verify old key was deleted\n\tresult, err := td.IamAdmin.Projects.ServiceAccounts.Keys.Get(oldK.Name).Do()\n\tif err == nil && result != nil {\n\t\tt.Fatalf(\"old key was supposed to be deleted but get succeded\")\n\t} else if err != nil && !isGoogleAccountKeyNotFoundErr(err) {\n\t\tt.Fatalf(\"got an error while trying to confirm service account key was deleted: %v\", err)\n\t}\n\n\t// Verify new key != old key\n\tnewK := verifyRoleSetTokenKey(t, td, rsName)\n\tif newK.Name == oldK.Name {\n\t\tt.Fatalf(\"expected new key to have been created in rotate\")\n\t}\n\tif newK.PrivateKeyData == oldK.PrivateKeyData {\n\t\tt.Fatalf(\"expected new key data to have been created and saved in rotate\")\n\t}\n\n\t// 4. Delete role set\n\ttestRoleSetDelete(t, td, rsName, newSa.Name)\n\tverifyProjectBindingsRemoved(t, td, newSa.Email, roles)\n}", "is_vulnerable": 0}
{"code": "func (svc Service) GetTeamScheduledQueries(ctx context.Context, teamID uint, opts fleet.ListOptions) ([]*fleet.ScheduledQuery, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.Pack{\n\t\tType: ptr.String(fmt.Sprintf(\"team-%d\", teamID)),\n\t}, fleet.ActionRead); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgp, err := svc.ds.EnsureTeamPack(ctx, teamID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn svc.ds.ListScheduledQueriesInPackWithStats(ctx, gp.ID, opts)\n}", "is_vulnerable": 0}
{"code": "\t\tmodifyPayload      func(*testPayload)\n\t\tnoEnforceTimestamp bool\n\t\texpectedErr        bool\n\t}{\n\t\t{\n\t\t\tname:        \"valid signature is valid\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\texpectedErr: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid unbranded signature is valid\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\tunbrandedHeaders := http.Header{}\n\t\t\t\tunbrandedHeaders.Set(\"webhook-id\", tp.header.Get(\"svix-id\"))\n\t\t\t\tunbrandedHeaders.Set(\"webhook-timestamp\", tp.header.Get(\"svix-timestamp\"))\n\t\t\t\tunbrandedHeaders.Set(\"webhook-signature\", tp.header.Get(\"svix-signature\"))\n\t\t\t\ttp.header = unbrandedHeaders\n\t\t\t},\n\t\t\texpectedErr: false,\n\t\t},\n\t\t{\n\t\t\tname:        \"missing id returns error\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Del(\"svix-id\")\n\t\t\t},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"missing timestamp returns error\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Del(\"svix-timestamp\")\n\t\t\t},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"missing signature returns error\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Del(\"svix-signature\")\n\t\t\t},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid signature is invalid\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Set(\"svix-signature\", \"v1,Ceo5qEr07ixe2NLpvHk3FH9bwy/WavXrAFQ/9tdO6mc=\")\n\t\t\t},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"partial signature is invalid\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Set(\"svix-signature\", \"v1,\")\n\t\t\t},\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"old timestamp fails\",\n\t\t\ttestPayload: newTestPayload(time.Now().Add(tolerance * -1)),\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"new timestamp fails\",\n\t\t\ttestPayload: newTestPayload(time.Now().Add(tolerance + time.Second)),\n\t\t\texpectedErr: true,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid multi sig is valid\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\tsigs := []string{\n\t\t\t\t\t\"v1,Ceo5qEr07ixe2NLpvHk3FH9bwy/WavXrAFQ/9tdO6mc=\",\n\t\t\t\t\t\"v2,Ceo5qEr07ixe2NLpvHk3FH9bwy/WavXrAFQ/9tdO6mc=\",\n\t\t\t\t\ttp.header.Get(\"svix-signature\"), // valid signature\n\t\t\t\t\t\"v1,Ceo5qEr07ixe2NLpvHk3FH9bwy/WavXrAFQ/9tdO6mc=\",\n\t\t\t\t}\n\t\t\t\ttp.header.Set(\"svix-signature\", strings.Join(sigs, \" \"))\n\t\t\t},\n\t\t\texpectedErr: false,\n\t\t},\n\t\t{\n\t\t\tname:               \"old timestamp passes when ignoring tolerance\",\n\t\t\ttestPayload:        newTestPayload(time.Now().Add(tolerance * -1)),\n\t\t\tnoEnforceTimestamp: true,\n\t\t\texpectedErr:        false,\n\t\t},\n\t\t{\n\t\t\tname:               \"new timestamp passes when ignoring tolerance\",\n\t\t\ttestPayload:        newTestPayload(time.Now().Add(tolerance * 1)),\n\t\t\tnoEnforceTimestamp: true,\n\t\t\texpectedErr:        false,\n\t\t},\n\t\t{\n\t\t\tname:               \"valid timestamp passes when ignoring tolerance\",\n\t\t\ttestPayload:        newTestPayload(time.Now()),\n\t\t\tnoEnforceTimestamp: true,\n\t\t\texpectedErr:        false,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid timestamp fails when ignoring tolerance\",\n\t\t\ttestPayload: newTestPayload(time.Now()),\n\t\t\tmodifyPayload: func(tp *testPayload) {\n\t\t\t\ttp.header.Set(\"svix-timestamp\", fmt.Sprint(time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC).Unix()))\n\t\t\t},\n\t\t\tnoEnforceTimestamp: true,\n\t\t\texpectedErr:        true,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tif tc.modifyPayload != nil {\n\t\t\ttc.modifyPayload(tc.testPayload)\n\t\t}\n\n\t\twh, err := svix.NewWebhook(tc.testPayload.secret)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t\tcontinue\n\t\t}\n\t\tif tc.noEnforceTimestamp {\n\t\t\terr = wh.VerifyIgnoringTimestamp(tc.testPayload.payload, tc.testPayload.header)\n\t\t} else {\n\t\t\terr = wh.Verify(tc.testPayload.payload, tc.testPayload.header)\n\t\t}\n\t\tif err != nil && !tc.expectedErr {\n\t\t\tt.Errorf(\"%s: failed with err %s but shouldn't have\", tc.name, err.Error())\n\t\t} else if err == nil && tc.expectedErr {\n\t\t\tt.Errorf(\"%s: didn't error but should have\", tc.name)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockResourceOwnerPasswordCredentialsGrantStorage) DeleteRefreshTokenSession(arg0 context.Context, arg1 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"DeleteRefreshTokenSession\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func Satitize(data *imagedata.ImageData) (*imagedata.ImageData, error) {\n\tr := bytes.NewReader(data.Data)\n\tl := xml.NewLexer(parse.NewInput(r))\n\n\tbuf, cancel := imagedata.BorrowBuffer()\n\n\tignoreTag := 0\n\n\tfor {\n\t\ttt, tdata := l.Next()\n\n\t\tif ignoreTag > 0 {\n\t\t\tswitch tt {\n\t\t\tcase xml.ErrorToken:\n\t\t\t\tcancel()\n\t\t\t\treturn nil, l.Err()\n\t\t\tcase xml.EndTagToken, xml.StartTagCloseVoidToken:\n\t\t\t\tignoreTag--\n\t\t\tcase xml.StartTagToken:\n\t\t\t\tignoreTag++\n\t\t\t}\n\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch tt {\n\t\tcase xml.ErrorToken:\n\t\t\tif l.Err() != io.EOF {\n\t\t\t\tcancel()\n\t\t\t\treturn nil, l.Err()\n\t\t\t}\n\n\t\t\tnewData := imagedata.ImageData{\n\t\t\t\tData: buf.Bytes(),\n\t\t\t\tType: data.Type,\n\t\t\t}\n\t\t\tnewData.SetCancel(cancel)\n\n\t\t\treturn &newData, nil\n\t\tcase xml.StartTagToken:\n\t\t\tif strings.ToLower(string(l.Text())) == \"script\" {\n\t\t\t\tignoreTag++\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbuf.Write(tdata)\n\t\tcase xml.AttributeToken:\n\t\t\tif _, unsafe := unsafeAttrs[strings.ToLower(string(l.Text()))]; unsafe {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbuf.Write(tdata)\n\t\tdefault:\n\t\t\tbuf.Write(tdata)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *CommonController) GetRemoteIp() string {\n\t// \u8fd9\u91cc\u4e5f\u53ef\u4ee5\u901a\u8fc7X-Forwarded-For\u8bf7\u6c42\u5934\u7684\u7b2c\u4e00\u4e2a\u503c\u4f5c\u4e3a\u7528\u6237\u7684ip\n\t// \u4f46\u662f\u8981\u6ce8\u610f\u7684\u662f\u8fd9\u4e24\u4e2a\u8bf7\u6c42\u5934\u4ee3\u8868\u7684ip\u90fd\u6709\u53ef\u80fd\u662f\u4f2a\u9020\u7684\n\tip := c.Ctx.Request.Header.Get(\"X-Real-IP\")\n\tif ip == \"\"{\n\t\t// \u5f53\u8bf7\u6c42\u5934\u4e0d\u5b58\u5728\u5373\u4e0d\u5b58\u5728\u4ee3\u7406\u65f6\u76f4\u63a5\u83b7\u53d6ip\n\t\tip = strings.Split(c.Ctx.Request.RemoteAddr, \":\")[0]\n\t}\n\treturn ip\n}", "is_vulnerable": 1}
{"code": "func (u *userSet) Get(value string) (resolutionTracer, bool) {\n\tu.m.Lock()\n\tdefer u.m.Unlock()\n\n\tvar found bool\n\tvar rt resolutionTracer\n\tif rt, found = u.u[value]; !found {\n\t\tif rt, found = u.u[AllUsers]; !found {\n\t\t\treturn nil, false\n\t\t}\n\t}\n\treturn rt, found\n}", "is_vulnerable": 1}
{"code": "func (c *EncryptionClient) PutObject(input *s3.PutObjectInput) (*s3.PutObjectOutput, error) {\n\treq, out := c.PutObjectRequest(input)\n\treturn out, req.Send()\n}", "is_vulnerable": 1}
{"code": "func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (err error) {\n\tif len(images) == 0 {\n\t\treturn flag.ErrHelp\n\t}\n\n\tif !options.OneOf(c.KeyRef, c.Sk, c.CertRef) && !options.EnableExperimental() {\n\t\treturn &options.PubKeyParseError{}\n\t}\n\n\tociremoteOpts, err := c.ClientOpts(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"constructing client options: %w\", err)\n\t}\n\tco := &cosign.CheckOpts{\n\t\tRegistryClientOpts:           ociremoteOpts,\n\t\tCertEmail:                    c.CertEmail,\n\t\tCertOidcIssuer:               c.CertOidcIssuer,\n\t\tCertGithubWorkflowTrigger:    c.CertGithubWorkflowTrigger,\n\t\tCertGithubWorkflowSha:        c.CertGithubWorkflowSha,\n\t\tCertGithubWorkflowName:       c.CertGithubWorkflowName,\n\t\tCertGithubWorkflowRepository: c.CertGithubWorkflowRepository,\n\t\tCertGithubWorkflowRef:        c.CertGithubWorkflowRef,\n\t\tEnforceSCT:                   c.EnforceSCT,\n\t}\n\tif c.CheckClaims {\n\t\tco.ClaimVerifier = cosign.IntotoSubjectClaimVerifier\n\t}\n\tif options.EnableExperimental() {\n\t\tif c.RekorURL != \"\" {\n\t\t\trekorClient, err := rekor.NewClient(c.RekorURL)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating Rekor client: %w\", err)\n\t\t\t}\n\t\t\tco.RekorClient = rekorClient\n\t\t}\n\t\tco.RootCerts, err = fulcio.GetRoots()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"getting Fulcio roots: %w\", err)\n\t\t}\n\t\tco.IntermediateCerts, err = fulcio.GetIntermediates()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"getting Fulcio intermediates: %w\", err)\n\t\t}\n\t}\n\tkeyRef := c.KeyRef\n\n\t// Keys are optional!\n\tswitch {\n\tcase keyRef != \"\":\n\t\tco.SigVerifier, err = sigs.PublicKeyFromKeyRef(ctx, keyRef)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading public key: %w\", err)\n\t\t}\n\t\tpkcs11Key, ok := co.SigVerifier.(*pkcs11key.Key)\n\t\tif ok {\n\t\t\tdefer pkcs11Key.Close()\n\t\t}\n\tcase c.Sk:\n\t\tsk, err := pivkey.GetKeyWithSlot(c.Slot)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"opening piv token: %w\", err)\n\t\t}\n\t\tdefer sk.Close()\n\t\tco.SigVerifier, err = sk.Verifier()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"initializing piv token verifier: %w\", err)\n\t\t}\n\tcase c.CertRef != \"\":\n\t\tcert, err := loadCertFromFileOrURL(c.CertRef)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading certificate from reference: %w\", err)\n\t\t}\n\t\tif c.CertChain == \"\" {\n\t\t\terr = cosign.CheckCertificatePolicy(cert, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tco.SigVerifier, err = signature.LoadVerifier(cert.PublicKey, crypto.SHA256)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating certificate verifier: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\t// Verify certificate with chain\n\t\t\tchain, err := loadCertChainFromFileOrURL(c.CertChain)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tco.SigVerifier, err = cosign.ValidateAndUnpackCertWithChain(cert, chain, co)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating certificate verifier: %w\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// NB: There are only 2 kinds of verification right now:\n\t// 1. You gave us the public key explicitly to verify against so co.SigVerifier is non-nil or,\n\t// 2. We're going to find an x509 certificate on the signature and verify against Fulcio root trust\n\t// TODO(nsmith5): Refactor this verification logic to pass back _how_ verification\n\t// was performed so we don't need to use this fragile logic here.\n\tfulcioVerified := (co.SigVerifier == nil)\n\n\tfor _, imageRef := range images {\n\t\tvar verified []oci.Signature\n\t\tvar bundleVerified bool\n\n\t\tif c.LocalImage {\n\t\t\tverified, bundleVerified, err = cosign.VerifyLocalImageAttestations(ctx, imageRef, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tref, err := name.ParseReference(imageRef)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tverified, bundleVerified, err = cosign.VerifyImageAttestations(ctx, ref, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tvar cuePolicies, regoPolicies []string\n\n\t\tfor _, policy := range c.Policies {\n\t\t\tswitch filepath.Ext(policy) {\n\t\t\tcase \".rego\":\n\t\t\t\tregoPolicies = append(regoPolicies, policy)\n\t\t\tcase \".cue\":\n\t\t\t\tcuePolicies = append(cuePolicies, policy)\n\t\t\tdefault:\n\t\t\t\treturn errors.New(\"invalid policy format, expected .cue or .rego\")\n\t\t\t}\n\t\t}\n\n\t\tvar validationErrors []error\n\t\tfor _, vp := range verified {\n\t\t\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"converting to consumable policy validation: %w\", err)\n\t\t\t}\n\t\t\tif len(payload) == 0 {\n\t\t\t\t// This is not the predicate type we're looking for.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif len(cuePolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against CUE policies: %v\\n\", cuePolicies)\n\t\t\t\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\n\t\t\t\tif cueValidationErr != nil {\n\t\t\t\t\tvalidationErrors = append(validationErrors, cueValidationErr)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(regoPolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against Rego policies: %v\\n\", regoPolicies)\n\t\t\t\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\n\t\t\t\tif len(regoValidationErrs) > 0 {\n\t\t\t\t\tvalidationErrors = append(validationErrors, regoValidationErrs...)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif len(validationErrors) > 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"There are %d number of errors occurred during the validation:\\n\", len(validationErrors))\n\t\t\tfor _, v := range validationErrors {\n\t\t\t\t_, _ = fmt.Fprintf(os.Stderr, \"- %v\\n\", v)\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\n\t\t}\n\n\t\t// TODO: add CUE validation report to `PrintVerificationHeader`.\n\t\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\n\t\t// The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\n\t\tPrintVerification(imageRef, verified, \"text\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\t\tgo func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tfor i, request := range req.Reqs {\n\t\t\t\t\tif i != 0 && !task.waitOrStop() {\n\t\t\t\t\t\tsendResponse(req.ReqID, 0, nil, task.servingTime)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t// Look up the root hash belonging to the request\n\t\t\t\t\theader := h.blockchain.GetHeaderByHash(request.BHash)\n\t\t\t\t\tif header == nil {\n\t\t\t\t\t\tp.Log().Warn(\"Failed to retrieve associate header for code\", \"hash\", request.BHash)\n\t\t\t\t\t\tp.bumpInvalid()\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\t// Refuse to search stale state data in the database since looking for\n\t\t\t\t\t// a non-exist key is kind of expensive.\n\t\t\t\t\tlocal := h.blockchain.CurrentHeader().Number.Uint64()\n\t\t\t\t\tif !h.server.archiveMode && header.Number.Uint64()+core.TriesInMemory <= local {\n\t\t\t\t\t\tp.Log().Debug(\"Reject stale code request\", \"number\", header.Number.Uint64(), \"head\", local)\n\t\t\t\t\t\tp.bumpInvalid()\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\ttriedb := h.blockchain.StateCache().TrieDB()\n\n\t\t\t\t\taccount, err := h.getAccount(triedb, header.Root, common.BytesToHash(request.AccKey))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tp.Log().Warn(\"Failed to retrieve account for code\", \"block\", header.Number, \"hash\", header.Hash(), \"account\", common.BytesToHash(request.AccKey), \"err\", err)\n\t\t\t\t\t\tp.bumpInvalid()\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tcode, err := triedb.Node(common.BytesToHash(account.CodeHash))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tp.Log().Warn(\"Failed to retrieve account code\", \"block\", header.Number, \"hash\", header.Hash(), \"account\", common.BytesToHash(request.AccKey), \"codehash\", common.BytesToHash(account.CodeHash), \"err\", err)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\t// Accumulate the code and abort if enough data was retrieved\n\t\t\t\t\tdata = append(data, code)\n\t\t\t\t\tif bytes += len(code); bytes >= softResponseLimit {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treply := p.replyCode(req.ReqID, data)\n\t\t\t\tsendResponse(req.ReqID, uint64(reqCnt), reply, task.done())\n\t\t\t\tif metrics.EnabledExpensive {\n\t\t\t\t\tmiscOutCodePacketsMeter.Mark(1)\n\t\t\t\t\tmiscOutCodeTrafficMeter.Mark(int64(reply.size()))\n\t\t\t\t\tmiscServingTimeCodeTimer.Update(time.Duration(task.servingTime))\n\t\t\t\t}\n\t\t\t}()", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) RestartJobs(ctx context.Context, in *clientpb.RestartJobReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_RestartJobs_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func printSummary(color logger.UseColor, outputFiles []OutputFile, start time.Time) {\n\tif len(outputFiles) == 0 {\n\t\treturn\n\t}\n\n\tvar table logger.SummaryTable = make([]logger.SummaryTableEntry, len(outputFiles))\n\n\tif cwd, err := os.Getwd(); err == nil {\n\t\tif realFS, err := fs.RealFS(fs.RealFSOptions{AbsWorkingDir: cwd}); err == nil {\n\t\t\tfor i, file := range outputFiles {\n\t\t\t\tpath, ok := realFS.Rel(realFS.Cwd(), file.Path)\n\t\t\t\tif !ok {\n\t\t\t\t\tpath = file.Path\n\t\t\t\t}\n\t\t\t\tbase := realFS.Base(path)\n\t\t\t\tn := len(file.Contents)\n\t\t\t\ttable[i] = logger.SummaryTableEntry{\n\t\t\t\t\tDir:         path[:len(path)-len(base)],\n\t\t\t\t\tBase:        base,\n\t\t\t\t\tSize:        prettyPrintByteCount(n),\n\t\t\t\t\tBytes:       n,\n\t\t\t\t\tIsSourceMap: strings.HasSuffix(base, \".map\"),\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Don't print the time taken by the build if we're running under Yarn 1\n\t// since Yarn 1 always prints its own copy of the time taken by each command\n\tif userAgent, ok := os.LookupEnv(\"npm_config_user_agent\"); ok {\n\t\tif strings.Contains(userAgent, \"yarn/1.\") {\n\t\t\tlogger.PrintSummary(color, table, nil)\n\t\t\treturn\n\t\t}\n\t}\n\n\tlogger.PrintSummary(color, table, &start)\n}", "is_vulnerable": 0}
{"code": "func findKeyStart(data []byte, key string) (int, error) {\n\ti := 0\n\tln := len(data)\n\tif ln > 0 && (data[0] == '{' || data[0] == '[') {\n\t\ti = 1\n\t}\n\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\n\tif ku, err := Unescape(StringToBytes(key), stackbuf[:]); err == nil {\n\t\tkey = bytesToString(&ku)\n\t}\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"':\n\t\t\ti++\n\t\t\tkeyBegin := i\n\n\t\t\tstrEnd, keyEscaped := stringEnd(data[i:])\n\t\t\tif strEnd == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ti += strEnd\n\t\t\tkeyEnd := i - 1\n\n\t\t\tvalueOffset := nextToken(data[i:])\n\t\t\tif valueOffset == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\ti += valueOffset\n\n\t\t\t// if string is a key, and key level match\n\t\t\tk := data[keyBegin:keyEnd]\n\t\t\t// for unescape: if there are no escape sequences, this is cheap; if there are, it is a\n\t\t\t// bit more expensive, but causes no allocations unless len(key) > unescapeStackBufSize\n\t\t\tif keyEscaped {\n\t\t\t\tif ku, err := Unescape(k, stackbuf[:]); err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t} else {\n\t\t\t\t\tk = ku\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif data[i] == ':' && len(key) == len(k) && bytesToString(&k) == key {\n\t\t\t\treturn keyBegin - 1, nil\n\t\t\t}\n\n\t\tcase '[':\n\t\t\ti = blockEnd(data[i:], data[i], ']') + i\n\t\tcase '{':\n\t\t\ti = blockEnd(data[i:], data[i], '}') + i\n\t\t}\n\t\ti++\n\t}\n\n\treturn -1, KeyPathNotFoundError\n}", "is_vulnerable": 1}
{"code": "func (m *MockCoreStorage) DeleteRefreshTokenSession(arg0 context.Context, arg1 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"DeleteRefreshTokenSession\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) transformFuse(runtime *datav1alpha1.JuiceFSRuntime, dataset *datav1alpha1.Dataset, value *JuiceFS) (err error) {\n\tif len(dataset.Spec.Mounts) <= 0 {\n\t\treturn errors.New(\"do not assign mount point\")\n\t}\n\tmount := dataset.Spec.Mounts[0]\n\n\tvalue.Configs.Name = mount.Name\n\n\t// transform image\n\timage := runtime.Spec.Fuse.Image\n\ttag := runtime.Spec.Fuse.ImageTag\n\timagePullPolicy := runtime.Spec.Fuse.ImagePullPolicy\n\tvalue.Fuse.Image, value.Fuse.ImageTag, value.Fuse.ImagePullPolicy, err = j.parseJuiceFSImage(value.Edition, image, tag, imagePullPolicy)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// transform envs\n\tvalue.Fuse.Envs = runtime.Spec.Fuse.Env\n\n\t// transform options\n\tvar tiredStoreLevel *datav1alpha1.Level\n\tif len(runtime.Spec.TieredStore.Levels) != 0 {\n\t\ttiredStoreLevel = &runtime.Spec.TieredStore.Levels[0]\n\t}\n\toptionsFromDataset, err := j.genValue(mount, tiredStoreLevel, value, dataset.Spec.SharedOptions, dataset.Spec.SharedEncryptOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform format cmd\n\tj.genFormatCmd(value, runtime.Spec.Configs, optionsFromDataset)\n\n\t// transform quota cmd\n\terr = j.genQuotaCmd(value, mount)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform mount cmd & stat cmd\n\toptions, err := j.genMountOptions(mount, tiredStoreLevel)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Keep mount options in dataset still work, but it can be overwrited by fuse speicifed option\n\toptions = utils.UnionMapsWithOverride(optionsFromDataset, options)\n\tfor k, v := range runtime.Spec.Fuse.Options {\n\t\toptions[k] = v\n\t}\n\terr = j.genFuseMount(value, options)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform nodeSelector\n\tj.transformFuseNodeSelector(runtime, value)\n\tvalue.Fuse.Enabled = true\n\n\t// transform resource\n\terr = j.transformResourcesForFuse(runtime, value)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// transform volumes for fuse\n\terr = j.transformFuseVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform volumes for fuse\")\n\t\treturn err\n\t}\n\t// transform cache volumes for fuse\n\terr = j.transformFuseCacheVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform cache volumes for fuse\")\n\t\treturn err\n\t}\n\n\t// set critical fuse pod to avoid eviction\n\tvalue.Fuse.CriticalPod = common.CriticalFusePodEnabled()\n\n\t// parse fuse container network mode\n\tvalue.Fuse.HostNetwork = datav1alpha1.IsHostNetwork(runtime.Spec.Fuse.NetworkMode)\n\treturn\n}", "is_vulnerable": 1}
{"code": "func unpackTarFiles(reader *tar.Reader) (err error) {\n\tvar header *tar.Header\n\tvar count int = 0\n\tvar reSlash = regexp.MustCompile(`/.*`)\n\n\tinnerDir := \"\"\n\tfor {\n\t\tif header, err = reader.Next(); err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tcondPrint(\"Files \", false, CHATTY)\n\t\t\t\tcondPrint(strconv.Itoa(count), true, 1)\n\t\t\t\treturn nil // OK\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\t// cond_print(fmt.Sprintf(\"%#v\\n\", header), true, CHATTY)\n\t\t/*\n\t\t\ttar.Header{\n\t\t\t\tTypeflag:0x30,\n\t\t\t\tName:\"mysql-8.0.11-macos10.13-x86_64/docs/INFO_SRC\",\n\t\t\t\tLinkname:\"\",\n\t\t\t\tSize:185,\n\t\t\t\tMode:420,\n\t\t\t\tUid:7161,\n\t\t\t\tGid:10,\n\t\t\t\tUname:\"pb2user\",\n\t\t\t\tGname:\"owner\",\n\t\t\t\tModTime:time.Time{wall:0x0, ext:63658769207, loc:(*time.Location)(0x13730e0)},\n\t\t\t\tAccessTime:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)},\n\t\t\t\tChangeTime:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)},\n\t\t\t\tDevmajor:0, Devminor:0,\n\t\t\t\tXattrs:map[string]string(nil),\n\t\t\t\tPAXRecords:map[string]string(nil),\n\t\t\t\tFormat:0}\n\t\t\ttar.Header{\n\t\t\t\tTypeflag:0x32,\n\t\t\t\tName:\"mysql-8.0.11-macos10.13-x86_64/lib/libssl.dylib\",\n\t\t\t\tLinkname:\"libssl.1.0.0.dylib\",\n\t\t\t\tSize:0,\n\t\t\t\tMode:493,\n\t\t\t\tUid:7161,\n\t\t\t\tGid:10,\n\t\t\t\tUname:\"pb2user\",\n\t\t\t\tGname:\"owner\",\n\t\t\t\tModTime:time.Time{wall:0x0, ext:63658772525, loc:(*time.Location)(0x13730e0)},\n\t\t\t\tAccessTime:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)},\n\t\t\t\tChangeTime:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)},\n\t\t\t\tDevmajor:0,\n\t\t\t\tDevminor:0,\n\t\t\t\tXattrs:map[string]string(nil),\n\t\t\t\tPAXRecords:map[string]string(nil),\n\t\t\t\tFormat:0}\n\t\t*/\n\t\tfilemode := os.FileMode(header.Mode)\n\t\tfilename := sanitizedName(header.Name)\n\t\tfileDir := path.Dir(filename)\n\t\tupperDir := reSlash.ReplaceAllString(fileDir, \"\")\n\t\tif innerDir != \"\" {\n\t\t\tif upperDir != innerDir {\n\t\t\t\treturn fmt.Errorf(\"found more than one directory inside the tarball\\n\"+\n\t\t\t\t\t\"<%s> and <%s>\", upperDir, innerDir)\n\t\t\t}\n\t\t} else {\n\t\t\tinnerDir = upperDir\n\t\t}\n\n\t\tif _, err = os.Stat(fileDir); os.IsNotExist(err) {\n\t\t\tif err = os.MkdirAll(fileDir, globals.PublicDirectoryAttr); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcondPrint(\" + \"+fileDir+\" \", true, CHATTY)\n\t\t}\n\t\tif header.Typeflag == 0 {\n\t\t\theader.Typeflag = tar.TypeReg\n\t\t}\n\t\tswitch header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif err = os.MkdirAll(filename, globals.PublicDirectoryAttr); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase tar.TypeReg:\n\t\t\tif err = unpackTarFile(filename, reader); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\terr = os.Chmod(filename, filemode)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcount++\n\t\t\tcondPrint(filename, true, CHATTY)\n\t\t\tif count%10 == 0 {\n\t\t\t\tmark := \".\"\n\t\t\t\tif count%100 == 0 {\n\t\t\t\t\tmark = strconv.Itoa(count)\n\t\t\t\t}\n\t\t\t\tif Verbose < CHATTY {\n\t\t\t\t\tcondPrint(mark, false, 1)\n\t\t\t\t}\n\t\t\t}\n\t\tcase tar.TypeSymlink:\n\t\t\tif header.Linkname != \"\" {\n\t\t\t\tcondPrint(fmt.Sprintf(\"%s -> %s\", filename, header.Linkname), true, CHATTY)\n\t\t\t\terr = os.Symlink(header.Linkname, filename)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"%#v\\n#ERROR: %s\", header, err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"file %s is a symlink, but no link information was provided\", filename)\n\t\t\t}\n\t\t}\n\t}\n\t// return nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeResponder) GetCode() string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetCode\")\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (mgr *SessionManager) updateFailureCount(username string, failed bool) {\n\n\tfailures := mgr.GetLoginFailures()\n\n\t// Expire old entries in the cache if we have a failure window defined.\n\tif window := getLoginFailureWindow(); window > 0 {\n\t\tcount := expireOldFailedAttempts(window, &failures)\n\t\tif count > 0 {\n\t\t\tlog.Infof(\"Expired %d entries from session cache due to max age reached\", count)\n\t\t}\n\t}\n\n\t// If we exceed a certain cache size, we need to remove random entries to\n\t// prevent overbloating the cache with fake entries, as this could lead to\n\t// memory exhaustion and ultimately in a DoS. We remove a single entry to\n\t// replace it with the new one.\n\t//\n\t// Chances are that we remove the one that is under active attack, but this\n\t// chance is low (1:cache_size)\n\tif failed && len(failures) >= getMaximumCacheSize() {\n\t\tlog.Warnf(\"Session cache size exceeds %d entries, removing random entry\", getMaximumCacheSize())\n\t\tidx := rand.Intn(len(failures) - 1)\n\t\tvar rmUser string\n\t\ti := 0\n\t\tfor key := range failures {\n\t\t\tif i == idx {\n\t\t\t\trmUser = key\n\t\t\t\tdelete(failures, key)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ti++\n\t\t}\n\t\tlog.Infof(\"Deleted entry for user %s from cache\", rmUser)\n\t}\n\n\tattempt, ok := failures[username]\n\tif !ok {\n\t\tattempt = LoginAttempts{FailCount: 0}\n\t}\n\n\t// On login failure, increase fail count and update last failed timestamp.\n\t// On login success, remove the entry from the cache.\n\tif failed {\n\t\tattempt.FailCount += 1\n\t\tattempt.LastFailed = time.Now()\n\t\tfailures[username] = attempt\n\t\tlog.Warnf(\"User %s failed login %d time(s)\", username, attempt.FailCount)\n\t} else {\n\t\tif attempt.FailCount > 0 {\n\t\t\t// Forget username for cache size enforcement, since entry in cache was deleted\n\t\t\tdelete(failures, username)\n\t\t}\n\t}\n\n\terr := mgr.storage.SetLoginAttempts(failures)\n\tif err != nil {\n\t\tlog.Errorf(\"Could not update login attempts: %v\", err)\n\t}\n\n}", "is_vulnerable": 1}
{"code": "func submitHandler(w http.ResponseWriter, r *http.Request) {\n\n\tswitch r.Method {\n\tcase \"GET\":\n\t\tt := tmpl.Lookup(\"submit.html\")\n\t\terr := t.ExecuteTemplate(w, \"submit\", nil)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tbreak\n\tcase \"POST\":\n\t\t// prepare target\n\t\turl, err := url.Parse(strings.TrimSpace(r.FormValue(\"url\")))\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif !options.AllowInsecureURIs {\n\t\t\tif !strings.HasPrefix(url.Scheme, \"http\") {\n\t\t\t\thttp.Error(w, \"only http(s) urls are accepted\", http.StatusNotAcceptable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tfn := lib.SafeFileName(url.String())\n\t\tfp := lib.ScreenshotPath(fn, url, options.ScreenshotPath)\n\n\t\tresp, title, err := chrm.Preflight(url)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tvar rid uint\n\t\tif rsDB != nil {\n\t\t\tif rid, err = chrm.StorePreflight(url, rsDB, resp, title, fn); err != nil {\n\t\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tbuf, err := chrm.Screenshot(url)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif err := ioutil.WriteFile(fp, buf, 0644); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif rid > 0 {\n\t\t\thttp.Redirect(w, r, \"/details?id=\"+strconv.Itoa(int(rid)), 301)\n\t\t\treturn\n\t\t}\n\n\t\thttp.Redirect(w, r, \"/submit\", 301)\n\t\tbreak\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *Router) ServeHTTP(rw http.ResponseWriter, req *http.Request) {\n\tif t, ok := r.routers[req.Method]; ok {\n\t\t// Fast match for static routes\n\t\tif !strings.ContainsAny(req.URL.Path, \":*\") {\n\t\t\tleaf := r.getLeaf(req.Method, req.URL.Path)\n\t\t\tif leaf != nil {\n\t\t\t\tleaf.handle(rw, req, nil)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\th, p, ok := t.Match(req.URL.EscapedPath())\n\t\tif ok {\n\t\t\tif splat, ok := p[\"*0\"]; ok {\n\t\t\t\tp[\"*\"] = splat // Easy name.\n\t\t\t}\n\t\t\th(rw, req, p)\n\t\t\treturn\n\t\t}\n\t}\n\n\tr.notFound(rw, req)\n}", "is_vulnerable": 0}
{"code": "func AuthenticationMiddleware(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tbearerTokenRaw := r.Header.Get(\"Authorization\")\n\t\tsplitToken := strings.Split(bearerTokenRaw, \"Bearer\")\n\t\tif len(splitToken) != 2 {\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t\taccessTokenString := strings.TrimSpace(splitToken[1])\n\t\taccessClaims, err := auth.ValidateAccessToken(accessTokenString)\n\t\tif err != nil {\n\t\t\tif _, ok := err.(*auth.ErrExpiredToken); ok {\n\t\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\t\tw.Write([]byte(`{\n\t\"data\": {},\n\t\"errors\": [\n\t{\n\t\t\"extensions\": {\n\t\t\t\"code\": \"UNAUTHENTICATED\"\n\t\t}\n\t}\n\t]\n\t\t\t\t}`))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlog.Error(err)\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tvar userID uuid.UUID\n\t\tif accessClaims.Restricted == auth.InstallOnly {\n\t\t\tuserID = uuid.New()\n\t\t} else {\n\t\t\tuserID, err = uuid.Parse(accessClaims.UserID)\n\t\t\tif err != nil {\n\t\t\t\tlog.WithError(err).Error(\"middleware access token userID parse\")\n\t\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tctx := context.WithValue(r.Context(), UserIDKey, userID)\n\t\tctx = context.WithValue(ctx, RestrictedModeKey, accessClaims.Restricted)\n\t\tctx = context.WithValue(ctx, OrgRoleKey, accessClaims.OrgRole)\n\n\t\tnext.ServeHTTP(w, r.WithContext(ctx))\n\t})\n}", "is_vulnerable": 0}
{"code": "func isLoopbackURI(requested *url.URL, registeredURI string) bool {\n\tregistered, err := url.Parse(registeredURI)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\tif registered.Scheme != \"http\" || !isLoopbackAddress(registered.Host) {\n\t\treturn false\n\t}\n\n\tif requested.Scheme == \"http\" && isLoopbackAddress(requested.Host) && registered.Path == requested.Path {\n\t\treturn true\n\t}\n\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (e *Engine) MessageReceived(ctx context.Context, p peer.ID, m bsmsg.BitSwapMessage) {\n\tentries := m.Wantlist()\n\n\tif len(entries) > 0 {\n\t\tlog.Debugw(\"Bitswap engine <- msg\", \"local\", e.self, \"from\", p, \"entryCount\", len(entries))\n\t\tfor _, et := range entries {\n\t\t\tif !et.Cancel {\n\t\t\t\tif et.WantType == pb.Message_Wantlist_Have {\n\t\t\t\t\tlog.Debugw(\"Bitswap engine <- want-have\", \"local\", e.self, \"from\", p, \"cid\", et.Cid)\n\t\t\t\t} else {\n\t\t\t\t\tlog.Debugw(\"Bitswap engine <- want-block\", \"local\", e.self, \"from\", p, \"cid\", et.Cid)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif m.Empty() {\n\t\tlog.Infof(\"received empty message from %s\", p)\n\t}\n\n\tnewWorkExists := false\n\tdefer func() {\n\t\tif newWorkExists {\n\t\t\te.signalNewWork()\n\t\t}\n\t}()\n\n\t// Dispatch entries\n\twants, cancels := e.splitWantsCancels(entries)\n\twants, denials := e.splitWantsDenials(p, wants)\n\n\t// Get block sizes\n\twantKs := cid.NewSet()\n\tfor _, entry := range wants {\n\t\twantKs.Add(entry.Cid)\n\t}\n\tblockSizes, err := e.bsm.getBlockSizes(ctx, wantKs.Keys())\n\tif err != nil {\n\t\tlog.Info(\"aborting message processing\", err)\n\t\treturn\n\t}\n\n\te.lock.Lock()\n\tfor _, entry := range wants {\n\t\te.peerLedger.Wants(p, entry.Cid)\n\t}\n\tfor _, entry := range cancels {\n\t\te.peerLedger.CancelWant(p, entry.Cid)\n\t}\n\te.lock.Unlock()\n\n\t// Get the ledger for the peer\n\tl := e.findOrCreate(p)\n\tl.lk.Lock()\n\tdefer l.lk.Unlock()\n\n\t// If the peer sent a full wantlist, replace the ledger's wantlist\n\tif m.Full() {\n\t\tl.wantList = wl.New()\n\t}\n\n\tvar activeEntries []peertask.Task\n\n\t// Remove cancelled blocks from the queue\n\tfor _, entry := range cancels {\n\t\tlog.Debugw(\"Bitswap engine <- cancel\", \"local\", e.self, \"from\", p, \"cid\", entry.Cid)\n\t\tif l.CancelWant(entry.Cid) {\n\t\t\te.peerRequestQueue.Remove(entry.Cid, p)\n\t\t}\n\t}\n\n\t// Cancel a block operation\n\tsendDontHave := func(entry bsmsg.Entry) {\n\t\t// Only add the task to the queue if the requester wants a DONT_HAVE\n\t\tif e.sendDontHaves && entry.SendDontHave {\n\t\t\tc := entry.Cid\n\n\t\t\tnewWorkExists = true\n\t\t\tisWantBlock := false\n\t\t\tif entry.WantType == pb.Message_Wantlist_Block {\n\t\t\t\tisWantBlock = true\n\t\t\t}\n\n\t\t\tactiveEntries = append(activeEntries, peertask.Task{\n\t\t\t\tTopic:    c,\n\t\t\t\tPriority: int(entry.Priority),\n\t\t\t\tWork:     bsmsg.BlockPresenceSize(c),\n\t\t\t\tData: &taskData{\n\t\t\t\t\tBlockSize:    0,\n\t\t\t\t\tHaveBlock:    false,\n\t\t\t\t\tIsWantBlock:  isWantBlock,\n\t\t\t\t\tSendDontHave: entry.SendDontHave,\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\t}\n\n\t// Deny access to blocks\n\tfor _, entry := range denials {\n\t\tlog.Debugw(\"Bitswap engine: block denied access\", \"local\", e.self, \"from\", p, \"cid\", entry.Cid, \"sendDontHave\", entry.SendDontHave)\n\t\tsendDontHave(entry)\n\t}\n\n\t// For each want-have / want-block\n\tfor _, entry := range wants {\n\t\tc := entry.Cid\n\t\tblockSize, found := blockSizes[entry.Cid]\n\n\t\t// Add each want-have / want-block to the ledger\n\t\tl.Wants(c, entry.Priority, entry.WantType)\n\n\t\t// If the block was not found\n\t\tif !found {\n\t\t\tlog.Debugw(\"Bitswap engine: block not found\", \"local\", e.self, \"from\", p, \"cid\", entry.Cid, \"sendDontHave\", entry.SendDontHave)\n\t\t\tsendDontHave(entry)\n\t\t} else {\n\t\t\t// The block was found, add it to the queue\n\t\t\tnewWorkExists = true\n\n\t\t\tisWantBlock := e.sendAsBlock(entry.WantType, blockSize)\n\n\t\t\tlog.Debugw(\"Bitswap engine: block found\", \"local\", e.self, \"from\", p, \"cid\", entry.Cid, \"isWantBlock\", isWantBlock)\n\n\t\t\t// entrySize is the amount of space the entry takes up in the\n\t\t\t// message we send to the recipient. If we're sending a block, the\n\t\t\t// entrySize is the size of the block. Otherwise it's the size of\n\t\t\t// a block presence entry.\n\t\t\tentrySize := blockSize\n\t\t\tif !isWantBlock {\n\t\t\t\tentrySize = bsmsg.BlockPresenceSize(c)\n\t\t\t}\n\t\t\tactiveEntries = append(activeEntries, peertask.Task{\n\t\t\t\tTopic:    c,\n\t\t\t\tPriority: int(entry.Priority),\n\t\t\t\tWork:     entrySize,\n\t\t\t\tData: &taskData{\n\t\t\t\t\tBlockSize:    blockSize,\n\t\t\t\t\tHaveBlock:    true,\n\t\t\t\t\tIsWantBlock:  isWantBlock,\n\t\t\t\t\tSendDontHave: entry.SendDontHave,\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\t}\n\n\t// Push entries onto the request queue\n\tif len(activeEntries) > 0 {\n\t\te.peerRequestQueue.PushTasks(p, activeEntries...)\n\t\te.updateMetrics()\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestIngressAnnotationOpentracingTrustSetTrue(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(enableOpentracingAnnotation)] = \"true\"\n\tdata[parser.GetAnnotationWithPrefix(opentracingTrustSpanAnnotation)] = \"true\"\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\topenTracing, ok := val.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected a Config type\")\n\t}\n\n\tif !openTracing.Enabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif !openTracing.TrustEnabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *FullState) WriteStateFile(ctx context.Context, statePath string) error {\n\tstateFile, err := json.MarshalIndent(s, \"\", \"  \")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"[state] Failed to Marshal state object: %v\", err)\n\t}\n\tlogrus.Tracef(\"Writing state file: %s\", stateFile)\n\tif err := os.WriteFile(statePath, stateFile, 0600); err != nil {\n\t\treturn fmt.Errorf(\"[state] Failed to write state file: %v\", err)\n\t}\n\tlog.Infof(ctx, \"Successfully Deployed state file at [%s]\", statePath)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *repositoryClient) ListSignatures(ctx context.Context, desc ocispec.Descriptor, fn func(signatureManifests []ocispec.Descriptor) error) error {\n\treferrers, err := remote.Referrers(c.ref.Context().Digest(desc.Digest.String()), c.remoteOpts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treferrersDescs, err := referrers.IndexManifest()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdescList := []ocispec.Descriptor{}\n\tfor _, d := range referrersDescs.Manifests {\n\t\tif d.ArtifactType == notationregistry.ArtifactTypeNotation {\n\t\t\tdescList = append(descList, v1ToOciSpecDescriptor(d))\n\t\t}\n\t}\n\n\treturn fn(descList)\n}", "is_vulnerable": 0}
{"code": "func (v *View) UserByID(userID, instanceID string) (*model.UserView, error) {\n\treturn view.UserByID(v.Db, userTable, userID, instanceID)\n}", "is_vulnerable": 1}
{"code": "func GetEngineInfo() (*EngineInfo, error) {\n\tvar cInfo C.gpgme_engine_info_t\n\terr := handleError(C.gpgme_get_engine_info(&cInfo))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn copyEngineInfo(cInfo), nil // It is up to the caller not to invalidate cInfo concurrently until this is done.\n}", "is_vulnerable": 0}
{"code": "func toJsonString(v interface{}) string {\n\tjsonString, _ := json.Marshal(v)\n\treturn string(jsonString)\n}", "is_vulnerable": 0}
{"code": "func (t *assetAction) checkERC20AssetList() error {\n\treturn t.bridgeView.FindAssetList(t.erc20AL, t.blockHeight, t.logIndex)\n}", "is_vulnerable": 1}
{"code": "func getFiles(f iofs.ReadDirFS, name string) ([]string, error) {\n\tvar v []string\n\n\tentries, err := f.ReadDir(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, e := range entries {\n\t\tentryName := e.Name()\n\t\tif name != \".\" {\n\t\t\tentryName = filepath.Join(name, entryName)\n\t\t}\n\n\t\tif e.IsDir() {\n\t\t\tfiles, err := getFiles(f, entryName)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tif files == nil {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t\t\n\t\t\tv = append(v, files...)\n\t\t\tcontinue\n\t\t}\n\n\t\tv = append(v, entryName)\n\t}\n\n\treturn v, nil\n}", "is_vulnerable": 1}
{"code": "func (fs *UnixFS) Chmod(name string, mode FileMode) error {\n\tdirfd, name, closeFd, err := fs.safePath(name)\n\tdefer closeFd()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn convertErrorType(unix.Fchmodat(dirfd, name, uint32(mode), 0))\n}", "is_vulnerable": 0}
{"code": "func (s *store) GetList(ctx context.Context, key string, opts storage.ListOptions, listObj runtime.Object) error {\n\trecursive := opts.Recursive\n\tresourceVersion := opts.ResourceVersion\n\tmatch := opts.ResourceVersionMatch\n\tpred := opts.Predicate\n\tctx, span := tracing.Start(ctx, fmt.Sprintf(\"List(recursive=%v) etcd3\", recursive),\n\t\tattribute.String(\"audit-id\", audit.GetAuditIDTruncated(ctx)),\n\t\tattribute.String(\"key\", key),\n\t\tattribute.String(\"resourceVersion\", resourceVersion),\n\t\tattribute.String(\"resourceVersionMatch\", string(match)),\n\t\tattribute.Int(\"limit\", int(pred.Limit)),\n\t\tattribute.String(\"continue\", pred.Continue))\n\tdefer span.End(500 * time.Millisecond)\n\tlistPtr, err := meta.GetItemsPtr(listObj)\n\tif err != nil {\n\t\treturn err\n\t}\n\tv, err := conversion.EnforcePtr(listPtr)\n\tif err != nil || v.Kind() != reflect.Slice {\n\t\treturn fmt.Errorf(\"need ptr to slice: %v\", err)\n\t}\n\tkey = path.Join(s.pathPrefix, key)\n\n\t// For recursive lists, we need to make sure the key ended with \"/\" so that we only\n\t// get children \"directories\". e.g. if we have key \"/a\", \"/a/b\", \"/ab\", getting keys\n\t// with prefix \"/a\" will return all three, while with prefix \"/a/\" will return only\n\t// \"/a/b\" which is the correct answer.\n\tif recursive && !strings.HasSuffix(key, \"/\") {\n\t\tkey += \"/\"\n\t}\n\tkeyPrefix := key\n\n\t// set the appropriate clientv3 options to filter the returned data set\n\tvar limitOption *clientv3.OpOption\n\tlimit := pred.Limit\n\tvar paging bool\n\toptions := make([]clientv3.OpOption, 0, 4)\n\tif s.pagingEnabled && pred.Limit > 0 {\n\t\tpaging = true\n\t\toptions = append(options, clientv3.WithLimit(limit))\n\t\tlimitOption = &options[len(options)-1]\n\t}\n\n\tnewItemFunc := getNewItemFunc(listObj, v)\n\n\tvar fromRV *uint64\n\tif len(resourceVersion) > 0 {\n\t\tparsedRV, err := s.versioner.ParseResourceVersion(resourceVersion)\n\t\tif err != nil {\n\t\t\treturn apierrors.NewBadRequest(fmt.Sprintf(\"invalid resource version: %v\", err))\n\t\t}\n\t\tfromRV = &parsedRV\n\t}\n\n\tvar returnedRV, continueRV, withRev int64\n\tvar continueKey string\n\tswitch {\n\tcase recursive && s.pagingEnabled && len(pred.Continue) > 0:\n\t\tcontinueKey, continueRV, err = storage.DecodeContinue(pred.Continue, keyPrefix)\n\t\tif err != nil {\n\t\t\treturn apierrors.NewBadRequest(fmt.Sprintf(\"invalid continue token: %v\", err))\n\t\t}\n\n\t\tif len(resourceVersion) > 0 && resourceVersion != \"0\" {\n\t\t\treturn apierrors.NewBadRequest(\"specifying resource version is not allowed when using continue\")\n\t\t}\n\n\t\trangeEnd := clientv3.GetPrefixRangeEnd(keyPrefix)\n\t\toptions = append(options, clientv3.WithRange(rangeEnd))\n\t\tkey = continueKey\n\n\t\t// If continueRV > 0, the LIST request needs a specific resource version.\n\t\t// continueRV==0 is invalid.\n\t\t// If continueRV < 0, the request is for the latest resource version.\n\t\tif continueRV > 0 {\n\t\t\twithRev = continueRV\n\t\t\treturnedRV = continueRV\n\t\t}\n\tcase recursive && s.pagingEnabled && pred.Limit > 0:\n\t\tif fromRV != nil {\n\t\t\tswitch match {\n\t\t\tcase metav1.ResourceVersionMatchNotOlderThan:\n\t\t\t\t// The not older than constraint is checked after we get a response from etcd,\n\t\t\t\t// and returnedRV is then set to the revision we get from the etcd response.\n\t\t\tcase metav1.ResourceVersionMatchExact:\n\t\t\t\treturnedRV = int64(*fromRV)\n\t\t\t\twithRev = returnedRV\n\t\t\tcase \"\": // legacy case\n\t\t\t\tif *fromRV > 0 {\n\t\t\t\t\treturnedRV = int64(*fromRV)\n\t\t\t\t\twithRev = returnedRV\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown ResourceVersionMatch value: %v\", match)\n\t\t\t}\n\t\t}\n\n\t\trangeEnd := clientv3.GetPrefixRangeEnd(keyPrefix)\n\t\toptions = append(options, clientv3.WithRange(rangeEnd))\n\tdefault:\n\t\tif fromRV != nil {\n\t\t\tswitch match {\n\t\t\tcase metav1.ResourceVersionMatchNotOlderThan:\n\t\t\t\t// The not older than constraint is checked after we get a response from etcd,\n\t\t\t\t// and returnedRV is then set to the revision we get from the etcd response.\n\t\t\tcase metav1.ResourceVersionMatchExact:\n\t\t\t\treturnedRV = int64(*fromRV)\n\t\t\t\twithRev = returnedRV\n\t\t\tcase \"\": // legacy case\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown ResourceVersionMatch value: %v\", match)\n\t\t\t}\n\t\t}\n\n\t\tif recursive {\n\t\t\toptions = append(options, clientv3.WithPrefix())\n\t\t}\n\t}\n\tif withRev != 0 {\n\t\toptions = append(options, clientv3.WithRev(withRev))\n\t}\n\n\t// loop until we have filled the requested limit from etcd or there are no more results\n\tvar lastKey []byte\n\tvar hasMore bool\n\tvar getResp *clientv3.GetResponse\n\tvar numFetched int\n\tvar numEvald int\n\t// Because these metrics are for understanding the costs of handling LIST requests,\n\t// get them recorded even in error cases.\n\tdefer func() {\n\t\tnumReturn := v.Len()\n\t\tmetrics.RecordStorageListMetrics(s.groupResourceString, numFetched, numEvald, numReturn)\n\t}()\n\tfor {\n\t\tstartTime := time.Now()\n\t\tgetResp, err = s.client.KV.Get(ctx, key, options...)\n\t\tif recursive {\n\t\t\tmetrics.RecordEtcdRequestLatency(\"list\", s.groupResourceString, startTime)\n\t\t} else {\n\t\t\tmetrics.RecordEtcdRequestLatency(\"get\", s.groupResourceString, startTime)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn interpretListError(err, len(pred.Continue) > 0, continueKey, keyPrefix)\n\t\t}\n\t\tnumFetched += len(getResp.Kvs)\n\t\tif err = s.validateMinimumResourceVersion(resourceVersion, uint64(getResp.Header.Revision)); err != nil {\n\t\t\treturn err\n\t\t}\n\t\thasMore = getResp.More\n\n\t\tif len(getResp.Kvs) == 0 && getResp.More {\n\t\t\treturn fmt.Errorf(\"no results were found, but etcd indicated there were more values remaining\")\n\t\t}\n\n\t\t// avoid small allocations for the result slice, since this can be called in many\n\t\t// different contexts and we don't know how significantly the result will be filtered\n\t\tif pred.Empty() {\n\t\t\tgrowSlice(v, len(getResp.Kvs))\n\t\t} else {\n\t\t\tgrowSlice(v, 2048, len(getResp.Kvs))\n\t\t}\n\n\t\t// take items from the response until the bucket is full, filtering as we go\n\t\tfor i, kv := range getResp.Kvs {\n\t\t\tif paging && int64(v.Len()) >= pred.Limit {\n\t\t\t\thasMore = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tlastKey = kv.Key\n\n\t\t\tdata, _, err := s.transformer.TransformFromStorage(ctx, kv.Value, authenticatedDataString(kv.Key))\n\t\t\tif err != nil {\n\t\t\t\treturn storage.NewInternalErrorf(\"unable to transform key %q: %v\", kv.Key, err)\n\t\t\t}\n\n\t\t\tif err := appendListItem(v, data, uint64(kv.ModRevision), pred, s.codec, s.versioner, newItemFunc); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tnumEvald++\n\n\t\t\t// free kv early. Long lists can take O(seconds) to decode.\n\t\t\tgetResp.Kvs[i] = nil\n\t\t}\n\n\t\t// indicate to the client which resource version was returned\n\t\tif returnedRV == 0 {\n\t\t\treturnedRV = getResp.Header.Revision\n\t\t}\n\n\t\t// no more results remain or we didn't request paging\n\t\tif !hasMore || !paging {\n\t\t\tbreak\n\t\t}\n\t\t// we're paging but we have filled our bucket\n\t\tif int64(v.Len()) >= pred.Limit {\n\t\t\tbreak\n\t\t}\n\n\t\tif limit < maxLimit {\n\t\t\t// We got incomplete result due to field/label selector dropping the object.\n\t\t\t// Double page size to reduce total number of calls to etcd.\n\t\t\tlimit *= 2\n\t\t\tif limit > maxLimit {\n\t\t\t\tlimit = maxLimit\n\t\t\t}\n\t\t\t*limitOption = clientv3.WithLimit(limit)\n\t\t}\n\t\tkey = string(lastKey) + \"\\x00\"\n\t\tif withRev == 0 {\n\t\t\twithRev = returnedRV\n\t\t\toptions = append(options, clientv3.WithRev(withRev))\n\t\t}\n\t}\n\n\t// instruct the client to begin querying from immediately after the last key we returned\n\t// we never return a key that the client wouldn't be allowed to see\n\tif hasMore {\n\t\t// we want to start immediately after the last key\n\t\tnext, err := storage.EncodeContinue(string(lastKey)+\"\\x00\", keyPrefix, returnedRV)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvar remainingItemCount *int64\n\t\t// getResp.Count counts in objects that do not match the pred.\n\t\t// Instead of returning inaccurate count for non-empty selectors, we return nil.\n\t\t// Only set remainingItemCount if the predicate is empty.\n\t\tif utilfeature.DefaultFeatureGate.Enabled(features.RemainingItemCount) {\n\t\t\tif pred.Empty() {\n\t\t\t\tc := int64(getResp.Count - pred.Limit)\n\t\t\t\tremainingItemCount = &c\n\t\t\t}\n\t\t}\n\t\treturn s.versioner.UpdateList(listObj, uint64(returnedRV), next, remainingItemCount)\n\t}\n\n\t// no continuation\n\treturn s.versioner.UpdateList(listObj, uint64(returnedRV), \"\", nil)\n}", "is_vulnerable": 1}
{"code": "func handleI18nCurrentLanguage(w http.ResponseWriter, r *http.Request) {\n\tlog.Printf(\"home: language is %s\", config.Language)\n\n\t_ = aghhttp.WriteJSONResponse(w, r, &languageJSON{\n\t\tLanguage: config.Language,\n\t})\n}", "is_vulnerable": 0}
{"code": "func ParseUintListMaximum(val string, maximum int) (map[int]bool, error) {\n\treturn parseUintList(val, maximum)\n}", "is_vulnerable": 0}
{"code": "func NoNamespaceKeyFunc(prefix string, obj runtime.Object) (string, error) {\n\tmeta, err := meta.Accessor(obj)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tname := meta.Name()\n\tif ok, msg := validation.ValidatePathSegmentName(name, false); !ok {\n\t\treturn \"\", fmt.Errorf(\"invalid name: %v\", msg)\n\t}\n\treturn prefix + \"/\" + meta.Name(), nil\n}", "is_vulnerable": 0}
{"code": "func (s *sigs) Get() ([]oci.Signature, error) {\n\tm, err := s.Manifest()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnumLayers := int64(len(m.Layers))\n\tif numLayers > maxLayers {\n\t\treturn nil, oci.NewMaxLayersExceeded(numLayers, maxLayers)\n\t}\n\tsignatures := make([]oci.Signature, 0, len(m.Layers))\n\tfor _, desc := range m.Layers {\n\t\tlayer, err := s.Image.LayerByDigest(desc.Digest)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsignatures = append(signatures, signature.New(layer, desc))\n\t}\n\treturn signatures, nil\n}", "is_vulnerable": 0}
{"code": "func (ns *nodeServer) getNode() (node *v1.Node, err error) {\n\t// Default to allow patch stale node info\n\tif envVar, found := os.LookupEnv(AllowPatchStaleNodeEnv); !found || envVar == \"true\" {\n\t\tif ns.node != nil {\n\t\t\tglog.V(3).Infof(\"Found cached node %s\", ns.node.Name)\n\t\t\treturn ns.node, nil\n\t\t}\n\t}\n\n\tif node, err = ns.nodeAuthorizedClient.CoreV1().Nodes().Get(context.TODO(), ns.nodeId, metav1.GetOptions{}); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// if node, err = kubeclient.GetNode(ns.apiReader, ns.nodeId); err != nil {\n\t// return nil, err\n\t// }\n\n\tglog.V(1).Infof(\"Got node %s from api server\", node.Name)\n\tns.node = node\n\treturn ns.node, nil\n}", "is_vulnerable": 0}
{"code": "func (m *AnotherNinOptEnumDefault) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: AnotherNinOptEnumDefault: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: AnotherNinOptEnumDefault: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v AnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= AnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v YetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field2 = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v YetYetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field3 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) OutgoingTLSConfigForCheck(id string) (*tls.Config, error) {\n\tif !c.base.EnableAgentTLSForChecks {\n\t\treturn &tls.Config{\n\t\t\tInsecureSkipVerify: c.getSkipVerifyForCheck(id),\n\t\t}, nil\n\t}\n\n\ttlsConfig, err := c.commonTLSConfig(false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttlsConfig.InsecureSkipVerify = c.getSkipVerifyForCheck(id)\n\ttlsConfig.ServerName = c.base.ServerName\n\tif tlsConfig.ServerName == \"\" {\n\t\ttlsConfig.ServerName = c.base.NodeName\n\t}\n\n\treturn tlsConfig, nil\n}", "is_vulnerable": 1}
{"code": "func HTTPRedirectf(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, msg string, args ...interface{}) {\n\tif assert.HTTPRedirectf(t, handler, method, url, values, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (t Token) ToADALToken() (converted adal.Token, err error) {\n\ttokenExpirationDate, err := ParseExpirationDate(t.ExpiresOn)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"Error parsing Token Expiration Date %q: %+v\", t.ExpiresOn, err)\n\t\treturn\n\t}\n\n\tdifference := tokenExpirationDate.Sub(date.UnixEpoch())\n\n\tconverted = adal.Token{\n\t\tAccessToken:  t.AccessToken,\n\t\tType:         t.TokenType,\n\t\tExpiresIn:    \"3600\",\n\t\tExpiresOn:    strconv.Itoa(int(difference.Seconds())),\n\t\tRefreshToken: t.RefreshToken,\n\t\tResource:     t.Resource,\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func FindRemoteIP(r *http.Request) string {\n\tremoteIP, _, err := net.SplitHostPort(r.RemoteAddr)\n\tif err != nil {\n\t\tremoteIP = r.RemoteAddr\n\t}\n\tremoteIP = dropIPv6zone(remoteIP)\n\n\t// When listening on a Unix socket, RemoteAddr is empty.\n\tif remoteIP == \"\" {\n\t\tremoteIP = \"127.0.0.1\"\n\t}\n\n\treturn remoteIP\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Website(ctx context.Context, in *clientpb.Website, opts ...grpc.CallOption) (*clientpb.Website, error) {\n\tout := new(clientpb.Website)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Website\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (h *httpContext) MakeServers() ([]caddy.Server, error) {\n\t// make sure TLS is disabled for explicitly-HTTP sites\n\t// (necessary when HTTP address shares a block containing tls)\n\tfor _, cfg := range h.siteConfigs {\n\t\tif !cfg.TLS.Enabled {\n\t\t\tcontinue\n\t\t}\n\t\tif cfg.Addr.Port == HTTPPort || cfg.Addr.Scheme == \"http\" {\n\t\t\tcfg.TLS.Enabled = false\n\t\t\tlog.Printf(\"[WARNING] TLS disabled for %s\", cfg.Addr)\n\t\t} else if cfg.Addr.Scheme == \"\" {\n\t\t\t// set scheme to https ourselves, since TLS is enabled\n\t\t\t// and it was not explicitly set to something else. this\n\t\t\t// makes it appear as \"https\" when we print the list of\n\t\t\t// running sites; otherwise \"http\" would be assumed which\n\t\t\t// is incorrect for this site.\n\t\t\tcfg.Addr.Scheme = \"https\"\n\t\t}\n\t\tif cfg.Addr.Port == \"\" && ((!cfg.TLS.Manual && !cfg.TLS.SelfSigned) || cfg.TLS.OnDemand) {\n\t\t\t// this is vital, otherwise the function call below that\n\t\t\t// sets the listener address will use the default port\n\t\t\t// instead of 443 because it doesn't know about TLS.\n\t\t\tcfg.Addr.Port = HTTPSPort\n\t\t}\n\t}\n\n\t// we must map (group) each config to a bind address\n\tgroups, err := groupSiteConfigsByListenAddr(h.siteConfigs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// then we create a server for each group\n\tvar servers []caddy.Server\n\tfor addr, group := range groups {\n\t\ts, err := NewServer(addr, group)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tservers = append(servers, s)\n\t}\n\n\treturn servers, nil\n}", "is_vulnerable": 1}
{"code": "func Equalf(t TestingT, expected interface{}, actual interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Equalf(t, expected, actual, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func TestPing(t *testing.T) {\n\tserver := test.NewServer(\n\t\t&test.RequestHandlerMapping{\n\t\t\tMethod:  http.MethodHead,\n\t\t\tPattern: \"/v2/\",\n\t\t\tHandler: test.Handler(nil),\n\t\t})\n\tdefer server.Close()\n\n\tclient, err := newRegistryClient(server.URL)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create client for registry: %v\", err)\n\t}\n\n\tif err = client.Ping(); err != nil {\n\t\tt.Errorf(\"failed to ping registry: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *NinOptNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\tm.Field1 = &v2\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\tm.Field2 = &v2\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field3 = &v\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field4 = &v\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field5 = &v\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field6 = &v\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.Field7 = &v\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\tv2 := int64(v)\n\t\t\tm.Field8 = &v2\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.Field9 = &v\n\t\tcase 10:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.Field10 = &v\n\t\tcase 11:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.Field11 = &v\n\t\tcase 12:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.Field12 = &v\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.Field13 = &b\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Field14 = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Field15 == nil {\n\t\t\t\tm.Field15 = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipFuzz(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func isValidCString(cs string) bool {\n\treturn !strings.ContainsRune(cs, '\\x00')\n}", "is_vulnerable": 0}
{"code": "func (e *EngineInfo) Version() string {\n\treturn C.GoString(e.info.version)\n}", "is_vulnerable": 1}
{"code": "func TestGlobalRateLimiting(t *testing.T) {\n\ting := buildIngress()\n\n\tannRateLimit := parser.GetAnnotationWithPrefix(\"global-rate-limit\")\n\tannRateLimitWindow := parser.GetAnnotationWithPrefix(\"global-rate-limit-window\")\n\tannRateLimitKey := parser.GetAnnotationWithPrefix(\"global-rate-limit-key\")\n\tannRateLimitIgnoredCIDRs := parser.GetAnnotationWithPrefix(\"global-rate-limit-ignored-cidrs\")\n\n\ttestCases := []struct {\n\t\ttitle          string\n\t\tannotations    map[string]string\n\t\texpectedConfig *Config\n\t\texpectedErr    error\n\t}{\n\t\t{\n\t\t\t\"no annotation\",\n\t\t\tnil,\n\t\t\t&Config{},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"minimum required annotations\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2m\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$remote_addr\",\n\t\t\t\tIgnoredCIDRs: make([]string, 0),\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"global-rate-limit-key annotation\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2m\",\n\t\t\t\tannRateLimitKey:    \"$http_x_api_user\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$http_x_api_user\",\n\t\t\t\tIgnoredCIDRs: make([]string, 0),\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"global-rate-limit-ignored-cidrs annotation\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:             \"100\",\n\t\t\t\tannRateLimitWindow:       \"2m\",\n\t\t\t\tannRateLimitKey:          \"$http_x_api_user\",\n\t\t\t\tannRateLimitIgnoredCIDRs: \"127.0.0.1, 200.200.24.0/24\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$http_x_api_user\",\n\t\t\t\tIgnoredCIDRs: []string{\"127.0.0.1\", \"200.200.24.0/24\"},\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"incorrect duration for window\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2mb\",\n\t\t\t\tannRateLimitKey:    \"$http_x_api_user\",\n\t\t\t},\n\t\t\t&Config{},\n\t\t\ting_errors.LocationDenied{\n\t\t\t\tReason: fmt.Errorf(\"failed to parse 'global-rate-limit-window' value: time: unknown unit \\\"mb\\\" in duration \\\"2mb\\\"\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ting.SetAnnotations(testCase.annotations)\n\n\t\ti, actualErr := NewParser(mockBackend{}).Parse(ing)\n\t\tif (testCase.expectedErr == nil || actualErr == nil) && testCase.expectedErr != actualErr {\n\t\t\tt.Errorf(\"expected error 'nil' but got '%v'\", actualErr)\n\t\t} else if testCase.expectedErr != nil && actualErr != nil &&\n\t\t\ttestCase.expectedErr.Error() != actualErr.Error() {\n\t\t\tt.Errorf(\"expected error '%v' but got '%v'\", testCase.expectedErr, actualErr)\n\t\t}\n\n\t\tactualConfig := i.(*Config)\n\t\tif !testCase.expectedConfig.Equal(actualConfig) {\n\t\t\texpectedJSON, _ := json.Marshal(testCase.expectedConfig)\n\t\t\tactualJSON, _ := json.Marshal(actualConfig)\n\t\t\tt.Errorf(\"%v: expected config '%s' but got '%s'\", testCase.title, expectedJSON, actualJSON)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetHTTPC2ProfileByName(ctx context.Context, in *clientpb.C2ProfileReq, opts ...grpc.CallOption) (*clientpb.HTTPC2Config, error) {\n\tout := new(clientpb.HTTPC2Config)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetHTTPC2ProfileByName\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func aesgcmTest(t *testing.T, iv, key, plaintext, expected, tag []byte) {\n\tcd := CipherData{\n\t\tKey: key,\n\t\tIV:  iv,\n\t}\n\tgcm, err := newAESGCM(cd)\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\n\tcipherdata := gcm.Encrypt(bytes.NewReader(plaintext))\n\n\tciphertext, err := ioutil.ReadAll(cipherdata)\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\n\t// splitting tag and ciphertext\n\tetag := ciphertext[len(ciphertext)-16:]\n\tif !bytes.Equal(etag, tag) {\n\t\tt.Errorf(\"expected tags to be equivalent\")\n\t}\n\tif !bytes.Equal(ciphertext, expected) {\n\t\tt.Errorf(\"expected ciphertext to be equivalent\")\n\t}\n\n\tdata := gcm.Decrypt(bytes.NewReader(ciphertext))\n\ttext, err := ioutil.ReadAll(data)\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\tif !bytes.Equal(plaintext, text) {\n\t\tt.Errorf(\"expected ciphertext to be equivalent\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) StartTCPStagerListener(ctx context.Context, in *clientpb.StagerListenerReq, opts ...grpc.CallOption) (*clientpb.StagerListener, error) {\n\tout := new(clientpb.StagerListener)\n\terr := c.cc.Invoke(ctx, SliverRPC_StartTCPStagerListener_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (r *TerraformRunnerServer) tfOutput(ctx context.Context, opts ...tfexec.OutputOption) (map[string]tfexec.OutputMeta, error) {\n\tlog := ctrl.LoggerFrom(ctx, \"instance-id\", r.InstanceID).WithName(loggerName)\n\n\t// This is the only place where we disable the logger\n\tr.tf.SetStdout(io.Discard)\n\tr.tf.SetStderr(io.Discard)\n\n\tdefer r.initLogger(log)\n\n\treturn r.tf.Output(ctx, opts...)\n}", "is_vulnerable": 0}
{"code": "func httpProxyErrors(proxy *contourv1.HTTPProxy) string {\n\tcond := proxy.Status.GetConditionFor(\"Valid\")\n\terrors := cond.Errors\n\tif len(errors) > 0 {\n\t\treturn spew.Sdump(errors)\n\t}\n\n\treturn \"\"\n}", "is_vulnerable": 0}
{"code": "func (ts *Server) GetKeyspace(ctx context.Context, keyspace string) (*KeyspaceInfo, error) {\n\tif err := ValidateKeyspaceName(keyspace); err != nil {\n\t\treturn nil, vterrors.Wrapf(err, \"GetKeyspace: %s\", err)\n\t}\n\n\tkeyspacePath := path.Join(KeyspacesPath, keyspace, KeyspaceFile)\n\tdata, version, err := ts.globalCell.Get(ctx, keyspacePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tk := &topodatapb.Keyspace{}\n\tif err = proto.Unmarshal(data, k); err != nil {\n\t\treturn nil, vterrors.Wrap(err, \"bad keyspace data\")\n\t}\n\n\treturn &KeyspaceInfo{\n\t\tkeyspace: keyspace,\n\t\tversion:  version,\n\t\tKeyspace: k,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (t *Trie) Reset() {\n\tt.root = nil\n\tt.unhashed = 0\n}", "is_vulnerable": 0}
{"code": "func (src *AuthenticationSASL) Encode(dst []byte) []byte {\n\tdst = append(dst, 'R')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\tdst = pgio.AppendUint32(dst, AuthTypeSASL)\n\n\tfor _, s := range src.AuthMechanisms {\n\t\tdst = append(dst, []byte(s)...)\n\t\tdst = append(dst, 0)\n\t}\n\tdst = append(dst, 0)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (c *Context) KeyListMode() KeyListMode {\n\tres := KeyListMode(C.gpgme_get_keylist_mode(c.ctx))\n\truntime.KeepAlive(c)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func newTIFF(enc byteOrder) []byte {\n\tb := []byte{0, 0, 0, 42, 0, 0, 0, 0}\n\tswitch enc.Uint16([]byte{1, 0}) {\n\tcase 0x1:\n\t\tb[0], b[1] = 'I', 'I'\n\tcase 0x100:\n\t\tb[0], b[1] = 'M', 'M'\n\tdefault:\n\t\tpanic(\"odd byte order\")\n\t}\n\treturn b\n}", "is_vulnerable": 0}
{"code": "func NewParser(resolver resolver.Resolver) parser.IngressAnnotation {\n\treturn authTLS{\n\t\tr:                resolver,\n\t\tannotationConfig: authTLSAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestListApps(t *testing.T) {\n\tappServer := newTestAppServer(t, newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"bcd\"\n\t}), newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"abc\"\n\t}), newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"def\"\n\t}))\n\n\tres, err := appServer.List(context.Background(), &application.ApplicationQuery{})\n\tassert.NoError(t, err)\n\tvar names []string\n\tfor i := range res.Items {\n\t\tnames = append(names, res.Items[i].Name)\n\t}\n\tassert.Equal(t, []string{\"abc\", \"bcd\", \"def\"}, names)\n}", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tt = Tag{}\n\t\t\terr = language.ErrSyntax\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func (c *Context) SetTextMode(yes bool) {\n\tC.gpgme_set_textmode(c.ctx, cbool(yes))\n\truntime.KeepAlive(c)\n}", "is_vulnerable": 0}
{"code": "func saveClusterState(ctx context.Context, kubeCluster *cluster.Cluster, clusterState *cluster.FullState) error {\n\tvar err error\n\tif err = kubeCluster.UpdateClusterCurrentState(ctx, clusterState); err != nil {\n\t\treturn err\n\t}\n\t// Attempt to store cluster full state to Kubernetes\n\tfor i := 1; i <= 3; i++ {\n\t\terr = cluster.SaveFullStateToKubernetes(ctx, kubeCluster, clusterState)\n\t\tif err != nil {\n\t\t\ttime.Sleep(time.Second * time.Duration(2))\n\t\t\tcontinue\n\t\t}\n\t\tbreak\n\t}\n\tif err != nil {\n\t\tlogrus.Warnf(\"Failed to save full cluster state to Kubernetes\")\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *KeyAgentTestSuite) TestHostCertVerification(c *check.C) {\n\t// Make a new local agent.\n\tlka, err := NewLocalAgent(s.keyDir, s.hostname, s.username, true)\n\tc.Assert(err, check.IsNil)\n\n\t// By default user has not refused any hosts.\n\tc.Assert(lka.UserRefusedHosts(), check.Equals, false)\n\n\t// Create a CA, generate a keypair for the CA, and add it to the known\n\t// hosts cache (done by \"tsh login\").\n\tkeygen := testauthority.New()\n\tcaPriv, caPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\tcaPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(caPub)\n\tc.Assert(err, check.IsNil)\n\terr = lka.keyStore.AddKnownHostKeys(\"example.com\", []ssh.PublicKey{caPublicKey})\n\tc.Assert(err, check.IsNil)\n\n\t// Generate a host certificate for node with role \"node\".\n\t_, hostPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\troles, err := teleport.ParseRoles(\"node\")\n\tc.Assert(err, check.IsNil)\n\thostCertBytes, err := keygen.GenerateHostCert(services.HostCertParams{\n\t\tPrivateCASigningKey: caPriv,\n\t\tCASigningAlg:        defaults.CASignatureAlgorithm,\n\t\tPublicHostKey:       hostPub,\n\t\tHostID:              \"5ff40d80-9007-4f28-8f49-7d4fda2f574d\",\n\t\tNodeName:            \"server01\",\n\t\tPrincipals: []string{\n\t\t\t\"127.0.0.1\",\n\t\t},\n\t\tClusterName: \"example.com\",\n\t\tRoles:       roles,\n\t\tTTL:         1 * time.Hour,\n\t})\n\tc.Assert(err, check.IsNil)\n\thostPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(hostCertBytes)\n\tc.Assert(err, check.IsNil)\n\n\ttests := []struct {\n\t\tinAddr   string\n\t\toutError bool\n\t}{\n\t\t// Correct DNS is valid.\n\t\t{\n\t\t\tinAddr:   \"server01.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Hostname only is valid.\n\t\t{\n\t\t\tinAddr:   \"server01:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// IP is valid.\n\t\t{\n\t\t\tinAddr:   \"127.0.0.1:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// UUID is valid.\n\t\t{\n\t\t\tinAddr:   \"5ff40d80-9007-4f28-8f49-7d4fda2f574d.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Wrong DNS name is invalid.\n\t\t{\n\t\t\tinAddr:   \"server02.example.com:3022\",\n\t\t\toutError: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\terr = lka.CheckHostSignature(tt.inAddr, nil, hostPublicKey)\n\t\tif tt.outError {\n\t\t\tc.Assert(err, check.NotNil)\n\t\t} else {\n\t\t\tc.Assert(err, check.IsNil)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m Map) Exclude(exclude []string) Map {\n\texcluded := make(Map)\n\tfor k, v := range m {\n\t\tvar shouldInclude = true\n\t\tfor _, toExclude := range exclude {\n\t\t\tif k == toExclude {\n\t\t\t\tshouldInclude = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif shouldInclude {\n\t\t\texcluded[k] = v\n\t\t}\n\t}\n\treturn excluded\n}", "is_vulnerable": 1}
{"code": "func TestHttpGetter_header(t *testing.T) {\n\tln := testHttpServer(t)\n\tdefer ln.Close()\n\tctx := context.Background()\n\n\tg := new(HttpGetter)\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/header\"\n\n\treq := &Request{\n\t\tDst: dst,\n\t\tu:   &u,\n\t}\n\n\t// Get it!\n\tif err := g.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\t// Verify the main file exists\n\tmainPath := filepath.Join(dst, \"main.tf\")\n\tif _, err := os.Stat(mainPath); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func apiHandler(w http.ResponseWriter, r *http.Request, timeout time.Duration, serial string) {\n\tvar buf []byte\n\tvar n int\n\tvar err error\n\n\tcid := r.Header.Get(\"X-Request-ID\")\n\tclog := log.WithFields(log.Fields{\n\t\t\"X-Request-ID\": cid,\n\t})\n\n\tif r.Method != \"POST\" {\n\t\tw.Header().Set(\"Allow\", \"POST\")\n\t\thttp.Error(w, http.StatusText(http.StatusMethodNotAllowed),\n\t\t\thttp.StatusMethodNotAllowed)\n\t\treturn\n\t}\n\n\tif buf, err = ioutil.ReadAll(r.Body); err != nil {\n\t\tclog.WithError(err).Error(\"failed reading incoming request\")\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tif len(buf) < 3 || len(buf) > 2048 {\n\t\thttp.Error(w, http.StatusText(http.StatusBadRequest),\n\t\t\thttp.StatusBadRequest)\n\t\treturn\n\t}\n\n\tif buf, err = usbProxy(buf, cid, timeout, serial); err != nil {\n\t\tclog.WithError(err).Error(\"failed usb proxy\")\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/octet-stream\")\n\tif n, err = w.Write(buf); err != nil {\n\t\tclog.WithError(err).Error(\"failed response write\")\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tif n != len(buf) {\n\t\tclog.WithError(err).WithFields(log.Fields{\n\t\t\t\"n\":   n,\n\t\t\t\"len\": len(buf),\n\t\t}).Error(\"partial response write\")\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "\treturn func(\n\t\tctx context.Context,\n\t\tmethod string,\n\t\treq, reply interface{},\n\t\tcc *grpc.ClientConn,\n\t\tinvoker grpc.UnaryInvoker,\n\t\tcallOpts ...grpc.CallOption,\n\t) error {\n\t\ti := &InterceptorInfo{\n\t\t\tMethod: method,\n\t\t\tType:   UnaryClient,\n\t\t}\n\t\tif cfg.Filter != nil && !cfg.Filter(i) {\n\t\t\treturn invoker(ctx, method, req, reply, cc, callOpts...)\n\t\t}\n\n\t\tname, attr, _ := telemetryAttributes(method, cc.Target())\n\n\t\tstartOpts := append([]trace.SpanStartOption{\n\t\t\ttrace.WithSpanKind(trace.SpanKindClient),\n\t\t\ttrace.WithAttributes(attr...),\n\t\t},\n\t\t\tcfg.SpanStartOptions...,\n\t\t)\n\n\t\tctx, span := tracer.Start(\n\t\t\tctx,\n\t\t\tname,\n\t\t\tstartOpts...,\n\t\t)\n\t\tdefer span.End()\n\n\t\tctx = inject(ctx, cfg.Propagators)\n\n\t\tif cfg.SentEvent {\n\t\t\tmessageSent.Event(ctx, 1, req)\n\t\t}\n\n\t\terr := invoker(ctx, method, req, reply, cc, callOpts...)\n\n\t\tif cfg.ReceivedEvent {\n\t\t\tmessageReceived.Event(ctx, 1, reply)\n\t\t}\n\n\t\tif err != nil {\n\t\t\ts, _ := status.FromError(err)\n\t\t\tspan.SetStatus(codes.Error, s.Message())\n\t\t\tspan.SetAttributes(statusCodeAttr(s.Code()))\n\t\t} else {\n\t\t\tspan.SetAttributes(statusCodeAttr(grpc_codes.OK))\n\t\t}\n\n\t\treturn err\n\t}", "is_vulnerable": 0}
{"code": "\tcheckLabels := func(labels []string) (gotCode bool, gotMethod bool) {\n\t\tfor _, label := range labels {\n\t\t\tswitch label {\n\t\t\tcase \"code\":\n\t\t\t\tgotCode = true\n\t\t\tcase \"method\":\n\t\t\t\tgotMethod = true\n\t\t\tdefault:\n\t\t\t\tpanic(\"metric partitioned with non-supported labels for this test\")\n\t\t\t}\n\t\t}\n\t\treturn\n\t}", "is_vulnerable": 0}
{"code": "func (a *AuthenticatorOAuth2Introspection) tokenToCache(config *AuthenticatorOAuth2IntrospectionConfiguration, i *AuthenticatorOAuth2IntrospectionResult, token string) {\n\tif !config.Cache.Enabled {\n\t\treturn\n\t}\n\n\tif a.cacheTTL != nil {\n\t\ta.tokenCache.SetWithTTL(token, i, 1, *a.cacheTTL)\n\t} else {\n\t\ta.tokenCache.Set(token, i, 1)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *Kept) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue260\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Kept: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Kept: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue260\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue260\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue260\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Age\", wireType)\n\t\t\t}\n\t\t\tm.Age = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue260\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Age |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue260(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue260\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue260\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (t *SecureTrie) GetKey(shaKey []byte) []byte {\n\tif key, ok := t.getSecKeyCache()[string(shaKey)]; ok {\n\t\treturn key\n\t}\n\treturn t.trie.db.preimage(common.BytesToHash(shaKey))\n}", "is_vulnerable": 0}
{"code": "func (evm *EVM) Create2(caller ContractRef, code []byte, gas uint64, endowment *big.Int, salt *uint256.Int) (ret []byte, contractAddr common.Address, leftOverGas uint64, err error) {\n\tcodeAndHash := &codeAndHash{code: code}\n\tcontractAddr = crypto.CreateAddress2(caller.Address(), common.Hash(salt.Bytes32()), codeAndHash.Hash().Bytes())\n\treturn evm.create(caller, codeAndHash, gas, endowment, contractAddr)\n}", "is_vulnerable": 0}
{"code": "func getRequestBody(request *http.Request) ([]byte, error) {\n\t// Read request payload\n\tbody, err := ioutil.ReadAll(request.Body)\n\t// Reset request.Body ReadCloser to prevent side-effect if re-read\n\trequest.Body = ioutil.NopCloser(bytes.NewBuffer(body))\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\treturn body, nil\n}", "is_vulnerable": 1}
{"code": "func (dolr DeploymentOperationsListResult) deploymentOperationsListResultPreparer() (*http.Request, error) {\n\tif dolr.NextLink == nil || len(to.String(dolr.NextLink)) < 1 {\n\t\treturn nil, nil\n\t}\n\treturn autorest.Prepare(&http.Request{},\n\t\tautorest.AsJSON(),\n\t\tautorest.AsGet(),\n\t\tautorest.WithBaseURL(to.String(dolr.NextLink)))\n}", "is_vulnerable": 1}
{"code": "func TestInvalidRelationTypeRestrictionsValidations(t *testing.T) {\n\tvar tests = []struct {\n\t\tname  string\n\t\tmodel *openfgapb.AuthorizationModel\n\t\terr   error\n\t}{\n\t\t{\n\t\t\tname: \"relational type which does not exist\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"reader\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"group\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: InvalidRelationTypeError(\"document\", \"reader\", \"group\", \"\"),\n\t\t},\n\t\t{\n\t\t\tname: \"relation type of form type#relation where relation doesn't exist\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"group\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"reader\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType:     \"group\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: InvalidRelationTypeError(\"document\", \"reader\", \"group\", \"admin\"),\n\t\t},\n\t\t{\n\t\t\tname: \"assignable relation with no type: this\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: AssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"assignable relation with no type: union\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: AssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"assignable relation with no type: intersection\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: AssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"assignable relation with no type: difference base\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: AssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"assignable relation with no type: difference subtract\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: AssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"non-assignable relation with a type\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{Relation: \"writer\"},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: NonAssignableRelationError(\"document\", \"reader\"),\n\t\t},\n\t\t{\n\t\t\tname: \"userset specified as allowed type, but the relation is used in a TTU rewrite\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"folder\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"member\": This(),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"member\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\":   This(),\n\t\t\t\t\t\t\t\"can_view\": TupleToUserset(\"parent\", \"member\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType:     \"folder\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"member\", //this isn't allowed\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: &InvalidRelationError{ObjectType: \"document\", Relation: \"parent\"},\n\t\t},\n\t\t{\n\t\t\tname: \"userset specified as allowed type, but the relation is used in a TTU rewrite included in a union\",\n\t\t\tmodel: &openfgapb.AuthorizationModel{\n\t\t\t\tSchemaVersion: SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"folder\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\": This(),\n\t\t\t\t\t\t\t\"viewer\": This(),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"folder\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\": This(),\n\t\t\t\t\t\t\t\"viewer\": Union(TupleToUserset(\"parent\", \"viewer\"), This()),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType:     \"folder\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"parent\", // this isn't allowed\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType:     \"folder\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"parent\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tType: \"user\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: &InvalidRelationError{ObjectType: \"document\", Relation: \"parent\"},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\terr := Validate(test.model)\n\t\t\trequire.EqualError(t, err, test.err.Error())\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *managedIdentityClient) getAzureArcSecretKey(ctx context.Context, resources []string) (string, error) {\n\t// create the request to retreive the secret key challenge provided by the HIMDS service\n\trequest, err := runtime.NewRequest(ctx, http.MethodGet, c.endpoint)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\trequest.Raw().Header.Set(headerMetadata, \"true\")\n\tq := request.Raw().URL.Query()\n\tq.Add(\"api-version\", azureArcAPIVersion)\n\tq.Add(\"resource\", strings.Join(resources, \" \"))\n\trequest.Raw().URL.RawQuery = q.Encode()\n\t// send the initial request to get the short-lived secret key\n\tresponse, err := c.azClient.Pipeline().Do(request)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\t// the endpoint is expected to return a 401 with the WWW-Authenticate header set to the location\n\t// of the secret key file. Any other status code indicates an error in the request.\n\tif response.StatusCode != 401 {\n\t\tmsg := fmt.Sprintf(\"expected a 401 response, received %d\", response.StatusCode)\n\t\treturn \"\", newAuthenticationFailedError(credNameManagedIdentity, msg, response, nil)\n\t}\n\theader := response.Header.Get(\"WWW-Authenticate\")\n\tif len(header) == 0 {\n\t\treturn \"\", errors.New(\"did not receive a value from WWW-Authenticate header\")\n\t}\n\t// the WWW-Authenticate header is expected in the following format: Basic realm=/some/file/path.key\n\tpos := strings.LastIndex(header, \"=\")\n\tif pos == -1 {\n\t\treturn \"\", fmt.Errorf(\"did not receive a correct value from WWW-Authenticate header: %s\", header)\n\t}\n\tkey, err := os.ReadFile(header[pos+1:])\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not read file (%s) contents: %v\", header[pos+1:], err)\n\t}\n\treturn string(key), nil\n}", "is_vulnerable": 1}
{"code": "\tgo func(p string) {\n\t\t_ = s.Filesystem().UnixFS().Close()\n\t\tif err := os.RemoveAll(p); err != nil {\n\t\t\tlog.WithFields(log.Fields{\"path\": p, \"error\": err}).Warn(\"failed to remove server files during deletion process\")\n\t\t}\n\t}(s.Filesystem().Path())", "is_vulnerable": 0}
{"code": "func TestIsTrustedAddress(t *testing.T) {\n\tcases := []struct {\n\t\tname    string\n\t\tcidr    string\n\t\tpeer    string\n\t\ttrusted bool\n\t}{\n\t\t{\n\t\t\tname:    \"localhost client\",\n\t\t\tcidr:    \"\",\n\t\t\tpeer:    \"127.0.0.1\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"external client without trusted cidr\",\n\t\t\tcidr:    \"\",\n\t\t\tpeer:    \"172.0.0.1\",\n\t\t\ttrusted: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr in range\",\n\t\t\tcidr:    \"172.17.0.0/16,192.17.0.0/16\",\n\t\t\tpeer:    \"172.17.0.2\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr in range with both ipv6 and ipv4\",\n\t\t\tcidr:    \"172.17.0.0/16,2001:db8:1234:1a00::/56\",\n\t\t\tpeer:    \"2001:0db8:1234:1aff:ffff:ffff:ffff:ffff\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr outside range\",\n\t\t\tcidr:    \"172.17.0.0/16,172.17.0.0/16\",\n\t\t\tpeer:    \"110.17.0.2\",\n\t\t\ttrusted: false,\n\t\t},\n\t}\n\n\tfor _, tt := range cases {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif result := isTrustedAddress(tt.peer, strings.Split(tt.cidr, \",\")); result != tt.trusted {\n\t\t\t\tt.Errorf(\"Unexpected authentication result: want %v but got %v\",\n\t\t\t\t\ttt.trusted, result)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (v V001Entry) IndexKeys() ([]string, error) {\n\tvar result []string\n\n\tfor _, sig := range v.DSSEObj.Signatures {\n\t\tif sig == nil || sig.Verifier == nil {\n\t\t\treturn result, errors.New(\"missing or malformed public key\")\n\t\t}\n\t\tkeyObj, err := x509.NewPublicKey(bytes.NewReader(*sig.Verifier))\n\t\tif err != nil {\n\t\t\treturn result, err\n\t\t}\n\n\t\tcanonKey, err := keyObj.CanonicalValue()\n\t\tif err != nil {\n\t\t\treturn result, fmt.Errorf(\"could not canonicalize key: %w\", err)\n\t\t}\n\n\t\tkeyHash := sha256.Sum256(canonKey)\n\t\tresult = append(result, \"sha256:\"+hex.EncodeToString(keyHash[:]))\n\n\t\tresult = append(result, keyObj.Subjects()...)\n\t}\n\n\tif v.DSSEObj.PayloadHash != nil {\n\t\tpayloadHashKey := strings.ToLower(fmt.Sprintf(\"%s:%s\", *v.DSSEObj.PayloadHash.Algorithm, *v.DSSEObj.PayloadHash.Value))\n\t\tresult = append(result, payloadHashKey)\n\t}\n\n\tif v.DSSEObj.EnvelopeHash != nil {\n\t\tenvelopeHashKey := strings.ToLower(fmt.Sprintf(\"%s:%s\", *v.DSSEObj.EnvelopeHash.Algorithm, *v.DSSEObj.EnvelopeHash.Value))\n\t\tresult = append(result, envelopeHashKey)\n\t}\n\n\tif v.env == nil {\n\t\tlog.Logger.Info(\"DSSEObj content or DSSE envelope is nil, returning partial set of keys\")\n\t\treturn result, nil\n\t}\n\n\tswitch v.env.PayloadType {\n\tcase in_toto.PayloadType:\n\n\t\tif v.env.Payload == \"\" {\n\t\t\tlog.Logger.Info(\"DSSEObj DSSE payload is empty\")\n\t\t\treturn result, nil\n\t\t}\n\t\tdecodedPayload, err := v.env.DecodeB64Payload()\n\t\tif err != nil {\n\t\t\treturn result, fmt.Errorf(\"could not decode envelope payload: %w\", err)\n\t\t}\n\t\tstatement, err := parseStatement(decodedPayload)\n\t\tif err != nil {\n\t\t\treturn result, err\n\t\t}\n\t\tfor _, s := range statement.Subject {\n\t\t\tfor alg, ds := range s.Digest {\n\t\t\t\tresult = append(result, alg+\":\"+ds)\n\t\t\t}\n\t\t}\n\t\t// Not all in-toto statements will contain a SLSA provenance predicate.\n\t\t// See https://github.com/in-toto/attestation/blob/main/spec/README.md#predicate\n\t\t// for other predicates.\n\t\tif predicate, err := parseSlsaPredicate(decodedPayload); err == nil {\n\t\t\tif predicate.Predicate.Materials != nil {\n\t\t\t\tfor _, s := range predicate.Predicate.Materials {\n\t\t\t\t\tfor alg, ds := range s.Digest {\n\t\t\t\t\t\tresult = append(result, alg+\":\"+ds)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tdefault:\n\t\tlog.Logger.Infof(\"Unknown DSSE envelope payloadType: %s\", v.env.PayloadType)\n\t}\n\treturn result, nil\n}", "is_vulnerable": 0}
{"code": "func getEtcHostsPath(podDir string) string {\n\treturn path.Join(podDir, \"etc-hosts\")\n}", "is_vulnerable": 0}
{"code": "func ExampleDial() {\n\t// An SSH client is represented with a ClientConn.\n\t//\n\t// To authenticate with the remote server you must pass at least one\n\t// implementation of AuthMethod via the Auth field in ClientConfig.\n\tconfig := &ssh.ClientConfig{\n\t\tUser: \"username\",\n\t\tAuth: []ssh.AuthMethod{\n\t\t\tssh.Password(\"yourpassword\"),\n\t\t},\n\t}\n\tclient, err := ssh.Dial(\"tcp\", \"yourserver.com:22\", config)\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to dial: \", err)\n\t}\n\n\t// Each ClientConn can support multiple interactive sessions,\n\t// represented by a Session.\n\tsession, err := client.NewSession()\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to create session: \", err)\n\t}\n\tdefer session.Close()\n\n\t// Once a Session is created, you can execute a single command on\n\t// the remote side using the Run method.\n\tvar b bytes.Buffer\n\tsession.Stdout = &b\n\tif err := session.Run(\"/usr/bin/whoami\"); err != nil {\n\t\tlog.Fatal(\"Failed to run: \" + err.Error())\n\t}\n\tfmt.Println(b.String())\n}", "is_vulnerable": 1}
{"code": "\thandler := func() {\n\t\tuserObj, userRel := tuple.SplitObjectRelation(req.GetUser())\n\t\tuserObjType, userObjID := tuple.SplitObject(userObj)\n\n\t\tvar sourceUserRef reverseexpand.IsUserRef\n\t\tsourceUserRef = &reverseexpand.UserRefObject{\n\t\t\tObject: &openfgav1.Object{\n\t\t\t\tType: userObjType,\n\t\t\t\tId:   userObjID,\n\t\t\t},\n\t\t}\n\n\t\tif tuple.IsTypedWildcard(userObj) {\n\t\t\tsourceUserRef = &reverseexpand.UserRefTypedWildcard{Type: tuple.GetType(userObj)}\n\t\t}\n\n\t\tif userRel != \"\" {\n\t\t\tsourceUserRef = &reverseexpand.UserRefObjectRelation{\n\t\t\t\tObjectRelation: &openfgav1.ObjectRelation{\n\t\t\t\t\tObject:   userObj,\n\t\t\t\t\tRelation: userRel,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treverseExpandResultsChan := make(chan *reverseexpand.ReverseExpandResult, 1)\n\t\tobjectsFound := atomic.Uint32{}\n\n\t\treverseExpandQuery := reverseexpand.NewReverseExpandQuery(\n\t\t\tq.datastore,\n\t\t\ttypesys,\n\t\t\treverseexpand.WithResolveNodeLimit(q.resolveNodeLimit),\n\t\t\treverseexpand.WithResolveNodeBreadthLimit(q.resolveNodeBreadthLimit),\n\t\t\treverseexpand.WithLogger(q.logger),\n\t\t)\n\n\t\tcancelCtx, cancel := context.WithCancel(ctx)\n\n\t\twg := sync.WaitGroup{}\n\n\t\terrChan := make(chan error, 1)\n\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\n\t\t\terr := reverseExpandQuery.Execute(cancelCtx, &reverseexpand.ReverseExpandRequest{\n\t\t\t\tStoreID:          req.GetStoreId(),\n\t\t\t\tObjectType:       targetObjectType,\n\t\t\t\tRelation:         targetRelation,\n\t\t\t\tUser:             sourceUserRef,\n\t\t\t\tContextualTuples: req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\tContext:          req.GetContext(),\n\t\t\t}, reverseExpandResultsChan, resolutionMetadata)\n\t\t\tif err != nil {\n\t\t\t\terrChan <- err\n\t\t\t}\n\t\t}()\n\n\t\tcheckResolver := graph.NewLocalChecker(\n\t\t\tstoragewrappers.NewCombinedTupleReader(q.datastore, req.GetContextualTuples().GetTupleKeys()),\n\t\t\tq.checkOptions...,\n\t\t)\n\t\tdefer checkResolver.Close()\n\n\t\tconcurrencyLimiterCh := make(chan struct{}, q.resolveNodeBreadthLimit)\n\n\tConsumerReadLoop:\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tbreak ConsumerReadLoop\n\t\t\tcase res, channelOpen := <-reverseExpandResultsChan:\n\t\t\t\tif !channelOpen {\n\t\t\t\t\tbreak ConsumerReadLoop\n\t\t\t\t}\n\n\t\t\t\tif !(maxResults == 0) && objectsFound.Load() >= maxResults {\n\t\t\t\t\tbreak ConsumerReadLoop\n\t\t\t\t}\n\n\t\t\t\tif res.ResultStatus == reverseexpand.NoFurtherEvalStatus {\n\t\t\t\t\tnoFurtherEvalRequiredCounter.Inc()\n\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tfurtherEvalRequiredCounter.Inc()\n\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(res *reverseexpand.ReverseExpandResult) {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\t<-concurrencyLimiterCh\n\t\t\t\t\t\twg.Done()\n\t\t\t\t\t}()\n\n\t\t\t\t\tconcurrencyLimiterCh <- struct{}{}\n\n\t\t\t\t\tresp, err := checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\t\t\t\t\tStoreID:              req.GetStoreId(),\n\t\t\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\t\t\t\t\tTupleKey:             tuple.NewTupleKey(res.Object, req.GetRelation(), req.GetUser()),\n\t\t\t\t\t\tContextualTuples:     req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\t\t\tContext:              req.GetContext(),\n\t\t\t\t\t\tResolutionMetadata: &graph.ResolutionMetadata{\n\t\t\t\t\t\t\tDepth: q.resolveNodeLimit,\n\t\t\t\t\t\t},\n\t\t\t\t\t})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tatomic.AddUint32(resolutionMetadata.QueryCount, resp.GetResolutionMetadata().DatastoreQueryCount)\n\n\t\t\t\t\tif resp.Allowed {\n\t\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t\t}\n\t\t\t\t}(res)\n\n\t\t\tcase err := <-errChan:\n\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\terr = serverErrors.AuthorizationModelResolutionTooComplex\n\t\t\t\t}\n\n\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\tbreak ConsumerReadLoop\n\t\t\t}\n\t\t}\n\n\t\tcancel()\n\t\twg.Wait()\n\t\tclose(resultsChan)\n\t}", "is_vulnerable": 0}
{"code": "func (p *OAuthProxy) GetRedirect(req *http.Request) (redirect string, err error) {\n\terr = req.ParseForm()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tredirect = req.Form.Get(\"rd\")\n\tif redirect == \"\" || !strings.HasPrefix(redirect, \"/\") || strings.HasPrefix(redirect, \"//\") {\n\t\tredirect = \"/\"\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func TestInvalidIngressAuthNoSecret(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(authTypeAnnotation)] = \"basic\"\n\ting.SetAnnotations(data)\n\n\t_, dir, _ := dummySecretContent(t)\n\tdefer os.RemoveAll(dir)\n\n\texpected := ing_errors.LocationDenied{\n\t\tReason: errors.New(\"error reading secret name from annotation: ingress rule without annotations\"),\n\t}\n\t_, err := NewParser(dir, &mockSecret{}).Parse(ing)\n\tif err.Error() != expected.Reason.Error() {\n\t\tt.Errorf(\"expected '%v' but got '%v'\", expected, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func CheckIllegal(args ...string) bool {\n\tif args == nil {\n\t\treturn false\n\t}\n\tfor _, arg := range args {\n\t\tif strings.Contains(arg, \"&\") || strings.Contains(arg, \"|\") || strings.Contains(arg, \";\") ||\n\t\t\tstrings.Contains(arg, \"$\") || strings.Contains(arg, \"'\") || strings.Contains(arg, \"`\") ||\n\t\t\tstrings.Contains(arg, \"(\") || strings.Contains(arg, \")\") || strings.Contains(arg, \"\\\"\") ||\n\t\t\tstrings.Contains(arg, \"\\n\") || strings.Contains(arg, \"\\r\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (ns *ExternalNotificationService) sendNewCommentNotificationEmail(ctx context.Context,\n\tuserID, email, lang string, rawData *schema.NewCommentTemplateRawData) {\n\tcodeContent := &schema.EmailCodeContent{\n\t\tSourceType: schema.UnsubscribeSourceType,\n\t\tNotificationSources: []constant.NotificationSource{\n\t\t\tconstant.InboxSource,\n\t\t},\n\t\tEmail:                    email,\n\t\tUserID:                   userID,\n\t\tSkipValidationLatestCode: true,\n\t}\n\t// If receiver has set language, use it to send email.\n\tif len(lang) > 0 {\n\t\tctx = context.WithValue(ctx, constant.AcceptLanguageFlag, i18n.Language(lang))\n\t}\n\ttitle, body, err := ns.emailService.NewCommentTemplate(ctx, rawData)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn\n\t}\n\n\tns.emailService.SendAndSaveCodeWithTime(\n\t\tctx, userID, email, title, body, rawData.UnsubscribeCode, codeContent.ToJSONString(), 1*24*time.Hour)\n}", "is_vulnerable": 0}
{"code": "func (f Formatter) FormatError(err error, msg string, kvList []interface{}) (prefix, argsStr string) {\n\targs := make([]interface{}, 0, 64) // using a constant here impacts perf\n\tprefix = f.prefix\n\tif f.outputFormat == outputJSON {\n\t\targs = append(args, \"logger\", prefix)\n\t\tprefix = \"\"\n\t}\n\tif f.opts.LogTimestamp {\n\t\targs = append(args, \"ts\", time.Now().Format(f.opts.TimestampFormat))\n\t}\n\tif policy := f.opts.LogCaller; policy == All || policy == Error {\n\t\targs = append(args, \"caller\", f.caller())\n\t}\n\targs = append(args, \"msg\", msg)\n\tvar loggableErr interface{}\n\tif err != nil {\n\t\tloggableErr = err.Error()\n\t}\n\targs = append(args, \"error\", loggableErr)\n\treturn f.prefix, f.render(args, kvList)\n}", "is_vulnerable": 1}
{"code": "\treturn httpclient.NamedMiddlewareFunc(ForwardedCookiesMiddlewareName, func(opts httpclient.Options, next http.RoundTripper) http.RoundTripper {\n\t\treturn httpclient.RoundTripperFunc(func(req *http.Request) (*http.Response, error) {\n\t\t\tfor _, cookie := range forwardedCookies {\n\t\t\t\treq.AddCookie(cookie)\n\t\t\t}\n\t\t\tproxyutil.ClearCookieHeader(req, allowedCookies, disallowedCookies)\n\t\t\treturn next.RoundTrip(req)\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (k *Key) ChainID() string {\n\tres := C.GoString(k.k.chain_id)\n\truntime.KeepAlive(k)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func TestInspectCommand_SecretsFromArgs(t *testing.T) {\n\topts := &inspectOpts{}\n\tcommand := inspectCommand(opts)\n\texpected := &inspectOpts{\n\t\treference: \"ref\",\n\t\tSecureFlagOpts: SecureFlagOpts{\n\t\t\tPassword:         \"password\",\n\t\t\tInsecureRegistry: true,\n\t\t\tUsername:         \"user\",\n\t\t},\n\t\toutputFormat:  cmd.OutputPlaintext,\n\t\tmaxSignatures: 100,\n\t}\n\tif err := command.ParseFlags([]string{\n\t\t\"--password\", expected.Password,\n\t\texpected.reference,\n\t\t\"-u\", expected.Username,\n\t\t\"--insecure-registry\",\n\t\t\"--output\", \"text\"}); err != nil {\n\t\tt.Fatalf(\"Parse Flag failed: %v\", err)\n\t}\n\tif err := command.Args(command, command.Flags().Args()); err != nil {\n\t\tt.Fatalf(\"Parse Args failed: %v\", err)\n\t}\n\tif *opts != *expected {\n\t\tt.Fatalf(\"Expect inspect opts: %v, got: %v\", expected, opts)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t *Template) Validate() error {\n\tvar mErr multierror.Error\n\n\t// Verify we have something to render\n\tif t.SourcePath == \"\" && t.EmbeddedTmpl == \"\" {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify a source path or have an embedded template\"))\n\t}\n\n\t// Verify we can render somewhere\n\tif t.DestPath == \"\" {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify a destination for the template\"))\n\t}\n\n\t// Verify the destination doesn't escape\n\tescaped, err := escapingfs.PathEscapesAllocViaRelative(\"task\", t.DestPath)\n\tif err != nil {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid destination path: %v\", err))\n\t} else if escaped {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"destination escapes allocation directory\"))\n\t}\n\n\t// Verify a proper change mode\n\tswitch t.ChangeMode {\n\tcase TemplateChangeModeNoop, TemplateChangeModeRestart:\n\tcase TemplateChangeModeSignal:\n\t\tif t.ChangeSignal == \"\" {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify signal value when change mode is signal\"))\n\t\t}\n\t\tif t.Envvars {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"cannot use signals with env var templates\"))\n\t\t}\n\tdefault:\n\t\t_ = multierror.Append(&mErr, TemplateChangeModeInvalidError)\n\t}\n\n\t// Verify the splay is positive\n\tif t.Splay < 0 {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify positive splay value\"))\n\t}\n\n\t// Verify the permissions\n\tif t.Perms != \"\" {\n\t\tif _, err := strconv.ParseUint(t.Perms, 8, 12); err != nil {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Failed to parse %q as octal: %v\", t.Perms, err))\n\t\t}\n\t}\n\n\treturn mErr.ErrorOrNil()\n}", "is_vulnerable": 0}
{"code": "func XMLToText(r io.Reader, breaks []string, skip []string, strict bool) (string, error) {\n\tvar result string\n\n\tdec := xml.NewDecoder(r)\n\tdec.Strict = strict\n\tfor {\n\t\tt, err := dec.Token()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tswitch v := t.(type) {\n\t\tcase xml.CharData:\n\t\t\tresult += string(v)\n\t\tcase xml.StartElement:\n\t\t\tfor _, breakElement := range breaks {\n\t\t\t\tif v.Name.Local == breakElement {\n\t\t\t\t\tresult += \"\\n\"\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, skipElement := range skip {\n\t\t\t\tif v.Name.Local == skipElement {\n\t\t\t\t\tdepth := 1\n\t\t\t\t\tfor {\n\t\t\t\t\t\tt, err := dec.Token()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t// An io.EOF here is actually an error.\n\t\t\t\t\t\t\treturn \"\", err\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tswitch t.(type) {\n\t\t\t\t\t\tcase xml.StartElement:\n\t\t\t\t\t\t\tdepth++\n\t\t\t\t\t\tcase xml.EndElement:\n\t\t\t\t\t\t\tdepth--\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif depth == 0 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result, nil\n}", "is_vulnerable": 1}
{"code": "func NewEvmos(\n\tlogger log.Logger,\n\tdb dbm.DB,\n\ttraceStore io.Writer,\n\tloadLatest bool,\n\tskipUpgradeHeights map[int64]bool,\n\thomePath string,\n\tinvCheckPeriod uint,\n\tencodingConfig simappparams.EncodingConfig,\n\tappOpts servertypes.AppOptions,\n\tbaseAppOptions ...func(*baseapp.BaseApp),\n) *Evmos {\n\tappCodec := encodingConfig.Codec\n\tcdc := encodingConfig.Amino\n\tinterfaceRegistry := encodingConfig.InterfaceRegistry\n\n\teip712.SetEncodingConfig(encodingConfig)\n\n\t// setup memiavl if it's enabled in config\n\tbaseAppOptions = memiavlstore.SetupMemIAVL(logger, homePath, appOpts, false, false, baseAppOptions)\n\n\t// Setup Mempool and Proposal Handlers\n\tbaseAppOptions = append(baseAppOptions, func(app *baseapp.BaseApp) {\n\t\tmempool := mempool.NoOpMempool{}\n\t\tapp.SetMempool(mempool)\n\t\thandler := baseapp.NewDefaultProposalHandler(mempool, app)\n\t\tapp.SetPrepareProposal(handler.PrepareProposalHandler())\n\t\tapp.SetProcessProposal(handler.ProcessProposalHandler())\n\t})\n\n\t// NOTE we use custom transaction decoder that supports the sdk.Tx interface instead of sdk.StdTx\n\tbApp := baseapp.NewBaseApp(\n\t\tName,\n\t\tlogger,\n\t\tdb,\n\t\tencodingConfig.TxConfig.TxDecoder(),\n\t\tbaseAppOptions...,\n\t)\n\tbApp.SetCommitMultiStoreTracer(traceStore)\n\tbApp.SetVersion(version.Version)\n\tbApp.SetInterfaceRegistry(interfaceRegistry)\n\n\tkeys, memKeys, tkeys := StoreKeys()\n\n\tapp := &Evmos{\n\t\tBaseApp:           bApp,\n\t\tcdc:               cdc,\n\t\tappCodec:          appCodec,\n\t\tinterfaceRegistry: interfaceRegistry,\n\t\tinvCheckPeriod:    invCheckPeriod,\n\t\tkeys:              keys,\n\t\ttkeys:             tkeys,\n\t\tmemKeys:           memKeys,\n\t}\n\n\t// init params keeper and subspaces\n\tapp.ParamsKeeper = initParamsKeeper(appCodec, cdc, keys[paramstypes.StoreKey], tkeys[paramstypes.TStoreKey])\n\n\t// get authority address\n\tauthAddr := authtypes.NewModuleAddress(govtypes.ModuleName).String()\n\n\t// set the BaseApp's parameter store\n\tapp.ConsensusParamsKeeper = consensusparamkeeper.NewKeeper(appCodec, keys[consensusparamtypes.StoreKey], authAddr)\n\tbApp.SetParamStore(&app.ConsensusParamsKeeper)\n\n\t// add capability keeper and ScopeToModule for ibc module\n\tapp.CapabilityKeeper = capabilitykeeper.NewKeeper(appCodec, keys[capabilitytypes.StoreKey], memKeys[capabilitytypes.MemStoreKey])\n\n\tscopedIBCKeeper := app.CapabilityKeeper.ScopeToModule(ibcexported.ModuleName)\n\tscopedTransferKeeper := app.CapabilityKeeper.ScopeToModule(ibctransfertypes.ModuleName)\n\tscopedICAHostKeeper := app.CapabilityKeeper.ScopeToModule(icahosttypes.SubModuleName)\n\n\t// Applications that wish to enforce statically created ScopedKeepers should call `Seal` after creating\n\t// their scoped modules in `NewApp` with `ScopeToModule`\n\tapp.CapabilityKeeper.Seal()\n\n\t// use custom Ethermint account for contracts\n\tapp.AccountKeeper = authkeeper.NewAccountKeeper(\n\t\tappCodec, keys[authtypes.StoreKey],\n\t\tevmostypes.ProtoAccount, maccPerms,\n\t\tsdk.GetConfig().GetBech32AccountAddrPrefix(),\n\t\tauthAddr,\n\t)\n\tapp.BankKeeper = bankkeeper.NewBaseKeeper(\n\t\tappCodec, keys[banktypes.StoreKey], app.AccountKeeper, app.BlockedAddrs(), authAddr,\n\t)\n\tstakingKeeper := stakingkeeper.NewKeeper(\n\t\tappCodec, keys[stakingtypes.StoreKey], app.AccountKeeper, app.BankKeeper, authAddr,\n\t)\n\tapp.DistrKeeper = distrkeeper.NewKeeper(\n\t\tappCodec, keys[distrtypes.StoreKey], app.AccountKeeper, app.BankKeeper,\n\t\tstakingKeeper, authtypes.FeeCollectorName, authAddr,\n\t)\n\tapp.SlashingKeeper = slashingkeeper.NewKeeper(\n\t\tappCodec, app.LegacyAmino(), keys[slashingtypes.StoreKey], stakingKeeper, authAddr,\n\t)\n\tapp.FeeGrantKeeper = feegrantkeeper.NewKeeper(appCodec, keys[feegrant.StoreKey], app.AccountKeeper)\n\tapp.UpgradeKeeper = *upgradekeeper.NewKeeper(skipUpgradeHeights, keys[upgradetypes.StoreKey], appCodec, homePath, app.BaseApp, authAddr)\n\n\tapp.AuthzKeeper = authzkeeper.NewKeeper(keys[authzkeeper.StoreKey], appCodec, app.MsgServiceRouter(), app.AccountKeeper)\n\n\ttracer := cast.ToString(appOpts.Get(srvflags.EVMTracer))\n\n\t// Create Ethermint keepers\n\tapp.FeeMarketKeeper = feemarketkeeper.NewKeeper(\n\t\tappCodec, authtypes.NewModuleAddress(govtypes.ModuleName),\n\t\tkeys[feemarkettypes.StoreKey],\n\t\ttkeys[feemarkettypes.TransientKey],\n\t\tapp.GetSubspace(feemarkettypes.ModuleName),\n\t)\n\n\tevmKeeper := evmkeeper.NewKeeper(\n\t\tappCodec, keys[evmtypes.StoreKey], tkeys[evmtypes.TransientKey], authtypes.NewModuleAddress(govtypes.ModuleName),\n\t\tapp.AccountKeeper, app.BankKeeper, stakingKeeper, app.FeeMarketKeeper,\n\t\ttracer, app.GetSubspace(evmtypes.ModuleName),\n\t)\n\n\tapp.EvmKeeper = evmKeeper\n\n\t// Create IBC Keeper\n\tapp.IBCKeeper = ibckeeper.NewKeeper(\n\t\tappCodec, keys[ibcexported.StoreKey], app.GetSubspace(ibcexported.ModuleName), stakingKeeper, app.UpgradeKeeper, scopedIBCKeeper,\n\t)\n\n\t// register the proposal types\n\tgovRouter := govv1beta1.NewRouter()\n\tgovRouter.AddRoute(govtypes.RouterKey, govv1beta1.ProposalHandler).\n\t\tAddRoute(upgradetypes.RouterKey, upgrade.NewSoftwareUpgradeProposalHandler(&app.UpgradeKeeper)).\n\t\tAddRoute(ibcclienttypes.RouterKey, ibcclient.NewClientProposalHandler(app.IBCKeeper.ClientKeeper)).\n\t\tAddRoute(erc20types.RouterKey, erc20.NewErc20ProposalHandler(&app.Erc20Keeper)).\n\t\tAddRoute(vestingtypes.RouterKey, vesting.NewVestingProposalHandler(&app.VestingKeeper))\n\n\tgovConfig := govtypes.Config{\n\t\tMaxMetadataLen: 5000,\n\t}\n\tgovKeeper := govkeeper.NewKeeper(\n\t\tappCodec, keys[govtypes.StoreKey], app.AccountKeeper, app.BankKeeper,\n\t\tstakingKeeper, app.MsgServiceRouter(), govConfig, authAddr,\n\t)\n\n\t// Set legacy router for backwards compatibility with gov v1beta1\n\tgovKeeper.SetLegacyRouter(govRouter)\n\n\t// Evmos Keeper\n\tapp.InflationKeeper = inflationkeeper.NewKeeper(\n\t\tkeys[inflationtypes.StoreKey], appCodec, authtypes.NewModuleAddress(govtypes.ModuleName),\n\t\tapp.AccountKeeper, app.BankKeeper, app.DistrKeeper, stakingKeeper,\n\t\tauthtypes.FeeCollectorName,\n\t)\n\n\t// register the staking hooks\n\t// NOTE: stakingKeeper above is passed by reference, so that it will contain these hooks\n\t// NOTE: Distr, Slashing and Claim must be created before calling the Hooks method to avoid returning a Keeper without its table generated\n\tstakingKeeper.SetHooks(\n\t\tstakingtypes.NewMultiStakingHooks(\n\t\t\tapp.DistrKeeper.Hooks(),\n\t\t\tapp.SlashingKeeper.Hooks(),\n\t\t),\n\t)\n\n\tapp.StakingKeeper = *stakingKeeper\n\n\tapp.VestingKeeper = vestingkeeper.NewKeeper(\n\t\tkeys[vestingtypes.StoreKey], authtypes.NewModuleAddress(govtypes.ModuleName), appCodec,\n\t\tapp.AccountKeeper, app.BankKeeper, app.DistrKeeper, app.StakingKeeper, govKeeper, // NOTE: app.govKeeper not defined yet, use govKeeper\n\t)\n\n\tapp.Erc20Keeper = erc20keeper.NewKeeper(\n\t\tkeys[erc20types.StoreKey], appCodec, authtypes.NewModuleAddress(govtypes.ModuleName),\n\t\tapp.AccountKeeper, app.BankKeeper, app.EvmKeeper, app.StakingKeeper,\n\t\tapp.AuthzKeeper, &app.TransferKeeper,\n\t)\n\n\tapp.RevenueKeeper = revenuekeeper.NewKeeper(\n\t\tkeys[revenuetypes.StoreKey], appCodec, authtypes.NewModuleAddress(govtypes.ModuleName),\n\t\tapp.BankKeeper, app.DistrKeeper, app.AccountKeeper, app.EvmKeeper,\n\t\tauthtypes.FeeCollectorName,\n\t)\n\n\tapp.TransferKeeper = transferkeeper.NewKeeper(\n\t\tappCodec, keys[ibctransfertypes.StoreKey], app.GetSubspace(ibctransfertypes.ModuleName),\n\t\tapp.IBCKeeper.ChannelKeeper, // ICS4 Wrapper: claims IBC middleware\n\t\tapp.IBCKeeper.ChannelKeeper, &app.IBCKeeper.PortKeeper,\n\t\tapp.AccountKeeper, app.BankKeeper, scopedTransferKeeper,\n\t\tapp.Erc20Keeper, // Add ERC20 Keeper for ERC20 transfers\n\t)\n\tchainID := bApp.ChainID()\n\t// We call this after setting the hooks to ensure that the hooks are set on the keeper\n\tevmKeeper.WithPrecompiles(\n\t\tevmkeeper.AvailablePrecompiles(\n\t\t\tchainID,\n\t\t\t*stakingKeeper,\n\t\t\tapp.DistrKeeper,\n\t\t\tapp.BankKeeper,\n\t\t\tapp.Erc20Keeper,\n\t\t\tapp.VestingKeeper,\n\t\t\tapp.AuthzKeeper,\n\t\t\tapp.TransferKeeper,\n\t\t\tapp.IBCKeeper.ChannelKeeper,\n\t\t),\n\t)\n\n\tepochsKeeper := epochskeeper.NewKeeper(appCodec, keys[epochstypes.StoreKey])\n\tapp.EpochsKeeper = *epochsKeeper.SetHooks(\n\t\tepochskeeper.NewMultiEpochHooks(\n\t\t\t// insert epoch hooks receivers here\n\t\t\tapp.InflationKeeper.Hooks(),\n\t\t),\n\t)\n\n\tapp.GovKeeper = *govKeeper.SetHooks(\n\t\tgovtypes.NewMultiGovHooks(\n\t\t\tapp.VestingKeeper.Hooks(),\n\t\t),\n\t)\n\n\tapp.EvmKeeper = app.EvmKeeper.SetHooks(\n\t\tevmkeeper.NewMultiEvmHooks(\n\t\t\tapp.Erc20Keeper.Hooks(),\n\t\t\tapp.RevenueKeeper.Hooks(),\n\t\t),\n\t)\n\n\t// NOTE: app.Erc20Keeper is already initialized elsewhere\n\n\t// Override the ICS20 app module\n\ttransferModule := transfer.NewAppModule(app.TransferKeeper)\n\n\t// Create the app.ICAHostKeeper\n\tapp.ICAHostKeeper = icahostkeeper.NewKeeper(\n\t\tappCodec, app.keys[icahosttypes.StoreKey],\n\t\tapp.GetSubspace(icahosttypes.SubModuleName),\n\t\tapp.IBCKeeper.ChannelKeeper,\n\t\tapp.IBCKeeper.ChannelKeeper,\n\t\t&app.IBCKeeper.PortKeeper,\n\t\tapp.AccountKeeper,\n\t\tscopedICAHostKeeper,\n\t\tbApp.MsgServiceRouter(),\n\t)\n\n\t// create host IBC module\n\ticaHostIBCModule := icahost.NewIBCModule(app.ICAHostKeeper)\n\n\t/*\n\t\tCreate Transfer Stack\n\n\t\ttransfer stack contains (from bottom to top):\n\t\t\t- ERC-20 Middleware\n\t\t \t- Recovery Middleware\n\t\t \t- Airdrop Claims Middleware\n\t\t\t- IBC Transfer\n\n\t\tSendPacket, since it is originating from the application to core IBC:\n\t\t \ttransferKeeper.SendPacket -> claim.SendPacket -> recovery.SendPacket -> erc20.SendPacket -> channel.SendPacket\n\n\t\tRecvPacket, message that originates from core IBC and goes down to app, the flow is the other way\n\t\t\tchannel.RecvPacket -> erc20.OnRecvPacket -> recovery.OnRecvPacket -> claim.OnRecvPacket -> transfer.OnRecvPacket\n\t*/\n\n\t// create IBC module from top to bottom of stack\n\tvar transferStack porttypes.IBCModule\n\n\ttransferStack = transfer.NewIBCModule(app.TransferKeeper)\n\ttransferStack = erc20.NewIBCMiddleware(app.Erc20Keeper, transferStack)\n\n\t// Create static IBC router, add transfer route, then set and seal it\n\tibcRouter := porttypes.NewRouter()\n\tibcRouter.\n\t\tAddRoute(icahosttypes.SubModuleName, icaHostIBCModule).\n\t\tAddRoute(ibctransfertypes.ModuleName, transferStack)\n\n\tapp.IBCKeeper.SetRouter(ibcRouter)\n\n\t// create evidence keeper with router\n\tevidenceKeeper := evidencekeeper.NewKeeper(\n\t\tappCodec, keys[evidencetypes.StoreKey], &app.StakingKeeper, app.SlashingKeeper,\n\t)\n\t// If evidence needs to be handled for the app, set routes in router here and seal\n\tapp.EvidenceKeeper = *evidenceKeeper\n\n\t/****  Module Options ****/\n\n\t// NOTE: Any module instantiated in the module manager that is later modified\n\t// must be passed by reference here.\n\tapp.mm = module.NewManager(\n\t\t// SDK app modules\n\t\tgenutil.NewAppModule(\n\t\t\tapp.AccountKeeper, app.StakingKeeper, app.BaseApp.DeliverTx,\n\t\t\tencodingConfig.TxConfig,\n\t\t),\n\t\tauth.NewAppModule(appCodec, app.AccountKeeper, authsims.RandomGenesisAccounts, app.GetSubspace(authtypes.ModuleName)),\n\t\tbank.NewAppModule(appCodec, app.BankKeeper, app.AccountKeeper, app.GetSubspace(banktypes.ModuleName)),\n\t\tcapability.NewAppModule(appCodec, *app.CapabilityKeeper, false),\n\t\tgov.NewAppModule(appCodec, &app.GovKeeper, app.AccountKeeper, app.BankKeeper, app.GetSubspace(govtypes.ModuleName)),\n\t\tslashing.NewAppModule(appCodec, app.SlashingKeeper, app.AccountKeeper, app.BankKeeper, app.StakingKeeper, app.GetSubspace(slashingtypes.ModuleName)),\n\t\tdistr.NewAppModule(appCodec, app.DistrKeeper, app.AccountKeeper, app.BankKeeper, app.StakingKeeper, app.GetSubspace(distrtypes.ModuleName)),\n\t\tstaking.NewAppModule(appCodec, &app.StakingKeeper, app.AccountKeeper, app.BankKeeper, app.GetSubspace(stakingtypes.ModuleName)),\n\t\tupgrade.NewAppModule(&app.UpgradeKeeper),\n\t\tevidence.NewAppModule(app.EvidenceKeeper),\n\t\tparams.NewAppModule(app.ParamsKeeper),\n\t\tfeegrantmodule.NewAppModule(appCodec, app.AccountKeeper, app.BankKeeper, app.FeeGrantKeeper, app.interfaceRegistry),\n\t\tauthzmodule.NewAppModule(appCodec, app.AuthzKeeper, app.AccountKeeper, app.BankKeeper, app.interfaceRegistry),\n\t\tconsensus.NewAppModule(appCodec, app.ConsensusParamsKeeper),\n\n\t\t// ibc modules\n\t\tibc.NewAppModule(app.IBCKeeper),\n\t\tica.NewAppModule(nil, &app.ICAHostKeeper),\n\t\ttransferModule,\n\t\t// Ethermint app modules\n\t\tevm.NewAppModule(app.EvmKeeper, app.AccountKeeper, app.GetSubspace(evmtypes.ModuleName)),\n\t\tfeemarket.NewAppModule(app.FeeMarketKeeper, app.GetSubspace(feemarkettypes.ModuleName)),\n\t\t// Evmos app modules\n\t\tinflation.NewAppModule(app.InflationKeeper, app.AccountKeeper, *app.StakingKeeper.Keeper,\n\t\t\tapp.GetSubspace(inflationtypes.ModuleName)),\n\t\terc20.NewAppModule(app.Erc20Keeper, app.AccountKeeper,\n\t\t\tapp.GetSubspace(erc20types.ModuleName)),\n\t\tepochs.NewAppModule(appCodec, app.EpochsKeeper),\n\t\tvesting.NewAppModule(app.VestingKeeper, app.AccountKeeper, app.BankKeeper, *app.StakingKeeper.Keeper),\n\t\trevenue.NewAppModule(app.RevenueKeeper, app.AccountKeeper,\n\t\t\tapp.GetSubspace(revenuetypes.ModuleName)),\n\t)\n\n\t// During begin block slashing happens after distr.BeginBlocker so that\n\t// there is nothing left over in the validator fee pool, to keep the\n\t// CanWithdrawInvariant invariant.\n\t// NOTE: upgrade module must go first to handle software upgrades.\n\t// NOTE: staking module is required if HistoricalEntries param > 0.\n\t// NOTE: capability module's beginblocker must come before any modules using capabilities (e.g. IBC)\n\tapp.mm.SetOrderBeginBlockers(\n\t\tupgradetypes.ModuleName,\n\t\tcapabilitytypes.ModuleName,\n\t\t// Note: epochs' begin should be \"real\" start of epochs, we keep epochs beginblock at the beginning\n\t\tepochstypes.ModuleName,\n\t\tfeemarkettypes.ModuleName,\n\t\tevmtypes.ModuleName,\n\t\tdistrtypes.ModuleName,\n\t\tslashingtypes.ModuleName,\n\t\tevidencetypes.ModuleName,\n\t\tstakingtypes.ModuleName,\n\t\tibcexported.ModuleName,\n\t\t// no-op modules\n\t\tibctransfertypes.ModuleName,\n\t\ticatypes.ModuleName,\n\t\tauthtypes.ModuleName,\n\t\tbanktypes.ModuleName,\n\t\tgovtypes.ModuleName,\n\t\tgenutiltypes.ModuleName,\n\t\tauthz.ModuleName,\n\t\tfeegrant.ModuleName,\n\t\tparamstypes.ModuleName,\n\t\tvestingtypes.ModuleName,\n\t\tinflationtypes.ModuleName,\n\t\terc20types.ModuleName,\n\t\trevenuetypes.ModuleName,\n\t\tconsensusparamtypes.ModuleName,\n\t)\n\n\t// NOTE: fee market module must go last in order to retrieve the block gas used.\n\tapp.mm.SetOrderEndBlockers(\n\t\tgovtypes.ModuleName,\n\t\tstakingtypes.ModuleName,\n\t\tevmtypes.ModuleName,\n\t\tfeemarkettypes.ModuleName,\n\t\t// Note: epochs' endblock should be \"real\" end of epochs, we keep epochs endblock at the end\n\t\tepochstypes.ModuleName,\n\t\t// no-op modules\n\t\tibcexported.ModuleName,\n\t\tibctransfertypes.ModuleName,\n\t\ticatypes.ModuleName,\n\t\tcapabilitytypes.ModuleName,\n\t\tauthtypes.ModuleName,\n\t\tbanktypes.ModuleName,\n\t\tdistrtypes.ModuleName,\n\t\tslashingtypes.ModuleName,\n\t\tgenutiltypes.ModuleName,\n\t\tevidencetypes.ModuleName,\n\t\tauthz.ModuleName,\n\t\tfeegrant.ModuleName,\n\t\tparamstypes.ModuleName,\n\t\tupgradetypes.ModuleName,\n\t\t// Evmos modules\n\t\tvestingtypes.ModuleName,\n\t\tinflationtypes.ModuleName,\n\t\terc20types.ModuleName,\n\t\trevenuetypes.ModuleName,\n\t\tconsensusparamtypes.ModuleName,\n\t)\n\n\t// NOTE: The genutils module must occur after staking so that pools are\n\t// properly initialized with tokens from genesis accounts.\n\t// NOTE: Capability module must occur first so that it can initialize any capabilities\n\t// so that other modules that want to create or claim capabilities afterwards in InitChain\n\t// can do so safely.\n\tapp.mm.SetOrderInitGenesis(\n\t\t// SDK modules\n\t\tcapabilitytypes.ModuleName,\n\t\tauthtypes.ModuleName,\n\t\tbanktypes.ModuleName,\n\t\tdistrtypes.ModuleName,\n\t\tstakingtypes.ModuleName,\n\t\tslashingtypes.ModuleName,\n\t\tgovtypes.ModuleName,\n\t\tibcexported.ModuleName,\n\t\t// Ethermint modules\n\t\t// evm module denomination is used by the revenue module, in AnteHandle\n\t\tevmtypes.ModuleName,\n\t\t// NOTE: feemarket module needs to be initialized before genutil module:\n\t\t// gentx transactions use MinGasPriceDecorator.AnteHandle\n\t\tfeemarkettypes.ModuleName,\n\t\tgenutiltypes.ModuleName,\n\t\tevidencetypes.ModuleName,\n\t\tibctransfertypes.ModuleName,\n\t\ticatypes.ModuleName,\n\t\tauthz.ModuleName,\n\t\tfeegrant.ModuleName,\n\t\tparamstypes.ModuleName,\n\t\tupgradetypes.ModuleName,\n\t\t// Evmos modules\n\t\tvestingtypes.ModuleName,\n\t\tinflationtypes.ModuleName,\n\t\terc20types.ModuleName,\n\t\tepochstypes.ModuleName,\n\t\trevenuetypes.ModuleName,\n\t\tconsensusparamtypes.ModuleName,\n\t)\n\n\tapp.configurator = module.NewConfigurator(app.appCodec, app.MsgServiceRouter(), app.GRPCQueryRouter())\n\tapp.mm.RegisterServices(app.configurator)\n\n\t// add test gRPC service for testing gRPC queries in isolation\n\t// testdata.RegisterTestServiceServer(app.GRPCQueryRouter(), testdata.TestServiceImpl{})\n\n\t// create the simulation manager and define the order of the modules for deterministic simulations\n\t//\n\t// NOTE: this is not required apps that don't use the simulator for fuzz testing\n\t// transactions\n\toverrideModules := map[string]module.AppModuleSimulation{\n\t\tauthtypes.ModuleName: auth.NewAppModule(app.appCodec, app.AccountKeeper, authsims.RandomGenesisAccounts, app.GetSubspace(authtypes.ModuleName)),\n\t}\n\tapp.sm = module.NewSimulationManagerFromAppModules(app.mm.Modules, overrideModules)\n\n\tautocliv1.RegisterQueryServer(app.GRPCQueryRouter(), runtimeservices.NewAutoCLIQueryService(app.mm.Modules))\n\n\treflectionSvc, err := runtimeservices.NewReflectionService()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treflectionv1.RegisterReflectionServiceServer(app.GRPCQueryRouter(), reflectionSvc)\n\n\tapp.sm.RegisterStoreDecoders()\n\n\t// initialize stores\n\tapp.MountKVStores(keys)\n\tapp.MountTransientStores(tkeys)\n\tapp.MountMemoryStores(memKeys)\n\n\t// load state streaming if enabled\n\tif _, _, err := streaming.LoadStreamingServices(bApp, appOpts, appCodec, logger, keys); err != nil {\n\t\tfmt.Printf(\"failed to load state streaming: %s\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// wire up the versiondb's `StreamingService` and `MultiStore`.\n\tvar queryMultiStore sdk.MultiStore\n\n\tstreamers := cast.ToStringSlice(appOpts.Get(streaming.OptStoreStreamers))\n\tif slices.Contains(streamers, versionDB) {\n\t\tqueryMultiStore, err = app.setupVersionDB(homePath, keys, tkeys, memKeys)\n\t\tif err != nil {\n\t\t\tpanic(errorsmod.Wrap(err, \"error on versionDB setup\"))\n\t\t}\n\t}\n\n\t// initialize BaseApp\n\tapp.SetInitChainer(app.InitChainer)\n\tapp.SetBeginBlocker(app.BeginBlocker)\n\n\tmaxGasWanted := cast.ToUint64(appOpts.Get(srvflags.EVMMaxTxGasWanted))\n\n\tapp.setAnteHandler(encodingConfig.TxConfig, maxGasWanted)\n\tapp.setPostHandler()\n\tapp.SetEndBlocker(app.EndBlocker)\n\tapp.setupUpgradeHandlers()\n\n\tif loadLatest {\n\t\tif err := app.LoadLatestVersion(); err != nil {\n\t\t\tlogger.Error(\"error on loading last version\", \"err\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// queryMultiStore will be only defined when using versionDB\n\t\t// when defined, we check if the iavl & versionDB versions match\n\t\tif queryMultiStore != nil {\n\t\t\tv1 := queryMultiStore.LatestVersion()\n\t\t\tv2 := app.LastBlockHeight()\n\t\t\tif v1 > 0 && v1 != v2 {\n\t\t\t\ttmos.Exit(fmt.Sprintf(\"versiondb lastest version %d don't match iavl latest version %d\", v1, v2))\n\t\t\t}\n\t\t}\n\t}\n\n\tapp.ScopedIBCKeeper = scopedIBCKeeper\n\tapp.ScopedTransferKeeper = scopedTransferKeeper\n\n\t// Finally start the tpsCounter.\n\tapp.tpsCounter = newTPSCounter(logger)\n\tgo func() {\n\t\t// Unfortunately golangci-lint is so pedantic\n\t\t// so we have to ignore this error explicitly.\n\t\t_ = app.tpsCounter.start(context.Background())\n\t}()\n\n\treturn app\n}", "is_vulnerable": 0}
{"code": "\tDescribe(\"parseRestFilters\", func() {\n\t\tvar r sqlRepository\n\t\tvar options rest.QueryOptions\n\n\t\tBeforeEach(func() {\n\t\t\tr = sqlRepository{}\n\t\t})\n\n\t\tIt(\"returns nil if filters is empty\", func() {\n\t\t\toptions.Filters = nil\n\t\t\tExpect(r.parseRestFilters(context.Background(), options)).To(BeNil())\n\t\t})\n\n\t\tIt(\"returns a '=' condition for 'id' filter\", func() {\n\t\t\toptions.Filters = map[string]interface{}{\"id\": \"123\"}\n\t\t\tExpect(r.parseRestFilters(context.Background(), options)).To(Equal(squirrel.And{squirrel.Eq{\"id\": \"123\"}}))\n\t\t})\n\n\t\tIt(\"returns a 'in' condition for multiples 'id' filters\", func() {\n\t\t\toptions.Filters = map[string]interface{}{\"id\": []string{\"123\", \"456\"}}\n\t\t\tExpect(r.parseRestFilters(context.Background(), options)).To(Equal(squirrel.And{squirrel.Eq{\"id\": []string{\"123\", \"456\"}}}))\n\t\t})\n\n\t\tIt(\"returns a 'like' condition for other filters\", func() {\n\t\t\toptions.Filters = map[string]interface{}{\"name\": \"joe\"}\n\t\t\tExpect(r.parseRestFilters(context.Background(), options)).To(Equal(squirrel.And{squirrel.Like{\"name\": \"joe%\"}}))\n\t\t})\n\n\t\tIt(\"uses the custom filter\", func() {\n\t\t\tr.filterMappings = map[string]filterFunc{\n\t\t\t\t\"test\": func(field string, value interface{}) squirrel.Sqlizer {\n\t\t\t\t\treturn squirrel.Gt{field: value}\n\t\t\t\t},\n\t\t\t}\n\t\t\toptions.Filters = map[string]interface{}{\"test\": 100}\n\t\t\tExpect(r.parseRestFilters(context.Background(), options)).To(Equal(squirrel.And{squirrel.Gt{\"test\": 100}}))\n\t\t})\n\t})\n})", "is_vulnerable": 0}
{"code": "func (m *UnrecognizedWithEmbed) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: UnrecognizedWithEmbed: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: UnrecognizedWithEmbed: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field UnrecognizedWithEmbed_Embedded\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.UnrecognizedWithEmbed_Embedded.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Field2 = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func getFeaturesHandler(w http.ResponseWriter, r *http.Request) {\n\tfeatures := []string{}\n\tif comps.Supported() {\n\t\tfeatures = append(features, \"components\")\n\t}\n\tif configs.Supported() {\n\t\tfeatures = append(features, \"configurations\")\n\t}\n\tif inst.CheckPlatform() == \"kubernetes\" {\n\t\tfeatures = append(features, \"status\")\n\t}\n\trespondWithJSON(w, 200, features)\n}", "is_vulnerable": 1}
{"code": "func (client TagsClient) DeleteValueSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func JSONToYAML(j []byte) ([]byte, error) {\n\t// Convert the JSON to an object.\n\tvar jsonObj interface{}\n\n\t// We are using yaml.Unmarshal here (instead of json.Unmarshal) because the\n\t// Go JSON library doesn't try to pick the right number type (int, float,\n\t// etc.) when unmarshalling to interface{}, it just picks float64\n\t// universally. go-yaml does go through the effort of picking the right\n\t// number type, so we can preserve number type throughout this process.\n\terr := yaml.Unmarshal(j, &jsonObj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Marshal this object into YAML.\n\tyamlBytes, err := yaml.Marshal(jsonObj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn yamlBytes, nil\n}", "is_vulnerable": 0}
{"code": "func testHttpServerProxy(t *testing.T, upstreamHost string) net.Listener {\n\tt.Helper()\n\n\tln, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\tmux := http.NewServeMux()\n\n\tmux.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tt.Logf(\"serving proxy: %v: %#+v\", r.URL.Path, r.Header)\n\t\t// create the reverse proxy\n\t\tproxy := httputil.NewSingleHostReverseProxy(r.URL)\n\t\t// Note that ServeHttp is non blocking & uses a go routine under the hood\n\t\tproxy.ServeHTTP(w, r)\n\t})\n\n\tvar server http.Server\n\tserver.Handler = mux\n\tgo server.Serve(ln)\n\n\treturn ln\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\n\t\t\ting := buildIngress()\n\n\t\t\tdata := map[string]string{}\n\t\t\tdata[parser.GetAnnotationWithPrefix(\"fastcgi-index\")] = tt.index\n\t\t\tdata[parser.GetAnnotationWithPrefix(\"fastcgi-params-configmap\")] = tt.configmapname\n\t\t\ting.SetAnnotations(data)\n\n\t\t\tm := &mockConfigMap{\n\t\t\t\textraConfigMap: map[string]map[string]string{\n\t\t\t\t\ttt.configmapname: tt.configmap,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tgot, err := NewParser(m).Parse(ing)\n\t\t\tif (err != nil) != tt.wantErr {\n\t\t\t\tt.Errorf(\"fastcgi.Parse() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(got, tt.want) {\n\t\t\t\tt.Errorf(\"fastcgi.Parse() = %v, want %v\", got, tt.want)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func (r *MySQL) ProbeWithDataVerification(db *sql.DB) error {\n\tfor k, v := range r.Data {\n\t\tlog.Debugf(\"[%s / %s / %s] - Verifying Data - [%s] : [%s]\", r.ProbeKind, r.ProbeName, r.ProbeTag, k, v)\n\t\tsql, err := r.getSQL(k)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlog.Debugf(\"[%s / %s / %s] - SQL - [%s]\", r.ProbeKind, r.ProbeName, r.ProbeTag, sql)\n\t\trows, err := db.Query(sql)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !rows.Next() {\n\t\t\trows.Close()\n\t\t\treturn fmt.Errorf(\"No data found for [%s]\", k)\n\t\t}\n\t\t//check the value is equal to the value in data\n\t\tvar value string\n\t\tif err := rows.Scan(&value); err != nil {\n\t\t\trows.Close()\n\t\t\treturn err\n\t\t}\n\t\tif value != v {\n\t\t\trows.Close()\n\t\t\treturn fmt.Errorf(\"Value not match for [%s] expected [%s] got [%s] \", k, v, value)\n\t\t}\n\t\trows.Close()\n\t\tlog.Debugf(\"[%s / %s / %s] - Data Verified Successfully! - [%s] : [%s]\", r.ProbeKind, r.ProbeName, r.ProbeTag, k, v)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func repoRootFromVCSPaths(importPath string, security web.SecurityMode, vcsPaths []*vcsPath) (*RepoRoot, error) {\n\tif str.HasPathPrefix(importPath, \"example.net\") {\n\t\t// TODO(rsc): This should not be necessary, but it's required to keep\n\t\t// tests like ../../testdata/script/mod_get_extra.txt from using the network.\n\t\t// That script has everything it needs in the replacement set, but it is still\n\t\t// doing network calls.\n\t\treturn nil, fmt.Errorf(\"no modules on example.net\")\n\t}\n\tif importPath == \"rsc.io\" {\n\t\t// This special case allows tests like ../../testdata/script/govcs.txt\n\t\t// to avoid making any network calls. The module lookup for a path\n\t\t// like rsc.io/nonexist.svn/foo needs to not make a network call for\n\t\t// a lookup on rsc.io.\n\t\treturn nil, fmt.Errorf(\"rsc.io is not a module\")\n\t}\n\t// A common error is to use https://packagepath because that's what\n\t// hg and git require. Diagnose this helpfully.\n\tif prefix := httpPrefix(importPath); prefix != \"\" {\n\t\t// The importPath has been cleaned, so has only one slash. The pattern\n\t\t// ignores the slashes; the error message puts them back on the RHS at least.\n\t\treturn nil, fmt.Errorf(\"%q not allowed in import path\", prefix+\"//\")\n\t}\n\tfor _, srv := range vcsPaths {\n\t\tif !str.HasPathPrefix(importPath, srv.pathPrefix) {\n\t\t\tcontinue\n\t\t}\n\t\tm := srv.regexp.FindStringSubmatch(importPath)\n\t\tif m == nil {\n\t\t\tif srv.pathPrefix != \"\" {\n\t\t\t\treturn nil, importErrorf(importPath, \"invalid %s import path %q\", srv.pathPrefix, importPath)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// Build map of named subexpression matches for expand.\n\t\tmatch := map[string]string{\n\t\t\t\"prefix\": srv.pathPrefix + \"/\",\n\t\t\t\"import\": importPath,\n\t\t}\n\t\tfor i, name := range srv.regexp.SubexpNames() {\n\t\t\tif name != \"\" && match[name] == \"\" {\n\t\t\t\tmatch[name] = m[i]\n\t\t\t}\n\t\t}\n\t\tif srv.vcs != \"\" {\n\t\t\tmatch[\"vcs\"] = expand(match, srv.vcs)\n\t\t}\n\t\tif srv.repo != \"\" {\n\t\t\tmatch[\"repo\"] = expand(match, srv.repo)\n\t\t}\n\t\tif srv.check != nil {\n\t\t\tif err := srv.check(match); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tvcs := vcsByCmd(match[\"vcs\"])\n\t\tif vcs == nil {\n\t\t\treturn nil, fmt.Errorf(\"unknown version control system %q\", match[\"vcs\"])\n\t\t}\n\t\tif err := CheckGOVCS(vcs, match[\"root\"]); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tvar repoURL string\n\t\tif !srv.schemelessRepo {\n\t\t\trepoURL = match[\"repo\"]\n\t\t} else {\n\t\t\trepo := match[\"repo\"]\n\t\t\tvar ok bool\n\t\t\trepoURL, ok = interceptVCSTest(repo, vcs, security)\n\t\t\tif !ok {\n\t\t\t\tscheme := vcs.Scheme[0] // default to first scheme\n\t\t\t\tif vcs.PingCmd != \"\" {\n\t\t\t\t\t// If we know how to test schemes, scan to find one.\n\t\t\t\t\tfor _, s := range vcs.Scheme {\n\t\t\t\t\t\tif security == web.SecureOnly && !vcs.isSecureScheme(s) {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif vcs.Ping(s, repo) == nil {\n\t\t\t\t\t\t\tscheme = s\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\trepoURL = scheme + \"://\" + repo\n\t\t\t}\n\t\t}\n\t\trr := &RepoRoot{\n\t\t\tRepo: repoURL,\n\t\t\tRoot: match[\"root\"],\n\t\t\tVCS:  vcs,\n\t\t}\n\t\treturn rr, nil\n\t}\n\treturn nil, errUnknownSite\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CrackFilesList(ctx context.Context, in *clientpb.CrackFile, opts ...grpc.CallOption) (*clientpb.CrackFiles, error) {\n\tout := new(clientpb.CrackFiles)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/CrackFilesList\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (l Logger) WithValues(keysAndValues ...any) Logger {\n\tif l.sink == nil {\n\t\treturn l\n\t}\n\tl.setSink(l.sink.WithValues(keysAndValues...))\n\treturn l\n}", "is_vulnerable": 0}
{"code": "func logNamespaceDiagnostics(spec *specs.Spec) {\n\tsawMountNS := false\n\tsawUserNS := false\n\tsawUTSNS := false\n\tfor _, ns := range spec.Linux.Namespaces {\n\t\tswitch ns.Type {\n\t\tcase specs.CgroupNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join cgroup namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create cgroup namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.IPCNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join IPC namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create IPC namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.MountNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join mount namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawMountNS = true\n\t\tcase specs.NetworkNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join network namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create network namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.PIDNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join PID namespace, sorry about that\")\n\t\t\t} else {\n\t\t\t\tlogrus.Debugf(\"unable to create PID namespace, sorry about that\")\n\t\t\t}\n\t\tcase specs.UserNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join user namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawUserNS = true\n\t\tcase specs.UTSNamespace:\n\t\t\tif ns.Path != \"\" {\n\t\t\t\tlogrus.Debugf(\"unable to join UTS namespace %q, creating a new one\", ns.Path)\n\t\t\t}\n\t\t\tsawUTSNS = true\n\t\t}\n\t}\n\tif !sawMountNS {\n\t\tlogrus.Debugf(\"mount namespace not requested, but creating a new one anyway\")\n\t}\n\tif !sawUserNS {\n\t\tlogrus.Debugf(\"user namespace not requested, but creating a new one anyway\")\n\t}\n\tif !sawUTSNS {\n\t\tlogrus.Debugf(\"UTS namespace not requested, but creating a new one anyway\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestOIAP(t *testing.T) {\n\trwc := openTPMOrSkip(t)\n\tdefer rwc.Close()\n\n\t// Get auth info from OIAP.\n\toiapr, err := oiap(rwc)\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't run OIAP:\", err)\n\t}\n\tdefer oiapr.Close(rwc)\n}", "is_vulnerable": 0}
{"code": "\tgo func() {\n\t\tfor {\n\t\t\tif c.Timeout != 0 {\n\t\t\t\tif err := c.Server.SetDeadline(time.Now().Add(time.Duration(c.Timeout) * time.Second)); err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t\tl, err := c.ReadL()\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif _, err := local.Write(c.RB[2+16 : 2+16+l]); err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()", "is_vulnerable": 1}
{"code": "func (r *Router) ServeTCP(conn tcp.WriteCloser) {\n\t// Handling Non-TLS TCP connection early if there is neither HTTP(S) nor TLS\n\t// routers on the entryPoint, and if there is at least one non-TLS TCP router.\n\t// In the case of a non-TLS TCP client (that does not \"send\" first), we would\n\t// block forever on clientHelloInfo, which is why we want to detect and\n\t// handle that case first and foremost.\n\tif r.muxerTCP.HasRoutes() && !r.muxerTCPTLS.HasRoutes() && !r.muxerHTTPS.HasRoutes() {\n\t\tconnData, err := tcpmuxer.NewConnData(\"\", conn, nil)\n\t\tif err != nil {\n\t\t\tlog.WithoutContext().Errorf(\"Error while reading TCP connection data: %v\", err)\n\t\t\tconn.Close()\n\t\t\treturn\n\t\t}\n\n\t\thandler, _ := r.muxerTCP.Match(connData)\n\t\t// If there is a handler matching the connection metadata,\n\t\t// we let it handle the connection.\n\t\tif handler != nil {\n\t\t\thandler.ServeTCP(conn)\n\t\t\treturn\n\t\t}\n\t\t// Otherwise, we keep going because:\n\t\t// 1) we could be in the case where we have HTTP routers.\n\t\t// 2) if it is an HTTPS request, even though we do not have any TLS routers,\n\t\t// we still need to reply with a 404.\n\t}\n\n\t// TODO -- Check if ProxyProtocol changes the first bytes of the request\n\tbr := bufio.NewReader(conn)\n\thello, err := clientHelloInfo(br)\n\tif err != nil {\n\t\tconn.Close()\n\t\treturn\n\t}\n\n\t// Remove read/write deadline and delegate this to underlying tcp server (for now only handled by HTTP Server)\n\terr = conn.SetReadDeadline(time.Time{})\n\tif err != nil {\n\t\tlog.WithoutContext().Errorf(\"Error while setting read deadline: %v\", err)\n\t}\n\n\terr = conn.SetWriteDeadline(time.Time{})\n\tif err != nil {\n\t\tlog.WithoutContext().Errorf(\"Error while setting write deadline: %v\", err)\n\t}\n\n\tconnData, err := tcpmuxer.NewConnData(hello.serverName, conn, hello.protos)\n\tif err != nil {\n\t\tlog.WithoutContext().Errorf(\"Error while reading TCP connection data: %v\", err)\n\t\tconn.Close()\n\t\treturn\n\t}\n\n\tif !hello.isTLS {\n\t\thandler, _ := r.muxerTCP.Match(connData)\n\t\tswitch {\n\t\tcase handler != nil:\n\t\t\thandler.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\tcase r.httpForwarder != nil:\n\t\t\tr.httpForwarder.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\tdefault:\n\t\t\tconn.Close()\n\t\t}\n\t\treturn\n\t}\n\n\t// For real, the handler eventually used for HTTPS is (almost) always the same:\n\t// it is the httpsForwarder that is used for all HTTPS connections that match\n\t// (which is also incidentally the same used in the last block below for 404s).\n\t// The added value from doing Match is to find and use the specific TLS config\n\t// (wrapped inside the returned handler) requested for the given HostSNI.\n\thandlerHTTPS, catchAllHTTPS := r.muxerHTTPS.Match(connData)\n\tif handlerHTTPS != nil && !catchAllHTTPS {\n\t\t// In order not to depart from the behavior in 2.6, we only allow an HTTPS router\n\t\t// to take precedence over a TCP-TLS router if it is _not_ an HostSNI(*) router (so\n\t\t// basically any router that has a specific HostSNI based rule).\n\t\thandlerHTTPS.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\treturn\n\t}\n\n\t// Contains also TCP TLS passthrough routes.\n\thandlerTCPTLS, catchAllTCPTLS := r.muxerTCPTLS.Match(connData)\n\tif handlerTCPTLS != nil && !catchAllTCPTLS {\n\t\thandlerTCPTLS.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\treturn\n\t}\n\n\t// Fallback on HTTPS catchAll.\n\t// We end up here for e.g. an HTTPS router that only has a PathPrefix rule,\n\t// which under the scenes is counted as an HostSNI(*) rule.\n\tif handlerHTTPS != nil {\n\t\thandlerHTTPS.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\treturn\n\t}\n\n\t// Fallback on TCP TLS catchAll.\n\tif handlerTCPTLS != nil {\n\t\thandlerTCPTLS.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\treturn\n\t}\n\n\t// needed to handle 404s for HTTPS, as well as all non-Host (e.g. PathPrefix) matches.\n\tif r.httpsForwarder != nil {\n\t\tr.httpsForwarder.ServeTCP(r.GetConn(conn, hello.peeked))\n\t\treturn\n\t}\n\n\tconn.Close()\n}", "is_vulnerable": 1}
{"code": "func createDefaultConfigFileIfNotExists() error {\n\tdefaultFilePath := GetDefaultConfigFilePath()\n\tif isExists(defaultFilePath) {\n\t\treturn nil\n\t}\n\tfolderPath := filepath.Dir(defaultFilePath)\n\tif !isExists(folderPath) {\n\t\terr := os.Mkdir(folderPath, folderPermission)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tf, err := os.Create(defaultFilePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn f.Close()\n}", "is_vulnerable": 1}
{"code": "func NotContainsf(t TestingT, s interface{}, contains interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotContainsf(t, s, contains, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\t\tgo func() {\n\t\t\tc.Collect(metricCh)\n\t\t\tclose(endCh)\n\t\t}()", "is_vulnerable": 1}
{"code": "func mainExitCode() int {\n\tdefer func() {\n\t\t// log error in case of panic()\n\t\tif err := recover(); err != nil {\n\t\t\tlog.Errorf(\"program panicked: %s\", err)\n\t\t\tlog.Errorf(\"Stack: %s\", debug.Stack())\n\t\t}\n\t}()\n\n\tvar err error\n\tstart := time.Now()\n\n\tversionFlag := flag.Bool(\"version\", false, \"show version number and exit\")\n\tflag.Usage = usage\n\tflag.Parse()\n\n\tif *versionFlag {\n\t\tfmt.Fprintf(os.Stderr, \"sshproxy version %s\\n\", SshproxyVersion)\n\t\treturn 0\n\t}\n\n\tconfigFile := defaultConfig\n\tif flag.NArg() != 0 {\n\t\tconfigFile = flag.Arg(0)\n\t}\n\n\tcurrentUser, err := user.Current()\n\tif err != nil {\n\t\tlog.Fatalf(\"Cannot find current user: %s\", err)\n\t}\n\tusername := currentUser.Username\n\n\tsshConnection := os.Getenv(\"SSH_CONNECTION\")\n\tif sshConnection == \"\" {\n\t\tlog.Fatal(\"No SSH_CONNECTION environment variable\")\n\t}\n\n\tsshInfos, err := NewSSHInfo(sshConnection)\n\tif err != nil {\n\t\tlog.Fatalf(\"parsing SSH_CONNECTION '%s': %s\", sshConnection, err)\n\t}\n\n\tconninfo := &ConnInfo{\n\t\tStart: start,\n\t\tUser:  username,\n\t\tSSH:   sshInfos,\n\t}\n\n\tsid := utils.CalcSessionID(conninfo.User, conninfo.Start, conninfo.SSH.Src())\n\n\tgroups, err := utils.GetGroups()\n\tif err != nil {\n\t\tlog.Fatalf(\"Cannot find current user groups: %s\", err)\n\t}\n\n\tconfig, err := utils.LoadConfig(configFile, username, sid, start, groups)\n\tif err != nil {\n\t\tlog.Fatalf(\"Reading configuration '%s': %s\", configFile, err)\n\t}\n\n\tlogformat := fmt.Sprintf(\"%%{time:2006-01-02 15:04:05} %%{level} %s: %%{message}\", sid)\n\tsyslogformat := fmt.Sprintf(\"%%{level} %s: %%{message}\", sid)\n\tutils.MustSetupLogging(\"sshproxy\", config.Log, logformat, syslogformat, config.Debug)\n\n\tfor _, configLine := range utils.PrintConfig(config, groups) {\n\t\tlog.Debug(configLine)\n\t}\n\n\tlog.Infof(\"%s connected from %s to sshd listening on %s\", username, sshInfos.Src(), sshInfos.Dst())\n\tdefer log.Info(\"disconnected\")\n\n\tcli, err := utils.NewEtcdClient(config, log)\n\tif err != nil {\n\t\tlog.Errorf(\"Cannot contact etcd cluster to update state: %v\", err)\n\t}\n\n\tif cli != nil && cli.IsAlive() {\n\t\tif config.MaxConnectionsPerUser > 0 {\n\t\t\tuserConnectionsCount, err := cli.GetUserConnectionsCount(username)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"Getting user connections count: %s\", err)\n\t\t\t}\n\t\t\tlog.Debugf(\"Number of connections of %s: %d\", username, userConnectionsCount)\n\t\t\tif userConnectionsCount >= config.MaxConnectionsPerUser {\n\t\t\t\tfmt.Fprintln(os.Stderr, \"Too many simultaneous connections\")\n\t\t\t\tlog.Fatalf(\"Max connections per user reached for %s\", username)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif config.Etcd.Mandatory {\n\t\t\tlog.Fatal(\"Etcd is mandatory but unavailable\")\n\t\t}\n\t}\n\n\tservice, hostport, forceCommand, commandMustMatch, etcdKeyTTL, environment, err := findDestination(cli, username, config.Routes, sshInfos.Dst(), config.CheckInterval)\n\tswitch {\n\tcase err != nil:\n\t\tlog.Fatalf(\"Finding destination: %s\", err)\n\tcase hostport == \"\":\n\t\terrorBanner := \"\"\n\t\tif cli != nil && cli.IsAlive() {\n\t\t\terrorBanner, _, _ = cli.GetErrorBanner()\n\t\t}\n\t\tif errorBanner == \"\" {\n\t\t\terrorBanner = config.ErrorBanner\n\t\t}\n\t\tif errorBanner != \"\" {\n\t\t\tfmt.Println(errorBanner)\n\t\t}\n\t\tlog.Fatal(\"Cannot find a valid destination\")\n\t}\n\thost, port, err := utils.SplitHostPort(hostport)\n\tif err != nil {\n\t\tlog.Fatalf(\"Invalid destination '%s': %s\", hostport, err)\n\t}\n\n\tlog.Debugf(\"service = %s\", service)\n\n\t// merge service environment with global environment\n\tfor k, v := range environment {\n\t\tconfig.Environment[k] = v\n\t}\n\tsetEnvironment(config.Environment)\n\n\t// waitgroup and channel to stop our background command when exiting.\n\tvar wg sync.WaitGroup\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer func() {\n\t\tcancel()\n\t\twg.Wait()\n\t}()\n\n\tsigChannel := make(chan os.Signal, 1)\n\tsignal.Notify(sigChannel, os.Interrupt, syscall.SIGHUP, syscall.SIGTERM)\n\tgo func() {\n\t\ts := <-sigChannel\n\t\tlog.Infof(\"Got signal %s, exiting\", s)\n\t\tcancel()\n\t}()\n\n\tvar etcdPath string\n\tvar tmpKeepAliveChan <-chan *clientv3.LeaseKeepAliveResponse\n\t// Register destination in etcd and keep it alive while running.\n\tif cli != nil && cli.IsAlive() {\n\t\tkey := fmt.Sprintf(\"%s@%s\", username, service)\n\t\tkeepAliveChan, eP, err := cli.SetDestination(ctx, key, sshInfos.Dst(), hostport, etcdKeyTTL)\n\t\tetcdPath = eP\n\t\tif err != nil {\n\t\t\tlog.Warningf(\"setting destination in etcd: %v\", err)\n\t\t}\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase isChanAlive := <-keepAliveChan:\n\t\t\t\t\tif isChanAlive == nil {\n\t\t\t\t\t\tcli.Disable()\n\t\t\t\t\t\ttmpKeepAliveChan, err = cli.NewLease(ctx)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlog.Warningf(\"getting a new lease in etcd: %v\", err)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tkeepAliveChan = tmpKeepAliveChan\n\t\t\t\t\t\t\tcli.Enable()\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// launch background command\n\tif config.BgCommand != \"\" {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tcmd := prepareBackgroundCommand(ctx, config.BgCommand, config.Debug)\n\t\t\tif _, err := runCommand(cmd, false); err != nil {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t// stay silent as the session is now finished\n\t\t\t\tdefault:\n\t\t\t\t\tlog.Errorf(\"error running background command: %s\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// Launch goroutine which exits sshproxy if it's attached to PID 1\n\t// (which means its ssh parent connection is dead).\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(1 * time.Second):\n\t\t\t\tif os.Getppid() == 1 {\n\t\t\t\t\tlog.Warning(\"SSH parent connection is dead\")\n\t\t\t\t\tcancel()\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\toriginalCmd := os.Getenv(\"SSH_ORIGINAL_COMMAND\")\n\tlog.Debugf(\"original command = %s\", originalCmd)\n\n\tinteractiveCommand := term.IsTerminal(os.Stdout.Fd())\n\tlog.Debugf(\"interactiveCommand = %v\", interactiveCommand)\n\n\tsshArgs := config.SSH.Args\n\tenvSshproxyArgs := strings.Fields(os.Getenv(\"SSHPROXY_ARGS\"))\n\tif len(envSshproxyArgs) != 0 {\n\t\tsshArgs = append(sshArgs, envSshproxyArgs...)\n\t}\n\tif port != utils.DefaultSSHPort {\n\t\tsshArgs = append(sshArgs, \"-p\", port)\n\t}\n\tdoCmd := \"\"\n\tif forceCommand != \"\" {\n\t\tlog.Debugf(\"forceCommand = %s\", forceCommand)\n\t\tdoCmd = forceCommand\n\t} else if originalCmd != \"\" {\n\t\tdoCmd = originalCmd\n\t}\n\tcommandTranslated := false\n\tif doCmd != \"\" {\n\t\tif commandMustMatch && originalCmd != doCmd {\n\t\t\tlog.Errorf(\"error executing proxied ssh command: originalCmd \\\"%s\\\" does not match forceCommand \\\"%s\\\"\", originalCmd, forceCommand)\n\t\t\treturn 1\n\t\t}\n\t\tfor fromCmd, translateCmdConf := range config.TranslateCommands {\n\t\t\tif doCmd == fromCmd {\n\t\t\t\tlog.Debugf(\"translateCmdConf = %+v\", translateCmdConf)\n\t\t\t\tsshArgs = append(sshArgs, translateCmdConf.SSHArgs...)\n\t\t\t\tsshArgs = append(sshArgs, host, \"--\", translateCmdConf.Command)\n\t\t\t\tif config.Dump != \"\" && translateCmdConf.DisableDump {\n\t\t\t\t\tconfig.Dump = \"etcd\"\n\t\t\t\t}\n\t\t\t\tcommandTranslated = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !commandTranslated {\n\t\t\tif interactiveCommand {\n\t\t\t\t// Force TTY allocation because the user probably asked for it.\n\t\t\t\tsshArgs = append(sshArgs, \"-t\")\n\t\t\t}\n\t\t\tsshArgs = append(sshArgs, host, \"--\", doCmd)\n\t\t}\n\t} else {\n\t\tsshArgs = append(sshArgs, host)\n\t}\n\tcmd := exec.CommandContext(ctx, config.SSH.Exe, sshArgs...)\n\tlog.Debugf(\"command = %s %q\", cmd.Path, cmd.Args)\n\n\tvar recorder *Recorder\n\tif config.Dump != \"\" {\n\t\trecorder = NewRecorder(conninfo, config.Dump, doCmd, config.EtcdStatsInterval.Duration(), config.LogStatsInterval.Duration(), config.DumpLimitSize, config.DumpLimitWindow.Duration())\n\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\trecorder.Run(ctx, cli, etcdPath)\n\t\t}()\n\t}\n\n\tlog.Infof(\"proxied to %s (service: %s)\", hostport, service)\n\n\tvar rc int\n\tif interactiveCommand {\n\t\trc, err = runTtyCommand(cmd, recorder)\n\t} else {\n\t\trc, err = runStdCommand(cmd, recorder)\n\t}\n\tif err != nil {\n\t\tlog.Errorf(\"error executing proxied ssh command: %s\", err)\n\t}\n\n\t// return command exit code\n\treturn rc\n}", "is_vulnerable": 0}
{"code": "func bitField(nd data.UnixFSData) bitfield.Bitfield {\n\tbf := bitfield.NewBitfield(int(nd.FieldFanout().Must().Int()))\n\tbf.SetBytes(nd.FieldData().Must().Bytes())\n\treturn bf\n}", "is_vulnerable": 1}
{"code": "func (m *kubeGenericRuntimeManager) getSeccompProfile(annotations map[string]string, containerName string,\n\tpodSecContext *v1.PodSecurityContext, containerSecContext *v1.SecurityContext, fallbackToRuntimeDefault bool) *runtimeapi.SecurityProfile {\n\t// container fields are applied first\n\tif containerSecContext != nil && containerSecContext.SeccompProfile != nil {\n\t\treturn fieldSeccompProfile(containerSecContext.SeccompProfile, m.seccompProfileRoot, fallbackToRuntimeDefault)\n\t}\n\n\t// when container seccomp is not defined, try to apply from pod field\n\tif podSecContext != nil && podSecContext.SeccompProfile != nil {\n\t\treturn fieldSeccompProfile(podSecContext.SeccompProfile, m.seccompProfileRoot, fallbackToRuntimeDefault)\n\t}\n\n\tif fallbackToRuntimeDefault {\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t}\n\t}\n\n\treturn &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *Duration) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowDuration\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Duration: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Duration: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Seconds\", wireType)\n\t\t\t}\n\t\t\tm.Seconds = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowDuration\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Seconds |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Nanos\", wireType)\n\t\t\t}\n\t\t\tm.Nanos = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowDuration\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Nanos |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipDuration(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthDuration\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthDuration\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"unsafe query, 'with' replacement\", func(t *testing.T) {\n\t\tr := New(\n\t\t\tQuery(`is_array([1, 2, 3]) with is_array as count`),\n\t\t\tUnsafeBuiltins(map[string]struct{}{\"count\": {}}),\n\t\t)\n\t\tif _, err := r.Eval(ctx); err == nil || !strings.Contains(err.Error(), unsafeCountExprWith) {\n\t\t\tt.Fatalf(\"Expected unsafe built-in error but got %v\", err)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (t *MultiResolver) TenantIDs(ctx context.Context) ([]string, error) {\n\t//lint:ignore faillint wrapper around upstream method\n\torgID, err := user.ExtractOrgID(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\torgIDs := strings.Split(orgID, tenantIDsLabelSeparator)\n\tfor _, orgID := range orgIDs {\n\t\tif err := ValidTenantID(orgID); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif containsUnsafePathSegments(orgID) {\n\t\t\treturn nil, errInvalidTenantID\n\t\t}\n\t}\n\n\treturn NormalizeTenantIDs(orgIDs), nil\n}", "is_vulnerable": 0}
{"code": "func (m *IntMerge) Unmarshal(dAtA []byte) error {\n\tvar hasFields [1]uint64\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: IntMerge: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: IntMerge: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int64\", wireType)\n\t\t\t}\n\t\t\tm.Int64 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Int64 |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\thasFields[0] |= uint64(0x00000001)\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32\", wireType)\n\t\t\t}\n\t\t\tm.Int32 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Int32 |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sint32\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.Sint32 = v\n\t\t\thasFields[0] |= uint64(0x00000002)\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sint64\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\tm.Sint64 = int64(v)\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint64\", wireType)\n\t\t\t}\n\t\t\tm.Uint64 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Uint64 |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint32\", wireType)\n\t\t\t}\n\t\t\tm.Uint32 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Uint32 |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\thasFields[0] |= uint64(0x00000004)\n\t\tcase 7:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fixed64\", wireType)\n\t\t\t}\n\t\t\tm.Fixed64 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Fixed64 = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 8:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fixed32\", wireType)\n\t\t\t}\n\t\t\tm.Fixed32 = 0\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Fixed32 = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sfixed32\", wireType)\n\t\t\t}\n\t\t\tm.Sfixed32 = 0\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Sfixed32 = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\thasFields[0] |= uint64(0x00000008)\n\t\tcase 10:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sfixed64\", wireType)\n\t\t\t}\n\t\t\tm.Sfixed64 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Sfixed64 = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 11:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bool\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Bool = bool(v != 0)\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnmarshalmerge(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthUnmarshalmerge\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnmarshalmerge\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\tif hasFields[0]&uint64(0x00000001) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"Int64\")\n\t}\n\tif hasFields[0]&uint64(0x00000002) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"Sint32\")\n\t}\n\tif hasFields[0]&uint64(0x00000004) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"Uint32\")\n\t}\n\tif hasFields[0]&uint64(0x00000008) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"Sfixed32\")\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func ParseQuery(source *Source) (*QueryDocument, error) {\n\tp := parser{\n\t\tlexer:         lexer.New(source),\n\t\tmaxTokenLimit: 0, // 0 is the default value\n\t}\n\treturn p.parseQueryDocument(), p.err\n}", "is_vulnerable": 1}
{"code": "func (m *manager) noRemainingOwnerLabels(crb *rbacv1.ClusterRoleBinding) (bool, error) {\n\tfor k, v := range crb.Labels {\n\t\tif v == owner {\n\t\t\tif exists, err := m.ownerExists(k); exists || err != nil {\n\t\t\t\treturn false, err\n\t\t\t}\n\t\t}\n\n\t\tif k == rtbOwnerLabel {\n\t\t\tif exists, err := m.ownerExists(v); exists || err != nil {\n\t\t\t\treturn false, err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true, nil\n}", "is_vulnerable": 0}
{"code": "func TestJobEndpointConnect_gatewayProxyForBridge(t *testing.T) {\n\tt.Parallel()\n\n\tt.Run(\"nil\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(nil)\n\t\trequire.Nil(t, result)\n\t})\n\n\tt.Run(\"nil proxy\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tIngress: &structs.ConsulIngressConfigEntry{\n\t\t\t\tListeners: []*structs.ConsulIngressListener{{\n\t\t\t\t\tPort:     3000,\n\t\t\t\t\tProtocol: \"tcp\",\n\t\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\t\tName: \"service1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  helper.TimeToPtr(defaultConnectTimeout),\n\t\t\tEnvoyGatewayNoDefaultBind:       true,\n\t\t\tEnvoyGatewayBindTaggedAddresses: false,\n\t\t\tEnvoyGatewayBindAddresses: map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\t\"service1\": {\n\t\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\t\tPort:    3000,\n\t\t\t\t}},\n\t\t}, result)\n\t})\n\n\tt.Run(\"ingress set defaults\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConnectTimeout: helper.TimeToPtr(2 * time.Second),\n\t\t\t\tConfig:         map[string]interface{}{\"foo\": 1},\n\t\t\t},\n\t\t\tIngress: &structs.ConsulIngressConfigEntry{\n\t\t\t\tListeners: []*structs.ConsulIngressListener{{\n\t\t\t\t\tPort:     3000,\n\t\t\t\t\tProtocol: \"tcp\",\n\t\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\t\tName: \"service1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  helper.TimeToPtr(2 * time.Second),\n\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\tEnvoyGatewayNoDefaultBind:       true,\n\t\t\tEnvoyGatewayBindTaggedAddresses: false,\n\t\t\tEnvoyGatewayBindAddresses: map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\t\"service1\": {\n\t\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\t\tPort:    3000,\n\t\t\t\t}},\n\t\t}, result)\n\t})\n\n\tt.Run(\"ingress leave as-is\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\t},\n\t\t\tIngress: &structs.ConsulIngressConfigEntry{\n\t\t\t\tListeners: []*structs.ConsulIngressListener{{\n\t\t\t\t\tPort:     3000,\n\t\t\t\t\tProtocol: \"tcp\",\n\t\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\t\tName: \"service1\",\n\t\t\t\t\t}},\n\t\t\t\t}},\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  nil,\n\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\tEnvoyGatewayNoDefaultBind:       false,\n\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\tEnvoyGatewayBindAddresses:       nil,\n\t\t}, result)\n\t})\n\n\tt.Run(\"terminating set defaults\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConnectTimeout:        helper.TimeToPtr(2 * time.Second),\n\t\t\t\tEnvoyDNSDiscoveryType: \"STRICT_DNS\",\n\t\t\t},\n\t\t\tTerminating: &structs.ConsulTerminatingConfigEntry{\n\t\t\t\tServices: []*structs.ConsulLinkedService{{\n\t\t\t\t\tName:     \"service1\",\n\t\t\t\t\tCAFile:   \"/cafile.pem\",\n\t\t\t\t\tCertFile: \"/certfile.pem\",\n\t\t\t\t\tKeyFile:  \"/keyfile.pem\",\n\t\t\t\t\tSNI:      \"\",\n\t\t\t\t}},\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  helper.TimeToPtr(2 * time.Second),\n\t\t\tEnvoyGatewayNoDefaultBind:       true,\n\t\t\tEnvoyGatewayBindTaggedAddresses: false,\n\t\t\tEnvoyDNSDiscoveryType:           \"STRICT_DNS\",\n\t\t\tEnvoyGatewayBindAddresses: map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\t\"default\": {\n\t\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\t\tPort:    -1,\n\t\t\t\t},\n\t\t\t},\n\t\t}, result)\n\t})\n\n\tt.Run(\"terminating leave as-is\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\t},\n\t\t\tTerminating: &structs.ConsulTerminatingConfigEntry{\n\t\t\t\tServices: []*structs.ConsulLinkedService{{\n\t\t\t\t\tName: \"service1\",\n\t\t\t\t}},\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  nil,\n\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\tEnvoyGatewayNoDefaultBind:       false,\n\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\tEnvoyGatewayBindAddresses:       nil,\n\t\t}, result)\n\t})\n\n\tt.Run(\"mesh set defaults\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConnectTimeout: helper.TimeToPtr(2 * time.Second),\n\t\t\t},\n\t\t\tMesh: &structs.ConsulMeshConfigEntry{\n\t\t\t\t// nothing\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  helper.TimeToPtr(2 * time.Second),\n\t\t\tEnvoyGatewayNoDefaultBind:       true,\n\t\t\tEnvoyGatewayBindTaggedAddresses: false,\n\t\t\tEnvoyGatewayBindAddresses: map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\t\"lan\": {\n\t\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\t\tPort:    -1,\n\t\t\t\t},\n\t\t\t\t\"wan\": {\n\t\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\t\tPort:    -1,\n\t\t\t\t},\n\t\t\t},\n\t\t}, result)\n\t})\n\n\tt.Run(\"mesh leave as-is\", func(t *testing.T) {\n\t\tresult := gatewayProxyForBridge(&structs.ConsulGateway{\n\t\t\tProxy: &structs.ConsulGatewayProxy{\n\t\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\t},\n\t\t\tMesh: &structs.ConsulMeshConfigEntry{\n\t\t\t\t// nothing\n\t\t\t},\n\t\t})\n\t\trequire.Equal(t, &structs.ConsulGatewayProxy{\n\t\t\tConnectTimeout:                  nil,\n\t\t\tConfig:                          map[string]interface{}{\"foo\": 1},\n\t\t\tEnvoyGatewayNoDefaultBind:       false,\n\t\t\tEnvoyGatewayBindTaggedAddresses: true,\n\t\t\tEnvoyGatewayBindAddresses:       nil,\n\t\t}, result)\n\t})\n\n}", "is_vulnerable": 1}
{"code": "func (l *lua) matchesListenerDirection(isInboundListener bool) bool {\n\treturn (!isInboundListener && l.Listener == \"outbound\") || (isInboundListener && l.Listener == \"inbound\")\n}", "is_vulnerable": 0}
{"code": "func Test_ValidateStrings(t *testing.T) {\n\t_, err := validateStrings(\"anything here\", errors.New(\"test error\"))\n\tassert.Error(t, err)\n\tassert.Contains(t, err.Error(), \"test error\")\n\n\t_, err = validateStrings(\"\\x87\\x01\", nil)\n\tassert.Error(t, err)\n\tassert.Contains(t, err.Error(), \"is not a valid UTF-8 string\")\n\n\tvalue, err := validateStrings(\"anything here\", nil)\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"anything here\", value)\n\n\t_, err = validateStrings([]string{\"abc\", \"\\x87\\x01\"}, nil)\n\tassert.Error(t, err)\n\tassert.Contains(t, err.Error(), \"is not a valid UTF-8 string\")\n}", "is_vulnerable": 0}
{"code": "\t\t\tfunc(t *testing.T) {\n\t\t\t\tsuite := testCase\n\t\t\t\tc := &check{t, testCase.serverType}\n\n\t\t\t\tsuite.SetUpSuite(c)\n\t\t\t\tsuite.TestUserCreate(c)\n\t\t\t\tsuite.TestUserPolicyEscalationBug(c)\n\t\t\t\tsuite.TestPolicyCreate(c)\n\t\t\t\tsuite.TestCannedPolicies(c)\n\t\t\t\tsuite.TestGroupAddRemove(c)\n\t\t\t\tsuite.TestServiceAccountOpsByAdmin(c)\n\t\t\t\tsuite.TestServiceAccountPrivilegeEscalationBug(c)\n\t\t\t\tsuite.TestServiceAccountOpsByUser(c)\n\t\t\t\tsuite.TestAddServiceAccountPerms(c)\n\t\t\t\tsuite.TearDownSuite(c)\n\t\t\t},", "is_vulnerable": 0}
{"code": "func DefaultAPIClientCerts(certDir string) []ClientCertInfo {\n\treturn []ClientCertInfo{\n\t\tDefaultOpenshiftLoopbackClientCertInfo(certDir),\n\t\tDefaultClusterAdminClientCertInfo(certDir),\n\t\tDefaultRouterClientCertInfo(certDir),\n\t\tDefaultRegistryClientCertInfo(certDir),\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *mockViewUser) UserByID(string, string) (*user_view_model.UserView, error) {\n\treturn &user_view_model.UserView{\n\t\tState:    int32(user_model.UserStateActive),\n\t\tUserName: \"UserName\",\n\t\tHumanView: &user_view_model.HumanView{\n\t\t\tFirstName:                \"FirstName\",\n\t\t\tInitRequired:             m.InitRequired,\n\t\t\tPasswordInitRequired:     m.PasswordInitRequired,\n\t\t\tPasswordSet:              m.PasswordSet,\n\t\t\tPasswordChangeRequired:   m.PasswordChangeRequired,\n\t\t\tIsEmailVerified:          m.IsEmailVerified,\n\t\t\tOTPState:                 m.OTPState,\n\t\t\tMFAMaxSetUp:              m.MFAMaxSetUp,\n\t\t\tMFAInitSkipped:           m.MFAInitSkipped,\n\t\t\tPasswordlessInitRequired: m.PasswordlessInitRequired,\n\t\t\tPasswordlessTokens:       m.PasswordlessTokens,\n\t\t},\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (ams *authMaintenanceServer) isAuthenticated(ctx context.Context) error {\n\tauthInfo, err := ams.ag.AuthInfoFromCtx(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn ams.ag.AuthStore().IsAdminPermitted(authInfo)\n}", "is_vulnerable": 0}
{"code": "func volumeNameLen(path string) int {\n\tswitch {\n\tcase len(path) >= 2 && path[1] == ':':\n\t\t// Path starts with a drive letter.\n\t\t//\n\t\t// Not all Windows functions necessarily enforce the requirement that\n\t\t// drive letters be in the set A-Z, and we don't try to here.\n\t\t//\n\t\t// We don't handle the case of a path starting with a non-ASCII character,\n\t\t// in which case the \"drive letter\" might be multiple bytes long.\n\t\treturn 2\n\n\tcase len(path) == 0 || !isSlash(path[0]):\n\t\t// Path does not have a volume component.\n\t\treturn 0\n\n\tcase pathHasPrefixFold(path, `\\\\.\\UNC`):\n\t\t// We're going to treat the UNC host and share as part of the volume\n\t\t// prefix for historical reasons, but this isn't really principled;\n\t\t// Windows's own GetFullPathName will happily remove the first\n\t\t// component of the path in this space, converting\n\t\t// \\\\.\\unc\\a\\b\\..\\c into \\\\.\\unc\\a\\c.\n\t\treturn uncLen(path, len(`\\\\.\\UNC\\`))\n\n\tcase pathHasPrefixFold(path, `\\\\.`):\n\t\t// Path starts with \\\\., and is a Local Device path.\n\t\t//\n\t\t// We currently treat the next component after the \\\\.\\ prefix\n\t\t// as part of the volume name, although there doesn't seem to be\n\t\t// a principled reason to do this.\n\t\tif len(path) == 3 {\n\t\t\treturn 3 // exactly \\\\.\n\t\t}\n\t\t_, rest, ok := cutPath(path[4:])\n\t\tif !ok {\n\t\t\treturn len(path)\n\t\t}\n\t\treturn len(path) - len(rest) - 1\n\n\tcase pathHasPrefixFold(path, `\\\\?`) || pathHasPrefixFold(path, `\\??`):\n\t\t// Path starts with \\\\?\\ or \\??\\, and is a Root Local Device path.\n\t\t//\n\t\t// While Windows usually treats / and \\ as equivalent,\n\t\t// /??/ does not seem to be recognized as a Root Local Device path.\n\t\t// We treat it as one anyway here to be safe.\n\t\treturn 3\n\n\tcase len(path) >= 2 && isSlash(path[1]):\n\t\t// Path starts with \\\\, and is a UNC path.\n\t\treturn uncLen(path, 2)\n\t}\n\treturn 0\n}", "is_vulnerable": 0}
{"code": "func OperateFirewallPort(oldPorts, newPorts []int) error {\n\tclient, err := firewall.NewFirewallClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor _, port := range newPorts {\n\n\t\tif err := client.Port(fireClient.FireInfo{Port: strconv.Itoa(port), Protocol: \"tcp\", Strategy: \"accept\"}, \"add\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, port := range oldPorts {\n\t\tif err := client.Port(fireClient.FireInfo{Port: strconv.Itoa(port), Protocol: \"tcp\", Strategy: \"accept\"}, \"remove\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn client.Reload()\n}", "is_vulnerable": 1}
{"code": "func (wh *WorkflowHandler) SignalWithStartWorkflowExecution(ctx context.Context, request *workflowservice.SignalWithStartWorkflowExecutionRequest) (_ *workflowservice.SignalWithStartWorkflowExecutionResponse, retError error) {\n\tdefer log.CapturePanic(wh.logger, &retError)\n\n\tif request == nil {\n\t\treturn nil, errRequestNotSet\n\t}\n\n\tif err := wh.validateWorkflowID(request.GetWorkflowId()); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif request.GetSignalName() == \"\" {\n\t\treturn nil, errSignalNameNotSet\n\t}\n\n\tif len(request.GetSignalName()) > wh.config.MaxIDLengthLimit() {\n\t\treturn nil, errSignalNameTooLong\n\t}\n\n\tif request.WorkflowType == nil || request.WorkflowType.GetName() == \"\" {\n\t\treturn nil, errWorkflowTypeNotSet\n\t}\n\n\tif len(request.WorkflowType.GetName()) > wh.config.MaxIDLengthLimit() {\n\t\treturn nil, errWorkflowTypeTooLong\n\t}\n\n\tif err := common.ValidateUTF8String(\"WorkflowType\", request.WorkflowType.GetName()); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := wh.validateTaskQueue(request.TaskQueue); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := validateRequestId(&request.RequestId, wh.config.MaxIDLengthLimit()); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := wh.validateSignalWithStartWorkflowTimeouts(request); err != nil {\n\t\treturn nil, err\n\t}\n\n\tnamespaceName := namespace.Name(request.GetNamespace())\n\tif err := wh.validateRetryPolicy(namespaceName, request.RetryPolicy); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := wh.validateWorkflowStartDelay(request.GetCronSchedule(), request.GetWorkflowStartDelay()); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := backoff.ValidateSchedule(request.GetCronSchedule()); err != nil {\n\t\treturn nil, err\n\t}\n\n\trequest, err := wh.unaliasSignalWithStartWorkflowExecutionRequestSearchAttributes(request, namespaceName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err = wh.validateSearchAttributes(request.GetSearchAttributes(), namespaceName); err != nil {\n\t\treturn nil, err\n\t}\n\n\tenums.SetDefaultWorkflowIdReusePolicy(&request.WorkflowIdReusePolicy)\n\n\tnamespaceID, err := wh.namespaceRegistry.GetNamespaceID(namespaceName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp, err := wh.historyClient.SignalWithStartWorkflowExecution(ctx, &historyservice.SignalWithStartWorkflowExecutionRequest{\n\t\tNamespaceId:            namespaceID.String(),\n\t\tSignalWithStartRequest: request,\n\t})\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &workflowservice.SignalWithStartWorkflowExecutionResponse{RunId: resp.GetRunId()}, nil\n}", "is_vulnerable": 0}
{"code": "func TestHgCheckLocal(t *testing.T) {\n\t// Verify repo.CheckLocal fails for non-Hg directories.\n\t// TestHg is already checking on a valid repo\n\ttempDir, err := ioutil.TempDir(\"\", \"go-vcs-hg-tests\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tdefer func() {\n\t\terr = os.RemoveAll(tempDir)\n\t\tif err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t}()\n\n\trepo, _ := NewHgRepo(\"\", tempDir)\n\tif repo.CheckLocal() {\n\t\tt.Error(\"Hg CheckLocal does not identify non-Hg location\")\n\t}\n\n\t// Test NewRepo when there's no local. This should simply provide a working\n\t// instance without error based on looking at the remote localtion.\n\t_, nrerr := NewRepo(\"http://hg.code.sf.net/p/vcstesthgrepo/code\", tempDir+\"/testhgrepo\")\n\tif nrerr != nil {\n\t\tt.Error(nrerr)\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tAuthRequests: func(tt *testing.T, userID string) cache.AuthRequestCache {\n\t\t\t\t\tm := mock.NewMockAuthRequestCache(gomock.NewController(tt))\n\t\t\t\t\ta := authRequest(userID)\n\t\t\t\t\tm.EXPECT().GetAuthRequestByID(gomock.Any(), \"authRequestID\").Return(a, nil)\n\t\t\t\t\tm.EXPECT().CacheAuthRequest(gomock.Any(), a)\n\t\t\t\t\treturn m\n\t\t\t\t},\n\t\t\t\tUserViewProvider:  &mockViewUser{},\n\t\t\t\tUserEventProvider: &mockEventUser{},\n\t\t\t\tOrgViewProvider:   &mockViewOrg{State: domain.OrgStateActive},\n\t\t\t\tPasswordChecker: &mockPasswordChecker{\n\t\t\t\t\terr: command.ErrPasswordInvalid(nil),\n\t\t\t\t},\n\t\t\t\tLockoutPolicyViewProvider: &mockLockoutPolicy{\n\t\t\t\t\tpolicy: &query.LockoutPolicy{\n\t\t\t\t\t\tShowFailures: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\targs: args{\n\t\t\t\tctx:           authz.NewMockContext(\"instance1\", \"\", \"\"),\n\t\t\t\tauthReqID:     \"authRequestID\",\n\t\t\t\tuserID:        \"user1\",\n\t\t\t\tresourceOwner: \"org1\",\n\t\t\t\tpassword:      \"password\",\n\t\t\t\tuserAgentID:   \"userAgentID\",\n\t\t\t\tinfo: &domain.BrowserInfo{\n\t\t\t\t\tUserAgent: \"useragent\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\trepo := &AuthRequestRepo{\n\t\t\t\tAuthRequests:              tt.fields.AuthRequests(t, tt.args.userID),\n\t\t\t\tUserViewProvider:          tt.fields.UserViewProvider,\n\t\t\t\tUserEventProvider:         tt.fields.UserEventProvider,\n\t\t\t\tOrgViewProvider:           tt.fields.OrgViewProvider,\n\t\t\t\tPasswordChecker:           tt.fields.PasswordChecker,\n\t\t\t\tLockoutPolicyViewProvider: tt.fields.LockoutPolicyViewProvider,\n\t\t\t}\n\t\t\terr := repo.VerifyPassword(tt.args.ctx, tt.args.authReqID, tt.args.userID, tt.args.resourceOwner, tt.args.password, tt.args.userAgentID, tt.args.info)\n\t\t\tassert.ErrorIs(t, err, zerrors.ThrowInvalidArgument(nil, \"EVENT-SDe2f\", \"Errors.User.UsernameOrPassword.Invalid\"))\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (i *instances) GetMetadata(scope string, id string) MetadataOutput {\n\tctx := context.Background()\n\tvar url []string\n\tvar secondaryUrl []string\n\tif i.kubeClient != nil {\n\t\tresp, err := i.kubeClient.AppsV1().Deployments(scope).List(ctx, (meta_v1.ListOptions{}))\n\t\tif err != nil {\n\t\t\treturn MetadataOutput{}\n\t\t}\n\t\tif len(resp.Items) > 0 {\n\t\t\tfor _, d := range resp.Items {\n\t\t\t\tif d.Spec.Template.Annotations[daprEnabledAnnotation] != \"\" {\n\t\t\t\t\tdaprID := d.Spec.Template.Annotations[daprIDAnnotation]\n\t\t\t\t\tif daprID == id {\n\t\t\t\t\t\tpods, err := i.kubeClient.CoreV1().Pods(d.GetNamespace()).List(ctx, meta_v1.ListOptions{\n\t\t\t\t\t\t\tLabelSelector: labels.SelectorFromSet(d.Spec.Selector.MatchLabels).String(),\n\t\t\t\t\t\t})\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlog.Println(err)\n\t\t\t\t\t\t\treturn MetadataOutput{}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif len(pods.Items) > 0 {\n\t\t\t\t\t\t\tp := pods.Items[0]\n\t\t\t\t\t\t\turl = append(url, fmt.Sprintf(\"http://%v:%v/v1.0/metadata\", p.Status.PodIP, 3501))\n\t\t\t\t\t\t\tsecondaryUrl = append(secondaryUrl, fmt.Sprintf(\"http://%v:%v/v1.0/metadata\", p.Status.PodIP, 3500))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\trespSts, errSts := i.kubeClient.AppsV1().StatefulSets(scope).List(ctx, (meta_v1.ListOptions{}))\n\n\t\tif errSts != nil || len(respSts.Items) == 0 {\n\t\t\treturn MetadataOutput{}\n\t\t}\n\t\tfor _, d := range respSts.Items {\n\t\t\tif d.Spec.Template.Annotations[daprEnabledAnnotation] != \"\" {\n\t\t\t\tdaprID := d.Spec.Template.Annotations[daprIDAnnotation]\n\t\t\t\tif daprID == id {\n\t\t\t\t\tpods, err := i.kubeClient.CoreV1().Pods(d.GetNamespace()).List(ctx, meta_v1.ListOptions{\n\t\t\t\t\t\tLabelSelector: labels.SelectorFromSet(d.Spec.Selector.MatchLabels).String(),\n\t\t\t\t\t})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Println(err)\n\t\t\t\t\t\treturn MetadataOutput{}\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(pods.Items) > 0 {\n\t\t\t\t\t\tp := pods.Items[0]\n\t\t\t\t\t\turl = append(url, fmt.Sprintf(\"http://%v:%v/v1.0/metadata\", p.Status.PodIP, 3501))\n\t\t\t\t\t\tsecondaryUrl = append(secondaryUrl, fmt.Sprintf(\"http://%v:%v/v1.0/metadata\", p.Status.PodIP, 3500))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t} else if i.platform == platforms.DockerCompose {\n\t\tappId := i.GetInstance(scope, id).AppID\n\t\tport := i.GetInstance(scope, id).HTTPPort\n\t\taddress, err := i.resolver.ResolveID(nameresolution.ResolveRequest{ID: appId})\n\t\tif err != nil {\n\t\t\tlog.Println(err)\n\t\t\treturn MetadataOutput{}\n\t\t}\n\t\turl = append(url, fmt.Sprintf(\"http://%s:%v/v1.0/metadata\", strings.Split(address, \":\")[0], port))\n\n\t} else {\n\t\tport := i.GetInstance(scope, id).HTTPPort\n\t\turl = append(url, fmt.Sprintf(\"http://localhost:%v/v1.0/metadata\", port))\n\t}\n\tif len(url) != 0 {\n\t\tdata := i.getMetadataOutputFromURLs(url[0], \"\")\n\n\t\tif len(url) > 1 {\n\t\t\t// merge the actor metadata from the other replicas\n\n\t\t\tfor index := range url[1:] {\n\t\t\t\treplicaData := i.getMetadataOutputFromURLs(url[index+1], secondaryUrl[index+1])\n\n\t\t\t\tfor _, actor := range replicaData.Actors {\n\t\t\t\t\t// check if this actor type is already in the list\n\t\t\t\t\tfound := false\n\n\t\t\t\t\tfor _, knownActor := range data.Actors {\n\t\t\t\t\t\tif knownActor.Type == actor.Type {\n\t\t\t\t\t\t\tfound = true\n\t\t\t\t\t\t\tknownActor.Count += actor.Count\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif !found {\n\t\t\t\t\t\tdata.Actors = append(data.Actors, actor)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn data\n\t}\n\treturn MetadataOutput{}\n}", "is_vulnerable": 0}
{"code": "func (va ClawbackVestingAccount) Validate() error {\n\tif va.GetStartTime() >= va.GetEndTime() {\n\t\treturn errors.New(\"vesting start-time must be before end-time\")\n\t}\n\n\tlockupEnd := va.GetStartTime()\n\tlockupCoins := sdk.NewCoins()\n\n\tfor _, p := range va.LockupPeriods {\n\t\tlockupEnd += p.Length\n\t\tlockupCoins = lockupCoins.Add(p.Amount...)\n\t}\n\n\tif lockupEnd > va.EndTime {\n\t\treturn errors.New(\"lockup schedule extends beyond account end time\")\n\t}\n\n\t// use CoinEq to prevent panic\n\tif !CoinEq(lockupCoins, va.OriginalVesting) {\n\t\treturn errors.New(\"original vesting coins does not match the sum of all coins in lockup periods\")\n\t}\n\n\tvestingEnd := va.GetStartTime()\n\tvestingCoins := sdk.NewCoins()\n\n\tfor _, p := range va.VestingPeriods {\n\t\tvestingEnd += p.Length\n\t\tvestingCoins = vestingCoins.Add(p.Amount...)\n\t}\n\n\tif vestingEnd > va.EndTime {\n\t\treturn errors.New(\"vesting schedule exteds beyond account end time\")\n\t}\n\n\tif !CoinEq(vestingCoins, va.OriginalVesting) {\n\t\treturn errors.New(\"original vesting coins does not match the sum of all coins in vesting periods\")\n\t}\n\n\treturn va.BaseVestingAccount.Validate()\n}", "is_vulnerable": 1}
{"code": "func (context *DatabaseContext) QueryAllDocs(startKey string, endKey string) (sgbucket.QueryResultIterator, error) {\n\n\t// View Query\n\tif context.Options.UseViews {\n\t\topts := Body{\"stale\": false, \"reduce\": false}\n\t\tif startKey != \"\" {\n\t\t\topts[\"startkey\"] = startKey\n\t\t}\n\t\tif endKey != \"\" {\n\t\t\topts[\"endkey\"] = endKey\n\t\t}\n\t\treturn context.ViewQueryWithStats(DesignDocSyncHousekeeping(), ViewAllDocs, opts)\n\t}\n\n\tbucketName := context.Bucket.GetName()\n\n\t// N1QL Query\n\tallDocsQueryStatement := replaceSyncTokensQuery(QueryAllDocs.statement, context.UseXattrs())\n\tif startKey != \"\" {\n\t\tallDocsQueryStatement = fmt.Sprintf(\"%s AND META(`%s`).id >= '%s'\",\n\t\t\tallDocsQueryStatement, bucketName, startKey)\n\t}\n\tif endKey != \"\" {\n\t\tallDocsQueryStatement = fmt.Sprintf(\"%s AND META(`%s`).id <= '%s'\",\n\t\t\tallDocsQueryStatement, bucketName, endKey)\n\t}\n\n\tallDocsQueryStatement = fmt.Sprintf(\"%s ORDER BY META(`%s`).id\",\n\t\tallDocsQueryStatement, bucketName)\n\n\treturn context.N1QLQueryWithStats(QueryTypeAllDocs, allDocsQueryStatement, nil, gocb.RequestPlus, QueryAllDocs.adhoc)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) StartRportFwdListener(ctx context.Context, in *sliverpb.RportFwdStartListenerReq, opts ...grpc.CallOption) (*sliverpb.RportFwdListener, error) {\n\tout := new(sliverpb.RportFwdListener)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/StartRportFwdListener\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (reader *URLReader) Read() ([]byte, error) {\n\tlog := logging.NewArgoEventsLogger()\n\tlog.Debugf(\"reading urlArtifact from %s\", reader.urlArtifact.Path)\n\tinsecureSkipVerify := !reader.urlArtifact.VerifyCert\n\tclient := &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: insecureSkipVerify},\n\t\t},\n\t}\n\tresp, err := client.Get(reader.urlArtifact.Path)\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tlog.Warnf(\"failed to read %s. status code: %d\", reader.urlArtifact.Path, resp.StatusCode)\n\t\treturn nil, errors.Errorf(\"status code %v\", resp.StatusCode)\n\t}\n\n\tcontent, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Warnf(\"failed to read url body for %s: %s\", reader.urlArtifact.Path, err)\n\t\treturn nil, err\n\t}\n\treturn content, nil\n}", "is_vulnerable": 1}
{"code": "func SnapshotFileMetaEqual(actual data.SnapshotFileMeta, expected data.SnapshotFileMeta) error {\n\t// TUF-1.0 no longer considers the length and hashes to be a required\n\t// member of snapshots. However they are considering requiring hashes\n\t// for delegated roles to avoid an attack described in Section 5.6 of\n\t// the Mercury paper:\n\t// https://github.com/theupdateframework/specification/pull/40\n\tif expected.Length != 0 && actual.Length != expected.Length {\n\t\treturn ErrWrongLength{expected.Length, actual.Length}\n\t}\n\t// 5.6.2 - Check against snapshot role's targets hash\n\tif len(expected.Hashes) != 0 {\n\t\tif err := hashEqual(actual.Hashes, expected.Hashes); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// 5.6.4 - Check against snapshot role's snapshot version\n\tif err := versionEqual(actual.Version, expected.Version); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (v *View) UserByLoginNameAndResourceOwner(ctx context.Context, loginName, resourceOwner, instanceID string) (*model.UserView, error) {\n\tqueriedUser, err := v.query.GetNotifyUserByLoginName(ctx, true, loginName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//nolint: contextcheck // no lint was added because refactor would change too much code\n\tuser, err := view.UserByID(ctx, v.Db, queriedUser.ID, instanceID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif user.ResourceOwner != resourceOwner {\n\t\treturn nil, zerrors.ThrowNotFound(nil, \"VIEW-qScmi\", \"Errors.User.NotFound\")\n\t}\n\n\treturn user, nil\n}", "is_vulnerable": 0}
{"code": "func getCheckRequestURL(req *envoy_service_auth_v3.CheckRequest) url.URL {\n\th := req.GetAttributes().GetRequest().GetHttp()\n\tu := url.URL{\n\t\tScheme: h.GetScheme(),\n\t\tHost:   h.GetHost(),\n\t}\n\tu.Host = urlutil.GetDomainsForURL(&u)[0]\n\t// envoy sends the query string as part of the path\n\tpath := h.GetPath()\n\tif idx := strings.Index(path, \"?\"); idx != -1 {\n\t\tu.RawPath, u.RawQuery = path[:idx], path[idx+1:]\n\t\tu.RawQuery = u.Query().Encode()\n\t} else {\n\t\tu.RawPath = path\n\t}\n\tu.Path, _ = url.PathUnescape(u.RawPath)\n\treturn u\n}", "is_vulnerable": 0}
{"code": "func (s *CheckerSuite) TestValidate(c *check.C) {\n\tchecker := CertChecker{}\n\n\trsaKey, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tc.Assert(err, check.IsNil)\n\tsmallRSAKey, err := rsa.GenerateKey(rand.Reader, 1024)\n\tc.Assert(err, check.IsNil)\n\tellipticKey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\tc.Assert(err, check.IsNil)\n\n\t// 2048-bit RSA keys are valid.\n\tcryptoKey := rsaKey.Public()\n\tsshKey, err := ssh.NewPublicKey(cryptoKey)\n\tc.Assert(err, check.IsNil)\n\terr = checker.validate(sshKey)\n\tc.Assert(err, check.IsNil)\n\n\t// 1024-bit RSA keys are valid.\n\tcryptoKey = smallRSAKey.Public()\n\tsshKey, err = ssh.NewPublicKey(cryptoKey)\n\tc.Assert(err, check.IsNil)\n\terr = checker.validate(sshKey)\n\tc.Assert(err, check.IsNil)\n\n\t// ECDSA keys are valid.\n\tcryptoKey = ellipticKey.Public()\n\tsshKey, err = ssh.NewPublicKey(cryptoKey)\n\tc.Assert(err, check.IsNil)\n\terr = checker.validate(sshKey)\n\tc.Assert(err, check.IsNil)\n}", "is_vulnerable": 1}
{"code": "func getAuthenticator(ctx context.Context, ref string, registryClient registryclient.Client) (*authn.Authenticator, error) {\n\tparsedRef, err := name.ParseReference(ref)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to parse registry reference %s\", ref)\n\t}\n\n\tif err := registryClient.RefreshKeychainPullSecrets(ctx); err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to refresh image pull secrets\")\n\t}\n\n\tauthn, err := registryClient.Keychain().Resolve(&imageResource{parsedRef})\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to resolve auth for %s\", parsedRef.String())\n\t}\n\treturn &authn, nil\n}", "is_vulnerable": 0}
{"code": "func (r *BlockRequest) Validate(db ethdb.Database, msg *Msg) error {\n\tlog.Debug(\"Validating block body\", \"hash\", r.Hash)\n\n\t// Ensure we have a correct message with a single block body\n\tif msg.MsgType != MsgBlockBodies {\n\t\treturn errInvalidMessageType\n\t}\n\tbodies := msg.Obj.([]*types.Body)\n\tif len(bodies) != 1 {\n\t\treturn errInvalidEntryCount\n\t}\n\tbody := bodies[0]\n\n\t// Retrieve our stored header and validate block content against it\n\tif r.Header == nil {\n\t\tr.Header = rawdb.ReadHeader(db, r.Hash, r.Number)\n\t}\n\tif r.Header == nil {\n\t\treturn errHeaderUnavailable\n\t}\n\tif r.Header.TxHash != types.DeriveSha(types.Transactions(body.Transactions)) {\n\t\treturn errTxHashMismatch\n\t}\n\tif r.Header.UncleHash != types.CalcUncleHash(body.Uncles) {\n\t\treturn errUncleHashMismatch\n\t}\n\t// Validations passed, encode and store RLP\n\tdata, err := rlp.EncodeToBytes(body)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Rlp = data\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestCacheSeparation(t *testing.T) {\n\tnow, _ := time.Parse(time.UnixDate, \"Fri Apr 21 10:51:21 BST 2017\")\n\tutc := now.UTC()\n\n\ttestCases := []struct {\n\t\tname         string\n\t\tinitial      test.Case\n\t\tquery        test.Case\n\t\texpectCached bool // if a cache entry should be found before inserting\n\t}{\n\t\t{\n\t\t\tname: \"query type should be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeAAAA,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"DO bit should be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t\tDo:    true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"CD bit should be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname:            \"example.org.\",\n\t\t\t\tQtype:            dns.TypeA,\n\t\t\t\tCheckingDisabled: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"CD bit and DO bit should be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname:            \"example.org.\",\n\t\t\t\tQtype:            dns.TypeA,\n\t\t\t\tCheckingDisabled: true,\n\t\t\t\tDo:               true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"CD bit, DO bit, and query type should be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname:            \"example.org.\",\n\t\t\t\tQtype:            dns.TypeMX,\n\t\t\t\tCheckingDisabled: true,\n\t\t\t\tDo:               true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"authoritative answer bit should NOT be unique\",\n\t\t\tinitial: test.Case{\n\t\t\t\tQname: \"example.org.\",\n\t\t\t\tQtype: dns.TypeA,\n\t\t\t},\n\t\t\tquery: test.Case{\n\t\t\t\tQname:         \"example.org.\",\n\t\t\t\tQtype:         dns.TypeA,\n\t\t\t\tAuthoritative: true,\n\t\t\t},\n\t\t\texpectCached: true,\n\t\t},\n\t}\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tc := New()\n\t\t\tcrr := &ResponseWriter{ResponseWriter: nil, Cache: c}\n\n\t\t\t// Insert initial cache entry\n\t\t\tm := tc.initial.Msg()\n\t\t\tm = cacheMsg(m, tc.initial)\n\t\t\tstate := request.Request{W: &test.ResponseWriter{}, Req: m}\n\n\t\t\tmt, _ := response.Typify(m, utc)\n\t\t\tvalid, k := key(state.Name(), m, mt, state.Do(), state.Req.CheckingDisabled)\n\n\t\t\tif valid {\n\t\t\t\t// Insert cache entry\n\t\t\t\tcrr.set(m, k, mt, c.pttl)\n\t\t\t}\n\n\t\t\t// Attempt to retrieve cache entry\n\t\t\tm = tc.query.Msg()\n\t\t\tm = cacheMsg(m, tc.query)\n\t\t\tstate = request.Request{W: &test.ResponseWriter{}, Req: m}\n\n\t\t\titem := c.getIgnoreTTL(time.Now().UTC(), state, \"dns://:53\")\n\t\t\tfound := item != nil\n\n\t\t\tif !tc.expectCached && found {\n\t\t\t\tt.Fatal(\"Found cache message should that should not exist prior to inserting\")\n\t\t\t}\n\t\t\tif tc.expectCached && !found {\n\t\t\t\tt.Fatal(\"Did not find cache message that should exist prior to inserting\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client testClient) GetCreateMetaInfo(api plugin.API, options *jira.GetQueryOptions) (*jira.CreateMetaInfo, error) {\n\treturn &jira.CreateMetaInfo{\n\t\tProjects: []*jira.MetaProject{\n\t\t\t{\n\t\t\t\tIssueTypes: []*jira.MetaIssueType{\n\t\t\t\t\t{\n\t\t\t\t\t\tFields: tcontainer.MarshalMap{\n\t\t\t\t\t\t\t\"security\": tcontainer.MarshalMap{\n\t\t\t\t\t\t\t\t\"allowedValues\": []interface{}{\n\t\t\t\t\t\t\t\t\ttcontainer.MarshalMap{\n\t\t\t\t\t\t\t\t\t\t\"id\": \"10001\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestGetSeccompProfilePathDefaultSeccomp(t *testing.T) {\n\t_, _, m, err := createTestRuntimeManager()\n\trequire.NoError(t, err)\n\n\ttests := []struct {\n\t\tdescription     string\n\t\tannotation      map[string]string\n\t\tpodSc           *v1.PodSecurityContext\n\t\tcontainerSc     *v1.SecurityContext\n\t\tcontainerName   string\n\t\texpectedProfile string\n\t\texpectedError   string\n\t}{\n\t\t{\n\t\t\tdescription:     \"no seccomp should return runtime/default\",\n\t\t\texpectedProfile: v1.SeccompProfileRuntimeDefault,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"annotations: no seccomp with containerName should return runtime/default\",\n\t\t\tcontainerName:   \"container1\",\n\t\t\texpectedProfile: v1.SeccompProfileRuntimeDefault,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"pod seccomp profile set to unconfined returns unconfined\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\texpectedProfile: \"unconfined\",\n\t\t},\n\t\t{\n\t\t\tdescription:     \"container seccomp profile set to unconfined returns unconfined\",\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\texpectedProfile: \"unconfined\",\n\t\t},\n\t\t{\n\t\t\tdescription:     \"pod seccomp profile set to SeccompProfileTypeRuntimeDefault returns runtime/default\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: \"runtime/default\",\n\t\t},\n\t\t{\n\t\t\tdescription:     \"container seccomp profile set to SeccompProfileTypeRuntimeDefault returns runtime/default\",\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: \"runtime/default\",\n\t\t},\n\t\t{\n\t\t\tdescription:     \"pod seccomp profile set to SeccompProfileTypeLocalhost returns 'localhost/' + LocalhostProfile\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"filename\")}},\n\t\t\texpectedProfile: seccompLocalhostPath(\"filename\"),\n\t\t},\n\t\t{\n\t\t\tdescription:   \"pod seccomp profile set to SeccompProfileTypeLocalhost with empty LocalhostProfile returns error\",\n\t\t\tpodSc:         &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost}},\n\t\t\texpectedError: \"localhostProfile must be set if seccompProfile type is Localhost.\",\n\t\t},\n\t\t{\n\t\t\tdescription:   \"container seccomp profile set to SeccompProfileTypeLocalhost with empty LocalhostProfile returns error\",\n\t\t\tcontainerSc:   &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost}},\n\t\t\texpectedError: \"localhostProfile must be set if seccompProfile type is Localhost.\",\n\t\t},\n\t\t{\n\t\t\tdescription:     \"container seccomp profile set to SeccompProfileTypeLocalhost returns 'localhost/' + LocalhostProfile\",\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"filename2\")}},\n\t\t\texpectedProfile: seccompLocalhostPath(\"filename2\"),\n\t\t},\n\t\t{\n\t\t\tdescription:     \"prioritise container field over pod field\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: \"runtime/default\",\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tseccompProfile, err := m.getSeccompProfilePath(test.annotation, test.containerName, test.podSc, test.containerSc, true)\n\t\tif test.expectedError != \"\" {\n\t\t\tassert.EqualError(t, err, test.expectedError, \"TestCase[%d]: %s\", i, test.description)\n\t\t} else {\n\t\t\tassert.NoError(t, err, \"TestCase[%d]: %s\", i, test.description)\n\t\t\tassert.Equal(t, test.expectedProfile, seccompProfile, \"TestCase[%d]: %s\", i, test.description)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (r *PostgreSQL) getSQL(str string) (string, string, error) {\n\tif len(strings.TrimSpace(str)) == 0 {\n\t\treturn \"\", \"\", fmt.Errorf(\"Empty SQL data\")\n\t}\n\tfields := strings.Split(str, \":\")\n\tif len(fields) != 5 {\n\t\treturn \"\", \"\", fmt.Errorf(\"Invalid SQL data - [%s]. (syntax: database:table:field:key:value)\", str)\n\t}\n\tdb := global.EscapeQuote(fields[0])\n\ttable := global.EscapeQuote(fields[1])\n\tfield := global.EscapeQuote(fields[2])\n\tkey := global.EscapeQuote(fields[3])\n\tvalue := global.EscapeQuote(fields[4])\n\t//check value is int or not\n\tif _, err := strconv.Atoi(value); err != nil {\n\t\treturn \"\", \"\", fmt.Errorf(\"Invalid SQL data - [%s], the value must be int\", str)\n\t}\n\n\tsql := fmt.Sprintf(`SELECT \"%s\" FROM \"%s\" WHERE \"%s\" = %s`, field, table, key, value)\n\treturn db, sql, nil\n}", "is_vulnerable": 0}
{"code": "func (f *framerI) AppendControlFrames(frames []ackhandler.Frame, maxLen protocol.ByteCount, v protocol.VersionNumber) ([]ackhandler.Frame, protocol.ByteCount) {\n\tf.controlFrameMutex.Lock()\n\tdefer f.controlFrameMutex.Unlock()\n\n\tvar length protocol.ByteCount\n\t// add a PATH_RESPONSE first, but only pack a single PATH_RESPONSE per packet\n\tif len(f.pathResponses) > 0 {\n\t\tframe := f.pathResponses[0]\n\t\tframeLen := frame.Length(v)\n\t\tif frameLen <= maxLen {\n\t\t\tframes = append(frames, ackhandler.Frame{Frame: frame})\n\t\t\tlength += frameLen\n\t\t\tf.pathResponses = f.pathResponses[1:]\n\t\t}\n\t}\n\n\tfor len(f.controlFrames) > 0 {\n\t\tframe := f.controlFrames[len(f.controlFrames)-1]\n\t\tframeLen := frame.Length(v)\n\t\tif length+frameLen > maxLen {\n\t\t\tbreak\n\t\t}\n\t\tframes = append(frames, ackhandler.Frame{Frame: frame})\n\t\tlength += frameLen\n\t\tf.controlFrames = f.controlFrames[:len(f.controlFrames)-1]\n\t}\n\treturn frames, length\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) RegistryWrite(ctx context.Context, in *sliverpb.RegistryWriteReq, opts ...grpc.CallOption) (*sliverpb.RegistryWrite, error) {\n\tout := new(sliverpb.RegistryWrite)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/RegistryWrite\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func newToken() Token {\n\treturn Token{\n\t\tExpiresIn: \"0\",\n\t\tExpiresOn: \"0\",\n\t\tNotBefore: \"0\",\n\t}\n}", "is_vulnerable": 0}
{"code": "func (a azureCliTokenAuth) getAuthorizationToken(oauthConfig *adal.OAuthConfig, endpoint string) (*autorest.BearerAuthorizer, error) {\n\t// the Azure CLI appears to cache these, so to maintain compatibility with the interface this method is intentionally not on the pointer\n\ttoken, err := obtainAuthorizationToken(endpoint, a.profile.subscriptionId)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error obtaining Authorization Token from the Azure CLI: %s\", err)\n\t}\n\n\tadalToken, err := token.ToADALToken()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error converting Authorization Token to an ADAL Token: %s\", err)\n\t}\n\n\tspt, err := adal.NewServicePrincipalTokenFromManualToken(*oauthConfig, a.profile.clientId, endpoint, adalToken)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauth := autorest.NewBearerAuthorizer(spt)\n\treturn auth, nil\n}", "is_vulnerable": 1}
{"code": "func (m *AnotherNinOptEnumDefault) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: AnotherNinOptEnumDefault: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: AnotherNinOptEnumDefault: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v AnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= AnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v YetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field2 = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v YetYetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field3 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func EccPubEncrypt(plainText []byte, pub *ecdsa.PublicKey) (cryptText []byte, err error) { //\r\n\r\n\tdefer func() {\r\n\t\tif err := recover(); err != nil {\r\n\t\t\tswitch err.(type) {\r\n\t\t\tcase runtime.Error:\r\n\t\t\t\tlog.Println(\"runtime err:\", err, \"check key \")\r\n\t\t\tdefault:\r\n\t\t\t\tlog.Println(\"error:\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\r\n\tpublicKey := ImportECDSAPublic(pub)\r\n\t//\r\n\tcrypttext, err := Encrypt(rand.Reader, publicKey, plainText, nil, nil)\r\n\r\n\treturn crypttext, err\r\n\r\n}\r", "is_vulnerable": 1}
{"code": "func findKeyStart(data []byte, key string) (int, error) {\n\ti := 0\n\tln := len(data)\n\tif ln > 0 && (data[0] == '{' || data[0] == '[') {\n\t\ti = 1\n\t}\n\tvar stackbuf [unescapeStackBufSize]byte // stack-allocated array for allocation-free unescaping of small strings\n\n\tif ku, err := Unescape(StringToBytes(key), stackbuf[:]); err == nil {\n\t\tkey = bytesToString(&ku)\n\t}\n\n\tfor i < ln {\n\t\tswitch data[i] {\n\t\tcase '\"':\n\t\t\ti++\n\t\t\tkeyBegin := i\n\n\t\t\tstrEnd, keyEscaped := stringEnd(data[i:])\n\t\t\tif strEnd == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ti += strEnd\n\t\t\tkeyEnd := i - 1\n\n\t\t\tvalueOffset := nextToken(data[i:])\n\t\t\tif valueOffset == -1 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\ti += valueOffset\n\n\t\t\t// if string is a key, and key level match\n\t\t\tk := data[keyBegin:keyEnd]\n\t\t\t// for unescape: if there are no escape sequences, this is cheap; if there are, it is a\n\t\t\t// bit more expensive, but causes no allocations unless len(key) > unescapeStackBufSize\n\t\t\tif keyEscaped {\n\t\t\t\tif ku, err := Unescape(k, stackbuf[:]); err != nil {\n\t\t\t\t\tbreak\n\t\t\t\t} else {\n\t\t\t\t\tk = ku\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif data[i] == ':' && len(key) == len(k) && bytesToString(&k) == key {\n\t\t\t\treturn keyBegin - 1, nil\n\t\t\t}\n\n\t\tcase '[':\n\t\t\tend := blockEnd(data[i:], data[i], ']')\n\t\t\tif end != -1 {\n\t\t\t\ti = i + end\n\t\t\t}\n\t\tcase '{':\n\t\t\tend := blockEnd(data[i:], data[i], '}')\n\t\t\tif end != -1 {\n\t\t\t\ti = i + end\n\t\t\t}\n\t\t}\n\t\ti++\n\t}\n\n\treturn -1, KeyPathNotFoundError\n}", "is_vulnerable": 0}
{"code": "func (db *Database) InsertBlob(hash common.Hash, blob []byte) {\n\tdb.lock.Lock()\n\tdefer db.lock.Unlock()\n\n\tdb.insert(hash, len(blob), rawNode(blob))\n}", "is_vulnerable": 1}
{"code": "func (svc *Service) RefetchHost(ctx context.Context, id uint) error {\n\tif !svc.authz.IsAuthenticatedWith(ctx, authz_ctx.AuthnDeviceToken) {\n\t\tif err := svc.authz.Authorize(ctx, &fleet.Host{}, fleet.ActionList); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thost, err := svc.ds.HostLite(ctx, id)\n\t\tif err != nil {\n\t\t\treturn ctxerr.Wrap(ctx, err, \"find host for refetch\")\n\t\t}\n\n\t\t// We verify fleet.ActionRead instead of fleet.ActionWrite because we want to allow\n\t\t// observers to be able to refetch hosts.\n\t\tif err := svc.authz.Authorize(ctx, host, fleet.ActionRead); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := svc.ds.UpdateHostRefetchRequested(ctx, id, true); err != nil {\n\t\treturn ctxerr.Wrap(ctx, err, \"save host\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func newGatewayStartCommand() *cobra.Command {\n\tcmd := cobra.Command{\n\t\tUse:   \"start\",\n\t\tShort: \"start the gateway\",\n\t\tRun:   startGateway,\n\t}\n\n\tcmd.Flags().StringVar(&gatewayListenAddr, \"listen-addr\", \"127.0.0.1:23790\", \"listen address\")\n\tcmd.Flags().StringVar(&gatewayDNSCluster, \"discovery-srv\", \"\", \"DNS domain used to bootstrap initial cluster\")\n\tcmd.Flags().StringVar(&gatewayDNSClusterServiceName, \"discovery-srv-name\", \"\", \"service name to query when using DNS discovery\")\n\tcmd.Flags().BoolVar(&gatewayInsecureDiscovery, \"insecure-discovery\", false, \"accept insecure SRV records\")\n\tcmd.Flags().StringVar(&gatewayCA, \"trusted-ca-file\", \"\", \"path to the client server TLS CA file for verifying the discovered endpoints when discovery-srv is provided.\")\n\n\tcmd.Flags().StringSliceVar(&gatewayEndpoints, \"endpoints\", []string{\"127.0.0.1:2379\"}, \"comma separated etcd cluster endpoints\")\n\n\tcmd.Flags().DurationVar(&getewayRetryDelay, \"retry-delay\", time.Minute, \"duration of delay before retrying failed endpoints\")\n\n\treturn &cmd\n}", "is_vulnerable": 0}
{"code": "func (r *Limits) ProcessLimit() int64 {\n\treturn config.Get().Docker.ContainerPidLimit\n}", "is_vulnerable": 0}
{"code": "func (cvss20 CVSS20) EnvironmentalScore() float64 {\n\t// Recompute base score\n\tadjustedImpact := math.Min(10, 10.41*(1-(1-cia(cvss20.ConfidentialityImpact)*ciar(cvss20.ConfidentialityRequirement))*(1-cia(cvss20.IntegrityImpact)*ciar(cvss20.IntegrityRequirement))*(1-cia(cvss20.AvailabilityImpact)*ciar(cvss20.AvailabilityRequirement))))\n\tfimpactBase := 0.0\n\tif adjustedImpact != 0 {\n\t\tfimpactBase = 1.176\n\t}\n\texpltBase := 20 * accessVector(cvss20.AccessVector) * accessComplexity(cvss20.AccessComplexity) * authentication(cvss20.Authentication)\n\trecBase := roundTo1Decimal(((0.6 * adjustedImpact) + (0.4 * expltBase) - 1.5) * fimpactBase)\n\tadjustedTemporal := roundTo1Decimal(recBase * exploitability(cvss20.Exploitability) * remediationLevel(cvss20.RemediationLevel) * reportConfidence(cvss20.ReportConfidence))\n\treturn roundTo1Decimal((adjustedTemporal + (10-adjustedTemporal)*collateralDamagePotential(cvss20.CollateralDamagePotential)) * targetDistribution(cvss20.TargetDistribution))\n}", "is_vulnerable": 1}
{"code": "func (l Logger) Error(err error, msg string, keysAndValues ...any) {\n\tif l.sink == nil {\n\t\treturn\n\t}\n\tif withHelper, ok := l.sink.(CallStackHelperLogSink); ok {\n\t\twithHelper.GetCallStackHelper()()\n\t}\n\tl.sink.Error(err, msg, keysAndValues...)\n}", "is_vulnerable": 0}
{"code": "\tt.Run(fmt.Sprintf(\"%s %s\", desc, url), func(t *testing.T) {\n\t\tdefer bus.ClearBusHandlers()\n\n\t\ths := HTTPServer{\n\t\t\tCfg:             setting.NewCfg(),\n\t\t\tShortURLService: shortURLService,\n\t\t\tlog:             log.New(\"test\"),\n\t\t}\n\n\t\tsc := setupScenarioContext(t, url)\n\t\tsc.defaultHandler = routing.Wrap(func(c *models.ReqContext) response.Response {\n\t\t\tc.Req.Body = mockRequestBody(cmd)\n\t\t\tc.Req.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tsc.context = c\n\t\t\tsc.context.SignedInUser = &models.SignedInUser{OrgId: testOrgID, UserId: testUserID}\n\n\t\t\treturn hs.createShortURL(c)\n\t\t})\n\n\t\tsc.m.Post(routePattern, sc.defaultHandler)\n\n\t\tfn(sc)\n\t})\n}", "is_vulnerable": 0}
{"code": "func eqFilter(field string, value any) Sqlizer {\n\treturn Eq{field: value}\n}", "is_vulnerable": 0}
{"code": "func TestFSM_BadRestore_OSS(t *testing.T) {\n\tt.Parallel()\n\t// Create an FSM with some state.\n\tlogger := testutil.Logger(t)\n\tfsm, err := New(nil, logger)\n\trequire.NoError(t, err)\n\tfsm.state.EnsureNode(1, &structs.Node{Node: \"foo\", Address: \"127.0.0.1\"})\n\tabandonCh := fsm.state.AbandonCh()\n\n\t// Do a bad restore.\n\tbuf := bytes.NewBuffer([]byte(\"bad snapshot\"))\n\tsink := &MockSink{buf, false}\n\trequire.Error(t, fsm.Restore(sink))\n\n\t// Verify the contents didn't get corrupted.\n\t_, nodes, err := fsm.state.Nodes(nil)\n\trequire.NoError(t, err)\n\trequire.Len(t, nodes, 1)\n\trequire.Equal(t, \"foo\", nodes[0].Node)\n\trequire.Equal(t, \"127.0.0.1\", nodes[0].Address)\n\trequire.Empty(t, nodes[0].TaggedAddresses)\n\n\t// Verify the old state store didn't get abandoned.\n\tselect {\n\tcase <-abandonCh:\n\t\trequire.FailNow(t, \"FSM state was abandoned when it should not have been\")\n\tdefault:\n\t}\n}", "is_vulnerable": 0}
{"code": "func DeleteCustomEmoji(w http.ResponseWriter, r *http.Request) {\n\tif !requirePOST(w, r) {\n\t\treturn\n\t}\n\n\ttype deleteEmoji struct {\n\t\tName string `json:\"name\"`\n\t}\n\n\temoji := new(deleteEmoji)\n\n\tif err := json.NewDecoder(r.Body).Decode(emoji); err != nil {\n\t\tcontrollers.WriteSimpleResponse(w, false, err.Error())\n\t\treturn\n\t}\n\n\ttargetPath := filepath.Join(config.CustomEmojiPath, emoji.Name)\n\n\tif !filepath.IsLocal(targetPath) {\n\t\tcontrollers.WriteSimpleResponse(w, false, \"Emoji path is not valid\")\n\t\treturn\n\t}\n\n\tif err := os.Remove(targetPath); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\tcontrollers.WriteSimpleResponse(w, false, fmt.Sprintf(\"Emoji %q doesn't exist\", emoji.Name))\n\t\t} else {\n\t\t\tcontrollers.WriteSimpleResponse(w, false, err.Error())\n\t\t}\n\t\treturn\n\t}\n\n\tcontrollers.WriteSimpleResponse(w, true, fmt.Sprintf(\"Emoji %q has been deleted\", emoji.Name))\n}", "is_vulnerable": 0}
{"code": "func (o *Options) proposeChanges(ctx context.Context, repo *git.Repository, ref plumbing.ReferenceName, packageName string, newVersion NewVersionResults) (string, error) {\n\tgitURL, err := wgit.GetRemoteURL(repo)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to find git origin URL: %w\", err)\n\t}\n\n\tbasePullRequest := gh.BasePullRequest{\n\t\tRepoName:              gitURL.Name,\n\t\tOwner:                 gitURL.Organisation,\n\t\tBranch:                ref.String(),\n\t\tPullRequestBaseBranch: o.PullRequestBaseBranch,\n\t}\n\n\tclient := github.NewClient(o.GitHubHTTPClient.Client)\n\n\tgitOpts := gh.GitOptions{\n\t\tGithubClient: client,\n\t\tMaxRetries:   maxPullRequestRetries,\n\t\tLogger:       o.Logger,\n\t}\n\n\t// commit the changes\n\tif err = o.commitChanges(repo, packageName, newVersion.Version); err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to commit changes: %w\", err)\n\t}\n\n\t// todo jr remove if this doesn't help\n\twt, err := repo.Worktree()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to get the worktree: %w\", err)\n\t}\n\trs, err := debug(wt)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\to.Logger.Printf(\"proposeChanges: %s git status: %s\", packageName, string(rs))\n\n\t// setup githubReleases auth using standard environment variables\n\tpushOpts := &git.PushOptions{\n\t\tRemoteName: \"origin\",\n\t\tAuth:       wgit.GetGitAuth(),\n\t\tProgress:   os.Stdout, // todo remove if this doesn't help: extra logging to help debug intermittent \"object not found\" when pushing\n\t}\n\n\t// push the version update changes to our working branch\n\tif err := repo.Push(pushOpts); err != nil {\n\t\tif err.Error() == \"authorization failed\" {\n\t\t\treturn \"\", fmt.Errorf(\"failed to auth with git provider, does your personal access token have the repo scope? https://github.com/settings/tokens/new?scopes=repo: %w\", err)\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"failed to git push: %w\", err)\n\t}\n\n\t// now let's create a pull request\n\n\t// if we have a single version use it in the PR title, this might be a batch with multiple versions so default to a simple title\n\tvar title string\n\tif newVersion.Version != \"\" {\n\t\ttitle = fmt.Sprintf(o.PullRequestTitle, packageName, newVersion.Version)\n\t} else {\n\t\ttitle = fmt.Sprintf(o.PullRequestTitle, packageName, \"new versions\")\n\t}\n\n\t// Create an NewPullRequest struct which is used to create the real pull request from\n\tnewPR := &gh.NewPullRequest{\n\t\tBasePullRequest: basePullRequest,\n\t\tTitle:           title,\n\t\tBody:            wolfiImage,\n\t}\n\n\t// create the pull request\n\tpr, err := gitOpts.OpenPullRequest(ctx, newPR)\n\tprLink := pr.GetHTMLURL()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to create pull request: %w\", err)\n\t}\n\terr = gitOpts.LabelIssue(ctx, newPR.Owner, newPR.RepoName, *pr.Number, &o.IssueLabels)\n\tif err != nil {\n\t\tlog.Printf(\"Failed to apply labels [%s] to PR #%d\", strings.Join(o.IssueLabels, \",\"), pr.Number)\n\t}\n\tif newVersion.ReplaceExistingPRNumber != 0 {\n\t\terr = gitOpts.ClosePullRequest(ctx, gitURL.Organisation, gitURL.Name, newVersion.ReplaceExistingPRNumber)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"failed to close pull request: %d: %w\", newVersion.ReplaceExistingPRNumber, err)\n\t\t}\n\n\t\t// comment on the closed PR the new pull request link which supersedes it\n\t\tcomment := fmt.Sprintf(\"superseded by %s\", prLink)\n\t\t_, err = gitOpts.CommentIssue(ctx, gitURL.Organisation, gitURL.Name, comment, newVersion.ReplaceExistingPRNumber)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"failed to comment pull request: %d: %w\", newVersion.ReplaceExistingPRNumber, err)\n\t\t}\n\t}\n\treturn prLink, nil\n}", "is_vulnerable": 1}
{"code": "func (p *printer) saveExprStartFlags() (flags exprStartFlags) {\n\tn := len(p.js)\n\tif p.stmtStart == n {\n\t\tflags |= stmtStartFlag\n\t}\n\tif p.exportDefaultStart == n {\n\t\tflags |= exportDefaultStartFlag\n\t}\n\tif p.arrowExprStart == n {\n\t\tflags |= arrowExprStartFlag\n\t}\n\tif p.forOfInitStart == n {\n\t\tflags |= forOfInitStartFlag\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "\t\tToRequests: handler.ToRequestsFunc(func(mo handler.MapObject) []reconcile.Request {\n\t\t\tsc, ok := mo.Object.(*storagev1.StorageClass)\n\t\t\tif !ok || sc.Provisioner != options.ObjectBucketProvisionerName() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn []reconcile.Request{{\n\t\t\t\tNamespacedName: types.NamespacedName{\n\t\t\t\t\tName:      options.SystemName,\n\t\t\t\t\tNamespace: options.Namespace,\n\t\t\t\t},\n\t\t\t}}\n\t\t}),\n\t}\n\t// Watch for StorageClass changes to trigger reconcile and recreate it when deleted\n\terr = c.Watch(&source.Kind{Type: &storagev1.StorageClass{}}, &storageClassHandler, &logEventsPredicate)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// watch on notificationSource in order to keep the controller work queue\n\tnotificationSource := &NotificationSource{}\n\terr = c.Watch(notificationSource, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// handler for global RPC message and ,simply trigger a reconcile on every message\n\tnb.GlobalRPC.Handler = func(req *nb.RPCMessage) (interface{}, error) {\n\t\tlogrus.Infof(\"RPC Handle: {Op: %s, API: %s, Method: %s, Error: %s, Params: %+v}\", req.Op, req.API, req.Method, req.Error, req.Params)\n\t\tnotificationSource.Queue.AddRateLimited(reconcile.Request{NamespacedName: types.NamespacedName{\n\t\t\tName:      options.SystemName,\n\t\t\tNamespace: options.Namespace,\n\t\t}})\n\t\treturn nil, nil\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Nil) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipFuzz(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (f *timewindowCheckFilter) Init(next peer.EndorserServer) {\n\tf.next = next\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) MonitorStart(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*commonpb.Response, error) {\n\tout := new(commonpb.Response)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/MonitorStart\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestGitGetter_subdirectory_traversal(t *testing.T) {\n\tdst := testing_helper.TempDir(t)\n\n\trepo := testGitRepo(t, \"empty-repo\")\n\tu, err := url.Parse(fmt.Sprintf(\"git::%s//../../../../../../etc/passwd\", repo.url.String()))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\treq := &Request{\n\t\tSrc:     u.String(),\n\t\tDst:     dst,\n\t\tPwd:     \".\",\n\t\tGetMode: ModeDir,\n\t}\n\n\tgetter := &GitGetter{\n\t\tDetectors: []Detector{\n\t\t\tnew(GitDetector),\n\t\t\tnew(GitHubDetector),\n\t\t},\n\t}\n\tclient := &Client{\n\t\tGetters: []Getter{getter},\n\t}\n\n\tctx := context.Background()\n\t_, err = client.Get(ctx, req)\n\tif err == nil {\n\t\tt.Fatalf(\"expected client get to fail\")\n\t}\n\tif !strings.Contains(err.Error(), \"subdirectory component contain path traversal out of the repository\") {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewIgnoreNormalizer(ignore []v1alpha1.ResourceIgnoreDifferences, overrides map[string]v1alpha1.ResourceOverride, opts IgnoreNormalizerOpts) (diff.Normalizer, error) {\n\tfor key, override := range overrides {\n\t\tgroup, kind, err := getGroupKindForOverrideKey(key)\n\t\tif err != nil {\n\t\t\tlog.Warn(err)\n\t\t}\n\t\tif len(override.IgnoreDifferences.JSONPointers) > 0 || len(override.IgnoreDifferences.JQPathExpressions) > 0 {\n\t\t\tresourceIgnoreDifference := v1alpha1.ResourceIgnoreDifferences{\n\t\t\t\tGroup: group,\n\t\t\t\tKind:  kind,\n\t\t\t}\n\t\t\tif len(override.IgnoreDifferences.JSONPointers) > 0 {\n\t\t\t\tresourceIgnoreDifference.JSONPointers = override.IgnoreDifferences.JSONPointers\n\t\t\t}\n\t\t\tif len(override.IgnoreDifferences.JQPathExpressions) > 0 {\n\t\t\t\tresourceIgnoreDifference.JQPathExpressions = override.IgnoreDifferences.JQPathExpressions\n\t\t\t}\n\t\t\tignore = append(ignore, resourceIgnoreDifference)\n\t\t}\n\t}\n\tpatches := make([]normalizerPatch, 0)\n\tfor i := range ignore {\n\t\tfor _, path := range ignore[i].JSONPointers {\n\t\t\tpatchData, err := json.Marshal([]map[string]string{{\"op\": \"remove\", \"path\": path}})\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tpatch, err := jsonpatch.DecodePatch(patchData)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tpatches = append(patches, &jsonPatchNormalizerPatch{\n\t\t\t\tbaseNormalizerPatch: baseNormalizerPatch{\n\t\t\t\t\tgroupKind: schema.GroupKind{Group: ignore[i].Group, Kind: ignore[i].Kind},\n\t\t\t\t\tname:      ignore[i].Name,\n\t\t\t\t\tnamespace: ignore[i].Namespace,\n\t\t\t\t},\n\t\t\t\tpatch: &patch,\n\t\t\t})\n\t\t}\n\t\tfor _, pathExpression := range ignore[i].JQPathExpressions {\n\t\t\tjqDeletionQuery, err := gojq.Parse(fmt.Sprintf(\"del(%s)\", pathExpression))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tjqDeletionCode, err := gojq.Compile(jqDeletionQuery)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tpatches = append(patches, &jqNormalizerPatch{\n\t\t\t\tbaseNormalizerPatch: baseNormalizerPatch{\n\t\t\t\t\tgroupKind: schema.GroupKind{Group: ignore[i].Group, Kind: ignore[i].Kind},\n\t\t\t\t\tname:      ignore[i].Name,\n\t\t\t\t\tnamespace: ignore[i].Namespace,\n\t\t\t\t},\n\t\t\t\tcode:               jqDeletionCode,\n\t\t\t\tjqExecutionTimeout: opts.getJQExecutionTimeout(),\n\t\t\t})\n\t\t}\n\t}\n\treturn &ignoreNormalizer{patches: patches}, nil\n}", "is_vulnerable": 0}
{"code": "func (c *AuthConfig) getGrantHandler(mux cmdutil.Mux, auth authenticator.Request, clientregistry clientregistry.Registry, authregistry clientauthregistry.Registry) handlers.GrantHandler {\n\tswitch c.Options.GrantConfig.Method {\n\tcase configapi.GrantHandlerDeny:\n\t\treturn handlers.NewEmptyGrant()\n\n\tcase configapi.GrantHandlerAuto:\n\t\treturn handlers.NewAutoGrant()\n\n\tcase configapi.GrantHandlerPrompt:\n\t\tgrantServer := grant.NewGrant(getCSRF(), auth, grant.DefaultFormRenderer, clientregistry, authregistry)\n\t\tgrantServer.Install(mux, OpenShiftApprovePrefix)\n\t\treturn handlers.NewRedirectGrant(OpenShiftApprovePrefix)\n\n\tdefault:\n\t\tglog.Fatalf(\"No grant handler found that matches %v.  The oauth server cannot start!\", c.Options.GrantConfig.Method)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (src *CopyOutResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'H')\n\n\tdst = append(dst, src.OverallFormat)\n\n\tdst = pgio.AppendUint16(dst, uint16(len(src.ColumnFormatCodes)))\n\tfor _, fc := range src.ColumnFormatCodes {\n\t\tdst = pgio.AppendUint16(dst, fc)\n\t}\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (p Precompile) Redelegations(\n\tctx sdk.Context,\n\tmethod *abi.Method,\n\t_ *vm.Contract,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewRedelegationsRequest(method, args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: p.stakingKeeper.Keeper}\n\n\tres, err := queryServer.Redelegations(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := new(RedelegationsOutput).FromResponse(res)\n\n\treturn out.Pack(method.Outputs)\n}", "is_vulnerable": 0}
{"code": "func (repo *Repository) UpdateRepoFile(doer *User, opts UpdateRepoFileOptions) (err error) {\n\trepoWorkingPool.CheckIn(com.ToStr(repo.ID))\n\tdefer repoWorkingPool.CheckOut(com.ToStr(repo.ID))\n\n\tif err = repo.DiscardLocalRepoBranchChanges(opts.OldBranch); err != nil {\n\t\treturn fmt.Errorf(\"discard local repo branch[%s] changes: %v\", opts.OldBranch, err)\n\t} else if err = repo.UpdateLocalCopyBranch(opts.OldBranch); err != nil {\n\t\treturn fmt.Errorf(\"update local copy branch[%s]: %v\", opts.OldBranch, err)\n\t}\n\n\trepoPath := repo.RepoPath()\n\tlocalPath := repo.LocalCopyPath()\n\n\tif opts.OldBranch != opts.NewBranch {\n\t\t// Directly return error if new branch already exists in the server\n\t\tif git.RepoHasBranch(repoPath, opts.NewBranch) {\n\t\t\treturn dberrors.BranchAlreadyExists{Name: opts.NewBranch}\n\t\t}\n\n\t\t// Otherwise, delete branch from local copy in case out of sync\n\t\tif git.RepoHasBranch(localPath, opts.NewBranch) {\n\t\t\tif err = git.RepoDeleteBranch(localPath, opts.NewBranch, git.DeleteBranchOptions{\n\t\t\t\tForce: true,\n\t\t\t}); err != nil {\n\t\t\t\treturn fmt.Errorf(\"delete branch %q: %v\", opts.NewBranch, err)\n\t\t\t}\n\t\t}\n\n\t\tif err := repo.CheckoutNewBranch(opts.OldBranch, opts.NewBranch); err != nil {\n\t\t\treturn fmt.Errorf(\"checkout new branch[%s] from old branch[%s]: %v\", opts.NewBranch, opts.OldBranch, err)\n\t\t}\n\t}\n\n\toldFilePath := path.Join(localPath, opts.OldTreeName)\n\tfilePath := path.Join(localPath, opts.NewTreeName)\n\tif err = os.MkdirAll(path.Dir(filePath), os.ModePerm); err != nil {\n\t\treturn err\n\t}\n\n\t// If it's meant to be a new file, make sure it doesn't exist.\n\tif opts.IsNewFile {\n\t\tif com.IsExist(filePath) {\n\t\t\treturn ErrRepoFileAlreadyExist{filePath}\n\t\t}\n\t}\n\n\t// Ignore move step if it's a new file under a directory.\n\t// Otherwise, move the file when name changed.\n\tif osutil.IsFile(oldFilePath) && opts.OldTreeName != opts.NewTreeName {\n\t\tif err = git.RepoMove(localPath, opts.OldTreeName, opts.NewTreeName); err != nil {\n\t\t\treturn fmt.Errorf(\"git mv %q %q: %v\", opts.OldTreeName, opts.NewTreeName, err)\n\t\t}\n\t}\n\n\tif err = ioutil.WriteFile(filePath, []byte(opts.Content), 0666); err != nil {\n\t\treturn fmt.Errorf(\"write file: %v\", err)\n\t}\n\n\tif err = git.RepoAdd(localPath, git.AddOptions{All: true}); err != nil {\n\t\treturn fmt.Errorf(\"git add --all: %v\", err)\n\t} else if err = git.RepoCommit(localPath, doer.NewGitSig(), opts.Message); err != nil {\n\t\treturn fmt.Errorf(\"commit changes on %q: %v\", localPath, err)\n\t}\n\n\tenvs := ComposeHookEnvs(ComposeHookEnvsOptions{\n\t\tAuthUser:  doer,\n\t\tOwnerName: repo.MustOwner().Name,\n\t\tOwnerSalt: repo.MustOwner().Salt,\n\t\tRepoID:    repo.ID,\n\t\tRepoName:  repo.Name,\n\t\tRepoPath:  repo.RepoPath(),\n\t})\n\tif err = git.RepoPush(localPath, \"origin\", opts.NewBranch, git.PushOptions{Envs: envs}); err != nil {\n\t\treturn fmt.Errorf(\"git push origin %s: %v\", opts.NewBranch, err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestHttpGetter_meta(t *testing.T) {\n\tln := testHttpServer(t)\n\tdefer ln.Close()\n\tctx := context.Background()\n\n\tg := new(HttpGetter)\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/meta\"\n\n\treq := &Request{\n\t\tDst: dst,\n\t\tu:   &u,\n\t}\n\n\t// Get it!\n\tif err := g.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\t// Verify the main file exists\n\tmainPath := filepath.Join(dst, \"main.tf\")\n\tif _, err := os.Stat(mainPath); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestDoesPolicySignatureV2Match(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcreds := globalActiveCred\n\tpolicy := \"policy\"\n\ttestCases := []struct {\n\t\taccessKey string\n\t\tpolicy    string\n\t\tsignature string\n\t\terrCode   APIErrorCode\n\t}{\n\t\t{\"invalidAccessKey\", policy, calculateSignatureV2(policy, creds.SecretKey), ErrInvalidAccessKeyID},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(\"random\", creds.SecretKey), ErrSignatureDoesNotMatch},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(policy, creds.SecretKey), ErrNone},\n\t}\n\tfor i, test := range testCases {\n\t\tformValues := make(http.Header)\n\t\tformValues.Set(\"Awsaccesskeyid\", test.accessKey)\n\t\tformValues.Set(\"Signature\", test.signature)\n\t\tformValues.Set(\"Policy\", test.policy)\n\t\terrCode := doesPolicySignatureV2Match(formValues)\n\t\tif errCode != test.errCode {\n\t\t\tt.Fatalf(\"(%d) expected to get %s, instead got %s\", i+1, niceError(test.errCode), niceError(errCode))\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Task(ctx context.Context, in *sliverpb.TaskReq, opts ...grpc.CallOption) (*sliverpb.Task, error) {\n\tout := new(sliverpb.Task)\n\terr := c.cc.Invoke(ctx, SliverRPC_Task_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestTimeWindowCheckFilter(t *testing.T) {\n\tnextEndorser := &mockEndorserServer{}\n\tauth := NewTimeWindowCheckFilter(time.Minute * 15)\n\tauth.Init(nextEndorser)\n\n\tnow := time.Now()\n\n\t// Scenario I: Not expired timestamp\n\tsp := createSignedProposalForCheckTimeWindow(t, now)\n\t_, err := auth.ProcessProposal(context.Background(), sp)\n\trequire.NoError(t, err)\n\trequire.True(t, nextEndorser.invoked)\n\tnextEndorser.invoked = false\n\n\t// Scenario II: Expired timestamp before\n\tsp = createSignedProposalForCheckTimeWindow(t, now.Add(-time.Minute*30))\n\t_, err = auth.ProcessProposal(context.Background(), sp)\n\trequire.Contains(t, err.Error(), \"request unauthorized due to incorrect timestamp\")\n\trequire.False(t, nextEndorser.invoked)\n\n\t// Scenario III: Expired timestamp after\n\tsp = createSignedProposalForCheckTimeWindow(t, now.Add(time.Minute*30))\n\t_, err = auth.ProcessProposal(context.Background(), sp)\n\trequire.Contains(t, err.Error(), \"request unauthorized due to incorrect timestamp\")\n\trequire.False(t, nextEndorser.invoked)\n}", "is_vulnerable": 0}
{"code": "func (mr *MockRequesterMockRecorder) SetID(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"SetID\", reflect.TypeOf((*MockRequester)(nil).SetID), arg0)\n}", "is_vulnerable": 0}
{"code": "func (c *proxiedConn) LocalAddr() net.Addr {\n\tif c.boundAddr != nil {\n\t\treturn c.boundAddr\n\t}\n\treturn c.conn.LocalAddr()\n}", "is_vulnerable": 0}
{"code": "func (e *ERC20LogicView) FindBridgeResumed(\n\tal *types.ERC20EventBridgeResumed,\n\tblockNumber,\n\tlogIndex uint64,\n) error {\n\tbf, err := bridgecontract.NewErc20BridgeLogicRestrictedFilterer(\n\t\te.clt.CollateralBridgeAddress(), e.clt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresp := \"ok\"\n\tdefer func() {\n\t\tmetrics.EthCallInc(\"find_bridge_stopped\", resp)\n\t}()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\titer, err := bf.FilterBridgeResumed(\n\t\t&bind.FilterOpts{\n\t\t\tStart:   blockNumber - 1,\n\t\t\tContext: ctx,\n\t\t},\n\t)\n\tif err != nil {\n\t\tresp = getMaybeHTTPStatus(err)\n\t\treturn err\n\t}\n\tdefer iter.Close()\n\n\tvar event *bridgecontract.Erc20BridgeLogicRestrictedBridgeResumed\n\n\tfor iter.Next() {\n\t\tif iter.Event.Raw.BlockNumber == blockNumber &&\n\t\t\tuint64(iter.Event.Raw.Index) == logIndex {\n\t\t\tevent = iter.Event\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif event == nil {\n\t\treturn ErrUnableToFindERC20BridgeStopped\n\t}\n\n\t// now ensure we have enough confirmations\n\tif err := e.ethConfs.Check(event.Raw.BlockNumber); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func InEpsilonSlice(t TestingT, expected interface{}, actual interface{}, epsilon float64, msgAndArgs ...interface{}) {\n\tif assert.InEpsilonSlice(t, expected, actual, epsilon, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func securityConfigureGenerator(s *specgen.SpecGenerator, g *generate.Generator, newImage *libimage.Image, rtc *config.Config) error {\n\tvar (\n\t\tcaplist []string\n\t\terr     error\n\t)\n\t// HANDLE CAPABILITIES\n\t// NOTE: Must happen before SECCOMP\n\tif s.Privileged {\n\t\tg.SetupPrivileged(true)\n\t\tcaplist, err = capabilities.BoundingSet()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\tmergedCaps, err := capabilities.MergeCapabilities(rtc.Containers.DefaultCapabilities, s.CapAdd, s.CapDrop)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tboundingSet, err := capabilities.BoundingSet()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tboundingCaps := make(map[string]interface{})\n\t\tfor _, b := range boundingSet {\n\t\t\tboundingCaps[b] = b\n\t\t}\n\t\tfor _, c := range mergedCaps {\n\t\t\tif _, ok := boundingCaps[c]; ok {\n\t\t\t\tcaplist = append(caplist, c)\n\t\t\t}\n\t\t}\n\n\t\tprivCapsRequired := []string{}\n\n\t\t// If the container image specifies an label with a\n\t\t// capabilities.ContainerImageLabel then split the comma separated list\n\t\t// of capabilities and record them.  This list indicates the only\n\t\t// capabilities, required to run the container.\n\t\tvar capsRequiredRequested []string\n\t\tfor key, val := range s.Labels {\n\t\t\tif util.StringInSlice(key, capabilities.ContainerImageLabels) {\n\t\t\t\tcapsRequiredRequested = strings.Split(val, \",\")\n\t\t\t}\n\t\t}\n\t\tif !s.Privileged && len(capsRequiredRequested) > 0 {\n\t\t\t// Pass capRequiredRequested in CapAdd field to normalize capabilities names\n\t\t\tcapsRequired, err := capabilities.MergeCapabilities(nil, capsRequiredRequested, nil)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"capabilities requested by user or image are not valid: %q\", strings.Join(capsRequired, \",\"))\n\t\t\t}\n\t\t\t// Verify all capRequired are in the capList\n\t\t\tfor _, cap := range capsRequired {\n\t\t\t\tif !util.StringInSlice(cap, caplist) {\n\t\t\t\t\tprivCapsRequired = append(privCapsRequired, cap)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif len(privCapsRequired) == 0 {\n\t\t\t\tcaplist = capsRequired\n\t\t\t} else {\n\t\t\t\tlogrus.Errorf(\"Capabilities requested by user or image are not allowed by default: %q\", strings.Join(privCapsRequired, \",\"))\n\t\t\t}\n\t\t}\n\t}\n\n\tconfigSpec := g.Config\n\tconfigSpec.Process.Capabilities.Ambient = []string{}\n\n\t// Always unset the inheritable capabilities similarly to what the Linux kernel does\n\t// They are used only when using capabilities with uid != 0.\n\tconfigSpec.Process.Capabilities.Inheritable = []string{}\n\tconfigSpec.Process.Capabilities.Bounding = caplist\n\n\tuser := strings.Split(s.User, \":\")[0]\n\n\tif (user == \"\" && s.UserNS.NSMode != specgen.KeepID) || user == \"root\" || user == \"0\" {\n\t\tconfigSpec.Process.Capabilities.Effective = caplist\n\t\tconfigSpec.Process.Capabilities.Permitted = caplist\n\t} else {\n\t\tmergedCaps, err := capabilities.MergeCapabilities(nil, s.CapAdd, nil)\n\t\tif err != nil {\n\t\t\treturn errors.Wrapf(err, \"capabilities requested by user are not valid: %q\", strings.Join(s.CapAdd, \",\"))\n\t\t}\n\t\tboundingSet, err := capabilities.BoundingSet()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tboundingCaps := make(map[string]interface{})\n\t\tfor _, b := range boundingSet {\n\t\t\tboundingCaps[b] = b\n\t\t}\n\t\tvar userCaps []string\n\t\tfor _, c := range mergedCaps {\n\t\t\tif _, ok := boundingCaps[c]; ok {\n\t\t\t\tuserCaps = append(userCaps, c)\n\t\t\t}\n\t\t}\n\t\tconfigSpec.Process.Capabilities.Effective = userCaps\n\t\tconfigSpec.Process.Capabilities.Permitted = userCaps\n\n\t\t// Ambient capabilities were added to Linux 4.3.  Set ambient\n\t\t// capabilities only when the kernel supports them.\n\t\tif supportAmbientCapabilities() {\n\t\t\tconfigSpec.Process.Capabilities.Ambient = userCaps\n\t\t\tconfigSpec.Process.Capabilities.Inheritable = userCaps\n\t\t}\n\t}\n\n\tg.SetProcessNoNewPrivileges(s.NoNewPrivileges)\n\n\tif err := setupApparmor(s, rtc, g); err != nil {\n\t\treturn err\n\t}\n\n\t// HANDLE SECCOMP\n\tif s.SeccompProfilePath != \"unconfined\" {\n\t\tseccompConfig, err := getSeccompConfig(s, configSpec, newImage)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tconfigSpec.Linux.Seccomp = seccompConfig\n\t}\n\n\t// Clear default Seccomp profile from Generator for unconfined containers\n\t// and privileged containers which do not specify a seccomp profile.\n\tif s.SeccompProfilePath == \"unconfined\" || (s.Privileged && (s.SeccompProfilePath == \"\" || s.SeccompProfilePath == config.SeccompOverridePath || s.SeccompProfilePath == config.SeccompDefaultPath)) {\n\t\tconfigSpec.Linux.Seccomp = nil\n\t}\n\n\tg.SetRootReadonly(s.ReadOnlyFilesystem)\n\n\tnoUseIPC := s.IpcNS.NSMode == specgen.FromContainer || s.IpcNS.NSMode == specgen.FromPod || s.IpcNS.NSMode == specgen.Host\n\tnoUseNet := s.NetNS.NSMode == specgen.FromContainer || s.NetNS.NSMode == specgen.FromPod || s.NetNS.NSMode == specgen.Host\n\tnoUseUTS := s.UtsNS.NSMode == specgen.FromContainer || s.UtsNS.NSMode == specgen.FromPod || s.UtsNS.NSMode == specgen.Host\n\n\t// Add default sysctls\n\tdefaultSysctls, err := util.ValidateSysctls(rtc.Sysctls())\n\tif err != nil {\n\t\treturn err\n\t}\n\tfor sysctlKey, sysctlVal := range defaultSysctls {\n\t\t// Ignore mqueue sysctls if --ipc=host\n\t\tif noUseIPC && strings.HasPrefix(sysctlKey, \"fs.mqueue.\") {\n\t\t\tlogrus.Infof(\"Sysctl %s=%s ignored in containers.conf, since IPC Namespace set to host\", sysctlKey, sysctlVal)\n\n\t\t\tcontinue\n\t\t}\n\n\t\t// Ignore net sysctls if --net=host\n\t\tif noUseNet && strings.HasPrefix(sysctlKey, \"net.\") {\n\t\t\tlogrus.Infof(\"Sysctl %s=%s ignored in containers.conf, since Network Namespace set to host\", sysctlKey, sysctlVal)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Ignore uts sysctls if --uts=host\n\t\tif noUseUTS && (strings.HasPrefix(sysctlKey, \"kernel.domainname\") || strings.HasPrefix(sysctlKey, \"kernel.hostname\")) {\n\t\t\tlogrus.Infof(\"Sysctl %s=%s ignored in containers.conf, since UTS Namespace set to host\", sysctlKey, sysctlVal)\n\t\t\tcontinue\n\t\t}\n\n\t\tg.AddLinuxSysctl(sysctlKey, sysctlVal)\n\t}\n\n\tfor sysctlKey, sysctlVal := range s.Sysctl {\n\t\tif s.IpcNS.IsHost() && strings.HasPrefix(sysctlKey, \"fs.mqueue.\") {\n\t\t\treturn errors.Wrapf(define.ErrInvalidArg, \"sysctl %s=%s can't be set since IPC Namespace set to host\", sysctlKey, sysctlVal)\n\t\t}\n\n\t\t// Ignore net sysctls if --net=host\n\t\tif s.NetNS.IsHost() && strings.HasPrefix(sysctlKey, \"net.\") {\n\t\t\treturn errors.Wrapf(define.ErrInvalidArg, \"sysctl %s=%s can't be set since Network Namespace set to host\", sysctlKey, sysctlVal)\n\t\t}\n\n\t\t// Ignore uts sysctls if --uts=host\n\t\tif s.UtsNS.IsHost() && (strings.HasPrefix(sysctlKey, \"kernel.domainname\") || strings.HasPrefix(sysctlKey, \"kernel.hostname\")) {\n\t\t\treturn errors.Wrapf(define.ErrInvalidArg, \"sysctl %s=%s can't be set since UTS Namespace set to host\", sysctlKey, sysctlVal)\n\t\t}\n\n\t\tg.AddLinuxSysctl(sysctlKey, sysctlVal)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func GetRangeIP(ipnet *net.IPNet) (net.IP, net.IP) {\n\tip := ipnet.IP\n\tmask := ipnet.Mask\n\n\tbeginIP := make([]byte, len(ip))\n\tendIP := make([]byte, len(ip))\n\tfor i := range []byte(ip) {\n\t\tbeginIP[i] = ip[i] & mask[i]\n\t\tendIP[i] = ip[i] | ^mask[i]\n\t}\n\treturn net.IP(beginIP), net.IP(endIP)\n}", "is_vulnerable": 1}
{"code": "func InstrumentHandlerResponseSize(obs prometheus.ObserverVec, next http.Handler) http.Handler {\n\tcode, method := checkLabels(obs)\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\td := newDelegator(w, nil)\n\t\tnext.ServeHTTP(d, r)\n\t\tobs.With(labels(code, method, r.Method, d.Status())).Observe(float64(d.Written()))\n\t})\n}", "is_vulnerable": 1}
{"code": "func newBaseGoCollector() baseGoCollector {\n\treturn baseGoCollector{\n\t\tgoroutinesDesc: NewDesc(\n\t\t\t\"go_goroutines\",\n\t\t\t\"Number of goroutines that currently exist.\",\n\t\t\tnil, nil),\n\t\tthreadsDesc: NewDesc(\n\t\t\t\"go_threads\",\n\t\t\t\"Number of OS threads created.\",\n\t\t\tnil, nil),\n\t\tgcDesc: NewDesc(\n\t\t\t\"go_gc_duration_seconds\",\n\t\t\t\"A summary of the pause duration of garbage collection cycles.\",\n\t\t\tnil, nil),\n\t\tgcLastTimeDesc: NewDesc(\n\t\t\tmemstatNamespace(\"last_gc_time_seconds\"),\n\t\t\t\"Number of seconds since 1970 of last garbage collection.\",\n\t\t\tnil, nil),\n\t\tgoInfoDesc: NewDesc(\n\t\t\t\"go_info\",\n\t\t\t\"Information about the Go environment.\",\n\t\t\tnil, Labels{\"version\": runtime.Version()}),\n\t}\n}", "is_vulnerable": 0}
{"code": "func RequireTeamAdmin(ctx context.Context, r db.Repository, teamID uuid.UUID) error {\n\tuserID, role, ok := GetUser(ctx)\n\tif !ok {\n\t\treturn errors.New(\"internal: user id is not set\")\n\t}\n\tteamRole, err := r.GetTeamRoleForUserID(ctx, db.GetTeamRoleForUserIDParams{UserID: userID, TeamID: teamID})\n\tisAdmin := role == auth.RoleAdmin\n\tisTeamAdmin := err == nil && ConvertToRoleCode(teamRole.RoleCode) == RoleCodeAdmin\n\tif !(isAdmin || isTeamAdmin) {\n\t\treturn &gqlerror.Error{\n\t\t\tMessage: \"organization or team admin role required\",\n\t\t\tExtensions: map[string]interface{}{\n\t\t\t\t\"code\": \"2-400\",\n\t\t\t},\n\t\t}\n\t} else if err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (wh *Webhook) serveInject(w http.ResponseWriter, r *http.Request) {\n\ttotalInjections.Increment()\n\tvar body []byte\n\tif r.Body != nil {\n\t\tif data, err := kube.HTTPConfigReader(r); err == nil {\n\t\t\tbody = data\n\t\t} else {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\tif len(body) == 0 {\n\t\thandleError(\"no body found\")\n\t\thttp.Error(w, \"no body found\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// verify the content type is accurate\n\tcontentType := r.Header.Get(\"Content-Type\")\n\tif contentType != \"application/json\" {\n\t\thandleError(fmt.Sprintf(\"contentType=%s, expect application/json\", contentType))\n\t\thttp.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType)\n\t\treturn\n\t}\n\n\tpath := \"\"\n\tif r.URL != nil {\n\t\tpath = r.URL.Path\n\t}\n\n\tvar reviewResponse *kube.AdmissionResponse\n\tvar obj runtime.Object\n\tvar ar *kube.AdmissionReview\n\tif out, _, err := deserializer.Decode(body, nil, obj); err != nil {\n\t\thandleError(fmt.Sprintf(\"Could not decode body: %v\", err))\n\t\treviewResponse = toAdmissionResponse(err)\n\t} else {\n\t\tlog.Debugf(\"AdmissionRequest for path=%s\\n\", path)\n\t\tar, err = kube.AdmissionReviewKubeToAdapter(out)\n\t\tif err != nil {\n\t\t\thandleError(fmt.Sprintf(\"Could not decode object: %v\", err))\n\t\t}\n\t\treviewResponse = wh.inject(ar, path)\n\t}\n\n\tresponse := kube.AdmissionReview{}\n\tresponse.Response = reviewResponse\n\tvar responseKube runtime.Object\n\tvar apiVersion string\n\tif ar != nil {\n\t\tapiVersion = ar.APIVersion\n\t\tresponse.TypeMeta = ar.TypeMeta\n\t\tif response.Response != nil {\n\t\t\tif ar.Request != nil {\n\t\t\t\tresponse.Response.UID = ar.Request.UID\n\t\t\t}\n\t\t}\n\t}\n\tresponseKube = kube.AdmissionReviewAdapterToKube(&response, apiVersion)\n\tresp, err := json.Marshal(responseKube)\n\tif err != nil {\n\t\tlog.Errorf(\"Could not encode response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not encode response: %v\", err), http.StatusInternalServerError)\n\t}\n\tif _, err := w.Write(resp); err != nil {\n\t\tlog.Errorf(\"Could not write response: %v\", err)\n\t\thttp.Error(w, fmt.Sprintf(\"could not write response: %v\", err), http.StatusInternalServerError)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) SaveImplantProfile(ctx context.Context, in *clientpb.ImplantProfile, opts ...grpc.CallOption) (*clientpb.ImplantProfile, error) {\n\tout := new(clientpb.ImplantProfile)\n\terr := c.cc.Invoke(ctx, SliverRPC_SaveImplantProfile_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (l *Login) handlePasswordReset(w http.ResponseWriter, r *http.Request) {\n\tauthReq, err := l.getAuthRequest(r)\n\tif err != nil {\n\t\tl.renderError(w, r, authReq, err)\n\t\treturn\n\t}\n\tloginName, err := query.NewUserLoginNamesSearchQuery(authReq.LoginName)\n\tif err != nil {\n\t\tl.renderInitPassword(w, r, authReq, authReq.UserID, \"\", err)\n\t\treturn\n\t}\n\tuser, err := l.query.GetUser(setContext(r.Context(), authReq.UserOrgID), true, false, loginName)\n\tif err != nil {\n\t\tif authReq.LoginPolicy.IgnoreUnknownUsernames && errors.IsNotFound(err) {\n\t\t\terr = nil\n\t\t}\n\t\tl.renderPasswordResetDone(w, r, authReq, err)\n\t\treturn\n\t}\n\tpasswordCodeGenerator, err := l.query.InitEncryptionGenerator(r.Context(), domain.SecretGeneratorTypePasswordResetCode, l.userCodeAlg)\n\tif err != nil {\n\t\tif authReq.LoginPolicy.IgnoreUnknownUsernames && errors.IsNotFound(err) {\n\t\t\terr = nil\n\t\t}\n\t\tl.renderPasswordResetDone(w, r, authReq, err)\n\t\treturn\n\t}\n\t_, err = l.command.RequestSetPassword(setContext(r.Context(), authReq.UserOrgID), user.ID, authReq.UserOrgID, domain.NotificationTypeEmail, passwordCodeGenerator)\n\tl.renderPasswordResetDone(w, r, authReq, err)\n}", "is_vulnerable": 0}
{"code": "func DelayWithRetryAfter(resp *http.Response, cancel <-chan struct{}) bool {\n\tif resp == nil {\n\t\treturn false\n\t}\n\tvar dur time.Duration\n\tra := resp.Header.Get(\"Retry-After\")\n\tif retryAfter, _ := strconv.Atoi(ra); retryAfter > 0 {\n\t\tdur = time.Duration(retryAfter) * time.Second\n\t} else if t, err := time.Parse(time.RFC1123, ra); err == nil {\n\t\tdur = t.Sub(time.Now())\n\t}\n\tif dur > 0 {\n\t\tselect {\n\t\tcase <-time.After(dur):\n\t\t\treturn true\n\t\tcase <-cancel:\n\t\t\treturn false\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func templateRunner(config *TaskTemplateManagerConfig) (\n\t*manager.Runner, map[string][]*structs.Template, error) {\n\n\tif len(config.Templates) == 0 {\n\t\treturn nil, nil, nil\n\t}\n\n\t// Parse the templates\n\tctmplMapping, err := parseTemplateConfigs(config)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Create the runner configuration.\n\trunnerConfig, err := newRunnerConfig(config, ctmplMapping)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\trunner, err := manager.NewRunner(runnerConfig, false)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Set Nomad's environment variables.\n\t// consul-template falls back to the host process environment if a\n\t// variable isn't explicitly set in the configuration, so we need\n\t// to mask the environment out to ensure only the task env vars are\n\t// available.\n\trunner.Env = maskProcessEnv(config.EnvBuilder.Build().All())\n\n\t// Build the lookup\n\tidMap := runner.TemplateConfigMapping()\n\tlookup := make(map[string][]*structs.Template, len(idMap))\n\tfor id, ctmpls := range idMap {\n\t\tfor _, ctmpl := range ctmpls {\n\t\t\ttemplates := lookup[id]\n\t\t\ttemplates = append(templates, ctmplMapping[ctmpl])\n\t\t\tlookup[id] = templates\n\t\t}\n\t}\n\n\treturn runner, lookup, nil\n}", "is_vulnerable": 0}
{"code": "func ClusterUp(ctx context.Context, dialersOptions hosts.DialersOptions, flags cluster.ExternalFlags, data map[string]interface{}) (string, string, string, string, map[string]pki.CertificatePKI, error) {\n\tvar APIURL, caCrt, clientCert, clientKey string\n\tvar reconcileCluster, restore bool\n\n\tclusterState, err := cluster.ReadStateFile(ctx, cluster.GetStateFilePath(flags.ClusterFilePath, flags.ConfigDir))\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\t// We generate the first encryption config in ClusterInit, to store it ASAP. It's written to the DesiredState\n\tstateEncryptionConfig := clusterState.DesiredState.EncryptionConfig\n\t// if CurrentState has EncryptionConfig, it means this is NOT the first time we enable encryption, we should use the _latest_ applied value from the current cluster\n\tif clusterState.CurrentState.EncryptionConfig != \"\" {\n\t\tstateEncryptionConfig = clusterState.CurrentState.EncryptionConfig\n\t}\n\n\tkubeCluster, err := cluster.InitClusterObject(ctx, clusterState.DesiredState.RancherKubernetesEngineConfig.DeepCopy(), flags, stateEncryptionConfig)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\tsvcOptionsData := cluster.GetServiceOptionData(data)\n\t// check if rotate certificates is triggered\n\tif kubeCluster.RancherKubernetesEngineConfig.RotateCertificates != nil {\n\t\treturn rebuildClusterWithRotatedCertificates(ctx, dialersOptions, flags, svcOptionsData)\n\t}\n\t// if we need to rotate the encryption key, do so and then return\n\t// note that we rotate the encryption key only when updating an existing cluster that has secret encryption enabled\n\t// all other cases will be handled later by reconciling the encryption provider config\n\tif kubeCluster.RancherKubernetesEngineConfig.RotateEncryptionKey {\n\t\tappliedConfig := clusterState.CurrentState.RancherKubernetesEngineConfig\n\t\tif appliedConfig != nil && appliedConfig.Services.KubeAPI.SecretsEncryptionConfig != nil && appliedConfig.Services.KubeAPI.SecretsEncryptionConfig.Enabled {\n\t\t\treturn RotateEncryptionKey(ctx, clusterState.CurrentState.RancherKubernetesEngineConfig.DeepCopy(), dialersOptions, flags)\n\t\t}\n\t}\n\n\tlog.Infof(ctx, \"Building Kubernetes cluster\")\n\terr = kubeCluster.SetupDialers(ctx, dialersOptions)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\terr = kubeCluster.TunnelHosts(ctx, flags)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\tcurrentCluster, err := kubeCluster.GetClusterState(ctx, clusterState)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\tif !flags.DisablePortCheck {\n\t\tif err = kubeCluster.CheckClusterPorts(ctx, currentCluster); err != nil {\n\t\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t\t}\n\t}\n\n\tif err = kubeCluster.RunSELinuxCheck(ctx); err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terr = cluster.SetUpAuthentication(ctx, kubeCluster, currentCluster, clusterState)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\tif len(kubeCluster.ControlPlaneHosts) > 0 {\n\t\tAPIURL = fmt.Sprintf(\"https://%s:6443\", kubeCluster.ControlPlaneHosts[0].Address)\n\t}\n\tclientCert = string(cert.EncodeCertPEM(kubeCluster.Certificates[pki.KubeAdminCertName].Certificate))\n\tclientKey = string(cert.EncodePrivateKeyPEM(kubeCluster.Certificates[pki.KubeAdminCertName].Key))\n\tcaCrt = string(cert.EncodeCertPEM(kubeCluster.Certificates[pki.CACertName].Certificate))\n\n\t// moved deploying certs before reconcile to remove all unneeded certs generation from reconcile\n\terr = kubeCluster.SetUpHosts(ctx, flags)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terr = cluster.ReconcileCluster(ctx, kubeCluster, currentCluster, flags, svcOptionsData)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\t/* reconcileCluster flag decides whether zero downtime upgrade logic is used or not.\n\tZero-downtime upgrades should happen only when upgrading existing clusters. Not for new clusters or during etcd snapshot restore.\n\tcurrentCluster != nil indicates this is an existing cluster. Restore flag on DesiredState.RancherKubernetesEngineConfig indicates if it's a snapshot restore or not.\n\treconcileCluster flag should be set to true only if currentCluster is not nil and restore is set to false\n\t*/\n\tif clusterState.DesiredState.RancherKubernetesEngineConfig != nil {\n\t\trestore = clusterState.DesiredState.RancherKubernetesEngineConfig.Restore.Restore\n\t}\n\tif currentCluster != nil && !restore {\n\t\t// reconcile this cluster, to check if upgrade is needed, or new nodes are getting added/removed\n\t\t/*This is to separate newly added nodes, so we don't try to check their status/cordon them before upgrade.\n\t\tThis will also cover nodes that were considered inactive first time cluster was provisioned, but are now active during upgrade*/\n\t\tcurrentClusterNodes := make(map[string]bool)\n\t\tfor _, node := range clusterState.CurrentState.RancherKubernetesEngineConfig.Nodes {\n\t\t\tcurrentClusterNodes[node.HostnameOverride] = true\n\t\t}\n\n\t\tnewNodes := make(map[string]bool)\n\t\tfor _, node := range clusterState.DesiredState.RancherKubernetesEngineConfig.Nodes {\n\t\t\tif !currentClusterNodes[node.HostnameOverride] {\n\t\t\t\tnewNodes[node.HostnameOverride] = true\n\t\t\t}\n\t\t}\n\t\tkubeCluster.NewHosts = newNodes\n\t\treconcileCluster = true\n\n\t\tmaxUnavailableWorker, maxUnavailableControl, err := kubeCluster.CalculateMaxUnavailable()\n\t\tif err != nil {\n\t\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t\t}\n\t\tlogrus.Infof(\"Setting maxUnavailable for worker nodes to: %v\", maxUnavailableWorker)\n\t\tlogrus.Infof(\"Setting maxUnavailable for controlplane nodes to: %v\", maxUnavailableControl)\n\t\tkubeCluster.MaxUnavailableForWorkerNodes, kubeCluster.MaxUnavailableForControlNodes = maxUnavailableWorker, maxUnavailableControl\n\t}\n\n\t// update APIURL after reconcile\n\tif len(kubeCluster.ControlPlaneHosts) > 0 {\n\t\tAPIURL = fmt.Sprintf(\"https://%s:6443\", kubeCluster.ControlPlaneHosts[0].Address)\n\t}\n\tif err = cluster.ReconcileEncryptionProviderConfig(ctx, kubeCluster, currentCluster); err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\tif err := kubeCluster.PrePullK8sImages(ctx); err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terrMsgMaxUnavailableNotFailedCtrl, err := kubeCluster.DeployControlPlane(ctx, svcOptionsData, reconcileCluster)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\t// Apply Authz configuration after deploying controlplane\n\terr = cluster.ApplyAuthzResources(ctx, kubeCluster.RancherKubernetesEngineConfig, flags, dialersOptions)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terr = kubeCluster.UpdateClusterCurrentState(ctx, clusterState)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\tk8sClient, err := k8s.NewClient(kubeCluster.LocalKubeConfigPath, kubeCluster.K8sWrapTransport)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, fmt.Errorf(\"failed to create Kubernetes Client: %w\", err)\n\t}\n\n\terr = cluster.SaveFullStateToK8s(ctx, k8sClient, clusterState)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terrMsgMaxUnavailableNotFailedWrkr, err := kubeCluster.DeployWorkerPlane(ctx, svcOptionsData, reconcileCluster)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\tif err = kubeCluster.CleanDeadLogs(ctx); err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terr = kubeCluster.SyncLabelsAndTaints(ctx, currentCluster)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\terr = cluster.ConfigureCluster(ctx, kubeCluster.RancherKubernetesEngineConfig, kubeCluster.Certificates, flags, dialersOptions, data, false)\n\tif err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\tif kubeCluster.EncryptionConfig.RewriteSecrets {\n\t\tif err = kubeCluster.RewriteSecrets(ctx); err != nil {\n\t\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t\t}\n\t}\n\n\tif err := checkAllIncluded(kubeCluster); err != nil {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, err\n\t}\n\n\tif errMsgMaxUnavailableNotFailedCtrl != \"\" || errMsgMaxUnavailableNotFailedWrkr != \"\" {\n\t\treturn APIURL, caCrt, clientCert, clientKey, nil, fmt.Errorf(errMsgMaxUnavailableNotFailedCtrl + errMsgMaxUnavailableNotFailedWrkr)\n\t}\n\tlog.Infof(ctx, \"Finished building Kubernetes cluster successfully\")\n\treturn APIURL, caCrt, clientCert, clientKey, kubeCluster.Certificates, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Client) Get(ctx context.Context, req *Request) (*GetResult, error) {\n\tif err := c.configure(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Pass along the configured Getter client in the context for usage with the X-Terraform-Get feature.\n\tctx = NewContextWithClient(ctx, c)\n\n\t// Store this locally since there are cases we swap this\n\tif req.GetMode == ModeInvalid {\n\t\treq.GetMode = ModeAny\n\t}\n\n\t// Client setting takes precedence for all requests\n\tif c.DisableSymlinks {\n\t\treq.DisableSymlinks = true\n\t}\n\n\t// If there is a subdir component, then we download the root separately\n\t// and then copy over the proper subdir.\n\treq.Src, req.subDir = SourceDirSubdir(req.Src)\n\n\tif req.subDir != \"\" {\n\t\t// Check if the subdirectory is attempting to traverse upwards, outside of\n\t\t// the cloned repository path.\n\t\treq.subDir = filepath.Clean(req.subDir)\n\t\tif containsDotDot(req.subDir) {\n\t\t\treturn nil, fmt.Errorf(\"subdirectory component contain path traversal out of the repository\")\n\t\t}\n\n\t\t// Prevent absolute paths, remove a leading path separator from the subdirectory\n\t\tif req.subDir[0] == os.PathSeparator {\n\t\t\treq.subDir = req.subDir[1:]\n\t\t}\n\n\t\ttd, tdcloser, err := safetemp.Dir(\"\", \"getter\")\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdefer tdcloser.Close()\n\n\t\treq.realDst = req.Dst\n\t\treq.Dst = td\n\t}\n\n\tvar multierr []error\n\tfor _, g := range c.Getters {\n\t\tshouldDownload, err := Detect(req, g)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !shouldDownload {\n\t\t\t// the request should not be processed by that getter\n\t\t\tcontinue\n\t\t}\n\n\t\tresult, getErr := c.get(ctx, req, g)\n\t\tif getErr != nil {\n\t\t\tif getErr.Fatal {\n\t\t\t\treturn nil, getErr.Err\n\t\t\t}\n\t\t\tmultierr = append(multierr, getErr.Err)\n\t\t\tcontinue\n\t\t}\n\n\t\treturn result, nil\n\t}\n\n\tif len(multierr) == 1 {\n\t\t// This is for keeping the error original format\n\t\treturn nil, multierr[0]\n\t}\n\n\tif multierr != nil {\n\t\tvar result *multierror.Error\n\t\tresult = multierror.Append(result, multierr...)\n\t\treturn nil, fmt.Errorf(\"error downloading '%s': %s\", req.Src, result.Error())\n\t}\n\n\treturn nil, fmt.Errorf(\"error downloading '%s'\", req.Src)\n}", "is_vulnerable": 0}
{"code": "func ExtractSignatureAndContent(data []byte) (signature, content []byte) {\n\tdataStr := string(data)\n\tif idx := strings.LastIndex(dataStr, SignaturePattern); idx != -1 {\n\t\tsignature = []byte(strings.TrimSpace(dataStr[idx:]))\n\t\tcontent = []byte(strings.TrimSpace(dataStr[:idx]))\n\t} else {\n\t\tcontent = data\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (p ratelimit) PatchFilter(_ *extensioncommon.RuntimeConfig, filter *envoy_listener_v3.Filter, isInboundListener bool) (*envoy_listener_v3.Filter, bool, error) {\n\t// rate limit is only applied to the inbound listener of the service itself\n\t// since the limit is aggregated from all downstream connections.\n\tif !isInboundListener {\n\t\treturn filter, false, nil\n\t}\n\n\tif filter.Name != \"envoy.filters.network.http_connection_manager\" {\n\t\treturn filter, false, nil\n\t}\n\tif typedConfig := filter.GetTypedConfig(); typedConfig == nil {\n\t\treturn filter, false, errors.New(\"error getting typed config for http filter\")\n\t}\n\n\tconfig := envoy_resource_v3.GetHTTPConnectionManager(filter)\n\tif config == nil {\n\t\treturn filter, false, errors.New(\"error unmarshalling filter\")\n\t}\n\n\ttokenBucket := envoy_type_v3.TokenBucket{}\n\n\tif p.TokensPerFill != nil {\n\t\ttokenBucket.TokensPerFill = &wrappers.UInt32Value{\n\t\t\tValue: uint32(*p.TokensPerFill),\n\t\t}\n\t}\n\tif p.MaxTokens != nil {\n\t\ttokenBucket.MaxTokens = uint32(*p.MaxTokens)\n\t}\n\n\tif p.FillInterval != nil {\n\t\ttokenBucket.FillInterval = durationpb.New(time.Duration(*p.FillInterval) * time.Second)\n\t}\n\n\tvar FilterEnabledDefault *envoy_core_v3.RuntimeFractionalPercent\n\tif p.FilterEnabled != nil {\n\t\tFilterEnabledDefault = &envoy_core_v3.RuntimeFractionalPercent{\n\t\t\tDefaultValue: &envoy_type_v3.FractionalPercent{\n\t\t\t\tNumerator:   *p.FilterEnabled,\n\t\t\t\tDenominator: envoy_type_v3.FractionalPercent_HUNDRED,\n\t\t\t},\n\t\t}\n\t}\n\n\tvar FilterEnforcedDefault *envoy_core_v3.RuntimeFractionalPercent\n\tif p.FilterEnforced != nil {\n\t\tFilterEnforcedDefault = &envoy_core_v3.RuntimeFractionalPercent{\n\t\t\tDefaultValue: &envoy_type_v3.FractionalPercent{\n\t\t\t\tNumerator:   *p.FilterEnforced,\n\t\t\t\tDenominator: envoy_type_v3.FractionalPercent_HUNDRED,\n\t\t\t},\n\t\t}\n\t}\n\n\tratelimitHttpFilter, err := extensioncommon.MakeEnvoyHTTPFilter(\n\t\t\"envoy.filters.http.local_ratelimit\",\n\t\t&envoy_ratelimit.LocalRateLimit{\n\t\t\tTokenBucket:    &tokenBucket,\n\t\t\tStatPrefix:     \"local_ratelimit\",\n\t\t\tFilterEnabled:  FilterEnabledDefault,\n\t\t\tFilterEnforced: FilterEnforcedDefault,\n\t\t},\n\t)\n\n\tif err != nil {\n\t\treturn filter, false, err\n\t}\n\n\tchangedFilters := make([]*envoy_http_v3.HttpFilter, 0, len(config.HttpFilters)+1)\n\n\t// The ratelimitHttpFilter is inserted as the first element of the http\n\t// filter chain.\n\tchangedFilters = append(changedFilters, ratelimitHttpFilter)\n\tchangedFilters = append(changedFilters, config.HttpFilters...)\n\tconfig.HttpFilters = changedFilters\n\n\tnewFilter, err := extensioncommon.MakeFilter(\"envoy.filters.network.http_connection_manager\", config)\n\tif err != nil {\n\t\treturn filter, false, errors.New(\"error making new filter\")\n\t}\n\n\treturn newFilter, true, nil\n}", "is_vulnerable": 0}
{"code": "func TestAuditEvent_new(t *testing.T) {\n\ttests := map[string]struct {\n\t\tOptions              []Option\n\t\tSubtype              subtype\n\t\tFormat               format\n\t\tIsErrorExpected      bool\n\t\tExpectedErrorMessage string\n\t\tExpectedID           string\n\t\tExpectedFormat       format\n\t\tExpectedSubtype      subtype\n\t\tExpectedTimestamp    time.Time\n\t\tIsNowExpected        bool\n\t}{\n\t\t\"nil\": {\n\t\t\tOptions:              nil,\n\t\t\tSubtype:              subtype(\"\"),\n\t\t\tFormat:               format(\"\"),\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.newEvent: audit.(auditEvent).validate: audit.(subtype).validate: '' is not a valid event subtype: invalid parameter\",\n\t\t},\n\t\t\"empty-Option\": {\n\t\t\tOptions:              []Option{},\n\t\t\tSubtype:              subtype(\"\"),\n\t\t\tFormat:               format(\"\"),\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.newEvent: audit.(auditEvent).validate: audit.(subtype).validate: '' is not a valid event subtype: invalid parameter\",\n\t\t},\n\t\t\"bad-id\": {\n\t\t\tOptions:              []Option{WithID(\"\")},\n\t\t\tSubtype:              ResponseType,\n\t\t\tFormat:               JSONFormat,\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.newEvent: error applying options: id cannot be empty\",\n\t\t},\n\t\t\"good\": {\n\t\t\tOptions: []Option{\n\t\t\t\tWithID(\"audit_123\"),\n\t\t\t\tWithFormat(string(JSONFormat)),\n\t\t\t\tWithSubtype(string(ResponseType)),\n\t\t\t\tWithNow(time.Date(2023, time.July, 4, 12, 3, 0, 0, time.Local)),\n\t\t\t},\n\t\t\tSubtype:           RequestType,\n\t\t\tFormat:            JSONxFormat,\n\t\t\tIsErrorExpected:   false,\n\t\t\tExpectedID:        \"audit_123\",\n\t\t\tExpectedTimestamp: time.Date(2023, time.July, 4, 12, 3, 0, 0, time.Local),\n\t\t\tExpectedSubtype:   RequestType,\n\t\t\tExpectedFormat:    JSONxFormat,\n\t\t},\n\t\t\"good-no-time\": {\n\t\t\tOptions: []Option{\n\t\t\t\tWithID(\"audit_123\"),\n\t\t\t\tWithFormat(string(JSONFormat)),\n\t\t\t\tWithSubtype(string(ResponseType)),\n\t\t\t},\n\t\t\tSubtype:         RequestType,\n\t\t\tFormat:          JSONxFormat,\n\t\t\tIsErrorExpected: false,\n\t\t\tExpectedID:      \"audit_123\",\n\t\t\tExpectedSubtype: RequestType,\n\t\t\tExpectedFormat:  JSONxFormat,\n\t\t\tIsNowExpected:   true,\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tname := name\n\t\ttc := tc\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\taudit, err := NewEvent(tc.Subtype, tc.Options...)\n\t\t\tswitch {\n\t\t\tcase tc.IsErrorExpected:\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.EqualError(t, err, tc.ExpectedErrorMessage)\n\t\t\t\trequire.Nil(t, audit)\n\t\t\tdefault:\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NotNil(t, audit)\n\t\t\t\trequire.Equal(t, tc.ExpectedID, audit.ID)\n\t\t\t\trequire.Equal(t, tc.ExpectedSubtype, audit.Subtype)\n\t\t\t\tswitch {\n\t\t\t\tcase tc.IsNowExpected:\n\t\t\t\t\trequire.True(t, time.Now().After(audit.Timestamp))\n\t\t\t\t\trequire.False(t, audit.Timestamp.IsZero())\n\t\t\t\tdefault:\n\t\t\t\t\trequire.Equal(t, tc.ExpectedTimestamp, audit.Timestamp)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *immuClient) _streamVerifiedSet(ctx context.Context, kvs []*stream.KeyValue) (*schema.TxHeader, error) {\n\tif len(kvs) == 0 {\n\t\treturn nil, errors.New(\"no key-values specified\")\n\t}\n\n\tif !c.IsConnected() {\n\t\treturn nil, errors.FromError(ErrNotConnected)\n\t}\n\n\terr := c.StateService.CacheLock()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer c.StateService.CacheUnlock()\n\n\tstart := time.Now()\n\tdefer c.Logger.Debugf(\"StreamVerifiedSet finished in %s\", time.Since(start))\n\n\tstate, err := c.StateService.GetState(ctx, c.Options.CurrentDatabase)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tstateTxID, err := stream.NumberToBytes(state.TxId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//--> collect the keys and values as they need to be used for verifications\n\tstdKVs := make([]*schema.KeyValue, 0, len(kvs))\n\tfor i, kv := range kvs {\n\t\tvar keyBuffer bytes.Buffer\n\t\tkeyTeeReader := io.TeeReader(kv.Key.Content, &keyBuffer)\n\t\tkey := make([]byte, kv.Key.Size)\n\t\tif _, err := keyTeeReader.Read(key); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// put a new Reader back\n\t\tkvs[i].Key.Content = bufio.NewReader(&keyBuffer)\n\n\t\tvar valueBuffer bytes.Buffer\n\t\tvalueTeeReader := io.TeeReader(kv.Value.Content, &valueBuffer)\n\t\tvalue := make([]byte, kv.Value.Size)\n\t\tif _, err = valueTeeReader.Read(value); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// put a new Reader back\n\t\tkvs[i].Value.Content = bufio.NewReader(&valueBuffer)\n\n\t\tstdKVs = append(stdKVs, &schema.KeyValue{Key: key, Value: value})\n\t}\n\t//<--\n\n\ts, err := c.streamVerifiableSet(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tss := c.StreamServiceFactory.NewMsgSender(s)\n\tkvss := c.StreamServiceFactory.NewKvStreamSender(ss)\n\n\terr = ss.Send(bytes.NewBuffer(stateTxID), len(stateTxID))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, kv := range kvs {\n\t\terr = kvss.Send(kv)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tverifiableTx, err := s.CloseAndRecv()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif verifiableTx.Tx.Header.Nentries != int32(len(kvs)) || len(verifiableTx.Tx.Entries) != len(kvs) {\n\t\treturn nil, store.ErrCorruptedData\n\t}\n\n\ttx := schema.TxFromProto(verifiableTx.Tx)\n\n\tentrySpecDigest, err := store.EntrySpecDigestFor(tx.Header().Version)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar verifies bool\n\n\tfor i, kv := range stdKVs {\n\t\tinclusionProof, err := tx.Proof(database.EncodeKey(kv.Key))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tmd := tx.Entries()[i].Metadata()\n\t\te := database.EncodeEntrySpec(kv.Key, md, kv.Value)\n\n\t\tverifies = store.VerifyInclusion(inclusionProof, entrySpecDigest(e), tx.Header().Eh)\n\t\tif !verifies {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\tif tx.Header().Eh != schema.DigestFromProto(verifiableTx.DualProof.TargetTxHeader.EH) {\n\t\treturn nil, store.ErrCorruptedData\n\t}\n\n\tvar sourceID, targetID uint64\n\tvar sourceAlh, targetAlh [sha256.Size]byte\n\n\tsourceID = state.TxId\n\tsourceAlh = schema.DigestFromProto(state.TxHash)\n\ttargetID = tx.Header().ID\n\ttargetAlh = tx.Header().Alh()\n\n\tif state.TxId > 0 {\n\t\tverifies = store.VerifyDualProof(\n\t\t\tschema.DualProofFromProto(verifiableTx.DualProof),\n\t\t\tsourceID,\n\t\t\ttargetID,\n\t\t\tsourceAlh,\n\t\t\ttargetAlh,\n\t\t)\n\n\t\tif !verifies {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\tnewState := &schema.ImmutableState{\n\t\tDb:        c.currentDatabase(),\n\t\tTxId:      targetID,\n\t\tTxHash:    targetAlh[:],\n\t\tSignature: verifiableTx.Signature,\n\t}\n\n\tif c.serverSigningPubKey != nil {\n\t\tok, err := newState.CheckSignature(c.serverSigningPubKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !ok {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\terr = c.StateService.SetState(c.Options.CurrentDatabase, newState)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn verifiableTx.Tx.Header, nil\n}", "is_vulnerable": 1}
{"code": "func (i *Imports) Validate(acctPubKey string, vr *ValidationResults) {\n\ttoSet := make(map[Subject]bool, len(*i))\n\tfor _, v := range *i {\n\t\tif v == nil {\n\t\t\tvr.AddError(\"null import is not allowed\")\n\t\t\tcontinue\n\t\t}\n\t\tif v.Type == Service {\n\t\t\tif _, ok := toSet[v.To]; ok {\n\t\t\t\tvr.AddError(\"Duplicate To subjects for %q\", v.To)\n\t\t\t}\n\t\t\ttoSet[v.To] = true\n\t\t}\n\t\tv.Validate(acctPubKey, vr)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Service) handleMessage(stream StepStream, addr string, exp *certificateExpirationCheck) error {\n\trequest, err := stream.Recv()\n\tif err == io.EOF {\n\t\treturn err\n\t}\n\tif err != nil {\n\t\ts.Logger.Warningf(\"Stream read from %s failed: %v\", addr, err)\n\t\treturn err\n\t}\n\n\texp.checkExpiration(time.Now(), extractChannel(request))\n\n\tif s.StepLogger.IsEnabledFor(zap.DebugLevel) {\n\t\tnodeName := commonNameFromContext(stream.Context())\n\t\ts.StepLogger.Debugf(\"Received message from %s(%s): %v\", nodeName, addr, requestAsString(request))\n\t}\n\n\tif submitReq := request.GetSubmitRequest(); submitReq != nil {\n\t\tnodeName := commonNameFromContext(stream.Context())\n\t\ts.Logger.Debugf(\"Received message from %s(%s): %v\", nodeName, addr, requestAsString(request))\n\t\treturn s.handleSubmit(submitReq, stream, addr)\n\t}\n\n\t// Else, it's a consensus message.\n\treturn s.Dispatcher.DispatchConsensus(stream.Context(), request.GetConsensusRequest())\n}", "is_vulnerable": 1}
{"code": "func streamLocation(getter ResourceGetter, connInfo client.ConnectionInfoGetter, ctx api.Context, name string, opts runtime.Object, container, path string) (*url.URL, http.RoundTripper, error) {\n\tpod, err := getPod(getter, ctx, name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Try to figure out a container\n\tif container == \"\" {\n\t\tif len(pod.Spec.Containers) == 1 {\n\t\t\tcontainer = pod.Spec.Containers[0].Name\n\t\t} else {\n\t\t\treturn nil, nil, errors.NewBadRequest(fmt.Sprintf(\"a container name must be specified for pod %s\", name))\n\t\t}\n\t}\n\tnodeHost := pod.Spec.NodeName\n\tif len(nodeHost) == 0 {\n\t\t// If pod has not been assigned a host, return an empty location\n\t\treturn nil, nil, errors.NewBadRequest(fmt.Sprintf(\"pod %s does not have a host assigned\", name))\n\t}\n\tnodeScheme, nodePort, nodeTransport, err := connInfo.GetConnectionInfo(nodeHost)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tparams := url.Values{}\n\tif err := streamParams(params, opts); err != nil {\n\t\treturn nil, nil, err\n\t}\n\tloc := &url.URL{\n\t\tScheme:   nodeScheme,\n\t\tHost:     fmt.Sprintf(\"%s:%d\", nodeHost, nodePort),\n\t\tPath:     fmt.Sprintf(\"/%s/%s/%s/%s\", path, pod.Namespace, name, container),\n\t\tRawQuery: params.Encode(),\n\t}\n\treturn loc, nodeTransport, nil\n}", "is_vulnerable": 1}
{"code": "func Validate(indexedResources *xdscommon.IndexedResources, envoyID string, vip string, validateEndpoints bool, clusters *envoy_admin_v3.Clusters) validate.Messages {\n\t// Get all SNIs from the clusters in the configuration. Not all SNIs will need to be validated, but this ensures we\n\t// capture SNIs which aren't directly identical to the upstream service name, but are still used for that upstream\n\t// service. For example, in the case of having a splitter/redirect or another L7 config entry, the upstream service\n\t// name could be \"db\" but due to a redirect SNI would be something like\n\t// \"redis.default.dc1.internal.<trustdomain>.consul\". The envoyID will be used to limit which SNIs we actually\n\t// validate.\n\tsnis := map[string]struct{}{}\n\tfor s := range indexedResources.Index[xdscommon.ClusterType] {\n\t\tsnis[s] = struct{}{}\n\t}\n\n\t// For this extension runtime configuration, we are only validating one upstream service, so the map key doesn't\n\t// need the full service name.\n\temptyServiceKey := api.CompoundServiceName{}\n\n\t// Build an ExtensionConfiguration for Validate plugin.\n\textConfig := extensioncommon.RuntimeConfig{\n\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\tName: \"builtin/proxy/validate\",\n\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\"envoyID\": envoyID,\n\t\t\t},\n\t\t},\n\t\tServiceName: emptyServiceKey,\n\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\temptyServiceKey: {\n\t\t\t\tVIP: vip,\n\t\t\t\t// Even though snis are under the upstream service name we're validating, it actually contains all\n\t\t\t\t// the cluster SNIs configured on this proxy, not just the upstream being validated. This means the\n\t\t\t\t// PatchCluster function in the Validate plugin will be run on all clusters, but errors will only\n\t\t\t\t// surface for clusters related to the upstream being validated.\n\t\t\t\tSNI:     snis,\n\t\t\t\tEnvoyID: envoyID,\n\t\t\t},\n\t\t},\n\t\tKind: api.ServiceKindConnectProxy,\n\t}\n\tbasicExtension, err := validate.MakeValidate(extConfig)\n\tif err != nil {\n\t\treturn []validate.Message{{Message: err.Error()}}\n\t}\n\textender := extensioncommon.BasicEnvoyExtender{\n\t\tExtension: basicExtension,\n\t}\n\terr = extender.Validate(&extConfig)\n\tif err != nil {\n\t\treturn []validate.Message{{Message: err.Error()}}\n\t}\n\n\t_, err = extender.Extend(indexedResources, &extConfig)\n\tif err != nil {\n\t\treturn []validate.Message{{Message: err.Error()}}\n\t}\n\n\tv, ok := extender.Extension.(*validate.Validate)\n\tif !ok {\n\t\tpanic(\"validate plugin was not correctly created\")\n\t}\n\n\treturn v.GetMessages(validateEndpoints, validate.DoEndpointValidation, clusters)\n}", "is_vulnerable": 1}
{"code": "func Test_IsTrusted_shouldReturnTrueIfTrustFeatureDisabled(t *testing.T) {\n\ttestutil.UnitTest(t) // disables trust feature\n\tf := NewFolder(\"c:\\\\dummy\\\\dummyF\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\tassert.True(t, f.IsTrusted())\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) Sanitize(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sanitize\", reflect.TypeOf((*MockAccessRequester)(nil).Sanitize), arg0)\n}", "is_vulnerable": 0}
{"code": "func Test_CORS_AllowOriginScheme(t *testing.T) {\n\tt.Parallel()\n\ttests := []struct {\n\t\treqOrigin, pattern string\n\t\tshouldAllowOrigin  bool\n\t}{\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"https://example.com\",\n\t\t\treqOrigin:         \"https://example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"https://example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://bbb.aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.aaa.example.com\",\n\t\t\treqOrigin:         \"http://bbb.aaa.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com:8080\",\n\t\t\treqOrigin:         \"http://aaa.example.com:8080\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://gofiber.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.aaa.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern: \"http://*.example.com\",\n\t\t\treqOrigin: `http://1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890\\\n\t\t  .1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890\\\n\t\t  .1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890\\\n\t\t\t.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.1234567890.example.com`,\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"https://*--aaa.bbb.com\",\n\t\t\treqOrigin:         \"https://prod-preview--aaa.bbb.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://*.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: true,\n\t\t},\n\t\t{\n\t\t\tpattern:           \"http://foo.[a-z]*.example.com\",\n\t\t\treqOrigin:         \"http://ccc.bbb.example.com\",\n\t\t\tshouldAllowOrigin: false,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tapp := fiber.New()\n\t\tapp.Use(\"/\", New(Config{AllowOrigins: tt.pattern}))\n\n\t\thandler := app.Handler()\n\n\t\tctx := &fasthttp.RequestCtx{}\n\t\tctx.Request.SetRequestURI(\"/\")\n\t\tctx.Request.Header.SetMethod(fiber.MethodOptions)\n\t\tctx.Request.Header.Set(fiber.HeaderOrigin, tt.reqOrigin)\n\n\t\thandler(ctx)\n\n\t\tif tt.shouldAllowOrigin {\n\t\t\tutils.AssertEqual(t, tt.reqOrigin, string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\t\t} else {\n\t\t\tutils.AssertEqual(t, \"\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func New(\n\tctx context.Context,\n\tport uint16,\n\trouter *mux.Router,\n\tqueries *query.Queries,\n\tverifier internal_authz.APITokenVerifier,\n\tauthZ internal_authz.Config,\n\ttlsConfig *tls.Config, http2HostName, http1HostName, externalDomain string,\n\taccessInterceptor *http_mw.AccessInterceptor,\n) (_ *API, err error) {\n\tapi := &API{\n\t\tport:              port,\n\t\tverifier:          verifier,\n\t\thealth:            queries,\n\t\trouter:            router,\n\t\thttp1HostName:     http1HostName,\n\t\tqueries:           queries,\n\t\taccessInterceptor: accessInterceptor,\n\t}\n\n\tapi.grpcServer = server.CreateServer(api.verifier, authZ, queries, http2HostName, externalDomain, tlsConfig, accessInterceptor.AccessService())\n\tapi.grpcGateway, err = server.CreateGateway(ctx, port, http1HostName, accessInterceptor, tlsConfig)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tapi.registerHealthServer()\n\n\tapi.RegisterHandlerOnPrefix(\"/debug\", api.healthHandler())\n\tapi.router.Handle(\"/\", http.RedirectHandler(login.HandlerPrefix, http.StatusFound))\n\n\treflection.Register(api.grpcServer)\n\treturn api, nil\n}", "is_vulnerable": 0}
{"code": "func (gfcf *genericProxyFilterConfigFactory) CreateFilterChain(context context.Context, callbacks api.NetWorkFilterChainFactoryCallbacks) {\n\tp := proxy.NewProxy(context, gfcf.Proxy)\n\tcallbacks.AddReadFilter(p)\n}", "is_vulnerable": 1}
{"code": "func (b *Builder) buildGRPCRoutes() ([]*envoy_config_route_v3.Route, error) {\n\taction := &envoy_config_route_v3.Route_Route{\n\t\tRoute: &envoy_config_route_v3.RouteAction{\n\t\t\tClusterSpecifier: &envoy_config_route_v3.RouteAction_Cluster{\n\t\t\t\tCluster: \"pomerium-control-plane-grpc\",\n\t\t\t},\n\t\t},\n\t}\n\treturn []*envoy_config_route_v3.Route{{\n\t\tName: \"pomerium-grpc\",\n\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Prefix{\n\t\t\t\tPrefix: \"/\",\n\t\t\t},\n\t\t\tGrpc: &envoy_config_route_v3.RouteMatch_GrpcRouteMatchOptions{},\n\t\t},\n\t\tAction: action,\n\t\tTypedPerFilterConfig: map[string]*any.Any{\n\t\t\t\"envoy.filters.http.ext_authz\": disableExtAuthz,\n\t\t},\n\t}}, nil\n}", "is_vulnerable": 1}
{"code": "func TestNormalizeJQPathExpression(t *testing.T) {\n\tnormalizer, err := NewIgnoreNormalizer([]v1alpha1.ResourceIgnoreDifferences{{\n\t\tGroup:             \"apps\",\n\t\tKind:              \"Deployment\",\n\t\tJQPathExpressions: []string{\".spec.template.spec.initContainers[] | select(.name == \\\"init-container-0\\\")\"},\n\t}}, make(map[string]v1alpha1.ResourceOverride))\n\n\tassert.Nil(t, err)\n\n\tdeployment := test.NewDeployment()\n\n\tvar initContainers []interface{}\n\tinitContainers = append(initContainers, map[string]interface{}{\"name\": \"init-container-0\"})\n\tinitContainers = append(initContainers, map[string]interface{}{\"name\": \"init-container-1\"})\n\terr = unstructured.SetNestedSlice(deployment.Object, initContainers, \"spec\", \"template\", \"spec\", \"initContainers\")\n\tassert.Nil(t, err)\n\n\tactualInitContainers, has, err := unstructured.NestedSlice(deployment.Object, \"spec\", \"template\", \"spec\", \"initContainers\")\n\tassert.Nil(t, err)\n\tassert.True(t, has)\n\tassert.Len(t, actualInitContainers, 2)\n\n\terr = normalizer.Normalize(deployment)\n\tassert.Nil(t, err)\n\tactualInitContainers, has, err = unstructured.NestedSlice(deployment.Object, \"spec\", \"template\", \"spec\", \"initContainers\")\n\tassert.Nil(t, err)\n\tassert.True(t, has)\n\tassert.Len(t, actualInitContainers, 1)\n\n\tactualInitContainerName, has, err := unstructured.NestedString(actualInitContainers[0].(map[string]interface{}), \"name\")\n\tassert.Nil(t, err)\n\tassert.True(t, has)\n\tassert.Equal(t, actualInitContainerName, \"init-container-1\")\n}", "is_vulnerable": 1}
{"code": "func (gfcf *genericProxyFilterConfigFactory) CreateFilterChain(ctx context.Context, callbacks api.NetWorkFilterChainFactoryCallbacks) {\n\tif gfcf.extendConfig != nil {\n\t\tctx = mosnctx.WithValue(ctx, types.ContextKeyProxyGeneralConfig, gfcf.extendConfig)\n\t}\n\tif gfcf.subProtocols != \"\" {\n\t\tctx = mosnctx.WithValue(ctx, types.ContextSubProtocol, gfcf.subProtocols)\n\t}\n\tp := proxy.NewProxy(ctx, gfcf.Proxy)\n\tcallbacks.AddReadFilter(p)\n}", "is_vulnerable": 0}
{"code": "func TestRoundtrip(t *testing.T) {\n\tt.Parallel()\n\tpayload := []byte(\"Lorem ipsum\")\n\n\tt.Run(\"HMAC\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tsharedkey := []byte(\"Avracadabra\")\n\t\tjwkKey, _ := jwk.FromRaw(sharedkey)\n\t\tkeys := map[string]interface{}{\n\t\t\t\"[]byte\":  sharedkey,\n\t\t\t\"jwk.Key\": jwkKey,\n\t\t}\n\t\thmacAlgorithms := []jwa.SignatureAlgorithm{jwa.HS256, jwa.HS384, jwa.HS512}\n\t\tfor _, alg := range hmacAlgorithms {\n\t\t\talg := alg\n\t\t\tt.Run(alg.String(), func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\ttestRoundtrip(t, payload, alg, sharedkey, keys)\n\t\t\t})\n\t\t}\n\t})\n\tt.Run(\"ECDSA\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tkey, err := jwxtest.GenerateEcdsaKey(jwa.P521)\n\t\trequire.NoError(t, err, \"ECDSA key generated\")\n\t\tjwkKey, _ := jwk.FromRaw(key.PublicKey)\n\t\tkeys := map[string]interface{}{\n\t\t\t\"Verify(ecdsa.PublicKey)\":  key.PublicKey,\n\t\t\t\"Verify(*ecdsa.PublicKey)\": &key.PublicKey,\n\t\t\t\"Verify(jwk.Key)\":          jwkKey,\n\t\t}\n\t\tfor _, alg := range []jwa.SignatureAlgorithm{jwa.ES256, jwa.ES384, jwa.ES512} {\n\t\t\talg := alg\n\t\t\tt.Run(alg.String(), func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\ttestRoundtrip(t, payload, alg, key, keys)\n\t\t\t})\n\t\t}\n\t})\n\tt.Run(\"RSA\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tkey, err := jwxtest.GenerateRsaKey()\n\t\trequire.NoError(t, err, \"RSA key generated\")\n\t\tjwkKey, _ := jwk.FromRaw(key.PublicKey)\n\t\tkeys := map[string]interface{}{\n\t\t\t\"Verify(rsa.PublicKey)\":  key.PublicKey,\n\t\t\t\"Verify(*rsa.PublicKey)\": &key.PublicKey,\n\t\t\t\"Verify(jwk.Key)\":        jwkKey,\n\t\t}\n\t\tfor _, alg := range []jwa.SignatureAlgorithm{jwa.RS256, jwa.RS384, jwa.RS512, jwa.PS256, jwa.PS384, jwa.PS512} {\n\t\t\talg := alg\n\t\t\tt.Run(alg.String(), func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\ttestRoundtrip(t, payload, alg, key, keys)\n\t\t\t})\n\t\t}\n\t})\n\tt.Run(\"EdDSA\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tkey, err := jwxtest.GenerateEd25519Key()\n\t\trequire.NoError(t, err, \"ed25519 key generated\")\n\t\tpubkey := key.Public()\n\t\tjwkKey, _ := jwk.FromRaw(pubkey)\n\t\tkeys := map[string]interface{}{\n\t\t\t\"Verify(ed25519.Public())\": pubkey,\n\t\t\t// Meh, this doesn't work\n\t\t\t// \"Verify(*ed25519.Public())\": &pubkey,\n\t\t\t\"Verify(jwk.Key)\": jwkKey,\n\t\t}\n\t\tfor _, alg := range []jwa.SignatureAlgorithm{jwa.EdDSA} {\n\t\t\talg := alg\n\t\t\tt.Run(alg.String(), func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\ttestRoundtrip(t, payload, alg, key, keys)\n\t\t\t})\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func NewUnstartedAgent(t *testing.T, name string, hcl string) (*Agent, error) {\n\tc := TestConfig(config.Source{Name: name, Format: \"hcl\", Data: hcl})\n\ta, err := New(c)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ta.State = local.NewState(LocalConfig(c), a.logger, a.tokens)\n\ta.sync = ae.NewStateSyncer(a.State, c.AEInterval, a.shutdownCh, a.logger)\n\ta.delegate = &consul.Client{}\n\ta.State.TriggerSyncChanges = a.sync.SyncChanges.Trigger\n\ttlsConfigurator, err := tlsutil.NewConfigurator(c.ToTLSUtilConfig(), nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ta.tlsConfigurator = tlsConfigurator\n\treturn a, nil\n}", "is_vulnerable": 0}
{"code": "func GetReferenceFromDescriptor(desc ocispec.Descriptor, ref name.Reference) string {\n\treturn ref.Context().RegistryStr() + \"/\" + ref.Context().RepositoryStr() + \"@\" + desc.Digest.String()\n}", "is_vulnerable": 0}
{"code": "func (g *Getter) Get(ctx context.Context, req *getter.Request) error {\n\n\tif g.Timeout > 0 {\n\t\tvar cancel context.CancelFunc\n\t\tctx, cancel = context.WithTimeout(ctx, g.Timeout)\n\t\tdefer cancel()\n\t}\n\n\t// Parse URL\n\tbucket, object, err := g.parseURL(req.URL())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Remove destination if it already exists\n\t_, err = os.Stat(req.Dst)\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\tif err == nil {\n\t\t// Remove the destination\n\t\tif err := os.RemoveAll(req.Dst); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Create all the parent directories\n\tif err := os.MkdirAll(filepath.Dir(req.Dst), req.Mode(0755)); err != nil {\n\t\treturn err\n\t}\n\n\tclient, err := storage.NewClient(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Iterate through all matching objects.\n\titer := client.Bucket(bucket).Objects(ctx, &storage.Query{Prefix: object})\n\tfor {\n\t\tobj, err := iter.Next()\n\t\tif err != nil && err != iterator.Done {\n\t\t\treturn err\n\t\t}\n\t\tif err == iterator.Done {\n\t\t\tbreak\n\t\t}\n\n\t\tif !strings.HasSuffix(obj.Name, \"/\") {\n\t\t\t// Get the object destination path\n\t\t\tobjDst, err := filepath.Rel(object, obj.Name)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tobjDst = filepath.Join(req.Dst, objDst)\n\t\t\t// Download the matching object.\n\t\t\terr = g.getObject(ctx, client, req, objDst, bucket, obj.Name)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestServiceSoftwareInventoryAuth(t *testing.T) {\n\tds := new(mock.Store)\n\n\tds.ListSoftwareFunc = func(ctx context.Context, opt fleet.SoftwareListOptions) ([]fleet.Software, error) {\n\t\treturn []fleet.Software{}, nil\n\t}\n\tds.CountSoftwareFunc = func(ctx context.Context, opt fleet.SoftwareListOptions) (int, error) {\n\t\treturn 0, nil\n\t}\n\tsvc := newTestService(t, ds, nil, nil)\n\n\tfor _, tc := range []struct {\n\t\tname                 string\n\t\tuser                 *fleet.User\n\t\tshouldFailGlobalRead bool\n\t\tshouldFailTeamRead   bool\n\t}{\n\t\t{\n\t\t\tname: \"global-admin\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID:         1,\n\t\t\t\tGlobalRole: ptr.String(fleet.RoleAdmin),\n\t\t\t},\n\t\t\tshouldFailGlobalRead: false,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"global-maintainer\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID:         1,\n\t\t\t\tGlobalRole: ptr.String(fleet.RoleMaintainer),\n\t\t\t},\n\t\t\tshouldFailGlobalRead: false,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"global-observer\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID:         1,\n\t\t\t\tGlobalRole: ptr.String(fleet.RoleObserver),\n\t\t\t},\n\t\t\tshouldFailGlobalRead: false,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"team-admin-belongs-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 1},\n\t\t\t\t\tRole: fleet.RoleAdmin,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"team-maintainer-belongs-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 1},\n\t\t\t\t\tRole: fleet.RoleMaintainer,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"team-observer-belongs-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 1},\n\t\t\t\t\tRole: fleet.RoleObserver,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"team-admin-does-not-belong-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 2},\n\t\t\t\t\tRole: fleet.RoleAdmin,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"team-maintainer-does-not-belong-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 2},\n\t\t\t\t\tRole: fleet.RoleMaintainer,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"team-observer-does-not-belong-to-team\",\n\t\t\tuser: &fleet.User{\n\t\t\t\tID: 1,\n\t\t\t\tTeams: []fleet.UserTeam{{\n\t\t\t\t\tTeam: fleet.Team{ID: 2},\n\t\t\t\t\tRole: fleet.RoleObserver,\n\t\t\t\t}},\n\t\t\t},\n\t\t\tshouldFailGlobalRead: true,\n\t\t\tshouldFailTeamRead:   true,\n\t\t},\n\t} {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tctx := viewer.NewContext(context.Background(), viewer.Viewer{User: tc.user})\n\n\t\t\t// List all software.\n\t\t\t_, err := svc.ListSoftware(ctx, fleet.SoftwareListOptions{})\n\t\t\tcheckAuthErr(t, tc.shouldFailGlobalRead, err)\n\n\t\t\t// Count all software.\n\t\t\t_, err = svc.CountSoftware(ctx, fleet.SoftwareListOptions{})\n\t\t\tcheckAuthErr(t, tc.shouldFailGlobalRead, err)\n\n\t\t\t// List software for a team.\n\t\t\t_, err = svc.ListSoftware(ctx, fleet.SoftwareListOptions{\n\t\t\t\tTeamID: ptr.Uint(1),\n\t\t\t})\n\t\t\tcheckAuthErr(t, tc.shouldFailTeamRead, err)\n\n\t\t\t// Count software for a team.\n\t\t\t_, err = svc.CountSoftware(ctx, fleet.SoftwareListOptions{\n\t\t\t\tTeamID: ptr.Uint(1),\n\t\t\t})\n\t\t\tcheckAuthErr(t, tc.shouldFailTeamRead, err)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func oauth2Login(ctx context.Context, port int, oidcSettings *settingspkg.OIDCConfig, oauth2conf *oauth2.Config, provider *oidc.Provider) (string, string) {\n\toauth2conf.RedirectURL = fmt.Sprintf(\"http://localhost:%d/auth/callback\", port)\n\toidcConf, err := oidcutil.ParseConfig(provider)\n\terrors.CheckError(err)\n\tlog.Debug(\"OIDC Configuration:\")\n\tlog.Debugf(\"  supported_scopes: %v\", oidcConf.ScopesSupported)\n\tlog.Debugf(\"  response_types_supported: %v\", oidcConf.ResponseTypesSupported)\n\n\t// handledRequests ensures we do not handle more requests than necessary\n\thandledRequests := 0\n\t// completionChan is to signal flow completed. Non-empty string indicates error\n\tcompletionChan := make(chan string)\n\t// stateNonce is an OAuth2 state nonce\n\tstateNonce := rand.RandString(10)\n\tvar tokenString string\n\tvar refreshToken string\n\n\thandleErr := func(w http.ResponseWriter, errMsg string) {\n\t\thttp.Error(w, html.EscapeString(errMsg), http.StatusBadRequest)\n\t\tcompletionChan <- errMsg\n\t}\n\n\t// PKCE implementation of https://tools.ietf.org/html/rfc7636\n\tcodeVerifier := rand.RandStringCharset(43, \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~\")\n\tcodeChallengeHash := sha256.Sum256([]byte(codeVerifier))\n\tcodeChallenge := base64.RawURLEncoding.EncodeToString(codeChallengeHash[:])\n\n\t// Authorization redirect callback from OAuth2 auth flow.\n\t// Handles both implicit and authorization code flow\n\tcallbackHandler := func(w http.ResponseWriter, r *http.Request) {\n\t\tlog.Debugf(\"Callback: %s\", r.URL)\n\n\t\tif formErr := r.FormValue(\"error\"); formErr != \"\" {\n\t\t\thandleErr(w, fmt.Sprintf(\"%s: %s\", formErr, r.FormValue(\"error_description\")))\n\t\t\treturn\n\t\t}\n\n\t\thandledRequests++\n\t\tif handledRequests > 2 {\n\t\t\t// Since implicit flow will redirect back to ourselves, this counter ensures we do not\n\t\t\t// fallinto a redirect loop (e.g. user visits the page by hand)\n\t\t\thandleErr(w, \"Unable to complete login flow: too many redirects\")\n\t\t\treturn\n\t\t}\n\n\t\tif len(r.Form) == 0 {\n\t\t\t// If we get here, no form data was set. We presume to be performing an implicit login\n\t\t\t// flow where the id_token is contained in a URL fragment, making it inaccessible to be\n\t\t\t// read from the request. This javascript will redirect the browser to send the\n\t\t\t// fragments as query parameters so our callback handler can read and return token.\n\t\t\tfmt.Fprintf(w, `<script>window.location.search = window.location.hash.substring(1)</script>`)\n\t\t\treturn\n\t\t}\n\n\t\tif state := r.FormValue(\"state\"); state != stateNonce {\n\t\t\thandleErr(w, \"Unknown state nonce\")\n\t\t\treturn\n\t\t}\n\n\t\ttokenString = r.FormValue(\"id_token\")\n\t\tif tokenString == \"\" {\n\t\t\tcode := r.FormValue(\"code\")\n\t\t\tif code == \"\" {\n\t\t\t\thandleErr(w, fmt.Sprintf(\"no code in request: %q\", r.Form))\n\t\t\t\treturn\n\t\t\t}\n\t\t\topts := []oauth2.AuthCodeOption{oauth2.SetAuthURLParam(\"code_verifier\", codeVerifier)}\n\t\t\ttok, err := oauth2conf.Exchange(ctx, code, opts...)\n\t\t\tif err != nil {\n\t\t\t\thandleErr(w, err.Error())\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar ok bool\n\t\t\ttokenString, ok = tok.Extra(\"id_token\").(string)\n\t\t\tif !ok {\n\t\t\t\thandleErr(w, \"no id_token in token response\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\trefreshToken, _ = tok.Extra(\"refresh_token\").(string)\n\t\t}\n\t\tsuccessPage := `\n\t\t<div style=\"height:100px; width:100%!; display:flex; flex-direction: column; justify-content: center; align-items:center; background-color:#2ecc71; color:white; font-size:22\"><div>Authentication successful!</div></div>\n\t\t<p style=\"margin-top:20px; font-size:18; text-align:center\">Authentication was successful, you can now return to CLI. This page will close automatically</p>\n\t\t<script>window.onload=function(){setTimeout(this.close, 4000)}</script>\n\t\t`\n\t\tfmt.Fprint(w, successPage)\n\t\tcompletionChan <- \"\"\n\t}\n\tsrv := &http.Server{Addr: \"localhost:\" + strconv.Itoa(port)}\n\thttp.HandleFunc(\"/auth/callback\", callbackHandler)\n\n\t// Redirect user to login & consent page to ask for permission for the scopes specified above.\n\tfmt.Printf(\"Opening browser for authentication\\n\")\n\n\tvar url string\n\tgrantType := oidcutil.InferGrantType(oidcConf)\n\topts := []oauth2.AuthCodeOption{oauth2.AccessTypeOffline}\n\tif claimsRequested := oidcSettings.GetIDTokenClaims(); claimsRequested != nil {\n\t\topts = oidcutil.AppendClaimsAuthenticationRequestParameter(opts, claimsRequested)\n\t}\n\n\tswitch grantType {\n\tcase oidcutil.GrantTypeAuthorizationCode:\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge\", codeChallenge))\n\t\topts = append(opts, oauth2.SetAuthURLParam(\"code_challenge_method\", \"S256\"))\n\t\turl = oauth2conf.AuthCodeURL(stateNonce, opts...)\n\tcase oidcutil.GrantTypeImplicit:\n\t\turl = oidcutil.ImplicitFlowURL(oauth2conf, stateNonce, opts...)\n\tdefault:\n\t\tlog.Fatalf(\"Unsupported grant type: %v\", grantType)\n\t}\n\tfmt.Printf(\"Performing %s flow login: %s\\n\", grantType, url)\n\ttime.Sleep(1 * time.Second)\n\terr = open.Start(url)\n\terrors.CheckError(err)\n\tgo func() {\n\t\tlog.Debugf(\"Listen: %s\", srv.Addr)\n\t\tif err := srv.ListenAndServe(); err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"Temporary HTTP server failed: %s\", err)\n\t\t}\n\t}()\n\terrMsg := <-completionChan\n\tif errMsg != \"\" {\n\t\tlog.Fatal(errMsg)\n\t}\n\tfmt.Printf(\"Authentication successful\\n\")\n\tctx, cancel := context.WithTimeout(ctx, 1*time.Second)\n\tdefer cancel()\n\t_ = srv.Shutdown(ctx)\n\tlog.Debugf(\"Token: %s\", tokenString)\n\tlog.Debugf(\"Refresh Token: %s\", refreshToken)\n\treturn tokenString, refreshToken\n}", "is_vulnerable": 1}
{"code": "func NewDeploymentOperationsListResultPage(getNextPage func(context.Context, DeploymentOperationsListResult) (DeploymentOperationsListResult, error)) DeploymentOperationsListResultPage {\n\treturn DeploymentOperationsListResultPage{fn: getNextPage}\n}", "is_vulnerable": 0}
{"code": "func (user *User) Match(username, password string) bool {\n\twhere := \"(name = ? OR email = ?) AND status =? \"\n\t_, err := Db.Where(where, username, username, Enabled).Get(user)\n\tif err != nil {\n\t\treturn false\n\t}\n\thashPassword := user.encryptPassword(password, user.Salt)\n\tif hashPassword != user.Password {\n\t\treturn false\n\t}\n\n\treturn true\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeResponder) GetQuery() url.Values {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetQuery\")\n\tret0, _ := ret[0].(url.Values)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (fakeIngressStore) GetBackendConfiguration() ngx_config.Configuration {\n\treturn ngx_config.Configuration{}\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_outgoingWrapper_BadDC(t *testing.T) {\n\tconfig := Config{\n\t\tCAFile:               \"../test/hostname/CertAuth.crt\",\n\t\tCertFile:             \"../test/hostname/Alice.crt\",\n\t\tKeyFile:              \"../test/hostname/Alice.key\",\n\t\tVerifyServerHostname: true,\n\t\tVerifyOutgoing:       true,\n\t\tDomain:               \"consul\",\n\t}\n\n\tclient, errc := startTLSServer(&config)\n\tif client == nil {\n\t\tt.Fatalf(\"startTLSServer err: %v\", <-errc)\n\t}\n\n\tc, err := NewConfigurator(config, nil)\n\trequire.NoError(t, err)\n\twrap := c.OutgoingRPCWrapper()\n\n\ttlsClient, err := wrap(\"dc2\", client)\n\trequire.NoError(t, err)\n\n\terr = tlsClient.(*tls.Conn).Handshake()\n\t_, ok := err.(x509.HostnameError)\n\trequire.True(t, ok)\n\ttlsClient.Close()\n\n\t<-errc\n}", "is_vulnerable": 0}
{"code": "func GetAppProject(app *argoappv1.Application, projLister applicationsv1.AppProjectLister, ns string, settingsManager *settings.SettingsManager, db db.ArgoDB, ctx context.Context) (*argoappv1.AppProject, error) {\n\tproj, err := GetAppProjectByName(app.Spec.GetProject(), projLister, ns, settingsManager, db, ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !proj.IsAppNamespacePermitted(app, ns) {\n\t\treturn nil, fmt.Errorf(\"application '%s' in namespace '%s' is not allowed to use project '%s'\",\n\t\t\tapp.Name, app.Namespace, proj.Name)\n\t}\n\treturn proj, nil\n}", "is_vulnerable": 1}
{"code": "func (sp *ServiceProvider) ValidateLogoutResponseRedirect(queryParameterData string) error {\n\tretErr := &InvalidResponseError{\n\t\tNow: TimeNow(),\n\t}\n\n\trawResponseBuf, err := base64.StdEncoding.DecodeString(queryParameterData)\n\tif err != nil {\n\t\tretErr.PrivateErr = fmt.Errorf(\"unable to parse base64: %s\", err)\n\t\treturn retErr\n\t}\n\tretErr.Response = string(rawResponseBuf)\n\n\tgr, err := ioutil.ReadAll(newSaferFlateReader(bytes.NewBuffer(rawResponseBuf)))\n\tif err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn retErr\n\t}\n\n\tif err := xrv.Validate(bytes.NewReader(gr)); err != nil {\n\t\treturn err\n\t}\n\n\tdoc := etree.NewDocument()\n\tif err := doc.ReadFromBytes(rawResponseBuf); err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn retErr\n\t}\n\n\tif err := sp.validateSignature(doc.Root()); err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn retErr\n\t}\n\n\tvar resp LogoutResponse\n\tif err := unmarshalElement(doc.Root(), &resp); err != nil {\n\t\tretErr.PrivateErr = err\n\t\treturn retErr\n\t}\n\tif err := sp.validateLogoutResponse(&resp); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func AddAria2(c *gin.Context) {\n\tuser := c.MustGet(\"user\").(*model.User)\n\tif !user.CanAddAria2Tasks() {\n\t\tcommon.ErrorStrResp(c, \"permission denied\", 403)\n\t\treturn\n\t}\n\tif !aria2.IsAria2Ready() {\n\t\tcommon.ErrorStrResp(c, \"aria2 not ready\", 500)\n\t\treturn\n\t}\n\tvar req AddAria2Req\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\treqPath, err := user.JoinPath(req.Path)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 403)\n\t\treturn\n\t}\n\tfor _, url := range req.Urls {\n\t\terr := aria2.AddURI(c, url, reqPath)\n\t\tif err != nil {\n\t\t\tcommon.ErrorResp(c, err, 500)\n\t\t\treturn\n\t\t}\n\t}\n\tcommon.SuccessResp(c)\n}", "is_vulnerable": 0}
{"code": "func (request *Request) Compile(options *protocols.ExecutorOptions) error {\n\t// TODO: logic similar to network + http => probably can be refactored\n\t// Resolve payload paths from vars if they exists\n\tfor name, payload := range options.Options.Vars.AsMap() {\n\t\tpayloadStr, ok := payload.(string)\n\t\t// check if inputs contains the payload\n\t\tif ok && fileutil.FileExists(payloadStr) {\n\t\t\tif request.Payloads == nil {\n\t\t\t\trequest.Payloads = make(map[string]interface{})\n\t\t\t}\n\t\t\trequest.Payloads[name] = payloadStr\n\t\t}\n\t}\n\n\tif len(request.Payloads) > 0 {\n\t\tvar err error\n\t\trequest.generator, err = generators.New(request.Payloads, request.AttackType.Value, options.TemplatePath, options.Options.AllowLocalFileAccess, options.Catalog, options.Options.AttackType)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"could not parse payloads\")\n\t\t}\n\t}\n\n\t// Compile User-Agent\n\tswitch request.UserAgent.Value {\n\tcase useragent.Off:\n\t\trequest.compiledUserAgent = \" \"\n\tcase useragent.Default:\n\t\trequest.compiledUserAgent = \"\"\n\tcase useragent.Custom:\n\t\tif request.CustomUserAgent == \"\" {\n\t\t\treturn errors.New(\"please set custom_user_agent in the template\")\n\t\t}\n\t\trequest.compiledUserAgent = request.CustomUserAgent\n\tcase useragent.Random:\n\t\trequest.compiledUserAgent = uarand.GetRandom()\n\t}\n\n\tif len(request.Matchers) > 0 || len(request.Extractors) > 0 {\n\t\tcompiled := &request.Operators\n\t\tcompiled.ExcludeMatchers = options.ExcludeMatchers\n\t\tcompiled.TemplateID = options.TemplateID\n\t\tif err := compiled.Compile(); err != nil {\n\t\t\treturn errors.Wrap(err, \"could not compile operators\")\n\t\t}\n\t\trequest.CompiledOperators = compiled\n\t}\n\trequest.options = options\n\n\tif len(request.Fuzzing) > 0 {\n\t\tfor _, rule := range request.Fuzzing {\n\t\t\tif fuzzingMode := options.Options.FuzzingMode; fuzzingMode != \"\" {\n\t\t\t\trule.Mode = fuzzingMode\n\t\t\t}\n\t\t\tif fuzzingType := options.Options.FuzzingType; fuzzingType != \"\" {\n\t\t\t\trule.Type = fuzzingType\n\t\t\t}\n\t\t\tif err := rule.Compile(request.generator, request.options); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"could not compile fuzzing rule\")\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (h *AuthHandlers) HostKeyAuth(addr string, remote net.Addr, key ssh.PublicKey) error {\n\t// Check if the given host key was signed by a Teleport certificate\n\t// authority (CA) or fallback to host key checking if it's allowed.\n\tcertChecker := sshutils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsHostAuthority: h.IsHostAuthority,\n\t\t\tHostKeyFallback: h.hostKeyCallback,\n\t\t},\n\t\tFIPS: h.FIPS,\n\t}\n\terr := certChecker.CheckHostKey(addr, remote, key)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (app *Evmos) setupUpgradeHandlers() {\n\t// v8 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv8.UpgradeName,\n\t\tv8.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t),\n\t)\n\n\t// v8.1 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv81.UpgradeName,\n\t\tv81.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t),\n\t)\n\n\t// v8.2 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv82.UpgradeName,\n\t\tv82.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t),\n\t)\n\n\t// v9 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv9.UpgradeName,\n\t\tv9.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.DistrKeeper,\n\t\t),\n\t)\n\n\t// v9.1 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv91.UpgradeName,\n\t\tv91.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.DistrKeeper,\n\t\t),\n\t)\n\n\t// v10 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv10.UpgradeName,\n\t\tv10.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.StakingKeeper,\n\t\t),\n\t)\n\n\t// v11 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv11.UpgradeName,\n\t\tv11.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.AccountKeeper,\n\t\t\tapp.BankKeeper,\n\t\t\tapp.StakingKeeper,\n\t\t\tapp.DistrKeeper,\n\t\t),\n\t)\n\n\t// v12 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv12.UpgradeName,\n\t\tv12.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.DistrKeeper,\n\t\t),\n\t)\n\n\t// v13 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv13.UpgradeName,\n\t\tv13.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\t*app.EvmKeeper,\n\t\t),\n\t)\n\n\t// !! ATTENTION !!\n\t// v14 upgrade handler\n\t// !! WHEN UPGRADING TO SDK v0.47 MAKE SURE TO INCLUDE THIS\n\t// source: https://github.com/cosmos/cosmos-sdk/blob/release/v0.47.x/UPGRADING.md#xconsensus\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv14.UpgradeName,\n\t\tv14.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.EvmKeeper,\n\t\t\tapp.ConsensusParamsKeeper,\n\t\t\tapp.IBCKeeper.ClientKeeper,\n\t\t\tapp.ParamsKeeper,\n\t\t\tapp.appCodec,\n\t\t),\n\t)\n\n\t// v15 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv15.UpgradeName,\n\t\tv15.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.BankKeeper,\n\t\t\tapp.EvmKeeper,\n\t\t\tapp.StakingKeeper,\n\t\t),\n\t)\n\n\t// v16 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv16.UpgradeName,\n\t\tv16.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t\tapp.AccountKeeper,\n\t\t\tapp.BankKeeper,\n\t\t\tapp.EvmKeeper,\n\t\t\tapp.GovKeeper,\n\t\t\tapp.InflationKeeper,\n\t\t),\n\t)\n\n\t// v17 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv17.UpgradeName,\n\t\tv17.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t),\n\t)\n\n\t// v18 upgrade handler\n\tapp.UpgradeKeeper.SetUpgradeHandler(\n\t\tv18.UpgradeName,\n\t\tv18.CreateUpgradeHandler(\n\t\t\tapp.mm, app.configurator,\n\t\t),\n\t)\n\n\t// When a planned update height is reached, the old binary will panic\n\t// writing on disk the height and name of the update that triggered it\n\t// This will read that value, and execute the preparations for the upgrade.\n\tupgradeInfo, err := app.UpgradeKeeper.ReadUpgradeInfoFromDisk()\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"failed to read upgrade info from disk: %w\", err))\n\t}\n\n\tif app.UpgradeKeeper.IsSkipHeight(upgradeInfo.Height) {\n\t\treturn\n\t}\n\n\tvar storeUpgrades *storetypes.StoreUpgrades\n\n\tswitch upgradeInfo.Name {\n\tcase v8.UpgradeName:\n\t\t// add revenue module for testnet (v7 -> v8)\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tAdded: []string{\"feesplit\"},\n\t\t}\n\tcase v81.UpgradeName:\n\t\t// NOTE: store upgrade for mainnet was not registered and was replaced by\n\t\t// the v8.2 upgrade.\n\tcase v82.UpgradeName:\n\t\t// add  missing revenue module for mainnet (v8.1 -> v8.2)\n\t\t// IMPORTANT: this upgrade CANNOT be executed for testnet!\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tAdded:   []string{revenuetypes.ModuleName},\n\t\t\tDeleted: []string{\"feesplit\"},\n\t\t}\n\tcase v9.UpgradeName, v91.UpgradeName:\n\t\t// no store upgrade in v9 or v9.1\n\tcase v10.UpgradeName:\n\t\t// no store upgrades in v10\n\tcase v11.UpgradeName:\n\t\t// add ica host submodule in v11\n\t\t// initialize recovery store\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tAdded: []string{icahosttypes.SubModuleName, \"recoveryv1\"},\n\t\t}\n\tcase v12.UpgradeName:\n\t\t// no store upgrades\n\tcase v13.UpgradeName:\n\t\t// no store upgrades\n\tcase v14.UpgradeName:\n\t\t// !! ATTENTION !!\n\t\t// !! WHEN UPGRADING TO SDK v0.47 MAKE SURE TO INCLUDE THIS\n\t\t// source: https://github.com/cosmos/cosmos-sdk/blob/release/v0.47.x/UPGRADING.md\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tAdded: []string{\n\t\t\t\tconsensusparamtypes.StoreKey,\n\t\t\t\tcrisistypes.ModuleName,\n\t\t\t},\n\t\t}\n\tcase v15.UpgradeName:\n\t\t// crisis module is deprecated in v15\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tDeleted: []string{crisistypes.ModuleName},\n\t\t}\n\tcase v16.UpgradeName:\n\t\t// recovery and incentives modules are deprecated in v16\n\t\tstoreUpgrades = &storetypes.StoreUpgrades{\n\t\t\tDeleted: []string{\"recoveryv1\", \"incentives\", \"claims\"},\n\t\t}\n\tcase v17.UpgradeName, v18.UpgradeName:\n\t\t// no store upgrades\n\t}\n\n\tif storeUpgrades != nil {\n\t\t// configure store loader that checks if version == upgradeHeight and applies store upgrades\n\t\tapp.SetStoreLoader(upgradetypes.UpgradeStoreLoader(upgradeInfo.Height, storeUpgrades))\n\t}\n}", "is_vulnerable": 1}
{"code": "func testScenario(t *testing.T, desc string, fn func(t *testing.T, sc scenarioContext)) {\n\tt.Helper()\n\n\tt.Run(desc, func(t *testing.T) {\n\t\tctx := web.Context{Req: &http.Request{\n\t\t\tHeader: http.Header{\n\t\t\t\t\"Content-Type\": []string{\"application/json\"},\n\t\t\t},\n\t\t}}\n\t\torgID := int64(1)\n\t\trole := models.ROLE_ADMIN\n\t\tsqlStore := sqlstore.InitTestDB(t)\n\t\tservice := LibraryElementService{\n\t\t\tCfg:      setting.NewCfg(),\n\t\t\tSQLStore: sqlStore,\n\t\t}\n\n\t\tuser := models.SignedInUser{\n\t\t\tUserId:     1,\n\t\t\tName:       \"Signed In User\",\n\t\t\tLogin:      \"signed_in_user\",\n\t\t\tEmail:      \"signed.in.user@test.com\",\n\t\t\tOrgId:      orgID,\n\t\t\tOrgRole:    role,\n\t\t\tLastSeenAt: time.Now(),\n\t\t}\n\n\t\t// deliberate difference between signed in user and user in db to make it crystal clear\n\t\t// what to expect in the tests\n\t\t// In the real world these are identical\n\t\tcmd := models.CreateUserCommand{\n\t\t\tEmail: \"user.in.db@test.com\",\n\t\t\tName:  \"User In DB\",\n\t\t\tLogin: userInDbName,\n\t\t}\n\n\t\t_, err := sqlStore.CreateUser(context.Background(), cmd)\n\t\trequire.NoError(t, err)\n\n\t\tsc := scenarioContext{\n\t\t\tuser:     user,\n\t\t\tctx:      &ctx,\n\t\t\tservice:  &service,\n\t\t\tsqlStore: sqlStore,\n\t\t\treqContext: &models.ReqContext{\n\t\t\t\tContext:      &ctx,\n\t\t\t\tSignedInUser: &user,\n\t\t\t},\n\t\t}\n\n\t\tsc.folder = createFolderWithACL(t, sc.sqlStore, \"ScenarioFolder\", sc.user, []folderACLItem{})\n\n\t\tfn(t, sc)\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestClientUnsupportedKex(t *testing.T) {\n\tif os.Getenv(\"GO_BUILDER_NAME\") != \"\" {\n\t\tt.Skip(\"skipping known-flaky test on the Go build dashboard; see golang.org/issue/15198\")\n\t}\n\tconfig := &ClientConfig{\n\t\tUser: \"testuser\",\n\t\tAuth: []AuthMethod{\n\t\t\tPublicKeys(),\n\t\t},\n\t\tConfig: Config{\n\t\t\tKeyExchanges: []string{\"diffie-hellman-group-exchange-sha256\"}, // not currently supported\n\t\t},\n\t\tHostKeyCallback: InsecureIgnoreHostKey(),\n\t}\n\tif err := tryAuth(t, config); err == nil || !strings.Contains(err.Error(), \"common algorithm\") {\n\t\tt.Errorf(\"got %v, expected 'common algorithm'\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func ActivateIdentity(rw io.ReadWriter, aikAuth []byte, ownerAuth []byte, aik tpmutil.Handle, asym, sym []byte) ([]byte, error) {\n\t// Run OIAP for the AIK.\n\toiaprAIK, err := oiap(rw)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to start OIAP session: %v\", err)\n\t}\n\n\t// Run OSAP for the owner, reading a random OddOSAP for our initial command\n\t// and getting back a secret and a handle.\n\tsharedSecretOwn, osaprOwn, err := newOSAPSession(rw, etOwner, khOwner, ownerAuth)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to start OSAP session: %v\", err)\n\t}\n\tdefer osaprOwn.Close(rw)\n\tdefer zeroBytes(sharedSecretOwn[:])\n\n\tauthIn := []interface{}{ordActivateIdentity, tpmutil.U32Bytes(asym)}\n\tca1, err := newCommandAuth(oiaprAIK.AuthHandle, oiaprAIK.NonceEven, aikAuth, authIn)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"newCommandAuth failed: %v\", err)\n\t}\n\tca2, err := newCommandAuth(osaprOwn.AuthHandle, osaprOwn.NonceEven, sharedSecretOwn[:], authIn)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"newCommandAuth failed: %v\", err)\n\t}\n\n\tsymkey, ra1, ra2, ret, err := activateIdentity(rw, aik, asym, ca1, ca2)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"activateIdentity failed: %v\", err)\n\t}\n\n\t// Check response authentication.\n\traIn := []interface{}{ret, ordActivateIdentity, symkey}\n\tif err := ra1.verify(ca1.NonceOdd, aikAuth, raIn); err != nil {\n\t\treturn nil, fmt.Errorf(\"aik resAuth failed to verify: %v\", err)\n\t}\n\n\tif err := ra2.verify(ca2.NonceOdd, sharedSecretOwn[:], raIn); err != nil {\n\t\treturn nil, fmt.Errorf(\"owner resAuth failed to verify: %v\", err)\n\t}\n\n\tcred, err := unloadTrspiCred(sym)\n\tvar (\n\t\tblock     cipher.Block\n\t\tiv        []byte\n\t\tciphertxt []byte\n\t\tsecret    []byte\n\t)\n\tswitch id := symkey.AlgID; id {\n\tcase AlgAES128:\n\t\tblock, err = aes.NewCipher(symkey.Key)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"aes.NewCipher failed: %v\", err)\n\t\t}\n\t\tiv = cred[:aes.BlockSize]\n\t\tciphertxt = cred[aes.BlockSize:]\n\t\tsecret = ciphertxt\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"%v is not a supported session key algorithm\", id)\n\t}\n\tswitch es := symkey.EncScheme; es {\n\tcase esSymCTR:\n\t\tstream := cipher.NewCTR(block, iv)\n\t\tstream.XORKeyStream(secret, ciphertxt)\n\tcase esSymOFB:\n\t\tstream := cipher.NewOFB(block, iv)\n\t\tstream.XORKeyStream(secret, ciphertxt)\n\tcase esSymCBCPKCS5:\n\t\tmode := cipher.NewCBCDecrypter(block, iv)\n\t\tmode.CryptBlocks(secret, ciphertxt)\n\t\t// Remove PKCS5 padding.\n\t\tpadlen := int(secret[len(secret)-1])\n\t\tsecret = secret[:len(secret)-padlen]\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"%v is not a supported encryption scheme\", es)\n\t}\n\n\treturn secret, nil\n}", "is_vulnerable": 1}
{"code": "func NewFileBasedRingBuffer(\n\tctx context.Context,\n\tconfig_obj *config_proto.Config,\n\tlog_ctx *logging.LogContext) (*FileBasedRingBuffer, error) {\n\n\tif config_obj.Client == nil || config_obj.Client.LocalBuffer == nil {\n\t\treturn nil, errors.New(\"Local buffer not configured\")\n\t}\n\n\tfilename := getLocalBufferName(config_obj)\n\tif filename == \"\" {\n\t\treturn nil, errors.New(\"Unsupport platform\")\n\t}\n\n\tfd, err := os.OpenFile(filename, os.O_RDWR|os.O_CREATE, 0700)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\theader := &Header{\n\t\t// Pad the header a bit to allow for extensions.\n\t\tWritePointer:   FirstRecordOffset,\n\t\tAvailableBytes: 0,\n\t\tLeasedBytes:    0,\n\t\tReadPointer:    FirstRecordOffset,\n\t\tMaxSize: int64(config_obj.Client.LocalBuffer.DiskSize) +\n\t\t\tFirstRecordOffset,\n\t}\n\tdata := make([]byte, FirstRecordOffset)\n\tn, err := fd.ReadAt(data, 0)\n\tif n > 0 && n < FirstRecordOffset && err == io.EOF {\n\t\tlog_ctx.Error(\"Possible corruption detected: file too short.\")\n\t\terr = fd.Truncate(0)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif n > 0 && (err == nil || err == io.EOF) {\n\t\terr := header.UnmarshalBinary(data[:n])\n\t\t// The header is not valid, truncate the file and\n\t\t// start again.\n\t\tif err != nil {\n\t\t\tlog_ctx.Errorf(\"Possible corruption detected: %v.\", err)\n\t\t\terr = fd.Truncate(0)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\t// If we opened a file which is not yet fully committed adjust\n\t// the available bytes again so we can replay the lost\n\t// messages.\n\tif header.LeasedBytes != 0 {\n\t\theader.AvailableBytes += header.LeasedBytes\n\t\theader.LeasedBytes = 0\n\t}\n\n\tresult := &FileBasedRingBuffer{\n\t\tconfig_obj:     config_obj,\n\t\tfd:             fd,\n\t\theader:         header,\n\t\tread_buf:       make([]byte, 8),\n\t\twrite_buf:      make([]byte, 8),\n\t\tleased_pointer: header.ReadPointer,\n\t\tlog_ctx:        log_ctx,\n\t}\n\n\tresult.c = sync.NewCond(&result.mu)\n\n\tlog_ctx.WithFields(logrus.Fields{\n\t\t\"filename\": filename,\n\t\t\"max_size\": result.header.MaxSize,\n\t}).Info(\"Ring Buffer: Creation\")\n\n\treturn result, nil\n}", "is_vulnerable": 1}
{"code": "func NewOperatorRole(namespace string) *rbacv1.Role {\n\treturn &rbacv1.Role{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"Role\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      components.OperatorServiceAccountName,\n\t\t\tNamespace: namespace,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRules: []rbacv1.PolicyRule{\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"secrets\",\n\t\t\t\t},\n\t\t\t\tResourceNames: []string{\n\t\t\t\t\tcomponents.KubeVirtCASecretName,\n\t\t\t\t\tcomponents.KubeVirtExportCASecretName,\n\t\t\t\t\tcomponents.VirtHandlerCertSecretName,\n\t\t\t\t\tcomponents.VirtHandlerServerCertSecretName,\n\t\t\t\t\tcomponents.VirtOperatorCertSecretName,\n\t\t\t\t\tcomponents.VirtApiCertSecretName,\n\t\t\t\t\tcomponents.VirtControllerCertSecretName,\n\t\t\t\t\tcomponents.VirtExportProxyCertSecretName,\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"configmaps\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tGroupNameRoute,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"routes\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t\t\"get\",\n\t\t\t\t\t\"list\",\n\t\t\t\t\t\"watch\",\n\t\t\t\t\t\"patch\",\n\t\t\t\t\t\"delete\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\tGroupNameRoute,\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"routes/custom-host\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"create\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func (va ClawbackVestingAccount) LockedCoins(blockTime time.Time) sdk.Coins {\n\treturn va.OriginalVesting.Sub(va.GetUnlockedVestedCoins(blockTime)...)\n}", "is_vulnerable": 0}
{"code": "func TestScalarMult(t *testing.T) {\n\tt.Run(\"P224\", func(t *testing.T) {\n\t\ttestScalarMult(t, nistec.NewP224Point, elliptic.P224())\n\t})\n\tt.Run(\"P256\", func(t *testing.T) {\n\t\ttestScalarMult(t, nistec.NewP256Point, elliptic.P256())\n\t})\n\tt.Run(\"P384\", func(t *testing.T) {\n\t\ttestScalarMult(t, nistec.NewP384Point, elliptic.P384())\n\t})\n\tt.Run(\"P521\", func(t *testing.T) {\n\t\ttestScalarMult(t, nistec.NewP521Point, elliptic.P521())\n\t})\n}", "is_vulnerable": 0}
{"code": "func StateDiffs(lives, configs []*unstructured.Unstructured, diffConfig DiffConfig) (*diff.DiffResultList, error) {\n\tnormResults, err := preDiffNormalize(lives, configs, diffConfig)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to perform pre-diff normalization: %w\", err)\n\t}\n\n\tdiffNormalizer, err := newDiffNormalizer(diffConfig.Ignores(), diffConfig.Overrides(), diffConfig.IgnoreNormalizerOpts())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create diff normalizer: %w\", err)\n\t}\n\n\tdiffOpts := []diff.Option{\n\t\tdiff.WithNormalizer(diffNormalizer),\n\t\tdiff.IgnoreAggregatedRoles(diffConfig.IgnoreAggregatedRoles()),\n\t\tdiff.WithStructuredMergeDiff(diffConfig.StructuredMergeDiff()),\n\t\tdiff.WithGVKParser(diffConfig.GVKParser()),\n\t\tdiff.WithManager(diffConfig.Manager()),\n\t\tdiff.WithServerSideDiff(diffConfig.ServerSideDiff()),\n\t\tdiff.WithServerSideDryRunner(diffConfig.ServerSideDryRunner()),\n\t\tdiff.WithIgnoreMutationWebhook(diffConfig.IgnoreMutationWebhook()),\n\t}\n\n\tif diffConfig.Logger() != nil {\n\t\tdiffOpts = append(diffOpts, diff.WithLogr(*diffConfig.Logger()))\n\t}\n\n\tuseCache, cachedDiff := diffConfig.DiffFromCache(diffConfig.AppName())\n\tif useCache && cachedDiff != nil {\n\t\tcached, err := diffArrayCached(normResults.Targets, normResults.Lives, cachedDiff, diffOpts...)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to calculate diff from cache: %w\", err)\n\t\t}\n\t\treturn cached, nil\n\t}\n\tarray, err := diff.DiffArray(normResults.Targets, normResults.Lives, diffOpts...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to calculate diff: %w\", err)\n\t}\n\treturn array, nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tcaseMsg := fmt.Sprintf(\"path: %v\\ndir: %v\", tc.path, tc.dir)\n\t\t\tescapes, err := GetPathInSandbox(tc.dir, tc.path)\n\t\t\tif tc.expectedErr != \"\" {\n\t\t\t\trequire.EqualError(t, err, tc.expectedErr, caseMsg)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err, caseMsg)\n\t\t\t}\n\t\t\trequire.Equal(t, tc.expected, escapes, caseMsg)\n\t\t})", "is_vulnerable": 0}
{"code": "func (f *FileStorage) Get(contentID string) (io.ReadCloser, error) {\n\tif f.Exists(contentID) {\n\t\treturn os.Open(f.storagePathFor(contentID))\n\t}\n\treturn nil, os.ErrNotExist\n}", "is_vulnerable": 1}
{"code": "func TestHtlcIncomingResolverExitCancelHodl(t *testing.T) {\n\tt.Parallel()\n\tdefer timeout(t)()\n\n\tctx := newIncomingResolverTestContext(t)\n\tctx.resolve()\n\tnotifyData := <-ctx.registry.notifyChan\n\tnotifyData.hodlChan <- invoices.NewFailResolution(\n\t\ttestResCircuitKey, testAcceptHeight, invoices.ResultCanceled,\n\t)\n\n\tctx.waitForResult(false)\n}", "is_vulnerable": 1}
{"code": "func (client ProvidersClient) ListSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (p *IngressProcessor) computeIngressRule(ing *networking_v1.Ingress, rule networking_v1.IngressRule) {\n\thost := rule.Host\n\n\t// If host name is blank, rewrite to Envoy's * default host.\n\tif host == \"\" {\n\t\thost = \"*\"\n\t}\n\n\tvar clientCertSecret *Secret\n\tvar err error\n\tif p.ClientCertificate != nil {\n\t\tclientCertSecret, err = p.source.LookupSecret(*p.ClientCertificate, validSecret)\n\t\tif err != nil {\n\t\t\tp.WithError(err).\n\t\t\t\tWithField(\"name\", ing.GetName()).\n\t\t\t\tWithField(\"namespace\", ing.GetNamespace()).\n\t\t\t\tWithField(\"secret\", p.ClientCertificate).\n\t\t\t\tError(\"tls.envoy-client-certificate contains unresolved secret reference\")\n\t\t\treturn\n\t\t}\n\t}\n\n\tfor _, httppath := range httppaths(rule) {\n\t\tpath := stringOrDefault(httppath.Path, \"/\")\n\t\t// Default to implementation specific path matching if not set.\n\t\tpathType := derefPathTypeOr(httppath.PathType, networking_v1.PathTypeImplementationSpecific)\n\t\tbe := httppath.Backend\n\t\tm := types.NamespacedName{Name: be.Service.Name, Namespace: ing.Namespace}\n\n\t\tvar port intstr.IntOrString\n\t\tif len(be.Service.Port.Name) > 0 {\n\t\t\tport = intstr.FromString(be.Service.Port.Name)\n\t\t} else {\n\t\t\tport = intstr.FromInt(int(be.Service.Port.Number))\n\t\t}\n\n\t\ts, err := p.dag.EnsureService(m, port, p.source)\n\t\tif err != nil {\n\t\t\tp.WithError(err).\n\t\t\t\tWithField(\"name\", ing.GetName()).\n\t\t\t\tWithField(\"namespace\", ing.GetNamespace()).\n\t\t\t\tWithField(\"service\", be.Service.Name).\n\t\t\t\tError(\"unresolved service reference\")\n\t\t\tcontinue\n\t\t}\n\n\t\tr, err := route(ing, rule.Host, path, pathType, s, clientCertSecret, p.FieldLogger)\n\t\tif err != nil {\n\t\t\tp.WithError(err).\n\t\t\t\tWithField(\"name\", ing.GetName()).\n\t\t\t\tWithField(\"namespace\", ing.GetNamespace()).\n\t\t\t\tWithField(\"regex\", path).\n\t\t\t\tErrorf(\"path regex is not valid\")\n\t\t\treturn\n\t\t}\n\n\t\t// should we create port 80 routes for this ingress\n\t\tif annotation.TLSRequired(ing) || annotation.HTTPAllowed(ing) {\n\t\t\tvhost := p.dag.EnsureVirtualHost(ListenerName{Name: host, ListenerName: \"ingress_http\"})\n\t\t\tvhost.addRoute(r)\n\t\t}\n\n\t\t// computeSecureVirtualhosts will have populated b.securevirtualhosts\n\t\t// with the names of tls enabled ingress objects. If host exists then\n\t\t// it is correctly configured for TLS.\n\t\tif svh := p.dag.GetSecureVirtualHost(ListenerName{Name: host, ListenerName: \"ingress_https\"}); svh != nil && host != \"*\" {\n\t\t\tsvh.addRoute(r)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (v *notaryVerifier) VerifySignature(ctx context.Context, opts images.Options) (*images.Response, error) {\n\tv.log.V(2).Info(\"verifying image\", \"reference\", opts.ImageRef)\n\n\tcertsPEM := combineCerts(opts)\n\tcerts, err := cryptoutils.LoadCertificatesFromPEM(bytes.NewReader([]byte(certsPEM)))\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to parse certificates\")\n\t}\n\n\ttrustStore := NewTrustStore(\"kyverno\", certs)\n\tpolicyDoc := v.buildPolicy()\n\tnotationVerifier, err := verifier.New(policyDoc, trustStore, nil)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to created verifier\")\n\t}\n\n\tv.log.V(4).Info(\"creating notation repo\", \"reference\", opts.ImageRef)\n\tparsedRef, err := parseReferenceCrane(ctx, opts.ImageRef, opts.RegistryClient)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to parse image reference: %s\", opts.ImageRef)\n\t}\n\tv.log.V(4).Info(\"created parsedRef\", \"reference\", opts.ImageRef)\n\n\tref := parsedRef.Ref.Name()\n\tremoteVerifyOptions := notation.RemoteVerifyOptions{\n\t\tArtifactReference:    ref,\n\t\tMaxSignatureAttempts: 10,\n\t}\n\n\ttargetDesc, outcomes, err := notation.Verify(context.TODO(), notationVerifier, parsedRef.Repo, remoteVerifyOptions)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to verify %s\", ref)\n\t}\n\n\tif err := v.verifyOutcomes(outcomes); err != nil {\n\t\treturn nil, err\n\t}\n\n\tv.log.V(2).Info(\"verified image\", \"type\", targetDesc.MediaType, \"digest\", targetDesc.Digest, \"size\", targetDesc.Size)\n\n\tresp := &images.Response{\n\t\tDigest:     targetDesc.Digest.String(),\n\t\tStatements: nil,\n\t}\n\n\treturn resp, nil\n}", "is_vulnerable": 0}
{"code": "func (ta *TaskArtifact) Validate() error {\n\t// Verify the source\n\tvar mErr multierror.Error\n\tif ta.GetterSource == \"\" {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"source must be specified\"))\n\t}\n\n\tswitch ta.GetterMode {\n\tcase \"\":\n\t\t// Default to any\n\t\tta.GetterMode = GetterModeAny\n\tcase GetterModeAny, GetterModeFile, GetterModeDir:\n\t\t// Ok\n\tdefault:\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid artifact mode %q; must be one of: %s, %s, %s\",\n\t\t\tta.GetterMode, GetterModeAny, GetterModeFile, GetterModeDir))\n\t}\n\n\tescaped, err := PathEscapesAllocDir(\"task\", ta.RelativeDest)\n\tif err != nil {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid destination path: %v\", err))\n\t} else if escaped {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"destination escapes allocation directory\"))\n\t}\n\n\tif err := ta.validateChecksum(); err != nil {\n\t\tmErr.Errors = append(mErr.Errors, err)\n\t}\n\n\treturn mErr.ErrorOrNil()\n}", "is_vulnerable": 1}
{"code": "func newPathTrie(owner common.Hash, skipLeftBoundary bool, db ethdb.KeyValueReader, batch ethdb.Batch) *pathTrie {\n\ttr := &pathTrie{\n\t\towner:            owner,\n\t\tskipLeftBoundary: skipLeftBoundary,\n\t\tdb:               db,\n\t\tbatch:            batch,\n\t}\n\ttr.tr = trie.NewStackTrie(tr.onTrieNode)\n\treturn tr\n}", "is_vulnerable": 0}
{"code": "func isValidFieldInclusion(field FieldFilter, value StringSet, inclusion string) bool {\n\tcontainsAny := value.ContainsAny(field.Values.Elems()...)\n\tcontainsAll := value.ContainsAll(field.Values.Elems()...)\n\n\tif (inclusion == FilterIncludeAny && !containsAny) ||\n\t\t(inclusion == FilterIncludeAll && !containsAll) ||\n\t\t(inclusion == FilterExcludeAny && containsAny) ||\n\t\t(inclusion == FilterEmpty && value.Len() > 0) {\n\t\treturn false\n\t}\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) Validate(ctx context.Context, resourceGroupName string, deploymentName string, parameters Deployment) (result DeploymentValidateResult, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/DeploymentsClient.Validate\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}},\n\t\t{TargetValue: parameters,\n\t\t\tConstraints: []validation.Constraint{{Target: \"parameters.Properties\", Name: validation.Null, Rule: false,\n\t\t\t\tChain: []validation.Constraint{{Target: \"parameters.Properties.TemplateLink\", Name: validation.Null, Rule: false,\n\t\t\t\t\tChain: []validation.Constraint{{Target: \"parameters.Properties.TemplateLink.URI\", Name: validation.Null, Rule: true, Chain: nil}}},\n\t\t\t\t\t{Target: \"parameters.Properties.ParametersLink\", Name: validation.Null, Rule: false,\n\t\t\t\t\t\tChain: []validation.Constraint{{Target: \"parameters.Properties.ParametersLink.URI\", Name: validation.Null, Rule: true, Chain: nil}}},\n\t\t\t\t}}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.DeploymentsClient\", \"Validate\", err.Error())\n\t}\n\n\treq, err := client.ValidatePreparer(ctx, resourceGroupName, deploymentName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Validate\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.ValidateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Validate\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.ValidateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"Validate\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func fieldProfile(scmp *v1.SeccompProfile, profileRootPath string, fallbackToRuntimeDefault bool) string {\n\tif scmp == nil {\n\t\tif fallbackToRuntimeDefault {\n\t\t\treturn v1.SeccompProfileRuntimeDefault\n\t\t}\n\t\treturn \"\"\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeRuntimeDefault {\n\t\treturn v1.SeccompProfileRuntimeDefault\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeLocalhost && scmp.LocalhostProfile != nil && len(*scmp.LocalhostProfile) > 0 {\n\t\tfname := filepath.Join(profileRootPath, *scmp.LocalhostProfile)\n\t\treturn v1.SeccompLocalhostProfileNamePrefix + fname\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeUnconfined {\n\t\treturn v1.SeccompProfileNameUnconfined\n\t}\n\n\tif fallbackToRuntimeDefault {\n\t\treturn v1.SeccompProfileRuntimeDefault\n\t}\n\treturn \"\"\n}", "is_vulnerable": 1}
{"code": "func (expr *IntroducerExpr) eval(env *ExpressionEnv) (eval, error) {\n\te, err := expr.Inner.eval(env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb, err := introducerCast(e, expr.TypedCollation.Collation)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tb.flag |= flagExplicitCollation\n\treturn b, nil\n}", "is_vulnerable": 0}
{"code": "func (ps *PlatformService) UpdateSessionsIsGuest(userID string, isGuest bool) error {\n\tsessions, err := ps.GetSessions(userID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, session := range sessions {\n\t\tsession.AddProp(model.SessionPropIsGuest, fmt.Sprintf(\"%t\", isGuest))\n\t\terr := ps.Store.Session().UpdateProps(session)\n\t\tif err != nil {\n\t\t\tmlog.Warn(\"Unable to update isGuest session\", mlog.Err(err))\n\t\t\tcontinue\n\t\t}\n\t\tps.AddSessionToCache(session)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *CommonController) AddAdminTemplate(tpl ...string)  {\n\tfor _,tplName := range tpl {\n\t\tc.AddTemplate(AdminTemplatePath(\"/template/\"+tplName))\n\t}\n}", "is_vulnerable": 1}
{"code": "func (rarFormat) Read(input io.Reader, destination string) error {\n\trr, err := rardecode.NewReader(input, \"\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"read: failed to create reader: %v\", err)\n\t}\n\n\tfor {\n\t\theader, err := rr.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = sanitizeExtractPath(header.Name, destination)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdestpath := filepath.Join(destination, header.Name)\n\n\t\tif header.IsDir {\n\t\t\terr = mkdir(destpath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// if files come before their containing folders, then we must\n\t\t// create their folders before writing the file\n\t\terr = mkdir(filepath.Dir(destpath))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = writeNewFile(destpath, rr, header.Mode())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func ParseRequestURL(r *http.Request) string {\n\tvar parsedURL url.URL\n\tparsedURL.Scheme = GetScheme(r)\n\tparsedURL.Host = GetHost(r)\n\tparsedURL = *parsedURL.JoinPath(r.Header.Get(PrefixHeader), r.URL.Path)\n\treturn parsedURL.String()\n}", "is_vulnerable": 0}
{"code": "func (a modSecurity) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "var _ = Describe(\"creating several Namespaces for a Tenant\", func() {\n\ttnt := &capsulev1beta2.Tenant{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: \"capsule-ns-attack-1\",\n\t\t},\n\t\tSpec: capsulev1beta2.TenantSpec{\n\t\t\tOwners: capsulev1beta2.OwnerListSpec{\n\t\t\t\t{\n\t\t\t\t\tName: \"charlie\",\n\t\t\t\t\tKind: \"User\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tKind: \"ServiceAccount\",\n\t\t\t\t\tName: \"system:serviceaccount:attacker-system:attacker\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tkubeSystem := &corev1.Namespace{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: \"kube-system\",\n\t\t},\n\t}\n\tJustBeforeEach(func() {\n\t\tEventuallyCreation(func() (err error) {\n\t\t\ttnt.ResourceVersion = \"\"\n\t\t\terr = k8sClient.Create(context.TODO(), tnt)\n\n\t\t\treturn\n\t\t}).Should(Succeed())\n\t})\n\tJustAfterEach(func() {\n\t\tExpect(k8sClient.Delete(context.TODO(), tnt)).Should(Succeed())\n\n\t})\n\n\tIt(\"Can't hijack offlimits namespace\", func() {\n\t\ttenant := &capsulev1beta2.Tenant{}\n\t\tExpect(k8sClient.Get(context.TODO(), types.NamespacedName{Name: tnt.Name}, tenant)).Should(Succeed())\n\n\t\t// Get the namespace\n\t\tExpect(k8sClient.Get(context.TODO(), types.NamespacedName{Name: kubeSystem.GetName()}, kubeSystem)).Should(Succeed())\n\n\t\tfor _, owner := range tnt.Spec.Owners {\n\t\t\tcs := ownerClient(owner)\n\n\t\t\tpatch := []byte(fmt.Sprintf(`{\"metadata\":{\"ownerReferences\":[{\"apiVersion\":\"%s/%s\",\"kind\":\"Tenant\",\"name\":\"%s\",\"uid\":\"%s\"}]}}`, capsulev1beta2.GroupVersion.Group, capsulev1beta2.GroupVersion.Version, tenant.GetName(), tenant.GetUID()))\n\n\t\t\t_, err := cs.CoreV1().Namespaces().Patch(context.TODO(), kubeSystem.Name, types.StrategicMergePatchType, patch, metav1.PatchOptions{})\n\t\t\tExpect(err).To(HaveOccurred())\n\n\t\t}\n\t})\n\n\tIt(\"Owners can create and attempt to patch new namespaces but patches should not be applied\", func() {\n\t\tfor _, owner := range tnt.Spec.Owners {\n\t\t\tcs := ownerClient(owner)\n\n\t\t\t// Each owner creates a new namespace\n\t\t\tns := NewNamespace(\"\")\n\t\t\tNamespaceCreation(ns, owner, defaultTimeoutInterval).Should(Succeed())\n\n\t\t\t// Attempt to patch the owner references of the new namespace\n\t\t\ttenant := &capsulev1beta2.Tenant{}\n\t\t\tExpect(k8sClient.Get(context.TODO(), types.NamespacedName{Name: tnt.Name}, tenant)).Should(Succeed())\n\n\t\t\trandomUID := types.UID(fmt.Sprintf(\"%d\", rand.Int()))\n\t\t\trandomName := fmt.Sprintf(\"random-tenant-%d\", rand.Int())\n\t\t\tpatch := []byte(fmt.Sprintf(`{\"metadata\":{\"ownerReferences\":[{\"apiVersion\":\"%s/%s\",\"kind\":\"Tenant\",\"name\":\"%s\",\"uid\":\"%s\"}]}}`, capsulev1beta2.GroupVersion.Group, capsulev1beta2.GroupVersion.Version, randomName, randomUID))\n\n\t\t\t_, err := cs.CoreV1().Namespaces().Patch(context.TODO(), ns.Name, types.StrategicMergePatchType, patch, metav1.PatchOptions{})\n\t\t\tExpect(err).ToNot(HaveOccurred())\n\n\t\t\tretrievedNs := &corev1.Namespace{}\n\t\t\tExpect(k8sClient.Get(context.TODO(), types.NamespacedName{Name: ns.Name}, retrievedNs)).Should(Succeed())\n\n\t\t\t// Check if the namespace has an owner reference with the specific UID and name\n\t\t\thasSpecificOwnerRef := false\n\t\t\tfor _, ownerRef := range retrievedNs.OwnerReferences {\n\t\t\t\tif ownerRef.UID == randomUID && ownerRef.Name == randomName {\n\t\t\t\t\thasSpecificOwnerRef = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tExpect(hasSpecificOwnerRef).To(BeFalse(), \"Namespace should not have owner reference with UID %s and name %s\", randomUID, randomName)\n\n\t\t\thasOriginReference := false\n\t\t\tfor _, ownerRef := range retrievedNs.OwnerReferences {\n\t\t\t\tif ownerRef.UID == tenant.GetUID() && ownerRef.Name == tenant.GetName() {\n\t\t\t\t\thasOriginReference = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tExpect(hasOriginReference).To(BeTrue(), \"Namespace should have origin reference\", tenant.GetUID(), tenant.GetName())\n\t\t}\n\t})\n\n})", "is_vulnerable": 0}
{"code": "func Benchmark_Session_Asserted(b *testing.B) {\n\tb.Run(\"default\", func(b *testing.B) {\n\t\tapp, store := fiber.New(), New()\n\t\tc := app.AcquireCtx(&fasthttp.RequestCtx{})\n\t\tdefer app.ReleaseCtx(c)\n\t\tc.Request().Header.SetCookie(store.sessionName, \"12356789\")\n\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\t\tfor n := 0; n < b.N; n++ {\n\t\t\tsess, err := store.Get(c)\n\t\t\tutils.AssertEqual(b, nil, err)\n\t\t\tsess.Set(\"john\", \"doe\")\n\t\t\terr = sess.Save()\n\t\t\tutils.AssertEqual(b, nil, err)\n\t\t}\n\t})\n\n\tb.Run(\"storage\", func(b *testing.B) {\n\t\tapp := fiber.New()\n\t\tstore := New(Config{\n\t\t\tStorage: memory.New(),\n\t\t})\n\t\tc := app.AcquireCtx(&fasthttp.RequestCtx{})\n\t\tdefer app.ReleaseCtx(c)\n\t\tc.Request().Header.SetCookie(store.sessionName, \"12356789\")\n\n\t\tb.ReportAllocs()\n\t\tb.ResetTimer()\n\t\tfor n := 0; n < b.N; n++ {\n\t\t\tsess, err := store.Get(c)\n\t\t\tutils.AssertEqual(b, nil, err)\n\t\t\tsess.Set(\"john\", \"doe\")\n\t\t\terr = sess.Save()\n\t\t\tutils.AssertEqual(b, nil, err)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func (i *ModuleInstaller) moduleInstallWalker(ctx context.Context, manifest modsdir.Manifest, upgrade bool, hooks ModuleInstallHooks, fetcher *getmodules.PackageFetcher) configs.ModuleWalker {\n\treturn configs.ModuleWalkerFunc(\n\t\tfunc(req *configs.ModuleRequest) (*configs.Module, *version.Version, hcl.Diagnostics) {\n\t\t\tvar diags hcl.Diagnostics\n\n\t\t\tif req.SourceAddr == nil {\n\t\t\t\t// If the parent module failed to parse the module source\n\t\t\t\t// address, we can't load it here. Return nothing as the parent\n\t\t\t\t// module's diagnostics should explain this.\n\t\t\t\treturn nil, nil, diags\n\t\t\t}\n\n\t\t\tif req.Name == \"\" {\n\t\t\t\t// An empty string for a module instance name breaks our\n\t\t\t\t// manifest map, which uses that to indicate the root module.\n\t\t\t\t// Because we descend into modules which have errors, we need\n\t\t\t\t// to look out for this case, but the config loader's\n\t\t\t\t// diagnostics will report the error later.\n\t\t\t\treturn nil, nil, diags\n\t\t\t}\n\n\t\t\tif !hclsyntax.ValidIdentifier(req.Name) {\n\t\t\t\t// A module with an invalid name shouldn't be installed at all. This is\n\t\t\t\t// mostly a concern for remote modules, since we need to be able to convert\n\t\t\t\t// the name to a valid path.\n\t\t\t\treturn nil, nil, diags\n\t\t\t}\n\n\t\t\tkey := manifest.ModuleKey(req.Path)\n\t\t\tinstPath := i.packageInstallPath(req.Path)\n\n\t\t\tlog.Printf(\"[DEBUG] Module installer: begin %s\", key)\n\n\t\t\t// First we'll check if we need to upgrade/replace an existing\n\t\t\t// installed module, and delete it out of the way if so.\n\t\t\treplace := upgrade\n\t\t\tif !replace {\n\t\t\t\trecord, recorded := manifest[key]\n\t\t\t\tswitch {\n\t\t\t\tcase !recorded:\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s is not yet installed\", key)\n\t\t\t\t\treplace = true\n\t\t\t\tcase record.SourceAddr != req.SourceAddr.String():\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s source address has changed from %q to %q\", key, record.SourceAddr, req.SourceAddr)\n\t\t\t\t\treplace = true\n\t\t\t\tcase record.Version != nil && !req.VersionConstraint.Required.Check(record.Version):\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s version %s no longer compatible with constraints %s\", key, record.Version, req.VersionConstraint.Required)\n\t\t\t\t\treplace = true\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// If we _are_ planning to replace this module, then we'll remove\n\t\t\t// it now so our installation code below won't conflict with any\n\t\t\t// existing remnants.\n\t\t\tif replace {\n\t\t\t\tif _, recorded := manifest[key]; recorded {\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: discarding previous record of %s prior to reinstall\", key)\n\t\t\t\t}\n\t\t\t\tdelete(manifest, key)\n\t\t\t\t// Deleting a module invalidates all of its descendent modules too.\n\t\t\t\tkeyPrefix := key + \".\"\n\t\t\t\tfor subKey := range manifest {\n\t\t\t\t\tif strings.HasPrefix(subKey, keyPrefix) {\n\t\t\t\t\t\tif _, recorded := manifest[subKey]; recorded {\n\t\t\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: also discarding downstream %s\", subKey)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdelete(manifest, subKey)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trecord, recorded := manifest[key]\n\t\t\tif !recorded {\n\t\t\t\t// Clean up any stale cache directory that might be present.\n\t\t\t\t// If this is a local (relative) source then the dir will\n\t\t\t\t// not exist, but we'll ignore that.\n\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: cleaning directory %s prior to install of %s\", instPath, key)\n\t\t\t\terr := os.RemoveAll(instPath)\n\t\t\t\tif err != nil && !os.IsNotExist(err) {\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: failed to remove %s: %s\", key, err)\n\t\t\t\t\tdiags = diags.Append(&hcl.Diagnostic{\n\t\t\t\t\t\tSeverity: hcl.DiagError,\n\t\t\t\t\t\tSummary:  \"Failed to remove local module cache\",\n\t\t\t\t\t\tDetail: fmt.Sprintf(\n\t\t\t\t\t\t\t\"Terraform tried to remove %s in order to reinstall this module, but encountered an error: %s\",\n\t\t\t\t\t\t\tinstPath, err,\n\t\t\t\t\t\t),\n\t\t\t\t\t})\n\t\t\t\t\treturn nil, nil, diags\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// If this module is already recorded and its root directory\n\t\t\t\t// exists then we will just load what's already there and\n\t\t\t\t// keep our existing record.\n\t\t\t\tinfo, err := os.Stat(record.Dir)\n\t\t\t\tif err == nil && info.IsDir() {\n\t\t\t\t\tmod, mDiags := i.loader.Parser().LoadConfigDir(record.Dir)\n\t\t\t\t\tif mod == nil {\n\t\t\t\t\t\t// nil indicates an unreadable module, which should never happen,\n\t\t\t\t\t\t// so we return the full loader diagnostics here.\n\t\t\t\t\t\tdiags = diags.Extend(mDiags)\n\t\t\t\t\t} else if vDiags := mod.CheckCoreVersionRequirements(req.Path, req.SourceAddr); vDiags.HasErrors() {\n\t\t\t\t\t\t// If the core version requirements are not met, we drop any other\n\t\t\t\t\t\t// diagnostics, as they may reflect language changes from future\n\t\t\t\t\t\t// Terraform versions.\n\t\t\t\t\t\tdiags = diags.Extend(vDiags)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdiags = diags.Extend(mDiags)\n\t\t\t\t\t}\n\n\t\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: Module installer: %s %s already installed in %s\", key, record.Version, record.Dir)\n\t\t\t\t\treturn mod, record.Version, diags\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// If we get down here then it's finally time to actually install\n\t\t\t// the module. There are some variants to this process depending\n\t\t\t// on what type of module source address we have.\n\n\t\t\tswitch addr := req.SourceAddr.(type) {\n\n\t\t\tcase addrs.ModuleSourceLocal:\n\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s has local path %q\", key, addr.String())\n\t\t\t\tmod, mDiags := i.installLocalModule(req, key, manifest, hooks)\n\t\t\t\tmDiags = maybeImproveLocalInstallError(req, mDiags)\n\t\t\t\tdiags = append(diags, mDiags...)\n\t\t\t\treturn mod, nil, diags\n\n\t\t\tcase addrs.ModuleSourceRegistry:\n\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s is a registry module at %s\", key, addr.String())\n\t\t\t\tmod, v, mDiags := i.installRegistryModule(ctx, req, key, instPath, addr, manifest, hooks, fetcher)\n\t\t\t\tdiags = append(diags, mDiags...)\n\t\t\t\treturn mod, v, diags\n\n\t\t\tcase addrs.ModuleSourceRemote:\n\t\t\t\tlog.Printf(\"[TRACE] ModuleInstaller: %s address %q will be handled by go-getter\", key, addr.String())\n\t\t\t\tmod, mDiags := i.installGoGetterModule(ctx, req, key, instPath, manifest, hooks, fetcher)\n\t\t\t\tdiags = append(diags, mDiags...)\n\t\t\t\treturn mod, nil, diags\n\n\t\t\tdefault:\n\t\t\t\t// Shouldn't get here, because there are no other implementations\n\t\t\t\t// of addrs.ModuleSource.\n\t\t\t\tpanic(fmt.Sprintf(\"unsupported module source address %#v\", addr))\n\t\t\t}\n\t\t},\n\t)\n}", "is_vulnerable": 0}
{"code": "func (EmptyEvidencePool) Update(State, types.EvidenceList)                {}", "is_vulnerable": 0}
{"code": "func (client ProvidersClient) UnregisterSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (s *Sync) Process(result SyncResult) error {\n\t// If the item was not requested either for code or node, bail out\n\tif s.nodeReqs[result.Hash] == nil && s.codeReqs[result.Hash] == nil {\n\t\treturn ErrNotRequested\n\t}\n\t// There is an pending code request for this data, commit directly\n\tvar filled bool\n\tif req := s.codeReqs[result.Hash]; req != nil && req.data == nil {\n\t\tfilled = true\n\t\treq.data = result.Data\n\t\ts.commit(req)\n\t}\n\t// There is an pending node request for this data, fill it.\n\tif req := s.nodeReqs[result.Hash]; req != nil && req.data == nil {\n\t\tfilled = true\n\t\t// Decode the node data content and update the request\n\t\tnode, err := decodeNode(result.Hash[:], result.Data)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treq.data = result.Data\n\n\t\t// Create and schedule a request for all the children nodes\n\t\trequests, err := s.children(req, node)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif len(requests) == 0 && req.deps == 0 {\n\t\t\ts.commit(req)\n\t\t} else {\n\t\t\treq.deps += len(requests)\n\t\t\tfor _, child := range requests {\n\t\t\t\ts.schedule(child)\n\t\t\t}\n\t\t}\n\t}\n\tif !filled {\n\t\treturn ErrAlreadyProcessed\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (a *defaultAuditor) audit() error {\n\tstart := time.Now()\n\ta.index++\n\ta.logger.Infof(\"audit #%d started @ %s\", a.index, start)\n\n\tverified := true\n\tchecked := false\n\twithError := false\n\tserverID := \"unknown\"\n\tvar prevState *schema.ImmutableState\n\tvar state *schema.ImmutableState\n\n\tdefer func() {\n\t\ta.updateMetrics(\n\t\t\tserverID, a.serverAddress, checked, withError, verified, prevState, state)\n\t}()\n\n\t// returning an error would completely stop the auditor process\n\tvar noErr error\n\n\tctx := context.Background()\n\tloginResponse, err := a.serviceClient.Login(ctx, &schema.LoginRequest{\n\t\tUser:     a.username,\n\t\tPassword: a.password,\n\t})\n\tif err != nil {\n\t\ta.logger.Errorf(\"error logging in with user %s: %v\", a.username, err)\n\t\twithError = true\n\t\treturn noErr\n\t}\n\tdefer a.serviceClient.Logout(ctx, &empty.Empty{})\n\n\tmd := metadata.Pairs(\"authorization\", loginResponse.Token)\n\tctx = metadata.NewOutgoingContext(context.Background(), md)\n\n\t//check if we have cycled through the list of databases\n\tif a.databaseIndex == len(a.databases) {\n\t\t//if we have reached the end get a fresh list of dbs that belong to the user\n\t\tdbs, err := a.serviceClient.DatabaseList(ctx, &emptypb.Empty{})\n\t\tif err != nil {\n\t\t\ta.logger.Errorf(\"error getting a list of databases %v\", err)\n\t\t\twithError = true\n\t\t\treturn noErr\n\t\t}\n\t\ta.databases = nil\n\n\t\tfor _, db := range dbs.Databases {\n\t\t\tdbMustBeAudited := len(a.auditDatabases) <= 0\n\t\t\tfor _, dbPrefix := range a.auditDatabases {\n\t\t\t\tif strings.HasPrefix(db.DatabaseName, dbPrefix) {\n\t\t\t\t\tdbMustBeAudited = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif dbMustBeAudited {\n\t\t\t\ta.databases = append(a.databases, db.DatabaseName)\n\t\t\t}\n\t\t}\n\n\t\ta.databaseIndex = 0\n\t\tif len(a.databases) <= 0 {\n\t\t\ta.logger.Errorf(\n\t\t\t\t\"audit #%d aborted: no databases to audit found after (re)loading the list of databases\",\n\t\t\t\ta.index)\n\t\t\twithError = true\n\t\t\treturn noErr\n\t\t}\n\n\t\ta.logger.Infof(\n\t\t\t\"audit #%d - list of databases to audit has been (re)loaded - %d database(s) found: %v\",\n\t\t\ta.index, len(a.databases), a.databases)\n\t}\n\n\tdbName := a.databases[a.databaseIndex]\n\tresp, err := a.serviceClient.UseDatabase(ctx, &schema.Database{\n\t\tDatabaseName: dbName,\n\t})\n\tif err != nil {\n\t\ta.logger.Errorf(\"error selecting database %s: %v\", dbName, err)\n\t\twithError = true\n\t\treturn noErr\n\t}\n\n\tmd = metadata.Pairs(\"authorization\", resp.Token)\n\tctx = metadata.NewOutgoingContext(context.Background(), md)\n\n\ta.logger.Infof(\"audit #%d - auditing database %s\\n\", a.index, dbName)\n\ta.databaseIndex++\n\n\tstate, err = a.serviceClient.CurrentState(ctx, &empty.Empty{})\n\tif err != nil {\n\t\ta.logger.Errorf(\"error getting current state: %v\", err)\n\t\twithError = true\n\t\treturn noErr\n\t}\n\n\tif err := a.verifyStateSignature(serverID, state); err != nil {\n\t\ta.logger.Errorf(\"audit #%d aborted: %v\", a.index, err)\n\t\twithError = true\n\t\treturn noErr\n\t}\n\n\tisEmptyDB := state.TxId == 0\n\n\tserverID = a.getServerID(ctx)\n\tprevState, err = a.history.Get(serverID, dbName)\n\tif err != nil {\n\t\ta.logger.Errorf(err.Error())\n\t\twithError = true\n\t\treturn noErr\n\t}\n\n\tif prevState != nil {\n\t\tif isEmptyDB {\n\t\t\ta.logger.Errorf(\n\t\t\t\t\"audit #%d aborted: database is empty on server %s @ %s, \"+\n\t\t\t\t\t\"but locally a previous state exists with hash %x at id %d\",\n\t\t\t\ta.index, serverID, a.serverAddress, prevState.TxHash, prevState.TxId)\n\t\t\twithError = true\n\t\t\treturn noErr\n\t\t}\n\n\t\tvtx, err := a.serviceClient.VerifiableTxById(ctx, &schema.VerifiableTxRequest{\n\t\t\tTx:           state.TxId,\n\t\t\tProveSinceTx: prevState.TxId,\n\t\t})\n\t\tif err != nil {\n\t\t\ta.logger.Errorf(\n\t\t\t\t\"error fetching consistency proof for previous state %d: %v\",\n\t\t\t\tprevState.TxId, err)\n\t\t\twithError = true\n\t\t\treturn noErr\n\t\t}\n\n\t\tdualProof := schema.DualProofFromProto(vtx.DualProof)\n\t\terr = schema.FillMissingLinearAdvanceProof(\n\t\t\tctx, dualProof, prevState.TxId, state.TxId, a.serviceClient,\n\t\t)\n\t\tif err != nil {\n\t\t\ta.logger.Errorf(\n\t\t\t\t\"error fetching consistency proof for previous state %d: %v\",\n\t\t\t\tprevState.TxId, err)\n\t\t\twithError = true\n\t\t\treturn noErr\n\t\t}\n\n\t\tverified = store.VerifyDualProof(\n\t\t\tdualProof,\n\t\t\tprevState.TxId,\n\t\t\tstate.TxId,\n\t\t\tschema.DigestFromProto(prevState.TxHash),\n\t\t\tschema.DigestFromProto(state.TxHash),\n\t\t)\n\n\t\ta.logger.Infof(\"audit #%d result:\\n db: %s, consistent:\t%t\\n\"+\n\t\t\t\"  previous state:\t%x at tx: %d\\n  current state:\t%x at tx: %d\",\n\t\t\ta.index, dbName, verified,\n\t\t\tprevState.TxHash, prevState.TxId, state.TxHash, state.TxId)\n\n\t\tchecked = true\n\t\t// publish audit notification\n\t\tif len(a.notificationConfig.URL) > 0 {\n\t\t\terr := a.publishAuditNotification(\n\t\t\t\tdbName,\n\t\t\t\ttime.Now(),\n\t\t\t\t!verified,\n\t\t\t\t&State{\n\t\t\t\t\tTx:   prevState.TxId,\n\t\t\t\t\tHash: base64.StdEncoding.EncodeToString(prevState.TxHash),\n\t\t\t\t\tSignature: Signature{\n\t\t\t\t\t\tSignature: base64.StdEncoding.EncodeToString(prevState.GetSignature().GetSignature()),\n\t\t\t\t\t\tPublicKey: base64.StdEncoding.EncodeToString(prevState.GetSignature().GetPublicKey()),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&State{\n\t\t\t\t\tTx:   state.TxId,\n\t\t\t\t\tHash: base64.StdEncoding.EncodeToString(state.TxHash),\n\t\t\t\t\tSignature: Signature{\n\t\t\t\t\t\tSignature: base64.StdEncoding.EncodeToString(state.GetSignature().GetSignature()),\n\t\t\t\t\t\tPublicKey: base64.StdEncoding.EncodeToString(state.GetSignature().GetPublicKey()),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\ta.logger.Errorf(\n\t\t\t\t\t\"error publishing audit notification for db %s: %v\", dbName, err)\n\t\t\t} else {\n\t\t\t\ta.logger.Infof(\n\t\t\t\t\t\"audit notification for db %s has been published at %s\",\n\t\t\t\t\tdbName, a.notificationConfig.URL)\n\t\t\t}\n\t\t}\n\t} else if isEmptyDB {\n\t\ta.logger.Warningf(\"audit #%d canceled: database is empty on server %s @ %s\",\n\t\t\ta.index, serverID, a.serverAddress)\n\t\treturn noErr\n\t}\n\n\tif !verified {\n\t\ta.logger.Warningf(\n\t\t\t\"audit #%d detected possible tampering of db %s remote state (at id %d) \"+\n\t\t\t\t\"so it will not overwrite the previous local state (at id %d)\",\n\t\t\ta.index, dbName, state.TxId, prevState.TxId)\n\t} else if prevState == nil || state.TxId != prevState.TxId {\n\t\tif err := a.history.Set(serverID, dbName, state); err != nil {\n\t\t\ta.logger.Errorf(err.Error())\n\t\t\treturn noErr\n\t\t}\n\t}\n\ta.logger.Infof(\"audit #%d finished in %s @ %s\",\n\t\ta.index, time.Since(start), time.Now().Format(time.RFC3339Nano))\n\n\treturn noErr\n}", "is_vulnerable": 0}
{"code": "func (iface *x11Interface) MountConnectedPlug(spec *mount.Specification, plug *interfaces.ConnectedPlug, slot *interfaces.ConnectedSlot) error {\n\tif implicitSystemConnectedSlot(slot) {\n\t\t// X11 slot is provided by the host system. Bring the host's\n\t\t// /tmp/.X11-unix/ directory over to the snap mount namespace.\n\t\treturn spec.AddMountEntry(osutil.MountEntry{\n\t\t\tName:    \"/var/lib/snapd/hostfs/tmp/.X11-unix\",\n\t\t\tDir:     \"/tmp/.X11-unix\",\n\t\t\tOptions: []string{\"bind\", \"ro\"},\n\t\t})\n\t}\n\n\t// X11 slot is provided by another snap on the system. Bring that snap's\n\t// /tmp/.X11-unix/ directory over to the snap mount namespace. Here we\n\t// rely on the predictable naming of the private /tmp directory of the\n\t// slot-side snap which is currently provided by snap-confine.\n\n\t// But if the same snap is providing both the plug and the slot, this is\n\t// not necessary.\n\tif plug.Snap().InstanceName() == slot.Snap().InstanceName() {\n\t\treturn nil\n\t}\n\tslotSnapName := slot.Snap().InstanceName()\n\treturn spec.AddMountEntry(osutil.MountEntry{\n\t\tName:    fmt.Sprintf(\"/var/lib/snapd/hostfs/tmp/snap.%s/tmp/.X11-unix\", slotSnapName),\n\t\tDir:     \"/tmp/.X11-unix\",\n\t\tOptions: []string{\"bind\", \"ro\"},\n\t})\n}", "is_vulnerable": 1}
{"code": "func openTPMOrSkip(t *testing.T) io.ReadWriteCloser {\n\ttpmPath := os.Getenv(tpmPathEnvVar)\n\tif tpmPath == \"\" {\n\t\ttpmPath = \"/dev/tpm0\"\n\t}\n\n\trwc, err := openAndStartupTPM(tpmPath, true)\n\tif err != nil {\n\t\tt.Skipf(\"Skipping test, since we can't open %s for read/write: %s\\n\", tpmPath, err)\n\t}\n\n\treturn rwc\n}", "is_vulnerable": 0}
{"code": "func JwtRefreshAuth() gin.HandlerFunc {\n\tjwtService := services.JwtService()\n\treturn func(ctx *gin.Context) {\n\n\t\theader := ctx.GetHeader(\"Authorization\")\n\t\tif header == \"\" {\n\t\t\tctx.JSON(http.StatusUnauthorized, models.ResponseJson{\n\t\t\t\tSuccess: false,\n\t\t\t\tMessage: \"authorization is required\",\n\t\t\t})\n\t\t\tctx.Abort()\n\t\t\treturn\n\t\t}\n\n\t\tparts := strings.Split(header, \" \")\n\t\tfmt.Println(parts)\n\t\tif len(parts) != 2 || strings.ToLower(parts[0]) == \"Bearer\" {\n\t\t\tctx.JSON(http.StatusUnauthorized, models.ResponseJson{\n\t\t\t\tSuccess: false,\n\t\t\t\tMessage: \"invalid token\",\n\t\t\t})\n\t\t\tctx.Abort()\n\t\t\treturn\n\t\t}\n\n\t\tclaims, err := jwtService.VerifyRefreshToken(parts[1])\n\t\tif err != nil {\n\t\t\tctx.JSON(http.StatusUnauthorized, models.ResponseJson{\n\t\t\t\tSuccess: false,\n\t\t\t\tMessage: err.Error(),\n\t\t\t})\n\t\t\tctx.Abort()\n\t\t\treturn\n\t\t}\n\n\t\tctx.Set(\"userId\", claims.Subject)\n\t\tctx.Next()\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestDuplicateTimestamps(t *testing.T) {\n\tvirtualSigstore, err := ca.NewVirtualSigstore()\n\tassert.NoError(t, err)\n\n\tentity, err := virtualSigstore.Attest(\"foo@example.com\", \"issuer\", []byte(\"statement\"))\n\tassert.NoError(t, err)\n\n\t_, err = verify.VerifyTimestampAuthorityWithThreshold(&dupTimestampEntity{entity}, virtualSigstore, 1)\n\tassert.Error(t, err) // duplicate timestamps should fail to verify\n}", "is_vulnerable": 1}
{"code": "func (c *Context) DecryptVerify(ciphertext, plaintext *Data) error {\n\terr := handleError(C.gpgme_op_decrypt_verify(c.ctx, ciphertext.dh, plaintext.dh))\n\truntime.KeepAlive(c)\n\truntime.KeepAlive(ciphertext)\n\truntime.KeepAlive(plaintext)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "\tnetInterfaceAddrs = func() ([]net.Addr, error) {\n\t\tvar ips []net.Addr\n\t\tvar err error\n\t\t//var ip net.IP\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"127.0.0.1\"), Mask: net.CIDRMask(8, 32)})\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"10.50.100.101\"), Mask: net.CIDRMask(24, 32)})\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"::1\"), Mask: net.CIDRMask(128, 128)})\n\n\t\treturn ips, err\n\t}", "is_vulnerable": 0}
{"code": "func endorser(network *nwo.Network, needTime *timestamppb.Timestamp) error {\n\tpeerOrg1 := network.Peer(\"Org1\", \"peer0\")\n\tsigningIdentity := network.PeerUserSigner(peerOrg1, \"User1\")\n\tcreator, err := signingIdentity.Serialize()\n\tExpect(err).NotTo(HaveOccurred())\n\n\tconn := network.PeerClientConn(peerOrg1)\n\tgatewayClient := gateway.NewGatewayClient(conn)\n\n\tinvocationSpec := &peer.ChaincodeInvocationSpec{\n\t\tChaincodeSpec: &peer.ChaincodeSpec{\n\t\t\tType:        peer.ChaincodeSpec_NODE,\n\t\t\tChaincodeId: &peer.ChaincodeID{Name: \"mycc\"},\n\t\t\tInput:       &peer.ChaincodeInput{Args: [][]byte{[]byte(\"invoke\"), []byte(\"a\"), []byte(\"b\"), []byte(\"10\")}},\n\t\t},\n\t}\n\n\tproposal, transactionID, err := createChaincodeProposalWithTransient(\n\t\tcommon.HeaderType_ENDORSER_TRANSACTION,\n\t\t\"testchannel\",\n\t\tinvocationSpec,\n\t\tcreator,\n\t\tnil,\n\t\tneedTime,\n\t)\n\tExpect(err).NotTo(HaveOccurred())\n\n\tproposedTransaction, err := protoutil.GetSignedProposal(proposal, signingIdentity)\n\tExpect(err).NotTo(HaveOccurred())\n\n\tmspid := network.Organization(peerOrg1.Organization).MSPID\n\n\tendorseRequest := &gateway.EndorseRequest{\n\t\tTransactionId:          transactionID,\n\t\tChannelId:              \"testchannel\",\n\t\tProposedTransaction:    proposedTransaction,\n\t\tEndorsingOrganizations: []string{mspid},\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), network.EventuallyTimeout)\n\tdefer cancel()\n\t_, err = gatewayClient.Endorse(ctx, endorseRequest)\n\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (m *Nil) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowFuzz\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipFuzz(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthFuzz\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func NewDeploymentListResultIterator(page DeploymentListResultPage) DeploymentListResultIterator {\n\treturn DeploymentListResultIterator{page: page}\n}", "is_vulnerable": 0}
{"code": "func listenForEventRequestPaused(ctx context.Context, logger *zap.Logger, allowList *regexp.Regexp, denyList *regexp.Regexp) {\n\tchromedp.ListenTarget(ctx, func(ev interface{}) {\n\t\tswitch e := ev.(type) {\n\t\tcase *fetch.EventRequestPaused:\n\t\t\tgo func() {\n\t\t\t\tlogger.Debug(fmt.Sprintf(\"event EventRequestPaused fired for '%s'\", e.Request.URL))\n\t\t\t\tallow := true\n\n\t\t\t\tif !allowList.MatchString(e.Request.URL) {\n\t\t\t\t\tlogger.Warn(fmt.Sprintf(\"'%s' does not match the expression from the allowed list\", e.Request.URL))\n\t\t\t\t\tallow = false\n\t\t\t\t}\n\n\t\t\t\tif denyList.String() != \"\" && denyList.MatchString(e.Request.URL) {\n\t\t\t\t\tlogger.Warn(fmt.Sprintf(\"'%s' matches the expression from the denied list\", e.Request.URL))\n\t\t\t\t\tallow = false\n\t\t\t\t}\n\n\t\t\t\tcctx := chromedp.FromContext(ctx)\n\t\t\t\texecutorCtx := cdp.WithExecutor(ctx, cctx.Target)\n\n\t\t\t\tif allow {\n\t\t\t\t\treq := fetch.ContinueRequest(e.RequestID)\n\t\t\t\t\terr := req.Do(executorCtx)\n\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlogger.Error(fmt.Sprintf(\"continue request: %s\", err))\n\t\t\t\t\t}\n\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\treq := fetch.FailRequest(e.RequestID, network.ErrorReasonAccessDenied)\n\t\t\t\terr := req.Do(executorCtx)\n\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogger.Error(fmt.Sprintf(\"fail request: %s\", err))\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func Handler(w http.ResponseWriter, r *http.Request, c *config.Config, logger log.Logger,\n\trh *ResultHistory, timeoutOffset float64, params url.Values, moduleUnknownCounter prometheus.Counter) {\n\n\tif params == nil {\n\t\tparams = r.URL.Query()\n\t}\n\tmoduleName := params.Get(\"module\")\n\tif moduleName == \"\" {\n\t\tmoduleName = \"http_2xx\"\n\t}\n\tmodule, ok := c.Modules[moduleName]\n\tif !ok {\n\t\thttp.Error(w, fmt.Sprintf(\"Unknown module %q\", moduleName), http.StatusBadRequest)\n\t\tlevel.Debug(logger).Log(\"msg\", \"Unknown module\", \"module\", moduleName)\n\t\tif moduleUnknownCounter != nil {\n\t\t\tmoduleUnknownCounter.Add(1)\n\t\t}\n\t\treturn\n\t}\n\n\ttimeoutSeconds, err := getTimeout(r, module, timeoutOffset)\n\tif err != nil {\n\t\thttp.Error(w, fmt.Sprintf(\"Failed to parse timeout from Prometheus header: %s\", err), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\tctx, cancel := context.WithTimeout(r.Context(), time.Duration(timeoutSeconds*float64(time.Second)))\n\tdefer cancel()\n\tr = r.WithContext(ctx)\n\n\tprobeSuccessGauge := prometheus.NewGauge(prometheus.GaugeOpts{\n\t\tName: \"probe_success\",\n\t\tHelp: \"Displays whether or not the probe was a success\",\n\t})\n\tprobeDurationGauge := prometheus.NewGauge(prometheus.GaugeOpts{\n\t\tName: \"probe_duration_seconds\",\n\t\tHelp: \"Returns how long the probe took to complete in seconds\",\n\t})\n\n\ttarget := params.Get(\"target\")\n\tif target == \"\" {\n\t\thttp.Error(w, \"Target parameter is missing\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tprober, ok := Probers[module.Prober]\n\tif !ok {\n\t\thttp.Error(w, fmt.Sprintf(\"Unknown prober %q\", module.Prober), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\thostname := params.Get(\"hostname\")\n\tif module.Prober == \"http\" && hostname != \"\" {\n\t\terr = setHTTPHost(hostname, &module)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif module.Prober == \"tcp\" && hostname != \"\" {\n\t\tif module.TCP.TLSConfig.ServerName == \"\" {\n\t\t\tmodule.TCP.TLSConfig.ServerName = hostname\n\t\t}\n\t}\n\n\tsl := newScrapeLogger(logger, moduleName, target)\n\tlevel.Info(sl).Log(\"msg\", \"Beginning probe\", \"probe\", module.Prober, \"timeout_seconds\", timeoutSeconds)\n\n\tstart := time.Now()\n\tregistry := prometheus.NewRegistry()\n\tregistry.MustRegister(probeSuccessGauge)\n\tregistry.MustRegister(probeDurationGauge)\n\tsuccess := prober(ctx, target, module, registry, sl)\n\tduration := time.Since(start).Seconds()\n\tprobeDurationGauge.Set(duration)\n\tif success {\n\t\tprobeSuccessGauge.Set(1)\n\t\tlevel.Info(sl).Log(\"msg\", \"Probe succeeded\", \"duration_seconds\", duration)\n\t} else {\n\t\tlevel.Error(sl).Log(\"msg\", \"Probe failed\", \"duration_seconds\", duration)\n\t}\n\n\tdebugOutput := DebugOutput(&module, &sl.buffer, registry)\n\trh.Add(moduleName, target, debugOutput, success)\n\n\tif r.URL.Query().Get(\"debug\") == \"true\" {\n\t\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\t\tw.Write([]byte(debugOutput))\n\t\treturn\n\t}\n\n\th := promhttp.HandlerFor(registry, promhttp.HandlerOpts{})\n\th.ServeHTTP(w, r)\n}", "is_vulnerable": 1}
{"code": "func TestNative_Render_DisallowedFunc_Env(t *testing.T) {\n\t// setup types\n\twant := yaml.StepSlice{}\n\n\t// run test\n\ttmpl, err := ioutil.ReadFile(\"testdata/disallowed/tmpl_env.yml\")\n\tif err != nil {\n\t\tt.Errorf(\"Reading file returned err: %v\", err)\n\t}\n\n\tgot, err := Render(string(tmpl), &yaml.Step{})\n\tif err == nil {\n\t\tt.Errorf(\"Render should have returned err\")\n\t}\n\n\tif !reflect.DeepEqual(got, want) {\n\t\tt.Errorf(\"Render is %v, want %v\", got, want)\n\t}\n}", "is_vulnerable": 0}
{"code": "func SetMinIOVersion(version string) {\n\tGlobalMinIOVersion = version\n}", "is_vulnerable": 0}
{"code": "func (s *MSPMessageCryptoService) Expiration(peerIdentity api.PeerIdentityType) (time.Time, error) {\n\tid, _, err := s.getValidatedIdentity(peerIdentity)\n\tif err != nil {\n\t\treturn time.Time{}, errors.Wrap(err, \"Unable to extract msp.Identity from peer Identity\")\n\t}\n\treturn id.ExpiresAt(), nil\n\n}", "is_vulnerable": 1}
{"code": "func TestGenerator(t *testing.T) {\n\tcases := []struct {\n\t\tname   string\n\t\tg      generator\n\t\tkey    string\n\t\tvalue  string\n\t\tforTCP bool\n\t\twant   interface{}\n\t}{\n\t\t{\n\t\t\tname:  \"destIPGenerator\",\n\t\t\tg:     destIPGenerator{},\n\t\t\tvalue: \"1.2.3.4\",\n\t\t\twant: yamlPermission(t, `\n         destinationIp:\n          addressPrefix: 1.2.3.4\n          prefixLen: 32`),\n\t\t},\n\t\t{\n\t\t\tname:  \"destPortGenerator\",\n\t\t\tg:     destPortGenerator{},\n\t\t\tvalue: \"80\",\n\t\t\twant: yamlPermission(t, `\n         destinationPort: 80`),\n\t\t},\n\t\t{\n\t\t\tname:  \"connSNIGenerator\",\n\t\t\tg:     connSNIGenerator{},\n\t\t\tvalue: \"exact.com\",\n\t\t\twant: yamlPermission(t, `\n         requestedServerName:\n          exact: exact.com`),\n\t\t},\n\t\t{\n\t\t\tname:  \"envoyFilterGenerator-string\",\n\t\t\tg:     envoyFilterGenerator{},\n\t\t\tkey:   \"experimental.a.b.c[d]\",\n\t\t\tvalue: \"val\",\n\t\t\twant: yamlPermission(t, `\n         metadata:\n          filter: a.b.c\n          path:\n          - key: d\n          value:\n            stringMatch:\n              exact: val`),\n\t\t},\n\t\t{\n\t\t\tname:  \"envoyFilterGenerator-list\",\n\t\t\tg:     envoyFilterGenerator{},\n\t\t\tkey:   \"experimental.a.b.c[d]\",\n\t\t\tvalue: \"[v1, v2]\",\n\t\t\twant: yamlPermission(t, `\n         metadata:\n          filter: a.b.c\n          path:\n          - key: d\n          value:\n            listMatch:\n              oneOf:\n                stringMatch:\n                  exact: v1, v2`),\n\t\t},\n\t\t{\n\t\t\tname:  \"srcIPGenerator\",\n\t\t\tg:     srcIPGenerator{},\n\t\t\tvalue: \"1.2.3.4\",\n\t\t\twant: yamlPrincipal(t, `\n         directRemoteIp:\n          addressPrefix: 1.2.3.4\n          prefixLen: 32`),\n\t\t},\n\t\t{\n\t\t\tname:  \"remoteIPGenerator\",\n\t\t\tg:     remoteIPGenerator{},\n\t\t\tvalue: \"1.2.3.4\",\n\t\t\twant: yamlPrincipal(t, `\n         remoteIp:\n          addressPrefix: 1.2.3.4\n          prefixLen: 32`),\n\t\t},\n\t\t{\n\t\t\tname:  \"srcNamespaceGenerator-http\",\n\t\t\tg:     srcNamespaceGenerator{},\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: source.principal\n          value:\n            stringMatch:\n              safeRegex:\n                googleRe2: {}\n                regex: .*/ns/foo/.*`),\n\t\t},\n\t\t{\n\t\t\tname:   \"srcNamespaceGenerator-tcp\",\n\t\t\tg:      srcNamespaceGenerator{},\n\t\t\tvalue:  \"foo\",\n\t\t\tforTCP: true,\n\t\t\twant: yamlPrincipal(t, `\n         authenticated:\n          principalName:\n            safeRegex:\n              googleRe2: {}\n              regex: .*/ns/foo/.*`),\n\t\t},\n\t\t{\n\t\t\tname:  \"srcPrincipalGenerator-http\",\n\t\t\tg:     srcPrincipalGenerator{},\n\t\t\tkey:   \"source.principal\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: source.principal\n          value:\n            stringMatch:\n              exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:   \"srcPrincipalGenerator-tcp\",\n\t\t\tg:      srcPrincipalGenerator{},\n\t\t\tkey:    \"source.principal\",\n\t\t\tvalue:  \"foo\",\n\t\t\tforTCP: true,\n\t\t\twant: yamlPrincipal(t, `\n         authenticated:\n          principalName:\n            exact: spiffe://foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestPrincipalGenerator\",\n\t\t\tg:     requestPrincipalGenerator{},\n\t\t\tkey:   \"request.auth.principal\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: request.auth.principal\n          value:\n            stringMatch:\n              exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestAudiencesGenerator\",\n\t\t\tg:     requestAudiencesGenerator{},\n\t\t\tkey:   \"request.auth.audiences\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: request.auth.audiences\n          value:\n            stringMatch:\n              exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestPresenterGenerator\",\n\t\t\tg:     requestPresenterGenerator{},\n\t\t\tkey:   \"request.auth.presenter\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: request.auth.presenter\n          value:\n            stringMatch:\n              exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestHeaderGenerator\",\n\t\t\tg:     requestHeaderGenerator{},\n\t\t\tkey:   \"request.headers[x-foo]\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         header:\n          exactMatch: foo\n          name: x-foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestClaimGenerator\",\n\t\t\tg:     requestClaimGenerator{},\n\t\t\tkey:   \"request.auth.claims[bar]\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: request.auth.claims\n          - key: bar\n          value:\n            listMatch:\n              oneOf:\n                stringMatch:\n                  exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"requestNestedClaimsGenerator\",\n\t\t\tg:     requestClaimGenerator{},\n\t\t\tkey:   \"request.auth.claims[bar][baz]\",\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPrincipal(t, `\n         metadata:\n          filter: istio_authn\n          path:\n          - key: request.auth.claims\n          - key: bar\n          - key: baz\n          value:\n            listMatch:\n              oneOf:\n                stringMatch:\n                  exact: foo`),\n\t\t},\n\t\t{\n\t\t\tname:  \"hostGenerator\",\n\t\t\tg:     hostGenerator{},\n\t\t\tvalue: \"foo\",\n\t\t\twant: yamlPermission(t, `\n         header:\n          exactMatch: foo\n          name: :authority`),\n\t\t},\n\t\t{\n\t\t\tname:  \"pathGenerator\",\n\t\t\tg:     pathGenerator{},\n\t\t\tvalue: \"/abc\",\n\t\t\twant: yamlPermission(t, `\n         urlPath:\n          path:\n            exact: /abc`),\n\t\t},\n\t\t{\n\t\t\tname:  \"methodGenerator\",\n\t\t\tg:     methodGenerator{},\n\t\t\tvalue: \"GET\",\n\t\t\twant: yamlPermission(t, `\n         header:\n          exactMatch: GET\n          name: :method`),\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tvar got interface{}\n\t\t\tvar err error\n\t\t\tif _, ok := tc.want.(*rbacpb.Permission); ok {\n\t\t\t\tgot, err = tc.g.permission(tc.key, tc.value, tc.forTCP)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"both permission and principal returned error\")\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tgot, err = tc.g.principal(tc.key, tc.value, tc.forTCP)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"both permission and principal returned error\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tif diff := cmp.Diff(got, tc.want, protocmp.Transform()); diff != \"\" {\n\t\t\t\tvar gotYaml string\n\t\t\t\tgotProto, ok := got.(proto.Message)\n\t\t\t\tif !ok {\n\t\t\t\t\tt.Fatal(\"failed to extract proto\")\n\t\t\t\t}\n\t\t\t\tif gotYaml, err = protomarshal.ToYAML(gotProto); err != nil {\n\t\t\t\t\tt.Fatalf(\"%s: failed to parse yaml: %s\", tc.name, err)\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"got:\\n %v\\n but want:\\n %v\", gotYaml, tc.want)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e *ExecCommandError) Error() string {\n\tlastOutput := e.Output\n\tif len(e.Output) > 200 {\n\t\tlastOutput = \"... \" + e.Output[len(e.Output)-200:]\n\t}\n\n\treturn fmt.Sprintf(\"failed executing %s %v, Error %s, LastOutput \\\"%s\\\"\", e.Command, e.Args, e.ExitErr, lastOutput)\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_SomeValuesFromConfig(t *testing.T) {\n\tc := Configurator{base: &Config{\n\t\tVerifyServerHostname: true,\n\t\tVerifyOutgoing:       true,\n\t\tDomain:               \"abc.de\",\n\t}}\n\tone, two, three := c.someValuesFromConfig()\n\trequire.Equal(t, c.base.VerifyServerHostname, one)\n\trequire.Equal(t, c.base.VerifyOutgoing, two)\n\trequire.Equal(t, c.base.Domain, three)\n}", "is_vulnerable": 0}
{"code": "\t\t\tpatch: func(rt *RuntimeConfig) {\n\t\t\t\trt.DataDir = dataDir\n\t\t\t\trt.HTTPUseCache = true\n\t\t\t},", "is_vulnerable": 0}
{"code": "func StructDetailsA(ctx PfCtx, obj interface{}, field string, opts StructDetails_Options) (ftype string, fname string, fvalue string, err error) {\n\tcheckperms := false\n\tif opts&SD_Perms_Check > 0 {\n\t\tcheckperms = true\n\t}\n\n\trequiretags := false\n\tif opts&SD_Tags_Require > 0 {\n\t\trequiretags = true\n\t}\n\n\ts, va := StructReflect(obj)\n\n\tfor i := 0; i < s.NumField(); i++ {\n\t\tf := s.Field(i)\n\t\tv := va.Field(i)\n\n\t\t/* Column/fieldname in SQL Table */\n\t\tfname = f.Tag.Get(\"pfcol\")\n\t\tif fname == \"\" {\n\t\t\tfname = strings.ToLower(f.Name)\n\t\t}\n\n\t\t/* Ignore the field completely? */\n\t\tttype, dorecurse, compound := PfType(f, v, true)\n\t\tif ttype == \"ignore\" {\n\t\t\tif fname == field {\n\t\t\t\treturn \"ignore\", \"\", \"\", errors.New(\"Field is ignored\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif dorecurse {\n\t\t\tftype, fname, fvalue, err = StructDetailsA(ctx, StructRecurse(v), field, opts)\n\t\t\tif ftype != \"\" || err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tif compound {\n\t\t\tcontinue\n\t\t}\n\n\t\t/* No tags, then ignore it */\n\t\tif requiretags && f.Tag == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t/* Wrong field, skip it */\n\t\tif fname != field {\n\t\t\tcontinue\n\t\t}\n\n\t\tif checkperms {\n\t\t\tok := true\n\t\t\tpermstr := f.Tag.Get(\"pfset\")\n\n\t\t\tok, err = ctx.CheckPermsT(\"StructDetails(\"+fname+\")\", permstr)\n\t\t\tif !ok {\n\t\t\t\treturn \"\", \"\", \"\", err\n\t\t\t}\n\t\t}\n\n\t\treturn \"string\", fname, ToString(v.Interface()), nil\n\t}\n\n\treturn \"\", \"\", \"\", nil\n}", "is_vulnerable": 0}
{"code": "func newHasher() *testHasher {\n\treturn &testHasher{hasher: sha3.NewLegacyKeccak256()}\n}", "is_vulnerable": 0}
{"code": "func (p *TSimpleJSONProtocol) safePeekContains(b []byte) bool {\n\tfor i := 0; i < len(b); i++ {\n\t\ta, _ := p.reader.Peek(i + 1)\n\t\tif len(a) == 0 || a[i] != b[i] {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "is_vulnerable": 1}
{"code": "func (g *HttpGetter) getSubdir(ctx context.Context, req *Request, source, subDir string) error {\n\t// Create a temporary directory to store the full source. This has to be\n\t// a non-existent directory.\n\ttd, tdcloser, err := safetemp.Dir(\"\", \"getter\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer tdcloser.Close()\n\n\t// Download that into the given directory\n\tif _, err := Get(ctx, td, source); err != nil {\n\t\treturn err\n\t}\n\n\t// Process any globbing\n\tsourcePath, err := SubdirGlob(td, subDir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Make sure the subdir path actually exists\n\tif _, err := os.Stat(sourcePath); err != nil {\n\t\treturn fmt.Errorf(\n\t\t\t\"Error downloading %s: %s\", source, err)\n\t}\n\n\t// Copy the subdirectory into our actual destination.\n\tif err := os.RemoveAll(req.Dst); err != nil {\n\t\treturn err\n\t}\n\n\t// Make the final destination\n\tif err := os.MkdirAll(req.Dst, req.Mode(0755)); err != nil {\n\t\treturn err\n\t}\n\n\treturn copyDir(ctx, req.Dst, sourcePath, false, req.umask())\n}", "is_vulnerable": 1}
{"code": "func (h *Handler) Filewrite(request *sftp.Request) (io.WriterAt, error) {\n\tif h.ro {\n\t\treturn nil, sftp.ErrSSHFxOpUnsupported\n\t}\n\tl := h.logger.WithField(\"source\", request.Filepath)\n\t// If the user doesn't have enough space left on the server it should respond with an\n\t// error since we won't be letting them write this file to the disk.\n\tif !h.fs.HasSpaceAvailable(true) {\n\t\treturn nil, ErrSSHQuotaExceeded\n\t}\n\n\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\t// The specific permission required to perform this action. If the file exists on the\n\t// system already it only needs to be an update, otherwise we'll check for a create.\n\tpermission := PermissionFileUpdate\n\t_, sterr := h.fs.Stat(request.Filepath)\n\tif sterr != nil {\n\t\tif !errors.Is(sterr, os.ErrNotExist) {\n\t\t\tl.WithField(\"error\", sterr).Error(\"error while getting file reader\")\n\t\t\treturn nil, sftp.ErrSSHFxFailure\n\t\t}\n\t\tpermission = PermissionFileCreate\n\t}\n\t// Confirm the user has permission to perform this action BEFORE calling Touch, otherwise\n\t// you'll potentially create a file on the system and then fail out because of user\n\t// permission checking after the fact.\n\tif !h.can(permission) {\n\t\treturn nil, sftp.ErrSSHFxPermissionDenied\n\t}\n\tf, err := h.fs.Touch(request.Filepath, os.O_RDWR|os.O_CREATE|os.O_TRUNC)\n\tif err != nil {\n\t\tl.WithField(\"flags\", request.Flags).WithField(\"error\", err).Error(\"failed to open existing file on system\")\n\t\treturn nil, sftp.ErrSSHFxFailure\n\t}\n\t// Chown may or may not have been called in the touch function, so always do\n\t// it at this point to avoid the file being improperly owned.\n\t_ = h.fs.Chown(request.Filepath)\n\tevent := server.ActivitySftpWrite\n\tif permission == PermissionFileCreate {\n\t\tevent = server.ActivitySftpCreate\n\t}\n\th.events.MustLog(event, FileAction{Entity: request.Filepath})\n\treturn f, nil\n}", "is_vulnerable": 1}
{"code": "func TestACLAddInvalidGlob(t *testing.T) {\n\ta := assert.New(t)\n\n\tinvalidGlobs := []string{\n\t\t\"*.*.stripe.com\", // multiple wildcards\n\t\t\"*\",              // matches everything\n\t\t\"*.\",             // matches everything\n\t}\n\n\tacl := &ACL{\n\t\tRules: make(map[string]Rule),\n\t}\n\n\tfor _, glob := range invalidGlobs {\n\t\terr := acl.Add(\"acl\", Rule{\n\t\t\tProject:     \"security\",\n\t\t\tPolicy:      Open,\n\t\t\tDomainGlobs: []string{glob},\n\t\t})\n\n\t\ta.Errorf(err, \"did not reject invalid glob %q\", glob)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *linuxContainer) newSetnsProcess(p *Process, cmd *exec.Cmd, messageSockPair, logFilePair filePair) (*setnsProcess, error) {\n\tcmd.Env = append(cmd.Env, \"_LIBCONTAINER_INITTYPE=\"+string(initSetns))\n\tstate, err := c.currentState()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unable to get container state: %w\", err)\n\t}\n\t// for setns process, we don't have to set cloneflags as the process namespaces\n\t// will only be set via setns syscall\n\tdata, err := c.bootstrapData(0, state.NamespacePaths)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tproc := &setnsProcess{\n\t\tcmd:             cmd,\n\t\tcgroupPaths:     state.CgroupPaths,\n\t\trootlessCgroups: c.config.RootlessCgroups,\n\t\tintelRdtPath:    state.IntelRdtPath,\n\t\tmessageSockPair: messageSockPair,\n\t\tlogFilePair:     logFilePair,\n\t\tmanager:         c.cgroupManager,\n\t\tconfig:          c.newInitConfig(p),\n\t\tprocess:         p,\n\t\tbootstrapData:   data,\n\t\tinitProcessPid:  state.InitProcessPid,\n\t}\n\tif len(p.SubCgroupPaths) > 0 {\n\t\tif add, ok := p.SubCgroupPaths[\"\"]; ok {\n\t\t\t// cgroup v1: using the same path for all controllers.\n\t\t\t// cgroup v2: the only possible way.\n\t\t\tfor k := range proc.cgroupPaths {\n\t\t\t\tproc.cgroupPaths[k] = path.Join(proc.cgroupPaths[k], add)\n\t\t\t}\n\t\t\t// cgroup v2: do not try to join init process's cgroup\n\t\t\t// as a fallback (see (*setnsProcess).start).\n\t\t\tproc.initProcessPid = 0\n\t\t} else {\n\t\t\t// Per-controller paths.\n\t\t\tfor ctrl, add := range p.SubCgroupPaths {\n\t\t\t\tif val, ok := proc.cgroupPaths[ctrl]; ok {\n\t\t\t\t\tproc.cgroupPaths[ctrl] = path.Join(val, add)\n\t\t\t\t} else {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unknown controller %s in SubCgroupPaths\", ctrl)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn proc, nil\n}", "is_vulnerable": 1}
{"code": "func TestZipBomb(t *testing.T) {\n\tinput := strings.Repeat(\"a\", 251000)\n\tcompressed, err := compress(DEFLATE, []byte(input))\n\tif err != nil {\n\t\tt.Errorf(\"compressing: %s\", err)\n\t}\n\tt.Logf(\"compression ratio: %d %g\", len(compressed), float64(len(input))/float64(len(compressed)))\n\tout, err := decompress(DEFLATE, compressed)\n\tif err == nil {\n\t\tt.Errorf(\"expected error decompressing zip bomb, got none. output size %d\", len(out))\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewKMSContextWrapEntry(kmsClient kmsiface.KMSAPI) WrapEntry {\n\t// These values are read only making them thread safe\n\tkp := &kmsKeyHandler{\n\t\tkms:         kmsClient,\n\t\twithContext: true,\n\t}\n\n\treturn kp.decryptHandler\n}", "is_vulnerable": 0}
{"code": "func (s *APIV2Service) ListStorages(ctx context.Context, _ *apiv2pb.ListStoragesRequest) (*apiv2pb.ListStoragesResponse, error) {\n\tstorages, err := s.Store.ListStoragesV1(ctx, &store.FindStorage{})\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.Internal, \"failed to list storages, error: %+v\", err)\n\t}\n\n\tresponse := &apiv2pb.ListStoragesResponse{\n\t\tStorages: []*apiv2pb.Storage{},\n\t}\n\tfor _, storage := range storages {\n\t\tresponse.Storages = append(response.Storages, convertStorageFromStore(storage))\n\t}\n\treturn response, nil\n}", "is_vulnerable": 1}
{"code": "\tmakeAny := func(m proto.Message) *anypb.Any {\n\t\tv, err := anypb.New(m)\n\t\trequire.NoError(t, err)\n\t\treturn v\n\t}\n\ttests := map[string]struct {\n\t\tfilter       *envoy_listener_v3.Filter\n\t\texpectFilter *envoy_listener_v3.Filter\n\t\texpectBool   bool\n\t\texpectErr    string\n\t}{\n\t\t\"invalid filter name is ignored\": {\n\t\t\tfilter:       &envoy_listener_v3.Filter{Name: \"something\"},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{Name: \"something\"},\n\t\t\texpectBool:   false,\n\t\t},\n\t\t\"error getting typed config\": {\n\t\t\tfilter:       &envoy_listener_v3.Filter{Name: \"envoy.filters.network.http_connection_manager\"},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{Name: \"envoy.filters.network.http_connection_manager\"},\n\t\t\texpectBool:   false,\n\t\t\texpectErr:    \"error getting typed config for http filter\",\n\t\t},\n\t\t\"error getting http connection manager\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: &anypb.Any{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: &anypb.Any{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: false,\n\t\t\texpectErr:  \"error unmarshalling filter\",\n\t\t},\n\t\t\"StripAnyHostPort is set\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tStripPortMode: &envoy_http_v3.HttpConnectionManager_StripAnyHostPort{\n\t\t\t\t\t\t\tStripAnyHostPort: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: true,\n\t\t},\n\t\t\"lambda filter injected correctly\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tStripPortMode: &envoy_http_v3.HttpConnectionManager_StripAnyHostPort{\n\t\t\t\t\t\t\tStripAnyHostPort: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName: \"envoy.filters.http.aws_lambda\",\n\t\t\t\t\t\t\t\tConfigType: &envoy_http_v3.HttpFilter_TypedConfig{TypedConfig: makeAny(\n\t\t\t\t\t\t\t\t\t&envoy_lambda_v3.Config{\n\t\t\t\t\t\t\t\t\t\tArn:                \"some-arn\",\n\t\t\t\t\t\t\t\t\t\tPayloadPassthrough: true,\n\t\t\t\t\t\t\t\t\t\tInvocationMode:     envoy_lambda_v3.Config_ASYNCHRONOUS,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t)},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: true,\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tl := awsLambda{\n\t\t\t\tARN:                \"some-arn\",\n\t\t\t\tPayloadPassthrough: true,\n\t\t\t\tInvocationMode:     \"asynchronous\",\n\t\t\t}\n\t\t\tf, ok, err := l.PatchFilter(nil, tc.filter)\n\t\t\trequire.Equal(t, tc.expectBool, ok)\n\t\t\tif tc.expectErr == \"\" {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t} else {\n\t\t\t\trequire.ErrorContains(t, err, tc.expectErr)\n\t\t\t}\n\t\t\tprototest.AssertDeepEqual(t, tc.expectFilter, f)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *KustomizationReconciler) reconcile(\n\tctx context.Context,\n\tkustomization kustomizev1.Kustomization,\n\tsource sourcev1.Source) (kustomizev1.Kustomization, error) {\n\t// record the value of the reconciliation request, if any\n\tif v, ok := meta.ReconcileAnnotationValue(kustomization.GetAnnotations()); ok {\n\t\tkustomization.Status.SetLastHandledReconcileRequest(v)\n\t}\n\n\trevision := source.GetArtifact().Revision\n\n\t// create tmp dir\n\ttmpDir, err := os.MkdirTemp(\"\", kustomization.Name)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"tmp dir error: %w\", err)\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tsourcev1.DirCreationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\tdefer os.RemoveAll(tmpDir)\n\n\t// download artifact and extract files\n\terr = r.download(source.GetArtifact(), tmpDir)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// check build path exists\n\tdirPath, err := securejoin.SecureJoin(tmpDir, kustomization.Spec.Path)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\tif _, err := os.Stat(dirPath); err != nil {\n\t\terr = fmt.Errorf(\"kustomization path not found: %w\", err)\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// setup the Kubernetes client for impersonation\n\timpersonation := NewKustomizeImpersonation(kustomization, r.Client, r.StatusPoller, r.DefaultServiceAccount, r.KubeConfigOpts)\n\tkubeClient, statusPoller, err := impersonation.GetClient(ctx)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), fmt.Errorf(\"failed to build kube client: %w\", err)\n\t}\n\n\t// generate kustomization.yaml if needed\n\terr = r.generate(kustomization, tmpDir, dirPath)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// build the kustomization\n\tresources, err := r.build(ctx, tmpDir, kustomization, dirPath)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// convert the build result into Kubernetes unstructured objects\n\tobjects, err := ssa.ReadObjects(bytes.NewReader(resources))\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// create a snapshot of the current inventory\n\toldStatus := kustomization.Status.DeepCopy()\n\n\t// create the server-side apply manager\n\tresourceManager := ssa.NewResourceManager(kubeClient, statusPoller, ssa.Owner{\n\t\tField: r.ControllerName,\n\t\tGroup: kustomizev1.GroupVersion.Group,\n\t})\n\tresourceManager.SetOwnerLabels(objects, kustomization.GetName(), kustomization.GetNamespace())\n\n\t// validate and apply resources in stages\n\tdrifted, changeSet, err := r.apply(ctx, resourceManager, kustomization, revision, objects)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// create an inventory of objects to be reconciled\n\tnewInventory := NewInventory()\n\terr = AddObjectsToInventory(newInventory, changeSet)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// detect stale objects which are subject to garbage collection\n\tvar staleObjects []*unstructured.Unstructured\n\tif oldStatus.Inventory != nil {\n\t\tdiffObjects, err := DiffInventory(oldStatus.Inventory, newInventory)\n\t\tif err != nil {\n\t\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\t\tkustomization,\n\t\t\t\trevision,\n\t\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\t\terr.Error(),\n\t\t\t), err\n\t\t}\n\n\t\t// TODO: remove this workaround after kustomize-controller 0.18 release\n\t\t// skip objects that were wrongly marked as namespaced\n\t\t// https://github.com/fluxcd/kustomize-controller/issues/466\n\t\tnewObjects, _ := ListObjectsInInventory(newInventory)\n\t\tfor _, obj := range diffObjects {\n\t\t\tpreserve := false\n\t\t\tif obj.GetNamespace() != \"\" {\n\t\t\t\tfor _, newObj := range newObjects {\n\t\t\t\t\tif newObj.GetNamespace() == \"\" &&\n\t\t\t\t\t\tobj.GetKind() == newObj.GetKind() &&\n\t\t\t\t\t\tobj.GetAPIVersion() == newObj.GetAPIVersion() &&\n\t\t\t\t\t\tobj.GetName() == newObj.GetName() {\n\t\t\t\t\t\tpreserve = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !preserve {\n\t\t\t\tstaleObjects = append(staleObjects, obj)\n\t\t\t}\n\t\t}\n\t}\n\n\t// run garbage collection for stale objects that do not have pruning disabled\n\tif _, err := r.prune(ctx, resourceManager, kustomization, revision, staleObjects); err != nil {\n\t\treturn kustomizev1.KustomizationNotReadyInventory(\n\t\t\tkustomization,\n\t\t\tnewInventory,\n\t\t\trevision,\n\t\t\tkustomizev1.PruneFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// health assessment\n\tif err := r.checkHealth(ctx, resourceManager, kustomization, revision, drifted, changeSet.ToObjMetadataSet()); err != nil {\n\t\treturn kustomizev1.KustomizationNotReadyInventory(\n\t\t\tkustomization,\n\t\t\tnewInventory,\n\t\t\trevision,\n\t\t\tkustomizev1.HealthCheckFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\treturn kustomizev1.KustomizationReadyInventory(\n\t\tkustomization,\n\t\tnewInventory,\n\t\trevision,\n\t\tkustomizev1.ReconciliationSucceededReason,\n\t\tfmt.Sprintf(\"Applied revision: %s\", revision),\n\t), nil\n}", "is_vulnerable": 0}
{"code": "func NotEqualf(t TestingT, expected interface{}, actual interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotEqualf(t, expected, actual, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (e *MaxLayerSizeExceeded) Error() string {\n\treturn fmt.Sprintf(\"size of layer (%d) exceeded the limit (%d)\", e.value, e.maximum)\n}", "is_vulnerable": 0}
{"code": "func OpenDB(cfg DBConfig, vars map[string]string) (*sql.DB, error) {\n\tvar dbDSN string\n\tif len(cfg.Snapshot) != 0 {\n\t\tlog.Info(\"create connection with snapshot\", zap.String(\"snapshot\", cfg.Snapshot))\n\t\tdbDSN = fmt.Sprintf(\"%s:%s@tcp(%s:%d)/?charset=utf8mb4&tidb_snapshot=%s\", cfg.User, cfg.Password, cfg.Host, cfg.Port, cfg.Snapshot)\n\t} else {\n\t\tdbDSN = fmt.Sprintf(\"%s:%s@tcp(%s:%d)/?charset=utf8mb4\", cfg.User, cfg.Password, cfg.Host, cfg.Port)\n\t}\n\n\tfor key, val := range vars {\n\t\t// key='val'. add single quote for better compatibility.\n\t\tdbDSN += fmt.Sprintf(\"&%s=%%27%s%%27\", key, url.QueryEscape(val))\n\t}\n\n\tdbConn, err := sql.Open(\"mysql\", dbDSN)\n\tif err != nil {\n\t\treturn nil, errors.Trace(err)\n\t}\n\n\terr = dbConn.Ping()\n\treturn dbConn, errors.Trace(err)\n}", "is_vulnerable": 1}
{"code": "func NewSanitizer() {\n\tsanitizer.init.Do(func() {\n\t\tInitializeSanitizer()\n\t})\n}", "is_vulnerable": 1}
{"code": "func (suite *KeeperTestSuite) TestGovClawbackNoOps() {\n\tif err := suite.SetupTest(); err != nil {\n\t\tpanic(err)\n\t}\n\n\taddr := sdk.AccAddress(suite.address.Bytes())\n\taddr2 := sdk.AccAddress(testutiltx.GenerateAddress().Bytes())\n\n\t// disable the address\n\tsuite.app.VestingKeeper.SetGovClawbackDisabled(suite.ctx, addr)\n\n\t// a duplicate entry should not panic but no-op\n\tsuite.app.VestingKeeper.SetGovClawbackDisabled(suite.ctx, addr)\n\n\t// check that the address is disabled\n\tdisabled := suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr)\n\tsuite.Require().True(disabled, \"expected address to be found in store\")\n\n\t// check that address 2 is not disabled\n\tdisabled = suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr2)\n\tsuite.Require().False(disabled, \"expected address not to be found in store\")\n\n\t// deleting a non-existent entry should not panic but no-op\n\tsuite.app.VestingKeeper.DeleteGovClawbackDisabled(suite.ctx, addr2)\n\n\t// check that the address is still not disabled\n\tdisabled = suite.app.VestingKeeper.HasGovClawbackDisabled(suite.ctx, addr2)\n\tsuite.Require().False(disabled, \"expected address not to be found in store\")\n}", "is_vulnerable": 0}
{"code": "func clientHelloInfo(br *bufio.Reader) (*clientHello, error) {\n\thdr, err := br.Peek(1)\n\tif err != nil {\n\t\tvar opErr *net.OpError\n\t\tif !errors.Is(err, io.EOF) && (!errors.As(err, &opErr) || opErr.Timeout()) {\n\t\t\tlog.WithoutContext().Errorf(\"Error while Peeking first byte: %s\", err)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// No valid TLS record has a type of 0x80, however SSLv2 handshakes start with an uint16 length\n\t// where the MSB is set and the first record is always < 256 bytes long.\n\t// Therefore, typ == 0x80 strongly suggests an SSLv2 client.\n\tconst recordTypeSSLv2 = 0x80\n\tconst recordTypeHandshake = 0x16\n\tif hdr[0] != recordTypeHandshake {\n\t\tif hdr[0] == recordTypeSSLv2 {\n\t\t\t// we consider SSLv2 as TLS, and it will be refused by real TLS handshake.\n\t\t\treturn &clientHello{\n\t\t\t\tisTLS:  true,\n\t\t\t\tpeeked: getPeeked(br),\n\t\t\t}, nil\n\t\t}\n\t\treturn &clientHello{\n\t\t\tpeeked: getPeeked(br),\n\t\t}, nil // Not TLS.\n\t}\n\n\tconst recordHeaderLen = 5\n\thdr, err = br.Peek(recordHeaderLen)\n\tif err != nil {\n\t\tlog.Errorf(\"Error while Peeking hello: %s\", err)\n\t\treturn &clientHello{\n\t\t\tpeeked: getPeeked(br),\n\t\t}, nil\n\t}\n\n\trecLen := int(hdr[3])<<8 | int(hdr[4]) // ignoring version in hdr[1:3]\n\n\tif recordHeaderLen+recLen > defaultBufSize {\n\t\tbr = bufio.NewReaderSize(br, recordHeaderLen+recLen)\n\t}\n\n\thelloBytes, err := br.Peek(recordHeaderLen + recLen)\n\tif err != nil {\n\t\tlog.Errorf(\"Error while Hello: %s\", err)\n\t\treturn &clientHello{\n\t\t\tisTLS:  true,\n\t\t\tpeeked: getPeeked(br),\n\t\t}, nil\n\t}\n\n\tsni := \"\"\n\tvar protos []string\n\tserver := tls.Server(helloSniffConn{r: bytes.NewReader(helloBytes)}, &tls.Config{\n\t\tGetConfigForClient: func(hello *tls.ClientHelloInfo) (*tls.Config, error) {\n\t\t\tsni = hello.ServerName\n\t\t\tprotos = hello.SupportedProtos\n\t\t\treturn nil, nil\n\t\t},\n\t})\n\t_ = server.Handshake()\n\n\treturn &clientHello{\n\t\tserverName: sni,\n\t\tisTLS:      true,\n\t\tpeeked:     getPeeked(br),\n\t\tprotos:     protos,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (c *httpConv) ServerRequest(server string, req *http.Request) []attribute.KeyValue {\n\t// TODO: This currently does not add the specification required\n\t// `http.target` attribute. It has too high of a cardinality to safely be\n\t// added. An alternate should be added, or this comment removed, when it is\n\t// addressed by the specification. If it is ultimately decided to continue\n\t// not including the attribute, the HTTPTargetKey field of the httpConv\n\t// should be removed as well.\n\n\tn := 4 // Method, scheme, proto, and host name.\n\tvar host string\n\tvar p int\n\tif server == \"\" {\n\t\thost, p = splitHostPort(req.Host)\n\t} else {\n\t\t// Prioritize the primary server name.\n\t\thost, p = splitHostPort(server)\n\t\tif p < 0 {\n\t\t\t_, p = splitHostPort(req.Host)\n\t\t}\n\t}\n\thostPort := requiredHTTPPort(req.TLS != nil, p)\n\tif hostPort > 0 {\n\t\tn++\n\t}\n\tpeer, peerPort := splitHostPort(req.RemoteAddr)\n\tif peer != \"\" {\n\t\tn++\n\t\tif peerPort > 0 {\n\t\t\tn++\n\t\t}\n\t}\n\tuseragent := req.UserAgent()\n\tif useragent != \"\" {\n\t\tn++\n\t}\n\tuserID, _, hasUserID := req.BasicAuth()\n\tif hasUserID {\n\t\tn++\n\t}\n\tclientIP := serverClientIP(req.Header.Get(\"X-Forwarded-For\"))\n\tif clientIP != \"\" {\n\t\tn++\n\t}\n\tattrs := make([]attribute.KeyValue, 0, n)\n\n\tattrs = append(attrs, c.method(req.Method))\n\tattrs = append(attrs, c.scheme(req.TLS != nil))\n\tattrs = append(attrs, c.proto(req.Proto))\n\tattrs = append(attrs, c.NetConv.HostName(host))\n\n\tif hostPort > 0 {\n\t\tattrs = append(attrs, c.NetConv.HostPort(hostPort))\n\t}\n\n\tif peer != \"\" {\n\t\t// The Go HTTP server sets RemoteAddr to \"IP:port\", this will not be a\n\t\t// file-path that would be interpreted with a sock family.\n\t\tattrs = append(attrs, c.NetConv.SockPeerAddr(peer))\n\t\tif peerPort > 0 {\n\t\t\tattrs = append(attrs, c.NetConv.SockPeerPort(peerPort))\n\t\t}\n\t}\n\n\tif useragent != \"\" {\n\t\tattrs = append(attrs, c.HTTPUserAgentKey.String(useragent))\n\t}\n\n\tif hasUserID {\n\t\tattrs = append(attrs, c.EnduserIDKey.String(userID))\n\t}\n\n\tif clientIP != \"\" {\n\t\tattrs = append(attrs, c.HTTPClientIPKey.String(clientIP))\n\t}\n\n\treturn attrs\n}", "is_vulnerable": 1}
{"code": "func InClusterConfig() (*Config, error) {\n\tconst (\n\t\ttokenFile  = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n\t\trootCAFile = \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n\t)\n\thost, port := os.Getenv(\"KUBERNETES_SERVICE_HOST\"), os.Getenv(\"KUBERNETES_SERVICE_PORT\")\n\tif len(host) == 0 || len(port) == 0 {\n\t\treturn nil, ErrNotInCluster\n\t}\n\n\ttoken, err := ioutil.ReadFile(tokenFile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttlsClientConfig := TLSClientConfig{}\n\n\tif _, err := certutil.NewPool(rootCAFile); err != nil {\n\t\tklog.Errorf(\"Expected to load root CA config from %s, but got err: %v\", rootCAFile, err)\n\t} else {\n\t\ttlsClientConfig.CAFile = rootCAFile\n\t}\n\n\treturn &Config{\n\t\t// TODO: switch to using cluster DNS.\n\t\tHost:            \"https://\" + net.JoinHostPort(host, port),\n\t\tTLSClientConfig: tlsClientConfig,\n\t\tBearerToken:     string(token),\n\t\tBearerTokenFile: tokenFile,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (devAddReq DeviceAddRequest) Validate() error {\n\treturn validation.ValidateStruct(&devAddReq,\n\t\tvalidation.Field(&devAddReq.Device, validation.Required),\n\t\tvalidation.Field(&devAddReq.NodeId, validation.Required, validation.By(ValidateUUID)),\n\t)\n}", "is_vulnerable": 0}
{"code": "func (m *Uint128Pair) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Uint128Pair: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Uint128Pair: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Left\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Left.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Right\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.Right = &v\n\t\t\tif err := m.Right.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestProviderOnMiddlewares(t *testing.T) {\n\tentryPoints := []string{\"web\"}\n\n\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\tServices: map[string]*dynamic.Service{\n\t\t\t\t\"test@file\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRouters: map[string]*dynamic.Router{\n\t\t\t\t\"router@file\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tRule:        \"Host(`test`)\",\n\t\t\t\t\tService:     \"test@file\",\n\t\t\t\t\tMiddlewares: []string{\"chain@file\", \"m1\"},\n\t\t\t\t},\n\t\t\t\t\"router@docker\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tRule:        \"Host(`test`)\",\n\t\t\t\t\tService:     \"test@file\",\n\t\t\t\t\tMiddlewares: []string{\"chain\", \"m1@file\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tMiddlewares: map[string]*dynamic.Middleware{\n\t\t\t\t\"chain@file\": {\n\t\t\t\t\tChain: &dynamic.Chain{Middlewares: []string{\"m1\", \"m2\", \"m1@file\"}},\n\t\t\t\t},\n\t\t\t\t\"chain@docker\": {\n\t\t\t\t\tChain: &dynamic.Chain{Middlewares: []string{\"m1\", \"m2\", \"m1@file\"}},\n\t\t\t\t},\n\t\t\t\t\"m1@file\":   {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m1\"}},\n\t\t\t\t\"m2@file\":   {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m2\"}},\n\t\t\t\t\"m1@docker\": {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m1\"}},\n\t\t\t\t\"m2@docker\": {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m2\"}},\n\t\t\t},\n\t\t},\n\t})\n\n\troundTripperManager := service.NewRoundTripperManager()\n\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\ttlsManager := tls.NewManager()\n\n\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry(), tlsManager)\n\n\t_ = routerManager.BuildHandlers(context.Background(), entryPoints, false)\n\n\tassert.Equal(t, []string{\"chain@file\", \"m1@file\"}, rtConf.Routers[\"router@file\"].Middlewares)\n\tassert.Equal(t, []string{\"m1@file\", \"m2@file\", \"m1@file\"}, rtConf.Middlewares[\"chain@file\"].Chain.Middlewares)\n\tassert.Equal(t, []string{\"chain@docker\", \"m1@file\"}, rtConf.Routers[\"router@docker\"].Middlewares)\n\tassert.Equal(t, []string{\"m1@docker\", \"m2@docker\", \"m1@file\"}, rtConf.Middlewares[\"chain@docker\"].Chain.Middlewares)\n}", "is_vulnerable": 0}
{"code": "\tapi.UserAPILoginOauth2AuthHandler = user_api.LoginOauth2AuthHandlerFunc(func(params user_api.LoginOauth2AuthParams) middleware.Responder {\n\t\tloginResponse, err := getLoginOauth2AuthResponse(params.Body)\n\t\tif err != nil {\n\t\t\treturn user_api.NewLoginOauth2AuthDefault(int(err.Code)).WithPayload(err)\n\t\t}\n\t\t// Custom response writer to set the session cookies\n\t\treturn middleware.ResponderFunc(func(w http.ResponseWriter, p runtime.Producer) {\n\t\t\tcookie := NewSessionCookieForConsole(loginResponse.SessionID)\n\t\t\thttp.SetCookie(w, &cookie)\n\t\t\tuser_api.NewLoginOauth2AuthNoContent().WriteResponse(w, p)\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func DirExistsf(t TestingT, path string, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.DirExistsf(t, path, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func TestMarshalJSONPeerState(t *testing.T) {\n\tps := NewPeerState(nil)\n\tdata, err := json.Marshal(ps)\n\trequire.NoError(t, err)\n\trequire.JSONEq(t, `{\n\t\t\"round_state\":{\n\t\t\t\"height\": \"0\",\n\t\t\t\"round\": -1,\n\t\t\t\"step\": 0,\n\t\t\t\"start_time\": \"0001-01-01T00:00:00Z\",\n\t\t\t\"proposal\": false,\n\t\t\t\"proposal_block_part_set_header\":\n\t\t\t\t{\"total\":0, \"hash\":\"\"},\n\t\t\t\"proposal_block_parts\": null,\n\t\t\t\"proposal_pol_round\": -1,\n\t\t\t\"proposal_pol\": null,\n\t\t\t\"prevotes\": null,\n\t\t\t\"precommits\": null,\n\t\t\t\"last_commit_round\": -1,\n\t\t\t\"last_commit\": null,\n\t\t\t\"catchup_commit_round\": -1,\n\t\t\t\"catchup_commit\": null\n\t\t},\n\t\t\"stats\":{\n\t\t\t\"votes\":\"0\",\n\t\t\t\"block_parts\":\"0\"}\n\t\t}`, string(data))\n}", "is_vulnerable": 0}
{"code": "func NewPublicKey(key interface{}) (PublicKey, error) {\n\tswitch key := key.(type) {\n\tcase *rsa.PublicKey:\n\t\treturn (*rsaPublicKey)(key), nil\n\tcase *ecdsa.PublicKey:\n\t\tif !supportedEllipticCurve(key.Curve) {\n\t\t\treturn nil, errors.New(\"ssh: only P-256, P-384 and P-521 EC keys are supported\")\n\t\t}\n\t\treturn (*ecdsaPublicKey)(key), nil\n\tcase *dsa.PublicKey:\n\t\treturn (*dsaPublicKey)(key), nil\n\tcase ed25519.PublicKey:\n\t\tif l := len(key); l != ed25519.PublicKeySize {\n\t\t\treturn nil, fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\n\t\t}\n\t\treturn ed25519PublicKey(key), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"ssh: unsupported key type %T\", key)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessTokenStrategy) GenerateAccessToken(arg0 context.Context, arg1 fosite.Requester) (string, string, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GenerateAccessToken\", arg0, arg1)\n\tret0, _ := ret[0].(string)\n\tret1, _ := ret[1].(string)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "is_vulnerable": 0}
{"code": "func sendTestRequest(url, cssURL, jssURL, apiUIVersion string) (string, error) {\n\tresp := httptest.NewRecorder()\n\treq := httptest.NewRequest(http.MethodGet, url, nil)\n\t// These header values are needed to get an HTML return document\n\treq.Header.Set(\"Accept\", \"*/*\")\n\treq.Header.Set(\"User-agent\", \"Mozilla\")\n\tsrv := api.NewAPIServer()\n\tsrv.CustomAPIUIResponseWriter(stringGetter(cssURL), stringGetter(jssURL), stringGetter(apiUIVersion))\n\terr := srv.AddSchemas(builtin.Schemas)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to add builtin schemas: %w\", err)\n\t}\n\tsrv.ServeHTTP(resp, req)\n\treturn resp.Body.String(), nil\n}", "is_vulnerable": 0}
{"code": "func TestUsersPost(t *testing.T) {\n\n\tfmt.Println(\"Testing User Add\")\n\n\tassert := assert.New(t)\n\tapiTest := newHarborAPI()\n\tconfig.Upload(map[string]interface{}{\n\t\tcommon.AUTHMode: \"db_auth\",\n\t})\n\t// case 1: register a new user without admin auth, expect 400, because self registration is on\n\tt.Log(\"case 1: Register user without admin auth\")\n\tcode, err := apiTest.UsersPost(testUser0002)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a test User\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 1: Add user status should be 400\")\n\t}\n\n\t// case 2: register a new user with admin auth, but username is empty, expect 400\n\tt.Log(\"case 2: Register user with admin auth, but username is empty\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 2: Add user status should be 400\")\n\t}\n\n\t// case 3: register a new user with admin auth, but bad username format, expect 400\n\ttestUser0002.Username = \"test@$\"\n\tt.Log(\"case 3: Register user with admin auth, but bad username format\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 3: Add user status should be 400\")\n\t}\n\n\t// case 4: register a new user with admin auth, but bad userpassword format, expect 400\n\ttestUser0002.Username = \"testUser0002\"\n\tt.Log(\"case 4: Register user with admin auth, but empty password.\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 4: Add user status should be 400\")\n\t}\n\n\t// case 5: register a new user with admin auth, but email is empty, expect 400\n\ttestUser0002.Password = \"testUser0002\"\n\tt.Log(\"case 5: Register user with admin auth, but email is empty\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 5: Add user status should be 400\")\n\t}\n\n\t// case 6: register a new user with admin auth, but bad email format, expect 400\n\ttestUser0002.Email = \"test...\"\n\tt.Log(\"case 6: Register user with admin auth, but bad email format\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 6: Add user status should be 400\")\n\t}\n\n\t// case 7: register a new user with admin auth, but userrealname is empty, expect 400\n\t/*\n\t\ttestUser0002.Email = \"testUser0002@mydomain.com\"\n\t\tfmt.Println(\"Register user with admin auth, but user realname is empty\")\n\t\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\t\tif err != nil {\n\t\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\t\tt.Log(err)\n\t\t} else {\n\t\t\tassert.Equal(400, code, \"Add user status should be 400\")\n\t\t}\n\t*/\n\t// case 8: register a new user with admin auth, but bad userrealname format, expect 400\n\ttestUser0002.Email = \"testUser0002@mydomain.com\"\n\ttestUser0002.Realname = \"test$com\"\n\tt.Log(\"case 8: Register user with admin auth, but bad user realname format\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\n\t} else {\n\t\tassert.Equal(400, code, \"case 8: Add user status should be 400\")\n\t}\n\n\t// case 9: register a new user with admin auth, but bad user comment, expect 400\n\ttestUser0002.Realname = \"testUser0002\"\n\ttestUser0002.Comment = \"vmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\"\n\tt.Log(\"case 9: Register user with admin auth, but user comment length is illegal\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(400, code, \"case 9: Add user status should be 400\")\n\t}\n\ttestUser0002.Comment = \"test user\"\n\n\t// case 10: register an admin using non-admin user, expect 403\n\tt.Log(\"case 10: Register admin user with non admin auth\")\n\ttestUser0002.HasAdminRole = true\n\tcode, err = apiTest.UsersPost(testUser0002)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(http.StatusForbidden, code, \"case 10: Add user status should be 403\")\n\t}\n\ttestUser0002.HasAdminRole = false\n\n\t// case 11: register a new user with admin auth, expect 201\n\tt.Log(\"case 11: Register user with admin auth, right parameters\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(201, code, \"case 11: Add user status should be 201\")\n\t}\n\n\t// case 12: register duplicate user with admin auth, expect 409\n\tt.Log(\"case 12: Register duplicate user with admin auth\")\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(409, code, \"case 12: Add user status should be 409\")\n\t}\n\n\t// case 13: register a new user with admin auth, but duplicate email, expect 409\n\tt.Log(\"case 13: Register user with admin auth, but duplicate email\")\n\ttestUser0002.Username = \"testUsertest\"\n\ttestUser0002.Email = \"testUser0002@mydomain.com\"\n\tcode, err = apiTest.UsersPost(testUser0002, *admin)\n\tif err != nil {\n\t\tt.Error(\"Error occurred while add a user\", err.Error())\n\t\tt.Log(err)\n\t} else {\n\t\tassert.Equal(409, code, \"case 13: Add user status should be 409\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) loadSyncStatus() {\n\tvar progress SyncProgress\n\n\tif status := rawdb.ReadSnapshotSyncStatus(s.db); status != nil {\n\t\tif err := json.Unmarshal(status, &progress); err != nil {\n\t\t\tlog.Error(\"Failed to decode snap sync status\", \"err\", err)\n\t\t} else {\n\t\t\tfor _, task := range progress.Tasks {\n\t\t\t\tlog.Debug(\"Scheduled account sync task\", \"from\", task.Next, \"last\", task.Last)\n\t\t\t}\n\t\t\ts.tasks = progress.Tasks\n\t\t\tfor _, task := range s.tasks {\n\t\t\t\ttask := task // closure for task.genBatch in the stacktrie writer callback\n\n\t\t\t\ttask.genBatch = ethdb.HookedBatch{\n\t\t\t\t\tBatch: s.db.NewBatch(),\n\t\t\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\t\t\ts.accountBytes += common.StorageSize(len(key) + len(value))\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\toptions := trie.NewStackTrieOptions()\n\t\t\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\t\t\trawdb.WriteTrieNode(task.genBatch, common.Hash{}, path, hash, blob, s.scheme)\n\t\t\t\t})\n\t\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\t\t\ts.cleanPath(task.genBatch, common.Hash{}, path)\n\t\t\t\t\t})\n\t\t\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\t\t\toptions = options.WithSkipBoundary(task.Next != (common.Hash{}), task.Last != common.MaxHash, boundaryAccountNodesGauge)\n\t\t\t\t}\n\t\t\t\ttask.genTrie = trie.NewStackTrie(options)\n\t\t\t\tfor accountHash, subtasks := range task.SubTasks {\n\t\t\t\t\tfor _, subtask := range subtasks {\n\t\t\t\t\t\tsubtask := subtask // closure for subtask.genBatch in the stacktrie writer callback\n\n\t\t\t\t\t\tsubtask.genBatch = ethdb.HookedBatch{\n\t\t\t\t\t\t\tBatch: s.db.NewBatch(),\n\t\t\t\t\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\t\t\t\t\ts.storageBytes += common.StorageSize(len(key) + len(value))\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}\n\t\t\t\t\t\towner := accountHash // local assignment for stacktrie writer closure\n\t\t\t\t\t\toptions := trie.NewStackTrieOptions()\n\t\t\t\t\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\t\t\t\t\trawdb.WriteTrieNode(subtask.genBatch, owner, path, hash, blob, s.scheme)\n\t\t\t\t\t\t})\n\t\t\t\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t\t\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t\t\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\t\t\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\t\t\t\t\ts.cleanPath(subtask.genBatch, owner, path)\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t\t\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\t\t\t\t\toptions = options.WithSkipBoundary(subtask.Next != common.Hash{}, subtask.Last != common.MaxHash, boundaryStorageNodesGauge)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsubtask.genTrie = trie.NewStackTrie(options)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.lock.Lock()\n\t\t\tdefer s.lock.Unlock()\n\n\t\t\ts.snapped = len(s.tasks) == 0\n\n\t\t\ts.accountSynced = progress.AccountSynced\n\t\t\ts.accountBytes = progress.AccountBytes\n\t\t\ts.bytecodeSynced = progress.BytecodeSynced\n\t\t\ts.bytecodeBytes = progress.BytecodeBytes\n\t\t\ts.storageSynced = progress.StorageSynced\n\t\t\ts.storageBytes = progress.StorageBytes\n\n\t\t\ts.trienodeHealSynced = progress.TrienodeHealSynced\n\t\t\ts.trienodeHealBytes = progress.TrienodeHealBytes\n\t\t\ts.bytecodeHealSynced = progress.BytecodeHealSynced\n\t\t\ts.bytecodeHealBytes = progress.BytecodeHealBytes\n\t\t\treturn\n\t\t}\n\t}\n\t// Either we've failed to decode the previous state, or there was none.\n\t// Start a fresh sync by chunking up the account range and scheduling\n\t// them for retrieval.\n\ts.tasks = nil\n\ts.accountSynced, s.accountBytes = 0, 0\n\ts.bytecodeSynced, s.bytecodeBytes = 0, 0\n\ts.storageSynced, s.storageBytes = 0, 0\n\ts.trienodeHealSynced, s.trienodeHealBytes = 0, 0\n\ts.bytecodeHealSynced, s.bytecodeHealBytes = 0, 0\n\n\tvar next common.Hash\n\tstep := new(big.Int).Sub(\n\t\tnew(big.Int).Div(\n\t\t\tnew(big.Int).Exp(common.Big2, common.Big256, nil),\n\t\t\tbig.NewInt(int64(accountConcurrency)),\n\t\t), common.Big1,\n\t)\n\tfor i := 0; i < accountConcurrency; i++ {\n\t\tlast := common.BigToHash(new(big.Int).Add(next.Big(), step))\n\t\tif i == accountConcurrency-1 {\n\t\t\t// Make sure we don't overflow if the step is not a proper divisor\n\t\t\tlast = common.MaxHash\n\t\t}\n\t\tbatch := ethdb.HookedBatch{\n\t\t\tBatch: s.db.NewBatch(),\n\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\ts.accountBytes += common.StorageSize(len(key) + len(value))\n\t\t\t},\n\t\t}\n\t\toptions := trie.NewStackTrieOptions()\n\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\trawdb.WriteTrieNode(batch, common.Hash{}, path, hash, blob, s.scheme)\n\t\t})\n\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\ts.cleanPath(batch, common.Hash{}, path)\n\t\t\t})\n\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\toptions = options.WithSkipBoundary(next != common.Hash{}, last != common.MaxHash, boundaryAccountNodesGauge)\n\t\t}\n\t\ts.tasks = append(s.tasks, &accountTask{\n\t\t\tNext:     next,\n\t\t\tLast:     last,\n\t\t\tSubTasks: make(map[common.Hash][]*storageTask),\n\t\t\tgenBatch: batch,\n\t\t\tgenTrie:  trie.NewStackTrie(options),\n\t\t})\n\t\tlog.Debug(\"Created account sync task\", \"from\", next, \"last\", last)\n\t\tnext = common.BigToHash(new(big.Int).Add(last.Big(), common.Big1))\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestMqttAdaptorConnectWithAuthError(t *testing.T) {\n\ta := NewAdaptorWithAuth(\"xyz://localhost:1883\", \"client\", \"user\", \"pass\")\n\tvar expected error\n\texpected = multierror.Append(expected, errors.New(\"Network Error : Unknown protocol\"))\n\n\tgobottest.Assert(t, a.Connect(), expected)\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetProtocol(p Protocol) error {\n\terr := handleError(C.gpgme_set_protocol(c.ctx, C.gpgme_protocol_t(p)))\n\truntime.KeepAlive(c)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func downloadToFileWithPostProcess(client *http.Client, url, file string, postProcess postProcessFunc) error {\n\tresp, err := client.Get(url)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn fmt.Errorf(\"bad status: %s\", resp.Status)\n\t}\n\n\tb, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tb, err = postProcess(b)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(file, b, 0644)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) GetBeaconTasks(ctx context.Context, in *clientpb.Beacon, opts ...grpc.CallOption) (*clientpb.BeaconTasks, error) {\n\tout := new(clientpb.BeaconTasks)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetBeaconTasks\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func Test_CORS_Wildcard(t *testing.T) {\n\tt.Parallel()\n\t// New fiber instance\n\tapp := fiber.New()\n\t// OPTIONS (preflight) response headers when AllowOrigins is *\n\tapp.Use(New(Config{\n\t\tAllowOrigins:     \"*\",\n\t\tAllowCredentials: true,\n\t\tMaxAge:           3600,\n\t\tExposeHeaders:    \"X-Request-ID\",\n\t\tAllowHeaders:     \"Authentication\",\n\t}))\n\t// Get handler pointer\n\thandler := app.Handler()\n\n\t// Make request\n\tctx := &fasthttp.RequestCtx{}\n\tctx.Request.SetRequestURI(\"/\")\n\tctx.Request.Header.Set(fiber.HeaderOrigin, \"localhost\")\n\tctx.Request.Header.SetMethod(fiber.MethodOptions)\n\n\t// Perform request\n\thandler(ctx)\n\n\t// Check result\n\tutils.AssertEqual(t, \"*\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\tutils.AssertEqual(t, \"true\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowCredentials)))\n\tutils.AssertEqual(t, \"3600\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlMaxAge)))\n\tutils.AssertEqual(t, \"Authentication\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowHeaders)))\n\n\t// Test non OPTIONS (preflight) response headers\n\tctx = &fasthttp.RequestCtx{}\n\tctx.Request.Header.SetMethod(fiber.MethodGet)\n\thandler(ctx)\n\n\tutils.AssertEqual(t, \"true\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowCredentials)))\n\tutils.AssertEqual(t, \"X-Request-ID\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlExposeHeaders)))\n}", "is_vulnerable": 1}
{"code": "func loadIndex(data []byte) (*IndexFile, error) {\n\ti := &IndexFile{}\n\tif err := yaml.Unmarshal(data, i); err != nil {\n\t\treturn i, err\n\t}\n\ti.SortEntries()\n\tif i.APIVersion == \"\" {\n\t\treturn i, ErrNoAPIVersion\n\t}\n\treturn i, nil\n}", "is_vulnerable": 1}
{"code": "func (s *TestSuiteIAM) TestUserPolicyEscalationBug(c *check) {\n\tctx, cancel := context.WithTimeout(context.Background(), testDefaultTimeout)\n\tdefer cancel()\n\n\tbucket := getRandomBucketName()\n\terr := s.client.MakeBucket(ctx, bucket, minio.MakeBucketOptions{})\n\tif err != nil {\n\t\tc.Fatalf(\"bucket creat error: %v\", err)\n\t}\n\n\t// 2. Create a user, associate policy and verify access\n\taccessKey, secretKey := mustGenerateCredentials(c)\n\terr = s.adm.SetUser(ctx, accessKey, secretKey, madmin.AccountEnabled)\n\tif err != nil {\n\t\tc.Fatalf(\"Unable to set user: %v\", err)\n\t}\n\t// 2.1 check that user does not have any access to the bucket\n\tuClient := s.getUserClient(c, accessKey, secretKey, \"\")\n\tc.mustNotListObjects(ctx, uClient, bucket)\n\n\t// 2.2 create and associate policy to user\n\tpolicy := \"mypolicy-test-user-update\"\n\tpolicyBytes := []byte(fmt.Sprintf(`{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n  {\n   \"Effect\": \"Allow\",\n   \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:ListBucket\"\n   ],\n   \"Resource\": [\n    \"arn:aws:s3:::%s/*\"\n   ]\n  }\n ]\n}`, bucket))\n\terr = s.adm.AddCannedPolicy(ctx, policy, policyBytes)\n\tif err != nil {\n\t\tc.Fatalf(\"policy add error: %v\", err)\n\t}\n\terr = s.adm.SetPolicy(ctx, policy, accessKey, false)\n\tif err != nil {\n\t\tc.Fatalf(\"Unable to set policy: %v\", err)\n\t}\n\t// 2.3 check user has access to bucket\n\tc.mustListObjects(ctx, uClient, bucket)\n\t// 2.3 check that user cannot delete the bucket\n\terr = uClient.RemoveBucket(ctx, bucket)\n\tif err == nil || err.Error() != \"Access Denied.\" {\n\t\tc.Fatalf(\"bucket was deleted unexpectedly or got unexpected err: %v\", err)\n\t}\n\n\t// 3. Craft a request to update the user's permissions\n\tep := s.adm.GetEndpointURL()\n\turlValue := url.Values{}\n\turlValue.Add(\"accessKey\", accessKey)\n\tu, err := url.Parse(fmt.Sprintf(\"%s://%s/minio/admin/v3/add-user?%s\", ep.Scheme, ep.Host, s3utils.QueryEncode(urlValue)))\n\tif err != nil {\n\t\tc.Fatalf(\"unexpected url parse err: %v\", err)\n\t}\n\treq, err := http.NewRequestWithContext(ctx, http.MethodPut, u.String(), nil)\n\tif err != nil {\n\t\tc.Fatalf(\"unexpected new request err: %v\", err)\n\t}\n\treqBodyArg := madmin.UserInfo{\n\t\tSecretKey:  secretKey,\n\t\tPolicyName: \"consoleAdmin\",\n\t\tStatus:     madmin.AccountEnabled,\n\t}\n\tbuf, err := json.Marshal(reqBodyArg)\n\tif err != nil {\n\t\tc.Fatalf(\"unexpected json encode err: %v\", err)\n\t}\n\tbuf, err = madmin.EncryptData(secretKey, buf)\n\tif err != nil {\n\t\tc.Fatalf(\"unexpected encryption err: %v\", err)\n\t}\n\n\treq.ContentLength = int64(len(buf))\n\tsum := sha256.Sum256(buf)\n\treq.Header.Set(\"X-Amz-Content-Sha256\", hex.EncodeToString(sum[:]))\n\treq.Body = ioutil.NopCloser(bytes.NewReader(buf))\n\treq = signer.SignV4(*req, accessKey, secretKey, \"\", \"\")\n\n\t// 3.1 Execute the request.\n\tresp, err := s.TestSuiteCommon.client.Do(req)\n\tif err != nil {\n\t\tc.Fatalf(\"unexpected request err: %v\", err)\n\t}\n\tif resp.StatusCode != 200 {\n\t\tc.Fatalf(\"got unexpected response: %#v\\n\", resp)\n\t}\n\n\t// 3.2 check that user cannot delete the bucket\n\terr = uClient.RemoveBucket(ctx, bucket)\n\tif err == nil || err.Error() != \"Access Denied.\" {\n\t\tc.Fatalf(\"User was able to escalate privileges (Err=%v)!\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestClean(t *testing.T) {\n\ttests := []struct {\n\t\tinput   string\n\t\tcleaned string\n\t}{\n\t\t{\n\t\t\t\"../../../tmp/foo\",\n\t\t\t\"/tmp/foo\",\n\t\t},\n\t\t{\n\t\t\t\"/../../../tmp/foo\",\n\t\t\t\"/tmp/foo\",\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tout := clean(test.input)\n\t\tif out != test.cleaned {\n\t\t\tt.Errorf(\"Expected: %s, saw %s\", test.cleaned, out)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewGitReader(gitArtifact *v1alpha1.GitArtifact) (*GitArtifactReader, error) {\n\tif gitArtifact == nil {\n\t\treturn nil, fmt.Errorf(\"nil git artifact\")\n\t}\n\tfor _, na := range notAllowedInPath {\n\t\tif strings.Contains(gitArtifact.FilePath, na) {\n\t\t\treturn nil, fmt.Errorf(\"%q is not allowed in the filepath\", na)\n\t\t}\n\t}\n\n\treturn &GitArtifactReader{\n\t\tartifact: gitArtifact,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn satisfy{\n\t\tr:                r,\n\t\tannotationConfig: satisfyAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func verifyRekorBundle(ctx context.Context, bundlePath string, rekorClient *client.Rekor,\n\tblobBytes []byte, sig string, pubKeyBytes []byte) (*bundle.RekorPayload, error) {\n\tb, err := cosign.FetchLocalSignedPayloadFromPath(bundlePath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif b.Bundle == nil {\n\t\treturn nil, fmt.Errorf(\"rekor entry could not be extracted from local bundle\")\n\t}\n\n\tif err := verifyBundleMatchesData(ctx, b.Bundle, blobBytes, pubKeyBytes, []byte(sig)); err != nil {\n\t\treturn nil, err\n\t}\n\n\tpublicKeys, err := cosign.GetRekorPubs(ctx, rekorClient)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"retrieving rekor public key: %w\", err)\n\t}\n\n\tpubKey, ok := publicKeys[b.Bundle.Payload.LogID]\n\tif !ok {\n\t\treturn nil, errors.New(\"rekor log public key not found for payload\")\n\t}\n\terr = cosign.VerifySET(b.Bundle.Payload, b.Bundle.SignedEntryTimestamp, pubKey.PubKey)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif pubKey.Status != tuf.Active {\n\t\tfmt.Fprintf(os.Stderr, \"**Info** Successfully verified Rekor entry using an expired verification key\\n\")\n\t}\n\n\treturn &b.Bundle.Payload, nil\n}", "is_vulnerable": 0}
{"code": "func (err *ContextError) Error() string {\n\tif len(err.Errors) > 0 {\n\t\treturn err.Errors[0].Text\n\t}\n\treturn \"Context creation failed\"\n}", "is_vulnerable": 0}
{"code": "func (t *TableController) InitTable(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tcode := utils.SanitizeInput(ctx.Param(\"code\"))\n\terr := t.sysTableService.InitTable(ctx, code)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (m *Mock) MethodCalled(methodName string, arguments ...interface{}) Arguments {\n\tm.mutex.Lock()\n\t//TODO: could combine expected and closes in single loop\n\tfound, call := m.findExpectedCall(methodName, arguments...)\n\n\tif found < 0 {\n\t\t// expected call found but it has already been called with repeatable times\n\t\tif call != nil {\n\t\t\tm.mutex.Unlock()\n\t\t\tm.fail(\"\\nassert: mock: The method has been called over %d times.\\n\\tEither do one more Mock.On(\\\"%s\\\").Return(...), or remove extra call.\\n\\tThis call was unexpected:\\n\\t\\t%s\\n\\tat: %s\", call.totalCalls, methodName, callString(methodName, arguments, true), assert.CallerInfo())\n\t\t}\n\t\t// we have to fail here - because we don't know what to do\n\t\t// as the return arguments.  This is because:\n\t\t//\n\t\t//   a) this is a totally unexpected call to this method,\n\t\t//   b) the arguments are not what was expected, or\n\t\t//   c) the developer has forgotten to add an accompanying On...Return pair.\n\t\tclosestCall, mismatch := m.findClosestCall(methodName, arguments...)\n\t\tm.mutex.Unlock()\n\n\t\tif closestCall != nil {\n\t\t\tm.fail(\"\\n\\nmock: Unexpected Method Call\\n-----------------------------\\n\\n%s\\n\\nThe closest call I have is: \\n\\n%s\\n\\n%s\\nDiff: %s\",\n\t\t\t\tcallString(methodName, arguments, true),\n\t\t\t\tcallString(methodName, closestCall.Arguments, true),\n\t\t\t\tdiffArguments(closestCall.Arguments, arguments),\n\t\t\t\tstrings.TrimSpace(mismatch),\n\t\t\t)\n\t\t} else {\n\t\t\tm.fail(\"\\nassert: mock: I don't know what to return because the method call was unexpected.\\n\\tEither do Mock.On(\\\"%s\\\").Return(...) first, or remove the %s() call.\\n\\tThis method was unexpected:\\n\\t\\t%s\\n\\tat: %s\", methodName, methodName, callString(methodName, arguments, true), assert.CallerInfo())\n\t\t}\n\t}\n\n\tif call.Repeatability == 1 {\n\t\tcall.Repeatability = -1\n\t} else if call.Repeatability > 1 {\n\t\tcall.Repeatability--\n\t}\n\tcall.totalCalls++\n\n\t// add the call\n\tm.Calls = append(m.Calls, *newCall(m, methodName, assert.CallerInfo(), arguments...))\n\tm.mutex.Unlock()\n\n\t// block if specified\n\tif call.WaitFor != nil {\n\t\t<-call.WaitFor\n\t} else {\n\t\ttime.Sleep(call.waitTime)\n\t}\n\n\tm.mutex.Lock()\n\trunFn := call.RunFn\n\tm.mutex.Unlock()\n\n\tif runFn != nil {\n\t\trunFn(arguments)\n\t}\n\n\tm.mutex.Lock()\n\treturnArgs := call.ReturnArguments\n\tm.mutex.Unlock()\n\n\treturn returnArgs\n}", "is_vulnerable": 0}
{"code": "func SettingsEmailPost(c *context.Context, f form.AddEmail) {\n\tc.Title(\"settings.emails\")\n\tc.PageIs(\"SettingsEmails\")\n\n\t// Make emailaddress primary.\n\tif c.Query(\"_method\") == \"PRIMARY\" {\n\t\tif err := db.MakeEmailPrimary(&db.EmailAddress{ID: c.QueryInt64(\"id\")}); err != nil {\n\t\t\tc.ServerError(\"MakeEmailPrimary\", err)\n\t\t\treturn\n\t\t}\n\n\t\tc.SubURLRedirect(\"/user/settings/email\")\n\t\treturn\n\t}\n\n\t// Add Email address.\n\temails, err := db.GetEmailAddresses(c.User.ID)\n\tif err != nil {\n\t\tc.ServerError(\"GetEmailAddresses\", err)\n\t\treturn\n\t}\n\tc.Data[\"Emails\"] = emails\n\n\tif c.HasError() {\n\t\tc.Success(SETTINGS_EMAILS)\n\t\treturn\n\t}\n\n\temailAddr := &db.EmailAddress{\n\t\tUID:         c.User.ID,\n\t\tEmail:       f.Email,\n\t\tIsActivated: !conf.Auth.RequireEmailConfirmation,\n\t}\n\tif err := db.AddEmailAddress(emailAddr); err != nil {\n\t\tif db.IsErrEmailAlreadyUsed(err) {\n\t\t\tc.RenderWithErr(c.Tr(\"form.email_been_used\"), SETTINGS_EMAILS, &f)\n\t\t} else {\n\t\t\tc.ServerError(\"AddEmailAddress\", err)\n\t\t}\n\t\treturn\n\t}\n\n\t// Send confirmation email\n\tif conf.Auth.RequireEmailConfirmation {\n\t\temail.SendActivateEmailMail(c.Context, db.NewMailerUser(c.User), emailAddr.Email)\n\n\t\tif err := c.Cache.Put(\"MailResendLimit_\"+c.User.LowerName, c.User.LowerName, 180); err != nil {\n\t\t\tlog.Error(\"Set cache 'MailResendLimit' failed: %v\", err)\n\t\t}\n\t\tc.Flash.Info(c.Tr(\"settings.add_email_confirmation_sent\", emailAddr.Email, conf.Auth.ActivateCodeLives/60))\n\t} else {\n\t\tc.Flash.Success(c.Tr(\"settings.add_email_success\"))\n\t}\n\n\tc.SubURLRedirect(\"/user/settings/email\")\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn connection{\n\t\tr:                r,\n\t\tannotationConfig: connectionHeadersAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAllDocsQuery(t *testing.T) {\n\n\tif base.UnitTestUrlIsWalrus() {\n\t\tt.Skip(\"This test is Couchbase Server only\")\n\t}\n\n\tdb, testBucket := setupTestDBWithCacheOptions(t, CacheOptions{})\n\tdefer testBucket.Close()\n\tdefer tearDownTestDB(t, db)\n\n\t// Add docs with channel assignment\n\tfor i := 1; i <= 10; i++ {\n\t\t_, err := db.Put(fmt.Sprintf(\"allDocsTest%d\", i), Body{\"channels\": []string{\"ABC\"}})\n\t\tassert.NoError(t, err, \"Put allDocsTest doc\")\n\t}\n\n\t// Standard query\n\tstartKey := \"a\"\n\tendKey := \"\"\n\tresults, queryErr := db.QueryAllDocs(startKey, endKey)\n\tassert.NoError(t, queryErr, \"Query error\")\n\tvar row map[string]interface{}\n\trowCount := 0\n\tfor results.Next(&row) {\n\t\trowCount++\n\t}\n\tassert.Equal(t, 10, rowCount)\n\n\t// Attempt to invalidate standard query\n\tstartKey = \"a' AND 1=0\\x00\"\n\tendKey = \"\"\n\tresults, queryErr = db.QueryAllDocs(startKey, endKey)\n\tassert.NoError(t, queryErr, \"Query error\")\n\trowCount = 0\n\tfor results.Next(&row) {\n\t\trowCount++\n\t}\n\tassert.Equal(t, 10, rowCount)\n\n\t// Attempt to invalidate statement to add row to resultset\n\tstartKey = `a' UNION ALL SELECT TOSTRING(BASE64_DECODE(\"SW52YWxpZERhdGE=\")) as id;` + \"\\x00\"\n\tendKey = \"\"\n\tresults, queryErr = db.QueryAllDocs(startKey, endKey)\n\tassert.NoError(t, queryErr, \"Query error\")\n\trowCount = 0\n\tfor results.Next(&row) {\n\t\tassert.NotEqual(t, row[\"id\"], \"InvalidData\")\n\t\trowCount++\n\t}\n\tassert.Equal(t, 10, rowCount)\n\n\t// Attempt to create syntax error\n\tstartKey = `a'1`\n\tendKey = \"\"\n\tresults, queryErr = db.QueryAllDocs(startKey, endKey)\n\tassert.NoError(t, queryErr, \"Query error\")\n\trowCount = 0\n\tfor results.Next(&row) {\n\t\trowCount++\n\t}\n\tassert.Equal(t, 10, rowCount)\n\n}", "is_vulnerable": 0}
{"code": "func (f *ScmpFilter) addRuleWrapper(call ScmpSyscall, action ScmpAction, exact bool, cond C.scmp_cast_t) error {\n\tvar length C.uint\n\tif cond != nil {\n\t\tlength = 1\n\t} else {\n\t\tlength = 0\n\t}\n\n\tvar retCode C.int\n\tif exact {\n\t\tretCode = C.seccomp_rule_add_exact_array(f.filterCtx, action.toNative(), C.int(call), length, cond)\n\t} else {\n\t\tretCode = C.seccomp_rule_add_array(f.filterCtx, action.toNative(), C.int(call), length, cond)\n\t}\n\n\tif syscall.Errno(-1*retCode) == syscall.EFAULT {\n\t\treturn fmt.Errorf(\"unrecognized syscall\")\n\t} else if syscall.Errno(-1*retCode) == syscall.EPERM {\n\t\treturn fmt.Errorf(\"requested action matches default action of filter\")\n\t} else if retCode != 0 {\n\t\treturn syscall.Errno(-1 * retCode)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\textractor := func(c *fiber.Ctx) (string, error) {\n\t\tbody := string(c.Body())\n\t\t// Generate the correct extractor to get the token from the correct location\n\t\tselectors := strings.Split(body, \"=\")\n\n\t\tif len(selectors) != 2 || selectors[1] == \"\" {\n\t\t\treturn \"\", ErrMissingParam\n\t\t}\n\t\treturn selectors[1], nil\n\t}", "is_vulnerable": 0}
{"code": "\tt.Run(\"Given two teams\", func(t *testing.T) {\n\t\ths := setupSimpleHTTPServer(nil)\n\t\ths.SQLStore = sqlstore.InitTestDB(t)\n\t\tmock := &mockstore.SQLStoreMock{}\n\t\ths.Cfg.EditorsCanAdmin = true\n\t\tloggedInUserScenario(t, \"When calling GET on\", \"/api/teams/search\", \"/api/teams/search\", func(sc *scenarioContext) {\n\t\t\t_, err := hs.SQLStore.CreateTeam(\"team1\", \"\", 1)\n\t\t\trequire.NoError(t, err)\n\t\t\t_, err = hs.SQLStore.CreateTeam(\"team2\", \"\", 1)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tsc.handlerFunc = hs.SearchTeams\n\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{}).exec()\n\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\t\t\tvar resp models.SearchTeamQueryResult\n\t\t\terr = json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tassert.EqualValues(t, 2, resp.TotalCount)\n\t\t\tassert.Equal(t, 2, len(resp.Teams))\n\t\t}, mock)\n\n\t\tloggedInUserScenario(t, \"When calling GET on\", \"/api/teams/search\", \"/api/teams/search\", func(sc *scenarioContext) {\n\t\t\t_, err := hs.SQLStore.CreateTeam(\"team1\", \"\", 1)\n\t\t\trequire.NoError(t, err)\n\t\t\t_, err = hs.SQLStore.CreateTeam(\"team2\", \"\", 1)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tsc.handlerFunc = hs.SearchTeams\n\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{\"perpage\": \"10\", \"page\": \"2\"}).exec()\n\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\t\t\tvar resp models.SearchTeamQueryResult\n\t\t\terr = json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tassert.EqualValues(t, 2, resp.TotalCount)\n\t\t\tassert.Equal(t, 0, len(resp.Teams))\n\t\t}, mock)\n\t})", "is_vulnerable": 0}
{"code": "func findID(idStr string, mapping []IDMap, lookupFunc func(uid string) (string, error), overflowFile string) (string, error) {\n\tif len(mapping) == 0 {\n\t\treturn idStr, nil\n\t}\n\n\tid, err := strconv.ParseInt(idStr, 10, 0)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"cannot parse ID: %w\", err)\n\t}\n\tfor _, m := range mapping {\n\t\tif int(id) >= m.ContainerID && int(id) < m.ContainerID+m.Size {\n\t\t\tuser := fmt.Sprintf(\"%d\", m.HostID+(int(id)-m.ContainerID))\n\n\t\t\treturn lookupFunc(user)\n\t\t}\n\t}\n\n\t// User not found, read the overflow\n\toverflow, err := ioutil.ReadFile(overflowFile)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(overflow), nil\n}", "is_vulnerable": 1}
{"code": "func (h http) processBearerToken() (username string, groups []string, err error) {\n\ttr := &authenticationv1.TokenReview{\n\t\tSpec: authenticationv1.TokenReviewSpec{\n\t\t\tToken: h.bearerToken(),\n\t\t},\n\t}\n\n\tif err = h.client.Create(h.Request.Context(), tr); err != nil {\n\t\treturn \"\", nil, fmt.Errorf(\"cannot create TokenReview\")\n\t}\n\n\tif !tr.Status.Authenticated {\n\t\treturn \"\", nil, fmt.Errorf(\"cannot verify the token due to error\")\n\t}\n\n\tif statusErr := tr.Status.Error; len(statusErr) > 0 {\n\t\treturn \"\", nil, fmt.Errorf(\"cannot verify the token due to error\")\n\t}\n\n\treturn tr.Status.User.Username, tr.Status.User.Groups, nil\n}", "is_vulnerable": 0}
{"code": "func TestHostMatchesGlob(t *testing.T) {\n\tglobs := map[string]struct {\n\t\thostname string\n\t\tglob     string\n\t\tmatch    bool\n\t}{\n\t\t\"simple match\": {\n\t\t\t\"example.com\",\n\t\t\t\"example.com\",\n\t\t\ttrue,\n\t\t},\n\t\t\"leading wildcard matches first component\": {\n\t\t\t\"contrived.example.com\",\n\t\t\t\"*.example.com\",\n\t\t\ttrue,\n\t\t},\n\t\t\"leading wildcard matches first two components\": {\n\t\t\t\"more.contrived.example.com\",\n\t\t\t\"*.example.com\",\n\t\t\ttrue,\n\t\t},\n\t\t\"wildcard after leading component\": {\n\t\t\t\"login.eu.example.com\",\n\t\t\t\"login.*.example.com\",\n\t\t\tfalse,\n\t\t},\n\t\t\"trailing dot\": {\n\t\t\t\"example.com.\",\n\t\t\t\"example.com\",\n\t\t\ttrue,\n\t\t},\n\t\t\"uppercase host with lowercase glob\": {\n\t\t\t\"EXAMPLE.COM\",\n\t\t\t\"example.com\",\n\t\t\ttrue,\n\t\t},\n\t\t\"lowercase host with uppercase glob\": {\n\t\t\t\"example.com\",\n\t\t\t\"EXAMPLE.COM\",\n\t\t\ttrue,\n\t\t},\n\t\t\"empty hostname\": {\n\t\t\t\"\",\n\t\t\t\"example.com\",\n\t\t\tfalse,\n\t\t},\n\t}\n\n\ta := assert.New(t)\n\tfor name, g := range globs {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\ta.Equal(\n\t\t\t\tg.match,\n\t\t\t\thostMatchesGlob(g.hostname, g.glob),\n\t\t\t)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func home(w http.ResponseWriter, r *http.Request) {\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"show databases\")\n\tcheckY(err)\n\n\trows, err := statement.Query()\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tvar n int = 1\n\tfor rows.Next() {\n\t\tvar field string\n\t\trows.Scan(&field)\n\t\tfmt.Fprint(w, linkDeeper(\"\", field, \"DB[\"+strconv.Itoa(n)+\"]\"))\n\t\tfmt.Fprintln(w, \" \", field, \"<br>\")\n\t\tn = n + 1\n\t}\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"valid malfeasance proof\", func(t *testing.T) {\n\t\tdb := sql.InMemory()\n\t\tlg := logtest.New(t)\n\t\tctrl := gomock.NewController(t)\n\t\ttrt := malfeasance.NewMocktortoise(ctrl)\n\t\tpostVerifier := malfeasance.NewMockpostVerifier(ctrl)\n\n\t\th := malfeasance.NewHandler(\n\t\t\tdatastore.NewCachedDB(db, lg),\n\t\t\tlg,\n\t\t\t\"self\",\n\t\t\t[]types.NodeID{types.RandomNodeID()},\n\t\t\tsigning.NewEdVerifier(),\n\t\t\ttrt,\n\t\t\tpostVerifier,\n\t\t)\n\n\t\tproof := wire.MalfeasanceProof{\n\t\t\tLayer: types.LayerID(11),\n\t\t\tProof: wire.Proof{\n\t\t\t\tType: wire.InvalidPostIndex,\n\t\t\t\tData: &wire.InvalidPostIndexProof{\n\t\t\t\t\tAtx:        atx,\n\t\t\t\t\tInvalidIdx: 7,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tpostVerifier.EXPECT().Verify(gomock.Any(), gomock.Any(), gomock.Any(), gomock.Any()).\n\t\t\tReturn(errors.New(\"invalid\"))\n\t\ttrt.EXPECT().OnMalfeasance(sig.NodeID())\n\t\terr := h.HandleSyncedMalfeasanceProof(context.Background(), nodeIdH32, \"peer\", codec.MustEncode(&proof))\n\t\trequire.NoError(t, err)\n\n\t\tmalicious, err := identities.IsMalicious(db, sig.NodeID())\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, malicious)\n\t})", "is_vulnerable": 0}
{"code": "func Greaterf(t TestingT, e1 interface{}, e2 interface{}, msg string, args ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn Greater(t, e1, e2, append([]interface{}{msg}, args...)...)\n}", "is_vulnerable": 0}
{"code": "func TestGetDynamic(t *testing.T) {\n\tsavedServices := services\n\tsavedGetVCSDirFn := getVCSDirFn\n\tdefer func() {\n\t\tservices = savedServices\n\t\tgetVCSDirFn = savedGetVCSDirFn\n\t}()\n\tservices = []*service{{pattern: regexp.MustCompile(\".*\"), get: testGet}}\n\tgetVCSDirFn = testGet\n\tclient := &http.Client{Transport: testTransport(testWeb)}\n\n\tfor _, tt := range getDynamicTests {\n\t\tdir, err := getDynamic(context.Background(), client, tt.importPath, \"\")\n\n\t\tif tt.dir == nil {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"getDynamic(client, %q, etag) did not return expected error\", tt.importPath)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif err != nil {\n\t\t\tt.Errorf(\"getDynamic(client, %q, etag) return unexpected error: %v\", tt.importPath, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !cmp.Equal(dir, tt.dir) {\n\t\t\tt.Errorf(\"getDynamic(client, %q, etag) =\\n     %+v,\\nwant %+v\", tt.importPath, dir, tt.dir)\n\t\t\tfor i, f := range dir.Files {\n\t\t\t\tvar want *File\n\t\t\t\tif i < len(tt.dir.Files) {\n\t\t\t\t\twant = tt.dir.Files[i]\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"file %d = %+v, want %+v\", i, f, want)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestFilesystem_Blocks_Symlinks(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\n\tif err := rfs.CreateServerFileFromString(\"/../malicious.txt\", \"external content\"); err != nil {\n\t\tpanic(err)\n\t}\n\n\tif err := os.Mkdir(filepath.Join(rfs.root, \"/malicious_dir\"), 0o777); err != nil {\n\t\tpanic(err)\n\t}\n\n\tif err := os.Symlink(filepath.Join(rfs.root, \"malicious.txt\"), filepath.Join(rfs.root, \"/server/symlinked.txt\")); err != nil {\n\t\tpanic(err)\n\t}\n\n\tif err := os.Symlink(filepath.Join(rfs.root, \"malicious_does_not_exist.txt\"), filepath.Join(rfs.root, \"/server/symlinked_does_not_exist.txt\")); err != nil {\n\t\tpanic(err)\n\t}\n\n\tif err := os.Symlink(filepath.Join(rfs.root, \"/server/symlinked_does_not_exist.txt\"), filepath.Join(rfs.root, \"/server/symlinked_does_not_exist2.txt\")); err != nil {\n\t\tpanic(err)\n\t}\n\n\tif err := os.Symlink(filepath.Join(rfs.root, \"/malicious_dir\"), filepath.Join(rfs.root, \"/server/external_dir\")); err != nil {\n\t\tpanic(err)\n\t}\n\n\tg.Describe(\"Writefile\", func() {\n\t\tg.It(\"cannot write to a file symlinked outside the root\", func() {\n\t\t\tr := bytes.NewReader([]byte(\"testing\"))\n\n\t\t\terr := fs.Writefile(\"symlinked.txt\", r)\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot write to a non-existent file symlinked outside the root\", func() {\n\t\t\tr := bytes.NewReader([]byte(\"testing what the fuck\"))\n\n\t\t\terr := fs.Writefile(\"symlinked_does_not_exist.txt\", r)\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot write to chained symlinks with target that does not exist outside the root\", func() {\n\t\t\tr := bytes.NewReader([]byte(\"testing what the fuck\"))\n\n\t\t\terr := fs.Writefile(\"symlinked_does_not_exist2.txt\", r)\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot write a file to a directory symlinked outside the root\", func() {\n\t\t\tr := bytes.NewReader([]byte(\"testing\"))\n\n\t\t\terr := fs.Writefile(\"external_dir/foo.txt\", r)\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\t})\n\n\tg.Describe(\"CreateDirectory\", func() {\n\t\tg.It(\"cannot create a directory outside the root\", func() {\n\t\t\terr := fs.CreateDirectory(\"my_dir\", \"external_dir\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot create a nested directory outside the root\", func() {\n\t\t\terr := fs.CreateDirectory(\"my/nested/dir\", \"external_dir/foo/bar\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot create a nested directory outside the root\", func() {\n\t\t\terr := fs.CreateDirectory(\"my/nested/dir\", \"external_dir/server\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\t})\n\n\tg.Describe(\"Rename\", func() {\n\t\tg.It(\"cannot rename a file symlinked outside the directory root\", func() {\n\t\t\terr := fs.Rename(\"symlinked.txt\", \"foo.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot rename a symlinked directory outside the root\", func() {\n\t\t\terr := fs.Rename(\"external_dir\", \"foo\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot rename a file to a location outside the directory root\", func() {\n\t\t\trfs.CreateServerFileFromString(\"my_file.txt\", \"internal content\")\n\n\t\t\terr := fs.Rename(\"my_file.txt\", \"external_dir/my_file.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\t})\n\n\tg.Describe(\"Chown\", func() {\n\t\tg.It(\"cannot chown a file symlinked outside the directory root\", func() {\n\t\t\terr := fs.Chown(\"symlinked.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"cannot chown a directory symlinked outside the directory root\", func() {\n\t\t\terr := fs.Chown(\"external_dir\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\t})\n\n\tg.Describe(\"Copy\", func() {\n\t\tg.It(\"cannot copy a file symlinked outside the directory root\", func() {\n\t\t\terr := fs.Copy(\"symlinked.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\t})\n\n\tg.Describe(\"Delete\", func() {\n\t\tg.It(\"deletes the symlinked file but leaves the source\", func() {\n\t\t\terr := fs.Delete(\"symlinked.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t_, err = os.Stat(filepath.Join(rfs.root, \"malicious.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t_, err = rfs.StatServerFile(\"symlinked.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, os.ErrNotExist)).IsTrue()\n\t\t})\n\t})\n\n\trfs.reset()\n}", "is_vulnerable": 1}
{"code": "func (m *Manager) Get(storeName, configName string) (*tls.Config, error) {\n\tm.lock.RLock()\n\tdefer m.lock.RUnlock()\n\n\tvar tlsConfig *tls.Config\n\tvar err error\n\n\tsniStrict := false\n\tconfig, ok := m.configs[configName]\n\tif ok {\n\t\tsniStrict = config.SniStrict\n\t\ttlsConfig, err = buildTLSConfig(config)\n\t} else {\n\t\terr = fmt.Errorf(\"unknown TLS options: %s\", configName)\n\t}\n\tif err != nil {\n\t\ttlsConfig = &tls.Config{}\n\t}\n\n\tstore := m.getStore(storeName)\n\tif store == nil {\n\t\terr = fmt.Errorf(\"TLS store %s not found\", storeName)\n\t}\n\tacmeTLSStore := m.getStore(tlsalpn01.ACMETLS1Protocol)\n\tif acmeTLSStore == nil {\n\t\terr = fmt.Errorf(\"ACME TLS store %s not found\", tlsalpn01.ACMETLS1Protocol)\n\t}\n\n\ttlsConfig.GetCertificate = func(clientHello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n\t\tdomainToCheck := types.CanonicalDomain(clientHello.ServerName)\n\n\t\tif isACMETLS(clientHello) {\n\t\t\tcertificate := acmeTLSStore.GetBestCertificate(clientHello)\n\t\t\tif certificate == nil {\n\t\t\t\tlog.WithoutContext().Debugf(\"TLS: no certificate for TLSALPN challenge: %s\", domainToCheck)\n\t\t\t\t// We want the user to eventually get the (alertUnrecognizedName) \"unrecognized\n\t\t\t\t// name\" error.\n\t\t\t\t// Unfortunately, if we returned an error here, since we can't use\n\t\t\t\t// the unexported error (errNoCertificates) that our caller (config.getCertificate\n\t\t\t\t// in crypto/tls) uses as a sentinel, it would report an (alertInternalError)\n\t\t\t\t// \"internal error\" instead of an alertUnrecognizedName.\n\t\t\t\t// Which is why we return no error, and we let the caller detect that there's\n\t\t\t\t// actually no certificate, and fall back into the flow that will report\n\t\t\t\t// the desired error.\n\t\t\t\t// https://cs.opensource.google/go/go/+/dev.boringcrypto.go1.17:src/crypto/tls/common.go;l=1058\n\t\t\t\treturn nil, nil\n\t\t\t}\n\n\t\t\treturn certificate, nil\n\t\t}\n\n\t\tbestCertificate := store.GetBestCertificate(clientHello)\n\t\tif bestCertificate != nil {\n\t\t\treturn bestCertificate, nil\n\t\t}\n\n\t\tif sniStrict {\n\t\t\tlog.WithoutContext().Debugf(\"TLS: strict SNI enabled - No certificate found for domain: %q, closing connection\", domainToCheck)\n\t\t\t// Same comment as above, as in the isACMETLS case.\n\t\t\treturn nil, nil\n\t\t}\n\n\t\tif store == nil {\n\t\t\tlog.WithoutContext().Errorf(\"TLS: No certificate store found with this name: %q, closing connection\", storeName)\n\n\t\t\t// Same comment as above, as in the isACMETLS case.\n\t\t\treturn nil, nil\n\t\t}\n\n\t\tlog.WithoutContext().Debugf(\"Serving default certificate for request: %q\", domainToCheck)\n\t\treturn store.DefaultCertificate, nil\n\t}\n\n\treturn tlsConfig, err\n}", "is_vulnerable": 1}
{"code": "func TestHeaderAnnotations(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\ting.SetAnnotations(data)\n\n\ttests := []struct {\n\t\ttitle         string\n\t\turl           string\n\t\theaders       string\n\t\tparsedHeaders []string\n\t\texpErr        bool\n\t}{\n\t\t{\"single header\", \"http://goog.url\", \"h1\", []string{\"h1\"}, false},\n\t\t{\"nothing\", \"http://goog.url\", \"\", []string{}, false},\n\t\t{\"spaces\", \"http://goog.url\", \"  \", []string{}, false},\n\t\t{\"two headers\", \"http://goog.url\", \"1,2\", []string{\"1\", \"2\"}, false},\n\t\t{\"two headers and empty entries\", \"http://goog.url\", \",1,,2,\", []string{\"1\", \"2\"}, false},\n\t\t{\"header with spaces\", \"http://goog.url\", \"1 2\", []string{}, true},\n\t\t{\"header with other bad symbols\", \"http://goog.url\", \"1+2\", []string{}, true},\n\t}\n\n\tfor _, test := range tests {\n\t\tdata[parser.GetAnnotationWithPrefix(\"auth-url\")] = test.url\n\t\tdata[parser.GetAnnotationWithPrefix(\"auth-response-headers\")] = test.headers\n\t\tdata[parser.GetAnnotationWithPrefix(\"auth-method\")] = \"GET\"\n\n\t\ti, err := NewParser(&resolver.Mock{}).Parse(ing)\n\t\tif test.expErr {\n\t\t\tif err == nil {\n\t\t\t\tt.Error(\"expected error but retuned nil\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tu, ok := i.(*Config)\n\t\tif !ok {\n\t\t\tt.Errorf(\"%v: expected an External type\", test.title)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !reflect.DeepEqual(u.ResponseHeaders, test.parsedHeaders) {\n\t\t\tt.Errorf(\"%v: expected \\\"%v\\\" but \\\"%v\\\" was returned\", test.title, test.headers, u.ResponseHeaders)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestVerificationCode_ExpireVerificationCode(t *testing.T) {\n\tt.Parallel()\n\n\tdb, _ := testDatabaseInstance.NewDatabase(t, nil)\n\trealm := NewRealmWithDefaults(\"Test Realm\")\n\n\tvc := &VerificationCode{\n\t\tCode:          \"123456\",\n\t\tLongCode:      \"defghijk329024\",\n\t\tTestType:      \"confirmed\",\n\t\tExpiresAt:     time.Now().Add(time.Hour),\n\t\tLongExpiresAt: time.Now().Add(2 * time.Hour),\n\t}\n\n\tif err := realm.SaveVerificationCode(db, vc); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tuuid := vc.UUID\n\tif uuid == \"\" {\n\t\tt.Fatal(\"expected uuid\")\n\t}\n\n\t{\n\t\tgot, err := realm.ExpireCode(db, uuid, SystemTest)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\tif got, want := got.ID, vc.ID; got != want {\n\t\t\tt.Errorf(\"expected %#v to be %#v\", got, want)\n\t\t}\n\t\tif got.ExpiresAt.After(time.Now()) {\n\t\t\tt.Errorf(\"expected expired, got %v\", got.ExpiresAt)\n\t\t}\n\t}\n\n\tif _, err := realm.ExpireCode(db, uuid, SystemTest); err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestInvalidPaddingOpen(t *testing.T) {\n\tkey := make([]byte, 32)\n\tnonce := make([]byte, 16)\n\n\t// Plaintext with invalid padding\n\tplaintext := padBuffer(make([]byte, 28), aes.BlockSize)\n\tplaintext[len(plaintext)-1] = 0xFF\n\n\tio.ReadFull(rand.Reader, key)\n\tio.ReadFull(rand.Reader, nonce)\n\n\tblock, _ := aes.NewCipher(key)\n\tcbc := cipher.NewCBCEncrypter(block, nonce)\n\tbuffer := append([]byte{}, plaintext...)\n\tcbc.CryptBlocks(buffer, buffer)\n\n\taead, _ := NewCBCHMAC(key, aes.NewCipher)\n\tctx := aead.(*cbcAEAD)\n\n\t// Mutated ciphertext, but with correct auth tag\n\tsize := uint64(len(buffer))\n\tciphertext, tail := resize(buffer, size+(uint64(len(key))/2))\n\tcopy(tail, ctx.computeAuthTag(nil, nonce, ciphertext[:size]))\n\n\t// Open should fail (b/c of invalid padding, even though tag matches)\n\t_, err := aead.Open(nil, nonce, ciphertext, nil)\n\tif err == nil || !strings.Contains(err.Error(), \"invalid padding\") {\n\t\tt.Error(\"no or unexpected error on open with invalid padding:\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func Clean(path string) string {\n\toriginalPath := path\n\tvolLen := volumeNameLen(path)\n\tpath = path[volLen:]\n\tif path == \"\" {\n\t\tif volLen > 1 && os.IsPathSeparator(originalPath[0]) && os.IsPathSeparator(originalPath[1]) {\n\t\t\t// should be UNC\n\t\t\treturn FromSlash(originalPath)\n\t\t}\n\t\treturn originalPath + \".\"\n\t}\n\trooted := os.IsPathSeparator(path[0])\n\n\t// Invariants:\n\t//\treading from path; r is index of next byte to process.\n\t//\twriting to buf; w is index of next byte to write.\n\t//\tdotdot is index in buf where .. must stop, either because\n\t//\t\tit is the leading slash or it is a leading ../../.. prefix.\n\tn := len(path)\n\tout := lazybuf{path: path, volAndPath: originalPath, volLen: volLen}\n\tr, dotdot := 0, 0\n\tif rooted {\n\t\tout.append(Separator)\n\t\tr, dotdot = 1, 1\n\t}\n\n\tfor r < n {\n\t\tswitch {\n\t\tcase os.IsPathSeparator(path[r]):\n\t\t\t// empty path element\n\t\t\tr++\n\t\tcase path[r] == '.' && (r+1 == n || os.IsPathSeparator(path[r+1])):\n\t\t\t// . element\n\t\t\tr++\n\t\tcase path[r] == '.' && path[r+1] == '.' && (r+2 == n || os.IsPathSeparator(path[r+2])):\n\t\t\t// .. element: remove to last separator\n\t\t\tr += 2\n\t\t\tswitch {\n\t\t\tcase out.w > dotdot:\n\t\t\t\t// can backtrack\n\t\t\t\tout.w--\n\t\t\t\tfor out.w > dotdot && !os.IsPathSeparator(out.index(out.w)) {\n\t\t\t\t\tout.w--\n\t\t\t\t}\n\t\t\tcase !rooted:\n\t\t\t\t// cannot backtrack, but not rooted, so append .. element.\n\t\t\t\tif out.w > 0 {\n\t\t\t\t\tout.append(Separator)\n\t\t\t\t}\n\t\t\t\tout.append('.')\n\t\t\t\tout.append('.')\n\t\t\t\tdotdot = out.w\n\t\t\t}\n\t\tdefault:\n\t\t\t// real path element.\n\t\t\t// add slash if needed\n\t\t\tif rooted && out.w != 1 || !rooted && out.w != 0 {\n\t\t\t\tout.append(Separator)\n\t\t\t}\n\t\t\t// If a ':' appears in the path element at the start of a Windows path,\n\t\t\t// insert a .\\ at the beginning to avoid converting relative paths\n\t\t\t// like a/../c: into c:.\n\t\t\tif runtime.GOOS == \"windows\" && out.w == 0 && out.volLen == 0 && r != 0 {\n\t\t\t\tfor i := r; i < n && !os.IsPathSeparator(path[i]); i++ {\n\t\t\t\t\tif path[i] == ':' {\n\t\t\t\t\t\tout.append('.')\n\t\t\t\t\t\tout.append(Separator)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// copy element\n\t\t\tfor ; r < n && !os.IsPathSeparator(path[r]); r++ {\n\t\t\t\tout.append(path[r])\n\t\t\t}\n\t\t}\n\t}\n\n\t// Turn empty string into \".\"\n\tif out.w == 0 {\n\t\tout.append('.')\n\t}\n\n\treturn FromSlash(out.string())\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeCodeStorageMockRecorder) InvalidateAuthorizeCodeSession(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"InvalidateAuthorizeCodeSession\", reflect.TypeOf((*MockAuthorizeCodeStorage)(nil).InvalidateAuthorizeCodeSession), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "\t\tWriteHeader: func(httpsnoop.WriteHeaderFunc) httpsnoop.WriteHeaderFunc {\n\t\t\treturn rww.WriteHeader\n\t\t},\n\t})\n\n\tlabeler := &Labeler{}\n\tctx = injectLabeler(ctx, labeler)\n\n\tnext.ServeHTTP(w, r.WithContext(ctx))\n\n\tsetAfterServeAttributes(span, bw.read, rww.written, rww.statusCode, bw.err, rww.err)\n\n\t// Add metrics\n\tattributes := append(labeler.Get(), semconvutil.HTTPServerRequestMetrics(h.server, r)...)\n\tif rww.statusCode > 0 {\n\t\tattributes = append(attributes, semconv.HTTPStatusCode(rww.statusCode))\n\t}\n\to := metric.WithAttributes(attributes...)\n\th.counters[RequestContentLength].Add(ctx, bw.read, o)\n\th.counters[ResponseContentLength].Add(ctx, rww.written, o)\n\n\t// Use floating point division here for higher precision (instead of Millisecond method).\n\telapsedTime := float64(time.Since(requestStartTime)) / float64(time.Millisecond)\n\n\th.valueRecorders[ServerLatency].Record(ctx, elapsedTime, o)\n}", "is_vulnerable": 0}
{"code": "func TestWithMessage(t *testing.T) {\n\tkey, err := jwxtest.GenerateRsaKey()\n\tif !assert.NoError(t, err, \"jwxtest.Generate should succeed\") {\n\t\treturn\n\t}\n\n\tconst text = \"hello, world\"\n\tsigned, err := jws.Sign([]byte(text), jws.WithKey(jwa.RS256, key))\n\tif !assert.NoError(t, err, `jws.Sign should succeed`) {\n\t\treturn\n\t}\n\n\tm := jws.NewMessage()\n\tpayload, err := jws.Verify(signed, jws.WithKey(jwa.RS256, key.PublicKey), jws.WithMessage(m))\n\tif !assert.NoError(t, err, `jws.Verify should succeed`) {\n\t\treturn\n\t}\n\tif !assert.Equal(t, payload, []byte(text), `jws.Verify should produce the correct payload`) {\n\t\treturn\n\t}\n\n\tparsed, err := jws.Parse(signed)\n\tif !assert.NoError(t, err, `jws.Parse should succeed`) {\n\t\treturn\n\t}\n\n\t// The result of using jws.WithMessage should match the result of jws.Parse\n\tbuf1, _ := json.Marshal(m)\n\tbuf2, _ := json.Marshal(parsed)\n\n\tif !assert.Equal(t, buf1, buf2, `result of jws.PArse and jws.Verify(..., jws.WithMessage()) should match`) {\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func init() {\n\tdisableExtAuthz = marshalAny(&envoy_extensions_filters_http_ext_authz_v3.ExtAuthzPerRoute{\n\t\tOverride: &envoy_extensions_filters_http_ext_authz_v3.ExtAuthzPerRoute_Disabled{\n\t\t\tDisabled: true,\n\t\t},\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestPluginProxyRoutesAccessControl(t *testing.T) {\n\troutes := []*plugins.Route{\n\t\t{\n\t\t\tPath:    \"settings\",\n\t\t\tMethod:  \"GET\",\n\t\t\tURL:     \"http://localhost/api/settings\",\n\t\t\tReqRole: org.RoleAdmin, // Protected by role\n\t\t},\n\t\t{\n\t\t\tPath:      \"projects\",\n\t\t\tMethod:    \"GET\",\n\t\t\tURL:       \"http://localhost/api/projects\",\n\t\t\tReqAction: \"plugin-id.projects:read\", // Protected by RBAC action\n\t\t},\n\t}\n\n\ttcs := []struct {\n\t\tproxyPath       string\n\t\tusrRole         org.RoleType\n\t\tusrPerms        map[string][]string\n\t\texpectedURLPath string\n\t\texpectedStatus  int\n\t}{\n\t\t{\n\t\t\tproxyPath:       \"/settings\",\n\t\t\tusrRole:         org.RoleAdmin,\n\t\t\texpectedURLPath: \"/api/settings\",\n\t\t\texpectedStatus:  http.StatusOK,\n\t\t},\n\t\t{\n\t\t\tproxyPath:       \"/settings\",\n\t\t\tusrRole:         org.RoleViewer,\n\t\t\texpectedURLPath: \"/api/settings\",\n\t\t\texpectedStatus:  http.StatusForbidden,\n\t\t},\n\t\t{\n\t\t\tproxyPath:       \"/projects\",\n\t\t\tusrPerms:        map[string][]string{\"plugin-id.projects:read\": {}},\n\t\t\texpectedURLPath: \"/api/projects\",\n\t\t\texpectedStatus:  http.StatusOK,\n\t\t},\n\t\t{\n\t\t\tproxyPath:       \"/projects\",\n\t\t\tusrPerms:        map[string][]string{},\n\t\t\texpectedURLPath: \"/api/projects\",\n\t\t\texpectedStatus:  http.StatusForbidden,\n\t\t},\n\t}\n\n\tfor _, tc := range tcs {\n\t\tt.Run(fmt.Sprintf(\"Should enforce RBAC when proxying path %s %s\", tc.proxyPath, http.StatusText(tc.expectedStatus)), func(t *testing.T) {\n\t\t\tsecretsService := secretsManager.SetupTestService(t, fakes.NewFakeSecretsStore())\n\t\t\trequestHandled := false\n\t\t\trequestURL := \"\"\n\t\t\tbackendServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\trequestURL = r.URL.RequestURI()\n\t\t\t\tw.WriteHeader(200)\n\t\t\t\t_, _ = w.Write([]byte(\"I am the backend\"))\n\t\t\t\trequestHandled = true\n\t\t\t}))\n\t\t\tt.Cleanup(backendServer.Close)\n\n\t\t\tbackendURL, err := url.Parse(backendServer.URL)\n\t\t\trequire.NoError(t, err)\n\n\t\t\ttestRoutes := make([]*plugins.Route, len(routes))\n\t\t\tfor i, r := range routes {\n\t\t\t\tu, err := url.Parse(r.URL)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tu.Scheme = backendURL.Scheme\n\t\t\t\tu.Host = backendURL.Host\n\t\t\t\ttestRoute := *r\n\t\t\t\ttestRoute.URL = u.String()\n\t\t\t\ttestRoutes[i] = &testRoute\n\t\t\t}\n\n\t\t\tresponseWriter := web.NewResponseWriter(\"GET\", httptest.NewRecorder())\n\n\t\t\tctx := &contextmodel.ReqContext{\n\t\t\t\tLogger: logger.New(\"pluginproxy-test\"),\n\t\t\t\tSignedInUser: &user.SignedInUser{\n\t\t\t\t\tOrgID:       1,\n\t\t\t\t\tOrgRole:     tc.usrRole,\n\t\t\t\t\tPermissions: map[int64]map[string][]string{1: tc.usrPerms},\n\t\t\t\t},\n\t\t\t\tContext: &web.Context{\n\t\t\t\t\tReq:  httptest.NewRequest(\"GET\", tc.proxyPath, nil),\n\t\t\t\t\tResp: responseWriter,\n\t\t\t\t},\n\t\t\t}\n\t\t\tps := &pluginsettings.DTO{\n\t\t\t\tSecureJSONData: map[string][]byte{},\n\t\t\t}\n\t\t\tcfg := &setting.Cfg{}\n\t\t\tproxy, err := NewPluginProxy(ps, testRoutes, ctx, tc.proxyPath, cfg, secretsService, tracing.InitializeTracerForTest(), &http.Transport{}, acimpl.ProvideAccessControl(featuremgmt.WithFeatures()), featuremgmt.WithFeatures(featuremgmt.FlagAccessControlOnCall))\n\t\t\trequire.NoError(t, err)\n\t\t\tproxy.HandleRequest()\n\n\t\t\tfor {\n\t\t\t\tif requestHandled || ctx.Resp.Written() {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\trequire.Equal(t, tc.expectedStatus, ctx.Resp.Status())\n\n\t\t\tif tc.expectedStatus == http.StatusForbidden {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.Equal(t, tc.expectedURLPath, requestURL)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (mr *MockTokenRevocationStorageMockRecorder) DeleteRefreshTokenSession(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DeleteRefreshTokenSession\", reflect.TypeOf((*MockTokenRevocationStorage)(nil).DeleteRefreshTokenSession), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func RandomAlphaNumeric(count int) (string, error) {\n\tRandomString, err := Random(count, 0, 0, true, true)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Error: %s\", err)\n\t}\n\tmatch, err := regexp.MatchString(\"([0-9]+)\", RandomString)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tif !match {\n\t\t//Get the position between 0 and the length of the string-1  to insert a random number\n\t\tposition := rand.Intn(count)\n\t\t//Insert a random number between [0-9] in the position\n\t\tRandomString = RandomString[:position] + string('0'+rand.Intn(10)) + RandomString[position+1:]\n\t\treturn RandomString, err\n\t}\n\treturn RandomString, err\n\n}", "is_vulnerable": 1}
{"code": "func buildAgentService(s *structs.NodeService, proxies map[string]*local.ManagedProxy) api.AgentService {\n\tweights := api.AgentWeights{Passing: 1, Warning: 1}\n\tif s.Weights != nil {\n\t\tif s.Weights.Passing > 0 {\n\t\t\tweights.Passing = s.Weights.Passing\n\t\t}\n\t\tweights.Warning = s.Weights.Warning\n\t}\n\tas := api.AgentService{\n\t\tKind:              api.ServiceKind(s.Kind),\n\t\tID:                s.ID,\n\t\tService:           s.Service,\n\t\tTags:              s.Tags,\n\t\tMeta:              s.Meta,\n\t\tPort:              s.Port,\n\t\tAddress:           s.Address,\n\t\tEnableTagOverride: s.EnableTagOverride,\n\t\tCreateIndex:       s.CreateIndex,\n\t\tModifyIndex:       s.ModifyIndex,\n\t\tWeights:           weights,\n\t}\n\n\tif as.Tags == nil {\n\t\tas.Tags = []string{}\n\t}\n\tif as.Meta == nil {\n\t\tas.Meta = map[string]string{}\n\t}\n\t// Attach Unmanaged Proxy config if exists\n\tif s.Kind == structs.ServiceKindConnectProxy {\n\t\tas.Proxy = s.Proxy.ToAPI()\n\t\t// DEPRECATED (ProxyDestination) - remove this when removing ProxyDestination\n\t\t// Also set the deprecated ProxyDestination\n\t\tas.ProxyDestination = as.Proxy.DestinationServiceName\n\t}\n\n\t// Attach Connect configs if they exist. We use the actual proxy state since\n\t// that may have had defaults filled in compared to the config that was\n\t// provided with the service as stored in the NodeService here.\n\tif proxy, ok := proxies[s.ID+\"-proxy\"]; ok {\n\t\tas.Connect = &api.AgentServiceConnect{\n\t\t\tProxy: &api.AgentServiceConnectProxy{\n\t\t\t\tExecMode:  api.ProxyExecMode(proxy.Proxy.ExecMode.String()),\n\t\t\t\tCommand:   proxy.Proxy.Command,\n\t\t\t\tConfig:    proxy.Proxy.Config,\n\t\t\t\tUpstreams: proxy.Proxy.Upstreams.ToAPI(),\n\t\t\t},\n\t\t}\n\t} else if s.Connect.Native {\n\t\tas.Connect = &api.AgentServiceConnect{\n\t\t\tNative: true,\n\t\t}\n\t}\n\treturn as\n}", "is_vulnerable": 0}
{"code": "func containsInt(ints []int, n int) bool {\n\tfor _, i := range ints {\n\t\tif i == n {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Netstat(ctx context.Context, in *sliverpb.NetstatReq, opts ...grpc.CallOption) (*sliverpb.Netstat, error) {\n\tout := new(sliverpb.Netstat)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Netstat\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func FormatEndpoint(endpoint string) string {\n\tendpoint = strings.TrimSpace(endpoint)\n\tendpoint = strings.TrimRight(endpoint, \"/\")\n\tif !strings.HasPrefix(endpoint, \"http://\") &&\n\t\t!strings.HasPrefix(endpoint, \"https://\") {\n\t\tendpoint = \"http://\" + endpoint\n\t}\n\n\treturn endpoint\n}", "is_vulnerable": 1}
{"code": "func groupConnectHook(job *structs.Job, g *structs.TaskGroup) error {\n\t// Create an environment interpolator with what we have at submission time.\n\t// This should only be used to interpolate connect service names which are\n\t// used in sidecar or gateway task names. Note that the service name might\n\t// also be interpolated with job specifics during service canonicalization.\n\tenv := taskenv.NewEmptyBuilder().UpdateTask(&structs.Allocation{\n\t\tJob:       job,\n\t\tTaskGroup: g.Name,\n\t}, nil).Build()\n\n\tfor _, service := range g.Services {\n\t\tswitch {\n\t\t// mutate depending on what the connect block is being used for\n\n\t\tcase service.Connect.HasSidecar():\n\t\t\t// interpolate the connect service name, which is used to create\n\t\t\t// a name of an injected sidecar task\n\t\t\tservice.Name = env.ReplaceEnv(service.Name)\n\n\t\t\t// Check to see if the sidecar task already exists\n\t\t\ttask := getSidecarTaskForService(g, service.Name)\n\n\t\t\t// If the task doesn't already exist, create a new one and add it to the job\n\t\t\tif task == nil {\n\t\t\t\ttask = newConnectSidecarTask(service.Name)\n\n\t\t\t\t// If there happens to be a task defined with the same name\n\t\t\t\t// append an UUID fragment to the task name\n\t\t\t\tfor _, t := range g.Tasks {\n\t\t\t\t\tif t.Name == task.Name {\n\t\t\t\t\t\ttask.Name = task.Name + \"-\" + uuid.Generate()[:6]\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tg.Tasks = append(g.Tasks, task)\n\t\t\t}\n\n\t\t\tif service.Connect.SidecarTask != nil {\n\t\t\t\tservice.Connect.SidecarTask.MergeIntoTask(task)\n\t\t\t}\n\n\t\t\t// Canonicalize task since this mutator runs after job canonicalization\n\t\t\ttask.Canonicalize(job, g)\n\n\t\t\t// create a port for the sidecar task's proxy port\n\t\t\tportLabel := service.Connect.SidecarService.Port\n\t\t\tif portLabel == \"\" {\n\t\t\t\tportLabel = envoy.PortLabel(structs.ConnectProxyPrefix, service.Name, \"\")\n\t\t\t}\n\t\t\tinjectPort(g, portLabel)\n\n\t\tcase service.Connect.IsNative():\n\t\t\t// find the task backing this connect native service and set the kind\n\t\t\tnativeTaskName := service.TaskName\n\t\t\tif t, err := getNamedTaskForNativeService(g, service.Name, nativeTaskName); err != nil {\n\t\t\t\treturn err\n\t\t\t} else {\n\t\t\t\tt.Kind = structs.NewTaskKind(structs.ConnectNativePrefix, service.Name)\n\t\t\t\tservice.TaskName = t.Name // in case the task was inferred\n\t\t\t}\n\n\t\tcase service.Connect.IsGateway():\n\t\t\t// interpolate the connect service name, which is used to create\n\t\t\t// a name of an injected gateway task\n\t\t\tservice.Name = env.ReplaceEnv(service.Name)\n\n\t\t\t// Generate a proxy configuration, if one is not provided, that is\n\t\t\t// most appropriate for the network mode being used.\n\t\t\tnetMode := g.Networks[0].Mode\n\t\t\tservice.Connect.Gateway.Proxy = gatewayProxy(service.Connect.Gateway, netMode)\n\n\t\t\t// Inject a port whether bridge or host network (if not already set).\n\t\t\t// This port is accessed by the magic of Connect plumbing so it seems\n\t\t\t// reasonable to keep the magic alive here.\n\t\t\tif service.Connect.IsTerminating() && service.PortLabel == \"\" {\n\t\t\t\t// Inject a dynamic port for the terminating gateway.\n\t\t\t\tportLabel := envoy.PortLabel(structs.ConnectTerminatingPrefix, service.Name, \"\")\n\t\t\t\tservice.PortLabel = portLabel\n\t\t\t\tinjectPort(g, portLabel)\n\t\t\t}\n\n\t\t\t// A mesh Gateway will need 2 ports (lan and wan).\n\t\t\tif service.Connect.IsMesh() {\n\n\t\t\t\t// service port is used for mesh gateway wan address - it should\n\t\t\t\t// come from a configured host_network to make sense\n\t\t\t\tif service.PortLabel == \"\" {\n\t\t\t\t\treturn errors.New(\"service.port must be set for mesh gateway service\")\n\t\t\t\t}\n\n\t\t\t\t// Inject a dynamic port for mesh gateway LAN address.\n\t\t\t\tlanPortLabel := envoy.PortLabel(structs.ConnectMeshPrefix, service.Name, \"lan\")\n\t\t\t\tinjectPort(g, lanPortLabel)\n\t\t\t}\n\n\t\t\t// inject the gateway task only if it does not yet already exist\n\t\t\tif !hasGatewayTaskForService(g, service.Name) {\n\t\t\t\tprefix := service.Connect.Gateway.Prefix()\n\n\t\t\t\t// detect whether the group is in host networking mode, which will\n\t\t\t\t// require tweaking the default gateway task config\n\t\t\t\tnetHost := netMode == \"host\"\n\t\t\t\ttask := newConnectGatewayTask(prefix, service.Name, netHost)\n\t\t\t\tg.Tasks = append(g.Tasks, task)\n\n\t\t\t\t// the connect.sidecar_task stanza can also be used to configure\n\t\t\t\t// a custom task to use as a gateway proxy\n\t\t\t\tif service.Connect.SidecarTask != nil {\n\t\t\t\t\tservice.Connect.SidecarTask.MergeIntoTask(task)\n\t\t\t\t}\n\n\t\t\t\ttask.Canonicalize(job, g)\n\t\t\t}\n\t\t}\n\t}\n\n\t// re-canonicalize group network since this hook runs after canonicalizaton\n\tg.Networks[0].Canonicalize()\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func PossibleDeploymentModeValues() []DeploymentMode {\n\treturn original.PossibleDeploymentModeValues()\n}", "is_vulnerable": 1}
{"code": "func (r *albumRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\treturn r.CountAll(r.parseRestOptions(r.ctx, options...))\n}", "is_vulnerable": 0}
{"code": "func (plr ProviderListResult) providerListResultPreparer() (*http.Request, error) {\n\tif plr.NextLink == nil || len(to.String(plr.NextLink)) < 1 {\n\t\treturn nil, nil\n\t}\n\treturn autorest.Prepare(&http.Request{},\n\t\tautorest.AsJSON(),\n\t\tautorest.AsGet(),\n\t\tautorest.WithBaseURL(to.String(plr.NextLink)))\n}", "is_vulnerable": 1}
{"code": "func (c *CommonController) SetTitle(title string)  {\n\tc.SetData(\"Title\",title+\" - Bifrost\")\n}", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) Chown(path string) error {\n\tcleaned, err := fs.SafePath(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn fs.unsafeChown(cleaned)\n}", "is_vulnerable": 0}
{"code": "func (t *TestResourceTreeServer) SendHeader(metadata.MD) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *DroppedWithoutGetters) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypedeclall\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: DroppedWithoutGetters: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: DroppedWithoutGetters: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Height\", wireType)\n\t\t\t}\n\t\t\tm.Height = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypedeclall\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Height |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Width\", wireType)\n\t\t\t}\n\t\t\tm.Width = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypedeclall\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Width |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypedeclall(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypedeclall\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func BenchmarkOnes(b *testing.B) {\n\tbf, err := NewBitfield(benchmarkSize)\n\tassertNoError(b, err)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tfor j := 0; j*4 < benchmarkSize; j++ {\n\t\t\tif bf.Ones() != j {\n\t\t\t\tb.Fatal(\"bad\", i)\n\t\t\t}\n\t\t\tbf.SetBit(j * 4)\n\t\t}\n\t\tfor j := 0; j*4 < benchmarkSize; j++ {\n\t\t\tbf.UnsetBit(j * 4)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestParse(t *testing.T) {\n\tannotation := parser.GetAnnotationWithPrefix(\"client-body-buffer-size\")\n\tap := NewParser(&resolver.Mock{})\n\tif ap == nil {\n\t\tt.Fatalf(\"expected a parser.IngressAnnotation but returned nil\")\n\t}\n\n\ttestCases := []struct {\n\t\tannotations map[string]string\n\t\texpected    string\n\t}{\n\t\t{map[string]string{annotation: \"8k\"}, \"8k\"},\n\t\t{map[string]string{annotation: \"16k\"}, \"16k\"},\n\t\t{map[string]string{annotation: \"10000\"}, \"10000\"},\n\t\t{map[string]string{annotation: \"16R\"}, \"\"},\n\t\t{map[string]string{annotation: \"16kkk\"}, \"\"},\n\t\t{map[string]string{annotation: \"\"}, \"\"},\n\t\t{map[string]string{}, \"\"},\n\t\t{nil, \"\"},\n\t}\n\n\ting := &networking.Ingress{\n\t\tObjectMeta: meta_v1.ObjectMeta{\n\t\t\tName:      \"foo\",\n\t\t\tNamespace: api.NamespaceDefault,\n\t\t},\n\t\tSpec: networking.IngressSpec{},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ting.SetAnnotations(testCase.annotations)\n\t\tresult, _ := ap.Parse(ing)\n\t\tif result != testCase.expected {\n\t\t\tt.Errorf(\"expected %v but returned %v, annotations: %s\", testCase.expected, result, testCase.annotations)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn snippet{\n\t\tr:                r,\n\t\tannotationConfig: configurationSnippetAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Cp(ctx context.Context, in *sliverpb.CpReq, opts ...grpc.CallOption) (*sliverpb.Cp, error) {\n\tout := new(sliverpb.Cp)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Cp\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func NewConcatKDF(hash crypto.Hash, z, algID, ptyUInfo, ptyVInfo, supPubInfo, supPrivInfo []byte) io.Reader {\n\tbuffer := make([]byte, uint64(len(algID))+uint64(len(ptyUInfo))+uint64(len(ptyVInfo))+uint64(len(supPubInfo))+uint64(len(supPrivInfo)))\n\tn := 0\n\tn += copy(buffer, algID)\n\tn += copy(buffer[n:], ptyUInfo)\n\tn += copy(buffer[n:], ptyVInfo)\n\tn += copy(buffer[n:], supPubInfo)\n\tcopy(buffer[n:], supPrivInfo)\n\n\thasher := hash.New()\n\n\treturn &concatKDF{\n\t\tz:      z,\n\t\tinfo:   buffer,\n\t\thasher: hasher,\n\t\tcache:  []byte{},\n\t\ti:      1,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *httpConv) ServerRequestMetrics(server string, req *http.Request) []attribute.KeyValue {\n\t// TODO: This currently does not add the specification required\n\t// `http.target` attribute. It has too high of a cardinality to safely be\n\t// added. An alternate should be added, or this comment removed, when it is\n\t// addressed by the specification. If it is ultimately decided to continue\n\t// not including the attribute, the HTTPTargetKey field of the httpConv\n\t// should be removed as well.\n\n\tn := 4 // Method, scheme, proto, and host name.\n\tvar host string\n\tvar p int\n\tif server == \"\" {\n\t\thost, p = splitHostPort(req.Host)\n\t} else {\n\t\t// Prioritize the primary server name.\n\t\thost, p = splitHostPort(server)\n\t\tif p < 0 {\n\t\t\t_, p = splitHostPort(req.Host)\n\t\t}\n\t}\n\thostPort := requiredHTTPPort(req.TLS != nil, p)\n\tif hostPort > 0 {\n\t\tn++\n\t}\n\tattrs := make([]attribute.KeyValue, 0, n)\n\n\tattrs = append(attrs, c.methodMetric(req.Method))\n\tattrs = append(attrs, c.scheme(req.TLS != nil))\n\tattrs = append(attrs, c.flavor(req.Proto))\n\tattrs = append(attrs, c.NetConv.HostName(host))\n\n\tif hostPort > 0 {\n\t\tattrs = append(attrs, c.NetConv.HostPort(hostPort))\n\t}\n\n\treturn attrs\n}", "is_vulnerable": 0}
{"code": "func Start(ctx context.Context, conf Config, systemDefaults sd.SystemDefaults, command *command.Commands, queries *query.Queries, dbClient *database.DB, esV2 *eventstore2.Eventstore, oidcEncryption crypto.EncryptionAlgorithm, userEncryption crypto.EncryptionAlgorithm) (*EsRepository, error) {\n\tview, err := auth_view.StartView(dbClient, oidcEncryption, queries, esV2)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauth_handler.Register(ctx, conf.Spooler, view, queries)\n\tauth_handler.Start(ctx)\n\n\tauthReq := cache.Start(dbClient, conf.AmountOfCachedAuthRequests)\n\n\tuserRepo := eventstore.UserRepo{\n\t\tSearchLimit:    conf.SearchLimit,\n\t\tEventstore:     esV2,\n\t\tView:           view,\n\t\tQuery:          queries,\n\t\tSystemDefaults: systemDefaults,\n\t}\n\t//TODO: remove as soon as possible\n\tqueryView := queryViewWrapper{\n\t\tqueries,\n\t\tview,\n\t}\n\treturn &EsRepository{\n\t\tuserRepo,\n\t\teventstore.AuthRequestRepo{\n\t\t\tPrivacyPolicyProvider:     queries,\n\t\t\tLabelPolicyProvider:       queries,\n\t\t\tCommand:                   command,\n\t\t\tQuery:                     queries,\n\t\t\tOrgViewProvider:           queries,\n\t\t\tAuthRequests:              authReq,\n\t\t\tView:                      view,\n\t\t\tUserCodeAlg:               userEncryption,\n\t\t\tUserSessionViewProvider:   view,\n\t\t\tUserViewProvider:          view,\n\t\t\tUserCommandProvider:       command,\n\t\t\tUserEventProvider:         &userRepo,\n\t\t\tIDPProviderViewProvider:   queries,\n\t\t\tIDPUserLinksProvider:      queries,\n\t\t\tLockoutPolicyViewProvider: queries,\n\t\t\tLoginPolicyViewProvider:   queries,\n\t\t\tUserGrantProvider:         queryView,\n\t\t\tProjectProvider:           queryView,\n\t\t\tApplicationProvider:       queries,\n\t\t\tCustomTextProvider:        queries,\n\t\t\tPasswordChecker:           command,\n\t\t\tIdGenerator:               id.SonyFlakeGenerator(),\n\t\t},\n\t\teventstore.TokenRepo{\n\t\t\tView:       view,\n\t\t\tEventstore: esV2,\n\t\t},\n\t\teventstore.RefreshTokenRepo{\n\t\t\tView:         view,\n\t\t\tEventstore:   esV2,\n\t\t\tSearchLimit:  conf.SearchLimit,\n\t\t\tKeyAlgorithm: oidcEncryption,\n\t\t},\n\t\teventstore.UserSessionRepo{\n\t\t\tView: view,\n\t\t},\n\t\teventstore.OrgRepository{\n\t\t\tSearchLimit:    conf.SearchLimit,\n\t\t\tView:           view,\n\t\t\tSystemDefaults: systemDefaults,\n\t\t\tEventstore:     esV2,\n\t\t\tQuery:          queries,\n\t\t},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func makeHostsMount(podDir string, podIPs []string, hostName, hostDomainName string, hostAliases []v1.HostAlias, useHostNetwork bool) (*kubecontainer.Mount, error) {\n\thostsFilePath := path.Join(podDir, \"etc-hosts\")\n\tif err := ensureHostsFile(hostsFilePath, podIPs, hostName, hostDomainName, hostAliases, useHostNetwork); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &kubecontainer.Mount{\n\t\tName:           \"k8s-managed-etc-hosts\",\n\t\tContainerPath:  etcHostsPath,\n\t\tHostPath:       hostsFilePath,\n\t\tReadOnly:       false,\n\t\tSELinuxRelabel: true,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func AccountPostLogin(w http.ResponseWriter, r *http.Request) {\n\taccount, err := (&models.Account{Context: ctx.Context}).FromBody(r)\n\tif err != nil {\n\t\tctx.HandleStatus(w, r, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\tvar a1 = &models.Account{Context: ctx.Context}\n\ta1.FromData(account)\n\ta1, err = a1.Get()\n\tif err != nil {\n\t\tctx.HandleStatus(w, r, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\taccount, err = a1.VerifyPassword(account.Password)\n\tif err != nil {\n\t\tctx.HandleStatus(w, r, \"Invalid username or password!\", http.StatusForbidden)\n\t\treturn\n\t}\n\n\tsession, err := (&models.Session{Context: ctx.Context, Unique: account.Unique}).Post()\n\tif err != nil {\n\t\tctx.HandleStatus(w, r, err.Error(), http.StatusBadRequest)\n\t\treturn\n\t}\n\n\texpiry := time.Now().Add(time.Hour * 15) // TODO: Change this once we've implemented refreshing\n\tSetAuthCookie(w, types.CookieSessionID, session.Key.ID.String(), expiry)\n\tSetAuthCookie(w, types.CookieRefreshToken, session.Refresh, expiry)\n\n\tctx.HandleJson(w, r, account.CopyPublic(), http.StatusOK)\n}", "is_vulnerable": 0}
{"code": "func RegisterRoutes(m *macaron.Macaron) {\n\tbind := binding.Bind\n\n\tm.Group(\"/v1\", func() {\n\t\t// Handle preflight OPTIONS request\n\t\tm.Options(\"/*\", func() {})\n\n\t\t// Miscellaneous\n\t\tm.Post(\"/markdown\", bind(api.MarkdownOption{}), misc.Markdown)\n\t\tm.Post(\"/markdown/raw\", misc.MarkdownRaw)\n\n\t\t// Users\n\t\tm.Group(\"/users\", func() {\n\t\t\tm.Get(\"/search\", user.Search)\n\n\t\t\tm.Group(\"/:username\", func() {\n\t\t\t\tm.Get(\"\", user.GetInfo)\n\n\t\t\t\tm.Group(\"/tokens\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(user.ListAccessTokens).\n\t\t\t\t\t\tPost(bind(api.CreateAccessTokenOption{}), user.CreateAccessToken)\n\t\t\t\t}, reqBasicAuth())\n\t\t\t})\n\t\t})\n\n\t\tm.Group(\"/users\", func() {\n\t\t\tm.Group(\"/:username\", func() {\n\t\t\t\tm.Get(\"/keys\", user.ListPublicKeys)\n\n\t\t\t\tm.Get(\"/followers\", user.ListFollowers)\n\t\t\t\tm.Group(\"/following\", func() {\n\t\t\t\t\tm.Get(\"\", user.ListFollowing)\n\t\t\t\t\tm.Get(\"/:target\", user.CheckFollowing)\n\t\t\t\t})\n\t\t\t})\n\t\t}, reqToken())\n\n\t\tm.Group(\"/user\", func() {\n\t\t\tm.Get(\"\", user.GetAuthenticatedUser)\n\t\t\tm.Combo(\"/emails\").Get(user.ListEmails).\n\t\t\t\tPost(bind(api.CreateEmailOption{}), user.AddEmail).\n\t\t\t\tDelete(bind(api.CreateEmailOption{}), user.DeleteEmail)\n\n\t\t\tm.Get(\"/followers\", user.ListMyFollowers)\n\t\t\tm.Group(\"/following\", func() {\n\t\t\t\tm.Get(\"\", user.ListMyFollowing)\n\t\t\t\tm.Combo(\"/:username\").Get(user.CheckMyFollowing).Put(user.Follow).Delete(user.Unfollow)\n\t\t\t})\n\n\t\t\tm.Group(\"/keys\", func() {\n\t\t\t\tm.Combo(\"\").Get(user.ListMyPublicKeys).\n\t\t\t\t\tPost(bind(api.CreateKeyOption{}), user.CreatePublicKey)\n\t\t\t\tm.Combo(\"/:id\").Get(user.GetPublicKey).\n\t\t\t\t\tDelete(user.DeletePublicKey)\n\t\t\t})\n\n\t\t\tm.Combo(\"/issues\").Get(repo.ListUserIssues)\n\t\t}, reqToken())\n\n\t\t// Repositories\n\t\tm.Get(\"/users/:username/repos\", reqToken(), repo.ListUserRepositories)\n\t\tm.Get(\"/orgs/:org/repos\", reqToken(), repo.ListOrgRepositories)\n\t\tm.Combo(\"/user/repos\", reqToken()).Get(repo.ListMyRepos).\n\t\t\tPost(bind(api.CreateRepoOption{}), repo.Create)\n\t\tm.Post(\"/org/:org/repos\", reqToken(), bind(api.CreateRepoOption{}), repo.CreateOrgRepo)\n\n\t\tm.Group(\"/repos\", func() {\n\t\t\tm.Get(\"/search\", repo.Search)\n\n\t\t\tm.Get(\"/:username/:reponame\", repoAssignment(), repo.Get)\n\t\t})\n\n\t\tm.Group(\"/repos\", func() {\n\t\t\tm.Post(\"/migrate\", bind(form.MigrateRepo{}), repo.Migrate)\n\t\t\tm.Delete(\"/:username/:reponame\", repoAssignment(), repo.Delete)\n\n\t\t\tm.Group(\"/:username/:reponame\", func() {\n\t\t\t\tm.Group(\"/hooks\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.ListHooks).\n\t\t\t\t\t\tPost(bind(api.CreateHookOption{}), repo.CreateHook)\n\t\t\t\t\tm.Combo(\"/:id\").Patch(bind(api.EditHookOption{}), repo.EditHook).\n\t\t\t\t\t\tDelete(repo.DeleteHook)\n\t\t\t\t}, reqAdmin())\n\t\t\t\tm.Group(\"/collaborators\", func() {\n\t\t\t\t\tm.Get(\"\", repo.ListCollaborators)\n\t\t\t\t\tm.Combo(\"/:collaborator\").Get(repo.IsCollaborator).Put(bind(api.AddCollaboratorOption{}), repo.AddCollaborator).\n\t\t\t\t\t\tDelete(repo.DeleteCollaborator)\n\t\t\t\t}, reqAdmin())\n\t\t\t\tm.Get(\"/raw/*\", context.RepoRef(), repo.GetRawFile)\n\t\t\t\tm.Get(\"/archive/*\", repo.GetArchive)\n\t\t\t\tm.Get(\"/forks\", repo.ListForks)\n\t\t\t\tm.Group(\"/branches\", func() {\n\t\t\t\t\tm.Get(\"\", repo.ListBranches)\n\t\t\t\t\tm.Get(\"/*\", repo.GetBranch)\n\t\t\t\t})\n\n\t\t\t\tm.Group(\"/commits\", func() {\n\t\t\t\t\tm.Get(\"/:sha\", repo.GetSingleCommit)\n\t\t\t\t\tm.Get(\"/*\", repo.GetReferenceSHA)\n\t\t\t\t})\n\n\t\t\t\tm.Group(\"/keys\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.ListDeployKeys).\n\t\t\t\t\t\tPost(bind(api.CreateKeyOption{}), repo.CreateDeployKey)\n\t\t\t\t\tm.Combo(\"/:id\").Get(repo.GetDeployKey).\n\t\t\t\t\t\tDelete(repo.DeleteDeploykey)\n\t\t\t\t}, reqAdmin())\n\t\t\t\tm.Group(\"/issues\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.ListIssues).Post(bind(api.CreateIssueOption{}), repo.CreateIssue)\n\t\t\t\t\tm.Group(\"/comments\", func() {\n\t\t\t\t\t\tm.Get(\"\", repo.ListRepoIssueComments)\n\t\t\t\t\t\tm.Combo(\"/:id\").Patch(bind(api.EditIssueCommentOption{}), repo.EditIssueComment)\n\t\t\t\t\t})\n\t\t\t\t\tm.Group(\"/:index\", func() {\n\t\t\t\t\t\tm.Combo(\"\").Get(repo.GetIssue).Patch(bind(api.EditIssueOption{}), repo.EditIssue)\n\n\t\t\t\t\t\tm.Group(\"/comments\", func() {\n\t\t\t\t\t\t\tm.Combo(\"\").Get(repo.ListIssueComments).Post(bind(api.CreateIssueCommentOption{}), repo.CreateIssueComment)\n\t\t\t\t\t\t\tm.Combo(\"/:id\").Patch(bind(api.EditIssueCommentOption{}), repo.EditIssueComment).\n\t\t\t\t\t\t\t\tDelete(repo.DeleteIssueComment)\n\t\t\t\t\t\t})\n\n\t\t\t\t\t\tm.Group(\"/labels\", func() {\n\t\t\t\t\t\t\tm.Combo(\"\").Get(repo.ListIssueLabels).\n\t\t\t\t\t\t\t\tPost(bind(api.IssueLabelsOption{}), repo.AddIssueLabels).\n\t\t\t\t\t\t\t\tPut(bind(api.IssueLabelsOption{}), repo.ReplaceIssueLabels).\n\t\t\t\t\t\t\t\tDelete(repo.ClearIssueLabels)\n\t\t\t\t\t\t\tm.Delete(\"/:id\", repo.DeleteIssueLabel)\n\t\t\t\t\t\t})\n\n\t\t\t\t\t})\n\t\t\t\t}, mustEnableIssues)\n\t\t\t\tm.Group(\"/labels\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.ListLabels).\n\t\t\t\t\t\tPost(bind(api.CreateLabelOption{}), repo.CreateLabel)\n\t\t\t\t\tm.Combo(\"/:id\").Get(repo.GetLabel).Patch(bind(api.EditLabelOption{}), repo.EditLabel).\n\t\t\t\t\t\tDelete(repo.DeleteLabel)\n\t\t\t\t})\n\t\t\t\tm.Group(\"/milestones\", func() {\n\t\t\t\t\tm.Combo(\"\").Get(repo.ListMilestones).\n\t\t\t\t\t\tPost(reqRepoWriter(), bind(api.CreateMilestoneOption{}), repo.CreateMilestone)\n\t\t\t\t\tm.Combo(\"/:id\").Get(repo.GetMilestone).\n\t\t\t\t\t\tPatch(reqRepoWriter(), bind(api.EditMilestoneOption{}), repo.EditMilestone).\n\t\t\t\t\t\tDelete(reqRepoWriter(), repo.DeleteMilestone)\n\t\t\t\t})\n\n\t\t\t\tm.Patch(\"/issue-tracker\", bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\n\t\t\t\tm.Post(\"/mirror-sync\", repo.MirrorSync)\n\t\t\t\tm.Get(\"/editorconfig/:filename\", context.RepoRef(), repo.GetEditorconfig)\n\t\t\t}, repoAssignment())\n\t\t}, reqToken())\n\n\t\tm.Get(\"/issues\", reqToken(), repo.ListUserIssues)\n\n\t\t// Organizations\n\t\tm.Combo(\"/user/orgs\", reqToken()).Get(org.ListMyOrgs).Post(bind(api.CreateOrgOption{}), org.CreateMyOrg)\n\n\t\tm.Get(\"/users/:username/orgs\", org.ListUserOrgs)\n\t\tm.Group(\"/orgs/:orgname\", func() {\n\t\t\tm.Combo(\"\").Get(org.Get).Patch(bind(api.EditOrgOption{}), org.Edit)\n\t\t\tm.Combo(\"/teams\").Get(org.ListTeams)\n\t\t}, orgAssignment(true))\n\n\t\tm.Any(\"/*\", func(c *context.Context) {\n\t\t\tc.NotFound()\n\t\t})\n\n\t\tm.Group(\"/admin\", func() {\n\t\t\tm.Group(\"/users\", func() {\n\t\t\t\tm.Post(\"\", bind(api.CreateUserOption{}), admin.CreateUser)\n\n\t\t\t\tm.Group(\"/:username\", func() {\n\t\t\t\t\tm.Combo(\"\").Patch(bind(api.EditUserOption{}), admin.EditUser).\n\t\t\t\t\t\tDelete(admin.DeleteUser)\n\t\t\t\t\tm.Post(\"/keys\", bind(api.CreateKeyOption{}), admin.CreatePublicKey)\n\t\t\t\t\tm.Post(\"/orgs\", bind(api.CreateOrgOption{}), admin.CreateOrg)\n\t\t\t\t\tm.Post(\"/repos\", bind(api.CreateRepoOption{}), admin.CreateRepo)\n\t\t\t\t})\n\t\t\t})\n\n\t\t\tm.Group(\"/orgs/:orgname\", func() {\n\t\t\t\tm.Group(\"/teams\", func() {\n\t\t\t\t\tm.Post(\"\", orgAssignment(true), bind(api.CreateTeamOption{}), admin.CreateTeam)\n\t\t\t\t})\n\t\t\t})\n\t\t\tm.Group(\"/teams\", func() {\n\t\t\t\tm.Group(\"/:teamid\", func() {\n\t\t\t\t\tm.Combo(\"/members/:username\").Put(admin.AddTeamMember).Delete(admin.RemoveTeamMember)\n\t\t\t\t\tm.Combo(\"/repos/:reponame\").Put(admin.AddTeamRepository).Delete(admin.RemoveTeamRepository)\n\t\t\t\t}, orgAssignment(false, true))\n\t\t\t})\n\t\t}, reqAdmin())\n\t}, context.APIContexter())\n}", "is_vulnerable": 1}
{"code": "func (c *Cluster) GetStateFileFromConfigMap(ctx context.Context) (string, error) {\n\tkubeletImage := c.Services.Kubelet.Image\n\tfor _, host := range c.ControlPlaneHosts {\n\t\tstateFile, err := services.RunGetStateFileFromConfigMap(ctx, host, c.PrivateRegistriesMap, kubeletImage, c.Version)\n\t\tif err != nil || stateFile == \"\" {\n\t\t\tlogrus.Infof(\"Could not get ConfigMap with cluster state from host [%s]\", host.Address)\n\t\t\tcontinue\n\t\t}\n\t\treturn stateFile, nil\n\t}\n\treturn \"\", fmt.Errorf(\"[state] Unable to get ConfigMap with cluster state from any Control Plane host\")\n}", "is_vulnerable": 0}
{"code": "func verifyEnvelopeWithArtifact(verifier signature.Verifier, envelope EnvelopeContent, artifact io.Reader) error {\n\terr := verifyEnvelope(verifier, envelope)\n\tif err != nil {\n\t\treturn err\n\t}\n\tstatement, err := envelope.Statement()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not verify artifact: unable to extract statement from envelope: %w\", err)\n\t}\n\tvar artifactDigestAlgorithm string\n\tvar artifactDigest []byte\n\n\t// Determine artifact digest algorithm by looking at the first subject's\n\t// digests. This assumes that if a statement contains multiple subjects,\n\t// they all use the same digest algorithm(s).\n\tif len(statement.Subject) == 0 {\n\t\treturn errors.New(\"no subjects found in statement\")\n\t}\n\tif len(statement.Subject[0].Digest) == 0 {\n\t\treturn errors.New(\"no digests found in statement\")\n\t}\n\n\t// Select the strongest digest algorithm available.\n\tfor _, alg := range []string{\"sha512\", \"sha384\", \"sha256\"} {\n\t\tif _, ok := statement.Subject[0].Digest[alg]; ok {\n\t\t\tartifactDigestAlgorithm = alg\n\t\t\tcontinue\n\t\t}\n\t}\n\tif artifactDigestAlgorithm == \"\" {\n\t\treturn errors.New(\"could not verify artifact: unsupported digest algorithm\")\n\t}\n\n\t// Compute digest of the artifact.\n\tvar hasher hash.Hash\n\tswitch artifactDigestAlgorithm {\n\tcase \"sha512\":\n\t\thasher = crypto.SHA512.New()\n\tcase \"sha384\":\n\t\thasher = crypto.SHA384.New()\n\tcase \"sha256\":\n\t\thasher = crypto.SHA256.New()\n\t}\n\t_, err = io.Copy(hasher, artifact)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not verify artifact: unable to calculate digest: %w\", err)\n\t}\n\tartifactDigest = hasher.Sum(nil)\n\n\t// limit the number of subjects to prevent DoS\n\tif len(statement.Subject) > maxAllowedSubjects {\n\t\treturn fmt.Errorf(\"too many subjects: %d > %d\", len(statement.Subject), maxAllowedSubjects)\n\t}\n\n\t// Look for artifact digest in statement\n\tfor _, subject := range statement.Subject {\n\t\t// limit the number of digests to prevent DoS\n\t\tif len(subject.Digest) > maxAllowedSubjectDigests {\n\t\t\treturn fmt.Errorf(\"too many digests: %d > %d\", len(subject.Digest), maxAllowedSubjectDigests)\n\t\t}\n\t\tfor alg, digest := range subject.Digest {\n\t\t\thexdigest, err := hex.DecodeString(digest)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"could not verify artifact: unable to decode subject digest: %w\", err)\n\t\t\t}\n\t\t\tif alg == artifactDigestAlgorithm && bytes.Equal(artifactDigest, hexdigest) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\treturn fmt.Errorf(\"could not verify artifact: unable to confirm artifact digest is present in subject digests: %w\", err)\n}", "is_vulnerable": 0}
{"code": "func (m *Type) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowType\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Type: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Type: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fields\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Fields = append(m.Fields, &Field{})\n\t\t\tif err := m.Fields[len(m.Fields)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Oneofs\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Oneofs = append(m.Oneofs, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Options\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Options = append(m.Options, &Option{})\n\t\t\tif err := m.Options[len(m.Options)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field SourceContext\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.SourceContext == nil {\n\t\t\t\tm.SourceContext = &SourceContext{}\n\t\t\t}\n\t\t\tif err := m.SourceContext.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Syntax\", wireType)\n\t\t\t}\n\t\t\tm.Syntax = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Syntax |= Syntax(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipType(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestHelmManifestFromChartRepoWithValueFileOutsideRepo(t *testing.T) {\n\tservice := newService(\".\")\n\tsource := &argoappv1.ApplicationSource{\n\t\tChart:          \"my-chart\",\n\t\tTargetRevision: \">= 1.0.0\",\n\t\tHelm: &argoappv1.ApplicationSourceHelm{\n\t\t\tValueFiles: []string{\"../my-chart-2/my-chart-2-values.yaml\"},\n\t\t},\n\t}\n\trequest := &apiclient.ManifestRequest{Repo: &argoappv1.Repository{}, ApplicationSource: source, NoCache: true}\n\t_, err := service.GenerateManifest(context.Background(), request)\n\tassert.Error(t, err, \"should be on or under current directory\")\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(fmt.Sprintf(\"Platform %s should be supported\", scenario.platform), func(t *testing.T) {\n\t\t\ttarget := NewConfigurations(scenario.platform, nil, \"\")\n\t\t\tisSupported := target.Supported()\n\t\t\tassert.Equal(t, scenario.want, isSupported)\n\t\t})", "is_vulnerable": 0}
{"code": "func startsWithFilter(field string, value any) Sqlizer {\n\treturn Like{field: fmt.Sprintf(\"%s%%\", value)}\n}", "is_vulnerable": 0}
{"code": "func (n *remotereceivernotoken) Setup(t *testing.T) []framework.Option {\n\tn.ch = make(chan http.Header, 1)\n\tapp := app.New(t,\n\t\tapp.WithHandlerFunc(\"/helloworld\", func(w http.ResponseWriter, r *http.Request) {\n\t\t\tn.ch <- r.Header\n\t\t}),\n\t)\n\n\tn.daprd1 = daprd.New(t,\n\t\tdaprd.WithAppAPIToken(t, \"abc\"),\n\t)\n\n\tn.daprd2 = daprd.New(t,\n\t\tdaprd.WithAppPort(app.Port()),\n\t)\n\n\treturn []framework.Option{\n\t\tframework.WithProcesses(app, n.daprd1, n.daprd2),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) GrantAudience(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GrantAudience\", reflect.TypeOf((*MockAccessRequester)(nil).GrantAudience), arg0)\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tgo func(res *reverseexpand.ReverseExpandResult) {\n\t\t\t\t\tdefer func() {\n\t\t\t\t\t\t<-concurrencyLimiterCh\n\t\t\t\t\t\twg.Done()\n\t\t\t\t\t}()\n\n\t\t\t\t\tconcurrencyLimiterCh <- struct{}{}\n\t\t\t\t\tcheckRequestMetadata := graph.NewCheckRequestMetadata(q.resolveNodeLimit)\n\n\t\t\t\t\tresp, err := q.checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\t\t\t\t\tStoreID:              req.GetStoreId(),\n\t\t\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\t\t\t\t\tTupleKey:             tuple.NewTupleKey(res.Object, req.GetRelation(), req.GetUser()),\n\t\t\t\t\t\tContextualTuples:     req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\t\t\tContext:              req.GetContext(),\n\t\t\t\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t\t\t\t})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) {\n\t\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tatomic.AddUint32(resolutionMetadata.DatastoreQueryCount, resp.GetResolutionMetadata().DatastoreQueryCount)\n\t\t\t\t\tatomic.AddUint32(resolutionMetadata.DispatchCount, checkRequestMetadata.DispatchCounter.Load())\n\n\t\t\t\t\tif resp.Allowed {\n\t\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t\t}\n\t\t\t\t}(res)", "is_vulnerable": 0}
{"code": "func Pipe(p []int) error {\n\treturn Pipe2(p, 0)\n}", "is_vulnerable": 0}
{"code": "\t\tSkipper: func(c echo.Context) bool {\n\t\t\treturn c.RealIP() == \"::1\" || c.RealIP() == \"127.0.0.1\"\n\t\t\t// return true\n\t\t},\n\t\tParseTokenFunc: func(token string, c echo.Context) (interface{}, error) {\n\t\t\tclaims, code := jwt.Validate(token) // TODO - needs JWT validation\n\t\t\tif code != common_err.SUCCESS {\n\t\t\t\treturn nil, echo.ErrUnauthorized\n\t\t\t}\n\n\t\t\tc.Request().Header.Set(\"user_id\", strconv.Itoa(claims.ID))\n\n\t\t\treturn claims, nil\n\t\t},\n\t\tTokenLookupFuncs: []echo_middleware.ValuesExtractor{\n\t\t\tfunc(c echo.Context) ([]string, error) {\n\t\t\t\treturn []string{c.Request().Header.Get(echo.HeaderAuthorization)}, nil\n\t\t\t},\n\t\t},\n\t}))", "is_vulnerable": 1}
{"code": "func (o *PackageOptions) updateAdvisories(ctx context.Context, repo *git.Repository) error {\n\tcurrentDir, err := os.Getwd()\n\tif err != nil {\n\t\treturn err\n\t}\n\tgitURL, err := wolfigit.GetRemoteURLFromDir(currentDir)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// checkout repo into tmp dir so we know we are working on a clean HEAD\n\tcloneOpts := &git.CloneOptions{\n\t\tURL:               gitURL.RawURL,\n\t\tRecurseSubmodules: git.NoRecurseSubmodules,\n\t\tShallowSubmodules: true,\n\t\tAuth:              wolfigit.GetGitAuth(),\n\t\tTags:              git.AllTags,\n\t\tDepth:             20,\n\t}\n\n\ttempDir, err := os.MkdirTemp(\"\", \"wolfictl\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create temporary folder to clone package configs into: %w\", err)\n\t}\n\n\t_, err = git.PlainClone(tempDir, false, cloneOpts)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to clone repository %s into %s: %w\", o.TargetRepo, tempDir, err)\n\t}\n\n\tif _, err := os.Stat(filepath.Join(tempDir, \".git\")); os.IsNotExist(err) {\n\t\to.Logger.Println(\"skip sec fixes as we are not running update from a git repo\")\n\t\treturn nil\n\t}\n\n\t// ignore errors getting previous tags as most likely there's no existing release so should check all commits\n\tprevious, err := wolfigit.GetVersionFromTag(tempDir, 2)\n\tif err != nil {\n\t\to.Logger.Println(\"no previous tag found so checking all commits for sec fixes\")\n\t}\n\n\t// get list of commits between the previous tag and current tag\n\tcveFixes, err := o.getFixesCVEList(tempDir, previous)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get CVE list from commits between tags %s and %s: %w\", previous, o.Version, err)\n\t}\n\n\tif len(cveFixes) == 0 {\n\t\to.Logger.Printf(\"no fixes: CVE### comments found from commits between tags %s and %s, skip creating sec fix advisories\\n\", previous.Original(), o.Version)\n\t\treturn nil\n\t}\n\t// run the equivalent of `wolfictl advisory create ./foo.melange.yaml --vuln 'CVE-2022-31130' --status 'fixed' --fixed-version '7.5.17-r1'`\n\tfor _, fixComment := range cveFixes {\n\t\to.Logger.Printf(\"adding advisory for %s\\n\", fixComment)\n\t\terr = o.createAdvisories(ctx, fixComment)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to create advisory for CVE list from commits between previous tag, %s: %w\", strings.Join(cveFixes, \" \"), err)\n\t\t}\n\t}\n\n\treturn o.addCommit(repo, cveFixes)\n}", "is_vulnerable": 1}
{"code": "func (src *ErrorResponse) Encode(dst []byte) []byte {\n\treturn append(dst, src.marshalBinary('E')...)\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) CheckNameAvailabilitySender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) RunAs(ctx context.Context, in *sliverpb.RunAsReq, opts ...grpc.CallOption) (*sliverpb.RunAs, error) {\n\tout := new(sliverpb.RunAs)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/RunAs\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"with annotation in namespace/name format\", func(t *testing.T) {\n\t\ting := ingTpl.DeepCopy()\n\t\ting.ObjectMeta.SetAnnotations(map[string]string{\n\t\t\tparser.GetAnnotationWithPrefix(\"auth-secret\"): \"otherns/auth\",\n\t\t})\n\t\tif err := s.listers.Ingress.Update(ing); err != nil {\n\t\t\tt.Errorf(\"error updating the Ingress: %v\", err)\n\t\t}\n\t\ts.updateSecretIngressMap(ing)\n\n\t\tif l := s.secretIngressMap.Len(); !(l == 1 && s.secretIngressMap.Has(\"otherns/auth\")) {\n\t\t\tt.Errorf(\"Expected \\\"otherns/auth\\\" to be the only referenced Secret (got %d)\", l)\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func (s *MemoryStore) SetClientAssertionJWT(_ context.Context, jti string, exp time.Time) error {\n\t// delete expired jtis\n\tfor j, e := range s.BlacklistedJTIs {\n\t\tif e.Before(time.Now()) {\n\t\t\tdelete(s.BlacklistedJTIs, j)\n\t\t}\n\t}\n\n\tif _, exists := s.BlacklistedJTIs[jti]; exists {\n\t\treturn fosite.ErrJTIKnown\n\t}\n\n\ts.BlacklistedJTIs[jti] = exp\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (b *BasicEnvoyExtender) patchTProxyListener(config *RuntimeConfig, l *envoy_listener_v3.Listener) (proto.Message, bool, error) {\n\tvar resultErr error\n\tpatched := false\n\n\tvip := config.Upstreams[config.ServiceName].VIP\n\n\tfor _, filterChain := range l.FilterChains {\n\t\tvar filters []*envoy_listener_v3.Filter\n\n\t\tmatch := filterChainTProxyMatch(vip, filterChain)\n\t\tif !match {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, filter := range filterChain.Filters {\n\t\t\tnewFilter, ok, err := b.Extension.PatchFilter(config, filter, IsInboundPublicListener(l))\n\t\t\tif err != nil {\n\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching listener filter: %w\", err))\n\t\t\t\tfilters = append(filters, filter)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ok {\n\t\t\t\tfilters = append(filters, newFilter)\n\t\t\t\tpatched = true\n\t\t\t} else {\n\t\t\t\tfilters = append(filters, filter)\n\t\t\t}\n\t\t}\n\t\tfilterChain.Filters = filters\n\t}\n\n\treturn l, patched, resultErr\n}", "is_vulnerable": 0}
{"code": "func (acl *ACL) Add(svc string, r Rule) error {\n\terr := acl.PolicyDisabled(svc, r.Policy)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = acl.ValidateDomainGlobs(svc, r.DomainGlobs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, ok := acl.Rules[svc]; ok {\n\t\treturn fmt.Errorf(\"rule already exists for service %v\", svc)\n\t}\n\tacl.Rules[svc] = r\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.GetRoute()\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"received a request, processing it...\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Desugar().Error(\"failed to parse request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\treturn\n\t}\n\n\tevent := &events.BitbucketEventData{\n\t\tHeaders:  request.Header,\n\t\tBody:     (*json.RawMessage)(&body),\n\t\tMetadata: router.bitbucketEventSource.Metadata,\n\t}\n\n\teventBody, err := json.Marshal(event)\n\tif err != nil {\n\t\tlogger.Info(\"failed to marshal event\")\n\t\tcommon.SendErrorResponse(writer, \"invalid event\")\n\t\treturn\n\t}\n\n\tlogger.Info(\"dispatching event on route's data channel\")\n\troute.DataCh <- eventBody\n\n\tlogger.Info(\"request successfully processed\")\n\tcommon.SendSuccessResponse(writer, \"success\")\n}", "is_vulnerable": 0}
{"code": "func (s *store) Delete(\n\tctx context.Context, key string, out runtime.Object, preconditions *storage.Preconditions,\n\tvalidateDeletion storage.ValidateObjectFunc, cachedExistingObject runtime.Object) error {\n\tv, err := conversion.EnforcePtr(out)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to convert output object to pointer: %v\", err)\n\t}\n\tkey = path.Join(s.pathPrefix, key)\n\treturn s.conditionalDelete(ctx, key, out, v, preconditions, validateDeletion, cachedExistingObject)\n}", "is_vulnerable": 1}
{"code": "func (s *CipherState) Decrypt(out, ad, ciphertext []byte) ([]byte, error) {\n\tif s.invalid {\n\t\treturn nil, ErrCipherSuiteCopied\n\t}\n\tif s.n > MaxNonce {\n\t\treturn nil, ErrMaxNonce\n\t}\n\tout, err := s.c.Decrypt(out, s.n, ad, ciphertext)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ts.n++\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (cephfsVolume *cephfs) execMount(mountpoint string) error {\n\t// cephfs mount option\n\tcephSensitiveOpt := []string{\"name=\" + cephfsVolume.id}\n\t// override secretfile if secret is provided\n\tif cephfsVolume.secret != \"\" {\n\t\tcephSensitiveOpt = append(cephSensitiveOpt, \"secret=\"+cephfsVolume.secret)\n\t} else {\n\t\tcephSensitiveOpt = append(cephSensitiveOpt, \"secretfile=\"+cephfsVolume.secretFile)\n\t}\n\t// build option array\n\topt := []string{}\n\tif cephfsVolume.readonly {\n\t\topt = append(opt, \"ro\")\n\t}\n\n\t// build src like mon1:6789,mon2:6789,mon3:6789:/\n\tsrc := strings.Join(cephfsVolume.mon, \",\") + \":\" + cephfsVolume.path\n\n\topt = util.JoinMountOptions(cephfsVolume.mountOptions, opt)\n\tif err := cephfsVolume.mounter.MountSensitive(src, mountpoint, \"ceph\", opt, cephSensitiveOpt); err != nil {\n\t\treturn fmt.Errorf(\"CephFS: mount failed: %v\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (self *InventoryService) UpdateVersion(tool_request *artifacts_proto.Tool) {\n\tself.mu.Lock()\n\tdefer self.mu.Unlock()\n\n\t// Update the list of version for this tool, replacing existing\n\t// definitions.\n\tversions, _ := self.versions[tool_request.Name]\n\tversion_known := false\n\tfor idx, v := range versions {\n\t\tif v.Artifact == tool_request.Artifact {\n\t\t\tversions[idx] = tool_request\n\t\t\tversion_known = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif !version_known {\n\t\tversions = append(versions, proto.Clone(tool_request).(*artifacts_proto.Tool))\n\t}\n\tself.versions[tool_request.Name] = versions\n}", "is_vulnerable": 1}
{"code": "func (a ipallowlist) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, allowlistAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Chmod(ctx context.Context, in *sliverpb.ChmodReq, opts ...grpc.CallOption) (*sliverpb.Chmod, error) {\n\tout := new(sliverpb.Chmod)\n\terr := c.cc.Invoke(ctx, SliverRPC_Chmod_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\treturn func(\n\t\turl string,\n\t\targs map[string]interface{},\n\t\tmessageType string,\n\t\tallowUnverifiedNotificationChannel bool,\n\t) error {\n\t\targs = mapNotifyUserToArgs(user, args)\n\t\tsanitizeArgsForHTML(args)\n\t\tdata := GetTemplateData(ctx, translator, args, url, messageType, user.PreferredLanguage.String(), colors)\n\t\ttemplate, err := templates.GetParsedTemplate(mailhtml, data)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn generateEmail(\n\t\t\tctx,\n\t\t\tchannels,\n\t\t\tuser,\n\t\t\tdata.Subject,\n\t\t\ttemplate,\n\t\t\tallowUnverifiedNotificationChannel,\n\t\t\ttriggeringEvent,\n\t\t)\n\t}", "is_vulnerable": 0}
{"code": "func (k *Key) ClientSSHConfig() (*ssh.ClientConfig, error) {\n\tusername, err := k.CertUsername()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to extract username from SSH certificate\")\n\t}\n\tauthMethod, err := k.AsAuthMethod()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert identity file to auth method\")\n\t}\n\thostKeyCallback, err := k.HostKeyCallback()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed to convert identity file to HostKeyCallback\")\n\t}\n\treturn &ssh.ClientConfig{\n\t\tUser:            username,\n\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\tHostKeyCallback: hostKeyCallback,\n\t\tTimeout:         defaults.DefaultDialTimeout,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func TestSHA512_256(t *testing.T) {\n\tinput := [][]byte{[]byte(\"abc\"), []byte(\"def\"), []byte(\"ghi\")}\n\tinput2 := [][]byte{[]byte(\"abc\"), []byte(\"def\"), []byte(\"gh\")}\n\ttype args struct {\n\t\tin [][]byte\n\t}\n\ttests := []struct {\n\t\tname     string\n\t\targs     args\n\t\twant     []byte\n\t\twantDiff bool\n\t\twantLen  int\n\t}{{\n\t\tname:    \"same inputs produce the same hash\",\n\t\targs:    args{input},\n\t\twant:    SHA512_256(input...),\n\t\twantLen: 256 / 8,\n\t}, {\n\t\tname:     \"different inputs produce a differing hash\",\n\t\targs:     args{input2},\n\t\twant:     SHA512_256(input...),\n\t\twantDiff: true,\n\t\twantLen:  256 / 8,\n\t}}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot := SHA512_256(tt.args.in...)\n\t\t\tif tt.wantDiff {\n\t\t\t\tif !assert.NotEqualf(t, tt.want, got, \"SHA512_256(%v)\", tt.args.in) {\n\t\t\t\t\tt.Errorf(\"SHA512_256() = %v, do not want %v\", got, tt.want)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif !assert.Equalf(t, tt.want, got, \"SHA512_256(%v)\", tt.args.in) {\n\t\t\t\t\tt.Errorf(\"SHA512_256() = %v, want %v\", got, tt.want)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif tt.wantLen != len(got) {\n\t\t\t\tt.Errorf(\"SHA512_256() = bitlen %d, want %d\", len(got), tt.wantLen)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestHandler_ProcessAtxStoresNewVRFNonce(t *testing.T) {\n\t// Arrange\n\tgoldenATXID := types.ATXID{2, 3, 4}\n\tatxHdlr := newTestHandler(t, goldenATXID)\n\n\tsig, err := signing.NewEdSigner()\n\trequire.NoError(t, err)\n\n\tcoinbase := types.GenerateAddress([]byte(\"aaaa\"))\n\n\t// Act & Assert\n\tatx1 := newActivationTx(\n\t\tt,\n\t\tsig,\n\t\t0,\n\t\ttypes.EmptyATXID,\n\t\ttypes.EmptyATXID,\n\t\tnil,\n\t\ttypes.EpochID(2),\n\t\t0,\n\t\t100,\n\t\tcoinbase,\n\t\t100,\n\t\t&types.NIPost{PostMetadata: &types.PostMetadata{}},\n\t)\n\tnonce1 := types.VRFPostIndex(123)\n\tatx1.VRFNonce = &nonce1\n\tatxHdlr.mbeacon.EXPECT().OnAtx(gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnAtx(gomock.Any(), gomock.Any(), gomock.Any())\n\tproof, err := atxHdlr.processVerifiedATX(context.Background(), atx1)\n\trequire.NoError(t, err)\n\trequire.Nil(t, proof)\n\n\tgot, err := atxs.VRFNonce(atxHdlr.cdb, sig.NodeID(), atx1.TargetEpoch())\n\trequire.NoError(t, err)\n\trequire.Equal(t, nonce1, got)\n\n\t// another atx for the same epoch is considered malicious\n\tatx2 := newActivationTx(\n\t\tt,\n\t\tsig,\n\t\t1,\n\t\tatx1.ID(),\n\t\tatx1.ID(),\n\t\tnil,\n\t\ttypes.EpochID(3),\n\t\t0,\n\t\t100,\n\t\tcoinbase,\n\t\t100,\n\t\t&types.NIPost{PostMetadata: &types.PostMetadata{}},\n\t)\n\tnonce2 := types.VRFPostIndex(456)\n\tatx2.VRFNonce = &nonce2\n\tatxHdlr.mbeacon.EXPECT().OnAtx(gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnAtx(gomock.Any(), gomock.Any(), gomock.Any())\n\tproof, err = atxHdlr.processVerifiedATX(context.Background(), atx2)\n\trequire.NoError(t, err)\n\trequire.Nil(t, proof)\n\n\tgot, err = atxs.VRFNonce(atxHdlr.cdb, sig.NodeID(), atx2.TargetEpoch())\n\trequire.NoError(t, err)\n\trequire.Equal(t, nonce2, got)\n}", "is_vulnerable": 0}
{"code": "func isSymbolLink(filepath string) (bool, error) {\n\tfi, err := os.Lstat(path.Clean(filepath))\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif fi.Mode()&os.ModeSymlink != 0 {\n\t\treturn true, nil\n\t}\n\treturn false, nil\n}", "is_vulnerable": 0}
{"code": "func addInstallFlags(cmd *cobra.Command, f *pflag.FlagSet, client *action.Install, valueOpts *values.Options) {\n\tf.BoolVar(&client.CreateNamespace, \"create-namespace\", false, \"create the release namespace if not present\")\n\tf.BoolVar(&client.DryRun, \"dry-run\", false, \"simulate an install\")\n\tf.BoolVar(&client.Force, \"force\", false, \"force resource updates through a replacement strategy\")\n\tf.BoolVar(&client.DisableHooks, \"no-hooks\", false, \"prevent hooks from running during install\")\n\tf.BoolVar(&client.Replace, \"replace\", false, \"re-use the given name, only if that name is a deleted release which remains in the history. This is unsafe in production\")\n\tf.DurationVar(&client.Timeout, \"timeout\", 300*time.Second, \"time to wait for any individual Kubernetes operation (like Jobs for hooks)\")\n\tf.BoolVar(&client.Wait, \"wait\", false, \"if set, will wait until all Pods, PVCs, Services, and minimum number of Pods of a Deployment, StatefulSet, or ReplicaSet are in a ready state before marking the release as successful. It will wait for as long as --timeout\")\n\tf.BoolVar(&client.WaitForJobs, \"wait-for-jobs\", false, \"if set and --wait enabled, will wait until all Jobs have been completed before marking the release as successful. It will wait for as long as --timeout\")\n\tf.BoolVarP(&client.GenerateName, \"generate-name\", \"g\", false, \"generate the name (and omit the NAME parameter)\")\n\tf.StringVar(&client.NameTemplate, \"name-template\", \"\", \"specify template used to name the release\")\n\tf.StringVar(&client.Description, \"description\", \"\", \"add a custom description\")\n\tf.BoolVar(&client.Devel, \"devel\", false, \"use development versions, too. Equivalent to version '>0.0.0-0'. If --version is set, this is ignored\")\n\tf.BoolVar(&client.DependencyUpdate, \"dependency-update\", false, \"update dependencies if they are missing before installing the chart\")\n\tf.BoolVar(&client.DisableOpenAPIValidation, \"disable-openapi-validation\", false, \"if set, the installation process will not validate rendered templates against the Kubernetes OpenAPI Schema\")\n\tf.BoolVar(&client.Atomic, \"atomic\", false, \"if set, the installation process deletes the installation on failure. The --wait flag will be set automatically if --atomic is used\")\n\tf.BoolVar(&client.SkipCRDs, \"skip-crds\", false, \"if set, no CRDs will be installed. By default, CRDs are installed if not already present\")\n\tf.BoolVar(&client.SubNotes, \"render-subchart-notes\", false, \"if set, render subchart notes along with the parent\")\n\tf.BoolVar(&client.EnableDNS, \"enable-dns\", false, \"enable DNS lookups when rendering templates\")\n\taddValueOptionsFlags(f, valueOpts)\n\taddChartPathOptionsFlags(f, &client.ChartPathOptions)\n\n\terr := cmd.RegisterFlagCompletionFunc(\"version\", func(cmd *cobra.Command, args []string, toComplete string) ([]string, cobra.ShellCompDirective) {\n\t\trequiredArgs := 2\n\t\tif client.GenerateName {\n\t\t\trequiredArgs = 1\n\t\t}\n\t\tif len(args) != requiredArgs {\n\t\t\treturn nil, cobra.ShellCompDirectiveNoFileComp\n\t\t}\n\t\treturn compVersionFlag(args[requiredArgs-1], toComplete)\n\t})\n\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tsyncOptionsFactory := func() *application.SyncOptions {\n\t\t\t\t\tsyncOptions := application.SyncOptions{}\n\t\t\t\t\titems := make([]string, 0)\n\t\t\t\t\tif replace {\n\t\t\t\t\t\titems = append(items, common.SyncOptionReplace)\n\t\t\t\t\t}\n\t\t\t\t\tif serverSideApply {\n\t\t\t\t\t\titems = append(items, common.SyncOptionServerSideApply)\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(items) == 0 {\n\t\t\t\t\t\t// for prevent send even empty array if not need\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\t\t\t\t\tsyncOptions.Items = items\n\t\t\t\t\treturn &syncOptions\n\t\t\t\t}\n\n\t\t\t\tsyncReq := application.ApplicationSyncRequest{\n\t\t\t\t\tName:         &appName,\n\t\t\t\t\tAppNamespace: &appNs,\n\t\t\t\t\tDryRun:       &dryRun,\n\t\t\t\t\tRevision:     &revision,\n\t\t\t\t\tResources:    filteredResources,\n\t\t\t\t\tPrune:        &prune,\n\t\t\t\t\tManifests:    localObjsStrings,\n\t\t\t\t\tInfos:        getInfos(infos),\n\t\t\t\t\tSyncOptions:  syncOptionsFactory(),\n\t\t\t\t}\n\n\t\t\t\tswitch strategy {\n\t\t\t\tcase \"apply\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Apply: &argoappv1.SyncStrategyApply{}}\n\t\t\t\t\tsyncReq.Strategy.Apply.Force = force\n\t\t\t\tcase \"\", \"hook\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Hook: &argoappv1.SyncStrategyHook{}}\n\t\t\t\t\tsyncReq.Strategy.Hook.Force = force\n\t\t\t\tdefault:\n\t\t\t\t\tlog.Fatalf(\"Unknown sync strategy: '%s'\", strategy)\n\t\t\t\t}\n\t\t\t\tif retryLimit > 0 {\n\t\t\t\t\tsyncReq.RetryStrategy = &argoappv1.RetryStrategy{\n\t\t\t\t\t\tLimit: retryLimit,\n\t\t\t\t\t\tBackoff: &argoappv1.Backoff{\n\t\t\t\t\t\t\tDuration:    retryBackoffDuration.String(),\n\t\t\t\t\t\t\tMaxDuration: retryBackoffMaxDuration.String(),\n\t\t\t\t\t\t\tFactor:      pointer.Int64Ptr(retryBackoffFactor),\n\t\t\t\t\t\t},\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif diffChanges {\n\t\t\t\t\tresources, err := appIf.ManagedResources(ctx, &application.ResourcesQuery{\n\t\t\t\t\t\tApplicationName: &appName,\n\t\t\t\t\t\tAppNamespace:    &appNs,\n\t\t\t\t\t})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tconn, settingsIf := acdClient.NewSettingsClientOrDie()\n\t\t\t\t\tdefer argoio.Close(conn)\n\t\t\t\t\targoSettings, err := settingsIf.Get(ctx, &settings.SettingsQuery{})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tfoundDiffs := false\n\t\t\t\t\tfmt.Printf(\"====== Previewing differences between live and desired state of application %s ======\\n\", appQualifiedName)\n\n\t\t\t\t\tfoundDiffs = findandPrintDiff(ctx, app, resources, argoSettings, diffOption)\n\t\t\t\t\tif foundDiffs {\n\t\t\t\t\t\tif !diffChangesConfirm {\n\t\t\t\t\t\t\tyesno := cli.AskToProceed(fmt.Sprintf(\"Please review changes to application %s shown above. Do you want to continue the sync process? (y/n): \", appQualifiedName))\n\t\t\t\t\t\t\tif !yesno {\n\t\t\t\t\t\t\t\tos.Exit(0)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfmt.Printf(\"====== No Differences found ======\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_, err = appIf.Sync(ctx, &syncReq)\n\t\t\t\terrors.CheckError(err)\n\n\t\t\t\tif !async {\n\t\t\t\t\tapp, opState, err := waitOnApplicationStatus(ctx, acdClient, appQualifiedName, timeout, watchOpts{operation: true}, selectedResources)\n\t\t\t\t\terrors.CheckError(err)\n\n\t\t\t\t\tif !dryRun {\n\t\t\t\t\t\tif !opState.Phase.Successful() {\n\t\t\t\t\t\t\tlog.Fatalf(\"Operation has completed with phase: %s\", opState.Phase)\n\t\t\t\t\t\t} else if len(selectedResources) == 0 && app.Status.Sync.Status != argoappv1.SyncStatusCodeSynced {\n\t\t\t\t\t\t\t// Only get resources to be pruned if sync was application-wide and final status is not synced\n\t\t\t\t\t\t\tpruningRequired := opState.SyncResult.Resources.PruningRequired()\n\t\t\t\t\t\t\tif pruningRequired > 0 {\n\t\t\t\t\t\t\t\tlog.Fatalf(\"%d resources require pruning\", pruningRequired)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t},", "is_vulnerable": 1}
{"code": "func (t *Teler) checkBadCrawler(r *http.Request) error {\n\t// Retrieve the User-Agent from the request\n\tua := r.UserAgent()\n\n\t// Do not process the check if User-Agent is empty\n\tif ua == \"\" {\n\t\treturn nil\n\t}\n\n\t// Iterate over BadCrawler compiled patterns and do the check\n\tfor _, pattern := range t.threat.badCrawler {\n\t\t// Initialize a variable to track whether a match is found\n\t\tvar match bool\n\n\t\t// Check the type of the pattern\n\t\tswitch p := pattern.(type) {\n\t\tcase *regexp.Regexp: // If the pattern is a regex\n\t\t\tmatch = p.MatchString(ua)\n\t\tcase *pcre.Matcher: // If the pattern is a PCRE expr\n\t\t\tmatch = p.MatchString(ua, 0)\n\t\tdefault: // If the pattern is of an unknown type, skip to the next iteration\n\t\t\tcontinue\n\t\t}\n\n\t\t// Check if the pattern is not nil and matches the User-Agent\n\t\tif match {\n\t\t\treturn errors.New(\"bad crawler\")\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func Render(tmpl string, s *types.Step) (types.StepSlice, error) {\n\tbuffer := new(bytes.Buffer)\n\tconfig := new(types.Build)\n\n\tvelaFuncs := funcHandler{envs: convertPlatformVars(s.Environment)}\n\ttemplateFuncMap := map[string]interface{}{\n\t\t\"vela\": velaFuncs.returnPlatformVar,\n\t}\n\t// modify Masterminds/sprig functions\n\t// to remove OS functions\n\t//\n\t// https://masterminds.github.io/sprig/os.html\n\tsf := sprig.TxtFuncMap()\n\tdelete(sf, \"env\")\n\tdelete(sf, \"expandenv\")\n\n\t// parse the template with Masterminds/sprig functions\n\t//\n\t// https://pkg.go.dev/github.com/Masterminds/sprig?tab=doc#TxtFuncMap\n\tt, err := template.New(s.Name).Funcs(sf).Funcs(templateFuncMap).Parse(tmpl)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to parse template %s: %v\", s.Template.Name, err)\n\t}\n\n\t// apply the variables to the parsed template\n\terr = t.Execute(buffer, s.Template.Variables)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to execute template %s: %v\", s.Template.Name, err)\n\t}\n\n\t// unmarshal the template to the pipeline\n\terr = yaml.Unmarshal(buffer.Bytes(), config)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to unmarshal yaml: %v\", err)\n\t}\n\n\t// ensure all templated steps have template prefix\n\tfor index, newStep := range config.Steps {\n\t\tconfig.Steps[index].Name = fmt.Sprintf(\"%s_%s\", s.Name, newStep.Name)\n\t}\n\n\treturn config.Steps, nil\n}", "is_vulnerable": 0}
{"code": "func (client ProvidersClient) GetSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "\tproject, err := loader.Load(configDetails, func(options *loader.Options) {\n\t\toptions.SetProjectName(\"dashboard\", true)\n\t})", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) WGStopSocks(ctx context.Context, in *sliverpb.WGSocksStopReq, opts ...grpc.CallOption) (*sliverpb.WGSocks, error) {\n\tout := new(sliverpb.WGSocks)\n\terr := c.cc.Invoke(ctx, SliverRPC_WGStopSocks_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func obtainAuthorizationToken(endpoint string, subscriptionId string) (*cli.Token, error) {\n\tvar stderr bytes.Buffer\n\tvar stdout bytes.Buffer\n\n\tcmd := exec.Command(\"az\", \"account\", \"get-access-token\", \"--resource\", endpoint, \"--subscription\", subscriptionId, \"-o=json\")\n\n\tcmd.Stderr = &stderr\n\tcmd.Stdout = &stdout\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn nil, fmt.Errorf(\"Error launching Azure CLI: %+v\", err)\n\t}\n\n\tif err := cmd.Wait(); err != nil {\n\t\treturn nil, fmt.Errorf(\"Error waiting for the Azure CLI: %+v\", err)\n\t}\n\n\tstdOutStr := stdout.String()\n\tstdErrStr := stderr.String()\n\n\tif stdErrStr != \"\" {\n\t\treturn nil, fmt.Errorf(\"Error retrieving access token from Azure CLI: %s\", strings.TrimSpace(stdErrStr))\n\t}\n\n\tvar token *cli.Token\n\terr := json.Unmarshal([]byte(stdOutStr), &token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error unmarshaling Access Token from the Azure CLI: %s\", err)\n\t}\n\n\treturn token, nil\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tbroadcast := func(webConn *WebConn) {\n\t\t\t\t\tif !connIndex.Has(webConn) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif webConn.ShouldSendEvent(msg) {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase webConn.send <- h.runBroadcastHooks(msg, webConn, broadcastHooks, broadcastHookArgs):\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t// Don't log the warning if it's an inactive connection.\n\t\t\t\t\t\t\tif webConn.active.Load() {\n\t\t\t\t\t\t\t\tmlog.Error(\"webhub.broadcast: cannot send, closing websocket for user\",\n\t\t\t\t\t\t\t\t\tmlog.String(\"user_id\", webConn.UserId),\n\t\t\t\t\t\t\t\t\tmlog.String(\"conn_id\", webConn.GetConnectionID()))\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tclose(webConn.send)\n\t\t\t\t\t\t\tconnIndex.Remove(webConn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}", "is_vulnerable": 0}
{"code": "func (c *managedIdentityClient) createAccessToken(res *http.Response) (azcore.AccessToken, error) {\n\tvalue := struct {\n\t\t// these are the only fields that we use\n\t\tToken        string        `json:\"access_token,omitempty\"`\n\t\tRefreshToken string        `json:\"refresh_token,omitempty\"`\n\t\tExpiresIn    wrappedNumber `json:\"expires_in,omitempty\"` // this field should always return the number of seconds for which a token is valid\n\t\tExpiresOn    interface{}   `json:\"expires_on,omitempty\"` // the value returned in this field varies between a number and a date string\n\t}{}\n\tif err := runtime.UnmarshalAsJSON(res, &value); err != nil {\n\t\treturn azcore.AccessToken{}, fmt.Errorf(\"internal AccessToken: %v\", err)\n\t}\n\tif value.ExpiresIn != \"\" {\n\t\texpiresIn, err := json.Number(value.ExpiresIn).Int64()\n\t\tif err != nil {\n\t\t\treturn azcore.AccessToken{}, err\n\t\t}\n\t\treturn azcore.AccessToken{Token: value.Token, ExpiresOn: time.Now().Add(time.Second * time.Duration(expiresIn)).UTC()}, nil\n\t}\n\tswitch v := value.ExpiresOn.(type) {\n\tcase float64:\n\t\treturn azcore.AccessToken{Token: value.Token, ExpiresOn: time.Unix(int64(v), 0).UTC()}, nil\n\tcase string:\n\t\tif expiresOn, err := strconv.Atoi(v); err == nil {\n\t\t\treturn azcore.AccessToken{Token: value.Token, ExpiresOn: time.Unix(int64(expiresOn), 0).UTC()}, nil\n\t\t}\n\t\treturn azcore.AccessToken{}, newAuthenticationFailedError(credNameManagedIdentity, \"unexpected expires_on value: \"+v, res, nil)\n\tdefault:\n\t\tmsg := fmt.Sprintf(\"unsupported type received in expires_on: %T, %v\", v, v)\n\t\treturn azcore.AccessToken{}, newAuthenticationFailedError(credNameManagedIdentity, msg, res, nil)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *Server) Backup(b backup.BackupInterface) error {\n\tignored := b.Ignored()\n\tif b.Ignored() == \"\" {\n\t\tif i, err := s.getServerwideIgnoredFiles(); err != nil {\n\t\t\tlog.WithField(\"server\", s.ID()).WithField(\"error\", err).Warn(\"failed to get server-wide ignored files\")\n\t\t} else {\n\t\t\tignored = i\n\t\t}\n\t}\n\n\tad, err := b.Generate(s.Context(), s.Filesystem().Path(), ignored)\n\tif err != nil {\n\t\tif err := s.notifyPanelOfBackup(b.Identifier(), &backup.ArchiveDetails{}, false); err != nil {\n\t\t\ts.Log().WithFields(log.Fields{\n\t\t\t\t\"backup\": b.Identifier(),\n\t\t\t\t\"error\":  err,\n\t\t\t}).Warn(\"failed to notify panel of failed backup state\")\n\t\t} else {\n\t\t\ts.Log().WithField(\"backup\", b.Identifier()).Info(\"notified panel of failed backup state\")\n\t\t}\n\n\t\ts.Events().Publish(BackupCompletedEvent+\":\"+b.Identifier(), map[string]interface{}{\n\t\t\t\"uuid\":          b.Identifier(),\n\t\t\t\"is_successful\": false,\n\t\t\t\"checksum\":      \"\",\n\t\t\t\"checksum_type\": \"sha1\",\n\t\t\t\"file_size\":     0,\n\t\t})\n\n\t\treturn errors.WrapIf(err, \"backup: error while generating server backup\")\n\t}\n\n\t// Try to notify the panel about the status of this backup. If for some reason this request\n\t// fails, delete the archive from the daemon and return that error up the chain to the caller.\n\tif notifyError := s.notifyPanelOfBackup(b.Identifier(), ad, true); notifyError != nil {\n\t\t_ = b.Remove()\n\n\t\ts.Log().WithField(\"error\", notifyError).Info(\"failed to notify panel of successful backup state\")\n\t\treturn err\n\t} else {\n\t\ts.Log().WithField(\"backup\", b.Identifier()).Info(\"notified panel of successful backup state\")\n\t}\n\n\t// Emit an event over the socket so we can update the backup in realtime on\n\t// the frontend for the server.\n\ts.Events().Publish(BackupCompletedEvent+\":\"+b.Identifier(), map[string]interface{}{\n\t\t\"uuid\":          b.Identifier(),\n\t\t\"is_successful\": true,\n\t\t\"checksum\":      ad.Checksum,\n\t\t\"checksum_type\": \"sha1\",\n\t\t\"file_size\":     ad.Size,\n\t})\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func parseObject(c *parseContext, i int, path string) (int, bool) {\n\tvar pmatch, kesc, vesc, ok, hit bool\n\tvar key, val string\n\trp := parseObjectPath(path)\n\tif !rp.more && rp.piped {\n\t\tc.pipe = rp.pipe\n\t\tc.piped = true\n\t}\n\tfor i < len(c.json) {\n\t\tfor ; i < len(c.json); i++ {\n\t\t\tif c.json[i] == '\"' {\n\t\t\t\t// parse_key_string\n\t\t\t\t// this is slightly different from getting s string value\n\t\t\t\t// because we don't need the outer quotes.\n\t\t\t\ti++\n\t\t\t\tvar s = i\n\t\t\t\tfor ; i < len(c.json); i++ {\n\t\t\t\t\tif c.json[i] > '\\\\' {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif c.json[i] == '\"' {\n\t\t\t\t\t\ti, key, kesc, ok = i+1, c.json[s:i], false, true\n\t\t\t\t\t\tgoto parse_key_string_done\n\t\t\t\t\t}\n\t\t\t\t\tif c.json[i] == '\\\\' {\n\t\t\t\t\t\ti++\n\t\t\t\t\t\tfor ; i < len(c.json); i++ {\n\t\t\t\t\t\t\tif c.json[i] > '\\\\' {\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif c.json[i] == '\"' {\n\t\t\t\t\t\t\t\t// look for an escaped slash\n\t\t\t\t\t\t\t\tif c.json[i-1] == '\\\\' {\n\t\t\t\t\t\t\t\t\tn := 0\n\t\t\t\t\t\t\t\t\tfor j := i - 2; j > 0; j-- {\n\t\t\t\t\t\t\t\t\t\tif c.json[j] != '\\\\' {\n\t\t\t\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tn++\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif n%2 == 0 {\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\ti, key, kesc, ok = i+1, c.json[s:i], true, true\n\t\t\t\t\t\t\t\tgoto parse_key_string_done\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tkey, kesc, ok = c.json[s:], false, false\n\t\t\tparse_key_string_done:\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif c.json[i] == '}' {\n\t\t\t\treturn i + 1, false\n\t\t\t}\n\t\t}\n\t\tif !ok {\n\t\t\treturn i, false\n\t\t}\n\t\tif rp.wild {\n\t\t\tif kesc {\n\t\t\t\tpmatch = match.Match(unescape(key), rp.part)\n\t\t\t} else {\n\t\t\t\tpmatch = match.Match(key, rp.part)\n\t\t\t}\n\t\t} else {\n\t\t\tif kesc {\n\t\t\t\tpmatch = rp.part == unescape(key)\n\t\t\t} else {\n\t\t\t\tpmatch = rp.part == key\n\t\t\t}\n\t\t}\n\t\thit = pmatch && !rp.more\n\t\tfor ; i < len(c.json); i++ {\n\t\t\tswitch c.json[i] {\n\t\t\tdefault:\n\t\t\t\tcontinue\n\t\t\tcase '\"':\n\t\t\t\ti++\n\t\t\t\ti, val, vesc, ok = parseString(c.json, i)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn i, false\n\t\t\t\t}\n\t\t\t\tif hit {\n\t\t\t\t\tif vesc {\n\t\t\t\t\t\tc.value.Str = unescape(val[1 : len(val)-1])\n\t\t\t\t\t} else {\n\t\t\t\t\t\tc.value.Str = val[1 : len(val)-1]\n\t\t\t\t\t}\n\t\t\t\t\tc.value.Raw = val\n\t\t\t\t\tc.value.Type = String\n\t\t\t\t\treturn i, true\n\t\t\t\t}\n\t\t\tcase '{':\n\t\t\t\tif pmatch && !hit {\n\t\t\t\t\ti, hit = parseObject(c, i+1, rp.path)\n\t\t\t\t\tif hit {\n\t\t\t\t\t\treturn i, true\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\ti, val = parseSquash(c.json, i)\n\t\t\t\t\tif hit {\n\t\t\t\t\t\tc.value.Raw = val\n\t\t\t\t\t\tc.value.Type = JSON\n\t\t\t\t\t\treturn i, true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase '[':\n\t\t\t\tif pmatch && !hit {\n\t\t\t\t\ti, hit = parseArray(c, i+1, rp.path)\n\t\t\t\t\tif hit {\n\t\t\t\t\t\treturn i, true\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\ti, val = parseSquash(c.json, i)\n\t\t\t\t\tif hit {\n\t\t\t\t\t\tc.value.Raw = val\n\t\t\t\t\t\tc.value.Type = JSON\n\t\t\t\t\t\treturn i, true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':\n\t\t\t\ti, val = parseNumber(c.json, i)\n\t\t\t\tif hit {\n\t\t\t\t\tc.value.Raw = val\n\t\t\t\t\tc.value.Type = Number\n\t\t\t\t\tc.value.Num, _ = strconv.ParseFloat(val, 64)\n\t\t\t\t\treturn i, true\n\t\t\t\t}\n\t\t\tcase 't', 'f', 'n':\n\t\t\t\tvc := c.json[i]\n\t\t\t\ti, val = parseLiteral(c.json, i)\n\t\t\t\tif hit {\n\t\t\t\t\tc.value.Raw = val\n\t\t\t\t\tswitch vc {\n\t\t\t\t\tcase 't':\n\t\t\t\t\t\tc.value.Type = True\n\t\t\t\t\tcase 'f':\n\t\t\t\t\t\tc.value.Type = False\n\t\t\t\t\t}\n\t\t\t\t\treturn i, true\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn i, false\n}", "is_vulnerable": 1}
{"code": "func verifyAud(aud ClaimStrings, cmp string, required bool) bool {\n\tif len(aud) == 0 {\n\t\treturn !required\n\t}\n\tfor _, audStr := range aud {\n\t\tif subtle.ConstantTimeCompare([]byte(audStr), []byte(cmp)) != 0 {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (wr FrameWriteRequest) isControl() bool {\n\treturn wr.stream == nil\n}", "is_vulnerable": 0}
{"code": "func TestVerbose(t *testing.T) {\n\ttests := []struct {\n\t\tname string\n\t\targs []string\n\t\twant string\n\t}{\n\t\t{\n\t\t\tname: \"verbose as version's flag\",\n\t\t\targs: []string{\"version\", \"-v\"},\n\t\t\twant: \"v0.42.0-cafe-1970-01-01\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"no verbose\",\n\t\t\targs: []string{\"version\"},\n\t\t\twant: \"v0.42.0\\n\",\n\t\t},\n\t\t{\n\t\t\tname: \"verbose as root's flag\",\n\t\t\targs: []string{\"--verbose\", \"version\"},\n\t\t\twant: \"v0.42.0-cafe-1970-01-01\\n\",\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tviper.Reset()\n\n\t\t\tvar out bytes.Buffer\n\n\t\t\tcmd := NewRootCmd(RootCommandConfig{\n\t\t\t\tName: \"func\",\n\t\t\t\tVersion: Version{\n\t\t\t\t\tDate: \"1970-01-01\",\n\t\t\t\t\tVers: \"v0.42.0\",\n\t\t\t\t\tHash: \"cafe\",\n\t\t\t\t}})\n\n\t\t\tcmd.SetArgs(tt.args)\n\t\t\tcmd.SetOut(&out)\n\t\t\tif err := cmd.Execute(); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tif out.String() != tt.want {\n\t\t\t\tt.Errorf(\"expected output: %q but got: %q\", tt.want, out.String())\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (k Keeper) ConvertVestingAccount(\n\tgoCtx context.Context,\n\tmsg *types.MsgConvertVestingAccount,\n) (*types.MsgConvertVestingAccountResponse, error) {\n\tctx := sdk.UnwrapSDKContext(goCtx)\n\taddress := sdk.MustAccAddressFromBech32(msg.VestingAddress)\n\n\tvestingAcc, err := k.GetClawbackVestingAccount(ctx, address)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// check if account has any vesting coins left\n\tif !vestingAcc.GetVestingCoins(ctx.BlockTime()).IsZero() {\n\t\treturn nil, errorsmod.Wrapf(errortypes.ErrInvalidRequest, \"vesting coins still left in account: %s\", msg.VestingAddress)\n\t}\n\n\t// check if account has any locked up coins left\n\tif vestingAcc.HasLockedCoins(ctx.BlockTime()) {\n\t\treturn nil, errorsmod.Wrapf(errortypes.ErrInvalidRequest, \"locked up coins still left in account: %s\", msg.VestingAddress)\n\t}\n\t\n\t// if gov clawback is disabled, remove the entry from the store.\n\t// if no entry is found for the address, this will no-op\n\tk.DeleteGovClawbackDisabled(ctx, address)\n\n\tethAccount := evmostypes.ProtoAccount().(*evmostypes.EthAccount)\n\tethAccount.BaseAccount = vestingAcc.BaseAccount\n\tk.accountKeeper.SetAccount(ctx, ethAccount)\n\n\treturn &types.MsgConvertVestingAccountResponse{}, nil\n}", "is_vulnerable": 0}
{"code": "func (k *Key) KeyListMode() KeyListMode {\n\treturn KeyListMode(k.k.keylist_mode)\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tviper.Reset()\n\n\t\t\tvar out bytes.Buffer\n\n\t\t\tcmd := NewRootCmd(RootCommandConfig{\n\t\t\t\tName: \"func\",\n\t\t\t\tVersion: Version{\n\t\t\t\t\tDate: \"1970-01-01\",\n\t\t\t\t\tVers: \"v0.42.0\",\n\t\t\t\t\tHash: \"cafe\",\n\t\t\t\t}})\n\n\t\t\tcmd.SetArgs(tt.args)\n\t\t\tcmd.SetOut(&out)\n\t\t\tif err := cmd.Execute(); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\toutLines := strings.Split(out.String(), \"\\n\")\n\t\t\tif len(outLines)-1 != tt.wantLF {\n\t\t\t\tt.Errorf(\"expected output with %v line breaks but got %v:\", tt.wantLF, len(outLines)-1)\n\t\t\t}\n\t\t\tif outLines[0] != tt.want {\n\t\t\t\tt.Errorf(\"expected output: %q but got: %q\", tt.want, outLines[0])\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func newSyncMemBatch() *syncMemBatch {\n\treturn &syncMemBatch{\n\t\tnodes: make(map[common.Hash][]byte),\n\t\tcodes: make(map[common.Hash][]byte),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (i *IDTokenHandleHelper) GetAccessTokenHash(ctx context.Context, requester fosite.AccessRequester, responder fosite.AccessResponder) string {\n\ttoken := responder.GetAccessToken()\n\n\tbuffer := bytes.NewBufferString(token)\n\thash := sha256.New()\n\thash.Write(buffer.Bytes())\n\thashBuf := bytes.NewBuffer(hash.Sum([]byte{}))\n\tlen := hashBuf.Len()\n\n\treturn base64.RawURLEncoding.EncodeToString(hashBuf.Bytes()[:len/2])\n}", "is_vulnerable": 1}
{"code": "func (fs *UnixFS) Mkdir(name string, mode FileMode) error {\n\tdirfd, name, closeFd, err := fs.safePath(name)\n\tdefer closeFd()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn fs.Mkdirat(dirfd, name, mode)\n}", "is_vulnerable": 0}
{"code": "func (evm *EVM) precompile(addr common.Address) (PrecompiledContract, bool) {\n\tvar precompiles map[common.Address]PrecompiledContract\n\tswitch {\n\tcase evm.chainRules.IsYoloV1:\n\t\tprecompiles = PrecompiledContractsYoloV1\n\tcase evm.chainRules.IsIstanbul:\n\t\tprecompiles = PrecompiledContractsIstanbul\n\tcase evm.chainRules.IsByzantium:\n\t\tprecompiles = PrecompiledContractsByzantium\n\tdefault:\n\t\tprecompiles = PrecompiledContractsHomestead\n\t}\n\tp, ok := precompiles[addr]\n\treturn p, ok\n}", "is_vulnerable": 0}
{"code": "func UpdateAccessControllerState(ctx context.Context, loggedOnUser string, sessionManager *scs.SessionManager) string {\n\trequestState := GetRequestStateFromContext(ctx)\n\tif requestState != nil {\n\t\tloggedOnUser = requestState.User.Name\n\t\tif requestState.UseSession {\n\t\t\tif updated, accessControllerState := requestState.AccessController.GetState(); updated {\n\t\t\t\tif accessControllerState == nil {\n\t\t\t\t\tsessionManager.Remove(ctx, accessControllerStateCookieName)\n\t\t\t\t} else {\n\t\t\t\t\tsessionManager.Put(ctx, accessControllerStateCookieName, accessControllerState)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn loggedOnUser\n}", "is_vulnerable": 1}
{"code": "\t\t\tmainthread.Execute(func() {\n\t\t\t\tif err = syscall.Setresuid(0, 0, uid); err != nil {\n\t\t\t\t\terr = fmt.Errorf(\"failed to escalate privileges\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tdefer syscall.Setresuid(uid, uid, 0)\n\n\t\t\t\tif err = file.Delete(); err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t})", "is_vulnerable": 1}
{"code": "func (mr *MockCoreStorageMockRecorder) DeleteRefreshTokenSession(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DeleteRefreshTokenSession\", reflect.TypeOf((*MockCoreStorage)(nil).DeleteRefreshTokenSession), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func (conf *Config) GetDriverConfig(db string) *mysql.Config {\n\tdriverCfg := mysql.NewConfig()\n\t// maxAllowedPacket=0 can be used to automatically fetch the max_allowed_packet variable from server on every connection.\n\t// https://github.com/go-sql-driver/mysql#maxallowedpacket\n\thostPort := net.JoinHostPort(conf.Host, strconv.Itoa(conf.Port))\n\tdriverCfg.User = conf.User\n\tdriverCfg.Passwd = conf.Password\n\tdriverCfg.Net = \"tcp\"\n\tdriverCfg.Addr = hostPort\n\tdriverCfg.DBName = db\n\tdriverCfg.Collation = \"utf8mb4_general_ci\"\n\tdriverCfg.ReadTimeout = conf.ReadTimeout\n\tdriverCfg.WriteTimeout = 30 * time.Second\n\tdriverCfg.InterpolateParams = true\n\tdriverCfg.MaxAllowedPacket = 0\n\tif conf.Security.DriveTLSName != \"\" {\n\t\tdriverCfg.TLSConfig = conf.Security.DriveTLSName\n\t}\n\tif conf.AllowCleartextPasswords {\n\t\tdriverCfg.AllowCleartextPasswords = true\n\t}\n\treturn driverCfg\n}", "is_vulnerable": 0}
{"code": "\treturn func(c *context.Context) {\n\t\tif !c.Repo.IsAdmin() {\n\t\t\tc.Error(http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func TestJobEndpointConnect_groupConnectHook_IngressGateway_CustomTask(t *testing.T) {\n\tt.Parallel()\n\n\t// Test that the connect gateway task is inserted if a gateway service exists\n\t// and since this is a bridge network, will rewrite the default gateway proxy\n\t// block with correct configuration.\n\tjob := mock.ConnectIngressGatewayJob(\"bridge\", false)\n\tjob.Meta = map[string]string{\n\t\t\"gateway_name\": \"my-gateway\",\n\t}\n\tjob.TaskGroups[0].Services[0].Name = \"${NOMAD_META_gateway_name}\"\n\tjob.TaskGroups[0].Services[0].Connect.SidecarTask = &structs.SidecarTask{\n\t\tDriver: \"raw_exec\",\n\t\tUser:   \"sidecars\",\n\t\tConfig: map[string]interface{}{\n\t\t\t\"command\": \"/bin/sidecar\",\n\t\t\t\"args\":    []string{\"a\", \"b\"},\n\t\t},\n\t\tResources: &structs.Resources{\n\t\t\tCPU: 400,\n\t\t\t// Memory: inherit 128\n\t\t},\n\t\tKillSignal: \"SIGHUP\",\n\t}\n\n\t// setup expectations\n\texpTG := job.TaskGroups[0].Copy()\n\texpTG.Tasks = []*structs.Task{\n\t\t// inject merged gateway task\n\t\t{\n\t\t\tName:   \"connect-ingress-my-gateway\",\n\t\t\tKind:   structs.NewTaskKind(structs.ConnectIngressPrefix, \"my-gateway\"),\n\t\t\tDriver: \"raw_exec\",\n\t\t\tUser:   \"sidecars\",\n\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\"command\": \"/bin/sidecar\",\n\t\t\t\t\"args\":    []string{\"a\", \"b\"},\n\t\t\t},\n\t\t\tResources: &structs.Resources{\n\t\t\t\tCPU:      400,\n\t\t\t\tMemoryMB: 128,\n\t\t\t},\n\t\t\tLogConfig: &structs.LogConfig{\n\t\t\t\tMaxFiles:      2,\n\t\t\t\tMaxFileSizeMB: 2,\n\t\t\t},\n\t\t\tShutdownDelay: 5 * time.Second,\n\t\t\tKillSignal:    \"SIGHUP\",\n\t\t\tConstraints: structs.Constraints{\n\t\t\t\tconnectGatewayVersionConstraint(),\n\t\t\t\tconnectListenerConstraint(),\n\t\t\t},\n\t\t},\n\t}\n\texpTG.Services[0].Name = \"my-gateway\"\n\texpTG.Tasks[0].Canonicalize(job, expTG)\n\texpTG.Networks[0].Canonicalize()\n\n\t// rewrite the service gateway proxy configuration\n\texpTG.Services[0].Connect.Gateway.Proxy = gatewayProxy(expTG.Services[0].Connect.Gateway, \"bridge\")\n\n\trequire.NoError(t, groupConnectHook(job, job.TaskGroups[0]))\n\trequire.Exactly(t, expTG, job.TaskGroups[0])\n\n\t// Test that the hook is idempotent\n\trequire.NoError(t, groupConnectHook(job, job.TaskGroups[0]))\n\trequire.Exactly(t, expTG, job.TaskGroups[0])\n}", "is_vulnerable": 0}
{"code": "func InstanceInterceptor(verifier authz.InstanceVerifier, headerName string, explicitInstanceIdServices ...string) grpc.UnaryServerInterceptor {\n\ttranslator, err := i18n.NewZitadelTranslator(language.English)\n\tlogging.OnError(err).Panic(\"unable to get translator\")\n\treturn func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {\n\t\treturn setInstance(ctx, req, info, handler, verifier, headerName, translator, explicitInstanceIdServices...)\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\treturn PreparerFunc(func(r *http.Request) (*http.Request, error) {\n\t\t\tr, err := p.Prepare(r)\n\t\t\tif err == nil {\n\t\t\t\tif r.URL == nil {\n\t\t\t\t\treturn r, NewError(\"autorest\", \"WithQueryParameters\", \"Invoked with a nil URL\")\n\t\t\t\t}\n\n\t\t\t\tv := r.URL.Query()\n\t\t\t\tfor key, value := range parameters {\n\t\t\t\t\td, err := url.QueryUnescape(value)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn r, err\n\t\t\t\t\t}\n\t\t\t\t\tv.Add(key, d)\n\t\t\t\t}\n\t\t\t\tr.URL.RawQuery = v.Encode()\n\t\t\t}\n\t\t\treturn r, err\n\t\t})", "is_vulnerable": 1}
{"code": "func UnpackTar(filename string, destination string, verbosityLevel int) (err error) {\n\tVerbose = verbosityLevel\n\tf, err := os.Stat(destination)\n\tif os.IsNotExist(err) {\n\t\treturn fmt.Errorf(\"destination directory '%s' does not exist\", destination)\n\t}\n\tfilemode := f.Mode()\n\tif !filemode.IsDir() {\n\t\treturn fmt.Errorf(\"destination '%s' is not a directory\", destination)\n\t}\n\tif !validSuffix(filename) {\n\t\treturn fmt.Errorf(\"unrecognized archive suffix\")\n\t}\n\tvar file *os.File\n\t// #nosec G304\n\tif file, err = os.Open(filename); err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\terr = os.Chdir(destination)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error changing directory to %s\", destination)\n\t}\n\tvar fileReader io.Reader = file\n\tvar decompressor *gzip.Reader\n\tif strings.HasSuffix(filename, globals.GzExt) {\n\t\tif decompressor, err = gzip.NewReader(file); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer decompressor.Close()\n\t}\n\tvar reader *tar.Reader\n\tif decompressor != nil {\n\t\treader = tar.NewReader(decompressor)\n\t} else {\n\t\treader = tar.NewReader(fileReader)\n\t}\n\treturn unpackTarFiles(reader, destination)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CrackFilesList(ctx context.Context, in *clientpb.CrackFile, opts ...grpc.CallOption) (*clientpb.CrackFiles, error) {\n\tout := new(clientpb.CrackFiles)\n\terr := c.cc.Invoke(ctx, SliverRPC_CrackFilesList_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\t\tpool.Submit(func() {\n\t\t\tfile, err := s.Filesystem().UnixFS().Touch(f.FileName, ufs.O_RDWR|ufs.O_CREATE, 0o644)\n\t\t\tif err != nil {\n\t\t\t\ts.Log().WithField(\"file_name\", f.FileName).WithField(\"error\", err).Error(\"failed to open file for configuration\")\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdefer file.Close()\n\n\t\t\tif err := f.Parse(file); err != nil {\n\t\t\t\ts.Log().WithField(\"error\", err).Error(\"failed to parse and update server configuration file\")\n\t\t\t}\n\n\t\t\ts.Log().WithField(\"file_name\", f.FileName).Debug(\"finished processing server configuration file\")\n\t\t})", "is_vulnerable": 0}
{"code": "func (fmr *firehoseReceiver) validate(r *http.Request) (int, error) {\n\tif string(fmr.config.AccessKey) == \"\" {\n\t\t// No access key is configured - accept all requests.\n\t\treturn http.StatusAccepted, nil\n\t}\n\tif accessKey := r.Header.Get(headerFirehoseAccessKey); accessKey == string(fmr.config.AccessKey) {\n\t\treturn http.StatusAccepted, nil\n\t}\n\treturn http.StatusUnauthorized, errInvalidAccessKey\n}", "is_vulnerable": 0}
{"code": "func (lm *localMounter) Mount() (string, error) {\n\tlm.mu.Lock()\n\tdefer lm.mu.Unlock()\n\n\tif lm.mounts == nil && lm.mountable != nil {\n\t\tmounts, release, err := lm.mountable.Mount()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tlm.mounts = mounts\n\t\tlm.release = release\n\t}\n\n\tif userns.RunningInUserNS() {\n\t\tvar err error\n\t\tlm.mounts, err = rootlessmountopts.FixUp(lm.mounts)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\n\tvar isFile bool\n\tif len(lm.mounts) == 1 && (lm.mounts[0].Type == \"bind\" || lm.mounts[0].Type == \"rbind\") {\n\t\tif !lm.forceRemount {\n\t\t\tro := false\n\t\t\tfor _, opt := range lm.mounts[0].Options {\n\t\t\t\tif opt == \"ro\" {\n\t\t\t\t\tro = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !ro {\n\t\t\t\treturn lm.mounts[0].Source, nil\n\t\t\t}\n\t\t}\n\t\tfi, err := os.Stat(lm.mounts[0].Source)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tif !fi.IsDir() {\n\t\t\tisFile = true\n\t\t}\n\t}\n\n\tdest, err := os.MkdirTemp(\"\", \"buildkit-mount\")\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"failed to create temp dir\")\n\t}\n\n\tif isFile {\n\t\tdest = filepath.Join(dest, \"file\")\n\t\tif err := os.WriteFile(dest, []byte{}, 0644); err != nil {\n\t\t\tos.RemoveAll(dest)\n\t\t\treturn \"\", errors.Wrap(err, \"failed to create temp file\")\n\t\t}\n\t}\n\n\tif err := mount.All(lm.mounts, dest); err != nil {\n\t\tos.RemoveAll(dest)\n\t\treturn \"\", errors.Wrapf(err, \"failed to mount %s: %+v\", dest, lm.mounts)\n\t}\n\tlm.target = dest\n\treturn dest, nil\n}", "is_vulnerable": 0}
{"code": "func (o *ops) ExtractFromIgnition(ignitionPath string, fileToExtract string) error {\n\to.log.Infof(\"Getting pull secret from %s\", ignitionPath)\n\tignitionData, err := ioutil.ReadFile(ignitionPath)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while trying to read %s : %e\", ignitionPath, err)\n\t\treturn err\n\t}\n\textractedContent, err := utils.GetFileContentFromIgnition(ignitionData, fileToExtract)\n\tif err != nil {\n\t\to.log.Error(\"Failed to parse ignition\")\n\t\treturn err\n\t}\n\n\ttmpFile := \"/opt/extracted_from_ignition.json\"\n\to.log.Infof(\"Writing extracted content to tmp file %s\", tmpFile)\n\t// #nosec\n\terr = ioutil.WriteFile(tmpFile, extractedContent, 0644)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while writing extracted content to %s\", tmpFile)\n\t\treturn err\n\t}\n\n\to.log.Infof(\"Moving %s to %s\", tmpFile, fileToExtract)\n\tdir := filepath.Dir(fileToExtract)\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mkdir\", \"-p\", filepath.Dir(fileToExtract))\n\tif err != nil {\n\t\to.log.Errorf(\"Failed to create directory %s \", dir)\n\t\treturn err\n\t}\n\t_, err = o.ExecPrivilegeCommand(o.logWriter, \"mv\", tmpFile, fileToExtract)\n\tif err != nil {\n\t\to.log.Errorf(\"Error occurred while moving %s to %s\", tmpFile, fileToExtract)\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (rfs *rootFs) StatServerFile(p string) (os.FileInfo, error) {\n\treturn os.Stat(filepath.Join(rfs.root, \"/server\", p))\n}", "is_vulnerable": 1}
{"code": "func TestStatic_GroupWithStatic(t *testing.T) {\n\tvar testCases = []struct {\n\t\tname                 string\n\t\tgivenGroup           string\n\t\tgivenPrefix          string\n\t\tgivenRoot            string\n\t\twhenURL              string\n\t\texpectStatus         int\n\t\texpectHeaderLocation string\n\t\texpectBodyStartsWith string\n\t}{\n\t\t{\n\t\t\tname:                 \"ok\",\n\t\t\tgivenPrefix:          \"/images\",\n\t\t\tgivenRoot:            \"../_fixture/images\",\n\t\t\twhenURL:              \"/group/images/walle.png\",\n\t\t\texpectStatus:         http.StatusOK,\n\t\t\texpectBodyStartsWith: string([]byte{0x89, 0x50, 0x4e, 0x47}),\n\t\t},\n\t\t{\n\t\t\tname:                 \"No file\",\n\t\t\tgivenPrefix:          \"/images\",\n\t\t\tgivenRoot:            \"../_fixture/scripts\",\n\t\t\twhenURL:              \"/group/images/bolt.png\",\n\t\t\texpectStatus:         http.StatusNotFound,\n\t\t\texpectBodyStartsWith: \"{\\\"message\\\":\\\"Not Found\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Directory not found (no trailing slash)\",\n\t\t\tgivenPrefix:          \"/images\",\n\t\t\tgivenRoot:            \"../_fixture/images\",\n\t\t\twhenURL:              \"/group/images/\",\n\t\t\texpectStatus:         http.StatusNotFound,\n\t\t\texpectBodyStartsWith: \"{\\\"message\\\":\\\"Not Found\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Directory redirect\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/folder\",\n\t\t\texpectStatus:         http.StatusMovedPermanently,\n\t\t\texpectHeaderLocation: \"/group/folder/\",\n\t\t\texpectBodyStartsWith: \"\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Directory redirect\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/folder%2f..\",\n\t\t\texpectStatus:         http.StatusMovedPermanently,\n\t\t\texpectHeaderLocation: \"/group/folder/../\",\n\t\t\texpectBodyStartsWith: \"\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Prefixed directory 404 (request URL without slash)\",\n\t\t\tgivenGroup:           \"_fixture\",\n\t\t\tgivenPrefix:          \"/folder/\", // trailing slash will intentionally not match \"/folder\"\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/_fixture/folder\", // no trailing slash\n\t\t\texpectStatus:         http.StatusNotFound,\n\t\t\texpectBodyStartsWith: \"{\\\"message\\\":\\\"Not Found\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Prefixed directory redirect (without slash redirect to slash)\",\n\t\t\tgivenGroup:           \"_fixture\",\n\t\t\tgivenPrefix:          \"/folder\", // no trailing slash shall match /folder and /folder/*\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/_fixture/folder\", // no trailing slash\n\t\t\texpectStatus:         http.StatusMovedPermanently,\n\t\t\texpectHeaderLocation: \"/_fixture/folder/\",\n\t\t\texpectBodyStartsWith: \"\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Directory with index.html\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/\",\n\t\t\texpectStatus:         http.StatusOK,\n\t\t\texpectBodyStartsWith: \"<!doctype html>\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Prefixed directory with index.html (prefix ending with slash)\",\n\t\t\tgivenPrefix:          \"/assets/\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/assets/\",\n\t\t\texpectStatus:         http.StatusOK,\n\t\t\texpectBodyStartsWith: \"<!doctype html>\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Prefixed directory with index.html (prefix ending without slash)\",\n\t\t\tgivenPrefix:          \"/assets\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/assets/\",\n\t\t\texpectStatus:         http.StatusOK,\n\t\t\texpectBodyStartsWith: \"<!doctype html>\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"Sub-directory with index.html\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture\",\n\t\t\twhenURL:              \"/group/folder/\",\n\t\t\texpectStatus:         http.StatusOK,\n\t\t\texpectBodyStartsWith: \"<!doctype html>\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"do not allow directory traversal (backslash - windows separator)\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture/\",\n\t\t\twhenURL:              `/group/..\\\\middleware/basic_auth.go`,\n\t\t\texpectStatus:         http.StatusNotFound,\n\t\t\texpectBodyStartsWith: \"{\\\"message\\\":\\\"Not Found\\\"}\\n\",\n\t\t},\n\t\t{\n\t\t\tname:                 \"do not allow directory traversal (slash - unix separator)\",\n\t\t\tgivenPrefix:          \"/\",\n\t\t\tgivenRoot:            \"../_fixture/\",\n\t\t\twhenURL:              `/group/../middleware/basic_auth.go`,\n\t\t\texpectStatus:         http.StatusNotFound,\n\t\t\texpectBodyStartsWith: \"{\\\"message\\\":\\\"Not Found\\\"}\\n\",\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\te := echo.New()\n\t\t\tgroup := \"/group\"\n\t\t\tif tc.givenGroup != \"\" {\n\t\t\t\tgroup = tc.givenGroup\n\t\t\t}\n\t\t\tg := e.Group(group)\n\t\t\tg.Static(tc.givenPrefix, tc.givenRoot)\n\n\t\t\treq := httptest.NewRequest(http.MethodGet, tc.whenURL, nil)\n\t\t\trec := httptest.NewRecorder()\n\t\t\te.ServeHTTP(rec, req)\n\t\t\tassert.Equal(t, tc.expectStatus, rec.Code)\n\t\t\tbody := rec.Body.String()\n\t\t\tif tc.expectBodyStartsWith != \"\" {\n\t\t\t\tassert.True(t, strings.HasPrefix(body, tc.expectBodyStartsWith))\n\t\t\t} else {\n\t\t\t\tassert.Equal(t, \"\", body)\n\t\t\t}\n\n\t\t\tif tc.expectHeaderLocation != \"\" {\n\t\t\t\tassert.Equal(t, tc.expectHeaderLocation, rec.Header().Get(echo.HeaderLocation))\n\t\t\t} else {\n\t\t\t\t_, ok := rec.Result().Header[echo.HeaderLocation]\n\t\t\t\tassert.False(t, ok)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (context *DatabaseContext) buildRoleAccessQuery(username string) string {\n\tstatement := replaceSyncTokensQuery(QueryRoleAccess.statement, context.UseXattrs())\n\n\t// SG usernames don't allow back tick, but guard username in select clause for additional safety\n\tusername = strings.Replace(username, \"`\", \"``\", -1)\n\tstatement = strings.Replace(statement, QuerySelectUserName, username, -1)\n\treturn statement\n}", "is_vulnerable": 0}
{"code": "func (h *httpContext) MakeServers() ([]caddy.Server, error) {\n\t// Iterate each site configuration and make sure that:\n\t// 1) TLS is disabled for explicitly-HTTP sites (necessary\n\t//    when an HTTP address shares a block containing tls)\n\t// 2) if QUIC is enabled, TLS ClientAuth is not, because\n\t//    currently, QUIC does not support ClientAuth (TODO:\n\t//    revisit this when our QUIC implementation supports it)\n\t// 3) if TLS ClientAuth is used, StrictHostMatching is on\n\tfor _, cfg := range h.siteConfigs {\n\t\tif !cfg.TLS.Enabled {\n\t\t\tcontinue\n\t\t}\n\t\tif cfg.Addr.Port == HTTPPort || cfg.Addr.Scheme == \"http\" {\n\t\t\tcfg.TLS.Enabled = false\n\t\t\tlog.Printf(\"[WARNING] TLS disabled for %s\", cfg.Addr)\n\t\t} else if cfg.Addr.Scheme == \"\" {\n\t\t\t// set scheme to https ourselves, since TLS is enabled\n\t\t\t// and it was not explicitly set to something else. this\n\t\t\t// makes it appear as \"https\" when we print the list of\n\t\t\t// running sites; otherwise \"http\" would be assumed which\n\t\t\t// is incorrect for this site.\n\t\t\tcfg.Addr.Scheme = \"https\"\n\t\t}\n\t\tif cfg.Addr.Port == \"\" && ((!cfg.TLS.Manual && !cfg.TLS.SelfSigned) || cfg.TLS.OnDemand) {\n\t\t\t// this is vital, otherwise the function call below that\n\t\t\t// sets the listener address will use the default port\n\t\t\t// instead of 443 because it doesn't know about TLS.\n\t\t\tcfg.Addr.Port = HTTPSPort\n\t\t}\n\t\tif cfg.TLS.ClientAuth != tls.NoClientCert {\n\t\t\tif QUIC {\n\t\t\t\treturn nil, fmt.Errorf(\"cannot enable TLS client authentication with QUIC, because QUIC does not yet support it\")\n\t\t\t}\n\t\t\t// this must be enabled so that a client cannot connect\n\t\t\t// using SNI for another site on this listener that\n\t\t\t// does NOT require ClientAuth, and then send HTTP\n\t\t\t// requests with the Host header of this site which DOES\n\t\t\t// require client auth, thus bypassing it...\n\t\t\tcfg.StrictHostMatching = true\n\t\t}\n\t}\n\n\t// we must map (group) each config to a bind address\n\tgroups, err := groupSiteConfigsByListenAddr(h.siteConfigs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// then we create a server for each group\n\tvar servers []caddy.Server\n\tfor addr, group := range groups {\n\t\ts, err := NewServer(addr, group)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tservers = append(servers, s)\n\t}\n\n\treturn servers, nil\n}", "is_vulnerable": 0}
{"code": "func (d *CachedDiscoveryClient) writeCachedFile(filename string, obj runtime.Object) error {\n\tif err := os.MkdirAll(filepath.Dir(filename), 0755); err != nil {\n\t\treturn err\n\t}\n\n\tbytes, err := runtime.Encode(scheme.Codecs.LegacyCodec(), obj)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tf, err := ioutil.TempFile(filepath.Dir(filename), filepath.Base(filename)+\".\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer os.Remove(f.Name())\n\t_, err = f.Write(bytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = os.Chmod(f.Name(), 0755)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tname := f.Name()\n\terr = f.Close()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// atomic rename\n\td.mutex.Lock()\n\tdefer d.mutex.Unlock()\n\terr = os.Rename(name, filename)\n\tif err == nil {\n\t\td.ourFiles[filename] = struct{}{}\n\t}\n\treturn err\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(name, func(t *testing.T) {\n\t\t\trun(t, tc)\n\t\t})", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\tdispatcher := NewLocalOnlyDispatcher(10, 100)\n\n\t\t\tds, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\t\t\trequire.NoError(err)\n\n\t\t\tds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(ds, tc.schema, tc.relationships, require)\n\n\t\t\tctx := datastoremw.ContextWithHandle(context.Background())\n\t\t\trequire.NoError(datastoremw.SetInContext(ctx, ds))\n\n\t\t\tresp, err := dispatcher.DispatchCheck(ctx, &v1.DispatchCheckRequest{\n\t\t\t\tResourceRelation: RR(tc.resource.Namespace, tc.resource.Relation),\n\t\t\t\tResourceIds:      []string{tc.resource.ObjectId},\n\t\t\t\tSubject:          tc.subject,\n\t\t\t\tMetadata: &v1.ResolverMeta{\n\t\t\t\t\tAtRevision:     revision.String(),\n\t\t\t\t\tDepthRemaining: 50,\n\t\t\t\t},\n\t\t\t\tResultsSetting: v1.DispatchCheckRequest_ALLOW_SINGLE_RESULT,\n\t\t\t})\n\t\t\trequire.NoError(err)\n\n\t\t\tmembership := v1.ResourceCheckResult_NOT_MEMBER\n\t\t\tif r, ok := resp.ResultsByResourceId[tc.resource.ObjectId]; ok {\n\t\t\t\tmembership = r.Membership\n\t\t\t}\n\n\t\t\trequire.Equal(tc.expectedPermissionship, membership)\n\n\t\t\tif tc.expectedCaveat != nil {\n\t\t\t\trequire.NotEmpty(resp.ResultsByResourceId[tc.resource.ObjectId].Expression)\n\t\t\t\ttestutil.RequireProtoEqual(t, tc.expectedCaveat, resp.ResultsByResourceId[tc.resource.ObjectId].Expression, \"mismatch in caveat\")\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func NewServer(\n\tnamespace string,\n\tkubeclientset kubernetes.Interface,\n\tappclientset appclientset.Interface,\n\tappLister applisters.ApplicationLister,\n\tappInformer cache.SharedIndexInformer,\n\trepoClientset apiclient.Clientset,\n\tcache *servercache.Cache,\n\tkubectl kube.Kubectl,\n\tdb db.ArgoDB,\n\tenf *rbac.Enforcer,\n\tprojectLock sync.KeyLock,\n\tsettingsMgr *settings.SettingsManager,\n\tprojInformer cache.SharedIndexInformer,\n\tenabledNamespaces []string,\n) (application.ApplicationServiceServer, AppResourceTreeFn) {\n\tappBroadcaster := &broadcasterHandler{}\n\tappInformer.AddEventHandler(appBroadcaster)\n\ts := &Server{\n\t\tns:                namespace,\n\t\tappclientset:      appclientset,\n\t\tappLister:         appLister,\n\t\tappInformer:       appInformer,\n\t\tappBroadcaster:    appBroadcaster,\n\t\tkubeclientset:     kubeclientset,\n\t\tcache:             cache,\n\t\tdb:                db,\n\t\trepoClientset:     repoClientset,\n\t\tkubectl:           kubectl,\n\t\tenf:               enf,\n\t\tprojectLock:       projectLock,\n\t\tauditLogger:       argo.NewAuditLogger(namespace, kubeclientset, \"argocd-server\"),\n\t\tsettingsMgr:       settingsMgr,\n\t\tprojInformer:      projInformer,\n\t\tenabledNamespaces: enabledNamespaces,\n\t}\n\treturn s, s.getAppResources\n}", "is_vulnerable": 1}
{"code": "func TestIterativeStateSyncBatchedFromDisk(t *testing.T)    { testIterativeStateSync(t, 100, true) }", "is_vulnerable": 0}
{"code": "func TestSessionManager_AdminToken_Deactivated(t *testing.T) {\n\tconst (\n\t\tdefaultSubject = \"admin\"\n\t)\n\tsettingsMgr := settings.NewSettingsManager(context.Background(), getKubeClient(\"pass\", false), \"argocd\")\n\tmgr := newSessionManager(settingsMgr, getProjLister(), NewInMemoryUserStateStorage())\n\n\ttoken, err := mgr.Create(defaultSubject, 0, \"\")\n\tif err != nil {\n\t\tt.Errorf(\"Could not create token: %v\", err)\n\t}\n\n\t_, err = mgr.Parse(token)\n\trequire.Error(t, err)\n\tassert.Contains(t, err.Error(), \"account admin is disabled\")\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_outgoingWrapper_BadCert(t *testing.T) {\n\tconfig := Config{\n\t\tCAFile:               \"../test/ca/root.cer\",\n\t\tCertFile:             \"../test/key/ourdomain.cer\",\n\t\tKeyFile:              \"../test/key/ourdomain.key\",\n\t\tVerifyServerHostname: true,\n\t\tVerifyOutgoing:       true,\n\t\tDomain:               \"consul\",\n\t}\n\n\tclient, errc := startTLSServer(&config)\n\tif client == nil {\n\t\tt.Fatalf(\"startTLSServer err: %v\", <-errc)\n\t}\n\n\tc, err := NewConfigurator(config, nil)\n\trequire.NoError(t, err)\n\twrap := c.OutgoingRPCWrapper()\n\n\ttlsClient, err := wrap(\"dc1\", client)\n\trequire.NoError(t, err)\n\n\terr = tlsClient.(*tls.Conn).Handshake()\n\tif _, ok := err.(x509.HostnameError); !ok {\n\t\tt.Fatalf(\"should get hostname err: %v\", err)\n\t}\n\ttlsClient.Close()\n\n\t<-errc\n}", "is_vulnerable": 0}
{"code": "func (p *printer) printIf(s *js_ast.SIf) {\n\tp.printSpaceBeforeIdentifier()\n\tp.print(\"if\")\n\tp.printSpace()\n\tp.print(\"(\")\n\tp.printExpr(s.Test, js_ast.LLowest, 0)\n\tp.print(\")\")\n\n\t// Simplify the else branch, which may disappear entirely\n\tno := s.NoOrNil\n\tif expr, ok := no.Data.(*js_ast.SExpr); ok {\n\t\tif value := p.simplifyUnusedExpr(expr.Value); value.Data == nil {\n\t\t\tno.Data = nil\n\t\t} else if value.Data != expr.Value.Data {\n\t\t\tno.Data = &js_ast.SExpr{Value: value}\n\t\t}\n\t}\n\n\tif yes, ok := s.Yes.Data.(*js_ast.SBlock); ok {\n\t\tp.printSpace()\n\t\tp.printBlock(s.Yes.Loc, *yes)\n\n\t\tif no.Data != nil {\n\t\t\tp.printSpace()\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t}\n\t} else if wrapToAvoidAmbiguousElse(s.Yes.Data) {\n\t\tp.printSpace()\n\t\tp.print(\"{\")\n\t\tp.printNewline()\n\n\t\tp.options.Indent++\n\t\tp.printStmt(s.Yes, canOmitStatement)\n\t\tp.options.Indent--\n\t\tp.needsSemicolon = false\n\n\t\tp.printIndent()\n\t\tp.print(\"}\")\n\n\t\tif no.Data != nil {\n\t\t\tp.printSpace()\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t}\n\t} else {\n\t\tp.printNewline()\n\t\tp.options.Indent++\n\t\tp.printStmt(s.Yes, 0)\n\t\tp.options.Indent--\n\n\t\tif no.Data != nil {\n\t\t\tp.printIndent()\n\t\t}\n\t}\n\n\tif no.Data != nil {\n\t\tp.printSemicolonIfNeeded()\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.print(\"else\")\n\n\t\tif block, ok := no.Data.(*js_ast.SBlock); ok {\n\t\t\tp.printSpace()\n\t\t\tp.printBlock(no.Loc, *block)\n\t\t\tp.printNewline()\n\t\t} else if ifStmt, ok := no.Data.(*js_ast.SIf); ok {\n\t\t\tp.printIf(ifStmt)\n\t\t} else {\n\t\t\tp.printNewline()\n\t\t\tp.options.Indent++\n\t\t\tp.printStmt(no, 0)\n\t\t\tp.options.Indent--\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (t *TestResourceTreeServer) SendMsg(m interface{}) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *CastType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowExample\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CastType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CastType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowExample\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int32 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipExample(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthExample\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func bindUnmountAllRootfs(ctx context.Context, sharedDir string, sandbox *Sandbox) error {\n\tspan, _ := trace(ctx, \"bindUnmountAllRootfs\")\n\tdefer span.Finish()\n\n\tvar errors *merr.Error\n\tfor _, c := range sandbox.containers {\n\t\tif isSymlink(filepath.Join(sharedDir, sandbox.id, c.id)) {\n\t\t\tlogrus.Warnf(\"container dir %s is a symlink, malicious guest?\", c.id)\n\t\t\tcontinue\n\t\t}\n\t\tc.unmountHostMounts()\n\t\tif c.state.Fstype == \"\" {\n\t\t\t// even if error found, don't break out of loop until all mounts attempted\n\t\t\t// to be unmounted, and collect all errors\n\t\t\terrors = merr.Append(errors, bindUnmountContainerRootfs(c.ctx, sharedDir, sandbox.id, c.id))\n\t\t}\n\t}\n\treturn errors.ErrorOrNil()\n}", "is_vulnerable": 0}
{"code": "func TestUpdateAppProject(t *testing.T) {\n\ttestApp := newTestApp()\n\tctx := context.Background()\n\t// nolint:staticcheck\n\tctx = context.WithValue(ctx, \"claims\", &jwt.StandardClaims{Subject: \"admin\"})\n\tappServer := newTestAppServer(testApp)\n\tappServer.enf.SetDefaultRole(\"\")\n\n\t// Verify normal update works (without changing project)\n\t_ = appServer.enf.SetBuiltinPolicy(`p, admin, applications, update, default/test-app, allow`)\n\t_, err := appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tassert.NoError(t, err)\n\n\t// Verify caller cannot update to another project\n\ttestApp.Spec.Project = \"my-proj\"\n\t_, err = appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tassert.Equal(t, status.Code(err), codes.PermissionDenied)\n\n\t// Verify inability to change projects without create privileges in new project\n\t_ = appServer.enf.SetBuiltinPolicy(`\np, admin, applications, update, default/test-app, allow\np, admin, applications, update, my-proj/test-app, allow\n`)\n\t_, err = appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tstatusErr := grpc.UnwrapGRPCStatus(err)\n\tassert.NotNil(t, statusErr)\n\tassert.Equal(t, codes.PermissionDenied, statusErr.Code())\n\n\t// Verify inability to change projects without update privileges in new project\n\t_ = appServer.enf.SetBuiltinPolicy(`\np, admin, applications, update, default/test-app, allow\np, admin, applications, create, my-proj/test-app, allow\n`)\n\t_, err = appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tassert.Equal(t, status.Code(err), codes.PermissionDenied)\n\n\t// Verify inability to change projects without update privileges in old project\n\t_ = appServer.enf.SetBuiltinPolicy(`\np, admin, applications, create, my-proj/test-app, allow\np, admin, applications, update, my-proj/test-app, allow\n`)\n\t_, err = appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tstatusErr = grpc.UnwrapGRPCStatus(err)\n\tassert.NotNil(t, statusErr)\n\tassert.Equal(t, codes.PermissionDenied, statusErr.Code())\n\n\t// Verify can update project with proper permissions\n\t_ = appServer.enf.SetBuiltinPolicy(`\np, admin, applications, update, default/test-app, allow\np, admin, applications, create, my-proj/test-app, allow\np, admin, applications, update, my-proj/test-app, allow\n`)\n\tupdatedApp, err := appServer.Update(ctx, &application.ApplicationUpdateRequest{Application: testApp})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"my-proj\", updatedApp.Spec.Project)\n}", "is_vulnerable": 1}
{"code": "func Generate(options ...Options) macaron.Handler {\n\topt := prepareOptions(options)\n\treturn func(ctx *macaron.Context, sess session.Store) {\n\t\tx := &csrf{\n\t\t\tSecret:         opt.Secret,\n\t\t\tHeader:         opt.Header,\n\t\t\tForm:           opt.Form,\n\t\t\tCookie:         opt.Cookie,\n\t\t\tCookiePath:     opt.CookiePath,\n\t\t\tCookieHttpOnly: opt.CookieHttpOnly,\n\t\t\tErrorFunc:      opt.ErrorFunc,\n\t\t}\n\t\tctx.MapTo(x, (*CSRF)(nil))\n\n\t\tif opt.Origin && len(ctx.Req.Header.Get(\"Origin\")) > 0 {\n\t\t\treturn\n\t\t}\n\n\t\tx.ID = \"0\"\n\t\tuid := sess.Get(opt.SessionKey)\n\t\tif uid != nil {\n\t\t\tx.ID = com.ToStr(uid)\n\t\t}\n\n\t\tneedsNew := false\n\t\toldUid := sess.Get(opt.oldSeesionKey)\n\t\tif oldUid == nil || oldUid.(string) != x.ID {\n\t\t\tneedsNew = true\n\t\t\tsess.Set(opt.oldSeesionKey, x.ID)\n\t\t} else {\n\t\t\t// If cookie present, map existing token, else generate a new one.\n\t\t\tif val := ctx.GetCookie(opt.Cookie); len(val) > 0 {\n\t\t\t\t// FIXME: test coverage.\n\t\t\t\tx.Token = val\n\t\t\t} else {\n\t\t\t\tneedsNew = true\n\t\t\t}\n\t\t}\n\n\t\tif needsNew {\n\t\t\t// FIXME: actionId.\n\t\t\tx.Token = GenerateToken(x.Secret, x.ID, \"POST\")\n\t\t\tif opt.SetCookie {\n\t\t\t\tctx.SetCookie(opt.Cookie, x.Token, 0, opt.CookiePath, \"\", false, opt.CookieHttpOnly, time.Now().AddDate(0, 0, 1))\n\t\t\t}\n\t\t}\n\n\t\tif opt.SetHeader {\n\t\t\tctx.Resp.Header().Add(opt.Header, x.Token)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func safeFilepathJoin(path1, path2 string) (string, error) {\n\trelPath, err := filepath.Rel(\".\", path2)\n\tif err != nil || strings.HasPrefix(relPath, \"..\") {\n\t\treturn \"\", fmt.Errorf(\"(zipslip) filepath is unsafe %q: %v\", path2, err)\n\t}\n\tif path1 == \"\" {\n\t\tpath1 = \".\"\n\t}\n\treturn filepath.Join(path1, filepath.Join(\"/\", relPath)), nil\n}", "is_vulnerable": 0}
{"code": "func ParseServiceAccountToken(token string) (*ServiceAccountClaims, error) {\n\tparser := &jwt.Parser{\n\t\tValidationHelper: jwt.NewValidationHelper(jwt.WithoutClaimsValidation(), jwt.WithoutAudienceValidation()),\n\t}\n\tvar claims ServiceAccountClaims\n\t_, _, err := parser.ParseUnverified(token, &claims)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to parse service account token: %s\", err)\n\t}\n\treturn &claims, nil\n}", "is_vulnerable": 0}
{"code": "func HTTPBodyNotContains(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, str interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.HTTPBodyNotContains(t, handler, method, url, values, str, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (iv *imageVerifier) verifyAttestation(statements []map[string]interface{}, attestation kyvernov1.Attestation, imageInfo apiutils.ImageInfo) error {\n\timage := imageInfo.String()\n\tstatementsByPredicate, types := buildStatementMap(statements)\n\tiv.logger.V(4).Info(\"checking attestations\", \"predicates\", types, \"image\", image)\n\n\tstatements = statementsByPredicate[attestation.PredicateType]\n\tif statements == nil {\n\t\tiv.logger.Info(\"attestation predicate type not found\", \"type\", attestation.PredicateType, \"predicates\", types, \"image\", imageInfo.String())\n\t\treturn fmt.Errorf(\"predicate type %s not found\", attestation.PredicateType)\n\t}\n\n\tfor _, s := range statements {\n\t\tiv.logger.Info(\"checking attestation\", \"predicates\", types, \"image\", imageInfo.String())\n\t\tval, err := iv.checkAttestations(attestation, s)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"failed to check attestations\")\n\t\t}\n\n\t\tif !val {\n\t\t\treturn fmt.Errorf(\"attestation checks failed for %s and predicate %s\", imageInfo.String(), attestation.PredicateType)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Container) IsPlugin() bool {\n\treturn len(c.Commands) == 0 && len(c.Entrypoint) == 0\n}", "is_vulnerable": 1}
{"code": "\tSpecify(\"external name services work over http\", func() {\n\t\tt := f.T()\n\n\t\tf.Fixtures.Echo.Deploy(namespace, \"ingress-conformance-echo\")\n\n\t\texternalNameService := &corev1.Service{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      \"external-name-service\",\n\t\t\t},\n\t\t\tSpec: corev1.ServiceSpec{\n\t\t\t\tType:         corev1.ServiceTypeExternalName,\n\t\t\t\tExternalName: \"ingress-conformance-echo.\" + namespace,\n\t\t\t\tPorts: []corev1.ServicePort{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"http\",\n\t\t\t\t\t\tPort: 80,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\trequire.NoError(t, f.Client.Create(context.TODO(), externalNameService))\n\n\t\tp := &contourv1.HTTPProxy{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      \"external-name-proxy\",\n\t\t\t},\n\t\t\tSpec: contourv1.HTTPProxySpec{\n\t\t\t\tVirtualHost: &contourv1.VirtualHost{\n\t\t\t\t\tFqdn: \"externalnameservice.projectcontour.io\",\n\t\t\t\t},\n\t\t\t\tRoutes: []contourv1.Route{\n\t\t\t\t\t{\n\t\t\t\t\t\tServices: []contourv1.Service{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName: externalNameService.Name,\n\t\t\t\t\t\t\t\tPort: 80,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRequestHeadersPolicy: &contourv1.HeadersPolicy{\n\t\t\t\t\t\t\tSet: []contourv1.HeaderValue{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName:  \"Host\",\n\t\t\t\t\t\t\t\t\tValue: externalNameService.Spec.ExternalName,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tproxy, ok := f.CreateHTTPProxyAndWaitFor(p, httpProxyValid)\n\t\tif !ok {\n\t\t\tt.Fatalf(\"The HTTPProxy did not become valid, here are the Valid condition's Errors: %s\", httpProxyErrors(proxy))\n\t\t}\n\n\t\tres, ok := f.HTTP.RequestUntil(&e2e.HTTPRequestOpts{\n\t\t\tHost:      p.Spec.VirtualHost.Fqdn,\n\t\t\tCondition: e2e.HasStatusCode(200),\n\t\t})\n\t\trequire.Truef(t, ok, \"expected 200 response code, got %d\", res.StatusCode)\n\t})", "is_vulnerable": 0}
{"code": "func (m *MockCoreStrategy) AccessTokenSignature(arg0 string) string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"AccessTokenSignature\", arg0)\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (s *APIV2Service) ListStorages(ctx context.Context, _ *apiv2pb.ListStoragesRequest) (*apiv2pb.ListStoragesResponse, error) {\n\tstorages, err := s.Store.ListStoragesV1(ctx, &store.FindStorage{})\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.Internal, \"failed to list storages, error: %+v\", err)\n\t}\n\n\tresponse := &apiv2pb.ListStoragesResponse{\n\t\tStorages: []*apiv2pb.Storage{},\n\t}\n\tfor _, storage := range storages {\n\t\tresponse.Storages = append(response.Storages, ConvertStorageFromStore(storage))\n\t}\n\treturn response, nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tfor _, pageSize := range []int{0, 104, 1023} {\n\t\t\t\tpageSize := pageSize\n\t\t\t\tt.Run(fmt.Sprintf(\"ps-%d_\", pageSize), func(t *testing.T) {\n\t\t\t\t\trequire := require.New(t)\n\n\t\t\t\t\tdispatcher := NewLocalOnlyDispatcher(10)\n\n\t\t\t\t\tds, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\t\t\t\t\trequire.NoError(err)\n\n\t\t\t\t\tds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(ds, tc.schema, tc.relationships, require)\n\n\t\t\t\t\tctx := datastoremw.ContextWithHandle(context.Background())\n\t\t\t\t\trequire.NoError(datastoremw.SetInContext(ctx, ds))\n\n\t\t\t\t\tvar currentCursor *v1.Cursor\n\t\t\t\t\tfoundResourceIDs := util.NewSet[string]()\n\t\t\t\t\tfor {\n\t\t\t\t\t\tstream := dispatch.NewCollectingDispatchStream[*v1.DispatchLookupResourcesResponse](ctx)\n\t\t\t\t\t\terr = dispatcher.DispatchLookupResources(&v1.DispatchLookupResourcesRequest{\n\t\t\t\t\t\t\tObjectRelation: tc.permission,\n\t\t\t\t\t\t\tSubject:        tc.subject,\n\t\t\t\t\t\t\tMetadata: &v1.ResolverMeta{\n\t\t\t\t\t\t\t\tAtRevision:     revision.String(),\n\t\t\t\t\t\t\t\tDepthRemaining: 50,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tOptionalLimit:  uint32(pageSize),\n\t\t\t\t\t\t\tOptionalCursor: currentCursor,\n\t\t\t\t\t\t}, stream)\n\t\t\t\t\t\trequire.NoError(err)\n\n\t\t\t\t\t\tif pageSize > 0 {\n\t\t\t\t\t\t\trequire.LessOrEqual(len(stream.Results()), pageSize)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tfor _, result := range stream.Results() {\n\t\t\t\t\t\t\tfoundResourceIDs.Add(result.ResolvedResource.ResourceId)\n\t\t\t\t\t\t\tcurrentCursor = result.AfterResponseCursor\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif pageSize == 0 || len(stream.Results()) < pageSize {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tfoundResourceIDsSlice := foundResourceIDs.AsSlice()\n\t\t\t\t\tsort.Strings(foundResourceIDsSlice)\n\t\t\t\t\tsort.Strings(tc.expectedResourceIDs)\n\n\t\t\t\t\trequire.Equal(tc.expectedResourceIDs, foundResourceIDsSlice)\n\t\t\t\t})\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func TestRouteActiveHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tRepositories: []v1alpha1.OwnedRepositories{\n\t\t\t\t\t{\n\t\t\t\t\t\tOwner: \"fake\",\n\t\t\t\t\t\tNames: []string{\n\t\t\t\t\t\t\t\"fake0\", \"fake1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (m *MockClientCredentialsGrantStorage) CreateAccessTokenSession(arg0 context.Context, arg1 string, arg2 fosite.Requester) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"CreateAccessTokenSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (i *Install) Run(chrt *chart.Chart, vals map[string]interface{}) (*release.Release, error) {\n\t// Check reachability of cluster unless in client-only mode (e.g. `helm template` without `--validate`)\n\tif !i.ClientOnly {\n\t\tif err := i.cfg.KubeClient.IsReachable(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := i.availableName(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Pre-install anything in the crd/ directory. We do this before Helm\n\t// contacts the upstream server and builds the capabilities object.\n\tif crds := chrt.CRDObjects(); !i.ClientOnly && !i.SkipCRDs && len(crds) > 0 {\n\t\t// On dry run, bail here\n\t\tif i.DryRun {\n\t\t\ti.cfg.Log(\"WARNING: This chart or one of its subcharts contains CRDs. Rendering may fail or contain inaccuracies.\")\n\t\t} else if err := i.installCRDs(crds); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif i.ClientOnly {\n\t\t// Add mock objects in here so it doesn't use Kube API server\n\t\t// NOTE(bacongobbler): used for `helm template`\n\t\ti.cfg.Capabilities = chartutil.DefaultCapabilities\n\t\ti.cfg.Capabilities.APIVersions = append(i.cfg.Capabilities.APIVersions, i.APIVersions...)\n\t\ti.cfg.KubeClient = &kubefake.PrintingKubeClient{Out: ioutil.Discard}\n\n\t\tmem := driver.NewMemory()\n\t\tmem.SetNamespace(i.Namespace)\n\t\ti.cfg.Releases = storage.Init(mem)\n\t} else if !i.ClientOnly && len(i.APIVersions) > 0 {\n\t\ti.cfg.Log(\"API Version list given outside of client only mode, this list will be ignored\")\n\t}\n\n\tif err := chartutil.ProcessDependencies(chrt, vals); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Make sure if Atomic is set, that wait is set as well. This makes it so\n\t// the user doesn't have to specify both\n\ti.Wait = i.Wait || i.Atomic\n\n\tcaps, err := i.cfg.getCapabilities()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//special case for helm template --is-upgrade\n\tisUpgrade := i.IsUpgrade && i.DryRun\n\toptions := chartutil.ReleaseOptions{\n\t\tName:      i.ReleaseName,\n\t\tNamespace: i.Namespace,\n\t\tRevision:  1,\n\t\tIsInstall: !isUpgrade,\n\t\tIsUpgrade: isUpgrade,\n\t}\n\tvaluesToRender, err := chartutil.ToRenderValues(chrt, vals, options, caps)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trel := i.createRelease(chrt, vals)\n\n\tvar manifestDoc *bytes.Buffer\n\trel.Hooks, manifestDoc, rel.Info.Notes, err = i.cfg.renderResources(chrt, valuesToRender, i.ReleaseName, i.OutputDir, i.SubNotes, i.UseReleaseName, i.IncludeCRDs, i.PostRenderer)\n\t// Even for errors, attach this if available\n\tif manifestDoc != nil {\n\t\trel.Manifest = manifestDoc.String()\n\t}\n\t// Check error from render\n\tif err != nil {\n\t\trel.SetStatus(release.StatusFailed, fmt.Sprintf(\"failed to render resource: %s\", err.Error()))\n\t\t// Return a release with partial data so that the client can show debugging information.\n\t\treturn rel, err\n\t}\n\n\t// Mark this release as in-progress\n\trel.SetStatus(release.StatusPendingInstall, \"Initial install underway\")\n\n\tvar toBeAdopted kube.ResourceList\n\tresources, err := i.cfg.KubeClient.Build(bytes.NewBufferString(rel.Manifest), !i.DisableOpenAPIValidation)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"unable to build kubernetes objects from release manifest\")\n\t}\n\n\t// It is safe to use \"force\" here because these are resources currently rendered by the chart.\n\terr = resources.Visit(setMetadataVisitor(rel.Name, rel.Namespace, true))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Install requires an extra validation step of checking that resources\n\t// don't already exist before we actually create resources. If we continue\n\t// forward and create the release object with resources that already exist,\n\t// we'll end up in a state where we will delete those resources upon\n\t// deleting the release because the manifest will be pointing at that\n\t// resource\n\tif !i.ClientOnly && !isUpgrade {\n\t\ttoBeAdopted, err = existingResourceConflict(resources, rel.Name, rel.Namespace)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"rendered manifests contain a resource that already exists. Unable to continue with install\")\n\t\t}\n\t}\n\n\t// Bail out here if it is a dry run\n\tif i.DryRun {\n\t\trel.Info.Description = \"Dry run complete\"\n\t\treturn rel, nil\n\t}\n\n\tif i.CreateNamespace {\n\t\tns := &v1.Namespace{\n\t\t\tTypeMeta: metav1.TypeMeta{\n\t\t\t\tAPIVersion: \"v1\",\n\t\t\t\tKind:       \"Namespace\",\n\t\t\t},\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tName: i.Namespace,\n\t\t\t\tLabels: map[string]string{\n\t\t\t\t\t\"name\": i.Namespace,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tbuf, err := yaml.Marshal(ns)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresourceList, err := i.cfg.KubeClient.Build(bytes.NewBuffer(buf), true)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif _, err := i.cfg.KubeClient.Create(resourceList); err != nil && !apierrors.IsAlreadyExists(err) {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// If Replace is true, we need to supercede the last release.\n\tif i.Replace {\n\t\tif err := i.replaceRelease(rel); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Store the release in history before continuing (new in Helm 3). We always know\n\t// that this is a create operation.\n\tif err := i.cfg.Releases.Create(rel); err != nil {\n\t\t// We could try to recover gracefully here, but since nothing has been installed\n\t\t// yet, this is probably safer than trying to continue when we know storage is\n\t\t// not working.\n\t\treturn rel, err\n\t}\n\n\t// pre-install hooks\n\tif !i.DisableHooks {\n\t\tif err := i.cfg.execHook(rel, release.HookPreInstall, i.Timeout); err != nil {\n\t\t\treturn i.failRelease(rel, fmt.Errorf(\"failed pre-install: %s\", err))\n\t\t}\n\t}\n\n\t// At this point, we can do the install. Note that before we were detecting whether to\n\t// do an update, but it's not clear whether we WANT to do an update if the re-use is set\n\t// to true, since that is basically an upgrade operation.\n\tif len(toBeAdopted) == 0 {\n\t\tif _, err := i.cfg.KubeClient.Create(resources); err != nil {\n\t\t\treturn i.failRelease(rel, err)\n\t\t}\n\t} else {\n\t\tif _, err := i.cfg.KubeClient.Update(toBeAdopted, resources, false); err != nil {\n\t\t\treturn i.failRelease(rel, err)\n\t\t}\n\t}\n\n\tif i.Wait {\n\t\tif err := i.cfg.KubeClient.Wait(resources, i.Timeout); err != nil {\n\t\t\treturn i.failRelease(rel, err)\n\t\t}\n\n\t}\n\n\tif !i.DisableHooks {\n\t\tif err := i.cfg.execHook(rel, release.HookPostInstall, i.Timeout); err != nil {\n\t\t\treturn i.failRelease(rel, fmt.Errorf(\"failed post-install: %s\", err))\n\t\t}\n\t}\n\n\tif len(i.Description) > 0 {\n\t\trel.SetStatus(release.StatusDeployed, i.Description)\n\t} else {\n\t\trel.SetStatus(release.StatusDeployed, \"Install complete\")\n\t}\n\n\t// This is a tricky case. The release has been created, but the result\n\t// cannot be recorded. The truest thing to tell the user is that the\n\t// release was created. However, the user will not be able to do anything\n\t// further with this release.\n\t//\n\t// One possible strategy would be to do a timed retry to see if we can get\n\t// this stored in the future.\n\tif err := i.recordRelease(rel); err != nil {\n\t\ti.cfg.Log(\"failed to record the release: %s\", err)\n\t}\n\n\treturn rel, nil\n}", "is_vulnerable": 1}
{"code": "func TestServerWithMySQLDatastoreAndExplicitCredentials(t *testing.T) {\n\ttestDatastore, stopFunc := storagefixtures.RunDatastoreTestContainer(t, \"mysql\")\n\tdefer func() {\n\t\tstopFunc()\n\t\t//goleak.VerifyNone(t)\n\t}()\n\n\turi := testDatastore.GetConnectionURI(false)\n\tds, err := mysql.New(\n\t\turi,\n\t\tsqlcommon.NewConfig(\n\t\t\tsqlcommon.WithUsername(testDatastore.GetUsername()),\n\t\t\tsqlcommon.WithPassword(testDatastore.GetPassword()),\n\t\t),\n\t)\n\trequire.NoError(t, err)\n\tdefer ds.Close()\n\n\ttest.RunAllTests(t, ds)\n}", "is_vulnerable": 1}
{"code": "func WaitForUserCompletion(sender Sender, code *DeviceCode) (*Token, error) {\n\treturn WaitForUserCompletionWithContext(context.Background(), sender, code)\n}", "is_vulnerable": 0}
{"code": "func (future *GroupsDeleteFuture) Result(client GroupsClient) (ar autorest.Response, err error) {\n\tvar done bool\n\tdone, err = future.Done(client)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsDeleteFuture\", \"Result\", future.Response(), \"Polling failure\")\n\t\treturn\n\t}\n\tif !done {\n\t\terr = azure.NewAsyncOpIncompleteError(\"resources.GroupsDeleteFuture\")\n\t\treturn\n\t}\n\tar.Response = future.Response()\n\treturn\n}", "is_vulnerable": 1}
{"code": "\t\tif i := bytes.IndexFunc(line, func(r rune) bool {\n\t\t\treturn r < 0x20 || r > 0x7e\n\t\t}); i != -1 {\n\t\t\treturn nil, data\n\t\t}\n\n\t\ti := bytes.Index(line, []byte{':'})\n\t\tif i == -1 {\n\t\t\treturn nil, data\n\t\t}\n\n\t\tkey, val := string(line[0:i]), string(line[i+1:])\n\t\tkey = strings.TrimSpace(key)\n\t\tif key != \"Hash\" {\n\t\t\treturn nil, data\n\t\t}\n\t\tval = strings.TrimSpace(val)\n\t\tb.Headers.Add(key, val)\n\t}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Chtimes(ctx context.Context, in *sliverpb.ChtimesReq, opts ...grpc.CallOption) (*sliverpb.Chtimes, error) {\n\tout := new(sliverpb.Chtimes)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Chtimes\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (m *Setup) command(ctx context.Context, command string) error {\n\tif m.envPath != \"\" {\n\t\tbackupEnv := os.Environ()\n\t\tos.Clearenv()\n\t\tos.Setenv(\"PATH\", m.envPath)\n\t\tdefer env.SetFromList(backupEnv)\n\t}\n\n\tconfig := &libcni.CNIConfig{Path: []string{m.cniPath.Plugin}}\n\n\t// set a timeout context for the execution of the CNI plugin\n\t// to interrupt its execution if it takes more than 5 seconds\n\tctx, cancel := context.WithTimeout(ctx, 5*time.Second)\n\tdefer cancel()\n\n\tif command == \"ADD\" {\n\t\tm.result = make([]types.Result, len(m.networkConfList))\n\t\tfor i := 0; i < len(m.networkConfList); i++ {\n\t\t\tvar err error\n\t\t\tif m.result[i], err = config.AddNetworkList(ctx, m.networkConfList[i], m.runtimeConf[i]); err != nil {\n\t\t\t\tfor j := i - 1; j >= 0; j-- {\n\t\t\t\t\tif err := config.DelNetworkList(ctx, m.networkConfList[j], m.runtimeConf[j]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t} else if command == \"DEL\" {\n\t\tfor i := 0; i < len(m.networkConfList); i++ {\n\t\t\tif err := config.DelNetworkList(ctx, m.networkConfList[i], m.runtimeConf[i]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestSortableRoute(t *testing.T) {\n\tarr := SortableRoute{\n\t\t{\n\t\t\tName: \"regex match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/.*\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex/.*/long\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/longest\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match long with POST method\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/longest\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \":method\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"POST\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match long with GET method\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/longest\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \":method\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"GET\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match short with HEAD method\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \":method\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"HEAD\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match short with GET method\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \":method\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"GET\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match/long\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// This assertion is to it easier to tell how\n\t// the array is rearranged by the sorting.\n\t// It also effectively ensures that buildNameSlice is\n\t// working correctly.\n\tnamesBeforeSort := buildNameSlice(arr)\n\tassert.Equal(t, []string{\n\t\t\"regex match short\",\n\t\t\"regex match long\",\n\t\t\"regex match with one header\",\n\t\t\"regex match with one header and one query\",\n\t\t\"regex match with two headers\",\n\t\t\"exact match short\",\n\t\t\"exact match long\",\n\t\t\"exact match long with POST method\",\n\t\t\"exact match long with GET method\",\n\t\t\"exact match with one header\",\n\t\t\"exact match with one header and one query\",\n\t\t\"exact match with two headers\",\n\t\t\"prefix match short\",\n\t\t\"prefix match short with HEAD method\",\n\t\t\"prefix match short with GET method\",\n\t\t\"prefix match long\",\n\t\t\"prefix match with one header\",\n\t\t\"prefix match with one header and one query\",\n\t\t\"prefix match with two headers\",\n\t}, namesBeforeSort)\n\n\tsort.Sort(arr)\n\n\tnamesAfterSort := buildNameSlice(arr)\n\tassert.Equal(t, []string{\n\t\t\"exact match long with GET method\",\n\t\t\"exact match long with POST method\",\n\t\t\"exact match long\",\n\t\t\"exact match with two headers\",\n\t\t\"exact match with one header and one query\",\n\t\t\"exact match with one header\",\n\t\t\"exact match short\",\n\t\t\"regex match long\",\n\t\t\"regex match with two headers\",\n\t\t\"regex match with one header and one query\",\n\t\t\"regex match with one header\",\n\t\t\"regex match short\",\n\t\t\"prefix match long\",\n\t\t\"prefix match short with GET method\",\n\t\t\"prefix match short with HEAD method\",\n\t\t\"prefix match short\",\n\t\t\"prefix match with two headers\",\n\t\t\"prefix match with one header and one query\",\n\t\t\"prefix match with one header\",\n\t}, namesAfterSort)\n\n}", "is_vulnerable": 0}
{"code": "func (f *Frontend) Send(msg FrontendMessage) error {\n\tbuf, err := msg.Encode(nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\t_, err = f.w.Write(buf)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (s *SSHServer) KeyboardInteractiveHandler(ctx ssh.Context, _ gossh.KeyboardInteractiveChallenge) bool {\n\tac := s.be.AllowKeyless(ctx)\n\tkeyboardInteractiveCounter.WithLabelValues(strconv.FormatBool(ac)).Inc()\n\n\t// If we're allowing keyless access, reset the public key fingerprint\n\tif ac {\n\t\tinitializePermissions(ctx)\n\t\tperms := ctx.Permissions()\n\n\t\t// XXX: reset the public-key fingerprint. This is used to validate the\n\t\t// public key being used to authenticate.\n\t\tperms.Extensions[\"pubkey-fp\"] = \"\"\n\t\tctx.SetValue(ssh.ContextKeyPermissions, perms)\n\t}\n\treturn ac\n}", "is_vulnerable": 0}
{"code": "func Test_IsTrusted_shouldReturnTrueForSubfolderOfTrustedFolders(t *testing.T) {\n\ttestutil.IntegTest(t)\n\ttestutil.OnlyOnWindows(t, \"Windows specific test\")\n\tconfig.CurrentConfig().SetTrustedFolderFeatureEnabled(true)\n\tconfig.CurrentConfig().SetTrustedFolders([]string{\"c:\\\\dummy\"})\n\tf := NewFolder(\"c:\\\\dummy\\\\dummyF\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\tassert.True(t, f.IsTrusted())\n}", "is_vulnerable": 0}
{"code": "func (m MapClaims) VerifyAudience(cmp string, req bool) bool {\n\taud, ok := m[\"aud\"]\n\tif !ok {\n\t\treturn !req\n\t}\n\n\tswitch v := aud.(type) {\n\tcase string:\n\t\treturn verifyAud(ClaimStrings{v}, cmp, req)\n\tcase []string:\n\t\treturn verifyAud(ClaimStrings(v), cmp, req)\n\tdefault:\n\t\treturn false\n\t}\n}", "is_vulnerable": 0}
{"code": "func validateDependency(dep *Dependency) error {\n\tif len(dep.Alias) > 0 && !aliasNameFormat.MatchString(dep.Alias) {\n\t\treturn ValidationErrorf(\"dependency %q has disallowed characters in the alias\", dep.Name)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func IsLatestSnapshot(err error) bool {\n\t_, ok := err.(ErrLatestSnapshot)\n\treturn ok\n}", "is_vulnerable": 1}
{"code": "func (d *driver) newNodeServer() *nodeServer {\n\treturn &nodeServer{\n\t\tnodeId:            d.nodeId,\n\t\tDefaultNodeServer: csicommon.NewDefaultNodeServer(d.csiDriver),\n\t\tclient:            d.client,\n\t\tapiReader:         d.apiReader,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (u User) JoinPath(reqPath string) (string, error) {\n\treturn utils.JoinBasePath(u.BasePath, reqPath)\n}", "is_vulnerable": 0}
{"code": "func (o *CopyOptions) copyFromPod(src, dest fileSpec) error {\n\tif len(src.File) == 0 || len(dest.File) == 0 {\n\t\treturn errFileCannotBeEmpty\n\t}\n\n\treader, outStream := io.Pipe()\n\toptions := &exec.ExecOptions{\n\t\tStreamOptions: exec.StreamOptions{\n\t\t\tIOStreams: genericclioptions.IOStreams{\n\t\t\t\tIn:     nil,\n\t\t\t\tOut:    outStream,\n\t\t\t\tErrOut: o.Out,\n\t\t\t},\n\n\t\t\tNamespace: src.PodNamespace,\n\t\t\tPodName:   src.PodName,\n\t\t},\n\n\t\t// TODO: Improve error messages by first testing if 'tar' is present in the container?\n\t\tCommand:  []string{\"tar\", \"cf\", \"-\", src.File},\n\t\tExecutor: &exec.DefaultRemoteExecutor{},\n\t}\n\n\tgo func() {\n\t\tdefer outStream.Close()\n\t\terr := o.execute(options)\n\t\tcmdutil.CheckErr(err)\n\t}()\n\tprefix := getPrefix(src.File)\n\tprefix = path.Clean(prefix)\n\t// remove extraneous path shortcuts - these could occur if a path contained extra \"../\"\n\t// and attempted to navigate beyond \"/\" in a remote filesystem\n\tprefix = stripPathShortcuts(prefix)\n\treturn o.untarAll(reader, dest.File, prefix)\n}", "is_vulnerable": 1}
{"code": "func InEpsilonf(t TestingT, expected interface{}, actual interface{}, epsilon float64, msg string, args ...interface{}) {\n\tif assert.InEpsilonf(t, expected, actual, epsilon, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func DefaultLinuxSpec() specs.Spec {\n\ts := specs.Spec{\n\t\tVersion: specs.Version,\n\t\tProcess: &specs.Process{\n\t\t\tCapabilities: &specs.LinuxCapabilities{\n\t\t\t\tBounding:    defaultCapabilities(),\n\t\t\t\tPermitted:   defaultCapabilities(),\n\t\t\t\tInheritable: defaultCapabilities(),\n\t\t\t\tEffective:   defaultCapabilities(),\n\t\t\t},\n\t\t},\n\t\tRoot: &specs.Root{},\n\t}\n\ts.Mounts = []specs.Mount{\n\t\t{\n\t\t\tDestination: \"/proc\",\n\t\t\tType:        \"proc\",\n\t\t\tSource:      \"proc\",\n\t\t\tOptions:     []string{\"nosuid\", \"noexec\", \"nodev\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/dev\",\n\t\t\tType:        \"tmpfs\",\n\t\t\tSource:      \"tmpfs\",\n\t\t\tOptions:     []string{\"nosuid\", \"strictatime\", \"mode=755\", \"size=65536k\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/dev/pts\",\n\t\t\tType:        \"devpts\",\n\t\t\tSource:      \"devpts\",\n\t\t\tOptions:     []string{\"nosuid\", \"noexec\", \"newinstance\", \"ptmxmode=0666\", \"mode=0620\", \"gid=5\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/sys\",\n\t\t\tType:        \"sysfs\",\n\t\t\tSource:      \"sysfs\",\n\t\t\tOptions:     []string{\"nosuid\", \"noexec\", \"nodev\", \"ro\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/sys/fs/cgroup\",\n\t\t\tType:        \"cgroup\",\n\t\t\tSource:      \"cgroup\",\n\t\t\tOptions:     []string{\"ro\", \"nosuid\", \"noexec\", \"nodev\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/dev/mqueue\",\n\t\t\tType:        \"mqueue\",\n\t\t\tSource:      \"mqueue\",\n\t\t\tOptions:     []string{\"nosuid\", \"noexec\", \"nodev\"},\n\t\t},\n\t\t{\n\t\t\tDestination: \"/dev/shm\",\n\t\t\tType:        \"tmpfs\",\n\t\t\tSource:      \"shm\",\n\t\t\tOptions:     []string{\"nosuid\", \"noexec\", \"nodev\", \"mode=1777\"},\n\t\t},\n\t}\n\n\ts.Linux = &specs.Linux{\n\t\tMaskedPaths: []string{\n\t\t\t\"/proc/kcore\",\n\t\t\t\"/proc/latency_stats\",\n\t\t\t\"/proc/timer_list\",\n\t\t\t\"/proc/timer_stats\",\n\t\t\t\"/proc/sched_debug\",\n\t\t\t\"/proc/scsi\",\n\t\t},\n\t\tReadonlyPaths: []string{\n\t\t\t\"/proc/asound\",\n\t\t\t\"/proc/bus\",\n\t\t\t\"/proc/fs\",\n\t\t\t\"/proc/irq\",\n\t\t\t\"/proc/sys\",\n\t\t\t\"/proc/sysrq-trigger\",\n\t\t},\n\t\tNamespaces: []specs.LinuxNamespace{\n\t\t\t{Type: \"mount\"},\n\t\t\t{Type: \"network\"},\n\t\t\t{Type: \"uts\"},\n\t\t\t{Type: \"pid\"},\n\t\t\t{Type: \"ipc\"},\n\t\t},\n\t\t// Devices implicitly contains the following devices:\n\t\t// null, zero, full, random, urandom, tty, console, and ptmx.\n\t\t// ptmx is a bind mount or symlink of the container's ptmx.\n\t\t// See also: https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#default-devices\n\t\tDevices: []specs.LinuxDevice{},\n\t\tResources: &specs.LinuxResources{\n\t\t\tDevices: []specs.LinuxDeviceCgroup{\n\t\t\t\t{\n\t\t\t\t\tAllow:  false,\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(1),\n\t\t\t\t\tMinor:  iPtr(5),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(1),\n\t\t\t\t\tMinor:  iPtr(3),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(1),\n\t\t\t\t\tMinor:  iPtr(9),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(1),\n\t\t\t\t\tMinor:  iPtr(8),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(5),\n\t\t\t\t\tMinor:  iPtr(0),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(5),\n\t\t\t\t\tMinor:  iPtr(1),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAllow:  false,\n\t\t\t\t\tType:   \"c\",\n\t\t\t\t\tMajor:  iPtr(10),\n\t\t\t\t\tMinor:  iPtr(229),\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// For LCOW support, populate a blank Windows spec\n\tif runtime.GOOS == \"windows\" {\n\t\ts.Windows = &specs.Windows{}\n\t}\n\n\t// For LCOW support, don't mask /sys/firmware\n\tif runtime.GOOS != \"windows\" {\n\t\ts.Linux.MaskedPaths = append(s.Linux.MaskedPaths, \"/sys/firmware\")\n\t}\n\n\treturn s\n}", "is_vulnerable": 0}
{"code": "func verifyBinary(u *url.URL, sha256Sum []byte, releaseInfo string, mode string, reader []byte) (err error) {\n\tif !atomic.CompareAndSwapUint32(&updateInProgress, 0, 1) {\n\t\treturn errors.New(\"update already in progress\")\n\t}\n\tdefer atomic.StoreUint32(&updateInProgress, 0)\n\n\ttransport := getUpdateTransport(30 * time.Second)\n\topts := selfupdate.Options{\n\t\tHash:     crypto.SHA256,\n\t\tChecksum: sha256Sum,\n\t}\n\n\tif err := opts.CheckPermissions(); err != nil {\n\t\treturn AdminError{\n\t\t\tCode:       AdminUpdateApplyFailure,\n\t\t\tMessage:    fmt.Sprintf(\"server update failed with: %s, do not restart the servers yet\", err),\n\t\t\tStatusCode: http.StatusInternalServerError,\n\t\t}\n\t}\n\n\tminisignPubkey := env.Get(envMinisignPubKey, defaultMinisignPubkey)\n\tif minisignPubkey != \"\" {\n\t\tv := selfupdate.NewVerifier()\n\t\tu.Path = path.Dir(u.Path) + slashSeparator + releaseInfo + \".minisig\"\n\t\tif err = v.LoadFromURL(u.String(), minisignPubkey, transport); err != nil {\n\t\t\treturn AdminError{\n\t\t\t\tCode:       AdminUpdateApplyFailure,\n\t\t\t\tMessage:    fmt.Sprintf(\"signature loading failed for %v with %v\", u, err),\n\t\t\t\tStatusCode: http.StatusInternalServerError,\n\t\t\t}\n\t\t}\n\t\topts.Verifier = v\n\t}\n\n\tif err = selfupdate.PrepareAndCheckBinary(bytes.NewReader(reader), opts); err != nil {\n\t\tvar pathErr *os.PathError\n\t\tif errors.As(err, &pathErr) {\n\t\t\treturn AdminError{\n\t\t\t\tCode: AdminUpdateApplyFailure,\n\t\t\t\tMessage: fmt.Sprintf(\"Unable to update the binary at %s: %v\",\n\t\t\t\t\tfilepath.Dir(pathErr.Path), pathErr.Err),\n\t\t\t\tStatusCode: http.StatusForbidden,\n\t\t\t}\n\t\t}\n\t\treturn AdminError{\n\t\t\tCode:       AdminUpdateApplyFailure,\n\t\t\tMessage:    err.Error(),\n\t\t\tStatusCode: http.StatusInternalServerError,\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *A) Unmarshal(dAtA []byte) error {\n\tvar hasFields [1]uint64\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowVanity\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: A: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: A: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Strings\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowVanity\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthVanity\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthVanity\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Strings = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowVanity\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int = &v\n\t\t\thasFields[0] |= uint64(0x00000001)\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipVanity(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthVanity\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\tif hasFields[0]&uint64(0x00000001) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"Int\")\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestSubmodules_update(t *testing.T) {\n\n\tdir := t.TempDir()\n\n\tdata, err := os.ReadFile(filepath.Join(\"testdata\", \".gitmodules\"))\n\tassert.NoError(t, err)\n\n\terr = os.WriteFile(filepath.Join(dir, \".gitmodules\"), data, 0666)\n\tassert.NoError(t, err)\n\n\t_, err = updateConfigfile(dir, \"foo\", \"bar\", \"v1.2.4\")\n\tassert.NoError(t, err)\n\n\tdata, err = os.ReadFile(filepath.Join(dir, \".gitmodules\"))\n\tassert.NoError(t, err)\n\n\tcfg := config.NewModules()\n\terr = cfg.Unmarshal(data)\n\n\tassert.Equal(t, \"v1.2.4\", cfg.Submodules[\"images/cheese/mount/bar\"].Branch)\n\tassert.Equal(t, \"v1.2.4\", cfg.Submodules[\"images/wine/mount/bar\"].Branch)\n}", "is_vulnerable": 1}
{"code": "func (a *Agent) connect() (conn *ssh.Client, err error) {\n\tfor _, authMethod := range a.authMethods {\n\t\t// Create a dialer (that respects HTTP proxies) and connect to remote host.\n\t\tdialer := proxy.DialerFromEnvironment(a.Addr.Addr)\n\t\tpconn, err := dialer.DialTimeout(a.Addr.AddrNetwork, a.Addr.Addr, apidefaults.DefaultDialTimeout)\n\t\tif err != nil {\n\t\t\ta.log.Debugf(\"Dial to %v failed: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tcallback, err := apisshutils.NewHostKeyCallback(\n\t\t\tapisshutils.HostKeyCallbackConfig{\n\t\t\t\tGetHostCheckers: a.getHostCheckers,\n\t\t\t\tOnCheckCert: func(cert *ssh.Certificate) {\n\t\t\t\t\ta.setPrincipals(cert.ValidPrincipals)\n\t\t\t\t},\n\t\t\t\tFIPS: a.FIPS,\n\t\t\t})\n\t\tif err != nil {\n\t\t\ta.log.Debugf(\"Failed to create host key callback for %v: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Build a new client connection. This is done to get access to incoming\n\t\t// global requests which dialer.Dial would not provide.\n\t\tconn, chans, reqs, err := ssh.NewClientConn(pconn, a.Addr.Addr, &ssh.ClientConfig{\n\t\t\tUser:            a.Username,\n\t\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\t\tHostKeyCallback: callback,\n\t\t\tTimeout:         apidefaults.DefaultDialTimeout,\n\t\t})\n\t\tif err != nil {\n\t\t\ta.log.Debugf(\"Failed to create client to %v: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create an empty channel and close it right away. This will prevent\n\t\t// ssh.NewClient from attempting to process any incoming requests.\n\t\temptyCh := make(chan *ssh.Request)\n\t\tclose(emptyCh)\n\n\t\tclient := ssh.NewClient(conn, chans, emptyCh)\n\n\t\t// Start a goroutine to process global requests from the server.\n\t\tgo a.handleGlobalRequests(a.ctx, reqs)\n\n\t\treturn client, nil\n\t}\n\treturn nil, trace.BadParameter(\"failed to dial: all auth methods failed\")\n}", "is_vulnerable": 0}
{"code": "\tmakeSet := func(privkey jwk.Key) jwk.Set {\n\t\tset := jwk.NewSet()\n\t\tk1, _ := jwk.FromRaw([]byte(\"abracadabra\"))\n\t\tset.AddKey(k1)\n\t\tk2, _ := jwk.FromRaw([]byte(\"opensesame\"))\n\t\tset.AddKey(k2)\n\t\tpubkey, _ := jwk.PublicKeyOf(privkey)\n\t\tpubkey.Set(jwk.AlgorithmKey, jwa.RS256)\n\t\tset.AddKey(pubkey)\n\t\treturn set\n\t}\n\n\tfor _, useJSON := range []bool{true, false} {\n\t\tuseJSON := useJSON\n\t\tt.Run(fmt.Sprintf(\"useJSON=%t\", useJSON), func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tt.Run(`match via \"alg\"`, func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\tkey, err := jwxtest.GenerateRsaJwk()\n\t\t\t\tif !assert.NoError(t, err, \"jwxtest.GenerateJwk should succeed\") {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tset := makeSet(key)\n\t\t\t\tsigned, err := jws.Sign([]byte(payload), jws.WithKey(jwa.RS256, key))\n\t\t\t\tif !assert.NoError(t, err, `jws.Sign should succeed`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif useJSON {\n\t\t\t\t\tm, err := jws.Parse(signed)\n\t\t\t\t\tif !assert.NoError(t, err, `jws.Parse should succeed`) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tsigned, err = json.Marshal(m)\n\t\t\t\t\tif !assert.NoError(t, err, `json.Marshal should succeed`) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tvar used jwk.Key\n\t\t\t\tverified, err := jws.Verify(signed, jws.WithKeySet(set, jws.WithRequireKid(false)), jws.WithKeyUsed(&used))\n\t\t\t\tif !assert.NoError(t, err, `jws.Verify should succeed`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif !assert.Equal(t, []byte(payload), verified, `payload should match`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\texpected, _ := jwk.PublicKeyOf(key)\n\t\t\t\tthumb1, _ := expected.Thumbprint(crypto.SHA1)\n\t\t\t\tthumb2, _ := used.Thumbprint(crypto.SHA1)\n\t\t\t\tif !assert.Equal(t, thumb1, thumb2, `keys should match`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t})\n\t\t\tt.Run(`match via \"kid\"`, func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\n\t\t\t\tkey, err := jwxtest.GenerateRsaJwk()\n\t\t\t\tif !assert.NoError(t, err, \"jwxtest.GenerateJwk should succeed\") {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tkey.Set(jwk.KeyIDKey, `mykey`)\n\n\t\t\t\tset := makeSet(key)\n\t\t\t\tsigned, err := jws.Sign([]byte(payload), jws.WithKey(jwa.RS256, key))\n\t\t\t\tif !assert.NoError(t, err, `jws.Sign should succeed`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif useJSON {\n\t\t\t\t\tm, err := jws.Parse(signed)\n\t\t\t\t\tif !assert.NoError(t, err, `jws.Parse should succeed`) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tsigned, err = json.Marshal(m)\n\t\t\t\t\tif !assert.NoError(t, err, `json.Marshal should succeed`) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tvar used jwk.Key\n\t\t\t\tverified, err := jws.Verify(signed, jws.WithKeySet(set), jws.WithKeyUsed(&used))\n\t\t\t\tif !assert.NoError(t, err, `jws.Verify should succeed`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tif !assert.Equal(t, []byte(payload), verified, `payload should match`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\texpected, _ := jwk.PublicKeyOf(key)\n\t\t\t\tthumb1, _ := expected.Thumbprint(crypto.SHA1)\n\t\t\t\tthumb2, _ := used.Thumbprint(crypto.SHA1)\n\t\t\t\tif !assert.Equal(t, thumb1, thumb2, `keys should match`) {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t})\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func getChat(rows *sql.Rows) ([]interface{}, error) {", "is_vulnerable": 0}
{"code": "func (c *Configurator) getSkipVerifyForCheck(id string) bool {\n\tc.Lock()\n\tdefer c.Unlock()\n\treturn c.checks[id]\n}", "is_vulnerable": 1}
{"code": "func UnmarshalRsaPublicKey(b []byte) (key PubKey, err error) {\n\tdefer func() { catch.HandlePanic(recover(), &err, \"RSA public-key unmarshaling\") }()\n\tpub, err := x509.ParsePKIXPublicKey(b)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpk, ok := pub.(*rsa.PublicKey)\n\tif !ok {\n\t\treturn nil, errors.New(\"not actually an rsa public key\")\n\t}\n\tif pk.N.BitLen() < MinRsaKeyBits {\n\t\treturn nil, ErrRsaKeyTooSmall\n\t}\n\tif pk.N.BitLen() > maxRsaKeyBits {\n\t\treturn nil, ErrRsaKeyTooBig\n\t}\n\n\treturn &RsaPublicKey{k: *pk}, nil\n}", "is_vulnerable": 0}
{"code": "func (ir *imageResource) String() string {\n\treturn ir.ref.Name()\n}", "is_vulnerable": 0}
{"code": "func isReservedBaseName(name string) bool {\n\tif len(name) == 3 {\n\t\tswitch string([]byte{toUpper(name[0]), toUpper(name[1]), toUpper(name[2])}) {\n\t\tcase \"CON\", \"PRN\", \"AUX\", \"NUL\":\n\t\t\treturn true\n\t\t}\n\t}\n\tif len(name) >= 4 {\n\t\tswitch string([]byte{toUpper(name[0]), toUpper(name[1]), toUpper(name[2])}) {\n\t\tcase \"COM\", \"LPT\":\n\t\t\tif len(name) == 4 && '1' <= name[3] && name[3] <= '9' {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\t// Superscript \u00b9, \u00b2, and \u00b3 are considered numbers as well.\n\t\t\tswitch name[3:] {\n\t\t\tcase \"\\u00b2\", \"\\u00b3\", \"\\u00b9\":\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Passing CONIN$ or CONOUT$ to CreateFile opens a console handle.\n\t// https://learn.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea#consoles\n\t//\n\t// While CONIN$ and CONOUT$ aren't documented as being files,\n\t// they behave the same as CON. For example, ./CONIN$ also opens the console input.\n\tif len(name) == 6 && name[5] == '$' && equalFold(name, \"CONIN$\") {\n\t\treturn true\n\t}\n\tif len(name) == 7 && name[6] == '$' && equalFold(name, \"CONOUT$\") {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Println(\"File Upload Endpoint Hit\")\n\n\t\t// Check for acls\n\t\tuserinfo := GetUserInfo(r.Context(), config_obj)\n\t\tpermissions := acls.ARTIFACT_WRITER\n\t\tperm, err := acls.CheckAccess(config_obj, userinfo.Name, permissions)\n\t\tif !perm || err != nil {\n\t\t\treturnError(w, http.StatusUnauthorized,\n\t\t\t\t\"User is not allowed to upload tools.\")\n\t\t\treturn\n\t\t}\n\n\t\t// Parse our multipart form, 10 << 20 specifies a maximum\n\t\t// upload of 10 MB files.\n\t\terr = r.ParseMultipartForm(10 << 20)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\n\t\ttool := &artifacts_proto.Tool{}\n\t\tparams, pres := r.Form[\"_params_\"]\n\t\tif !pres || len(params) != 1 {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\n\t\terr = json.Unmarshal([]byte(params[0]), tool)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\n\t\t// FormFile returns the first file for the given key `myFile`\n\t\t// it also returns the FileHeader so we can get the Filename,\n\t\t// the Header and the size of the file\n\t\tfile, handler, err := r.FormFile(\"file\")\n\t\tif err != nil {\n\t\t\treturnError(w, 403, fmt.Sprintf(\"Unsupported params: %v\", err))\n\t\t\treturn\n\t\t}\n\t\tdefer file.Close()\n\n\t\ttool.Filename = path.Base(handler.Filename)\n\t\ttool.ServeLocally = true\n\n\t\tfile_store_factory := file_store.GetFileStore(config_obj)\n\t\tpath_manager := paths.NewInventoryPathManager(config_obj, tool)\n\t\twriter, err := file_store_factory.WriteFile(path_manager.Path())\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\t\tdefer writer.Close()\n\n\t\terr = writer.Truncate()\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\tsha_sum := sha256.New()\n\n\t\t_, err = io.Copy(writer, io.TeeReader(file, sha_sum))\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\ttool.Hash = hex.EncodeToString(sha_sum.Sum(nil))\n\n\t\terr = services.GetInventory().AddTool(config_obj, tool,\n\t\t\tservices.ToolOptions{\n\t\t\t\tAdminOverride: true,\n\t\t\t})\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\t// Now materialize the tool\n\t\ttool, err = services.GetInventory().GetToolInfo(\n\t\t\tr.Context(), config_obj, tool.Name)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\tserialized, _ := json.Marshal(tool)\n\t\t_, err = w.Write(serialized)\n\t\tif err != nil {\n\t\t\tlogger := logging.GetLogger(config_obj, &logging.GUIComponent)\n\t\t\tlogger.Error(\"toolUploadHandler: %v\", err)\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func NotRegexpf(t TestingT, rx interface{}, str interface{}, msg string, args ...interface{}) {\n\tif assert.NotRegexpf(t, rx, str, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (h *AuthHandlers) UserKeyAuth(conn ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\tfingerprint := fmt.Sprintf(\"%v %v\", key.Type(), sshutils.Fingerprint(key))\n\n\t// create a new logging entry with info specific to this login attempt\n\tlog := h.log.WithField(trace.ComponentFields, log.Fields{\n\t\t\"local\":       conn.LocalAddr(),\n\t\t\"remote\":      conn.RemoteAddr(),\n\t\t\"user\":        conn.User(),\n\t\t\"fingerprint\": fingerprint,\n\t})\n\n\tcid := fmt.Sprintf(\"conn(%v->%v, user=%v)\", conn.RemoteAddr(), conn.LocalAddr(), conn.User())\n\tlog.Debugf(\"%v auth attempt\", cid)\n\n\tcert, ok := key.(*ssh.Certificate)\n\tlog.Debugf(\"%v auth attempt with key %v, %#v\", cid, fingerprint, cert)\n\tif !ok {\n\t\tlog.Debugf(\"auth attempt, unsupported key type\")\n\t\treturn nil, trace.BadParameter(\"unsupported key type: %v\", fingerprint)\n\t}\n\tif len(cert.ValidPrincipals) == 0 {\n\t\tlog.Debugf(\"need a valid principal for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid principal for key %v\", fingerprint)\n\t}\n\tif len(cert.KeyId) == 0 {\n\t\tlog.Debugf(\"need a valid key ID for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid key for key %v\", fingerprint)\n\t}\n\tteleportUser := cert.KeyId\n\n\t// only failed attempts are logged right now\n\trecordFailedLogin := func(err error) {\n\t\tfailedLoginCount.Inc()\n\t\tif err := h.c.Emitter.EmitAuditEvent(h.c.Server.Context(), &apievents.AuthAttempt{\n\t\t\tMetadata: apievents.Metadata{\n\t\t\t\tType: events.AuthAttemptEvent,\n\t\t\t\tCode: events.AuthAttemptFailureCode,\n\t\t\t},\n\t\t\tUserMetadata: apievents.UserMetadata{\n\t\t\t\tLogin: conn.User(),\n\t\t\t\tUser:  teleportUser,\n\t\t\t},\n\t\t\tConnectionMetadata: apievents.ConnectionMetadata{\n\t\t\t\tLocalAddr:  conn.LocalAddr().String(),\n\t\t\t\tRemoteAddr: conn.RemoteAddr().String(),\n\t\t\t},\n\t\t\tStatus: apievents.Status{\n\t\t\t\tSuccess: false,\n\t\t\t\tError:   err.Error(),\n\t\t\t},\n\t\t}); err != nil {\n\t\t\th.log.WithError(err).Warn(\"Failed to emit failed login audit event.\")\n\t\t}\n\t}\n\n\t// Check that the user certificate uses supported public key algorithms, was\n\t// issued by Teleport, and check the certificate metadata (principals,\n\t// timestamp, etc). Fallback to keys is not supported.\n\tclock := time.Now\n\tif h.c.Clock != nil {\n\t\tclock = h.c.Clock.Now\n\t}\n\tcertChecker := utils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsUserAuthority: h.IsUserAuthority,\n\t\t\tClock:           clock,\n\t\t},\n\t\tFIPS: h.c.FIPS,\n\t}\n\tpermissions, err := certChecker.Authenticate(conn, key)\n\tif err != nil {\n\t\tcertificateMismatchCount.Inc()\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tlog.Debugf(\"Successfully authenticated\")\n\n\tclusterName, err := h.c.AccessPoint.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// this is the only way we know of to pass valid additional data about the\n\t// connection to the handlers\n\tpermissions.Extensions[utils.CertTeleportUser] = teleportUser\n\tpermissions.Extensions[utils.CertTeleportClusterName] = clusterName.GetClusterName()\n\tpermissions.Extensions[utils.CertTeleportUserCertificate] = string(ssh.MarshalAuthorizedKey(cert))\n\n\tif h.isProxy() {\n\t\treturn permissions, nil\n\t}\n\n\t// check if the user has permission to log into the node.\n\tswitch {\n\tcase h.c.Component == teleport.ComponentForwardingNode:\n\t\terr = h.canLoginWithoutRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\tdefault:\n\t\terr = h.canLoginWithRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\t}\n\tif err != nil {\n\t\tlog.Errorf(\"Permission denied: %v\", err)\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn permissions, nil\n}", "is_vulnerable": 1}
{"code": "func (f *FileStorage) Exists(contentID string) bool {\n\t_, err := os.Stat(f.storagePathFor(contentID))\n\tif err != nil {\n\t\treturn !os.IsNotExist(err)\n\t}\n\treturn true\n}", "is_vulnerable": 1}
{"code": "\treturn RoundTripperFunc(func(r *http.Request) (*http.Response, error) {\n\t\tresp, err := next.RoundTrip(r)\n\t\tif err == nil {\n\t\t\tcounter.With(labels(code, method, r.Method, resp.StatusCode)).Inc()\n\t\t}\n\t\treturn resp, err\n\t})", "is_vulnerable": 1}
{"code": "func TestProviderOnMiddlewares(t *testing.T) {\n\tentryPoints := []string{\"web\"}\n\n\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\tServices: map[string]*dynamic.Service{\n\t\t\t\t\"test@file\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tRouters: map[string]*dynamic.Router{\n\t\t\t\t\"router@file\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tRule:        \"Host(`test`)\",\n\t\t\t\t\tService:     \"test@file\",\n\t\t\t\t\tMiddlewares: []string{\"chain@file\", \"m1\"},\n\t\t\t\t},\n\t\t\t\t\"router@docker\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tRule:        \"Host(`test`)\",\n\t\t\t\t\tService:     \"test@file\",\n\t\t\t\t\tMiddlewares: []string{\"chain\", \"m1@file\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tMiddlewares: map[string]*dynamic.Middleware{\n\t\t\t\t\"chain@file\": {\n\t\t\t\t\tChain: &dynamic.Chain{Middlewares: []string{\"m1\", \"m2\", \"m1@file\"}},\n\t\t\t\t},\n\t\t\t\t\"chain@docker\": {\n\t\t\t\t\tChain: &dynamic.Chain{Middlewares: []string{\"m1\", \"m2\", \"m1@file\"}},\n\t\t\t\t},\n\t\t\t\t\"m1@file\":   {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m1\"}},\n\t\t\t\t\"m2@file\":   {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m2\"}},\n\t\t\t\t\"m1@docker\": {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m1\"}},\n\t\t\t\t\"m2@docker\": {AddPrefix: &dynamic.AddPrefix{Prefix: \"/m2\"}},\n\t\t\t},\n\t\t},\n\t})\n\n\troundTripperManager := service.NewRoundTripperManager()\n\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\n\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry())\n\n\t_ = routerManager.BuildHandlers(context.Background(), entryPoints, false)\n\n\tassert.Equal(t, []string{\"chain@file\", \"m1@file\"}, rtConf.Routers[\"router@file\"].Middlewares)\n\tassert.Equal(t, []string{\"m1@file\", \"m2@file\", \"m1@file\"}, rtConf.Middlewares[\"chain@file\"].Chain.Middlewares)\n\tassert.Equal(t, []string{\"chain@docker\", \"m1@file\"}, rtConf.Routers[\"router@docker\"].Middlewares)\n\tassert.Equal(t, []string{\"m1@docker\", \"m2@docker\", \"m1@file\"}, rtConf.Middlewares[\"chain@docker\"].Chain.Middlewares)\n}", "is_vulnerable": 1}
{"code": "func (s *SASLAuth) AuthPlain(username, password string) error {\n\tif len(s.Plain) == 0 {\n\t\treturn ErrUnsupportedMech\n\t}\n\n\tvar lastErr error\n\tfor _, p := range s.Plain {\n\t\terr := p.AuthPlain(username, password)\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\t\tif err != nil {\n\t\t\tlastErr = err\n\t\t\tcontinue\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"no auth. provider accepted creds, last err: %w\", lastErr)\n}", "is_vulnerable": 0}
{"code": "func Validate(s *types.Schema, doc *types.ExecutableDefinition, variables map[string]interface{}, maxDepth int) []*errors.QueryError {\n\tc := newContext(s, doc, maxDepth)\n\n\topNames := make(nameSet)\n\tfragUsedBy := make(map[*types.FragmentDefinition][]*types.OperationDefinition)\n\tfor _, op := range doc.Operations {\n\t\tc.usedVars[op] = make(varSet)\n\t\topc := &opContext{c, []*types.OperationDefinition{op}}\n\n\t\t// Check if max depth is exceeded, if it's set. If max depth is exceeded,\n\t\t// don't continue to validate the document and exit early.\n\t\tif validateMaxDepth(opc, op.Selections, nil, 1) {\n\t\t\treturn c.errs\n\t\t}\n\n\t\tif op.Name.Name == \"\" && len(doc.Operations) != 1 {\n\t\t\tc.addErr(op.Loc, \"LoneAnonymousOperation\", \"This anonymous operation must be the only defined operation.\")\n\t\t}\n\t\tif op.Name.Name != \"\" {\n\t\t\tvalidateName(c, opNames, op.Name, \"UniqueOperationNames\", \"operation\")\n\t\t}\n\n\t\tvalidateDirectives(opc, string(op.Type), op.Directives)\n\n\t\tvarNames := make(nameSet)\n\t\tfor _, v := range op.Vars {\n\t\t\tvalidateName(c, varNames, v.Name, \"UniqueVariableNames\", \"variable\")\n\n\t\t\tt := resolveType(c, v.Type)\n\t\t\tif !canBeInput(t) {\n\t\t\t\tc.addErr(v.TypeLoc, \"VariablesAreInputTypes\", \"Variable %q cannot be non-input type %q.\", \"$\"+v.Name.Name, t)\n\t\t\t}\n\t\t\tvalidateValue(opc, v, variables[v.Name.Name], t)\n\n\t\t\tif v.Default != nil {\n\t\t\t\tvalidateLiteral(opc, v.Default)\n\n\t\t\t\tif t != nil {\n\t\t\t\t\tif nn, ok := t.(*types.NonNull); ok {\n\t\t\t\t\t\tc.addErr(v.Default.Location(), \"DefaultValuesOfCorrectType\", \"Variable %q of type %q is required and will not use the default value. Perhaps you meant to use type %q.\", \"$\"+v.Name.Name, t, nn.OfType)\n\t\t\t\t\t}\n\n\t\t\t\t\tif ok, reason := validateValueType(opc, v.Default, t); !ok {\n\t\t\t\t\t\tc.addErr(v.Default.Location(), \"DefaultValuesOfCorrectType\", \"Variable %q of type %q has invalid default value %s.\\n%s\", \"$\"+v.Name.Name, t, v.Default, reason)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tvar entryPoint types.NamedType\n\t\tswitch op.Type {\n\t\tcase query.Query:\n\t\t\tentryPoint = s.EntryPoints[\"query\"]\n\t\tcase query.Mutation:\n\t\t\tentryPoint = s.EntryPoints[\"mutation\"]\n\t\tcase query.Subscription:\n\t\t\tentryPoint = s.EntryPoints[\"subscription\"]\n\t\tdefault:\n\t\t\tpanic(\"unreachable\")\n\t\t}\n\n\t\tvalidateSelectionSet(opc, op.Selections, entryPoint)\n\n\t\tfragUsed := make(map[*types.FragmentDefinition]struct{})\n\t\tmarkUsedFragments(c, op.Selections, fragUsed)\n\t\tfor frag := range fragUsed {\n\t\t\tfragUsedBy[frag] = append(fragUsedBy[frag], op)\n\t\t}\n\t}\n\n\tfragNames := make(nameSet)\n\tfragVisited := make(map[*types.FragmentDefinition]struct{})\n\tfor _, frag := range doc.Fragments {\n\t\topc := &opContext{c, fragUsedBy[frag]}\n\n\t\tvalidateName(c, fragNames, frag.Name, \"UniqueFragmentNames\", \"fragment\")\n\t\tvalidateDirectives(opc, \"FRAGMENT_DEFINITION\", frag.Directives)\n\n\t\tt := unwrapType(resolveType(c, &frag.On))\n\t\t// continue even if t is nil\n\t\tif t != nil && !canBeFragment(t) {\n\t\t\tc.addErr(frag.On.Loc, \"FragmentsOnCompositeTypes\", \"Fragment %q cannot condition on non composite type %q.\", frag.Name.Name, t)\n\t\t\tcontinue\n\t\t}\n\n\t\tvalidateSelectionSet(opc, frag.Selections, t)\n\n\t\tif _, ok := fragVisited[frag]; !ok {\n\t\t\tdetectFragmentCycle(c, frag.Selections, fragVisited, nil, map[string]int{frag.Name.Name: 0})\n\t\t}\n\t}\n\n\tfor _, frag := range doc.Fragments {\n\t\tif len(fragUsedBy[frag]) == 0 {\n\t\t\tc.addErr(frag.Loc, \"NoUnusedFragments\", \"Fragment %q is never used.\", frag.Name.Name)\n\t\t}\n\t}\n\n\tfor _, op := range doc.Operations {\n\t\tc.errs = append(c.errs, c.opErrs[op]...)\n\n\t\topUsedVars := c.usedVars[op]\n\t\tfor _, v := range op.Vars {\n\t\t\tif _, ok := opUsedVars[v]; !ok {\n\t\t\t\topSuffix := \"\"\n\t\t\t\tif op.Name.Name != \"\" {\n\t\t\t\t\topSuffix = fmt.Sprintf(\" in operation %q\", op.Name.Name)\n\t\t\t\t}\n\t\t\t\tc.addErr(v.Loc, \"NoUnusedVariables\", \"Variable %q is never used%s.\", \"$\"+v.Name.Name, opSuffix)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn c.errs\n}", "is_vulnerable": 0}
{"code": "func TestSupported(t *testing.T) {\n\tvar scenarios = []struct {\n\t\tplatform platforms.Platform\n\t\twant     bool\n\t}{\n\t\t{platforms.Kubernetes, true},\n\t\t{platforms.Standalone, true},\n\t\t{platforms.DockerCompose, true},\n\t}\n\n\tfor _, scenario := range scenarios {\n\t\tt.Run(fmt.Sprintf(\"Platform %s should be supported\", scenario.platform), func(t *testing.T) {\n\t\t\ttarget := NewComponents(scenario.platform, nil, \"\")\n\t\t\tisSupported := target.Supported()\n\t\t\tassert.Equal(t, scenario.want, isSupported)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *A) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowA\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: A: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: A: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field F1\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowA\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthA\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthA\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.F1 = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipA(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthA\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func MakeTestClient(ctx context.Context, config common.TestClientConfig) (*pgconn.PgConn, error) {\n\t// Client will be connecting directly to the multiplexer address.\n\tpgconnConfig, err := pgconn.ParseConfig(fmt.Sprintf(\"postgres://%v@%v/?database=%v\",\n\t\tconfig.RouteToDatabase.Username, config.Address, config.RouteToDatabase.Database))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tpgconnConfig.TLSConfig, err = common.MakeTestClientTLSConfig(config)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tpgConn, err := pgconn.ConnectConfig(ctx, pgconnConfig)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn pgConn, nil\n}", "is_vulnerable": 1}
{"code": "func (l log) GetDocumentation() parser.AnnotationFields {\n\treturn l.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func CryptoRandom(count int, start int, end int, letters bool, numbers bool, chars ...rune) (string, error) {\n\tif count == 0 {\n\t\treturn \"\", nil\n\t} else if count < 0 {\n\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Requested random string length %v is less than 0.\", count) // equiv to err := errors.New(\"...\")\n\t\treturn \"\", err\n\t}\n\tif chars != nil && len(chars) == 0 {\n\t\terr := fmt.Errorf(\"randomstringutils illegal argument: The chars array must not be empty\")\n\t\treturn \"\", err\n\t}\n\n\tif start == 0 && end == 0 {\n\t\tif chars != nil {\n\t\t\tend = len(chars)\n\t\t} else {\n\t\t\tif !letters && !numbers {\n\t\t\t\tend = math.MaxInt32\n\t\t\t} else {\n\t\t\t\tend = 'z' + 1\n\t\t\t\tstart = ' '\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif end <= start {\n\t\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Parameter end (%v) must be greater than start (%v)\", end, start)\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tif chars != nil && end > len(chars) {\n\t\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Parameter end (%v) cannot be greater than len(chars) (%v)\", end, len(chars))\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\n\tbuffer := make([]rune, count)\n\tgap := end - start\n\n\t// high-surrogates range, (\\uD800-\\uDBFF) = 55296 - 56319\n\t//  low-surrogates range, (\\uDC00-\\uDFFF) = 56320 - 57343\n\n\tfor count != 0 {\n\t\tcount--\n\t\tvar ch rune\n\t\tif chars == nil {\n\t\t\tch = rune(getCryptoRandomInt(gap) + int64(start))\n\t\t} else {\n\t\t\tch = chars[getCryptoRandomInt(gap) + int64(start)]\n\t\t}\n\n\t\tif letters && unicode.IsLetter(ch) || numbers && unicode.IsDigit(ch) || !letters && !numbers {\n\t\t\tif ch >= 56320 && ch <= 57343 { // low surrogate range\n\t\t\t\tif count == 0 {\n\t\t\t\t\tcount++\n\t\t\t\t} else {\n\t\t\t\t\t// Insert low surrogate\n\t\t\t\t\tbuffer[count] = ch\n\t\t\t\t\tcount--\n\t\t\t\t\t// Insert high surrogate\n\t\t\t\t\tbuffer[count] = rune(55296 + getCryptoRandomInt(128))\n\t\t\t\t}\n\t\t\t} else if ch >= 55296 && ch <= 56191 { // High surrogates range (Partial)\n\t\t\t\tif count == 0 {\n\t\t\t\t\tcount++\n\t\t\t\t} else {\n\t\t\t\t\t// Insert low surrogate\n\t\t\t\t\tbuffer[count] = rune(56320 + getCryptoRandomInt(128))\n\t\t\t\t\tcount--\n\t\t\t\t\t// Insert high surrogate\n\t\t\t\t\tbuffer[count] = ch\n\t\t\t\t}\n\t\t\t} else if ch >= 56192 && ch <= 56319 {\n\t\t\t\t// private high surrogate, skip it\n\t\t\t\tcount++\n\t\t\t} else {\n\t\t\t\t// not one of the surrogates*\n\t\t\t\tbuffer[count] = ch\n\t\t\t}\n\t\t} else {\n\t\t\tcount++\n\t\t}\n\t}\n\treturn string(buffer), nil\n}", "is_vulnerable": 1}
{"code": "func Escalate() error {\n\truntime.LockOSThread()\n\tuid := os.Getuid()\n\treturn syscall.Setresuid(0, 0, uid)\n}", "is_vulnerable": 1}
{"code": "func MkdirAllWithPathCheck(path string, perm os.FileMode) error {\n\tif dir, err := os.Lstat(path); err == nil {\n\t\t// If the path exists already,\n\t\t// 1. for Unix/Linux OS, check if the path is directory.\n\t\t// 2. for windows NTFS, check if the path is symlink instead of directory.\n\t\tif dir.IsDir() ||\n\t\t\t(runtime.GOOS == \"windows\" && (dir.Mode()&os.ModeSymlink != 0)) {\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"path %v exists but is not a directory\", path)\n\t}\n\t// If existence of path not known, attempt to create it.\n\tif err := os.MkdirAll(path, perm); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestSanitizer(t *testing.T) {\n\ttestCases := []string{\n\t\t// Regular\n\t\t`<a onblur=\"alert(secret)\" href=\"http://www.google.com\">Google</a>`, `<a href=\"http://www.google.com\" rel=\"nofollow\">Google</a>`,\n\t\t\"<scr\u0130pt>&lt;script&gt;alert(document.domain)&lt;/script&gt;</scr\u0130pt>\", \"&lt;script&gt;alert(document.domain)&lt;/script&gt;\",\n\n\t\t// Code highlighting class\n\t\t`<code class=\"random string\"></code>`, `<code></code>`,\n\t\t`<code class=\"language-random ui tab active menu attached animating sidebar following bar center\"></code>`, `<code></code>`,\n\t\t`<code class=\"language-go\"></code>`, `<code class=\"language-go\"></code>`,\n\n\t\t// Input checkbox\n\t\t`<input type=\"hidden\">`, ``,\n\t\t`<input type=\"checkbox\">`, `<input type=\"checkbox\">`,\n\t\t`<input checked disabled autofocus>`, `<input checked=\"\" disabled=\"\">`,\n\n\t\t// Code highlight injection\n\t\t`<code class=\"language-random&#32;ui&#32;tab&#32;active&#32;menu&#32;attached&#32;animating&#32;sidebar&#32;following&#32;bar&#32;center\"></code>`, `<code></code>`,\n\t\t`<code class=\"language-lol&#32;ui&#32;tab&#32;active&#32;menu&#32;attached&#32;animating&#32;sidebar&#32;following&#32;bar&#32;center\">\n<code class=\"language-lol&#32;ui&#32;container&#32;input&#32;huge&#32;basic&#32;segment&#32;center\">&nbsp;</code>\n<img src=\"https://try.gogs.io/img/favicon.png\" width=\"200\" height=\"200\">\n<code class=\"language-lol&#32;ui&#32;container&#32;input&#32;massive&#32;basic&#32;segment\">Hello there! Something has gone wrong, we are working on it.</code>\n<code class=\"language-lol&#32;ui&#32;container&#32;input&#32;huge&#32;basic&#32;segment\">In the meantime, play a game with us at&nbsp;<a href=\"http://example.com/\">example.com</a>.</code>\n</code>`, \"<code>\\n<code>\\u00a0</code>\\n<img src=\\\"https://try.gogs.io/img/favicon.png\\\" width=\\\"200\\\" height=\\\"200\\\">\\n<code>Hello there! Something has gone wrong, we are working on it.</code>\\n<code>In the meantime, play a game with us at\\u00a0<a href=\\\"http://example.com/\\\" rel=\\\"nofollow\\\">example.com</a>.</code>\\n</code>\",\n\n\t\t// <kbd> tags\n\t\t`<kbd>Ctrl + C</kbd>`, `<kbd>Ctrl + C</kbd>`,\n\t\t`<i class=\"dropdown icon\">NAUGHTY</i>`, `<i>NAUGHTY</i>`,\n\t\t`<i class=\"icon dropdown\"></i>`, `<i class=\"icon dropdown\"></i>`,\n\t\t`<input type=\"checkbox\" disabled=\"\"/>unchecked`, `<input type=\"checkbox\" disabled=\"\"/>unchecked`,\n\t\t`<span class=\"emoji dropdown\">NAUGHTY</span>`, `<span>NAUGHTY</span>`,\n\t\t`<span class=\"emoji\">contents</span>`, `<span class=\"emoji\">contents</span>`,\n\n\t\t// Color property\n\t\t`<span style=\"color: red\">Hello World</span>`, `<span style=\"color: red\">Hello World</span>`,\n\t\t`<p style=\"color: red\">Hello World</p>`, `<p style=\"color: red\">Hello World</p>`,\n\t\t`<code style=\"color: red\">Hello World</code>`, `<code>Hello World</code>`,\n\t\t`<span style=\"bad-color: red\">Hello World</span>`, `<span>Hello World</span>`,\n\t\t`<p style=\"bad-color: red\">Hello World</p>`, `<p>Hello World</p>`,\n\t\t`<code style=\"bad-color: red\">Hello World</code>`, `<code>Hello World</code>`,\n\n\t\t// Org mode status of list items.\n\t\t`<li class=\"checked\"></li>`, `<li class=\"checked\"></li>`,\n\t\t`<li class=\"unchecked\"></li>`, `<li class=\"unchecked\"></li>`,\n\t\t`<li class=\"indeterminate\"></li>`, `<li class=\"indeterminate\"></li>`,\n\n\t\t// URLs\n\t\t`<a href=\"cbthunderlink://somebase64string)\">my custom URL scheme</a>`, `<a href=\"cbthunderlink://somebase64string)\" rel=\"nofollow\">my custom URL scheme</a>`,\n\t\t`<a href=\"matrix:roomid/psumPMeAfzgAeQpXMG:feneas.org?action=join\">my custom URL scheme</a>`, `<a href=\"matrix:roomid/psumPMeAfzgAeQpXMG:feneas.org?action=join\" rel=\"nofollow\">my custom URL scheme</a>`,\n\n\t\t// Disallow dangerous url schemes\n\t\t`<a href=\"javascript:alert('xss')\">bad</a>`, `bad`,\n\t\t`<a href=\"vbscript:no\">bad</a>`, `bad`,\n\t\t`<a href=\"data:1234\">bad</a>`, `bad`,\n\t}\n\n\tfor i := 0; i < len(testCases); i += 2 {\n\t\tassert.Equal(t, testCases[i+1], Sanitize(testCases[i]))\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client AccountsClient) Update(ctx context.Context, resourceGroupName string, accountName string, parameters AccountUpdateParameters) (result Account, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/AccountsClient.Update\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: accountName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"accountName\", Name: validation.MaxLength, Rule: 24, Chain: nil},\n\t\t\t\t{Target: \"accountName\", Name: validation.MinLength, Rule: 3, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"storage.AccountsClient\", \"Update\", err.Error())\n\t}\n\n\treq, err := client.UpdatePreparer(ctx, resourceGroupName, accountName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"Update\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.UpdateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"Update\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.UpdateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"Update\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func NotZerof(t TestingT, i interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotZerof(t, i, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func TestServer_DeltaAggregatedResources_v3_ACLTokenDeleted_StreamTerminatedDuringDiscoveryRequest(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"too slow for testing.Short\")\n\t}\n\n\taclRules := `service \"web\" { policy = \"write\" }`\n\ttoken := \"service-write-on-web\"\n\n\tpolicy, err := acl.NewPolicyFromSource(aclRules, nil, nil)\n\trequire.NoError(t, err)\n\n\tvar validToken atomic.Value\n\tvalidToken.Store(token)\n\n\taclResolve := func(id string) (acl.Authorizer, error) {\n\t\tif token := validToken.Load(); token == nil || id != token.(string) {\n\t\t\treturn nil, acl.ErrNotFound\n\t\t}\n\n\t\treturn acl.NewPolicyAuthorizerWithDefaults(acl.RootAuthorizer(\"deny\"), []*acl.Policy{policy}, nil)\n\t}\n\tscenario := newTestServerDeltaScenario(t, aclResolve, \"web-sidecar-proxy\", token,\n\t\t100*time.Millisecond, // Make this short.\n\t)\n\tmgr, errCh, envoy := scenario.mgr, scenario.errCh, scenario.envoy\n\n\tgetError := func() (gotErr error, ok bool) {\n\t\tselect {\n\t\tcase err := <-errCh:\n\t\t\treturn err, true\n\t\tdefault:\n\t\t\treturn nil, false\n\t\t}\n\t}\n\n\tsid := structs.NewServiceID(\"web-sidecar-proxy\", nil)\n\t// Register the proxy to create state needed to Watch() on\n\tmgr.RegisterProxy(t, sid)\n\n\t// Send initial cluster discover (OK)\n\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, nil)\n\t{\n\t\terr, ok := getError()\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t}\n\n\t// Check no response sent yet\n\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t{\n\t\terr, ok := getError()\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t}\n\n\t// Deliver a new snapshot\n\tsnap := newTestSnapshot(t, nil, \"\", nil)\n\tmgr.DeliverConfig(t, sid, snap)\n\n\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\tTypeUrl: xdscommon.ClusterType,\n\t\tNonce:   hexString(1),\n\t\tResources: makeTestResources(t,\n\t\t\tmakeTestCluster(t, snap, \"tcp:local_app\"),\n\t\t\tmakeTestCluster(t, snap, \"tcp:db\"),\n\t\t\tmakeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t),\n\t})\n\n\t// It also (in parallel) issues the next cluster request (which acts as an ACK\n\t// of the version we sent)\n\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, nil)\n\n\t// Check no response sent yet\n\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t{\n\t\terr, ok := getError()\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t}\n\n\t// Now nuke the ACL token while there's no activity.\n\tvalidToken.Store(\"\")\n\n\tselect {\n\tcase err := <-errCh:\n\t\trequire.Error(t, err)\n\t\tgerr, ok := status.FromError(err)\n\t\trequire.Truef(t, ok, \"not a grpc status error: type='%T' value=%v\", err, err)\n\t\trequire.Equal(t, codes.Unauthenticated, gerr.Code())\n\t\trequire.Equal(t, \"unauthenticated: ACL not found\", gerr.Message())\n\n\t\tmgr.AssertWatchCancelled(t, sid)\n\tcase <-time.After(200 * time.Millisecond):\n\t\tt.Fatalf(\"timed out waiting for handler to finish\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func verifyContainerResources(resources *containertypes.Resources, sysInfo *sysinfo.SysInfo, update bool) ([]string, error) {\n\twarnings := []string{}\n\tfixMemorySwappiness(resources)\n\n\t// memory subsystem checks and adjustments\n\tif resources.Memory != 0 && resources.Memory < linuxMinMemory {\n\t\treturn warnings, fmt.Errorf(\"Minimum memory limit allowed is 4MB\")\n\t}\n\tif resources.Memory > 0 && !sysInfo.MemoryLimit {\n\t\twarnings = append(warnings, \"Your kernel does not support memory limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support memory limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tresources.Memory = 0\n\t\tresources.MemorySwap = -1\n\t}\n\tif resources.Memory > 0 && resources.MemorySwap != -1 && !sysInfo.SwapLimit {\n\t\twarnings = append(warnings, \"Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.\")\n\t\tlogrus.Warn(\"Your kernel does not support swap limit capabilities,or the cgroup is not mounted. Memory limited without swap.\")\n\t\tresources.MemorySwap = -1\n\t}\n\tif resources.Memory > 0 && resources.MemorySwap > 0 && resources.MemorySwap < resources.Memory {\n\t\treturn warnings, fmt.Errorf(\"Minimum memoryswap limit should be larger than memory limit, see usage\")\n\t}\n\tif resources.Memory == 0 && resources.MemorySwap > 0 && !update {\n\t\treturn warnings, fmt.Errorf(\"You should always set the Memory limit when using Memoryswap limit, see usage\")\n\t}\n\tif resources.MemorySwappiness != nil && !sysInfo.MemorySwappiness {\n\t\twarnings = append(warnings, \"Your kernel does not support memory swappiness capabilities or the cgroup is not mounted. Memory swappiness discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support memory swappiness capabilities, or the cgroup is not mounted. Memory swappiness discarded.\")\n\t\tresources.MemorySwappiness = nil\n\t}\n\tif resources.MemorySwappiness != nil {\n\t\tswappiness := *resources.MemorySwappiness\n\t\tif swappiness < 0 || swappiness > 100 {\n\t\t\treturn warnings, fmt.Errorf(\"Invalid value: %v, valid memory swappiness range is 0-100\", swappiness)\n\t\t}\n\t}\n\tif resources.MemoryReservation > 0 && !sysInfo.MemoryReservation {\n\t\twarnings = append(warnings, \"Your kernel does not support memory soft limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support memory soft limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tresources.MemoryReservation = 0\n\t}\n\tif resources.MemoryReservation > 0 && resources.MemoryReservation < linuxMinMemory {\n\t\treturn warnings, fmt.Errorf(\"Minimum memory reservation allowed is 4MB\")\n\t}\n\tif resources.Memory > 0 && resources.MemoryReservation > 0 && resources.Memory < resources.MemoryReservation {\n\t\treturn warnings, fmt.Errorf(\"Minimum memory limit can not be less than memory reservation limit, see usage\")\n\t}\n\tif resources.KernelMemory > 0 && !sysInfo.KernelMemory {\n\t\twarnings = append(warnings, \"Your kernel does not support kernel memory limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support kernel memory limit capabilities or the cgroup is not mounted. Limitation discarded.\")\n\t\tresources.KernelMemory = 0\n\t}\n\tif resources.KernelMemory > 0 && resources.KernelMemory < linuxMinMemory {\n\t\treturn warnings, fmt.Errorf(\"Minimum kernel memory limit allowed is 4MB\")\n\t}\n\tif resources.KernelMemory > 0 && !kernel.CheckKernelVersion(4, 0, 0) {\n\t\twarnings = append(warnings, \"You specified a kernel memory limit on a kernel older than 4.0. Kernel memory limits are experimental on older kernels, it won't work as expected and can cause your system to be unstable.\")\n\t\tlogrus.Warn(\"You specified a kernel memory limit on a kernel older than 4.0. Kernel memory limits are experimental on older kernels, it won't work as expected and can cause your system to be unstable.\")\n\t}\n\tif resources.OomKillDisable != nil && !sysInfo.OomKillDisable {\n\t\t// only produce warnings if the setting wasn't to *disable* the OOM Kill; no point\n\t\t// warning the caller if they already wanted the feature to be off\n\t\tif *resources.OomKillDisable {\n\t\t\twarnings = append(warnings, \"Your kernel does not support OomKillDisable. OomKillDisable discarded.\")\n\t\t\tlogrus.Warn(\"Your kernel does not support OomKillDisable. OomKillDisable discarded.\")\n\t\t}\n\t\tresources.OomKillDisable = nil\n\t}\n\n\tif resources.PidsLimit != 0 && !sysInfo.PidsLimit {\n\t\twarnings = append(warnings, \"Your kernel does not support pids limit capabilities or the cgroup is not mounted. PIDs limit discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support pids limit capabilities or the cgroup is not mounted. PIDs limit discarded.\")\n\t\tresources.PidsLimit = 0\n\t}\n\n\t// cpu subsystem checks and adjustments\n\tif resources.NanoCPUs > 0 && resources.CPUPeriod > 0 {\n\t\treturn warnings, fmt.Errorf(\"Conflicting options: Nano CPUs and CPU Period cannot both be set\")\n\t}\n\tif resources.NanoCPUs > 0 && resources.CPUQuota > 0 {\n\t\treturn warnings, fmt.Errorf(\"Conflicting options: Nano CPUs and CPU Quota cannot both be set\")\n\t}\n\tif resources.NanoCPUs > 0 && (!sysInfo.CPUCfsPeriod || !sysInfo.CPUCfsQuota) {\n\t\treturn warnings, fmt.Errorf(\"NanoCPUs can not be set, as your kernel does not support CPU cfs period/quota or the cgroup is not mounted\")\n\t}\n\t// The highest precision we could get on Linux is 0.001, by setting\n\t//   cpu.cfs_period_us=1000ms\n\t//   cpu.cfs_quota=1ms\n\t// See the following link for details:\n\t// https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt\n\t// Here we don't set the lower limit and it is up to the underlying platform (e.g., Linux) to return an error.\n\t// The error message is 0.01 so that this is consistent with Windows\n\tif resources.NanoCPUs < 0 || resources.NanoCPUs > int64(sysinfo.NumCPU())*1e9 {\n\t\treturn warnings, fmt.Errorf(\"Range of CPUs is from 0.01 to %d.00, as there are only %d CPUs available\", sysinfo.NumCPU(), sysinfo.NumCPU())\n\t}\n\n\tif resources.CPUShares > 0 && !sysInfo.CPUShares {\n\t\twarnings = append(warnings, \"Your kernel does not support CPU shares or the cgroup is not mounted. Shares discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support CPU shares or the cgroup is not mounted. Shares discarded.\")\n\t\tresources.CPUShares = 0\n\t}\n\tif resources.CPUPeriod > 0 && !sysInfo.CPUCfsPeriod {\n\t\twarnings = append(warnings, \"Your kernel does not support CPU cfs period or the cgroup is not mounted. Period discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support CPU cfs period or the cgroup is not mounted. Period discarded.\")\n\t\tresources.CPUPeriod = 0\n\t}\n\tif resources.CPUPeriod != 0 && (resources.CPUPeriod < 1000 || resources.CPUPeriod > 1000000) {\n\t\treturn warnings, fmt.Errorf(\"CPU cfs period can not be less than 1ms (i.e. 1000) or larger than 1s (i.e. 1000000)\")\n\t}\n\tif resources.CPUQuota > 0 && !sysInfo.CPUCfsQuota {\n\t\twarnings = append(warnings, \"Your kernel does not support CPU cfs quota or the cgroup is not mounted. Quota discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support CPU cfs quota or the cgroup is not mounted. Quota discarded.\")\n\t\tresources.CPUQuota = 0\n\t}\n\tif resources.CPUQuota > 0 && resources.CPUQuota < 1000 {\n\t\treturn warnings, fmt.Errorf(\"CPU cfs quota can not be less than 1ms (i.e. 1000)\")\n\t}\n\tif resources.CPUPercent > 0 {\n\t\twarnings = append(warnings, fmt.Sprintf(\"%s does not support CPU percent. Percent discarded.\", runtime.GOOS))\n\t\tlogrus.Warnf(\"%s does not support CPU percent. Percent discarded.\", runtime.GOOS)\n\t\tresources.CPUPercent = 0\n\t}\n\n\t// cpuset subsystem checks and adjustments\n\tif (resources.CpusetCpus != \"\" || resources.CpusetMems != \"\") && !sysInfo.Cpuset {\n\t\twarnings = append(warnings, \"Your kernel does not support cpuset or the cgroup is not mounted. Cpuset discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support cpuset or the cgroup is not mounted. Cpuset discarded.\")\n\t\tresources.CpusetCpus = \"\"\n\t\tresources.CpusetMems = \"\"\n\t}\n\tcpusAvailable, err := sysInfo.IsCpusetCpusAvailable(resources.CpusetCpus)\n\tif err != nil {\n\t\treturn warnings, fmt.Errorf(\"Invalid value %s for cpuset cpus\", resources.CpusetCpus)\n\t}\n\tif !cpusAvailable {\n\t\treturn warnings, fmt.Errorf(\"Requested CPUs are not available - requested %s, available: %s\", resources.CpusetCpus, sysInfo.Cpus)\n\t}\n\tmemsAvailable, err := sysInfo.IsCpusetMemsAvailable(resources.CpusetMems)\n\tif err != nil {\n\t\treturn warnings, fmt.Errorf(\"Invalid value %s for cpuset mems\", resources.CpusetMems)\n\t}\n\tif !memsAvailable {\n\t\treturn warnings, fmt.Errorf(\"Requested memory nodes are not available - requested %s, available: %s\", resources.CpusetMems, sysInfo.Mems)\n\t}\n\n\t// blkio subsystem checks and adjustments\n\tif resources.BlkioWeight > 0 && !sysInfo.BlkioWeight {\n\t\twarnings = append(warnings, \"Your kernel does not support Block I/O weight or the cgroup is not mounted. Weight discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support Block I/O weight or the cgroup is not mounted. Weight discarded.\")\n\t\tresources.BlkioWeight = 0\n\t}\n\tif resources.BlkioWeight > 0 && (resources.BlkioWeight < 10 || resources.BlkioWeight > 1000) {\n\t\treturn warnings, fmt.Errorf(\"Range of blkio weight is from 10 to 1000\")\n\t}\n\tif resources.IOMaximumBandwidth != 0 || resources.IOMaximumIOps != 0 {\n\t\treturn warnings, fmt.Errorf(\"Invalid QoS settings: %s does not support Maximum IO Bandwidth or Maximum IO IOps\", runtime.GOOS)\n\t}\n\tif len(resources.BlkioWeightDevice) > 0 && !sysInfo.BlkioWeightDevice {\n\t\twarnings = append(warnings, \"Your kernel does not support Block I/O weight_device or the cgroup is not mounted. Weight-device discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support Block I/O weight_device or the cgroup is not mounted. Weight-device discarded.\")\n\t\tresources.BlkioWeightDevice = []*pblkiodev.WeightDevice{}\n\t}\n\tif len(resources.BlkioDeviceReadBps) > 0 && !sysInfo.BlkioReadBpsDevice {\n\t\twarnings = append(warnings, \"Your kernel does not support BPS Block I/O read limit or the cgroup is not mounted. Block I/O BPS read limit discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support BPS Block I/O read limit or the cgroup is not mounted. Block I/O BPS read limit discarded\")\n\t\tresources.BlkioDeviceReadBps = []*pblkiodev.ThrottleDevice{}\n\t}\n\tif len(resources.BlkioDeviceWriteBps) > 0 && !sysInfo.BlkioWriteBpsDevice {\n\t\twarnings = append(warnings, \"Your kernel does not support BPS Block I/O write limit or the cgroup is not mounted. Block I/O BPS write limit discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support BPS Block I/O write limit or the cgroup is not mounted. Block I/O BPS write limit discarded.\")\n\t\tresources.BlkioDeviceWriteBps = []*pblkiodev.ThrottleDevice{}\n\n\t}\n\tif len(resources.BlkioDeviceReadIOps) > 0 && !sysInfo.BlkioReadIOpsDevice {\n\t\twarnings = append(warnings, \"Your kernel does not support IOPS Block read limit or the cgroup is not mounted. Block I/O IOPS read limit discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support IOPS Block I/O read limit in IO or the cgroup is not mounted. Block I/O IOPS read limit discarded.\")\n\t\tresources.BlkioDeviceReadIOps = []*pblkiodev.ThrottleDevice{}\n\t}\n\tif len(resources.BlkioDeviceWriteIOps) > 0 && !sysInfo.BlkioWriteIOpsDevice {\n\t\twarnings = append(warnings, \"Your kernel does not support IOPS Block write limit or the cgroup is not mounted. Block I/O IOPS write limit discarded.\")\n\t\tlogrus.Warn(\"Your kernel does not support IOPS Block I/O write limit or the cgroup is not mounted. Block I/O IOPS write limit discarded.\")\n\t\tresources.BlkioDeviceWriteIOps = []*pblkiodev.ThrottleDevice{}\n\t}\n\n\treturn warnings, nil\n}", "is_vulnerable": 1}
{"code": "func (a *instanceInterceptor) handleInstance(w http.ResponseWriter, r *http.Request, next http.Handler) {\n\tfor _, prefix := range a.ignoredPrefixes {\n\t\tif strings.HasPrefix(r.URL.Path, prefix) {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t}\n\tctx, err := setInstance(r, a.verifier, a.headerName)\n\tif err != nil {\n\t\torigin := zitadel_http.ComposedOrigin(r.Context())\n\t\tlogging.WithFields(\"origin\", origin, \"externalDomain\", a.externalDomain).WithError(err).Error(\"unable to set instance\")\n\t\tzErr := new(zerrors.ZitadelError)\n\t\tif errors.As(err, &zErr) {\n\t\t\tzErr.SetMessage(a.translator.LocalizeFromRequest(r, zErr.GetMessage(), nil))\n\t\t\thttp.Error(w, fmt.Sprintf(\"unable to set instance using origin %s (ExternalDomain is %s): %s\", origin, a.externalDomain, zErr), http.StatusNotFound)\n\t\t\treturn\n\t\t}\n\t\thttp.Error(w, fmt.Sprintf(\"unable to set instance using origin %s (ExternalDomain is %s)\", origin, a.externalDomain), http.StatusNotFound)\n\t\treturn\n\t}\n\tr = r.WithContext(ctx)\n\tnext.ServeHTTP(w, r)\n}", "is_vulnerable": 0}
{"code": "func (page *DeploymentListResultPage) NextWithContext(ctx context.Context) (err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/DeploymentListResultPage.NextWithContext\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif page.Response().Response.Response != nil {\n\t\t\t\tsc = page.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tnext, err := page.fn(ctx, page.dlr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpage.dlr = next\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (us *UserExternalLoginService) ExternalLoginBindingUserSendEmail(\n\tctx context.Context, req *schema.ExternalLoginBindingUserSendEmailReq) (\n\tresp *schema.ExternalLoginBindingUserSendEmailResp, err error) {\n\tsiteGeneral, err := us.siteInfoCommonService.GetSiteGeneral(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresp = &schema.ExternalLoginBindingUserSendEmailResp{}\n\texternalLoginInfo, err := us.userExternalLoginRepo.GetCacheUserExternalLoginInfo(ctx, req.BindingKey)\n\tif err != nil || externalLoginInfo == nil {\n\t\treturn nil, errors.BadRequest(reason.UserNotFound)\n\t}\n\tif len(externalLoginInfo.Email) > 0 {\n\t\tlog.Warnf(\"the binding email has been sent %s\", req.BindingKey)\n\t\treturn &schema.ExternalLoginBindingUserSendEmailResp{}, nil\n\t}\n\n\tuserInfo, exist, err := us.userRepo.GetByEmail(ctx, req.Email)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif exist && !req.Must {\n\t\tresp.EmailExistAndMustBeConfirmed = true\n\t\treturn resp, nil\n\t}\n\n\tif !exist {\n\t\texternalLoginInfo.Email = req.Email\n\t\tuserInfo, err = us.registerNewUser(ctx, externalLoginInfo)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tresp.AccessToken, _, err = us.userCommonService.CacheLoginUserInfo(\n\t\t\tctx, userInfo.ID, userInfo.MailStatus, userInfo.Status, externalLoginInfo.ExternalID)\n\t\tif err != nil {\n\t\t\tlog.Error(err)\n\t\t}\n\t}\n\terr = us.userExternalLoginRepo.SetCacheUserExternalLoginInfo(ctx, req.BindingKey, externalLoginInfo)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// send bind confirmation email\n\tdata := &schema.EmailCodeContent{\n\t\tSourceType: schema.BindingSourceType,\n\t\tEmail:      req.Email,\n\t\tUserID:     userInfo.ID,\n\t\tBindingKey: req.BindingKey,\n\t}\n\tcode := uuid.NewString()\n\tverifyEmailURL := fmt.Sprintf(\"%s/users/account-activation?code=%s\", siteGeneral.SiteUrl, code)\n\ttitle, body, err := us.emailService.RegisterTemplate(ctx, verifyEmailURL)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tgo us.emailService.SendAndSaveCode(ctx, userInfo.EMail, title, body, code, data.ToJSONString())\n\treturn resp, nil\n}", "is_vulnerable": 1}
{"code": "func (d *Decoder) Read() (Token, error) {\n\tconst scalar = Null | Bool | Number | String\n\n\tdefer func() { d.lastCall = readCall }()\n\tif d.lastCall == peekCall {\n\t\treturn d.lastToken, d.lastErr\n\t}\n\n\ttok, err := d.parseNext()\n\tif err != nil {\n\t\treturn Token{}, err\n\t}\n\n\tswitch tok.kind {\n\tcase EOF:\n\t\tif len(d.openStack) != 0 ||\n\t\t\td.lastToken.kind&scalar|ObjectClose|ArrayClose == 0 {\n\t\t\treturn Token{}, ErrUnexpectedEOF\n\t\t}\n\n\tcase Null:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\n\tcase Bool, Number:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\n\tcase String:\n\t\tif d.isValueNext() {\n\t\t\tbreak\n\t\t}\n\t\t// This string token should only be for a field name.\n\t\tif d.lastToken.kind&(ObjectOpen|comma) == 0 {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\tif len(d.in) == 0 {\n\t\t\treturn Token{}, ErrUnexpectedEOF\n\t\t}\n\t\tif c := d.in[0]; c != ':' {\n\t\t\treturn Token{}, d.newSyntaxError(d.currPos(), `unexpected character %s, missing \":\" after field name`, string(c))\n\t\t}\n\t\ttok.kind = Name\n\t\td.consume(1)\n\n\tcase ObjectOpen, ArrayOpen:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = append(d.openStack, tok.kind)\n\n\tcase ObjectClose:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind&(Name|comma) != 0 ||\n\t\t\td.openStack[len(d.openStack)-1] != ObjectOpen {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = d.openStack[:len(d.openStack)-1]\n\n\tcase ArrayClose:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind == comma ||\n\t\t\td.openStack[len(d.openStack)-1] != ArrayOpen {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = d.openStack[:len(d.openStack)-1]\n\n\tcase comma:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind&(scalar|ObjectClose|ArrayClose) == 0 {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t}\n\n\t// Update d.lastToken only after validating token to be in the right sequence.\n\td.lastToken = tok\n\n\tif d.lastToken.kind == comma {\n\t\treturn d.Read()\n\t}\n\treturn tok, nil\n}", "is_vulnerable": 0}
{"code": "func ByteSlicePtr(b []byte) *[]byte {\n\treturn &b\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) ValidateSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (t *Table) queryEntities(uri string, headers map[string]string, ml MetadataLevel) (*EntityQueryResult, error) {\n\theaders = mergeHeaders(headers, t.tsc.client.getStandardHeaders())\n\tif ml != EmptyPayload {\n\t\theaders[headerAccept] = string(ml)\n\t}\n\n\tresp, err := t.tsc.client.exec(http.MethodGet, uri, headers, nil, t.tsc.auth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tif err = checkRespCode(resp, []int{http.StatusOK}); err != nil {\n\t\treturn nil, err\n\t}\n\n\tdata, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar entities EntityQueryResult\n\terr = json.Unmarshal(data, &entities)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor i := range entities.Entities {\n\t\tentities.Entities[i].Table = t\n\t}\n\tentities.table = t\n\n\tcontToken := extractContinuationTokenFromHeaders(resp.Header)\n\tif contToken == nil {\n\t\tentities.NextLink = nil\n\t} else {\n\t\toriginalURI, err := url.Parse(uri)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tv := originalURI.Query()\n\t\tif contToken.NextPartitionKey != \"\" {\n\t\t\tv.Set(nextPartitionKeyQueryParameter, contToken.NextPartitionKey)\n\t\t}\n\t\tif contToken.NextRowKey != \"\" {\n\t\t\tv.Set(nextRowKeyQueryParameter, contToken.NextRowKey)\n\t\t}\n\t\tnewURI := t.tsc.client.getEndpoint(tableServiceName, t.buildPath(), v)\n\t\tentities.NextLink = &newURI\n\t\tentities.ml = ml\n\t}\n\n\treturn &entities, nil\n}", "is_vulnerable": 0}
{"code": "func postServerWriteFile(c *gin.Context) {\n\ts := ExtractServer(c)\n\n\tf := c.Query(\"file\")\n\tf = \"/\" + strings.TrimLeft(f, \"/\")\n\n\tif err := s.Filesystem().IsIgnored(f); err != nil {\n\t\tmiddleware.CaptureAndAbort(c, err)\n\t\treturn\n\t}\n\tif err := s.Filesystem().Writefile(f, c.Request.Body); err != nil {\n\t\tif filesystem.IsErrorCode(err, filesystem.ErrCodeIsDirectory) {\n\t\t\tc.AbortWithStatusJSON(http.StatusBadRequest, gin.H{\n\t\t\t\t\"error\": \"Cannot write file, name conflicts with an existing directory by the same name.\",\n\t\t\t})\n\t\t\treturn\n\t\t}\n\n\t\tmiddleware.CaptureAndAbort(c, err)\n\t\treturn\n\t}\n\n\tc.Status(http.StatusNoContent)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) LootAll(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.AllLoot, error) {\n\tout := new(clientpb.AllLoot)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/LootAll\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) IsIgnored(paths ...string) error {\n\tfor _, p := range paths {\n\t\tsp, err := fs.SafePath(p)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif fs.denylist.MatchesPath(sp) {\n\t\t\treturn errors.WithStack(&Error{code: ErrCodeDenylistFile, path: p, resolved: sp})\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestDeleteApp_InvalidName(t *testing.T) {\n\tappServer := newTestAppServer()\n\t_, err := appServer.Delete(context.Background(), &application.ApplicationDeleteRequest{\n\t\tName: pointer.StringPtr(\"foo\"),\n\t})\n\tif !assert.Error(t, err) {\n\t\treturn\n\t}\n\tassert.True(t, apierrors.IsNotFound(err))\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeRequester) SetRequestedAudience(arg0 fosite.Arguments) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"SetRequestedAudience\", arg0)\n}", "is_vulnerable": 0}
{"code": "func Test_ProcessResults_whenDifferentPaths_AddsToCache(t *testing.T) {\n\ttestutil.UnitTest(t)\n\tf := NewFolder(\"dummy\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\n\tf.processResults([]snyk.Issue{\n\t\t{ID: \"id1\", AffectedFilePath: \"path1\"},\n\t\t{ID: \"id2\", AffectedFilePath: \"path2\"},\n\t})\n\n\tassert.Equal(t, 2, f.documentDiagnosticCache.Length())\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path1\"))\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path2\"))\n\tassert.Len(t, f.documentDiagnosticCache.Get(\"path1\"), 1)\n\tassert.Len(t, f.documentDiagnosticCache.Get(\"path2\"), 1)\n}", "is_vulnerable": 0}
{"code": "func TestTokenToAndFromContext_CookieToken(t *testing.T) {\n\ttoken := NewCookieToken(\"my_token\", \"gitpod.io\")\n\n\textracted, err := TokenFromContext(TokenToContext(context.Background(), token))\n\trequire.NoError(t, err)\n\trequire.Equal(t, token, extracted)\n}", "is_vulnerable": 1}
{"code": "func (generator *PayloadGenerator) loadPayloads(payloads map[string]interface{}, templatePath, templateDirectory string, sandbox bool) (map[string][]string, error) {\n\tloadedPayloads := make(map[string][]string)\n\n\tfor name, payload := range payloads {\n\t\tswitch pt := payload.(type) {\n\t\tcase string:\n\t\t\telements := strings.Split(pt, \"\\n\")\n\t\t\t//golint:gomnd // this is not a magic number\n\t\t\tif len(elements) >= 2 {\n\t\t\t\tloadedPayloads[name] = elements\n\t\t\t} else {\n\t\t\t\tif sandbox {\n\t\t\t\t\tpt = filepath.Clean(pt)\n\t\t\t\t\ttemplatePathDir := filepath.Dir(templatePath)\n\t\t\t\t\tif !(templatePathDir != \"/\" && strings.HasPrefix(pt, templatePathDir)) && !strings.HasPrefix(pt, templateDirectory) {\n\t\t\t\t\t\treturn nil, errors.New(\"denied payload file path specified\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpayloads, err := generator.loadPayloadsFromFile(pt)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, errors.Wrap(err, \"could not load payloads\")\n\t\t\t\t}\n\t\t\t\tloadedPayloads[name] = payloads\n\t\t\t}\n\t\tcase interface{}:\n\t\t\tloadedPayloads[name] = cast.ToStringSlice(pt)\n\t\t}\n\t}\n\treturn loadedPayloads, nil\n}", "is_vulnerable": 1}
{"code": "func (e *EgressDNS) signalAdded(dnsName string) {\n\te.added <- dnsName\n}", "is_vulnerable": 1}
{"code": "func (future *DeploymentsCreateOrUpdateFuture) Result(client DeploymentsClient) (de DeploymentExtended, err error) {\n\tvar done bool\n\tdone, err = future.Done(client)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsCreateOrUpdateFuture\", \"Result\", future.Response(), \"Polling failure\")\n\t\treturn\n\t}\n\tif !done {\n\t\terr = azure.NewAsyncOpIncompleteError(\"resources.DeploymentsCreateOrUpdateFuture\")\n\t\treturn\n\t}\n\tsender := autorest.DecorateSender(client, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))\n\tif de.Response.Response, err = future.GetResult(sender); err == nil && de.Response.Response.StatusCode != http.StatusNoContent {\n\t\tde, err = client.CreateOrUpdateResponder(de.Response.Response)\n\t\tif err != nil {\n\t\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsCreateOrUpdateFuture\", \"Result\", de.Response.Response, \"Failure responding to request\")\n\t\t}\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (h *HTMLResponseWriter) write(apiOp *types.APIRequest, code int, obj interface{}) {\n\th.start(apiOp, code)\n\tschemaSchema := apiOp.Schemas.Schemas[\"schema\"]\n\theaderString := start\n\tif schemaSchema != nil {\n\t\theaderString = strings.Replace(headerString, \"%SCHEMAS%\", jsonEncodeURL(apiOp.URLBuilder.Collection(schemaSchema)), 1)\n\t}\n\tvar jsurl, cssurl string\n\tif h.CSSURL != nil && h.JSURL != nil && h.CSSURL() != \"\" && h.JSURL() != \"\" {\n\t\tjsurl = h.JSURL()\n\t\tcssurl = h.CSSURL()\n\t} else if h.APIUIVersion != nil && h.APIUIVersion() != \"\" {\n\t\tjsurl = strings.Replace(JSURL, \"%API_UI_VERSION%\", h.APIUIVersion(), 1)\n\t\tcssurl = strings.Replace(CSSURL, \"%API_UI_VERSION%\", h.APIUIVersion(), 1)\n\t} else {\n\t\tjsurl = strings.Replace(JSURL, \"%API_UI_VERSION%\", DefaultVersion, 1)\n\t\tcssurl = strings.Replace(CSSURL, \"%API_UI_VERSION%\", DefaultVersion, 1)\n\t}\n\n\t// jsurl and cssurl are added to the document as attributes not entities which requires special encoding.\n\tjsurl, _ = encodeAttribute(jsurl)\n\tcssurl, _ = encodeAttribute(cssurl)\n\n\theaderString = strings.Replace(headerString, \"%JSURL%\", jsurl, 1)\n\theaderString = strings.Replace(headerString, \"%CSSURL%\", cssurl, 1)\n\n\tapiOp.Response.Write([]byte(headerString))\n\tif apiObj, ok := obj.(types.APIObject); ok {\n\t\th.Body(apiOp, apiOp.Response, apiObj)\n\t} else if list, ok := obj.(types.APIObjectList); ok {\n\t\th.BodyList(apiOp, apiOp.Response, list)\n\t}\n\tif schemaSchema != nil {\n\t\tapiOp.Response.Write(end)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *Timer) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Timer: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Timer: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Time1\", wireType)\n\t\t\t}\n\t\t\tm.Time1 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Time1 = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 2:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Time2\", wireType)\n\t\t\t}\n\t\t\tm.Time2 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Time2 = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Data\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Data = append(m.Data[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Data == nil {\n\t\t\t\tm.Data = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (p *Pack) teamPack() (*uint, error) {\n\tif !p.isTeamPack() {\n\t\treturn nil, nil\n\t}\n\tt := strings.TrimPrefix(*p.Type, \"team-\")\n\tteamID, err := strconv.ParseUint(t, 10, 64)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn ptr.Uint(uint(teamID)), nil\n}", "is_vulnerable": 0}
{"code": "func (c *fakePluginClient) CallResource(ctx context.Context, req *backend.CallResourceRequest, sender backend.CallResourceResponseSender) error {\n\tc.req = req\n\tbytes, err := json.Marshal(map[string]interface{}{\n\t\t\"message\": \"hello\",\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn sender.Send(&backend.CallResourceResponse{\n\t\tStatus:  http.StatusOK,\n\t\tHeaders: make(map[string][]string),\n\t\tBody:    bytes,\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) StopService(ctx context.Context, in *sliverpb.StopServiceReq, opts ...grpc.CallOption) (*sliverpb.ServiceInfo, error) {\n\tout := new(sliverpb.ServiceInfo)\n\terr := c.cc.Invoke(ctx, SliverRPC_StopService_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func NewExportProxyDeployment(namespace, repository, imagePrefix, version, productName, productVersion, productComponent, image string, pullPolicy corev1.PullPolicy, imagePullSecrets []corev1.LocalObjectReference, verbosity string, extraEnv map[string]string) (*appsv1.Deployment, error) {\n\tpodAntiAffinity := newPodAntiAffinity(kubevirtLabelKey, kubernetesHostnameTopologyKey, metav1.LabelSelectorOpIn, []string{VirtAPIName})\n\tdeploymentName := VirtExportProxyName\n\timageName := fmt.Sprintf(\"%s%s\", imagePrefix, deploymentName)\n\tenv := operatorutil.NewEnvVarMap(extraEnv)\n\tdeployment, err := newBaseDeployment(deploymentName, imageName, namespace, repository, version, productName, productVersion, productComponent, image, pullPolicy, imagePullSecrets, podAntiAffinity, env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tattachCertificateSecret(&deployment.Spec.Template.Spec, VirtExportProxyCertSecretName, \"/etc/virt-exportproxy/certificates\")\n\tattachProfileVolume(&deployment.Spec.Template.Spec)\n\n\tpod := &deployment.Spec.Template.Spec\n\tpod.ServiceAccountName = rbac.ExportProxyServiceAccountName\n\tpod.SecurityContext = &corev1.PodSecurityContext{\n\t\tRunAsNonRoot: boolPtr(true),\n\t}\n\n\tconst shortName = \"exportproxy\"\n\tcontainer := &deployment.Spec.Template.Spec.Containers[0]\n\t// virt-exportproxy too long\n\tcontainer.Name = shortName\n\tcontainer.Command = []string{\n\t\tVirtExportProxyName,\n\t\tportName,\n\t\t\"8443\",\n\t\t\"-v\",\n\t\tverbosity,\n\t}\n\tcontainer.Ports = []corev1.ContainerPort{\n\t\t{\n\t\t\tName:          shortName,\n\t\t\tProtocol:      corev1.ProtocolTCP,\n\t\t\tContainerPort: 8443,\n\t\t},\n\t\t{\n\t\t\tName:          \"metrics\",\n\t\t\tProtocol:      corev1.ProtocolTCP,\n\t\t\tContainerPort: 8443,\n\t\t},\n\t}\n\n\tcontainer.ReadinessProbe = &corev1.Probe{\n\t\tProbeHandler: corev1.ProbeHandler{\n\t\t\tHTTPGet: &corev1.HTTPGetAction{\n\t\t\t\tScheme: corev1.URISchemeHTTPS,\n\t\t\t\tPort: intstr.IntOrString{\n\t\t\t\t\tType:   intstr.Int,\n\t\t\t\t\tIntVal: 8443,\n\t\t\t\t},\n\t\t\t\tPath: \"/healthz\",\n\t\t\t},\n\t\t},\n\t\tInitialDelaySeconds: 15,\n\t\tPeriodSeconds:       10,\n\t}\n\n\tcontainer.Resources = corev1.ResourceRequirements{\n\t\tRequests: corev1.ResourceList{\n\t\t\tcorev1.ResourceCPU:    resource.MustParse(\"5m\"),\n\t\t\tcorev1.ResourceMemory: resource.MustParse(\"150Mi\"),\n\t\t},\n\t}\n\n\treturn deployment, nil\n}", "is_vulnerable": 1}
{"code": "func (m *NinRepNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipPacked(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestPlainSplit_NoUser(t *testing.T) {\n\ta := Auth{\n\t\tpasswd: []module.PlainAuth{\n\t\t\tmockAuth{\n\t\t\t\tdb: map[string][]string{\n\t\t\t\t\t\"user1\": []string{\"user1a\", \"user1b\"},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tids, err := a.AuthPlain(\"user1\", \"aaa\")\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected error:\", err)\n\t}\n\tif !reflect.DeepEqual(ids, []string{\"user1a\", \"user1b\"}) {\n\t\tt.Fatal(\"Wrong ids returned:\", ids)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestNewAPIKey(t *testing.T) {\n\ttestcases := []struct {\n\t\tname      string\n\t\treq       *requests.Request\n\t\twant      map[string]interface{}\n\t\tshouldErr bool\n\t\terr       error\n\t}{\n\t\t{\n\t\t\tname: \"test api key\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:   \"api\",\n\t\t\t\t\tComment: \"jsmith-api-key\",\n\t\t\t\t\tPayload: util.GetRandomStringFromRange(54, 72),\n\t\t\t\t},\n\t\t\t},\n\t\t\twant: map[string]interface{}{\n\t\t\t\t\"usage\":    \"api\",\n\t\t\t\t\"comment\":  \"jsmith-api-key\",\n\t\t\t\t\"disabled\": false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"test disabled api key\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:    \"api\",\n\t\t\t\t\tComment:  \"jsmith-api-key\",\n\t\t\t\t\tDisabled: true,\n\t\t\t\t\tPayload:  util.GetRandomStringFromRange(54, 72),\n\t\t\t\t},\n\t\t\t},\n\t\t\twant: map[string]interface{}{\n\t\t\t\t\"usage\":    \"api\",\n\t\t\t\t\"comment\":  \"jsmith-api-key\",\n\t\t\t\t\"disabled\": true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"test api key with empty payload\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:    \"api\",\n\t\t\t\t\tComment:  \"jsmith-api-key\",\n\t\t\t\t\tDisabled: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tshouldErr: true,\n\t\t\terr:       errors.ErrAPIKeyPayloadEmpty,\n\t\t},\n\t\t{\n\t\t\tname: \"test api key with empty payload\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:    \"api\",\n\t\t\t\t\tComment:  \"jsmith-api-key\",\n\t\t\t\t\tDisabled: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tshouldErr: true,\n\t\t\terr:       errors.ErrAPIKeyPayloadEmpty,\n\t\t},\n\t\t{\n\t\t\tname: \"test api key with empty usage\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tComment:  \"jsmith-api-key\",\n\t\t\t\t\tPayload:  util.GetRandomStringFromRange(54, 72),\n\t\t\t\t\tDisabled: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tshouldErr: true,\n\t\t\terr:       errors.ErrAPIKeyUsageEmpty,\n\t\t},\n\t\t{\n\t\t\tname: \"test api key with unsupported usage\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:    \"foo\",\n\t\t\t\t\tComment:  \"jsmith-api-key\",\n\t\t\t\t\tPayload:  util.GetRandomStringFromRange(54, 72),\n\t\t\t\t\tDisabled: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tshouldErr: true,\n\t\t\terr:       errors.ErrAPIKeyUsageUnsupported.WithArgs(\"foo\"),\n\t\t},\n\t\t{\n\t\t\tname: \"test api key with empty comment\",\n\t\t\treq: &requests.Request{\n\t\t\t\tKey: requests.Key{\n\t\t\t\t\tUsage:    \"api\",\n\t\t\t\t\tPayload:  util.GetRandomStringFromRange(54, 72),\n\t\t\t\t\tDisabled: true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tshouldErr: true,\n\t\t\terr:       errors.ErrAPIKeyCommentEmpty,\n\t\t},\n\t}\n\n\tfor _, tc := range testcases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tmsgs := []string{fmt.Sprintf(\"test name: %s\", tc.name)}\n\t\t\tif tc.req.Key.Payload != \"\" {\n\t\t\t\ttc.req.Response.Payload = tc.req.Key.Payload\n\t\t\t\thk, err := NewPassword(tc.req.Key.Payload)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"unexpected password generation error: %s\", err)\n\t\t\t\t}\n\t\t\t\ttc.req.Key.Payload = hk.Hash\n\t\t\t}\n\t\t\tkey, err := NewAPIKey(tc.req)\n\t\t\tif tests.EvalErrWithLog(t, err, \"new api key\", tc.shouldErr, tc.err, msgs) {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tgot := make(map[string]interface{})\n\t\t\tgot[\"usage\"] = key.Usage\n\t\t\tgot[\"comment\"] = key.Comment\n\t\t\tgot[\"disabled\"] = key.Disabled\n\n\t\t\ttests.EvalObjectsWithLog(t, \"eval\", tc.want, got, msgs)\n\t\t\tkey.Disable()\n\n\t\t\tbundle := NewAPIKeyBundle()\n\t\t\tbundle.Add(key)\n\t\t\tbundle.Get()\n\t\t\tbundle.Size()\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (iv *ImageVerification) Validate(isAuditFailureAction bool, path *field.Path) (errs field.ErrorList) {\n\tcopy := iv.Convert()\n\n\tif isAuditFailureAction && iv.MutateDigest {\n\t\terrs = append(errs, field.Invalid(path.Child(\"mutateDigest\"), iv.MutateDigest, \"mutateDigest must be set to false for \u2018Audit\u2019 failure action\"))\n\t}\n\n\tif len(copy.ImageReferences) == 0 {\n\t\terrs = append(errs, field.Invalid(path, iv, \"An image reference is required\"))\n\t}\n\n\tasPath := path.Child(\"attestations\")\n\tfor i, attestation := range copy.Attestations {\n\t\tattestationErrors := attestation.Validate(asPath.Index(i))\n\t\terrs = append(errs, attestationErrors...)\n\t}\n\n\tattestorsPath := path.Child(\"attestors\")\n\tfor i, as := range copy.Attestors {\n\t\tattestorErrors := as.Validate(attestorsPath.Index(i))\n\t\terrs = append(errs, attestorErrors...)\n\t}\n\n\tif iv.Type == Notary {\n\t\tfor _, attestorSet := range iv.Attestors {\n\t\t\tfor _, attestor := range attestorSet.Entries {\n\t\t\t\tif attestor.Keyless != nil {\n\t\t\t\t\terrs = append(errs, field.Invalid(attestorsPath, iv, \"Keyless field is not allowed for type notary\"))\n\t\t\t\t}\n\t\t\t\tif attestor.Keys != nil {\n\t\t\t\t\terrs = append(errs, field.Invalid(attestorsPath, iv, \"Keys field is not allowed for type notary\"))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "is_vulnerable": 0}
{"code": "func (ps *PlatformService) hubStart(broadcastHooks map[string]BroadcastHook) {\n\t// Total number of hubs is twice the number of CPUs.\n\tnumberOfHubs := runtime.NumCPU() * 2\n\tps.logger.Info(\"Starting websocket hubs\", mlog.Int(\"number_of_hubs\", numberOfHubs))\n\n\thubs := make([]*Hub, numberOfHubs)\n\n\tfor i := 0; i < numberOfHubs; i++ {\n\t\thubs[i] = newWebHub(ps)\n\t\thubs[i].connectionIndex = i\n\t\thubs[i].broadcastHooks = broadcastHooks\n\t\thubs[i].Start()\n\t}\n\t// Assigning to the hubs slice without any mutex is fine because it is only assigned once\n\t// during the start of the program and always read from after that.\n\tps.hubs = hubs\n}", "is_vulnerable": 0}
{"code": "func TestAllowElementsContent(t *testing.T) {\n\tpolicy := NewPolicy().AllowElementsContent(\"iframe\", \"script\")\n\n\ttests := []test{\n\t\t{\n\t\t\tin:       \"<iframe src='http://url.com/test'>this is fallback content</iframe>\",\n\t\t\texpected: \"this is fallback content\",\n\t\t},\n\t\t{\n\t\t\tin:       \"<script>var a = 10; alert(a);</script>\",\n\t\t\texpected: \"var a = 10; alert(a);\",\n\t\t},\n\t}\n\n\tfor ii, test := range tests {\n\t\tout := policy.Sanitize(test.in)\n\t\tif out != test.expected {\n\t\t\tt.Errorf(\n\t\t\t\t\"test %d failed;\\ninput   : %s\\noutput  : %s\\nexpected: %s\",\n\t\t\t\tii,\n\t\t\t\ttest.in,\n\t\t\t\tout,\n\t\t\t\ttest.expected,\n\t\t\t)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Prevent directory listings.\n\t\tif strings.HasSuffix(r.URL.Path, \"/\") {\n\t\t\thttp.NotFound(w, r)\n\t\t\treturn\n\t\t}\n\n\t\tw.Header().Set(\"Content-Type\", \"binary/octet-stream\")\n\t\tparent.ServeHTTP(w, r)\n\t})", "is_vulnerable": 0}
{"code": "func (b *Backend) Send(msg BackendMessage) error {\n\tbuf, err := msg.Encode(nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = b.w.Write(buf)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessTokenStrategy) ValidateAccessToken(arg0 context.Context, arg1 fosite.Requester, arg2 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"ValidateAccessToken\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (l *LdapAPI) Ping() {\n\tvar ldapConfs models.LdapConf\n\tvar err error\n\tvar ldapSession *ldapUtils.Session\n\n\tl.Ctx.Input.CopyBody(1 << 32)\n\n\tif string(l.Ctx.Input.RequestBody) == \"\" {\n\t\tldapSession, err = ldapUtils.LoadSystemLdapConfig()\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Can't load system configuration, error: %v\", err)\n\t\t\tl.RenderError(http.StatusInternalServerError, pingErrorMessage)\n\t\t\treturn\n\t\t}\n\t\terr = ldapSession.ConnectionTest()\n\t} else {\n\t\tl.DecodeJSONReqAndValidate(&ldapConfs)\n\t\terr = ldapUtils.ConnectionTestWithConfig(ldapConfs)\n\t}\n\n\tif err != nil {\n\t\tlog.Errorf(\"ldap connect fail, error: %v\", err)\n\t\t// do not return any detail information of the error, or may cause SSRF security issue #3755\n\t\tl.RenderError(http.StatusBadRequest, pingErrorMessage)\n\t\treturn\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestInitialAllocationListBinaryProtocol(t *testing.T) {\n\tvar m MyTestStruct\n\td := NewDeserializer()\n\tf := NewBinaryProtocolFactoryDefault()\n\td.Protocol = f.GetProtocol(d.Transport)\n\t// attempts to allocate a list with 1.8B elements for a 20 byte message\n\tdata := []byte(\"\\n\\x10\\rO\\t6\\x03\\n\\n\\n\\x10\\x0f\\n\\tslice\\x00\")\n\terr := d.Read(&m, data)\n\tif err == nil {\n\t\tt.Fatalf(\"Parsed invalid message correctly\")\n\t} else if !strings.Contains(err.Error(), \"Invalid data length\") {\n\t\tt.Fatalf(\"Failed for reason besides Invalid data length\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetBindMount(ctx *types.SystemContext, args []string, contextDir string, store storage.Store, imageMountLabel string, additionalMountPoints map[string]internal.StageMountDetails, workDir string) (specs.Mount, string, error) {\n\tnewMount := specs.Mount{\n\t\tType: define.TypeBind,\n\t}\n\n\tsetRelabel := false\n\tmountReadability := false\n\tsetDest := false\n\tbindNonRecursive := false\n\tfromImage := \"\"\n\n\tfor _, val := range args {\n\t\tkv := strings.SplitN(val, \"=\", 2)\n\t\tswitch kv[0] {\n\t\tcase \"type\":\n\t\t\t// This is already processed\n\t\t\tcontinue\n\t\tcase \"bind-nonrecursive\":\n\t\t\tnewMount.Options = append(newMount.Options, \"bind\")\n\t\t\tbindNonRecursive = true\n\t\tcase \"ro\", \"nosuid\", \"nodev\", \"noexec\":\n\t\t\t// TODO: detect duplication of these options.\n\t\t\t// (Is this necessary?)\n\t\t\tnewMount.Options = append(newMount.Options, kv[0])\n\t\t\tmountReadability = true\n\t\tcase \"rw\", \"readwrite\":\n\t\t\tnewMount.Options = append(newMount.Options, \"rw\")\n\t\t\tmountReadability = true\n\t\tcase \"readonly\":\n\t\t\t// Alias for \"ro\"\n\t\t\tnewMount.Options = append(newMount.Options, \"ro\")\n\t\t\tmountReadability = true\n\t\tcase \"shared\", \"rshared\", \"private\", \"rprivate\", \"slave\", \"rslave\", \"Z\", \"z\", \"U\":\n\t\t\tnewMount.Options = append(newMount.Options, kv[0])\n\t\tcase \"from\":\n\t\t\tif len(kv) == 1 {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%v: %w\", kv[0], errBadOptionArg)\n\t\t\t}\n\t\t\tfromImage = kv[1]\n\t\tcase \"bind-propagation\":\n\t\t\tif len(kv) == 1 {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%v: %w\", kv[0], errBadOptionArg)\n\t\t\t}\n\t\t\tnewMount.Options = append(newMount.Options, kv[1])\n\t\tcase \"src\", \"source\":\n\t\t\tif len(kv) == 1 {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%v: %w\", kv[0], errBadOptionArg)\n\t\t\t}\n\t\t\tnewMount.Source = kv[1]\n\t\tcase \"target\", \"dst\", \"destination\":\n\t\t\tif len(kv) == 1 {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%v: %w\", kv[0], errBadOptionArg)\n\t\t\t}\n\t\t\ttargetPath := kv[1]\n\t\t\tif !path.IsAbs(targetPath) {\n\t\t\t\ttargetPath = filepath.Join(workDir, targetPath)\n\t\t\t}\n\t\t\tif err := parse.ValidateVolumeCtrDir(targetPath); err != nil {\n\t\t\t\treturn newMount, \"\", err\n\t\t\t}\n\t\t\tnewMount.Destination = targetPath\n\t\t\tsetDest = true\n\t\tcase \"relabel\":\n\t\t\tif setRelabel {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"cannot pass 'relabel' option more than once: %w\", errBadOptionArg)\n\t\t\t}\n\t\t\tsetRelabel = true\n\t\t\tif len(kv) != 2 {\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%s mount option must be 'private' or 'shared': %w\", kv[0], errBadMntOption)\n\t\t\t}\n\t\t\tswitch kv[1] {\n\t\t\tcase \"private\":\n\t\t\t\tnewMount.Options = append(newMount.Options, \"Z\")\n\t\t\tcase \"shared\":\n\t\t\t\tnewMount.Options = append(newMount.Options, \"z\")\n\t\t\tdefault:\n\t\t\t\treturn newMount, \"\", fmt.Errorf(\"%s mount option must be 'private' or 'shared': %w\", kv[0], errBadMntOption)\n\t\t\t}\n\t\tcase \"consistency\":\n\t\t\t// Option for OS X only, has no meaning on other platforms\n\t\t\t// and can thus be safely ignored.\n\t\t\t// See also the handling of the equivalent \"delegated\" and \"cached\" in ValidateVolumeOpts\n\t\tdefault:\n\t\t\treturn newMount, \"\", fmt.Errorf(\"%v: %w\", kv[0], errBadMntOption)\n\t\t}\n\t}\n\n\t// default mount readability is always readonly\n\tif !mountReadability {\n\t\tnewMount.Options = append(newMount.Options, \"ro\")\n\t}\n\n\t// Following variable ensures that we return imagename only if we did additional mount\n\tisImageMounted := false\n\tif fromImage != \"\" {\n\t\tmountPoint := \"\"\n\t\tif additionalMountPoints != nil {\n\t\t\tif val, ok := additionalMountPoints[fromImage]; ok {\n\t\t\t\tmountPoint = val.MountPoint\n\t\t\t}\n\t\t}\n\t\t// if mountPoint of image was not found in additionalMap\n\t\t// or additionalMap was nil, try mounting image\n\t\tif mountPoint == \"\" {\n\t\t\timage, err := internalUtil.LookupImage(ctx, store, fromImage)\n\t\t\tif err != nil {\n\t\t\t\treturn newMount, \"\", err\n\t\t\t}\n\n\t\t\tmountPoint, err = image.Mount(context.Background(), nil, imageMountLabel)\n\t\t\tif err != nil {\n\t\t\t\treturn newMount, \"\", err\n\t\t\t}\n\t\t\tisImageMounted = true\n\t\t}\n\t\tcontextDir = mountPoint\n\t}\n\n\t// buildkit parity: default bind option must be `rbind`\n\t// unless specified\n\tif !bindNonRecursive {\n\t\tnewMount.Options = append(newMount.Options, \"rbind\")\n\t}\n\n\tif !setDest {\n\t\treturn newMount, fromImage, errBadVolDest\n\t}\n\n\t// buildkit parity: support absolute path for sources from current build context\n\tif contextDir != \"\" {\n\t\t// path should be /contextDir/specified path\n\t\tnewMount.Source = filepath.Join(contextDir, filepath.Clean(string(filepath.Separator)+newMount.Source))\n\t} else {\n\t\t// looks like its coming from `build run --mount=type=bind` allow using absolute path\n\t\t// error out if no source is set\n\t\tif newMount.Source == \"\" {\n\t\t\treturn newMount, \"\", errBadVolSrc\n\t\t}\n\t\tif err := parse.ValidateVolumeHostDir(newMount.Source); err != nil {\n\t\t\treturn newMount, \"\", err\n\t\t}\n\t}\n\n\topts, err := parse.ValidateVolumeOpts(newMount.Options)\n\tif err != nil {\n\t\treturn newMount, fromImage, err\n\t}\n\tnewMount.Options = opts\n\n\tif !isImageMounted {\n\t\t// we don't want any cleanups if image was not mounted explicitly\n\t\t// so dont return anything\n\t\tfromImage = \"\"\n\t}\n\n\treturn newMount, fromImage, nil\n}", "is_vulnerable": 1}
{"code": "func (d *Data) Name() string {\n\tres := C.GoString(C.gpgme_data_get_file_name(d.dh))\n\truntime.KeepAlive(d)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func (c *AuthConfig) getAuthenticationHandler(mux cmdutil.Mux, errorHandler handlers.AuthenticationErrorHandler) (handlers.AuthenticationHandler, error) {\n\tchallengers := map[string]handlers.AuthenticationChallenger{}\n\tredirectors := map[string]handlers.AuthenticationRedirector{}\n\n\tfor _, identityProvider := range c.Options.IdentityProviders {\n\t\tidentityMapper := identitymapper.NewAlwaysCreateUserIdentityToUserMapper(c.IdentityRegistry, c.UserRegistry)\n\n\t\tif configapi.IsPasswordAuthenticator(identityProvider) {\n\t\t\tpasswordAuth, err := c.getPasswordAuthenticator(identityProvider)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tif identityProvider.UseAsLogin {\n\t\t\t\t// Password auth requires:\n\t\t\t\t// 1. a session success handler (to remember you logged in)\n\t\t\t\t// 2. a redirectSuccessHandler (to go back to the \"then\" param)\n\t\t\t\tif c.SessionAuth == nil {\n\t\t\t\t\treturn nil, errors.New(\"SessionAuth is required for password-based login\")\n\t\t\t\t}\n\t\t\t\tpasswordSuccessHandler := handlers.AuthenticationSuccessHandlers{c.SessionAuth, redirectSuccessHandler{}}\n\n\t\t\t\tredirectors[\"login\"] = &redirector{RedirectURL: OpenShiftLoginPrefix, ThenParam: \"then\"}\n\t\t\t\tlogin := login.NewLogin(getCSRF(), &callbackPasswordAuthenticator{passwordAuth, passwordSuccessHandler}, login.DefaultLoginFormRenderer)\n\t\t\t\tlogin.Install(mux, OpenShiftLoginPrefix)\n\t\t\t}\n\t\t\tif identityProvider.UseAsChallenger {\n\t\t\t\tchallengers[\"login\"] = passwordchallenger.NewBasicAuthChallenger(\"openshift\")\n\t\t\t}\n\n\t\t} else if configapi.IsOAuthIdentityProvider(identityProvider) {\n\t\t\toauthProvider, err := c.getOAuthProvider(identityProvider)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// Default state builder, combining CSRF and return URL handling\n\t\t\tstate := external.CSRFRedirectingState(getCSRF())\n\n\t\t\t// OAuth auth requires\n\t\t\t// 1. a session success handler (to remember you logged in)\n\t\t\t// 2. a state success handler (to go back to the URL encoded in the state)\n\t\t\tif c.SessionAuth == nil {\n\t\t\t\treturn nil, errors.New(\"SessionAuth is required for OAuth-based login\")\n\t\t\t}\n\t\t\toauthSuccessHandler := handlers.AuthenticationSuccessHandlers{c.SessionAuth, state}\n\n\t\t\t// If the specified errorHandler doesn't handle the login error, let the state error handler attempt to propagate specific errors back to the token requester\n\t\t\toauthErrorHandler := handlers.AuthenticationErrorHandlers{errorHandler, state}\n\n\t\t\tcallbackPath := path.Join(OpenShiftOAuthCallbackPrefix, identityProvider.Name)\n\t\t\toauthHandler, err := external.NewExternalOAuthRedirector(oauthProvider, state, c.Options.MasterPublicURL+callbackPath, oauthSuccessHandler, oauthErrorHandler, identityMapper)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected error: %v\", err)\n\t\t\t}\n\n\t\t\tmux.Handle(callbackPath, oauthHandler)\n\t\t\tif identityProvider.UseAsLogin {\n\t\t\t\tredirectors[identityProvider.Name] = oauthHandler\n\t\t\t}\n\t\t\tif identityProvider.UseAsChallenger {\n\t\t\t\treturn nil, errors.New(\"oauth identity providers cannot issue challenges\")\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(redirectors) > 0 && len(challengers) == 0 {\n\t\t// Add a default challenger that will warn and give a link to the web browser token-granting location\n\t\tchallengers[\"placeholder\"] = placeholderchallenger.New(OpenShiftOAuthTokenRequestURL(c.Options.MasterPublicURL))\n\t}\n\n\tauthHandler := handlers.NewUnionAuthenticationHandler(challengers, redirectors, errorHandler)\n\treturn authHandler, nil\n}", "is_vulnerable": 1}
{"code": "func (svc *Service) ListUsers(ctx context.Context, opt fleet.UserListOptions) ([]*fleet.User, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.User{}, fleet.ActionRead); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn svc.ds.ListUsers(ctx, opt)\n}", "is_vulnerable": 1}
{"code": "func TestIngressAuthBadAuthType(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(authTypeAnnotation)] = \"invalid\"\n\ting.SetAnnotations(data)\n\n\t_, dir, _ := dummySecretContent(t)\n\tdefer os.RemoveAll(dir)\n\n\texpected := ing_errors.NewValidationError(\"nginx.ingress.kubernetes.io/auth-type\")\n\t_, err := NewParser(dir, &mockSecret{}).Parse(ing)\n\tif err.Error() != expected.Error() {\n\t\tt.Errorf(\"expected '%v' but got '%v'\", expected, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) WGStopPortForward(ctx context.Context, in *sliverpb.WGPortForwardStopReq, opts ...grpc.CallOption) (*sliverpb.WGPortForward, error) {\n\tout := new(sliverpb.WGPortForward)\n\terr := c.cc.Invoke(ctx, SliverRPC_WGStopPortForward_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (m *managerImpl) podEphemeralStorageLimitEviction(podStats statsapi.PodStats, pod *v1.Pod) bool {\n\t_, podLimits := apiv1resource.PodRequestsAndLimits(pod)\n\t_, found := podLimits[v1.ResourceEphemeralStorage]\n\tif !found {\n\t\treturn false\n\t}\n\n\tpodEphemeralStorageTotalUsage := &resource.Quantity{}\n\tvar fsStatsSet []fsStatsType\n\tif *m.dedicatedImageFs {\n\t\tfsStatsSet = []fsStatsType{fsStatsLogs, fsStatsLocalVolumeSource}\n\t} else {\n\t\tfsStatsSet = []fsStatsType{fsStatsRoot, fsStatsLogs, fsStatsLocalVolumeSource}\n\t}\n\tpodEphemeralUsage, err := podLocalEphemeralStorageUsage(podStats, pod, fsStatsSet, m.etcHostsPath(pod.UID))\n\tif err != nil {\n\t\tklog.Errorf(\"eviction manager: error getting pod disk usage %v\", err)\n\t\treturn false\n\t}\n\n\tpodEphemeralStorageTotalUsage.Add(podEphemeralUsage[v1.ResourceEphemeralStorage])\n\tpodEphemeralStorageLimit := podLimits[v1.ResourceEphemeralStorage]\n\tif podEphemeralStorageTotalUsage.Cmp(podEphemeralStorageLimit) > 0 {\n\t\t// the total usage of pod exceeds the total size limit of containers, evict the pod\n\t\tif m.evictPod(pod, 0, fmt.Sprintf(podEphemeralStorageMessageFmt, podEphemeralStorageLimit.String()), nil) {\n\t\t\tmetrics.Evictions.WithLabelValues(signalEphemeralPodFsLimit).Inc()\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func generateBytes(n int) ([]byte, error) {\n\tb := make([]byte, n)\n\t_, err := rand.Read(b)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, nil\n}", "is_vulnerable": 0}
{"code": "func RandomAlphaNumeric(count int) (string, error) {\n\tRandomString, err := Random(count, 0, 0, true, true)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"Error: %s\", err)\n\t}\n\n\treturn RandomString[:count], nil\n\n}", "is_vulnerable": 0}
{"code": "func (f Formatter) sanitize(kvList []any) []any {\n\tif len(kvList)%2 != 0 {\n\t\tkvList = append(kvList, noValue)\n\t}\n\tfor i := 0; i < len(kvList); i += 2 {\n\t\t_, ok := kvList[i].(string)\n\t\tif !ok {\n\t\t\tkvList[i] = f.nonStringKey(kvList[i])\n\t\t}\n\t}\n\treturn kvList\n}", "is_vulnerable": 0}
{"code": "func (mgr *SessionManager) Parse(tokenString string) (jwt.Claims, error) {\n\t// Parse takes the token string and a function for looking up the key. The latter is especially\n\t// useful if you use multiple keys for your application.  The standard is to use 'kid' in the\n\t// head of the token to identify which key to use, but the parsed token (head and claims) is provided\n\t// to the callback, providing flexibility.\n\tvar claims jwt.MapClaims\n\tsettings, err := mgr.settingsMgr.GetSettings()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttoken, err := jwt.ParseWithClaims(tokenString, &claims, func(token *jwt.Token) (interface{}, error) {\n\t\t// Don't forget to validate the alg is what you expect:\n\t\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\t\treturn nil, fmt.Errorf(\"Unexpected signing method: %v\", token.Header[\"alg\"])\n\t\t}\n\t\treturn settings.ServerSignature, nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tissuedAt, err := jwtutil.IssuedAtTime(claims)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsubject := jwtutil.StringField(claims, \"sub\")\n\tid := jwtutil.StringField(claims, \"jti\")\n\n\tif projName, role, ok := rbacpolicy.GetProjectRoleFromSubject(subject); ok {\n\t\tproj, err := mgr.projectsLister.Get(projName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, _, err = proj.GetJWTToken(role, issuedAt.Unix(), id)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn token.Claims, nil\n\t}\n\n\taccount, err := mgr.settingsMgr.GetAccount(subject)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !account.Enabled {\n\t\treturn nil, fmt.Errorf(\"account %s is disabled\", subject)\n\t}\n\n\tif id := jwtutil.StringField(claims, \"jti\"); id != \"\" && account.TokenIndex(id) == -1 {\n\t\treturn nil, fmt.Errorf(\"account %s does not have token with id %s\", subject, id)\n\t}\n\n\tif account.PasswordMtime != nil && issuedAt.Before(*account.PasswordMtime) {\n\t\treturn nil, fmt.Errorf(\"Account password has changed since token issued\")\n\t}\n\treturn token.Claims, nil\n}", "is_vulnerable": 0}
{"code": "func ParseDistinguishedName(name string) (map[string]string, error) {\n\tif strings.Contains(name, \"=#\") {\n\t\treturn nil, fmt.Errorf(\"unsupported distinguished name (DN) %q: notation does not support x509.subject identities containing \\\"=#\\\"\", name)\n\t}\n\n\tmandatoryFields := []string{\"C\", \"ST\", \"O\"}\n\tattrKeyValue := make(map[string]string)\n\tdn, err := ldapv3.ParseDN(name)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing distinguished name (DN) %q failed with err: %v. A valid DN must contain 'C', 'ST', and 'O' RDN attributes at a minimum, and follow RFC 4514 standard\", name, err)\n\t}\n\n\tfor _, rdn := range dn.RDNs {\n\t\t// multi-valued RDNs are not supported (TODO: add spec reference here)\n\t\tif len(rdn.Attributes) > 1 {\n\t\t\treturn nil, fmt.Errorf(\"distinguished name (DN) %q has multi-valued RDN attributes, remove multi-valued RDN attributes as they are not supported\", name)\n\t\t}\n\t\tfor _, attribute := range rdn.Attributes {\n\t\t\tif attrKeyValue[attribute.Type] == \"\" {\n\t\t\t\tattrKeyValue[attribute.Type] = attribute.Value\n\t\t\t} else {\n\t\t\t\treturn nil, fmt.Errorf(\"distinguished name (DN) %q has duplicate RDN attribute for %q, DN can only have unique RDN attributes\", name, attribute.Type)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Verify mandatory fields are present\n\tfor _, field := range mandatoryFields {\n\t\tif attrKeyValue[field] == \"\" {\n\t\t\treturn nil, fmt.Errorf(\"distinguished name (DN) %q has no mandatory RDN attribute for %q, it must contain 'C', 'ST', and 'O' RDN attributes at a minimum\", name, field)\n\t\t}\n\t}\n\t// No errors\n\treturn attrKeyValue, nil\n}", "is_vulnerable": 0}
{"code": "\tdefer func() { arcKeyDirectory = before }()", "is_vulnerable": 0}
{"code": "func (m *Struct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Struct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Struct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fields\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Fields == nil {\n\t\t\t\tm.Fields = make(map[string]*Value)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue *Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipStruct(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Fields[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipStruct(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *Compiler) stepWorkingDir(container *yaml_types.Container) string {\n\tif path.IsAbs(container.Directory) {\n\t\treturn container.Directory\n\t}\n\treturn path.Join(c.base, c.path, container.Directory)\n}", "is_vulnerable": 1}
{"code": "func LocalMounterWithMounts(mounts []mount.Mount) Mounter {\n\treturn &localMounter{mounts: mounts}\n}", "is_vulnerable": 1}
{"code": "func TestSkipUnknownTypeBinaryProtocol(t *testing.T) {\n\tvar m MyTestStruct\n\td := NewDeserializer()\n\tf := NewBinaryProtocolFactoryDefault()\n\td.Protocol = f.GetProtocol(d.Transport)\n\t// skip over a map with invalid key/value type and 1.7B entries\n\tdata := []byte(\"\\n\\x10\\rO\\t6\\x03\\n\\n\\n\\x10\\r\\n\\tslice\\x00\")\n\tstart := time.Now()\n\terr := d.Read(&m, data)\n\tif err == nil {\n\t\tt.Fatalf(\"Parsed invalid message correctly\")\n\t} else if !strings.Contains(err.Error(), \"unknown type\") {\n\t\tt.Fatalf(\"Failed for reason besides unknown type\")\n\t}\n\n\tif time.Now().Sub(start).Seconds() > 5 {\n\t\tt.Fatalf(\"It should not take seconds to parse a small message\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (autoApi *AutoCodeApi) GetDB(c *gin.Context) {\n\tdbs, err := autoCodeService.Database().GetDB()\n\tvar dbList []map[string]interface{}\n\tfor _, db := range global.GVA_CONFIG.DBList {\n\t\tvar item = make(map[string]interface{})\n\t\titem[\"aliasName\"] = db.AliasName\n\t\titem[\"dbName\"] = db.Dbname\n\t\titem[\"disable\"] = db.Disable\n\t\tdbList = append(dbList, item)\n\t}\n\tif err != nil {\n\t\tglobal.GVA_LOG.Error(\"\u83b7\u53d6\u5931\u8d25!\", zap.Error(err))\n\t\tresponse.FailWithMessage(\"\u83b7\u53d6\u5931\u8d25\", c)\n\t} else {\n\t\tresponse.OkWithDetailed(gin.H{\"dbs\": dbs, \"dbList\": dbList}, \"\u83b7\u53d6\u6210\u529f\", c)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestRouteRedirectTrailingSlash(t *testing.T) {\n\trouter := New()\n\trouter.RedirectFixedPath = false\n\trouter.RedirectTrailingSlash = true\n\trouter.GET(\"/path\", func(c *Context) {})\n\trouter.GET(\"/path2/\", func(c *Context) {})\n\trouter.POST(\"/path3\", func(c *Context) {})\n\trouter.PUT(\"/path4/\", func(c *Context) {})\n\n\tw := PerformRequest(router, http.MethodGet, \"/path/\")\n\tassert.Equal(t, \"/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, http.StatusMovedPermanently, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\")\n\tassert.Equal(t, \"/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, http.StatusMovedPermanently, w.Code)\n\n\tw = PerformRequest(router, http.MethodPost, \"/path3/\")\n\tassert.Equal(t, \"/path3\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, http.StatusTemporaryRedirect, w.Code)\n\n\tw = PerformRequest(router, http.MethodPut, \"/path4\")\n\tassert.Equal(t, \"/path4/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, http.StatusTemporaryRedirect, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path\")\n\tassert.Equal(t, http.StatusOK, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2/\")\n\tassert.Equal(t, http.StatusOK, w.Code)\n\n\tw = PerformRequest(router, http.MethodPost, \"/path3\")\n\tassert.Equal(t, http.StatusOK, w.Code)\n\n\tw = PerformRequest(router, http.MethodPut, \"/path4/\")\n\tassert.Equal(t, http.StatusOK, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\", header{Key: \"X-Forwarded-Prefix\", Value: \"/api\"})\n\tassert.Equal(t, \"/api/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2/\", header{Key: \"X-Forwarded-Prefix\", Value: \"/api/\"})\n\tassert.Equal(t, 200, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"../../api#?\"})\n\tassert.Equal(t, \"/api/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"../../api\"})\n\tassert.Equal(t, \"/api/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\", header{Key: \"X-Forwarded-Prefix\", Value: \"../../api\"})\n\tassert.Equal(t, \"/api/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\", header{Key: \"X-Forwarded-Prefix\", Value: \"/../../api\"})\n\tassert.Equal(t, \"/api/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"api/../../\"})\n\tassert.Equal(t, \"//path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"api/../../../\"})\n\tassert.Equal(t, \"/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\", header{Key: \"X-Forwarded-Prefix\", Value: \"../../gin-gonic.com\"})\n\tassert.Equal(t, \"/gin-goniccom/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path2\", header{Key: \"X-Forwarded-Prefix\", Value: \"/../../gin-gonic.com\"})\n\tassert.Equal(t, \"/gin-goniccom/path2/\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"https://gin-gonic.com/#\"})\n\tassert.Equal(t, \"https/gin-goniccom/https/gin-goniccom/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"#api\"})\n\tassert.Equal(t, \"api/api/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"/nor-mal/#?a=1\"})\n\tassert.Equal(t, \"/nor-mal/a1/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\", header{Key: \"X-Forwarded-Prefix\", Value: \"/nor-mal/%2e%2e/\"})\n\tassert.Equal(t, \"/nor-mal/2e2e/path\", w.Header().Get(\"Location\"))\n\tassert.Equal(t, 301, w.Code)\n\n\trouter.RedirectTrailingSlash = false\n\n\tw = PerformRequest(router, http.MethodGet, \"/path/\")\n\tassert.Equal(t, http.StatusNotFound, w.Code)\n\tw = PerformRequest(router, http.MethodGet, \"/path2\")\n\tassert.Equal(t, http.StatusNotFound, w.Code)\n\tw = PerformRequest(router, http.MethodPost, \"/path3/\")\n\tassert.Equal(t, http.StatusNotFound, w.Code)\n\tw = PerformRequest(router, http.MethodPut, \"/path4\")\n\tassert.Equal(t, http.StatusNotFound, w.Code)\n}", "is_vulnerable": 0}
{"code": "func (b *Builder) buildMetricsHTTPConnectionManagerFilter() (*envoy_config_listener_v3.Filter, error) {\n\trc, err := b.buildRouteConfiguration(\"metrics\", []*envoy_config_route_v3.VirtualHost{{\n\t\tName:    \"metrics\",\n\t\tDomains: []string{\"*\"},\n\t\tRoutes: []*envoy_config_route_v3.Route{{\n\t\t\tName: \"metrics\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Prefix{Prefix: \"/\"},\n\t\t\t},\n\t\t\tAction: &envoy_config_route_v3.Route_Route{\n\t\t\t\tRoute: &envoy_config_route_v3.RouteAction{\n\t\t\t\t\tClusterSpecifier: &envoy_config_route_v3.RouteAction_Cluster{\n\t\t\t\t\t\tCluster: \"pomerium-control-plane-metrics\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}},\n\t}})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ttc := marshalAny(&envoy_http_connection_manager.HttpConnectionManager{\n\t\tCodecType:  envoy_http_connection_manager.HttpConnectionManager_AUTO,\n\t\tStatPrefix: \"metrics\",\n\t\tRouteSpecifier: &envoy_http_connection_manager.HttpConnectionManager_RouteConfig{\n\t\t\tRouteConfig: rc,\n\t\t},\n\t\tHttpFilters: []*envoy_http_connection_manager.HttpFilter{{\n\t\t\tName: \"envoy.filters.http.router\",\n\t\t}},\n\t})\n\n\treturn &envoy_config_listener_v3.Filter{\n\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\tConfigType: &envoy_config_listener_v3.Filter_TypedConfig{\n\t\t\tTypedConfig: tc,\n\t\t},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (t *Trashcan) Archive(filePath string) error {\n\tinfo, err := osutil.Lstat(filePath)\n\tif os.IsNotExist(err) {\n\t\tl.Debugln(\"not archiving nonexistent file\", filePath)\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn err\n\t}\n\tif info.Mode()&os.ModeSymlink != 0 {\n\t\tpanic(\"bug: attempting to version a symlink\")\n\t}\n\n\tversionsDir := filepath.Join(t.folderPath, \".stversions\")\n\tif _, err := os.Stat(versionsDir); err != nil {\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn err\n\t\t}\n\n\t\tl.Debugln(\"creating versions dir\", versionsDir)\n\t\tif err := osutil.MkdirAll(versionsDir, 0777); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tosutil.HideFile(versionsDir)\n\t}\n\n\tl.Debugln(\"archiving\", filePath)\n\n\trelativePath, err := filepath.Rel(t.folderPath, filePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tarchivedPath := filepath.Join(versionsDir, relativePath)\n\tif err := osutil.MkdirAll(filepath.Dir(archivedPath), 0777); err != nil && !os.IsExist(err) {\n\t\treturn err\n\t}\n\n\tl.Debugln(\"moving to\", archivedPath)\n\n\tif err := osutil.Rename(filePath, archivedPath); err != nil {\n\t\treturn err\n\t}\n\n\t// Set the mtime to the time the file was deleted. This is used by the\n\t// cleanout routine. If this fails things won't work optimally but there's\n\t// not much we can do about it so we ignore the error.\n\tos.Chtimes(archivedPath, time.Now(), time.Now())\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (es *EmailService) SendAndSaveCode(ctx context.Context, toEmailAddr, subject, body, code, codeContent string) {\n\tes.Send(ctx, toEmailAddr, subject, body)\n\terr := es.emailRepo.SetCode(ctx, code, codeContent, 10*time.Minute)\n\tif err != nil {\n\t\tlog.Error(err)\n\t}\n}", "is_vulnerable": 1}
{"code": "\thttp.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tstart := time.Now()\n\t\tw.WriteHeader(http.StatusNotFound)\n\t\tfmt.Fprint(w, \"default backend - 404\")\n\n\t\tduration := time.Now().Sub(start).Seconds() * 1e3\n\n\t\tproto := strconv.Itoa(r.ProtoMajor)\n\t\tproto = proto + \".\" + strconv.Itoa(r.ProtoMinor)\n\n\t\trequestCount.WithLabelValues(proto).Inc()\n\t\trequestDuration.WithLabelValues(proto).Observe(duration)\n\t})", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateSymlinkExternal(c *C) {\n\ttype testcase struct {\n\t\tpath   string\n\t\ttarget string\n\t}\n\n\ts.bootstrapEmptyContainer(c)\n\tfor _, t := range []testcase{\n\t\t{\"meta/snap.yaml\", \"../..\"},\n\t\t{\"meta/snap.yaml\", \"../../\"},\n\t\t{\"meta/snap.yaml\", \"../../rev2\"},\n\t\t{\"meta/snap.yaml\", \"../../../core/current/meta/snap.yaml\"},\n\t\t{\"meta/gui/icons/snap.png\", \"../1/../../2/../../3/4/../../../test\"},\n\t\t{\"meta/gui/icons/snap.png\", \"/etc/shadow\"},\n\t\t{\"meta/gui/icons/snap.png\", \"/var/snap/other-snap/current/sensitive\"},\n\t} {\n\t\tc.Assert(os.MkdirAll(filepath.Join(s.snapDirPath, filepath.Dir(t.path)), 0755), IsNil)\n\t\tc.Assert(os.RemoveAll(filepath.Join(s.snapDirPath, t.path)), IsNil)\n\t\tc.Assert(os.Symlink(t.target, filepath.Join(s.snapDirPath, t.path)), IsNil)\n\n\t\tcmt := Commentf(fmt.Sprintf(\"path: %s, target: %s\", t.path, t.target))\n\t\texpectedError := fmt.Sprintf(\"external symlink found: %s -> %s\", t.path, t.target)\n\t\t_, err := snap.EvalAndValidateSymlink(s.container(), t.path)\n\t\tc.Check(err, ErrorMatches, expectedError, cmt)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestEncodeDecode(t *testing.T) {\n\tsrcBytes := []byte{'W', 0x00, 0x00, 0x00, 0x0b, 0x01, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01}\n\tdstResp := pgproto3.CopyBothResponse{}\n\terr := dstResp.Decode(srcBytes[5:])\n\tassert.NoError(t, err, \"No errors on decode\")\n\tdstBytes := []byte{}\n\tdstBytes = dstResp.Encode(dstBytes)\n\tassert.EqualValues(t, srcBytes, dstBytes, \"Expecting src & dest bytes to match\")\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"legacy_admin\", func(t *testing.T) {\n\t\tt.Parallel()\n\n\t\tif _, err := CompileAndAuthorize(LegacyRealmAdmin, []Permission{LegacyRealmAdmin}); err != nil {\n\t\t\tt.Error(err)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func TestInitialAllocationSetCompactProtocol(t *testing.T) {\n\tvar m MyTestStruct\n\td := NewDeserializer()\n\tf := NewCompactProtocolFactory()\n\td.Protocol = f.GetProtocol(d.Transport)\n\t// attempts to allocate a list of 950M elements for an 11 byte message\n\tdata := []byte(\"%0\\xa8\\xfa\\x97\\xb7\\xc4\\xc4\\x03\\x01a\")\n\terr := d.Read(&m, data)\n\tif err == nil {\n\t\tt.Fatalf(\"Parsed invalid message correctly\")\n\t} else if !strings.Contains(err.Error(), \"Invalid data length\") {\n\t\tt.Fatalf(\"Failed for reason besides Invalid data length\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (r *KustomizationReconciler) reconcile(\n\tctx context.Context,\n\tkustomization kustomizev1.Kustomization,\n\tsource sourcev1.Source) (kustomizev1.Kustomization, error) {\n\t// record the value of the reconciliation request, if any\n\tif v, ok := meta.ReconcileAnnotationValue(kustomization.GetAnnotations()); ok {\n\t\tkustomization.Status.SetLastHandledReconcileRequest(v)\n\t}\n\n\trevision := source.GetArtifact().Revision\n\n\t// create tmp dir\n\ttmpDir, err := os.MkdirTemp(\"\", kustomization.Name)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"tmp dir error: %w\", err)\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tsourcev1.DirCreationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\tdefer os.RemoveAll(tmpDir)\n\n\t// download artifact and extract files\n\terr = r.download(source.GetArtifact(), tmpDir)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// check build path exists\n\tdirPath, err := securejoin.SecureJoin(tmpDir, kustomization.Spec.Path)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\tif _, err := os.Stat(dirPath); err != nil {\n\t\terr = fmt.Errorf(\"kustomization path not found: %w\", err)\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ArtifactFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// setup the Kubernetes client for impersonation\n\timpersonation := NewKustomizeImpersonation(kustomization, r.Client, r.StatusPoller, r.DefaultServiceAccount, r.KubeConfigOpts)\n\tkubeClient, statusPoller, err := impersonation.GetClient(ctx)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), fmt.Errorf(\"failed to build kube client: %w\", err)\n\t}\n\n\t// generate kustomization.yaml if needed\n\terr = r.generate(kustomization, dirPath)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// build the kustomization\n\tresources, err := r.build(ctx, tmpDir, kustomization, dirPath)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// convert the build result into Kubernetes unstructured objects\n\tobjects, err := ssa.ReadObjects(bytes.NewReader(resources))\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.BuildFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// create a snapshot of the current inventory\n\toldStatus := kustomization.Status.DeepCopy()\n\n\t// create the server-side apply manager\n\tresourceManager := ssa.NewResourceManager(kubeClient, statusPoller, ssa.Owner{\n\t\tField: r.ControllerName,\n\t\tGroup: kustomizev1.GroupVersion.Group,\n\t})\n\tresourceManager.SetOwnerLabels(objects, kustomization.GetName(), kustomization.GetNamespace())\n\n\t// validate and apply resources in stages\n\tdrifted, changeSet, err := r.apply(ctx, resourceManager, kustomization, revision, objects)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// create an inventory of objects to be reconciled\n\tnewInventory := NewInventory()\n\terr = AddObjectsToInventory(newInventory, changeSet)\n\tif err != nil {\n\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\tkustomization,\n\t\t\trevision,\n\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// detect stale objects which are subject to garbage collection\n\tvar staleObjects []*unstructured.Unstructured\n\tif oldStatus.Inventory != nil {\n\t\tdiffObjects, err := DiffInventory(oldStatus.Inventory, newInventory)\n\t\tif err != nil {\n\t\t\treturn kustomizev1.KustomizationNotReady(\n\t\t\t\tkustomization,\n\t\t\t\trevision,\n\t\t\t\tkustomizev1.ReconciliationFailedReason,\n\t\t\t\terr.Error(),\n\t\t\t), err\n\t\t}\n\n\t\t// TODO: remove this workaround after kustomize-controller 0.18 release\n\t\t// skip objects that were wrongly marked as namespaced\n\t\t// https://github.com/fluxcd/kustomize-controller/issues/466\n\t\tnewObjects, _ := ListObjectsInInventory(newInventory)\n\t\tfor _, obj := range diffObjects {\n\t\t\tpreserve := false\n\t\t\tif obj.GetNamespace() != \"\" {\n\t\t\t\tfor _, newObj := range newObjects {\n\t\t\t\t\tif newObj.GetNamespace() == \"\" &&\n\t\t\t\t\t\tobj.GetKind() == newObj.GetKind() &&\n\t\t\t\t\t\tobj.GetAPIVersion() == newObj.GetAPIVersion() &&\n\t\t\t\t\t\tobj.GetName() == newObj.GetName() {\n\t\t\t\t\t\tpreserve = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !preserve {\n\t\t\t\tstaleObjects = append(staleObjects, obj)\n\t\t\t}\n\t\t}\n\t}\n\n\t// run garbage collection for stale objects that do not have pruning disabled\n\tif _, err := r.prune(ctx, resourceManager, kustomization, revision, staleObjects); err != nil {\n\t\treturn kustomizev1.KustomizationNotReadyInventory(\n\t\t\tkustomization,\n\t\t\tnewInventory,\n\t\t\trevision,\n\t\t\tkustomizev1.PruneFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\t// health assessment\n\tif err := r.checkHealth(ctx, resourceManager, kustomization, revision, drifted, changeSet.ToObjMetadataSet()); err != nil {\n\t\treturn kustomizev1.KustomizationNotReadyInventory(\n\t\t\tkustomization,\n\t\t\tnewInventory,\n\t\t\trevision,\n\t\t\tkustomizev1.HealthCheckFailedReason,\n\t\t\terr.Error(),\n\t\t), err\n\t}\n\n\treturn kustomizev1.KustomizationReadyInventory(\n\t\tkustomization,\n\t\tnewInventory,\n\t\trevision,\n\t\tkustomizev1.ReconciliationSucceededReason,\n\t\tfmt.Sprintf(\"Applied revision: %s\", revision),\n\t), nil\n}", "is_vulnerable": 1}
{"code": "func (s *Server) addMetricsBucketMatcher(bucket string) {\n\ts.metricsBuckets[bucket] = true\n}", "is_vulnerable": 0}
{"code": "func retryForIMDS(sender Sender, req *http.Request, maxAttempts int) (resp *http.Response, err error) {\n\t// copied from client.go due to circular dependency\n\tretries := []int{\n\t\thttp.StatusRequestTimeout,      // 408\n\t\thttp.StatusTooManyRequests,     // 429\n\t\thttp.StatusInternalServerError, // 500\n\t\thttp.StatusBadGateway,          // 502\n\t\thttp.StatusServiceUnavailable,  // 503\n\t\thttp.StatusGatewayTimeout,      // 504\n\t}\n\t// extra retry status codes specific to IMDS\n\tretries = append(retries,\n\t\thttp.StatusNotFound,\n\t\thttp.StatusGone,\n\t\t// all remaining 5xx\n\t\thttp.StatusNotImplemented,\n\t\thttp.StatusHTTPVersionNotSupported,\n\t\thttp.StatusVariantAlsoNegotiates,\n\t\thttp.StatusInsufficientStorage,\n\t\thttp.StatusLoopDetected,\n\t\thttp.StatusNotExtended,\n\t\thttp.StatusNetworkAuthenticationRequired)\n\n\t// see https://docs.microsoft.com/en-us/azure/active-directory/managed-service-identity/how-to-use-vm-token#retry-guidance\n\n\tconst maxDelay time.Duration = 60 * time.Second\n\n\tattempt := 0\n\tdelay := time.Duration(0)\n\n\tfor attempt < maxAttempts {\n\t\tresp, err = sender.Do(req)\n\t\t// we want to retry if err is not nil or the status code is in the list of retry codes\n\t\tif err == nil && !responseHasStatusCode(resp, retries...) {\n\t\t\treturn\n\t\t}\n\n\t\t// perform exponential backoff with a cap.\n\t\t// must increment attempt before calculating delay.\n\t\tattempt++\n\t\t// the base value of 2 is the \"delta backoff\" as specified in the guidance doc\n\t\tdelay += (time.Duration(math.Pow(2, float64(attempt))) * time.Second)\n\t\tif delay > maxDelay {\n\t\t\tdelay = maxDelay\n\t\t}\n\n\t\tselect {\n\t\tcase <-time.After(delay):\n\t\t\t// intentionally left blank\n\t\tcase <-req.Context().Done():\n\t\t\terr = req.Context().Err()\n\t\t\treturn\n\t\t}\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func InDelta(t TestingT, expected interface{}, actual interface{}, delta float64, msgAndArgs ...interface{}) {\n\tif assert.InDelta(t, expected, actual, delta, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (r *TerraformRunnerServer) Plan(ctx context.Context, req *PlanRequest) (*PlanReply, error) {\n\tlog := controllerruntime.LoggerFrom(ctx, \"instance-id\", r.InstanceID).WithName(loggerName)\n\tlog.Info(\"creating a plan\")\n\tctx, cancel := context.WithCancel(ctx)\n\tgo func() {\n\t\tselect {\n\t\tcase <-r.Done:\n\t\t\tcancel()\n\t\tcase <-ctx.Done():\n\t\t}\n\t}()\n\n\tif req.TfInstance != r.InstanceID {\n\t\terr := fmt.Errorf(\"no TF instance found\")\n\t\tlog.Error(err, \"no terraform\")\n\t\treturn nil, err\n\t}\n\n\tvar planOpt []tfexec.PlanOption\n\tif req.Out != \"\" {\n\t\tplanOpt = append(planOpt, tfexec.Out(req.Out))\n\t} else {\n\t\t// if backend is disabled completely, there will be no plan output file (req.Out = \"\")\n\t\tlog.Info(\"backend seems to be disabled completely, so there will be no plan output file\")\n\t}\n\n\tif req.Refresh == false {\n\t\tplanOpt = append(planOpt, tfexec.Refresh(req.Refresh))\n\t}\n\n\tif req.Destroy {\n\t\tplanOpt = append(planOpt, tfexec.Destroy(req.Destroy))\n\t}\n\n\tfor _, target := range req.Targets {\n\t\tplanOpt = append(planOpt, tfexec.Target(target))\n\t}\n\n\tdrifted, err := r.tf.Plan(ctx, planOpt...)\n\tif err != nil {\n\t\tst := status.New(codes.Internal, err.Error())\n\t\tvar stateErr *tfexec.ErrStateLocked\n\n\t\tif errors.As(err, &stateErr) {\n\t\t\tst, err = st.WithDetails(&PlanReply{Message: \"not ok\", StateLockIdentifier: stateErr.ID})\n\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\n\t\tlog.Error(err, \"error creating the plan\")\n\t\treturn nil, st.Err()\n\t}\n\n\tplanCreated := false\n\tif req.Out != \"\" {\n\t\tplanCreated = true\n\t\tplan, err := r.tf.ShowPlanFile(ctx, req.Out)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// This is the case when the plan is empty.\n\t\tif plan.PlannedValues.Outputs == nil &&\n\t\t\tplan.PlannedValues.RootModule.Resources == nil &&\n\t\t\tplan.ResourceChanges == nil &&\n\t\t\tplan.PriorState == nil &&\n\t\t\tplan.OutputChanges == nil {\n\t\t\tplanCreated = false\n\t\t}\n\t}\n\n\treturn &PlanReply{Message: \"ok\", Drifted: drifted, PlanCreated: planCreated}, nil\n}", "is_vulnerable": 1}
{"code": "func FsMkdir(c *gin.Context) {\n\tvar req MkdirOrLinkReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\treq.Path = stdpath.Join(user.BasePath, req.Path)\n\tif !user.CanWrite() {\n\t\tmeta, err := db.GetNearestMeta(stdpath.Dir(req.Path))\n\t\tif err != nil {\n\t\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif !common.CanWrite(meta, req.Path) {\n\t\t\tcommon.ErrorResp(c, errs.PermissionDenied, 403)\n\t\t\treturn\n\t\t}\n\t}\n\tif err := fs.MakeDir(c, req.Path); err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\tfs.ClearCache(stdpath.Dir(req.Path))\n\tcommon.SuccessResp(c)\n}", "is_vulnerable": 0}
{"code": "func (t *Teler) checkBadReferrer(r *http.Request) error {\n\t// Parse the request referer URL\n\tref, err := url.Parse(r.Referer())\n\tif err != nil {\n\t\t// If there is an error parsing the URL, return nil\n\t\t// TODO: What should we do so as not to stop the threat analysis chain from analyzeRequest?\n\t\treturn nil\n\t}\n\n\t// Extract the effective top-level domain plus one from the hostname of the referer URL\n\teTLD1, err := publicsuffix.EffectiveTLDPlusOne(ref.Hostname())\n\tif err != nil {\n\t\t// If there is an error extracting the effective top-level domain plus one, return nil\n\t\t// TODO: What should we do so as not to stop the threat analysis chain from analyzeRequest?\n\t\treturn nil\n\t}\n\n\t// Check if the root domain of request referer header is in the BadReferrer index\n\tif t.inThreatIndex(threat.BadReferrer, eTLD1) {\n\t\t// If the domain is found in the index, return an error indicating a bad HTTP referer\n\t\treturn errors.New(\"bad HTTP referer\")\n\t}\n\n\t// Return nil if no match is found in the BadReferrer index\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (patch UserPatch) Validate() error {\n\tif patch.Username != nil && len(*patch.Username) < 4 {\n\t\treturn fmt.Errorf(\"username is too short, minimum length is 4\")\n\t}\n\tif patch.Username != nil && len(*patch.Username) > 32 {\n\t\treturn fmt.Errorf(\"username is too long, maximum length is 32\")\n\t}\n\tif patch.Password != nil && len(*patch.Password) < 4 {\n\t\treturn fmt.Errorf(\"password is too short, minimum length is 4\")\n\t}\n\tif patch.Nickname != nil && len(*patch.Nickname) > 64 {\n\t\treturn fmt.Errorf(\"nickname is too long, maximum length is 64\")\n\t}\n\tif patch.Email != nil {\n\t\tif len(*patch.Email) > 256 {\n\t\t\treturn fmt.Errorf(\"email is too long, maximum length is 256\")\n\t\t}\n\t\tif common.ValidateEmail(*patch.Email) {\n\t\t\treturn fmt.Errorf(\"invalid email format\")\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *Context) Encrypt(recipients []*Key, flags EncryptFlag, plaintext, ciphertext *Data) error {\n\tsize := unsafe.Sizeof(new(C.gpgme_key_t))\n\trecp := C.calloc(C.size_t(len(recipients)+1), C.size_t(size))\n\tdefer C.free(recp)\n\tfor i := range recipients {\n\t\tptr := (*C.gpgme_key_t)(unsafe.Pointer(uintptr(recp) + size*uintptr(i)))\n\t\t*ptr = recipients[i].k\n\t}\n\terr := C.gpgme_op_encrypt(c.ctx, (*C.gpgme_key_t)(recp), C.gpgme_encrypt_flags_t(flags), plaintext.dh, ciphertext.dh)\n\truntime.KeepAlive(plaintext)\n\truntime.KeepAlive(ciphertext)\n\treturn handleError(err)\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerSnapYamlBadPermsFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\td := c.MkDir()\n\tc.Assert(os.Chmod(d, 0755), IsNil)\n\tc.Assert(os.Mkdir(filepath.Join(d, \"meta\"), 0755), IsNil)\n\tc.Assert(os.WriteFile(filepath.Join(d, \"meta\", \"snap.yaml\"), nil, 0), IsNil)\n\n\t// snapdir's / and /meta are 0755 (i.e. OK),\n\t// /meta/snap.yaml exists, but isn't readable\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(snapdir.New(d), info, discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 1}
{"code": "func (c Config) BuildOAuthConfig(activeDirectoryEndpoint string) (*OAuthConfig, error) {\n\tmultiAuth := OAuthConfig{}\n\tvar err error\n\n\tmultiAuth.OAuth, err = c.GetOAuthConfig(activeDirectoryEndpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(c.AuxiliaryTenantIDs) > 0 {\n\t\tmultiAuth.MultiTenantOauth, err = c.GetMultiTenantOAuthConfig(activeDirectoryEndpoint)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &multiAuth, nil\n}", "is_vulnerable": 0}
{"code": "func TestPathTraversalExploit(t *testing.T) {\n\tif runtime.GOOS != globalWindowsOSName {\n\t\tt.Skip()\n\t}\n\tdefer DetectTestLeak(t)()\n\tExecExtendedObjectLayerAPITest(t, testPathTraversalExploit, []string{\"PutObject\"})\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateSymlinkSnapMount(c *C) {\n\ttype testcase struct {\n\t\tpath   string\n\t\ttarget string\n\t}\n\n\ts.bootstrapEmptyContainer(c)\n\tfor _, t := range []testcase{\n\t\t{\"meta/snap.yaml\", \"..\"},\n\t\t{\"meta/snap.yaml\", \"../\"},\n\t\t{\"meta/gui/icons/snap.png\", \"../1/../../2/../../3/4/../..\"},\n\t} {\n\t\tc.Assert(os.MkdirAll(filepath.Join(s.snapDirPath, filepath.Dir(t.path)), 0755), IsNil)\n\t\tc.Assert(os.RemoveAll(filepath.Join(s.snapDirPath, t.path)), IsNil)\n\t\tc.Assert(os.Symlink(t.target, filepath.Join(s.snapDirPath, t.path)), IsNil)\n\n\t\tcmt := Commentf(fmt.Sprintf(\"path: %s, target: %s\", t.path, t.target))\n\t\texpectedError := fmt.Sprintf(\"bad symlink found: %s -> %s\", t.path, t.target)\n\t\t_, err := snap.EvalAndValidateSymlink(s.container(), t.path)\n\t\tc.Check(err, ErrorMatches, expectedError, cmt)\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\tmutate: func(service *corev1.Service) {\n\t\t\t\tservice.Spec.SessionAffinity = corev1.ServiceAffinityNone\n\t\t\t},", "is_vulnerable": 1}
{"code": "\t\t\t\treturn proxycfg.TestConfigSnapshot(t, func(ns *structs.NodeService) {\n\t\t\t\t\tns.Proxy.Config[\"protocol\"] = \"http\"\n\t\t\t\t\tns.Proxy.EnvoyExtensions = []structs.EnvoyExtension{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: api.BuiltinLuaExtension,\n\t\t\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"ProxyType\": \"connect-proxy\",\n\t\t\t\t\t\t\t\t\"Listener\":  \"inbound\",\n\t\t\t\t\t\t\t\t\"Script\": `\nfunction envoy_on_request(request_handle)\n  request_handle:headers():add(\"test\", \"test\")\nend`,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t}\n\t\t\t\t}, nil)", "is_vulnerable": 1}
{"code": "func (s *Stat) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(struct {\n\t\tName      string `json:\"name\"`\n\t\tCreated   string `json:\"created\"`\n\t\tModified  string `json:\"modified\"`\n\t\tMode      string `json:\"mode\"`\n\t\tModeBits  string `json:\"mode_bits\"`\n\t\tSize      int64  `json:\"size\"`\n\t\tDirectory bool   `json:\"directory\"`\n\t\tFile      bool   `json:\"file\"`\n\t\tSymlink   bool   `json:\"symlink\"`\n\t\tMime      string `json:\"mime\"`\n\t}{\n\t\tName:     s.Name(),\n\t\tCreated:  s.CTime().Format(time.RFC3339),\n\t\tModified: s.ModTime().Format(time.RFC3339),\n\t\tMode:     s.Mode().String(),\n\t\t// Using `&os.ModePerm` on the file's mode will cause the mode to only have the permission values, and nothing else.\n\t\tModeBits:  strconv.FormatUint(uint64(s.Mode()&os.ModePerm), 8),\n\t\tSize:      s.Size(),\n\t\tDirectory: s.IsDir(),\n\t\tFile:      !s.IsDir(),\n\t\tSymlink:   s.Mode().Perm()&os.ModeSymlink != 0,\n\t\tMime:      s.Mimetype,\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestCycleDetectionCheckResolver(t *testing.T) {\n\tt.Cleanup(func() {\n\t\tgoleak.VerifyNone(t)\n\t})\n\n\tctx := context.Background()\n\n\tcycleDetectionCheckResolver := NewCycleDetectionCheckResolver()\n\tt.Cleanup(cycleDetectionCheckResolver.Close)\n\n\tt.Run(\"detects_cycle_and_returns_cycle_detected_error\", func(t *testing.T) {\n\t\tcyclicalTuple := tuple.NewTupleKey(\"document:1\", \"viewer\", \"user:will\")\n\n\t\tvisitedPaths := make(map[string]struct{}, 0)\n\t\tvisitedPaths[tuple.TupleKeyToString(cyclicalTuple)] = struct{}{}\n\n\t\tresp, err := cycleDetectionCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:         uuid.NewString(),\n\t\t\tTupleKey:        cyclicalTuple,\n\t\t\tRequestMetadata: NewCheckRequestMetadata(defaultResolveNodeLimit),\n\t\t\tVisitedPaths:    visitedPaths,\n\t\t})\n\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, resp)\n\t\trequire.False(t, resp.GetAllowed())\n\t\trequire.True(t, resp.GetCycleDetected())\n\t\trequire.NotNil(t, resp.ResolutionMetadata)\n\t})\n\n\tt.Run(\"no_cycle_detected_delegates_request\", func(t *testing.T) {\n\t\tctrl := gomock.NewController(t)\n\t\tt.Cleanup(ctrl.Finish)\n\n\t\tmockLocalChecker := NewMockCheckResolver(ctrl)\n\t\tmockLocalChecker.EXPECT().ResolveCheck(gomock.Any(), gomock.Any()).Return(&ResolveCheckResponse{\n\t\t\tAllowed: true,\n\t\t}, nil).Times(1)\n\t\tcycleDetectionCheckResolver.SetDelegate(mockLocalChecker)\n\n\t\tresp, err := cycleDetectionCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:         uuid.NewString(),\n\t\t\tTupleKey:        tuple.NewTupleKey(\"document:1\", \"viewer\", \"user:will\"),\n\t\t\tRequestMetadata: NewCheckRequestMetadata(defaultResolveNodeLimit),\n\t\t\tVisitedPaths:    map[string]struct{}{},\n\t\t})\n\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, resp.GetAllowed())\n\t})\n}", "is_vulnerable": 0}
{"code": "\t\trender: func(comp common.ApplicationComponent, patcher *value.Value, clusterName string, overrideNamespace string, _ string) (*unstructured.Unstructured, []*unstructured.Unstructured, error) {\n\t\t\treturn &unstructured.Unstructured{\n\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\"apiVersion\": \"apps/v1\",\n\t\t\t\t\t\t\"kind\":       \"Deployment\",\n\t\t\t\t\t},\n\t\t\t\t}, []*unstructured.Unstructured{\n\t\t\t\t\t{\n\t\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\t\"apiVersion\": \"core.oam.dev/v1alpha2\",\n\t\t\t\t\t\t\t\"kind\":       \"ManualScalerTrait\",\n\t\t\t\t\t\t\t\"metadata\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\"labels\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\t\"trait.oam.dev/resource\": \"scaler\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"spec\": map[string]interface{}{\"replicaCount\": int64(10)},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, nil\n\t\t},", "is_vulnerable": 1}
{"code": "func submitHandler(w http.ResponseWriter, r *http.Request) {\n\n\tswitch r.Method {\n\tcase \"GET\":\n\t\tt := tmpl.Lookup(\"submit.html\")\n\t\terr := t.ExecuteTemplate(w, \"submit\", nil)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\tcase \"POST\":\n\t\t// prepare target\n\t\turl, err := url.Parse(strings.TrimSpace(r.FormValue(\"url\")))\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif !options.AllowInsecureURIs {\n\t\t\tif !strings.HasPrefix(url.Scheme, \"http\") {\n\t\t\t\thttp.Error(w, \"only http(s) urls are accepted\", http.StatusNotAcceptable)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tfn := lib.SafeFileName(url.String())\n\t\tfp := lib.ScreenshotPath(fn, url, options.ScreenshotPath)\n\n\t\tresp, title, err := chrm.Preflight(url)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tvar rid uint\n\t\tif rsDB != nil {\n\t\t\tif rid, err = chrm.StorePreflight(url, rsDB, resp, title, fn); err != nil {\n\t\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tbuf, err := chrm.Screenshot(url)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif err := ioutil.WriteFile(fp, buf, 0644); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tif rid > 0 {\n\t\t\thttp.Redirect(w, r, \"/details?id=\"+strconv.Itoa(int(rid)), http.StatusMovedPermanently)\n\t\t\treturn\n\t\t}\n\n\t\thttp.Redirect(w, r, \"/submit\", http.StatusMovedPermanently)\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewInstances(platform platforms.Platform, kubeClient *kubernetes.Clientset, dockerComposePath string) Instances {\n\ti := instances{}\n\ti.platform = platform\n\ti.metadataClient = http.Client{}\n\ti.daprApiToken = os.Getenv(\"DAPR_API_TOKEN\")\n\n\tif i.platform == platforms.Kubernetes {\n\t\ti.getInstancesFn = i.getKubernetesInstances\n\t\ti.getScopesFn = i.getKubernetesScopes\n\t\ti.kubeClient = kubeClient\n\t} else if i.platform == platforms.Standalone {\n\t\ti.getInstancesFn = i.getStandaloneInstances\n\t\ti.getScopesFn = i.getStandaloneScopes\n\t} else if i.platform == platforms.DockerCompose {\n\t\ti.getInstancesFn = i.getDockerComposeInstances\n\t\ti.getScopesFn = i.getDockerComposeScopes\n\t\ti.dockerComposePath = dockerComposePath\n\t\ti.resolver = mdns.NewResolver(logger.NewLogger(\"mdns\"))\n\t}\n\treturn &i\n}", "is_vulnerable": 0}
{"code": "func init() {\n\thttpGetter := &HttpGetter{\n\t\tNetrc: true,\n\t}\n\n\t// The order of the Getters in the list may affect the result\n\t// depending if the Request.Src is detected as valid by multiple getters\n\tGetters = []Getter{\n\t\t&GitGetter{\n\t\t\tDetectors: []Detector{\n\t\t\t\tnew(GitHubDetector),\n\t\t\t\tnew(GitDetector),\n\t\t\t\tnew(BitBucketDetector),\n\t\t\t\tnew(GitLabDetector),\n\t\t\t},\n\t\t},\n\t\tnew(HgGetter),\n\t\tnew(SmbClientGetter),\n\t\tnew(SmbMountGetter),\n\t\thttpGetter,\n\t\tnew(FileGetter),\n\t}\n}", "is_vulnerable": 0}
{"code": "func ExtractJwtAud(jwt string) ([]string, bool) {\n\tjwtSplit := strings.Split(jwt, \".\")\n\tif len(jwtSplit) != 3 {\n\t\treturn nil, false\n\t}\n\tpayload := jwtSplit[1]\n\n\tpayloadBytes, err := base64.RawStdEncoding.DecodeString(payload)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\n\tstructuredPayload := jwtPayload{}\n\terr = json.Unmarshal(payloadBytes, &structuredPayload)\n\tif err != nil {\n\t\treturn nil, false\n\t}\n\n\treturn structuredPayload.Aud, true\n}", "is_vulnerable": 0}
{"code": "func Password(bits int) (password string, err error) {\n\tbytes := bits / 8\n\tif bits%8 != 0 {\n\t\tbytes++\n\t}\n\tvar pw = make([]byte, bytes)\n\tn, err := rand.Read(pw)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"password read failed\")\n\t}\n\tif n != bytes {\n\t\treturn \"\", errors.Errorf(\"password short read: %d\", n)\n\t}\n\tpassword = base64.RawURLEncoding.EncodeToString(pw)\n\treturn password, nil\n}", "is_vulnerable": 0}
{"code": "func (src *Sync) Encode(dst []byte) ([]byte, error) {\n\treturn append(dst, 'S', 0, 0, 0, 4), nil\n}", "is_vulnerable": 0}
{"code": "func TestStringAgainstIncompleteParentheses(t *testing.T) {\n\ttype AddressByZipCode struct {\n\t\tZipCode string `gorm:\"primary_key\"`\n\t\tAddress string\n\t}\n\n\tDB.AutoMigrate(&AddressByZipCode{})\n\tDB.Create(&AddressByZipCode{ZipCode: \"00502\", Address: \"Holtsville\"})\n\n\tvar address AddressByZipCode\n\tvar addresses []AddressByZipCode\n\t_ = DB.First(&address, \"address_by_zip_codes=00502)) UNION ALL SELECT NULL,version(),current_database(),NULL,NULL,NULL,NULL,NULL--\").Find(&addresses).GetErrors()\n\tif len(addresses) > 0 {\n\t\tt.Errorf(\"Fetch a record from with a string that has incomplete parentheses should be fail, zip code is %v\", address.ZipCode)\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func (a auth) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, authSecretAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "\t\t\tusers.GetByCurrentAuthUserFunc.SetDefaultHook(func(ctx context.Context) (*types.User, error) {\n\t\t\t\tswitch actor.FromContext(ctx).UID {\n\t\t\t\tcase user1.ID:\n\t\t\t\t\treturn user1, nil\n\t\t\t\tcase user2.ID:\n\t\t\t\t\treturn user2, nil\n\t\t\t\tcase admin.ID:\n\t\t\t\t\treturn admin, nil\n\t\t\t\tdefault:\n\t\t\t\t\tpanic(\"bad actor\")\n\t\t\t\t}\n\t\t\t})", "is_vulnerable": 0}
{"code": "func (f *Frontend) SendSync(msg *Sync) {\n\tif f.encodeError != nil {\n\t\treturn\n\t}\n\n\tprevLen := len(f.wbuf)\n\tnewBuf, err := msg.Encode(f.wbuf)\n\tif err != nil {\n\t\tf.encodeError = err\n\t\treturn\n\t}\n\tf.wbuf = newBuf\n\n\tif f.tracer != nil {\n\t\tf.tracer.traceSync('F', int32(len(f.wbuf)-prevLen), msg)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *client) refreshAuthToken(localCfg *localconfig.LocalConfig, ctxName, configPath string) error {\n\tif c.RefreshToken == \"\" {\n\t\t// If we have no refresh token, there's no point in doing anything\n\t\treturn nil\n\t}\n\tconfigCtx, err := localCfg.ResolveContext(ctxName)\n\tif err != nil {\n\t\treturn err\n\t}\n\tparser := &jwt.Parser{\n\t\tValidationHelper: jwt.NewValidationHelper(jwt.WithoutClaimsValidation()),\n\t}\n\tvar claims jwt.StandardClaims\n\t_, _, err = parser.ParseUnverified(configCtx.User.AuthToken, &claims)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif claims.Valid(jwt.DefaultValidationHelper) == nil {\n\t\t// token is still valid\n\t\treturn nil\n\t}\n\n\tlog.Debug(\"Auth token no longer valid. Refreshing\")\n\trawIDToken, refreshToken, err := c.redeemRefreshToken()\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.AuthToken = rawIDToken\n\tc.RefreshToken = refreshToken\n\tlocalCfg.UpsertUser(localconfig.User{\n\t\tName:         ctxName,\n\t\tAuthToken:    c.AuthToken,\n\t\tRefreshToken: c.RefreshToken,\n\t})\n\terr = localconfig.WriteLocalConfig(*localCfg, configPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (mr *MockStorageMockRecorder) SetClientAssertionJWT(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"SetClientAssertionJWT\", reflect.TypeOf((*MockStorage)(nil).SetClientAssertionJWT), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func (o *CopyOptions) copyFromPod(src, dest fileSpec) error {\n\tif len(src.File) == 0 || len(dest.File) == 0 {\n\t\treturn errFileCannotBeEmpty\n\t}\n\n\treader, outStream := io.Pipe()\n\toptions := &exec.ExecOptions{\n\t\tStreamOptions: exec.StreamOptions{\n\t\t\tIOStreams: genericclioptions.IOStreams{\n\t\t\t\tIn:     nil,\n\t\t\t\tOut:    outStream,\n\t\t\t\tErrOut: o.Out,\n\t\t\t},\n\n\t\t\tNamespace: src.PodNamespace,\n\t\t\tPodName:   src.PodName,\n\t\t},\n\n\t\t// TODO: Improve error messages by first testing if 'tar' is present in the container?\n\t\tCommand:  []string{\"tar\", \"cf\", \"-\", src.File},\n\t\tExecutor: &exec.DefaultRemoteExecutor{},\n\t}\n\n\tgo func() {\n\t\tdefer outStream.Close()\n\t\terr := o.execute(options)\n\t\tcmdutil.CheckErr(err)\n\t}()\n\tprefix := getPrefix(src.File)\n\tprefix = path.Clean(prefix)\n\t// remove extraneous path shortcuts - these could occur if a path contained extra \"../\"\n\t// and attempted to navigate beyond \"/\" in a remote filesystem\n\tprefix = stripPathShortcuts(prefix)\n\treturn o.untarAll(src, reader, dest.File, prefix)\n}", "is_vulnerable": 0}
{"code": "func (c *Config) ToTLSUtilConfig() *tlsutil.Config {\n\treturn &tlsutil.Config{\n\t\tVerifyIncoming:           c.VerifyIncoming,\n\t\tVerifyOutgoing:           c.VerifyOutgoing,\n\t\tCAFile:                   c.CAFile,\n\t\tCAPath:                   c.CAPath,\n\t\tCertFile:                 c.CertFile,\n\t\tKeyFile:                  c.KeyFile,\n\t\tNodeName:                 c.NodeName,\n\t\tServerName:               c.ServerName,\n\t\tTLSMinVersion:            c.TLSMinVersion,\n\t\tCipherSuites:             c.TLSCipherSuites,\n\t\tPreferServerCipherSuites: c.TLSPreferServerCipherSuites,\n\t}\n}", "is_vulnerable": 1}
{"code": "func testHttpServerWithXTerraformGetLoop(t *testing.T) net.Listener {\n\tt.Helper()\n\n\tln, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\theader := fmt.Sprintf(\"http://%v:%v\", ln.Addr().String(), \"/loop\")\n\n\tmux := http.NewServeMux()\n\tmux.HandleFunc(\"/loop\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"X-Terraform-Get\", header)\n\t\tt.Logf(\"serving loop\")\n\t})\n\n\tvar server http.Server\n\tserver.Handler = mux\n\tgo server.Serve(ln)\n\n\treturn ln\n}", "is_vulnerable": 0}
{"code": "func (i *instances) CheckPlatform() string {\n\treturn i.platform\n}", "is_vulnerable": 1}
{"code": "func evalSymlink(c Container, path string) (symlinkInfo, error) {\n\tvar naiveTarget string\n\n\tconst maxDepth = 10\n\tcurrentDepth := 0\n\tfor currentDepth < maxDepth {\n\t\tcurrentDepth++\n\t\ttarget, err := c.ReadLink(path)\n\t\tif err != nil {\n\t\t\treturn symlinkInfo{}, err\n\t\t}\n\t\t// record first symlink target\n\t\tif currentDepth == 1 {\n\t\t\tnaiveTarget = target\n\t\t}\n\n\t\ttarget = filepath.Clean(target)\n\t\t// don't follow absolute targets\n\t\tif filepath.IsAbs(target) {\n\t\t\treturn symlinkInfo{target, os.FileMode(0), naiveTarget, true}, nil\n\t\t}\n\n\t\t// evaluate target relative to symlink directory\n\t\ttarget = filepath.Join(filepath.Dir(path), target)\n\n\t\t// target escapes container, cannot evaluate further, let's return\n\t\tif strings.Split(target, string(os.PathSeparator))[0] == \"..\" {\n\t\t\treturn symlinkInfo{target, os.FileMode(0), naiveTarget, true}, nil\n\t\t}\n\n\t\tinfo, err := c.Lstat(target)\n\t\t// cannot follow bad targets\n\t\tif err != nil {\n\t\t\treturn symlinkInfo{}, err\n\t\t}\n\n\t\t// non-symlink, let's return\n\t\tif info.Mode().Type() != os.ModeSymlink {\n\t\t\treturn symlinkInfo{target, info.Mode(), naiveTarget, false}, nil\n\t\t}\n\n\t\t// we have another symlink\n\t\tpath = target\n\t}\n\n\treturn symlinkInfo{}, fmt.Errorf(\"too many levels of symbolic links\")\n}", "is_vulnerable": 0}
{"code": "func (c *infosController) WorkerInfos() []client.WorkerInfo {\n\treturn c.c.WorkerInfos()\n}", "is_vulnerable": 0}
{"code": "func ToNumberVersion(versionString string) int {\n\tversionString = strings.TrimPrefix(versionString, \"v\")\n\tv := strings.Replace(versionString, \".\", \"\", -1)\n\tif len(v) < 3 {\n\t\tv += \"0\"\n\t}\n\n\tversionId, err := strconv.Atoi(v)\n\tif err != nil {\n\t\tlogger.Fatal(err)\n\t}\n\n\treturn versionId\n}", "is_vulnerable": 0}
{"code": "func (m *NonByteCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NonByteCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NonByteCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field1 == nil {\n\t\t\t\tm.Field1 = &T{}\n\t\t\t}\n\t\t\tif err := m.Field1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (client TagsClient) CreateOrUpdate(ctx context.Context, tagName string) (result TagDetails, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/TagsClient.CreateOrUpdate\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\treq, err := client.CreateOrUpdatePreparer(ctx, tagName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.TagsClient\", \"CreateOrUpdate\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.CreateOrUpdateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.TagsClient\", \"CreateOrUpdate\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.CreateOrUpdateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.TagsClient\", \"CreateOrUpdate\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func GetSigningKey() string {\n\tcfg := Get()\n\tsignKey := cfg.LoginToken.SigningKey\n\n\tif len(signKey) == 0 || signKey == \"kiali\" {\n\t\t// \"kiali\" is a well-known signing key reported in a CVE. We ban it's usage.\n\t\t// An empty key is also just not allowed.\n\t\tpanic(\"signing key for login tokens is invalid\")\n\t}\n\n\tif cfg.Auth.Strategy == AuthStrategyLogin {\n\t\t// If we are using \"login\" strategy, let's combine the login passphrase\n\t\t// and the token signing key to form a new signing key. This way, if\n\t\t// either the login passphrase or the signing key is changed, active\n\t\t// sessions will be invalidated.\n\t\tsignKey = fmt.Sprintf(\"%s+%s\", signKey, cfg.Server.Credentials.Passphrase)\n\t}\n\n\treturn signKey\n}", "is_vulnerable": 0}
{"code": "\tgo func() {\n\t\ttime.Sleep(250 * time.Millisecond)\n\t\tctx.mutex.Lock()\n\t\tif ctx.recentBuild == recentBuild {\n\t\t\tctx.recentBuild = nil\n\t\t}\n\t\tctx.mutex.Unlock()\n\t}()", "is_vulnerable": 0}
{"code": "func RunTestConditionalDelete(ctx context.Context, t *testing.T, store storage.Interface) {\n\tkey, storedObj := testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"foo\", UID: \"A\"}})\n\n\ttests := []struct {\n\t\tname                string\n\t\tprecondition        *storage.Preconditions\n\t\texpectInvalidObjErr bool\n\t}{{\n\t\tname:                \"UID match\",\n\t\tprecondition:        storage.NewUIDPreconditions(\"A\"),\n\t\texpectInvalidObjErr: false,\n\t}, {\n\t\tname:                \"UID mismatch\",\n\t\tprecondition:        storage.NewUIDPreconditions(\"B\"),\n\t\texpectInvalidObjErr: true,\n\t}}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tout := &example.Pod{}\n\t\t\terr := store.Delete(ctx, key, out, tt.precondition, storage.ValidateAllObjectFunc, nil)\n\t\t\tif tt.expectInvalidObjErr {\n\t\t\t\tif err == nil || !storage.IsInvalidObj(err) {\n\t\t\t\t\tt.Errorf(\"expecting invalid UID error, but get: %s\", err)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Delete failed: %v\", err)\n\t\t\t}\n\t\t\t// We expect the resource version of the returned object to be\n\t\t\t// updated compared to the last existing object.\n\t\t\tif storedObj.ResourceVersion == out.ResourceVersion {\n\t\t\t\tt.Errorf(\"expecting resource version to be updated, but get: %s\", out.ResourceVersion)\n\t\t\t}\n\t\t\tout.ResourceVersion = storedObj.ResourceVersion\n\t\t\tExpectNoDiff(t, \"incorrect pod:\", storedObj, out)\n\t\t\tkey, storedObj = testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"foo\", UID: \"A\"}})\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tConvey(\"snapshot public mode or signed in\", func() {\n\t\t\tmiddlewareScenario(t, \"Snapshot public mode disabled and unauthenticated request should return 401\", func(sc *scenarioContext) {\n\t\t\t\tsc.m.Get(\"/api/snapshot\", SnapshotPublicModeOrSignedIn(), sc.defaultHandler)\n\t\t\t\tsc.fakeReq(\"GET\", \"/api/snapshot\").exec()\n\t\t\t\tSo(sc.resp.Code, ShouldEqual, 401)\n\t\t\t})\n\n\t\t\tmiddlewareScenario(t, \"Snapshot public mode enabled and unauthenticated request should return 200\", func(sc *scenarioContext) {\n\t\t\t\tsetting.SnapshotPublicMode = true\n\t\t\t\tsc.m.Get(\"/api/snapshot\", SnapshotPublicModeOrSignedIn(), sc.defaultHandler)\n\t\t\t\tsc.fakeReq(\"GET\", \"/api/snapshot\").exec()\n\t\t\t\tSo(sc.resp.Code, ShouldEqual, 200)\n\t\t\t})\n\t\t})", "is_vulnerable": 0}
{"code": "\tg.POST(\"/resource\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing user in session\")\n\t\t}\n\n\t\tif err := c.Request().ParseMultipartForm(maxFileSize); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Upload file overload max size\").SetInternal(err)\n\t\t}\n\n\t\tfile, err := c.FormFile(\"file\")\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to get uploading file\").SetInternal(err)\n\t\t}\n\t\tif file == nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Upload file not found\").SetInternal(err)\n\t\t}\n\n\t\tfilename := file.Filename\n\t\tfiletype := file.Header.Get(\"Content-Type\")\n\t\tsize := file.Size\n\t\tsrc, err := file.Open()\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to open file\").SetInternal(err)\n\t\t}\n\t\tdefer src.Close()\n\n\t\tfileBytes, err := io.ReadAll(src)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to read file\").SetInternal(err)\n\t\t}\n\n\t\tresourceCreate := &api.ResourceCreate{\n\t\t\tFilename:  filename,\n\t\t\tType:      filetype,\n\t\t\tSize:      size,\n\t\t\tBlob:      fileBytes,\n\t\t\tCreatorID: userID,\n\t\t}\n\n\t\tresource, err := s.Store.CreateResource(ctx, resourceCreate)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to create resource\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"resource created\",\n\t\t})\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(resource)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode resource response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "func setInstance(r *http.Request, verifier authz.InstanceVerifier, headerName string) (_ context.Context, err error) {\n\tctx := r.Context()\n\tauthCtx, span := tracing.NewServerInterceptorSpan(ctx)\n\tdefer func() { span.EndWithError(err) }()\n\n\thost, err := HostFromRequest(r, headerName)\n\n\tif err != nil {\n\t\treturn nil, zerrors.ThrowNotFound(err, \"INST-zWq7X\", \"Errors.IAM.NotFound\")\n\t}\n\n\tinstance, err := verifier.InstanceByHost(authCtx, host)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tspan.End()\n\treturn authz.WithInstance(ctx, instance), nil\n}", "is_vulnerable": 0}
{"code": "func (e errorTranslateQuerier) Close() error {\n\treturn TranslateToPromqlAPIError(e.q.Close())\n}", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateContainerSymlinksMetaBadTargetMode(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\ts.bootstrapEmptyContainer(c)\n\tc.Assert(os.MkdirAll(filepath.Join(s.snapDirPath, \"meta\"), 0755), IsNil)\n\texternalSymlink := filepath.Join(s.snapDirPath, \"meta\", \"symlink\")\n\t// target is has bad mode\n\tconst mode = os.FileMode(0711)\n\tc.Assert(os.WriteFile(filepath.Join(s.snapDirPath, \"target\"), nil, mode), IsNil)\n\tc.Assert(os.Symlink(\"../target\", externalSymlink), IsNil)\n\n\tcontainer := s.container()\n\n\tsymlinkInfo, err := snap.EvalAndValidateSymlink(container, \"meta/symlink\")\n\tc.Check(err, IsNil)\n\tc.Check(symlinkInfo.Mode(), Equals, mode)\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(container, info, discard)\n\tc.Check(err, ErrorMatches, \"snap is unusable due to bad permissions\")\n}", "is_vulnerable": 0}
{"code": "func (c *Client) blobAndFileSASURI(options SASOptions, uri, permissions, canonicalizedResource, signedResource string, headers OverrideHeaders) (string, error) {\n\tstart := \"\"\n\tif options.Start != (time.Time{}) {\n\t\tstart = options.Start.UTC().Format(time.RFC3339)\n\t}\n\n\texpiry := options.Expiry.UTC().Format(time.RFC3339)\n\n\t// We need to replace + with %2b first to avoid being treated as a space (which is correct for query strings, but not the path component).\n\tcanonicalizedResource = strings.Replace(canonicalizedResource, \"+\", \"%2b\", -1)\n\tcanonicalizedResource, err := url.QueryUnescape(canonicalizedResource)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tprotocols := \"\"\n\tif options.UseHTTPS {\n\t\tprotocols = \"https\"\n\t}\n\tstringToSign, err := blobSASStringToSign(permissions, start, expiry, canonicalizedResource, options.Identifier, options.IP, protocols, c.apiVersion, signedResource, \"\", headers)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tsig := c.computeHmac256(stringToSign)\n\tsasParams := url.Values{\n\t\t\"sv\":  {c.apiVersion},\n\t\t\"se\":  {expiry},\n\t\t\"sr\":  {signedResource},\n\t\t\"sp\":  {permissions},\n\t\t\"sig\": {sig},\n\t}\n\n\tif start != \"\" {\n\t\tsasParams.Add(\"st\", start)\n\t}\n\n\tif c.apiVersion >= \"2015-04-05\" {\n\t\tif protocols != \"\" {\n\t\t\tsasParams.Add(\"spr\", protocols)\n\t\t}\n\t\tif options.IP != \"\" {\n\t\t\tsasParams.Add(\"sip\", options.IP)\n\t\t}\n\t}\n\n\t// Add override response hedaers\n\taddQueryParameter(sasParams, \"rscc\", headers.CacheControl)\n\taddQueryParameter(sasParams, \"rscd\", headers.ContentDisposition)\n\taddQueryParameter(sasParams, \"rsce\", headers.ContentEncoding)\n\taddQueryParameter(sasParams, \"rscl\", headers.ContentLanguage)\n\taddQueryParameter(sasParams, \"rsct\", headers.ContentType)\n\n\tsasURL, err := url.Parse(uri)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tsasURL.RawQuery = sasParams.Encode()\n\treturn sasURL.String(), nil\n}", "is_vulnerable": 0}
{"code": "func (v V002Entry) CreateFromArtifactProperties(_ context.Context, props types.ArtifactProperties) (models.ProposedEntry, error) {\n\treturnVal := models.Intoto{}\n\tre := V002Entry{\n\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{},\n\t\t\t},\n\t\t}}\n\tvar err error\n\tartifactBytes := props.ArtifactBytes\n\tif artifactBytes == nil {\n\t\tif props.ArtifactPath == nil {\n\t\t\treturn nil, errors.New(\"path to artifact file must be specified\")\n\t\t}\n\t\tif props.ArtifactPath.IsAbs() {\n\t\t\treturn nil, errors.New(\"intoto envelopes cannot be fetched over HTTP(S)\")\n\t\t}\n\t\tartifactBytes, err = os.ReadFile(filepath.Clean(props.ArtifactPath.Path))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tenv := dsse.Envelope{}\n\tif err := json.Unmarshal(artifactBytes, &env); err != nil {\n\t\treturn nil, fmt.Errorf(\"payload must be a valid dsse envelope: %w\", err)\n\t}\n\n\tallPubKeyBytes := make([][]byte, 0)\n\tif len(props.PublicKeyBytes) > 0 {\n\t\tallPubKeyBytes = append(allPubKeyBytes, props.PublicKeyBytes...)\n\t}\n\n\tif len(props.PublicKeyPaths) > 0 {\n\t\tfor _, path := range props.PublicKeyPaths {\n\t\t\tif path.IsAbs() {\n\t\t\t\treturn nil, errors.New(\"dsse public keys cannot be fetched over HTTP(S)\")\n\t\t\t}\n\n\t\t\tpublicKeyBytes, err := os.ReadFile(filepath.Clean(path.Path))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error reading public key file: %w\", err)\n\t\t\t}\n\n\t\t\tallPubKeyBytes = append(allPubKeyBytes, publicKeyBytes)\n\t\t}\n\t}\n\n\tkeysBySig, err := verifyEnvelope(allPubKeyBytes, &env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb64 := strfmt.Base64([]byte(env.Payload))\n\tre.IntotoObj.Content.Envelope.Payload = b64\n\tre.IntotoObj.Content.Envelope.PayloadType = &env.PayloadType\n\n\tfor _, sig := range env.Signatures {\n\t\tkey, ok := keysBySig[sig.Sig]\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"all signatures must have a key that verifies it\")\n\t\t}\n\n\t\tcanonKey, err := key.CanonicalValue()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not canonicize key: %w\", err)\n\t\t}\n\n\t\tkeyBytes := strfmt.Base64(canonKey)\n\t\tsigBytes := strfmt.Base64([]byte(sig.Sig))\n\t\tre.IntotoObj.Content.Envelope.Signatures = append(re.IntotoObj.Content.Envelope.Signatures, &models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\tKeyid:     sig.KeyID,\n\t\t\tSig:       &sigBytes,\n\t\t\tPublicKey: &keyBytes,\n\t\t})\n\t}\n\n\th := sha256.Sum256([]byte(artifactBytes))\n\tre.IntotoObj.Content.Hash = &models.IntotoV002SchemaContentHash{\n\t\tAlgorithm: swag.String(models.IntotoV001SchemaContentHashAlgorithmSha256),\n\t\tValue:     swag.String(hex.EncodeToString(h[:])),\n\t}\n\n\treturnVal.Spec = re.IntotoObj\n\treturnVal.APIVersion = swag.String(re.APIVersion())\n\n\treturn &returnVal, nil\n}", "is_vulnerable": 0}
{"code": "func (*apiHandler) stop() {\n}", "is_vulnerable": 0}
{"code": "func TestClientLoginCert(t *testing.T) {\n\tcert := &Certificate{\n\t\tKey:         testPublicKeys[\"rsa\"],\n\t\tValidBefore: CertTimeInfinity,\n\t\tCertType:    UserCert,\n\t}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tcertSigner, err := NewCertSigner(cert, testSigners[\"rsa\"])\n\tif err != nil {\n\t\tt.Fatalf(\"NewCertSigner: %v\", err)\n\t}\n\n\tclientConfig := &ClientConfig{\n\t\tUser: \"user\",\n\t}\n\tclientConfig.Auth = append(clientConfig.Auth, PublicKeys(certSigner))\n\n\t// should succeed\n\tif err := tryAuth(t, clientConfig); err != nil {\n\t\tt.Errorf(\"cert login failed: %v\", err)\n\t}\n\n\t// corrupted signature\n\tcert.Signature.Blob[0]++\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login passed with corrupted sig\")\n\t}\n\n\t// revoked\n\tcert.Serial = 666\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"revoked cert login succeeded\")\n\t}\n\tcert.Serial = 1\n\n\t// sign with wrong key\n\tcert.SignCert(rand.Reader, testSigners[\"dsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login passed with non-authoritative key\")\n\t}\n\n\t// host cert\n\tcert.CertType = HostCert\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login passed with wrong type\")\n\t}\n\tcert.CertType = UserCert\n\n\t// principal specified\n\tcert.ValidPrincipals = []string{\"user\"}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err != nil {\n\t\tt.Errorf(\"cert login failed: %v\", err)\n\t}\n\n\t// wrong principal specified\n\tcert.ValidPrincipals = []string{\"fred\"}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login passed with wrong principal\")\n\t}\n\tcert.ValidPrincipals = nil\n\n\t// added critical option\n\tcert.CriticalOptions = map[string]string{\"root-access\": \"yes\"}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login passed with unrecognized critical option\")\n\t}\n\n\t// allowed source address\n\tcert.CriticalOptions = map[string]string{\"source-address\": \"127.0.0.42/24,::42/120\"}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err != nil {\n\t\tt.Errorf(\"cert login with source-address failed: %v\", err)\n\t}\n\n\t// disallowed source address\n\tcert.CriticalOptions = map[string]string{\"source-address\": \"127.0.0.42,::42\"}\n\tcert.SignCert(rand.Reader, testSigners[\"ecdsa\"])\n\tif err := tryAuth(t, clientConfig); err == nil {\n\t\tt.Errorf(\"cert login with source-address succeeded\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func loginHandler(w http.ResponseWriter, request *http.Request) {\n\tuser := request.FormValue(\"user\")\n\tpass := request.FormValue(\"password\")\n\tif user != \"\" && pass != \"\" {\n\t\tsetCredentials(user, pass, w)\n\t}\n\thttp.Redirect(w, request, \"/\", 302)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CredsAdd(ctx context.Context, in *clientpb.Credentials, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CredsAdd_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestOperatorSystemAccount(t *testing.T) {\n\ts, _ := runOperatorServer(t)\n\tdefer s.Shutdown()\n\n\t// Create an account from another operator, this should fail if used as a system account.\n\tokp, _ := nkeys.CreateOperator()\n\tseed, _ := okp.Seed()\n\takp := createAccountForOperatorKey(t, s, seed)\n\tif err := s.SetSystemAccount(publicKeyFromKeyPair(t, akp)); err == nil {\n\t\tt.Fatalf(\"Expected this to fail\")\n\t}\n\tif acc := s.SystemAccount(); acc != nil {\n\t\tt.Fatalf(\"Expected no account to be set for system account\")\n\t}\n\n\tacc, _ := createAccount(t, s)\n\tif err := s.SetSystemAccount(acc.Name); err != nil {\n\t\tt.Fatalf(\"Expected this succeed, got %v\", err)\n\t}\n\tif sysAcc := s.SystemAccount(); sysAcc != acc {\n\t\tt.Fatalf(\"Did not get matching account for system account\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func LogHandler(logService *service.LogService) gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tzap.L().Info(\"Access Log start\")\n\t\tstartTime := time.Now()\n\t\tvar body interface{}\n\t\tvar query = c.Request.URL.Query()\n\t\t_ = c.ShouldBindBodyWith(&body, binding.JSON)\n\n\t\tblw := &response.BufferedResponseWriter{\n\t\t\tResponseWriter: c.Writer,\n\t\t\tBody:           bytes.NewBufferString(\"\"),\n\t\t}\n\t\tc.Writer = blw\n\n\t\tc.Next()\n\t\tduration := time.Since(startTime)\n\t\tresponseBody := blw.Body.String()\n\n\t\tqueryStr, _ := json.Marshal(query)\n\t\tbodyStr, _ := json.Marshal(body)\n\n\t\t//responseStatus := blw.Status()\n\t\tvar accessLog = model.AccessLog{\n\t\t\tBasic:    model.Basic{},\n\t\t\tMethod:   c.Request.Method,\n\t\t\tIp:       c.ClientIP(),\n\t\t\tLocality: \"\",\n\t\t\tUrl:      c.Request.URL.Path,\n\t\t\tBody:     utils.SanitizeInput(string(bodyStr)),\n\t\t\tQuery:    utils.SanitizeInput(string(queryStr)),\n\t\t\tResponse: utils.SanitizeInput(responseBody),\n\t\t}\n\t\terr := logService.CreateAccessLog(c, accessLog)\n\t\tif err != nil {\n\t\t\tzap.L().Error(\"\u65e5\u5fd7\u5b58\u50a8\u5f02\u5e38\u3002\u3002\u3002\u3002\", zap.Error(err))\n\t\t}\n\t\tzap.L().Info(\"\u7528\u6237\u8bbf\u95ee\u65e5\u5fd7:\",\n\t\t\tzap.String(\"uri\", c.Request.URL.Path),\n\t\t\tzap.String(\"method\", c.Request.Method),\n\t\t\tzap.Any(\"query\", accessLog.Query),\n\t\t\tzap.Any(\"body\", accessLog.Body),\n\t\t\tzap.String(\"response\", accessLog.Response),\n\t\t\tzap.String(\"ip\", c.ClientIP()),\n\t\t\tzap.String(\"duration\", fmt.Sprintf(\"%.4f seconds\", duration.Seconds())))\n\t\tzap.L().Info(\"Access Log end\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func NoErrorf(t TestingT, err error, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NoErrorf(t, err, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (vfs *VirtualFilesystem) BindAt(ctx context.Context, creds *auth.Credentials, source, target *PathOperation, recursive bool) error {\n\tsourceVd, err := vfs.GetDentryAt(ctx, creds, source, &GetDentryOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer sourceVd.DecRef(ctx)\n\ttargetVd, err := vfs.GetDentryAt(ctx, creds, target, &GetDentryOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvfs.lockMounts()\n\tdefer vfs.unlockMounts(ctx)\n\tvar clone *Mount\n\tif recursive {\n\t\tclone, err = vfs.cloneMountTree(ctx, sourceVd.mount, sourceVd.dentry, 0, nil)\n\t} else {\n\t\tclone, err = vfs.cloneMount(sourceVd.mount, sourceVd.dentry, nil, 0)\n\t}\n\tif err != nil {\n\t\tvfs.delayDecRef(targetVd)\n\t\treturn err\n\t}\n\tvfs.delayDecRef(clone)\n\tif err := vfs.attachTreeLocked(ctx, clone, targetVd); err != nil {\n\t\tvfs.abortUncomittedChildren(ctx, clone)\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (z *Zip) extractNext(to string) error {\n\tf, err := z.Read()\n\tif err != nil {\n\t\treturn err // don't wrap error; calling loop must break on io.EOF\n\t}\n\tdefer f.Close()\n\n\terrPath := z.CheckPath(to, f.Header.(zip.FileHeader).Name)\n\tif errPath != nil {\n\t\treturn fmt.Errorf(\"checking path traversal attempt: %v\", errPath)\n\t}\n\treturn z.extractFile(f, to)\n}", "is_vulnerable": 0}
{"code": "func (az *Cloud) createVhdBlob(accountName, accountKey, name string, sizeGB int64, tags map[string]string) (string, string, error) {\n\tblobClient, err := az.getBlobClient(accountName, accountKey)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\tsize := 1024 * 1024 * 1024 * sizeGB\n\tvhdSize := size + vhdHeaderSize /* header size */\n\t// Blob name in URL must end with '.vhd' extension.\n\tname = name + \".vhd\"\n\terr = blobClient.PutPageBlob(vhdContainerName, name, vhdSize, tags)\n\tif err != nil {\n\t\t// if container doesn't exist, create one and retry PutPageBlob\n\t\tdetail := err.Error()\n\t\tif strings.Contains(detail, errContainerNotFound) {\n\t\t\terr = blobClient.CreateContainer(vhdContainerName, azs.ContainerAccessTypeContainer)\n\t\t\tif err == nil {\n\t\t\t\terr = blobClient.PutPageBlob(vhdContainerName, name, vhdSize, tags)\n\t\t\t}\n\t\t}\n\t}\n\tif err != nil {\n\t\treturn \"\", \"\", fmt.Errorf(\"failed to put page blob: %v\", err)\n\t}\n\n\t// add VHD signature to the blob\n\th, err := createVHDHeader(uint64(size))\n\tif err != nil {\n\t\taz.deleteVhdBlob(accountName, accountKey, name)\n\t\treturn \"\", \"\", fmt.Errorf(\"failed to create vhd header, err: %v\", err)\n\t}\n\tif err = blobClient.PutPage(vhdContainerName, name, size, vhdSize-1, azs.PageWriteTypeUpdate, h[:vhdHeaderSize], nil); err != nil {\n\t\taz.deleteVhdBlob(accountName, accountKey, name)\n\t\treturn \"\", \"\", fmt.Errorf(\"failed to update vhd header, err: %v\", err)\n\t}\n\n\tscheme := \"http\"\n\tif useHTTPS {\n\t\tscheme = \"https\"\n\t}\n\thost := fmt.Sprintf(\"%s://%s.%s.%s\", scheme, accountName, blobServiceName, az.Environment.StorageEndpointSuffix)\n\turi := fmt.Sprintf(\"%s/%s/%s\", host, vhdContainerName, name)\n\treturn name, uri, nil\n\n}", "is_vulnerable": 1}
{"code": "func BuildBootstrapCommand() command.Command {\n\tconf := GeneratorsConfig{}\n\tflags, err := types.NewGinkgoFlagSet(\n\t\ttypes.GinkgoFlags{\n\t\t\t{Name: \"agouti\", KeyPath: \"Agouti\",\n\t\t\t\tUsage: \"If set, bootstrap will generate a bootstrap file for writing Agouti tests\"},\n\t\t\t{Name: \"nodot\", KeyPath: \"NoDot\",\n\t\t\t\tUsage: \"If set, bootstrap will generate a bootstrap test file that does not dot-import ginkgo and gomega\"},\n\t\t\t{Name: \"internal\", KeyPath: \"Internal\",\n\t\t\t\tUsage: \"If set, bootstrap will generate a bootstrap test file that uses the regular package name (i.e. `package X`, not `package X_test`)\"},\n\t\t\t{Name: \"template\", KeyPath: \"CustomTemplate\",\n\t\t\t\tUsageArgument: \"template-file\",\n\t\t\t\tUsage:         \"If specified, generate will use the contents of the file passed as the bootstrap template\"},\n\t\t\t{Name: \"template-data\", KeyPath: \"CustomTemplateData\",\n\t\t\t\tUsageArgument: \"template-data-file\",\n\t\t\t\tUsage:         \"If specified, generate will use the contents of the file passed as data to be rendered in the bootstrap template\"},\n\t\t},\n\t\t&conf,\n\t\ttypes.GinkgoFlagSections{},\n\t)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\treturn command.Command{\n\t\tName:     \"bootstrap\",\n\t\tUsage:    \"ginkgo bootstrap\",\n\t\tShortDoc: \"Bootstrap a test suite for the current package\",\n\t\tDocumentation: `Tests written in Ginkgo and Gomega require a small amount of boilerplate to hook into Go's testing infrastructure.\n\n{{bold}}ginkgo bootstrap{{/}} generates this boilerplate for you in a file named X_suite_test.go where X is the name of the package under test.`,\n\t\tDocLink: \"generators\",\n\t\tFlags:   flags,\n\t\tCommand: func(_ []string, _ []string) {\n\t\t\tgenerateBootstrap(conf)\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c opentelemetry) GetDocumentation() parser.AnnotationFields {\n\treturn c.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func TestConnectWithRedirects(t *testing.T) {\n\ttests := []struct {\n\t\tdesc              string\n\t\tredirects         []string\n\t\tmethod            string // initial request method, empty == GET\n\t\texpectError       bool\n\t\texpectedRedirects int\n\t\tnewPort           bool // special case different port test\n\t}{{\n\t\tdesc:              \"relative redirects allowed\",\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"redirects to the same host are allowed\",\n\t\tredirects:         []string{\"http://HOST/ok\"}, // HOST replaced with server address in test\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"POST redirects to GET\",\n\t\tmethod:            http.MethodPost,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"PUT redirects to GET\",\n\t\tmethod:            http.MethodPut,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"DELETE redirects to GET\",\n\t\tmethod:            http.MethodDelete,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"9 redirects are allowed\",\n\t\tredirects:         []string{\"/1\", \"/2\", \"/3\", \"/4\", \"/5\", \"/6\", \"/7\", \"/8\", \"/9\"},\n\t\texpectedRedirects: 9,\n\t}, {\n\t\tdesc:        \"10 redirects are forbidden\",\n\t\tredirects:   []string{\"/1\", \"/2\", \"/3\", \"/4\", \"/5\", \"/6\", \"/7\", \"/8\", \"/9\", \"/10\"},\n\t\texpectError: true,\n\t}, {\n\t\tdesc:        \"redirect to different host are prevented\",\n\t\tredirects:   []string{\"http://example.com/foo\"},\n\t\texpectError: true,\n\t}, {\n\t\tdesc:        \"multiple redirect to different host forbidden\",\n\t\tredirects:   []string{\"/1\", \"/2\", \"/3\", \"http://example.com/foo\"},\n\t\texpectError: true,\n\t}, {\n\t\tdesc:              \"redirect to different port is allowed\",\n\t\tredirects:         []string{\"http://HOST/foo\"},\n\t\texpectedRedirects: 1,\n\t\tnewPort:           true,\n\t}}\n\n\tconst resultString = \"Test output\"\n\tfor _, test := range tests {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tredirectCount := 0\n\t\t\ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\t\t\t// Verify redirect request.\n\t\t\t\tif redirectCount > 0 {\n\t\t\t\t\texpectedURL, err := url.Parse(test.redirects[redirectCount-1])\n\t\t\t\t\trequire.NoError(t, err, \"test URL error\")\n\t\t\t\t\tassert.Equal(t, req.URL.Path, expectedURL.Path, \"unknown redirect path\")\n\t\t\t\t\tassert.Equal(t, http.MethodGet, req.Method, \"redirects must always be GET\")\n\t\t\t\t}\n\t\t\t\tif redirectCount < len(test.redirects) {\n\t\t\t\t\thttp.Redirect(w, req, test.redirects[redirectCount], http.StatusFound)\n\t\t\t\t\tredirectCount++\n\t\t\t\t} else if redirectCount == len(test.redirects) {\n\t\t\t\t\tw.Write([]byte(resultString))\n\t\t\t\t} else {\n\t\t\t\t\tt.Errorf(\"unexpected number of redirects %d to %s\", redirectCount, req.URL.String())\n\t\t\t\t}\n\t\t\t}))\n\t\t\tdefer s.Close()\n\n\t\t\tu, err := url.Parse(s.URL)\n\t\t\trequire.NoError(t, err, \"Error parsing server URL\")\n\t\t\thost := u.Host\n\n\t\t\t// Special case new-port test with a secondary server.\n\t\t\tif test.newPort {\n\t\t\t\ts2 := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\t\t\t\tw.Write([]byte(resultString))\n\t\t\t\t}))\n\t\t\t\tdefer s2.Close()\n\t\t\t\tu2, err := url.Parse(s2.URL)\n\t\t\t\trequire.NoError(t, err, \"Error parsing secondary server URL\")\n\n\t\t\t\t// Sanity check: secondary server uses same hostname, different port.\n\t\t\t\trequire.Equal(t, u.Hostname(), u2.Hostname(), \"sanity check: same hostname\")\n\t\t\t\trequire.NotEqual(t, u.Port(), u2.Port(), \"sanity check: different port\")\n\n\t\t\t\t// Redirect to the secondary server.\n\t\t\t\thost = u2.Host\n\n\t\t\t}\n\n\t\t\t// Update redirect URLs with actual host.\n\t\t\tfor i := range test.redirects {\n\t\t\t\ttest.redirects[i] = strings.Replace(test.redirects[i], \"HOST\", host, 1)\n\t\t\t}\n\n\t\t\tmethod := test.method\n\t\t\tif method == \"\" {\n\t\t\t\tmethod = http.MethodGet\n\t\t\t}\n\n\t\t\tnetdialer := &net.Dialer{\n\t\t\t\tTimeout:   wait.ForeverTestTimeout,\n\t\t\t\tKeepAlive: wait.ForeverTestTimeout,\n\t\t\t}\n\t\t\tdialer := DialerFunc(func(req *http.Request) (net.Conn, error) {\n\t\t\t\tconn, err := netdialer.Dial(\"tcp\", req.URL.Host)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn conn, err\n\t\t\t\t}\n\t\t\t\tif err = req.Write(conn); err != nil {\n\t\t\t\t\trequire.NoError(t, conn.Close())\n\t\t\t\t\treturn nil, fmt.Errorf(\"error sending request: %v\", err)\n\t\t\t\t}\n\t\t\t\treturn conn, err\n\t\t\t})\n\t\t\tconn, rawResponse, err := ConnectWithRedirects(method, u, http.Header{} /*body*/, nil, dialer, true)\n\t\t\tif test.expectError {\n\t\t\t\trequire.Error(t, err, \"expected request error\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.NoError(t, err, \"unexpected request error\")\n\t\t\tassert.NoError(t, conn.Close(), \"error closing connection\")\n\n\t\t\tresp, err := http.ReadResponse(bufio.NewReader(bytes.NewReader(rawResponse)), nil)\n\t\t\trequire.NoError(t, err, \"unexpected request error\")\n\n\t\t\tresult, err := ioutil.ReadAll(resp.Body)\n\t\t\tassert.Nil(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\tif test.expectedRedirects < len(test.redirects) {\n\t\t\t\t// Expect the last redirect to be returned.\n\t\t\t\tassert.Equal(t, http.StatusFound, resp.StatusCode, \"Final response is not a redirect\")\n\t\t\t\tassert.Equal(t, test.redirects[len(test.redirects)-1], resp.Header.Get(\"Location\"))\n\t\t\t\tassert.NotEqual(t, resultString, string(result), \"wrong content\")\n\t\t\t} else {\n\t\t\t\tassert.Equal(t, resultString, string(result), \"stream content does not match\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewStore(maxAgeSeconds int, secrets ...string) Store {\n\tvalues := [][]byte{}\n\tfor _, secret := range secrets {\n\t\tvalues = append(values, []byte(secret))\n\t}\n\tcookie := sessions.NewCookieStore(values...)\n\tcookie.Options.MaxAge = maxAgeSeconds\n\tcookie.Options.HttpOnly = true\n\treturn store{cookie}\n}", "is_vulnerable": 1}
{"code": "func (r *CountedReader) Error() error {\n\tif errors.Is(r.err, io.EOF) {\n\t\treturn nil\n\t}\n\treturn r.err\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) Merge(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Merge\", reflect.TypeOf((*MockAuthorizeRequester)(nil).Merge), arg0)\n}", "is_vulnerable": 0}
{"code": "func (s *GetSecurityGroupsForVpcInput) Validate() error {\n\tinvalidParams := request.ErrInvalidParams{Context: \"GetSecurityGroupsForVpcInput\"}\n\tif s.MaxResults != nil && *s.MaxResults < 5 {\n\t\tinvalidParams.Add(request.NewErrParamMinValue(\"MaxResults\", 5))\n\t}\n\tif s.VpcId == nil {\n\t\tinvalidParams.Add(request.NewErrParamRequired(\"VpcId\"))\n\t}\n\n\tif invalidParams.Len() > 0 {\n\t\treturn invalidParams\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func gitCheckout(p *config.Pipeline, dir string, mutations map[string]string) error {\n\trepoValue := p.With[\"repository\"]\n\tif repoValue == \"\" {\n\t\treturn fmt.Errorf(\"no repository to checkout\")\n\t}\n\n\ttagValue := p.With[\"tag\"]\n\tif tagValue == \"\" {\n\t\treturn fmt.Errorf(\"no tag to checkout\")\n\t}\n\n\t// evaluate var substitutions\n\tevaluatedTag, err := util.MutateStringFromMap(mutations, tagValue)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tgitAuth, err := wgit.GetGitAuth(repoValue)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get git auth: %w\", err)\n\t}\n\n\tcloneOpts := &git.CloneOptions{\n\t\tURL:               repoValue,\n\t\tReferenceName:     plumbing.ReferenceName(fmt.Sprintf(\"refs/tags/%s\", evaluatedTag)),\n\t\tProgress:          os.Stdout,\n\t\tRecurseSubmodules: git.NoRecurseSubmodules,\n\t\tDepth:             1,\n\t\tAuth:              gitAuth,\n\t}\n\n\tlog.Printf(\"cloning sources from %s tag %s into a temporary directory '%s', this may take a while\", repoValue, dir, evaluatedTag)\n\n\tmaxRetries := 3\n\tr := &git.Repository{}\n\tfor attempt := 0; attempt < maxRetries; attempt++ {\n\t\tr, err = git.PlainClone(dir, false, cloneOpts)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\t\tlog.Printf(\"Attempt %d failed to clone %s ref %s with error: %v\", attempt+1, repoValue, evaluatedTag, err)\n\t\tif attempt < maxRetries-1 {\n\t\t\tlog.Println(\"Retrying...\")\n\t\t\ttime.Sleep(time.Second * 2)\n\t\t\t// delete the temporary directory\n\t\t\terr = os.RemoveAll(dir)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to remove temporary directory %s: %w\", dir, err)\n\t\t\t}\n\t\t\t// recreate the directory\n\t\t\terr = os.MkdirAll(dir, 0o755)\n\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to remove temporary directory %s: %w\", dir, err)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"failed to remove temporary directory %s: %w\", dir, err)\n\t\t\t}\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"failed to clone %s ref %s after %d attempts\", repoValue, evaluatedTag, maxRetries)\n\t\t}\n\t}\n\n\tif r == nil {\n\t\treturn fmt.Errorf(\"clone is empty %s ref %s\", repoValue, evaluatedTag)\n\t}\n\tlog.Println(\"git-checkout was successful\")\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (dl *Download) Execute() error {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Hour*12)\n\tdl.cancelFunc = &cancel\n\tdefer dl.Cancel()\n\n\t// Always ensure that we're checking the destination for the download to avoid a malicious\n\t// user from accessing internal network resources.\n\tif err := dl.isExternalNetwork(ctx); err != nil {\n\t\treturn err\n\t}\n\n\t// At this point we have verified the destination is not within the local network, so we can\n\t// now make a request to that URL and pull down the file, saving it to the server's data\n\t// directory.\n\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, dl.req.URL.String(), nil)\n\tif err != nil {\n\t\treturn errors.WrapIf(err, \"downloader: failed to create request\")\n\t}\n\n\treq.Header.Set(\"User-Agent\", \"Pterodactyl Panel (https://pterodactyl.io)\")\n\tres, err := client.Do(req)\n\tif err != nil {\n\t\treturn ErrDownloadFailed\n\t}\n\tdefer res.Body.Close()\n\tif res.StatusCode != http.StatusOK {\n\t\treturn errors.New(\"downloader: got bad response status from endpoint: \" + res.Status)\n\t}\n\n\t// If there is a Content-Length header on this request go ahead and check that we can\n\t// even write the whole file before beginning this process. If there is no header present\n\t// we'll just have to give it a spin and see how it goes.\n\tif res.ContentLength > 0 {\n\t\tif err := dl.server.Filesystem().HasSpaceFor(res.ContentLength); err != nil {\n\t\t\treturn errors.WrapIf(err, \"downloader: failed to write file: not enough space\")\n\t\t}\n\t}\n\n\tif dl.req.UseHeader {\n\t\tif contentDisposition := res.Header.Get(\"Content-Disposition\"); contentDisposition != \"\" {\n\t\t\t_, params, err := mime.ParseMediaType(contentDisposition)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.WrapIf(err, \"downloader: invalid \\\"Content-Disposition\\\" header\")\n\t\t\t}\n\n\t\t\tif v, ok := params[\"filename\"]; ok {\n\t\t\t\tdl.path = v\n\t\t\t}\n\t\t}\n\t}\n\tif dl.path == \"\" {\n\t\tif dl.req.FileName != \"\" {\n\t\t\tdl.path = dl.req.FileName\n\t\t} else {\n\t\t\tparts := strings.Split(dl.req.URL.Path, \"/\")\n\t\t\tdl.path = parts[len(parts)-1]\n\t\t}\n\t}\n\n\tp := dl.Path()\n\tdl.server.Log().WithField(\"path\", p).Debug(\"writing remote file to disk\")\n\n\tr := io.TeeReader(res.Body, dl.counter(res.ContentLength))\n\tif err := dl.server.Filesystem().Writefile(p, r); err != nil {\n\t\treturn errors.WrapIf(err, \"downloader: failed to write file to server directory\")\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (r *ResolveCheckResponse) GetCycleDetected() bool {\n\tif r != nil {\n\t\treturn r.GetResolutionMetadata().CycleDetected\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func Test_GetPluginAssets(t *testing.T) {\n\tpluginID := \"test-plugin\"\n\tpluginDir := \".\"\n\ttmpFile, err := ioutil.TempFile(pluginDir, \"\")\n\trequire.NoError(t, err)\n\ttmpFileInParentDir, err := ioutil.TempFile(\"..\", \"\")\n\trequire.NoError(t, err)\n\tt.Cleanup(func() {\n\t\terr := os.RemoveAll(tmpFile.Name())\n\t\tassert.NoError(t, err)\n\t\terr = os.RemoveAll(tmpFileInParentDir.Name())\n\t\tassert.NoError(t, err)\n\t})\n\texpectedBody := \"Plugin test\"\n\t_, err = tmpFile.WriteString(expectedBody)\n\tassert.NoError(t, err)\n\n\trequestedFile := filepath.Clean(tmpFile.Name())\n\n\tt.Run(\"Given a request for an existing plugin file that is listed as a signature covered file\", func(t *testing.T) {\n\t\tp := plugins.PluginDTO{\n\t\t\tJSONData: plugins.JSONData{\n\t\t\t\tID: pluginID,\n\t\t\t},\n\t\t\tPluginDir: pluginDir,\n\t\t\tSignedFiles: map[string]struct{}{\n\t\t\t\trequestedFile: {},\n\t\t\t},\n\t\t}\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{\n\t\t\t\tpluginID: p,\n\t\t\t},\n\t\t}\n\t\tl := &logger{}\n\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, requestedFile)\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\trequire.Equal(t, 200, sc.resp.Code)\n\t\t\t\tassert.Equal(t, expectedBody, sc.resp.Body.String())\n\t\t\t\tassert.Empty(t, l.warnings)\n\t\t\t})\n\t})\n\n\tt.Run(\"Given a request for a relative path\", func(t *testing.T) {\n\t\tp := plugins.PluginDTO{\n\t\t\tJSONData: plugins.JSONData{\n\t\t\t\tID: pluginID,\n\t\t\t},\n\t\t\tPluginDir: pluginDir,\n\t\t}\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{\n\t\t\t\tpluginID: p,\n\t\t\t},\n\t\t}\n\t\tl := &logger{}\n\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, tmpFileInParentDir.Name())\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\trequire.Equal(t, 404, sc.resp.Code)\n\t\t\t})\n\t})\n\n\tt.Run(\"Given a request for an existing plugin file that is not listed as a signature covered file\", func(t *testing.T) {\n\t\tp := plugins.PluginDTO{\n\t\t\tJSONData: plugins.JSONData{\n\t\t\t\tID: pluginID,\n\t\t\t},\n\t\t\tPluginDir: pluginDir,\n\t\t}\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{\n\t\t\t\tpluginID: p,\n\t\t\t},\n\t\t}\n\t\tl := &logger{}\n\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, requestedFile)\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\trequire.Equal(t, 200, sc.resp.Code)\n\t\t\t\tassert.Equal(t, expectedBody, sc.resp.Body.String())\n\t\t\t\tassert.Empty(t, l.warnings)\n\t\t\t})\n\t})\n\n\tt.Run(\"Given a request for an non-existing plugin file\", func(t *testing.T) {\n\t\tp := plugins.PluginDTO{\n\t\t\tJSONData: plugins.JSONData{\n\t\t\t\tID: pluginID,\n\t\t\t},\n\t\t\tPluginDir: pluginDir,\n\t\t}\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{\n\t\t\t\tpluginID: p,\n\t\t\t},\n\t\t}\n\t\tl := &logger{}\n\n\t\trequestedFile := \"nonExistent\"\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, requestedFile)\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\tvar respJson map[string]interface{}\n\t\t\t\terr := json.NewDecoder(sc.resp.Body).Decode(&respJson)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, 404, sc.resp.Code)\n\t\t\t\tassert.Equal(t, \"Plugin file not found\", respJson[\"message\"])\n\t\t\t\tassert.Empty(t, l.warnings)\n\t\t\t})\n\t})\n\n\tt.Run(\"Given a request for an non-existing plugin\", func(t *testing.T) {\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{},\n\t\t}\n\t\tl := &logger{}\n\n\t\trequestedFile := \"nonExistent\"\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, requestedFile)\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\tvar respJson map[string]interface{}\n\t\t\t\terr := json.NewDecoder(sc.resp.Body).Decode(&respJson)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tassert.Equal(t, 404, sc.resp.Code)\n\t\t\t\tassert.Equal(t, \"Plugin not found\", respJson[\"message\"])\n\t\t\t\tassert.Empty(t, l.warnings)\n\t\t\t})\n\t})\n\n\tt.Run(\"Given a request for a core plugin's file\", func(t *testing.T) {\n\t\tservice := &fakePluginStore{\n\t\t\tplugins: map[string]plugins.PluginDTO{\n\t\t\t\tpluginID: {\n\t\t\t\t\tClass: plugins.Core,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tl := &logger{}\n\n\t\turl := fmt.Sprintf(\"/public/plugins/%s/%s\", pluginID, requestedFile)\n\t\tpluginAssetScenario(t, \"When calling GET on\", url, \"/public/plugins/:pluginId/*\", service, l,\n\t\t\tfunc(sc *scenarioContext) {\n\t\t\t\tcallGetPluginAsset(sc)\n\n\t\t\t\trequire.Equal(t, 200, sc.resp.Code)\n\t\t\t\tassert.Equal(t, expectedBody, sc.resp.Body.String())\n\t\t\t\tassert.Empty(t, l.warnings)\n\t\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func fakeEvent(tb testing.TB, subtype subtype, format format, input *logical.LogInput) *eventlogger.Event {\n\ttb.Helper()\n\n\tdate := time.Date(2023, time.July, 11, 15, 49, 10, 0o0, time.Local)\n\n\tauditEvent, err := NewEvent(subtype,\n\t\tWithID(\"123\"),\n\t\tWithNow(date),\n\t)\n\trequire.NoError(tb, err)\n\trequire.NotNil(tb, auditEvent)\n\trequire.Equal(tb, \"123\", auditEvent.ID)\n\trequire.Equal(tb, \"v0.1\", auditEvent.Version)\n\trequire.Equal(tb, subtype, auditEvent.Subtype)\n\trequire.Equal(tb, date, auditEvent.Timestamp)\n\n\tauditEvent.Data = input\n\n\te := &eventlogger.Event{\n\t\tType:      eventlogger.EventType(event.AuditType),\n\t\tCreatedAt: auditEvent.Timestamp,\n\t\tFormatted: make(map[string][]byte),\n\t\tPayload:   auditEvent,\n\t}\n\n\treturn e\n}", "is_vulnerable": 1}
{"code": "func setup(t *testing.T) *testContext {\n\tpc := &fakePluginClient{}\n\tdc := &fakeDataSourceCache{ds: &datasources.DataSource{}}\n\ttc := &fakeOAuthTokenService{}\n\trv := &fakePluginRequestValidator{}\n\n\tss := kvstore.SetupTestService(t)\n\tssvc := secretsManager.SetupTestService(t, fakes.NewFakeSecretsStore())\n\tds := dsSvc.ProvideService(nil, ssvc, ss, nil, featuremgmt.WithFeatures(), acmock.New(), acmock.NewMockedPermissionsService())\n\n\treturn &testContext{\n\t\tpluginContext:          pc,\n\t\tsecretStore:            ss,\n\t\tdataSourceCache:        dc,\n\t\toauthTokenService:      tc,\n\t\tpluginRequestValidator: rv,\n\t\tqueryService:           query.ProvideService(setting.NewCfg(), dc, nil, rv, ds, pc, tc),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f *Formatter) AddValues(kvList []interface{}) {\n\t// Three slice args forces a copy.\n\tn := len(f.values)\n\tf.values = append(f.values[:n:n], kvList...)\n\n\tvals := f.values\n\tif hook := f.opts.RenderValuesHook; hook != nil {\n\t\tvals = hook(f.sanitize(vals))\n\t}\n\n\t// Pre-render values, so we don't have to do it on each Info/Error call.\n\tbuf := bytes.NewBuffer(make([]byte, 0, 1024))\n\tf.flatten(buf, vals, false, true) // escape user-provided keys\n\tf.valuesStr = buf.String()\n}", "is_vulnerable": 1}
{"code": "\ts.mux.HandleFunc(\"/healthz\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.WriteHeader(http.StatusOK)\n\t\tfmt.Fprint(w, \"ok\")\n\t})", "is_vulnerable": 0}
{"code": "func (sc *scenarioContext) fakeReqWithParams(method, url string, queryParams map[string]string) *scenarioContext {\n\tsc.resp = httptest.NewRecorder()\n\treq, err := http.NewRequest(method, url, nil)\n\t// TODO: Depend on sc.t\n\tif sc.t != nil {\n\t\trequire.NoError(sc.t, err)\n\t} else if err != nil {\n\t\tpanic(fmt.Sprintf(\"Making request failed: %s\", err))\n\t}\n\n\treq.Header.Add(\"Content-Type\", \"application/json\")\n\n\tq := req.URL.Query()\n\tfor k, v := range queryParams {\n\t\tq.Add(k, v)\n\t}\n\treq.URL.RawQuery = q.Encode()\n\tsc.req = req\n\treturn sc\n}", "is_vulnerable": 0}
{"code": "func (g *GitGetter) checkout(ctx context.Context, dst string, ref string) error {\n\tcmd := exec.CommandContext(ctx, \"git\", \"checkout\", ref)\n\tcmd.Dir = dst\n\treturn getRunCommand(cmd)\n}", "is_vulnerable": 0}
{"code": "func Test_AddRequestFilters(t *testing.T) {\n\tfilters, err := AddRequestFilters(\n\t\t\"ne(cluster, TheWorst)+eq(workflow.name, workflow)\", common.Execution, make([]common.InlineFilter, 0))\n\n\tassert.NoError(t, err)\n\trequire.Len(t, filters, 2)\n\n\texpression, err := filters[0].GetGormQueryExpr()\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"cluster <> ?\", expression.Query)\n\tassert.Equal(t, \"TheWorst\", expression.Args)\n\n\texpression, err = filters[1].GetGormQueryExpr()\n\tassert.NoError(t, err)\n\tassert.Equal(t, testutils.NameQueryPattern, expression.Query)\n\tassert.Equal(t, \"workflow\", expression.Args)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CredsAdd(ctx context.Context, in *clientpb.Credentials, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/CredsAdd\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func String(n int) (string, error) {\n\treturn StringFromCharset(n, letterBytes)\n}", "is_vulnerable": 0}
{"code": "func pickRandomNonAdminLoginFailure(failures map[string]LoginAttempts, username string) *string {\n\tidx := rand.Intn(len(failures) - 1)\n\ti := 0\n\tfor key := range failures {\n\t\tif i == idx {\n\t\t\tif key == common.ArgoCDAdminUsername || key == username {\n\t\t\t\treturn pickRandomNonAdminLoginFailure(failures, username)\n\t\t\t}\n\t\t\treturn &key\n\t\t}\n\t\ti++\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil, level.AllowNone())\n\t})", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerBadAppDirPermsFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: apps/foo\n`\n\td := emptyContainer(c)\n\tc.Assert(os.Mkdir(filepath.Join(d.Path(), \"apps\"), 0700), IsNil)\n\tc.Assert(os.WriteFile(filepath.Join(d.Path(), \"apps\", \"foo\"), nil, 0555), IsNil)\n\n\t// snapdir contains executable app, but path to executable isn't rx\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(d, info, discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 1}
{"code": "func (m *SampleOneOf) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: SampleOneOf: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: SampleOneOf: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &SampleOneOf_Field1{float64(math.Float64frombits(v))}\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &SampleOneOf_Field2{float32(math.Float32frombits(v))}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_Field3{v}\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_Field4{v}\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_Field5{v}\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_Field6{v}\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.TestOneof = &SampleOneOf_Field7{v}\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\tm.TestOneof = &SampleOneOf_Field8{int64(v)}\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &SampleOneOf_Field9{v}\n\t\tcase 10:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &SampleOneOf_Field10{v}\n\t\tcase 11:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &SampleOneOf_Field11{v}\n\t\tcase 12:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &SampleOneOf_Field12{v}\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.TestOneof = &SampleOneOf_Field13{b}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_Field14{string(dAtA[iNdEx:postIndex])}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := make([]byte, postIndex-iNdEx)\n\t\t\tcopy(v, dAtA[iNdEx:postIndex])\n\t\t\tm.TestOneof = &SampleOneOf_Field15{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field SubMessage\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &Subby{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.TestOneof = &SampleOneOf_SubMessage{v}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_OutgoingTLS_VerifyOutgoing(t *testing.T) {\n\tconf := &Config{\n\t\tVerifyOutgoing: true,\n\t\tCAFile:         \"../test/ca/root.cer\",\n\t}\n\tc := NewConfigurator(conf)\n\ttlsConf, err := c.OutgoingRPCConfig()\n\trequire.NoError(t, err)\n\trequire.NotNil(t, tlsConf)\n\trequire.Len(t, tlsConf.RootCAs.Subjects(), 1)\n\trequire.Empty(t, tlsConf.ServerName)\n\trequire.True(t, tlsConf.InsecureSkipVerify)\n}", "is_vulnerable": 1}
{"code": "func updateDeviceCgroupForGuestRootfs(spec *pb.Spec) {\n\tvar devStat unix.Stat_t\n\n\terr := unix.Stat(vmRootfs, &devStat)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tdevMajor := int64(unix.Major(devStat.Dev))\n\tdevMinor := int64(unix.Minor(devStat.Dev))\n\n\tnvdimmCg := pb.LinuxDeviceCgroup{\n\t\tAllow:  false,\n\t\tMajor:  devMajor,\n\t\tMinor:  devMinor,\n\t\tType:   \"b\",\n\t\tAccess: \"rwm\",\n\t}\n\n\tspec.Linux.Resources.Devices = append(spec.Linux.Resources.Devices, nvdimmCg)\n}", "is_vulnerable": 0}
{"code": "func (h *helm) GetParameters(valuesFiles []pathutil.ResolvedFilePath) (map[string]string, error) {\n\tout, err := h.cmd.inspectValues(\".\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvalues := []string{out}\n\tfor i := range valuesFiles {\n\t\tfile := string(valuesFiles[i])\n\t\tvar fileValues []byte\n\t\tparsedURL, err := url.ParseRequestURI(file)\n\t\tif err == nil && (parsedURL.Scheme == \"http\" || parsedURL.Scheme == \"https\") {\n\t\t\tfileValues, err = config.ReadRemoteFile(file)\n\t\t} else {\n\t\t\tif _, err := os.Stat(file); os.IsNotExist(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfileValues, err = ioutil.ReadFile(file)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to read value file %s: %s\", file, err)\n\t\t}\n\t\tvalues = append(values, string(fileValues))\n\t}\n\n\toutput := map[string]string{}\n\tfor _, file := range values {\n\t\tvalues := map[string]interface{}{}\n\t\tif err = yaml.Unmarshal([]byte(file), &values); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to parse values: %s\", err)\n\t\t}\n\t\tflatVals(values, output)\n\t}\n\n\treturn output, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Sideload(ctx context.Context, in *sliverpb.SideloadReq, opts ...grpc.CallOption) (*sliverpb.Sideload, error) {\n\tout := new(sliverpb.Sideload)\n\terr := c.cc.Invoke(ctx, SliverRPC_Sideload_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\treturn func(compiler *Compiler) {\n\t\tcompiler.workspaceBase = base\n\t\tcompiler.workspacePath = path\n\t}", "is_vulnerable": 0}
{"code": "func (m *MapProtoTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: MapProtoTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: MapProtoTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableTimestamp == nil {\n\t\t\t\tm.NullableTimestamp = make(map[int32]*types.Timestamp)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Timestamp\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Timestamp{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableTimestamp[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Timestamp == nil {\n\t\t\t\tm.Timestamp = make(map[int32]types.Timestamp)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Timestamp{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Timestamp{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Timestamp[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDuration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDuration == nil {\n\t\t\t\tm.NullableDuration = make(map[int32]*types.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Duration\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Duration{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDuration[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Duration == nil {\n\t\t\t\tm.Duration = make(map[int32]types.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Duration{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Duration{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Duration[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDouble == nil {\n\t\t\t\tm.NullableDouble = make(map[int32]*types.DoubleValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.DoubleValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.DoubleValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDouble[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullDouble == nil {\n\t\t\t\tm.NonnullDouble = make(map[int32]types.DoubleValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.DoubleValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.DoubleValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullDouble[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableFloat == nil {\n\t\t\t\tm.NullableFloat = make(map[int32]*types.FloatValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.FloatValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.FloatValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableFloat[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullFloat == nil {\n\t\t\t\tm.NonnullFloat = make(map[int32]types.FloatValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.FloatValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.FloatValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullFloat[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt64 == nil {\n\t\t\t\tm.NullableInt64 = make(map[int32]*types.Int64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Int64Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt64[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt64 == nil {\n\t\t\t\tm.NonnullInt64 = make(map[int32]types.Int64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Int64Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt64[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt64 == nil {\n\t\t\t\tm.NullableUInt64 = make(map[int32]*types.UInt64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.UInt64Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt64[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt64 == nil {\n\t\t\t\tm.NonnullUInt64 = make(map[int32]types.UInt64Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.UInt64Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt64Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt64[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt32 == nil {\n\t\t\t\tm.NullableInt32 = make(map[int32]*types.Int32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.Int32Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt32[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt32 == nil {\n\t\t\t\tm.NonnullInt32 = make(map[int32]types.Int32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.Int32Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.Int32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt32[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt32 == nil {\n\t\t\t\tm.NullableUInt32 = make(map[int32]*types.UInt32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.UInt32Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt32[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt32 == nil {\n\t\t\t\tm.NonnullUInt32 = make(map[int32]types.UInt32Value)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.UInt32Value{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.UInt32Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt32[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBool == nil {\n\t\t\t\tm.NullableBool = make(map[int32]*types.BoolValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.BoolValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BoolValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBool[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBool == nil {\n\t\t\t\tm.NonnullBool = make(map[int32]types.BoolValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.BoolValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BoolValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBool[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableString == nil {\n\t\t\t\tm.NullableString = make(map[int32]*types.StringValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.StringValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.StringValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableString[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullString == nil {\n\t\t\t\tm.NonnullString = make(map[int32]types.StringValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.StringValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.StringValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullString[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBytes == nil {\n\t\t\t\tm.NullableBytes = make(map[int32]*types.BytesValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *types.BytesValue\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BytesValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBytes[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBytes == nil {\n\t\t\t\tm.NonnullBytes = make(map[int32]types.BytesValue)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &types.BytesValue{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &types.BytesValue{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBytes[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) Path() string {\n\treturn fs.unixFS.BasePath()\n}", "is_vulnerable": 0}
{"code": "func BenchmarkSimpleLoop(b *testing.B) {\n\n\tstaticCallIdentity := []byte{\n\t\tbyte(vm.JUMPDEST), //  [ count ]\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),       // out offset\n\t\tbyte(vm.DUP1),       // out insize\n\t\tbyte(vm.DUP1),       // in offset\n\t\tbyte(vm.PUSH1), 0x4, // address of identity\n\t\tbyte(vm.GAS), // gas\n\t\tbyte(vm.STATICCALL),\n\t\tbyte(vm.POP),      // pop return value\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\tcallIdentity := []byte{\n\t\tbyte(vm.JUMPDEST), //  [ count ]\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),       // out offset\n\t\tbyte(vm.DUP1),       // out insize\n\t\tbyte(vm.DUP1),       // in offset\n\t\tbyte(vm.DUP1),       // value\n\t\tbyte(vm.PUSH1), 0x4, // address of identity\n\t\tbyte(vm.GAS), // gas\n\t\tbyte(vm.CALL),\n\t\tbyte(vm.POP),      // pop return value\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\tcallInexistant := []byte{\n\t\tbyte(vm.JUMPDEST), //  [ count ]\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),        // out offset\n\t\tbyte(vm.DUP1),        // out insize\n\t\tbyte(vm.DUP1),        // in offset\n\t\tbyte(vm.DUP1),        // value\n\t\tbyte(vm.PUSH1), 0xff, // address of existing contract\n\t\tbyte(vm.GAS), // gas\n\t\tbyte(vm.CALL),\n\t\tbyte(vm.POP),      // pop return value\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\tcallEOA := []byte{\n\t\tbyte(vm.JUMPDEST), //  [ count ]\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),        // out offset\n\t\tbyte(vm.DUP1),        // out insize\n\t\tbyte(vm.DUP1),        // in offset\n\t\tbyte(vm.DUP1),        // value\n\t\tbyte(vm.PUSH1), 0xE0, // address of EOA\n\t\tbyte(vm.GAS), // gas\n\t\tbyte(vm.CALL),\n\t\tbyte(vm.POP),      // pop return value\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\tloopingCode := []byte{\n\t\tbyte(vm.JUMPDEST), //  [ count ]\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),       // out offset\n\t\tbyte(vm.DUP1),       // out insize\n\t\tbyte(vm.DUP1),       // in offset\n\t\tbyte(vm.PUSH1), 0x4, // address of identity\n\t\tbyte(vm.GAS), // gas\n\n\t\tbyte(vm.POP), byte(vm.POP), byte(vm.POP), byte(vm.POP), byte(vm.POP), byte(vm.POP),\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\tcalllRevertingContractWithInput := []byte{\n\t\tbyte(vm.JUMPDEST), //\n\t\t// push args for the call\n\t\tbyte(vm.PUSH1), 0, // out size\n\t\tbyte(vm.DUP1),        // out offset\n\t\tbyte(vm.PUSH1), 0x20, // in size\n\t\tbyte(vm.PUSH1), 0x00, // in offset\n\t\tbyte(vm.PUSH1), 0x00, // value\n\t\tbyte(vm.PUSH1), 0xEE, // address of reverting contract\n\t\tbyte(vm.GAS), // gas\n\t\tbyte(vm.CALL),\n\t\tbyte(vm.POP),      // pop return value\n\t\tbyte(vm.PUSH1), 0, // jumpdestination\n\t\tbyte(vm.JUMP),\n\t}\n\n\t//tracer := vm.NewJSONLogger(nil, os.Stdout)\n\t//Execute(loopingCode, nil, &Config{\n\t//\tEVMConfig: vm.Config{\n\t//\t\tDebug:  true,\n\t//\t\tTracer: tracer,\n\t//\t}})\n\t// 100M gas\n\tbenchmarkNonModifyingCode(100000000, staticCallIdentity, \"staticcall-identity-100M\", b)\n\tbenchmarkNonModifyingCode(100000000, callIdentity, \"call-identity-100M\", b)\n\tbenchmarkNonModifyingCode(100000000, loopingCode, \"loop-100M\", b)\n\tbenchmarkNonModifyingCode(100000000, callInexistant, \"call-nonexist-100M\", b)\n\tbenchmarkNonModifyingCode(100000000, callEOA, \"call-EOA-100M\", b)\n\tbenchmarkNonModifyingCode(100000000, calllRevertingContractWithInput, \"call-reverting-100M\", b)\n\n\t//benchmarkNonModifyingCode(10000000, staticCallIdentity, \"staticcall-identity-10M\", b)\n\t//benchmarkNonModifyingCode(10000000, loopingCode, \"loop-10M\", b)\n}", "is_vulnerable": 0}
{"code": "func InitV1Router() *gin.Engine {\n\tginMode := gin.ReleaseMode\n\tif config.ServerInfo.RunMode != \"\" {\n\t\tginMode = config.ServerInfo.RunMode\n\t}\n\tif os.Getenv(gin.EnvGinMode) != \"\" {\n\t\tginMode = os.Getenv(gin.EnvGinMode)\n\t}\n\tgin.SetMode(ginMode)\n\n\tr := gin.New()\n\tr.Use(gin.Recovery())\n\tr.Use(middleware.Cors())\n\tr.Use(gzip.Gzip(gzip.DefaultCompression))\n\tif ginMode != gin.ReleaseMode {\n\t\tr.Use(middleware.WriteLog())\n\t}\n\n\tr.GET(\"/v1/sys/debug\", v1.GetSystemConfigDebug) // //debug\n\n\tr.GET(\"/v1/sys/version/check\", v1.GetSystemCheckVersion)\n\tr.GET(\"/ping\", func(ctx *gin.Context) {\n\t\tctx.String(200, \"pong\")\n\t})\n\tr.GET(\"/v1/recover/:type\", v1.GetRecoverStorage)\n\tv1Group := r.Group(\"/v1\")\n\n\tv1Group.Use(jwt.ExceptLocalhost())\n\t{\n\n\t\tv1SysGroup := v1Group.Group(\"/sys\")\n\t\tv1SysGroup.Use()\n\t\t{\n\t\t\tv1SysGroup.GET(\"/version\", v1.GetSystemCheckVersion) // version/check\n\n\t\t\tv1SysGroup.POST(\"/update\", v1.SystemUpdate)\n\n\t\t\tv1SysGroup.GET(\"/hardware\", v1.GetSystemHardwareInfo) // hardware/info\n\n\t\t\tv1SysGroup.GET(\"/wsssh\", v1.WsSsh)\n\t\t\tv1SysGroup.POST(\"/ssh-login\", v1.PostSshLogin)\n\t\t\t// v1SysGroup.GET(\"/config\", v1.GetSystemConfig) //delete\n\t\t\t// v1SysGroup.POST(\"/config\", v1.PostSetSystemConfig)\n\t\t\tv1SysGroup.GET(\"/logs\", v1.GetCasaOSErrorLogs) // error/logs\n\t\t\t// v1SysGroup.GET(\"/widget/config\", v1.GetWidgetConfig)//delete\n\t\t\t// v1SysGroup.POST(\"/widget/config\", v1.PostSetWidgetConfig)//delete\n\n\t\t\tv1SysGroup.POST(\"/stop\", v1.PostKillCasaOS)\n\n\t\t\tv1SysGroup.GET(\"/utilization\", v1.GetSystemUtilization)\n\t\t\t// v1SysGroup.GET(\"/cpu\", v1.GetSystemCupInfo)\n\t\t\t// v1SysGroup.GET(\"/mem\", v1.GetSystemMemInfo)\n\t\t\t// v1SysGroup.GET(\"/disk\", v1.GetSystemDiskInfo)\n\t\t\t// v1SysGroup.GET(\"/network\", v1.GetSystemNetInfo)\n\n\t\t\tv1SysGroup.GET(\"/server-info\", nil)\n\t\t\tv1SysGroup.PUT(\"/server-info\", nil)\n\t\t\t// v1SysGroup.GET(\"/port\", v1.GetCasaOSPort)\n\t\t\t// v1SysGroup.PUT(\"/port\", v1.PutCasaOSPort)\n\t\t\tv1SysGroup.GET(\"/proxy\", v1.GetSystemProxy)\n\t\t\tv1SysGroup.PUT(\"/state/:state\", v1.PutSystemState)\n\t\t}\n\t\tv1PortGroup := v1Group.Group(\"/port\")\n\t\tv1PortGroup.Use()\n\t\t{\n\t\t\tv1PortGroup.GET(\"/\", v1.GetPort)              // app/port\n\t\t\tv1PortGroup.GET(\"/state/:port\", v1.PortCheck) // app/check/:port\n\t\t}\n\n\t\tv1FileGroup := v1Group.Group(\"/file\")\n\t\tv1FileGroup.Use()\n\t\t{\n\t\t\tv1FileGroup.GET(\"\", v1.GetDownloadSingleFile) // download/:path\n\t\t\tv1FileGroup.POST(\"\", v1.PostCreateFile)\n\t\t\tv1FileGroup.PUT(\"\", v1.PutFileContent)\n\t\t\tv1FileGroup.PUT(\"/name\", v1.RenamePath)\n\t\t\t// file/rename\n\t\t\tv1FileGroup.GET(\"/content\", v1.GetFilerContent) // file/read\n\n\t\t\t// File uploads need to be handled separately, and will not be modified here\n\t\t\t//v1FileGroup.POST(\"/upload\", v1.PostFileUpload)\n\t\t\tv1FileGroup.POST(\"/upload\", v1.PostFileUpload)\n\t\t\tv1FileGroup.GET(\"/upload\", v1.GetFileUpload)\n\t\t\t// v1FileGroup.GET(\"/download\", v1.UserFileDownloadCommonService)\n\t\t\tv1FileGroup.GET(\"/ws\", v1.ConnectWebSocket)\n\t\t\tv1FileGroup.GET(\"/peers\", v1.GetPeers)\n\t\t}\n\t\tv1CloudGroup := v1Group.Group(\"/cloud\")\n\t\tv1CloudGroup.Use()\n\t\t{\n\t\t\tv1CloudGroup.GET(\"\", v1.ListStorages)\n\t\t\tv1CloudGroup.DELETE(\"\", v1.UmountStorage)\n\t\t}\n\t\tv1DriverGroup := v1Group.Group(\"/driver\")\n\t\tv1DriverGroup.Use()\n\t\t{\n\t\t\tv1DriverGroup.GET(\"\", v1.ListDriverInfo)\n\t\t}\n\n\t\tv1FolderGroup := v1Group.Group(\"/folder\")\n\t\tv1FolderGroup.Use()\n\t\t{\n\t\t\tv1FolderGroup.PUT(\"/name\", v1.RenamePath)\n\t\t\tv1FolderGroup.GET(\"\", v1.DirPath)   ///file/dirpath\n\t\t\tv1FolderGroup.POST(\"\", v1.MkdirAll) ///file/mkdir\n\t\t\tv1FolderGroup.GET(\"/size\", v1.GetSize)\n\t\t\tv1FolderGroup.GET(\"/count\", v1.GetFileCount)\n\t\t}\n\t\tv1BatchGroup := v1Group.Group(\"/batch\")\n\t\tv1BatchGroup.Use()\n\t\t{\n\n\t\t\tv1BatchGroup.DELETE(\"\", v1.DeleteFile) // file/delete\n\t\t\tv1BatchGroup.DELETE(\"/:id/task\", v1.DeleteOperateFileOrDir)\n\t\t\tv1BatchGroup.POST(\"/task\", v1.PostOperateFileOrDir) // file/operate\n\t\t\tv1BatchGroup.GET(\"\", v1.GetDownloadFile)\n\t\t}\n\t\tv1ImageGroup := v1Group.Group(\"/image\")\n\t\tv1ImageGroup.Use()\n\t\t{\n\t\t\tv1ImageGroup.GET(\"\", v1.GetFileImage)\n\t\t}\n\t\tv1SambaGroup := v1Group.Group(\"/samba\")\n\t\tv1SambaGroup.Use()\n\t\t{\n\t\t\tv1ConnectionsGroup := v1SambaGroup.Group(\"/connections\")\n\t\t\tv1ConnectionsGroup.Use()\n\t\t\t{\n\t\t\t\tv1ConnectionsGroup.GET(\"\", v1.GetSambaConnectionsList)\n\t\t\t\tv1ConnectionsGroup.POST(\"\", v1.PostSambaConnectionsCreate)\n\t\t\t\tv1ConnectionsGroup.DELETE(\"/:id\", v1.DeleteSambaConnections)\n\t\t\t}\n\t\t\tv1SharesGroup := v1SambaGroup.Group(\"/shares\")\n\t\t\tv1SharesGroup.Use()\n\t\t\t{\n\t\t\t\tv1SharesGroup.GET(\"\", v1.GetSambaSharesList)\n\t\t\t\tv1SharesGroup.POST(\"\", v1.PostSambaSharesCreate)\n\t\t\t\tv1SharesGroup.DELETE(\"/:id\", v1.DeleteSambaShares)\n\t\t\t\tv1SharesGroup.GET(\"/status\", v1.GetSambaStatus)\n\t\t\t}\n\t\t}\n\t\tv1NotifyGroup := v1Group.Group(\"/notify\")\n\t\tv1NotifyGroup.Use()\n\t\t{\n\t\t\tv1NotifyGroup.POST(\"/:path\", v1.PostNotifyMessage)\n\t\t\t// merge to system\n\t\t\tv1NotifyGroup.POST(\"/system_status\", v1.PostSystemStatusNotify)\n\t\t}\n\n\t\tv1OtherGroup := v1Group.Group(\"/other\")\n\t\tv1OtherGroup.Use()\n\t\t{\n\t\t\tv1OtherGroup.GET(\"/search\", v1.GetSearchResult)\n\n\t\t}\n\t}\n\n\treturn r\n}", "is_vulnerable": 1}
{"code": "func (e *ERC20LogicView) FindAssetList(\n\tal *types.ERC20AssetList,\n\tblockNumber,\n\tlogIndex uint64,\n\ttxHash string,\n) error {\n\tbf, err := bridgecontract.NewErc20BridgeLogicRestrictedFilterer(\n\t\te.clt.CollateralBridgeAddress(), e.clt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresp := \"ok\"\n\tdefer func() {\n\t\tmetrics.EthCallInc(\"find_asset_list\", al.VegaAssetID, resp)\n\t}()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\titer, err := bf.FilterAssetListed(\n\t\t&bind.FilterOpts{\n\t\t\tStart:   blockNumber - 1,\n\t\t\tContext: ctx,\n\t\t},\n\t\t[]ethcommon.Address{ethcommon.HexToAddress(al.AssetSource)},\n\t\t[][32]byte{},\n\t)\n\tif err != nil {\n\t\tresp = getMaybeHTTPStatus(err)\n\t\treturn err\n\t}\n\tdefer iter.Close()\n\n\tvar event *bridgecontract.Erc20BridgeLogicRestrictedAssetListed\n\tassetID := strings.TrimPrefix(al.VegaAssetID, \"0x\")\n\n\tfor iter.Next() {\n\t\tif hex.EncodeToString(iter.Event.VegaAssetId[:]) == assetID &&\n\t\t\titer.Event.Raw.BlockNumber == blockNumber &&\n\t\t\tuint64(iter.Event.Raw.Index) == logIndex &&\n\t\t\titer.Event.Raw.TxHash.Hex() == txHash {\n\t\t\tevent = iter.Event\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif event == nil {\n\t\treturn ErrUnableToFindERC20AssetList\n\t}\n\n\t// now ensure we have enough confirmations\n\tif err := e.ethConfs.Check(event.Raw.BlockNumber); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tgo func(c chan<- *chanResolveResult) {\n\t\t\tdefer wg.Done()\n\n\t\t\tuserset, err := query.getTypeDefinitionRelationUsersets(ctx, nestedRC)\n\t\t\tif err == nil {\n\t\t\t\terr = query.resolveNode(ctx, nestedRC, userset, typesys)\n\t\t\t}\n\n\t\t\tselect {\n\t\t\tcase c <- &chanResolveResult{err: err, found: nestedRC.userFound()}:\n\t\t\tcase <-done:\n\t\t\t}\n\t\t}(c)", "is_vulnerable": 1}
{"code": "func (d *DispatchPayloadConfig) Validate() error {\n\t// Verify the destination doesn't escape\n\tescaped, err := escapingfs.PathEscapesAllocViaRelative(\"task/local/\", d.File)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"invalid destination path: %v\", err)\n\t} else if escaped {\n\t\treturn fmt.Errorf(\"destination escapes allocation directory\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tIt(\"podman run user capabilities test\", func() {\n\t\t// We need to ignore the containers.conf on the test distribution for this test\n\t\tos.Setenv(\"CONTAINERS_CONF\", \"/dev/null\")\n\t\tif IsRemote() {\n\t\t\tpodmanTest.RestartRemoteService()\n\t\t}\n\t\tsession := podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"bin\", ALPINE, \"grep\", \"CapBnd\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"00000000a80425fb\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"bin\", ALPINE, \"grep\", \"CapEff\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"bin\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"root\", ALPINE, \"grep\", \"CapBnd\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"00000000a80425fb\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"root\", ALPINE, \"grep\", \"CapEff\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"00000000a80425fb\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", \"--user\", \"root\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", ALPINE, \"grep\", \"CapBnd\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"00000000a80425fb\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--rm\", ALPINE, \"grep\", \"CapEff\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"00000000a80425fb\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--user=1000:1000\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapAmb\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000002\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--user=1000:1000\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000002\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--user=0\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapAmb\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--user=0:0\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapAmb\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tsession = podmanTest.Podman([]string{\"run\", \"--user=0:0\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000000\"))\n\n\t\tif os.Geteuid() > 0 {\n\t\t\tif os.Getenv(\"SKIP_USERNS\") != \"\" {\n\t\t\t\tSkip(\"Skip userns tests.\")\n\t\t\t}\n\t\t\tif _, err := os.Stat(\"/proc/self/uid_map\"); err != nil {\n\t\t\t\tSkip(\"User namespaces not supported.\")\n\t\t\t}\n\t\t\tsession = podmanTest.Podman([]string{\"run\", \"--userns=keep-id\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapAmb\", \"/proc/self/status\"})\n\t\t\tsession.WaitWithDefaultTimeout()\n\t\t\tExpect(session).Should(Exit(0))\n\t\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000002\"))\n\n\t\t\tsession = podmanTest.Podman([]string{\"run\", \"--userns=keep-id\", \"--privileged\", \"--rm\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\t\tsession.WaitWithDefaultTimeout()\n\t\t\tExpect(session).Should(Exit(0))\n\t\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000002\"))\n\n\t\t\tsession = podmanTest.Podman([]string{\"run\", \"--userns=keep-id\", \"--cap-add=DAC_OVERRIDE\", \"--rm\", ALPINE, \"grep\", \"CapInh\", \"/proc/self/status\"})\n\t\t\tsession.WaitWithDefaultTimeout()\n\t\t\tExpect(session).Should(Exit(0))\n\t\t\tExpect(session.OutputToString()).To(ContainSubstring(\"0000000000000002\"))\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) WGStartPortForward(ctx context.Context, in *sliverpb.WGPortForwardStartReq, opts ...grpc.CallOption) (*sliverpb.WGPortForward, error) {\n\tout := new(sliverpb.WGPortForward)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/WGStartPortForward\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestSecrets_GenerateKeyConfigTTL(t *testing.T) {\n\tsecretType := SecretTypeKey\n\trsName := \"test-genkey\"\n\n\ttd := setupTest(t, \"1h\", \"2h\")\n\tdefer cleanup(t, td, rsName, testRoles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create new role set\n\texpectedBinds := ResourceBindings{projRes: testRoles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"secret_type\": secretType,\n\t\t\t\"project\":     td.Project,\n\t\t\t\"bindings\":    bindsRaw,\n\t\t})\n\tsa := getRoleSetAccount(t, td, rsName)\n\n\t// expect error for trying to read token from key roleset\n\ttestGetTokenFail(t, td, rsName)\n\n\tcreds, resp := testGetKey(t, td, rsName)\n\tif int(resp.Secret.LeaseTotal().Hours()) != 1 {\n\t\tt.Fatalf(\"expected lease duration %d, got %d\", 1, int(resp.Secret.LeaseTotal().Hours()))\n\t}\n\n\t// Confirm calls with key work\n\tkeyHttpC := oauth2.NewClient(context.Background(), creds.TokenSource)\n\tcheckSecretPermissions(t, td, keyHttpC)\n\n\tkeyName := resp.Secret.InternalData[\"key_name\"].(string)\n\tif keyName == \"\" {\n\t\tt.Fatalf(\"expected internal data to include key name\")\n\t}\n\n\t_, err = td.IamAdmin.Projects.ServiceAccounts.Keys.Get(keyName).Do()\n\tif err != nil {\n\t\tt.Fatalf(\"could not get key from given internal 'key_name': %v\", err)\n\t}\n\n\ttestRenewSecretKey(t, td, resp.Secret)\n\ttestRevokeSecretKey(t, td, resp.Secret)\n\n\tk, err := td.IamAdmin.Projects.ServiceAccounts.Keys.Get(keyName).Do()\n\n\tif k != nil {\n\t\tt.Fatalf(\"expected error as revoked key was deleted, instead got key: %v\", k)\n\t}\n\tif err == nil || !isGoogleAccountKeyNotFoundErr(err) {\n\t\tt.Fatalf(\"expected 404 error from getting deleted key, instead got error: %v\", err)\n\t}\n\n\t// Cleanup: Delete role set\n\ttestRoleSetDelete(t, td, rsName, sa.Name)\n\tverifyProjectBindingsRemoved(t, td, sa.Email, testRoles)\n}", "is_vulnerable": 0}
{"code": "func TestRenderComponent(t *testing.T) {\n\tr := require.New(t)\n\tp := &provider{\n\t\trender: func(comp common.ApplicationComponent, patcher *value.Value, _, _, _ string) (*unstructured.Unstructured, []*unstructured.Unstructured, error) {\n\t\t\treturn &unstructured.Unstructured{\n\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\"apiVersion\": \"apps/v1\",\n\t\t\t\t\t\t\"kind\":       \"Deployment\",\n\t\t\t\t\t},\n\t\t\t\t}, []*unstructured.Unstructured{\n\t\t\t\t\t{\n\t\t\t\t\t\tObject: map[string]interface{}{\n\t\t\t\t\t\t\t\"apiVersion\": \"core.oam.dev/v1alpha2\",\n\t\t\t\t\t\t\t\"kind\":       \"ManualScalerTrait\",\n\t\t\t\t\t\t\t\"metadata\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\"labels\": map[string]interface{}{\n\t\t\t\t\t\t\t\t\t\"trait.oam.dev/resource\": \"scaler\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"spec\": map[string]interface{}{\"replicaCount\": int64(10)},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, nil\n\t\t},\n\t}\n\tv, err := value.NewValue(`value: {}`, nil, \"\")\n\tr.NoError(err)\n\terr = p.RenderComponent(nil, v, nil)\n\tr.NoError(err)\n\ts, err := v.String()\n\tr.NoError(err)\n\tr.Equal(s, `value: {}\noutput: {\n\tapiVersion: \"apps/v1\"\n\tkind:       \"Deployment\"\n}\noutputs: {\n\tscaler: {\n\t\tapiVersion: \"core.oam.dev/v1alpha2\"\n\t\tkind:       \"ManualScalerTrait\"\n\t\tmetadata: {\n\t\t\tlabels: {\n\t\t\t\t\"trait.oam.dev/resource\": \"scaler\"\n\t\t\t}\n\t\t}\n\t\tspec: {\n\t\t\treplicaCount: 10\n\t\t}\n\t}\n}\n`)\n}", "is_vulnerable": 0}
{"code": "func runCmd(ctx *cli.Context) error {\n\tglogger := log.NewGlogHandler(log.StreamHandler(os.Stderr, log.TerminalFormat(false)))\n\tglogger.Verbosity(log.Lvl(ctx.GlobalInt(VerbosityFlag.Name)))\n\tlog.Root().SetHandler(glogger)\n\tlogconfig := &vm.LogConfig{\n\t\tDisableMemory: ctx.GlobalBool(DisableMemoryFlag.Name),\n\t\tDisableStack:  ctx.GlobalBool(DisableStackFlag.Name),\n\t\tDebug:         ctx.GlobalBool(DebugFlag.Name),\n\t}\n\n\tvar (\n\t\ttracer      vm.Tracer\n\t\tdebugLogger *vm.StructLogger\n\t\tstatedb     *state.StateDB\n\t\tchainConfig *params.ChainConfig\n\t\tsender      = common.BytesToAddress([]byte(\"sender\"))\n\t\treceiver    = common.BytesToAddress([]byte(\"receiver\"))\n\t\tblockNumber uint64\n\t)\n\tif ctx.GlobalBool(MachineFlag.Name) {\n\t\ttracer = NewJSONLogger(logconfig, os.Stdout)\n\t} else if ctx.GlobalBool(DebugFlag.Name) {\n\t\tdebugLogger = vm.NewStructLogger(logconfig)\n\t\ttracer = debugLogger\n\t} else {\n\t\tdebugLogger = vm.NewStructLogger(logconfig)\n\t}\n\tif ctx.GlobalString(GenesisFlag.Name) != \"\" {\n\t\tgen := readGenesis(ctx.GlobalString(GenesisFlag.Name))\n\t\tdb := ethdb.NewMemDatabase()\n\t\tgenesis := gen.ToBlock(db)\n\t\tstatedb, _ = state.New(genesis.Root(), state.NewDatabase(db))\n\t\tchainConfig = gen.Config\n\t\tblockNumber = gen.Number\n\t} else {\n\t\tstatedb, _ = state.New(common.Hash{}, state.NewDatabase(ethdb.NewMemDatabase()))\n\t}\n\tif ctx.GlobalString(SenderFlag.Name) != \"\" {\n\t\tsender = common.HexToAddress(ctx.GlobalString(SenderFlag.Name))\n\t}\n\tstatedb.CreateAccount(sender)\n\n\tif ctx.GlobalString(ReceiverFlag.Name) != \"\" {\n\t\treceiver = common.HexToAddress(ctx.GlobalString(ReceiverFlag.Name))\n\t}\n\n\tvar (\n\t\tcode []byte\n\t\tret  []byte\n\t\terr  error\n\t)\n\t// The '--code' or '--codefile' flag overrides code in state\n\tif ctx.GlobalString(CodeFileFlag.Name) != \"\" {\n\t\tvar hexcode []byte\n\t\tvar err error\n\t\t// If - is specified, it means that code comes from stdin\n\t\tif ctx.GlobalString(CodeFileFlag.Name) == \"-\" {\n\t\t\t//Try reading from stdin\n\t\t\tif hexcode, err = ioutil.ReadAll(os.Stdin); err != nil {\n\t\t\t\tfmt.Printf(\"Could not load code from stdin: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t} else {\n\t\t\t// Codefile with hex assembly\n\t\t\tif hexcode, err = ioutil.ReadFile(ctx.GlobalString(CodeFileFlag.Name)); err != nil {\n\t\t\t\tfmt.Printf(\"Could not load code from file: %v\\n\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t}\n\t\tcode = common.Hex2Bytes(string(bytes.TrimRight(hexcode, \"\\n\")))\n\n\t} else if ctx.GlobalString(CodeFlag.Name) != \"\" {\n\t\tcode = common.Hex2Bytes(ctx.GlobalString(CodeFlag.Name))\n\t} else if fn := ctx.Args().First(); len(fn) > 0 {\n\t\t// EASM-file to compile\n\t\tsrc, err := ioutil.ReadFile(fn)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tbin, err := compiler.Compile(fn, src, false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcode = common.Hex2Bytes(bin)\n\t}\n\n\tinitialGas := ctx.GlobalUint64(GasFlag.Name)\n\truntimeConfig := runtime.Config{\n\t\tOrigin:      sender,\n\t\tState:       statedb,\n\t\tGasLimit:    initialGas,\n\t\tGasPrice:    utils.GlobalBig(ctx, PriceFlag.Name),\n\t\tValue:       utils.GlobalBig(ctx, ValueFlag.Name),\n\t\tBlockNumber: new(big.Int).SetUint64(blockNumber),\n\t\tEVMConfig: vm.Config{\n\t\t\tTracer: tracer,\n\t\t\tDebug:  ctx.GlobalBool(DebugFlag.Name) || ctx.GlobalBool(MachineFlag.Name),\n\t\t},\n\t}\n\n\tif cpuProfilePath := ctx.GlobalString(CPUProfileFlag.Name); cpuProfilePath != \"\" {\n\t\tf, err := os.Create(cpuProfilePath)\n\t\tif err != nil {\n\t\t\tfmt.Println(\"could not create CPU profile: \", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err := pprof.StartCPUProfile(f); err != nil {\n\t\t\tfmt.Println(\"could not start CPU profile: \", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tdefer pprof.StopCPUProfile()\n\t}\n\n\tif chainConfig != nil {\n\t\truntimeConfig.ChainConfig = chainConfig\n\t}\n\ttstart := time.Now()\n\tvar leftOverGas uint64\n\tif ctx.GlobalBool(CreateFlag.Name) {\n\t\tinput := append(code, common.Hex2Bytes(ctx.GlobalString(InputFlag.Name))...)\n\t\tret, _, leftOverGas, err = runtime.Create(input, &runtimeConfig)\n\t} else {\n\t\tif len(code) > 0 {\n\t\t\tstatedb.SetCode(receiver, code)\n\t\t}\n\t\tret, leftOverGas, err = runtime.Call(receiver, common.Hex2Bytes(ctx.GlobalString(InputFlag.Name)), &runtimeConfig)\n\t}\n\texecTime := time.Since(tstart)\n\n\tif ctx.GlobalBool(DumpFlag.Name) {\n\t\tstatedb.IntermediateRoot(true)\n\t\tfmt.Println(string(statedb.Dump()))\n\t}\n\n\tif memProfilePath := ctx.GlobalString(MemProfileFlag.Name); memProfilePath != \"\" {\n\t\tf, err := os.Create(memProfilePath)\n\t\tif err != nil {\n\t\t\tfmt.Println(\"could not create memory profile: \", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err := pprof.WriteHeapProfile(f); err != nil {\n\t\t\tfmt.Println(\"could not write memory profile: \", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tf.Close()\n\t}\n\n\tif ctx.GlobalBool(DebugFlag.Name) {\n\t\tif debugLogger != nil {\n\t\t\tfmt.Fprintln(os.Stderr, \"#### TRACE ####\")\n\t\t\tvm.WriteTrace(os.Stderr, debugLogger.StructLogs())\n\t\t}\n\t\tfmt.Fprintln(os.Stderr, \"#### LOGS ####\")\n\t\tvm.WriteLogs(os.Stderr, statedb.Logs())\n\t}\n\n\tif ctx.GlobalBool(StatDumpFlag.Name) {\n\t\tvar mem goruntime.MemStats\n\t\tgoruntime.ReadMemStats(&mem)\n\t\tfmt.Fprintf(os.Stderr, `evm execution time: %v\nheap objects:       %d\nallocations:        %d\ntotal allocations:  %d\nGC calls:           %d\nGas used:           %d\n\n`, execTime, mem.HeapObjects, mem.Alloc, mem.TotalAlloc, mem.NumGC, initialGas-leftOverGas)\n\t}\n\tif tracer == nil {\n\t\tfmt.Printf(\"0x%x\\n\", ret)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\" error: %v\\n\", err)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestPrometheusConfigSecretsHidden(t *testing.T) {\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttime.Sleep(2 * time.Second)\n\t}))\n\tdefer ts.Close()\n\n\treq, err := http.NewRequest(\"GET\", \"?debug=true&target=\"+ts.URL, nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\trr := httptest.NewRecorder()\n\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil)\n\t})\n\thandler.ServeHTTP(rr, req)\n\n\tbody := rr.Body.String()\n\tif strings.Contains(body, \"mysecret\") {\n\t\tt.Errorf(\"Secret exposed in debug config output: %v\", body)\n\t}\n\tif !strings.Contains(body, \"<secret>\") {\n\t\tt.Errorf(\"Hidden secret missing from debug config output: %v\", body)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) ClientLog(ctx context.Context, opts ...grpc.CallOption) (SliverRPC_ClientLogClient, error) {\n\tstream, err := c.cc.NewStream(ctx, &SliverRPC_ServiceDesc.Streams[0], \"/rpcpb.SliverRPC/ClientLog\", opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tx := &sliverRPCClientLogClient{stream}\n\treturn x, nil\n}", "is_vulnerable": 0}
{"code": "func TestImportValidation(t *testing.T) {\n\tak := createAccountNKey(t)\n\tak2 := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\takp2 := publicKey(ak2, t)\n\ti := &Import{Subject: \"test\", Account: akp2, To: \"bar\", Type: Stream}\n\n\tvr := CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports should not generate an issue\")\n\t}\n\n\tvr = CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports should not generate an issue\")\n\t}\n\n\tactivation := NewActivationClaims(akp)\n\tactivation.Expires = time.Now().Add(time.Hour).UTC().Unix()\n\n\tactivation.ImportSubject = \"test\"\n\tactivation.ImportType = Stream\n\tactJWT := encode(activation, ak2, t)\n\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports with token should be valid\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *StdTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: StdTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: StdTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableTimestamp == nil {\n\t\t\t\tm.NullableTimestamp = new(time.Time)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(m.NullableTimestamp, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDuration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDuration == nil {\n\t\t\t\tm.NullableDuration = new(time.Duration)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(m.NullableDuration, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDouble == nil {\n\t\t\t\tm.NullableDouble = new(float64)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(m.NullableDouble, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableFloat == nil {\n\t\t\t\tm.NullableFloat = new(float32)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(m.NullableFloat, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt64 == nil {\n\t\t\t\tm.NullableInt64 = new(int64)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(m.NullableInt64, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt64 == nil {\n\t\t\t\tm.NullableUInt64 = new(uint64)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(m.NullableUInt64, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt32 == nil {\n\t\t\t\tm.NullableInt32 = new(int32)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(m.NullableInt32, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt32 == nil {\n\t\t\t\tm.NullableUInt32 = new(uint32)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(m.NullableUInt32, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBool == nil {\n\t\t\t\tm.NullableBool = new(bool)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(m.NullableBool, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableString == nil {\n\t\t\t\tm.NullableString = new(string)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(m.NullableString, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBytes == nil {\n\t\t\t\tm.NullableBytes = new([]byte)\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(m.NullableBytes, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&m.Timestamp, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(&m.Duration, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(&m.NonnullDouble, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(&m.NonnullFloat, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(&m.NonnullInt64, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(&m.NonnullUInt64, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(&m.NonnullInt32, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(&m.NonnullUInt32, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(&m.NonnullBool, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(&m.NonnullString, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(&m.NonnullBytes, dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (h *AppHandler) prepareWorkloadAndManifests(ctx context.Context,\n\tappParser *appfile.Parser,\n\tcomp common.ApplicationComponent,\n\tappRev *v1beta1.ApplicationRevision,\n\tpatcher *value.Value,\n\taf *appfile.Appfile) (*appfile.Workload, *types.ComponentManifest, error) {\n\twl, err := appParser.ParseWorkloadFromRevision(comp, appRev)\n\tif err != nil {\n\t\treturn nil, nil, errors.WithMessage(err, \"ParseWorkload\")\n\t}\n\twl.Patch = patcher\n\tmanifest, err := af.GenerateComponentManifest(wl, func(ctxData *process.ContextData) {\n\t\tif ns := componentNamespaceFromContext(ctx); ns != \"\" {\n\t\t\tctxData.Namespace = ns\n\t\t}\n\t\tif rk := replicaKeyFromContext(ctx); rk != \"\" {\n\t\t\tctxData.ReplicaKey = rk\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn nil, nil, errors.WithMessage(err, \"GenerateComponentManifest\")\n\t}\n\tif err := af.SetOAMContract(manifest); err != nil {\n\t\treturn nil, nil, errors.WithMessage(err, \"SetOAMContract\")\n\t}\n\tif err := h.HandleComponentsRevision(contextWithComponent(ctx, &comp), []*types.ComponentManifest{manifest}); err != nil {\n\t\treturn nil, nil, errors.WithMessage(err, \"HandleComponentsRevision\")\n\t}\n\n\treturn wl, manifest, nil\n}", "is_vulnerable": 0}
{"code": "func (c *immuClient) VerifiedTxByID(ctx context.Context, tx uint64) (*schema.Tx, error) {\n\terr := c.StateService.CacheLock()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer c.StateService.CacheUnlock()\n\n\tif !c.IsConnected() {\n\t\treturn nil, errors.FromError(ErrNotConnected)\n\t}\n\n\tstart := time.Now()\n\tdefer c.Logger.Debugf(\"VerifiedTxByID finished in %s\", time.Since(start))\n\n\tstate, err := c.StateService.GetState(ctx, c.Options.CurrentDatabase)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvTx, err := c.ServiceClient.VerifiableTxById(ctx, &schema.VerifiableTxRequest{\n\t\tTx:           tx,\n\t\tProveSinceTx: state.TxId,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdualProof := schema.DualProofFromProto(vTx.DualProof)\n\n\tvar sourceID, targetID uint64\n\tvar sourceAlh, targetAlh [sha256.Size]byte\n\n\tif state.TxId <= tx {\n\t\tsourceID = state.TxId\n\t\tsourceAlh = schema.DigestFromProto(state.TxHash)\n\t\ttargetID = tx\n\t\ttargetAlh = dualProof.TargetTxHeader.Alh()\n\t} else {\n\t\tsourceID = tx\n\t\tsourceAlh = dualProof.SourceTxHeader.Alh()\n\t\ttargetID = state.TxId\n\t\ttargetAlh = schema.DigestFromProto(state.TxHash)\n\t}\n\n\tif state.TxId > 0 {\n\t\tverifies := store.VerifyDualProof(\n\t\t\tdualProof,\n\t\t\tsourceID,\n\t\t\ttargetID,\n\t\t\tsourceAlh,\n\t\t\ttargetAlh,\n\t\t)\n\t\tif !verifies {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\tnewState := &schema.ImmutableState{\n\t\tDb:        c.currentDatabase(),\n\t\tTxId:      targetID,\n\t\tTxHash:    targetAlh[:],\n\t\tSignature: vTx.Signature,\n\t}\n\n\tif c.serverSigningPubKey != nil {\n\t\tok, err := newState.CheckSignature(c.serverSigningPubKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !ok {\n\t\t\treturn nil, store.ErrCorruptedData\n\t\t}\n\t}\n\n\terr = c.StateService.SetState(c.Options.CurrentDatabase, newState)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdecodeTxEntries(vTx.Tx.Entries)\n\n\treturn vTx.Tx, nil\n}", "is_vulnerable": 1}
{"code": "func Test_buildControlPlanePrefixRoute(t *testing.T) {\n\tb := &Builder{filemgr: filemgr.NewManager()}\n\troute, err := b.buildControlPlanePrefixRoute(\"/hello/world/\", false)\n\trequire.NoError(t, err)\n\ttestutil.AssertProtoJSONEqual(t, `\n\t\t{\n\t\t\t\"name\": \"pomerium-prefix-/hello/world/\",\n\t\t\t\"match\": {\n\t\t\t\t\"prefix\": \"/hello/world/\"\n\t\t\t},\n\t\t\t\"route\": {\n\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t},\n\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\"disabled\": true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t`, route)\n}", "is_vulnerable": 1}
{"code": "func (m *MockCoreStorage) GetRefreshTokenSession(arg0 context.Context, arg1 string, arg2 fosite.Session) (fosite.Requester, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetRefreshTokenSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(fosite.Requester)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) ShellcodeEncoderMap(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.ShellcodeEncoderMap, error) {\n\tout := new(clientpb.ShellcodeEncoderMap)\n\terr := c.cc.Invoke(ctx, SliverRPC_ShellcodeEncoderMap_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (t *Teler) checkCVE(r *http.Request) error {\n\t// data is the set of templates to check against.\n\tcveData := t.threat.cve\n\n\t// kind is the type of template to check (either \"path\" or \"raw\").\n\tvar kind string\n\n\t// requestParams is a map that stores the query parameters of the request URI and\n\t// iterate over the query parameters of the request URI and add them to the map.\n\trequestParams := make(map[string]string)\n\tfor q, v := range r.URL.Query() {\n\t\trequestParams[q] = v[0]\n\t}\n\n\t// Iterate over the templates in the data set.\n\tfor _, cveTemplate := range cveData.GetArray(\"templates\") {\n\t\t// ID is the current CVE ID of the templates\n\t\tcveID := string(cveTemplate.GetStringBytes(\"id\"))\n\n\t\t// Iterate over the requests in the template.\n\t\tfor _, request := range cveTemplate.GetArray(\"requests\") {\n\t\t\t// Determine the kind of template (either \"path\" or \"raw\").\n\t\t\tswitch {\n\t\t\tcase len(request.GetArray(\"path\")) > 0:\n\t\t\t\tkind = \"path\"\n\t\t\tcase len(request.GetArray(\"raw\")) > 0:\n\t\t\t\tkind = \"raw\"\n\t\t\t}\n\n\t\t\t// If the template is a \"path\" type and the request method doesn't match, skip this template.\n\t\t\tif kind == \"path\" && string(request.GetStringBytes(\"method\")) != r.Method {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Iterate over the CVE URLs\n\t\t\tfor _, cve := range cveURL[cveID] {\n\t\t\t\t// If the CVE path is empty or contains only a single character, skip this CVE URL.\n\t\t\t\tif len(cve.Path) <= 1 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// If the request path doesn't match the CVE path, skip this CVE URL.\n\t\t\t\tif r.URL.Path != cve.Path {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// diffParams is a map that stores the query parameters of the CVE URI and iterate over the\n\t\t\t\t// query parameters of the CVE URI and add them to the diffParams map.\n\t\t\t\tdiffParams := make(map[string]string)\n\t\t\t\tfor q, v := range cve.Query() {\n\t\t\t\t\tdiffParams[q] = v[0]\n\t\t\t\t}\n\n\t\t\t\t// allParamsMatch is a flag that indicates whether all the query parameters in the CVE URI are\n\t\t\t\t// present in the request URI and iterate over the query parameters of the CVE URI.\n\t\t\t\tallParamsMatch := true\n\t\t\t\tfor q, v := range diffParams {\n\t\t\t\t\t// If a query parameter in the CVE URI is not present in the request URI,\n\t\t\t\t\t// set allParamsMatch to false and break out of the loop.\n\t\t\t\t\tif requestParams[q] != v {\n\t\t\t\t\t\tallParamsMatch = false\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If all the query parameters in the CVE URI are present in the request URI, return an error of CVE ID.\n\t\t\t\tif allParamsMatch {\n\t\t\t\t\treturn errors.New(cveID)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return nil if the request doesn't match any known threat.\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\thandler := func() {\n\t\tuserObj, userRel := tuple.SplitObjectRelation(req.GetUser())\n\t\tuserObjType, userObjID := tuple.SplitObject(userObj)\n\n\t\tvar sourceUserRef reverseexpand.IsUserRef\n\t\tsourceUserRef = &reverseexpand.UserRefObject{\n\t\t\tObject: &openfgav1.Object{\n\t\t\t\tType: userObjType,\n\t\t\t\tId:   userObjID,\n\t\t\t},\n\t\t}\n\n\t\tif tuple.IsTypedWildcard(userObj) {\n\t\t\tsourceUserRef = &reverseexpand.UserRefTypedWildcard{Type: tuple.GetType(userObj)}\n\t\t}\n\n\t\tif userRel != \"\" {\n\t\t\tsourceUserRef = &reverseexpand.UserRefObjectRelation{\n\t\t\t\tObjectRelation: &openfgav1.ObjectRelation{\n\t\t\t\t\tObject:   userObj,\n\t\t\t\t\tRelation: userRel,\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\treverseExpandResultsChan := make(chan *reverseexpand.ReverseExpandResult, 1)\n\t\tobjectsFound := atomic.Uint32{}\n\n\t\treverseExpandQuery := reverseexpand.NewReverseExpandQuery(q.datastore, typesys,\n\t\t\treverseexpand.WithResolveNodeLimit(q.resolveNodeLimit),\n\t\t\treverseexpand.WithResolveNodeBreadthLimit(q.resolveNodeBreadthLimit),\n\t\t\treverseexpand.WithLogger(q.logger),\n\t\t)\n\n\t\tcancelCtx, cancel := context.WithCancel(ctx)\n\n\t\twg := sync.WaitGroup{}\n\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\n\t\t\treverseExpandQuery.Execute(cancelCtx, &reverseexpand.ReverseExpandRequest{\n\t\t\t\tStoreID:          req.GetStoreId(),\n\t\t\t\tObjectType:       targetObjectType,\n\t\t\t\tRelation:         targetRelation,\n\t\t\t\tUser:             sourceUserRef,\n\t\t\t\tContextualTuples: req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\tContext:          req.GetContext(),\n\t\t\t}, reverseExpandResultsChan, resolutionMetadata)\n\t\t}()\n\n\t\tcheckResolver := graph.NewLocalChecker(\n\t\t\tstoragewrappers.NewCombinedTupleReader(q.datastore, req.GetContextualTuples().GetTupleKeys()),\n\t\t\tq.checkOptions...,\n\t\t)\n\t\tdefer checkResolver.Close()\n\n\t\tconcurrencyLimiterCh := make(chan struct{}, q.resolveNodeBreadthLimit)\n\n\t\tfor res := range reverseExpandResultsChan {\n\t\t\tif res.Err != nil {\n\t\t\t\terr := res.Err\n\n\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\terr = serverErrors.AuthorizationModelResolutionTooComplex\n\t\t\t\t}\n\n\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tif !(maxResults == 0) && objectsFound.Load() >= maxResults {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tif res.ResultStatus == reverseexpand.NoFurtherEvalStatus {\n\t\t\t\tnoFurtherEvalRequiredCounter.Inc()\n\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfurtherEvalRequiredCounter.Inc()\n\n\t\t\twg.Add(1)\n\t\t\tgo func(res *reverseexpand.ReverseExpandResult) {\n\t\t\t\tdefer func() {\n\t\t\t\t\t<-concurrencyLimiterCh\n\t\t\t\t\twg.Done()\n\t\t\t\t}()\n\n\t\t\t\tconcurrencyLimiterCh <- struct{}{}\n\n\t\t\t\tresp, err := checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\t\t\t\tStoreID:              req.GetStoreId(),\n\t\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\t\t\t\tTupleKey:             tuple.NewTupleKey(res.Object, req.GetRelation(), req.GetUser()),\n\t\t\t\t\tContextualTuples:     req.GetContextualTuples().GetTupleKeys(),\n\t\t\t\t\tContext:              req.GetContext(),\n\t\t\t\t\tResolutionMetadata: &graph.ResolutionMetadata{\n\t\t\t\t\t\tDepth: q.resolveNodeLimit,\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t\tif err != nil {\n\t\t\t\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) || errors.Is(err, graph.ErrCycleDetected) {\n\t\t\t\t\t\tresultsChan <- ListObjectsResult{Err: serverErrors.AuthorizationModelResolutionTooComplex}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\n\t\t\t\t\tresultsChan <- ListObjectsResult{Err: err}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tatomic.AddUint32(resolutionMetadata.QueryCount, resp.GetResolutionMetadata().DatastoreQueryCount)\n\n\t\t\t\tif resp.Allowed {\n\t\t\t\t\ttrySendObject(res.Object, &objectsFound, maxResults, resultsChan)\n\t\t\t\t}\n\t\t\t}(res)\n\t\t}\n\n\t\tcancel()\n\t\twg.Wait()\n\t\tclose(resultsChan)\n\t}", "is_vulnerable": 1}
{"code": "func InEpsilonf(t TestingT, expected interface{}, actual interface{}, epsilon float64, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.InEpsilonf(t, expected, actual, epsilon, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "type AppResourceTreeFn func(ctx context.Context, app *appv1.Application) (*appv1.ApplicationTree, error)\n\nconst (\n\tmaxPodLogsToRender                 = 10\n\tbackgroundPropagationPolicy string = \"background\"\n\tforegroundPropagationPolicy string = \"foreground\"\n)\n\nvar (\n\twatchAPIBufferSize  = env.ParseNumFromEnv(argocommon.EnvWatchAPIBufferSize, 1000, 0, math.MaxInt32)\n\tpermissionDeniedErr = status.Error(codes.PermissionDenied, \"permission denied\")\n)\n\n// Server provides an Application service\ntype Server struct {\n\tns                string\n\tkubeclientset     kubernetes.Interface\n\tappclientset      appclientset.Interface\n\tappLister         applisters.ApplicationLister\n\tappInformer       cache.SharedIndexInformer\n\tappBroadcaster    Broadcaster\n\trepoClientset     apiclient.Clientset\n\tkubectl           kube.Kubectl\n\tdb                db.ArgoDB\n\tenf               *rbac.Enforcer\n\tprojectLock       sync.KeyLock\n\tauditLogger       *argo.AuditLogger\n\tsettingsMgr       *settings.SettingsManager\n\tcache             *servercache.Cache\n\tprojInformer      cache.SharedIndexInformer\n\tenabledNamespaces []string\n}", "is_vulnerable": 0}
{"code": "func newHandlerRole(namespace string) *rbacv1.Role {\n\treturn &rbacv1.Role{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"Role\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: namespace,\n\t\t\tName:      components.HandlerServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRules: []rbacv1.PolicyRule{\n\t\t\t{\n\t\t\t\tAPIGroups: []string{\n\t\t\t\t\t\"\",\n\t\t\t\t},\n\t\t\t\tResources: []string{\n\t\t\t\t\t\"configmaps\",\n\t\t\t\t},\n\t\t\t\tVerbs: []string{\n\t\t\t\t\t\"get\", \"list\", \"watch\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn sockjs.NewHandler(\"/api/v1/kolide/results\", opt, func(session sockjs.Session) {\n\t\tdefer session.Close(0, \"none\")\n\n\t\tconn := &websocket.Conn{Session: session}\n\n\t\t// Receive the auth bearer token\n\t\ttoken, err := conn.ReadAuthToken()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"failed to read auth token\")\n\t\t\treturn\n\t\t}\n\n\t\t// Authenticate with the token\n\t\tvc, err := authViewer(context.Background(), jwtKey, token, svc)\n\t\tif err != nil || !vc.CanPerformActions() {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unauthorized viewer\")\n\t\t\tconn.WriteJSONError(\"unauthorized\")\n\t\t\treturn\n\t\t}\n\n\t\tctx := viewer.NewContext(context.Background(), *vc)\n\n\t\tmsg, err := conn.ReadJSONMessage()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"reading select_campaign JSON\")\n\t\t\tconn.WriteJSONError(\"error reading select_campaign\")\n\t\t\treturn\n\t\t}\n\t\tif msg.Type != \"select_campaign\" {\n\t\t\tlogger.Log(\"err\", \"unexpected msg type, expected select_campaign\", \"msg-type\", msg.Type)\n\t\t\tconn.WriteJSONError(\"expected select_campaign\")\n\t\t\treturn\n\t\t}\n\n\t\tvar info struct {\n\t\t\tCampaignID uint `json:\"campaign_id\"`\n\t\t}\n\t\terr = json.Unmarshal(*(msg.Data.(*json.RawMessage)), &info)\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unmarshaling select_campaign data\")\n\t\t\tconn.WriteJSONError(\"error unmarshaling select_campaign data\")\n\t\t\treturn\n\t\t}\n\t\tif info.CampaignID == 0 {\n\t\t\tlogger.Log(\"err\", \"campaign ID not set\")\n\t\t\tconn.WriteJSONError(\"0 is not a valid campaign ID\")\n\t\t\treturn\n\t\t}\n\n\t\tsvc.StreamCampaignResults(ctx, conn, info.CampaignID)\n\n\t})", "is_vulnerable": 1}
{"code": "\tdefer func() {\n\t\tstopFunc()\n\t\tgoleak.VerifyNone(t)\n\t}()", "is_vulnerable": 0}
{"code": "func logPanic(r interface{}) {\n\t// Same as stdlib http server code. Manually allocate stack trace buffer size\n\t// to prevent excessively large logs\n\tconst size = 64 << 10\n\tstacktrace := make([]byte, size)\n\tstacktrace = stacktrace[:runtime.Stack(stacktrace, false)]\n\tlog.Errorf(\"Observed a panic: %#v (%v)\\n%s\", r, r, stacktrace)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Kill(ctx context.Context, in *sliverpb.KillReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Kill\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (src *FunctionCallResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'V')\n\n\tif src.Result == nil {\n\t\tdst = pgio.AppendInt32(dst, -1)\n\t} else {\n\t\tdst = pgio.AppendInt32(dst, int32(len(src.Result)))\n\t\tdst = append(dst, src.Result...)\n\t}\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeResponderMockRecorder) GetQuery() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetQuery\", reflect.TypeOf((*MockAuthorizeResponder)(nil).GetQuery))\n}", "is_vulnerable": 0}
{"code": "func (l *linuxStandardInit) Init() error {\n\truntime.LockOSThread()\n\tdefer runtime.UnlockOSThread()\n\tif !l.config.Config.NoNewKeyring {\n\t\tif err := selinux.SetKeyLabel(l.config.ProcessLabel); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer selinux.SetKeyLabel(\"\") //nolint: errcheck\n\t\tringname, keepperms, newperms := l.getSessionRingParams()\n\n\t\t// Do not inherit the parent's session keyring.\n\t\tif sessKeyId, err := keys.JoinSessionKeyring(ringname); err != nil {\n\t\t\t// If keyrings aren't supported then it is likely we are on an\n\t\t\t// older kernel (or inside an LXC container). While we could bail,\n\t\t\t// the security feature we are using here is best-effort (it only\n\t\t\t// really provides marginal protection since VFS credentials are\n\t\t\t// the only significant protection of keyrings).\n\t\t\t//\n\t\t\t// TODO(cyphar): Log this so people know what's going on, once we\n\t\t\t//               have proper logging in 'runc init'.\n\t\t\tif !errors.Is(err, unix.ENOSYS) {\n\t\t\t\treturn fmt.Errorf(\"unable to join session keyring: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\t// Make session keyring searchable. If we've gotten this far we\n\t\t\t// bail on any error -- we don't want to have a keyring with bad\n\t\t\t// permissions.\n\t\t\tif err := keys.ModKeyringPerm(sessKeyId, keepperms, newperms); err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to mod keyring permissions: %w\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := setupNetwork(l.config); err != nil {\n\t\treturn err\n\t}\n\tif err := setupRoute(l.config.Config); err != nil {\n\t\treturn err\n\t}\n\n\t// initialises the labeling system\n\tselinux.GetEnabled()\n\tif err := prepareRootfs(l.pipe, l.config); err != nil {\n\t\treturn err\n\t}\n\t// Set up the console. This has to be done *before* we finalize the rootfs,\n\t// but *after* we've given the user the chance to set up all of the mounts\n\t// they wanted.\n\tif l.config.CreateConsole {\n\t\tif err := setupConsole(l.consoleSocket, l.config, true); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := system.Setctty(); err != nil {\n\t\t\treturn &os.SyscallError{Syscall: \"ioctl(setctty)\", Err: err}\n\t\t}\n\t}\n\n\t// Finish the rootfs setup.\n\tif l.config.Config.Namespaces.Contains(configs.NEWNS) {\n\t\tif err := finalizeRootfs(l.config.Config); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif hostname := l.config.Config.Hostname; hostname != \"\" {\n\t\tif err := unix.Sethostname([]byte(hostname)); err != nil {\n\t\t\treturn &os.SyscallError{Syscall: \"sethostname\", Err: err}\n\t\t}\n\t}\n\tif err := apparmor.ApplyProfile(l.config.AppArmorProfile); err != nil {\n\t\treturn fmt.Errorf(\"unable to apply apparmor profile: %w\", err)\n\t}\n\n\tfor key, value := range l.config.Config.Sysctl {\n\t\tif err := writeSystemProperty(key, value); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, path := range l.config.Config.ReadonlyPaths {\n\t\tif err := readonlyPath(path); err != nil {\n\t\t\treturn fmt.Errorf(\"can't make %q read-only: %w\", path, err)\n\t\t}\n\t}\n\tfor _, path := range l.config.Config.MaskPaths {\n\t\tif err := maskPath(path, l.config.Config.MountLabel); err != nil {\n\t\t\treturn fmt.Errorf(\"can't mask path %s: %w\", path, err)\n\t\t}\n\t}\n\tpdeath, err := system.GetParentDeathSignal()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't get pdeath signal: %w\", err)\n\t}\n\tif l.config.NoNewPrivileges {\n\t\tif err := unix.Prctl(unix.PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0); err != nil {\n\t\t\treturn &os.SyscallError{Syscall: \"prctl(SET_NO_NEW_PRIVS)\", Err: err}\n\t\t}\n\t}\n\t// Tell our parent that we're ready to Execv. This must be done before the\n\t// Seccomp rules have been applied, because we need to be able to read and\n\t// write to a socket.\n\tif err := syncParentReady(l.pipe); err != nil {\n\t\treturn fmt.Errorf(\"sync ready: %w\", err)\n\t}\n\tif err := selinux.SetExecLabel(l.config.ProcessLabel); err != nil {\n\t\treturn fmt.Errorf(\"can't set process label: %w\", err)\n\t}\n\tdefer selinux.SetExecLabel(\"\") //nolint: errcheck\n\t// Without NoNewPrivileges seccomp is a privileged operation, so we need to\n\t// do this before dropping capabilities; otherwise do it as late as possible\n\t// just before execve so as few syscalls take place after it as possible.\n\tif l.config.Config.Seccomp != nil && !l.config.NoNewPrivileges {\n\t\tseccompFd, err := seccomp.InitSeccomp(l.config.Config.Seccomp)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := syncParentSeccomp(l.pipe, seccompFd); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif err := finalizeNamespace(l.config); err != nil {\n\t\treturn err\n\t}\n\t// finalizeNamespace can change user/group which clears the parent death\n\t// signal, so we restore it here.\n\tif err := pdeath.Restore(); err != nil {\n\t\treturn fmt.Errorf(\"can't restore pdeath signal: %w\", err)\n\t}\n\t// Compare the parent from the initial start of the init process and make\n\t// sure that it did not change.  if the parent changes that means it died\n\t// and we were reparented to something else so we should just kill ourself\n\t// and not cause problems for someone else.\n\tif unix.Getppid() != l.parentPid {\n\t\treturn unix.Kill(unix.Getpid(), unix.SIGKILL)\n\t}\n\t// Check for the arg before waiting to make sure it exists and it is\n\t// returned as a create time error.\n\tname, err := exec.LookPath(l.config.Args[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Set seccomp as close to execve as possible, so as few syscalls take\n\t// place afterward (reducing the amount of syscalls that users need to\n\t// enable in their seccomp profiles). However, this needs to be done\n\t// before closing the pipe since we need it to pass the seccompFd to\n\t// the parent.\n\tif l.config.Config.Seccomp != nil && l.config.NoNewPrivileges {\n\t\tseccompFd, err := seccomp.InitSeccomp(l.config.Config.Seccomp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"unable to init seccomp: %w\", err)\n\t\t}\n\n\t\tif err := syncParentSeccomp(l.pipe, seccompFd); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Close the pipe to signal that we have completed our init.\n\tlogrus.Debugf(\"init: closing the pipe to signal completion\")\n\t_ = l.pipe.Close()\n\n\t// Close the log pipe fd so the parent's ForwardLogs can exit.\n\tif err := unix.Close(l.logFd); err != nil {\n\t\treturn &os.PathError{Op: \"close log pipe\", Path: \"fd \" + strconv.Itoa(l.logFd), Err: err}\n\t}\n\n\t// Wait for the FIFO to be opened on the other side before exec-ing the\n\t// user process. We open it through /proc/self/fd/$fd, because the fd that\n\t// was given to us was an O_PATH fd to the fifo itself. Linux allows us to\n\t// re-open an O_PATH fd through /proc.\n\tfifoPath := \"/proc/self/fd/\" + strconv.Itoa(l.fifoFd)\n\tfd, err := unix.Open(fifoPath, unix.O_WRONLY|unix.O_CLOEXEC, 0)\n\tif err != nil {\n\t\treturn &os.PathError{Op: \"open exec fifo\", Path: fifoPath, Err: err}\n\t}\n\tif _, err := unix.Write(fd, []byte(\"0\")); err != nil {\n\t\treturn &os.PathError{Op: \"write exec fifo\", Path: fifoPath, Err: err}\n\t}\n\n\t// Close the O_PATH fifofd fd before exec because the kernel resets\n\t// dumpable in the wrong order. This has been fixed in newer kernels, but\n\t// we keep this to ensure CVE-2016-9962 doesn't re-emerge on older kernels.\n\t// N.B. the core issue itself (passing dirfds to the host filesystem) has\n\t// since been resolved.\n\t// https://github.com/torvalds/linux/blob/v4.9/fs/exec.c#L1290-L1318\n\t_ = unix.Close(l.fifoFd)\n\n\ts := l.config.SpecState\n\ts.Pid = unix.Getpid()\n\ts.Status = specs.StateCreated\n\tif err := l.config.Config.Hooks[configs.StartContainer].RunHooks(s); err != nil {\n\t\treturn err\n\t}\n\n\tif err := system.Exec(name, l.config.Args[0:], os.Environ()); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Compiler) createProcess(container *yaml_types.Container, stepType backend_types.StepType) (*backend_types.Step, error) {\n\tvar (\n\t\tuuid = ulid.Make()\n\n\t\tdetached   bool\n\t\tworkingDir string\n\n\t\tprivileged  = container.Privileged\n\t\tnetworkMode = container.NetworkMode\n\t)\n\n\tworkspaceBase := c.workspaceBase\n\tif container.IsPlugin() {\n\t\t// plugins have a predefined workspace base to not tamper with entrypoint executables\n\t\tworkspaceBase = pluginWorkspaceBase\n\t}\n\tworkspaceVolume := fmt.Sprintf(\"%s_default:%s\", c.prefix, workspaceBase)\n\n\tnetworks := []backend_types.Conn{\n\t\t{\n\t\t\tName:    fmt.Sprintf(\"%s_default\", c.prefix),\n\t\t\tAliases: []string{container.Name},\n\t\t},\n\t}\n\tfor _, network := range c.networks {\n\t\tnetworks = append(networks, backend_types.Conn{\n\t\t\tName: network,\n\t\t})\n\t}\n\n\textraHosts := make([]backend_types.HostAlias, len(container.ExtraHosts))\n\tfor i, extraHost := range container.ExtraHosts {\n\t\tname, ip, ok := strings.Cut(extraHost, \":\")\n\t\tif !ok {\n\t\t\treturn nil, &ErrExtraHostFormat{host: extraHost}\n\t\t}\n\t\textraHosts[i].Name = name\n\t\textraHosts[i].IP = ip\n\t}\n\n\tvar volumes []string\n\tif !c.local {\n\t\tvolumes = append(volumes, workspaceVolume)\n\t}\n\tvolumes = append(volumes, c.volumes...)\n\tfor _, volume := range container.Volumes.Volumes {\n\t\tvolumes = append(volumes, volume.String())\n\t}\n\n\t// append default environment variables\n\tenvironment := map[string]string{}\n\tmaps.Copy(environment, c.env)\n\n\tenvironment[\"CI_WORKSPACE\"] = path.Join(workspaceBase, c.workspacePath)\n\n\tif stepType == backend_types.StepTypeService || container.Detached {\n\t\tdetached = true\n\t}\n\n\tworkingDir = c.stepWorkingDir(container)\n\n\tgetSecretValue := func(name string) (string, error) {\n\t\tname = strings.ToLower(name)\n\t\tsecret, ok := c.secrets[name]\n\t\tif !ok {\n\t\t\treturn \"\", fmt.Errorf(\"secret %q not found\", name)\n\t\t}\n\n\t\tevent := c.metadata.Curr.Event\n\t\terr := secret.Available(event, container)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\treturn secret.Value, nil\n\t}\n\n\t// TODO: why don't we pass secrets to detached steps?\n\tif !detached {\n\t\tif err := settings.ParamsToEnv(container.Settings, environment, \"PLUGIN_\", true, getSecretValue); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := settings.ParamsToEnv(container.Environment, environment, \"\", false, getSecretValue); err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, requested := range container.Secrets.Secrets {\n\t\tsecretValue, err := getSecretValue(requested.Source)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tenvironment[requested.Target] = secretValue\n\t\t// TODO: deprecated, remove in 3.x\n\t\tenvironment[strings.ToUpper(requested.Target)] = secretValue\n\t}\n\n\tif utils.MatchImage(container.Image, c.escalated...) && container.IsPlugin() {\n\t\tprivileged = true\n\t}\n\n\tauthConfig := backend_types.Auth{}\n\tfor _, registry := range c.registries {\n\t\tif utils.MatchHostname(container.Image, registry.Hostname) {\n\t\t\tauthConfig.Username = registry.Username\n\t\t\tauthConfig.Password = registry.Password\n\t\t\tbreak\n\t\t}\n\t}\n\n\tmemSwapLimit := int64(container.MemSwapLimit)\n\tif c.reslimit.MemSwapLimit != 0 {\n\t\tmemSwapLimit = c.reslimit.MemSwapLimit\n\t}\n\tmemLimit := int64(container.MemLimit)\n\tif c.reslimit.MemLimit != 0 {\n\t\tmemLimit = c.reslimit.MemLimit\n\t}\n\tshmSize := int64(container.ShmSize)\n\tif c.reslimit.ShmSize != 0 {\n\t\tshmSize = c.reslimit.ShmSize\n\t}\n\tcpuQuota := int64(container.CPUQuota)\n\tif c.reslimit.CPUQuota != 0 {\n\t\tcpuQuota = c.reslimit.CPUQuota\n\t}\n\tcpuShares := int64(container.CPUShares)\n\tif c.reslimit.CPUShares != 0 {\n\t\tcpuShares = c.reslimit.CPUShares\n\t}\n\tcpuSet := container.CPUSet\n\tif c.reslimit.CPUSet != \"\" {\n\t\tcpuSet = c.reslimit.CPUSet\n\t}\n\n\tvar ports []backend_types.Port\n\tfor _, portDef := range container.Ports {\n\t\tport, err := convertPort(portDef)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tports = append(ports, port)\n\t}\n\n\t// at least one constraint contain status success, or all constraints have no status set\n\tonSuccess := container.When.IncludesStatusSuccess()\n\t// at least one constraint must include the status failure.\n\tonFailure := container.When.IncludesStatusFailure()\n\n\tfailure := container.Failure\n\tif container.Failure == \"\" {\n\t\tfailure = metadata.FailureFail\n\t}\n\n\treturn &backend_types.Step{\n\t\tName:           container.Name,\n\t\tUUID:           uuid.String(),\n\t\tType:           stepType,\n\t\tImage:          container.Image,\n\t\tPull:           container.Pull,\n\t\tDetached:       detached,\n\t\tPrivileged:     privileged,\n\t\tWorkingDir:     workingDir,\n\t\tEnvironment:    environment,\n\t\tCommands:       container.Commands,\n\t\tEntrypoint:     container.Entrypoint,\n\t\tExtraHosts:     extraHosts,\n\t\tVolumes:        volumes,\n\t\tTmpfs:          container.Tmpfs,\n\t\tDevices:        container.Devices,\n\t\tNetworks:       networks,\n\t\tDNS:            container.DNS,\n\t\tDNSSearch:      container.DNSSearch,\n\t\tMemSwapLimit:   memSwapLimit,\n\t\tMemLimit:       memLimit,\n\t\tShmSize:        shmSize,\n\t\tCPUQuota:       cpuQuota,\n\t\tCPUShares:      cpuShares,\n\t\tCPUSet:         cpuSet,\n\t\tAuthConfig:     authConfig,\n\t\tOnSuccess:      onSuccess,\n\t\tOnFailure:      onFailure,\n\t\tFailure:        failure,\n\t\tNetworkMode:    networkMode,\n\t\tPorts:          ports,\n\t\tBackendOptions: container.BackendOptions,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (sys *IAMSys) CreateUser(ctx context.Context, accessKey string, uinfo madmin.UserInfo) error {\n\tif !sys.Initialized() {\n\t\treturn errServerNotInitialized\n\t}\n\n\tif sys.usersSysType != MinIOUsersSysType {\n\t\treturn errIAMActionNotAllowed\n\t}\n\n\tif !auth.IsAccessKeyValid(accessKey) {\n\t\treturn auth.ErrInvalidAccessKeyLength\n\t}\n\n\tif !auth.IsSecretKeyValid(uinfo.SecretKey) {\n\t\treturn auth.ErrInvalidSecretKeyLength\n\t}\n\n\terr := sys.store.AddUser(ctx, accessKey, uinfo)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsys.notifyForUser(ctx, accessKey, false)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *HomeInterfaceSuite) TestConnectedPlugAppArmorWithoutAttrib(c *C) {\n\tapparmorSpec := apparmor.NewSpecification(interfaces.NewSnapAppSet(s.plug.Snap()))\n\terr := apparmorSpec.AddConnectedPlug(s.iface, s.plug, s.slot)\n\tc.Assert(err, IsNil)\n\tc.Assert(apparmorSpec.SecurityTags(), DeepEquals, []string{\"snap.other.app\"})\n\tc.Check(apparmorSpec.SnippetForTag(\"snap.other.app\"), testutil.Contains, `owner @{HOME}/ r,`)\n\tc.Check(apparmorSpec.SnippetForTag(\"snap.other.app\"), testutil.Contains, `audit deny @{HOME}/bin/{,**} wl,`)\n\tc.Check(apparmorSpec.SnippetForTag(\"snap.other.app\"), testutil.Contains, `audit deny @{HOME}/bin wl,`)\n\tc.Check(apparmorSpec.SnippetForTag(\"snap.other.app\"), Not(testutil.Contains), `# Allow non-owner read`)\n}", "is_vulnerable": 0}
{"code": "func toContainer(hostID int, idMap []IDMap) (int, error) {\n\tif idMap == nil {\n\t\treturn hostID, nil\n\t}\n\tfor _, m := range idMap {\n\t\tif (hostID >= m.HostID) && (hostID <= (m.HostID + m.Size - 1)) {\n\t\t\tcontID := m.ContainerID + (hostID - m.HostID)\n\t\t\treturn contID, nil\n\t\t}\n\t}\n\treturn -1, fmt.Errorf(\"Host ID %d cannot be mapped to a container ID\", hostID)\n}", "is_vulnerable": 1}
{"code": "func (r *taskResolver) Badges(ctx context.Context, obj *db.Task) (*TaskBadges, error) {\n\tchecklists, err := r.Repository.GetTaskChecklistsForTask(ctx, obj.TaskID)\n\tif err != nil {\n\t\treturn &TaskBadges{}, err\n\t}\n\tif len(checklists) == 0 {\n\t\treturn &TaskBadges{Checklist: nil}, err\n\t}\n\tcomplete := 0\n\ttotal := 0\n\tfor _, checklist := range checklists {\n\t\titems, err := r.Repository.GetTaskChecklistItemsForTaskChecklist(ctx, checklist.TaskChecklistID)\n\t\tif err != nil {\n\t\t\treturn &TaskBadges{}, err\n\t\t}\n\t\tfor _, item := range items {\n\t\t\ttotal += 1\n\t\t\tif item.Complete {\n\t\t\t\tcomplete += 1\n\t\t\t}\n\t\t}\n\t}\n\tif complete == 0 && total == 0 {\n\t\treturn &TaskBadges{Checklist: nil}, nil\n\t}\n\treturn &TaskBadges{Checklist: &ChecklistBadge{Total: total, Complete: complete}}, nil\n}", "is_vulnerable": 1}
{"code": "func (api *PublicEthereumAPI) generateFromArgs(args rpctypes.SendTxArgs) (*evmtypes.MsgEthereumTx, error) {\n\tvar (\n\t\tnonce, gasLimit uint64\n\t\terr             error\n\t)\n\n\tamount := (*big.Int)(args.Value)\n\tgasPrice := (*big.Int)(args.GasPrice)\n\n\tif args.GasPrice == nil {\n\t\t// Set default gas price\n\t\t// TODO: Change to min gas price from context once available through server/daemon\n\t\tgasPrice = big.NewInt(ethermint.DefaultGasPrice)\n\t}\n\n\t// get the nonce from the account retriever and the pending transactions\n\tnonce, err = api.accountNonce(api.clientCtx, args.From, true)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif args.Nonce != nil {\n\t\tif nonce != (uint64)(*args.Nonce) {\n\t\t\treturn nil, fmt.Errorf(fmt.Sprintf(\"invalid nonce; got %d, expected %d\", (uint64)(*args.Nonce), nonce))\n\t\t}\n\t}\n\n\tif args.Data != nil && args.Input != nil && !bytes.Equal(*args.Data, *args.Input) {\n\t\treturn nil, errors.New(\"both 'data' and 'input' are set and not equal. Please use 'input' to pass transaction call data\")\n\t}\n\n\t// Sets input to either Input or Data, if both are set and not equal error above returns\n\tvar input []byte\n\tif args.Input != nil {\n\t\tinput = *args.Input\n\t} else if args.Data != nil {\n\t\tinput = *args.Data\n\t}\n\n\tif args.To == nil && len(input) == 0 {\n\t\t// Contract creation\n\t\treturn nil, fmt.Errorf(\"contract creation without any data provided\")\n\t}\n\n\tif args.Gas == nil {\n\t\tcallArgs := rpctypes.CallArgs{\n\t\t\tFrom:     &args.From,\n\t\t\tTo:       args.To,\n\t\t\tGas:      args.Gas,\n\t\t\tGasPrice: args.GasPrice,\n\t\t\tValue:    args.Value,\n\t\t\tData:     args.Data,\n\t\t}\n\t\tgl, err := api.EstimateGas(callArgs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tgasLimit = uint64(gl)\n\t} else {\n\t\tgasLimit = (uint64)(*args.Gas)\n\t}\n\tmsg := evmtypes.NewMsgEthereumTx(nonce, args.To, amount, gasLimit, gasPrice, input)\n\n\treturn &msg, nil\n}", "is_vulnerable": 0}
{"code": "func TestSimTPM20QuoteAndVerify(t *testing.T) {\n\tsim, tpm := setupSimulatedTPM(t)\n\tdefer sim.Close()\n\n\tak, err := tpm.NewAK(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"NewAK() failed: %v\", err)\n\t}\n\tdefer ak.Close(tpm)\n\n\tnonce := []byte{1, 2, 3, 4, 5, 6, 7, 8}\n\tquote, err := ak.Quote(tpm, nonce, HashSHA256)\n\tif err != nil {\n\t\tt.Fatalf(\"ak.Quote() failed: %v\", err)\n\t}\n\n\t// Providing both PCR banks to AKPublic.Verify() ensures we can handle\n\t// the case where extra PCRs of a different digest algorithm are provided.\n\tvar pcrs []PCR\n\tfor _, alg := range []HashAlg{HashSHA256, HashSHA1} {\n\t\tp, err := tpm.PCRs(alg)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"tpm.PCRs(%v) failed: %v\", alg, err)\n\t\t}\n\t\tpcrs = append(pcrs, p...)\n\t}\n\n\tpub, err := ParseAKPublic(tpm.Version(), ak.AttestationParameters().Public)\n\tif err != nil {\n\t\tt.Fatalf(\"ParseAKPublic() failed: %v\", err)\n\t}\n\tif err := pub.Verify(*quote, pcrs, nonce); err != nil {\n\t\tt.Errorf(\"quote verification failed: %v\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestIterativeRandomDelayedSync(t *testing.T) {\n\t// Create a random trie to copy\n\tsrcDb, srcTrie, srcData := makeTestTrie()\n\n\t// Create a destination trie and sync with the scheduler\n\tdiskdb := memorydb.New()\n\ttriedb := NewDatabase(diskdb)\n\tsched := NewSync(srcTrie.Hash(), diskdb, nil, NewSyncBloom(1, diskdb))\n\n\tqueue := make(map[common.Hash]struct{})\n\tfor _, hash := range sched.Missing(10000) {\n\t\tqueue[hash] = struct{}{}\n\t}\n\tfor len(queue) > 0 {\n\t\t// Sync only half of the scheduled nodes, even those in random order\n\t\tresults := make([]SyncResult, 0, len(queue)/2+1)\n\t\tfor hash := range queue {\n\t\t\tdata, err := srcDb.Node(hash)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to retrieve node data for %x: %v\", hash, err)\n\t\t\t}\n\t\t\tresults = append(results, SyncResult{hash, data})\n\n\t\t\tif len(results) >= cap(results) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// Feed the retrieved results back and queue new tasks\n\t\tfor _, result := range results {\n\t\t\tif err := sched.Process(result); err != nil {\n\t\t\t\tt.Fatalf(\"failed to process result %v\", err)\n\t\t\t}\n\t\t}\n\t\tbatch := diskdb.NewBatch()\n\t\tif err := sched.Commit(batch); err != nil {\n\t\t\tt.Fatalf(\"failed to commit data: %v\", err)\n\t\t}\n\t\tbatch.Write()\n\t\tfor _, result := range results {\n\t\t\tdelete(queue, result.Hash)\n\t\t}\n\t\tfor _, hash := range sched.Missing(10000) {\n\t\t\tqueue[hash] = struct{}{}\n\t\t}\n\t}\n\t// Cross check that the two tries are in sync\n\tcheckTrieContents(t, triedb, srcTrie.Hash().Bytes(), srcData)\n}", "is_vulnerable": 0}
{"code": "func makeRBACRules(intentions structs.Intentions, intentionDefaultAllow bool, isHTTP bool) (*envoyrbac.RBAC, error) {\n\t// Note that we DON'T explicitly validate the trust-domain matches ours.\n\t//\n\t// For now we don't validate the trust domain of the _destination_ at all.\n\t// The RBAC policies below ignore the trust domain and it's implicit that\n\t// the request is for the correct cluster. We might want to reconsider this\n\t// later but plumbing in additional machinery to check the clusterID here\n\t// is not really necessary for now unless the Envoys are badly configured.\n\t// Our threat model _requires_ correctly configured and well behaved\n\t// proxies given that they have ACLs to fetch certs and so can do whatever\n\t// they want including not authorizing traffic at all or routing it do a\n\t// different service than they auth'd against.\n\n\t// TODO(banks,rb): Implement revocation list checking?\n\n\t// First build up just the basic principal matches.\n\trbacIxns := intentionListToIntermediateRBACForm(intentions, isHTTP)\n\n\t// Normalize: if we are in default-deny then all intentions must be allows and vice versa\n\tintentionDefaultAction := intentionActionFromBool(intentionDefaultAllow)\n\n\tvar rbacAction envoyrbac.RBAC_Action\n\tif intentionDefaultAllow {\n\t\t// The RBAC policies deny access to principals. The rest is allowed.\n\t\t// This is block-list style access control.\n\t\trbacAction = envoyrbac.RBAC_DENY\n\t} else {\n\t\t// The RBAC policies grant access to principals. The rest is denied.\n\t\t// This is safe-list style access control. This is the default type.\n\t\trbacAction = envoyrbac.RBAC_ALLOW\n\t}\n\n\t// Remove source and permissions precedence.\n\trbacIxns = removeIntentionPrecedence(rbacIxns, intentionDefaultAction)\n\n\t// For L4: we should generate one big Policy listing all Principals\n\t// For L7: we should generate one Policy per Principal and list all of the Permissions\n\trbac := &envoyrbac.RBAC{\n\t\tAction:   rbacAction,\n\t\tPolicies: make(map[string]*envoyrbac.Policy),\n\t}\n\n\tvar principalsL4 []*envoyrbac.Principal\n\tfor i, rbacIxn := range rbacIxns {\n\t\tif len(rbacIxn.Permissions) > 0 {\n\t\t\tif !isHTTP {\n\t\t\t\tpanic(\"invalid state: L7 permissions present for TCP service\")\n\t\t\t}\n\t\t\t// For L7: we should generate one Policy per Principal and list all of the Permissions\n\t\t\tpolicy := &envoyrbac.Policy{\n\t\t\t\tPrincipals:  []*envoyrbac.Principal{rbacIxn.ComputedPrincipal},\n\t\t\t\tPermissions: make([]*envoyrbac.Permission, 0, len(rbacIxn.Permissions)),\n\t\t\t}\n\t\t\tfor _, perm := range rbacIxn.Permissions {\n\t\t\t\tpolicy.Permissions = append(policy.Permissions, perm.ComputedPermission)\n\t\t\t}\n\t\t\trbac.Policies[fmt.Sprintf(\"consul-intentions-layer7-%d\", i)] = policy\n\t\t} else {\n\t\t\t// For L4: we should generate one big Policy listing all Principals\n\t\t\tprincipalsL4 = append(principalsL4, rbacIxn.ComputedPrincipal)\n\t\t}\n\t}\n\tif len(principalsL4) > 0 {\n\t\trbac.Policies[\"consul-intentions-layer4\"] = &envoyrbac.Policy{\n\t\t\tPrincipals:  principalsL4,\n\t\t\tPermissions: []*envoyrbac.Permission{anyPermission()},\n\t\t}\n\t}\n\n\tif len(rbac.Policies) == 0 {\n\t\trbac.Policies = nil\n\t}\n\treturn rbac, nil\n}", "is_vulnerable": 1}
{"code": "func newTerminalSession(w http.ResponseWriter, r *http.Request, responseHeader http.Header) (*terminalSession, error) {\n\tconn, err := upgrader.Upgrade(w, r, responseHeader)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsession := &terminalSession{\n\t\twsConn:   conn,\n\t\ttty:      true,\n\t\tsizeChan: make(chan remotecommand.TerminalSize),\n\t\tdoneChan: make(chan struct{}),\n\t}\n\treturn session, nil\n}", "is_vulnerable": 1}
{"code": "func computePodKey(obj *example.Pod) string {\n\treturn fmt.Sprintf(\"/pods/%s/%s\", obj.Namespace, obj.Name)\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerSymlinksOK(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: foo\n`\n\ts.bootstrapEmptyContainer(c)\n\tfn := filepath.Join(s.snapDirPath, \"foo\")\n\tc.Assert(os.WriteFile(fn+\".real\", nil, 0555), IsNil)\n\tc.Assert(os.Symlink(fn+\".real\", fn), IsNil)\n\n\t// snapdir contains a command that's a symlink to a file that's world-rx\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(s.container(), info, discard)\n\tc.Check(err, IsNil)\n}", "is_vulnerable": 0}
{"code": "func (c *EC2) GetSecurityGroupsForVpc(input *GetSecurityGroupsForVpcInput) (*GetSecurityGroupsForVpcOutput, error) {\n\treq, out := c.GetSecurityGroupsForVpcRequest(input)\n\treturn out, req.Send()\n}", "is_vulnerable": 0}
{"code": "func (e *ERC20LogicView) FindBridgeStopped(\n\tal *types.ERC20EventBridgeStopped,\n\tblockNumber,\n\tlogIndex uint64,\n) error {\n\tbf, err := bridgecontract.NewErc20BridgeLogicRestrictedFilterer(\n\t\te.clt.CollateralBridgeAddress(), e.clt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresp := \"ok\"\n\tdefer func() {\n\t\tmetrics.EthCallInc(\"find_bridge_stopped\", resp)\n\t}()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\titer, err := bf.FilterBridgeStopped(\n\t\t&bind.FilterOpts{\n\t\t\tStart:   blockNumber - 1,\n\t\t\tContext: ctx,\n\t\t},\n\t)\n\tif err != nil {\n\t\tresp = getMaybeHTTPStatus(err)\n\t\treturn err\n\t}\n\tdefer iter.Close()\n\n\tvar event *bridgecontract.Erc20BridgeLogicRestrictedBridgeStopped\n\n\tfor iter.Next() {\n\t\tif iter.Event.Raw.BlockNumber == blockNumber &&\n\t\t\tuint64(iter.Event.Raw.Index) == logIndex {\n\t\t\tevent = iter.Event\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif event == nil {\n\t\treturn ErrUnableToFindERC20BridgeStopped\n\t}\n\n\t// now ensure we have enough confirmations\n\tif err := e.ethConfs.Check(event.Raw.BlockNumber); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) ListSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (statereq StateRequest) Validate() error {\n\treturn validation.ValidateStruct(&statereq,\n\t\tvalidation.Field(&statereq.State, validation.Required, validation.By(ValidateEntryState)),\n\t)\n}", "is_vulnerable": 0}
{"code": "func (e *emailRepo) VerifyCode(ctx context.Context, code string) (content string, err error) {\n\tcontent, exist, err := e.data.Cache.GetString(ctx, code)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif !exist {\n\t\treturn \"\", nil\n\t}\n\treturn content, nil\n}", "is_vulnerable": 1}
{"code": "func GetConfigMapFromVolume(selector *v1.ConfigMapKeySelector) (string, error) {\n\tfilePath, err := GetConfigMapVolumePath(selector)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tdata, err := ioutil.ReadFile(filePath)\n\tif err != nil {\n\t\treturn \"\", errors.Wrapf(err, \"failed to get configMap value of name: %s, key: %s\", selector.Name, selector.Key)\n\t}\n\t// Contents edied by tools like \"vim\" always have an extra invisible \"\\n\" in the end,\n\t// and it's often negleted, but it makes differences for some of the applications.\n\treturn strings.TrimSuffix(string(data), \"\\n\"), nil\n}", "is_vulnerable": 1}
{"code": "func (s *StateDB) getDeletedStateObject(addr common.Address) *stateObject {\n\t// Prefer live objects if any is available\n\tif obj := s.stateObjects[addr]; obj != nil {\n\t\treturn obj\n\t}\n\t// If no live objects are available, attempt to use snapshots\n\tvar (\n\t\tdata Account\n\t\terr  error\n\t)\n\tif s.snap != nil {\n\t\tif metrics.EnabledExpensive {\n\t\t\tdefer func(start time.Time) { s.SnapshotAccountReads += time.Since(start) }(time.Now())\n\t\t}\n\t\tvar acc *snapshot.Account\n\t\tif acc, err = s.snap.Account(crypto.Keccak256Hash(addr.Bytes())); err == nil {\n\t\t\tif acc == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tdata.Nonce, data.Balance, data.CodeHash = acc.Nonce, acc.Balance, acc.CodeHash\n\t\t\tif len(data.CodeHash) == 0 {\n\t\t\t\tdata.CodeHash = emptyCodeHash\n\t\t\t}\n\t\t\tdata.Root = common.BytesToHash(acc.Root)\n\t\t\tif data.Root == (common.Hash{}) {\n\t\t\t\tdata.Root = emptyRoot\n\t\t\t}\n\t\t}\n\t}\n\t// If snapshot unavailable or reading from it failed, load from the database\n\tif s.snap == nil || err != nil {\n\t\tif metrics.EnabledExpensive {\n\t\t\tdefer func(start time.Time) { s.AccountReads += time.Since(start) }(time.Now())\n\t\t}\n\t\tenc, err := s.trie.TryGet(addr.Bytes())\n\t\tif err != nil {\n\t\t\ts.setError(fmt.Errorf(\"getDeleteStateObject (%x) error: %v\", addr.Bytes(), err))\n\t\t\treturn nil\n\t\t}\n\t\tif len(enc) == 0 {\n\t\t\treturn nil\n\t\t}\n\t\tif err := rlp.DecodeBytes(enc, &data); err != nil {\n\t\t\tlog.Error(\"Failed to decode state object\", \"addr\", addr, \"err\", err)\n\t\t\treturn nil\n\t\t}\n\t}\n\t// Insert into the live set\n\tobj := newObject(s, addr, data)\n\ts.setStateObject(obj)\n\treturn obj\n}", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateContainerMissingSnapYamlFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\tcontainer := s.container()\n\tc.Assert(os.Chmod(s.snapDirPath, 0755), IsNil)\n\tc.Assert(os.Mkdir(filepath.Join(s.snapDirPath, \"meta\"), 0755), IsNil)\n\n\t// snapdir's / and /meta are 0755 (i.e. OK), but no /meta/snap.yaml\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(container, info, discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n\n\t// component's / and /meta are 0755 (i.e. OK), but no /meta/component.yaml\n\n\terr = snap.ValidateComponentContainer(container, \"empty-snap+comp.comp\", discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n}", "is_vulnerable": 0}
{"code": "func (m *FakeMapEntry) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowMap\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: FakeMapEntry: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: FakeMapEntry: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Key\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMap\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Key = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMap\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Value = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Other\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMap\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Other = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipMap(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthMap\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) HostIOCRm(ctx context.Context, in *clientpb.IOC, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_HostIOCRm_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (f *Filter) Filter(subject any) {\n\tswitch v := subject.(type) {\n\tcase *structs.CheckServiceNodes:\n\t\tf.filterCheckServiceNodes(v)\n\n\tcase *structs.IndexedCheckServiceNodes:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterCheckServiceNodes(&v.Nodes)\n\n\tcase *structs.PreparedQueryExecuteResponse:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterCheckServiceNodes(&v.Nodes)\n\n\tcase *structs.IndexedServiceTopology:\n\t\tfiltered := f.filterServiceTopology(v.ServiceTopology)\n\t\tif filtered {\n\t\t\tv.FilteredByACLs = true\n\t\t\tv.QueryMeta.ResultsFilteredByACLs = true\n\t\t}\n\n\tcase *structs.DatacenterIndexedCheckServiceNodes:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterDatacenterCheckServiceNodes(&v.DatacenterNodes)\n\n\tcase *structs.IndexedCoordinates:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterCoordinates(&v.Coordinates)\n\n\tcase *structs.IndexedHealthChecks:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterHealthChecks(&v.HealthChecks)\n\n\tcase *structs.IndexedIntentions:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterIntentions(&v.Intentions)\n\n\tcase *structs.IndexedNodeDump:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterNodeDump(&v.Dump)\n\n\tcase *structs.IndexedServiceDump:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterServiceDump(&v.Dump)\n\n\tcase *structs.IndexedNodes:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterNodes(&v.Nodes)\n\n\tcase *structs.IndexedNodeServices:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterNodeServices(&v.NodeServices)\n\n\tcase *structs.IndexedNodeServiceList:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterNodeServiceList(&v.NodeServices)\n\n\tcase *structs.IndexedServiceNodes:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterServiceNodes(&v.ServiceNodes)\n\n\tcase *structs.IndexedServices:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterServices(v.Services, &v.EnterpriseMeta)\n\n\tcase *structs.IndexedSessions:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterSessions(&v.Sessions)\n\n\tcase *structs.IndexedPreparedQueries:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterPreparedQueries(&v.Queries)\n\n\tcase **structs.PreparedQuery:\n\t\tf.redactPreparedQueryTokens(v)\n\n\tcase *structs.ACLTokens:\n\t\tf.filterTokens(v)\n\tcase **structs.ACLToken:\n\t\tf.filterToken(v)\n\tcase *[]*structs.ACLTokenListStub:\n\t\tf.filterTokenStubs(v)\n\tcase **structs.ACLTokenListStub:\n\t\tf.filterTokenStub(v)\n\n\tcase *structs.ACLPolicies:\n\t\tf.filterPolicies(v)\n\tcase **structs.ACLPolicy:\n\t\tf.filterPolicy(v)\n\n\tcase *structs.ACLRoles:\n\t\tf.filterRoles(v)\n\tcase **structs.ACLRole:\n\t\tf.filterRole(v)\n\n\tcase *structs.ACLBindingRules:\n\t\tf.filterBindingRules(v)\n\tcase **structs.ACLBindingRule:\n\t\tf.filterBindingRule(v)\n\n\tcase *structs.ACLAuthMethods:\n\t\tf.filterAuthMethods(v)\n\tcase **structs.ACLAuthMethod:\n\t\tf.filterAuthMethod(v)\n\n\tcase *structs.IndexedServiceList:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterServiceList(&v.Services)\n\n\tcase *structs.IndexedExportedServiceList:\n\t\tfor peer, peerServices := range v.Services {\n\t\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterServiceList(&peerServices)\n\t\t\tif len(peerServices) == 0 {\n\t\t\t\tdelete(v.Services, peer)\n\t\t\t} else {\n\t\t\t\tv.Services[peer] = peerServices\n\t\t\t}\n\t\t}\n\n\tcase *structs.IndexedGatewayServices:\n\t\tv.QueryMeta.ResultsFilteredByACLs = f.filterGatewayServices(&v.Services)\n\n\tcase *structs.IndexedNodesWithGateways:\n\t\tif f.filterCheckServiceNodes(&v.Nodes) {\n\t\t\tv.QueryMeta.ResultsFilteredByACLs = true\n\t\t}\n\t\tif f.filterGatewayServices(&v.Gateways) {\n\t\t\tv.QueryMeta.ResultsFilteredByACLs = true\n\t\t}\n\t\tif f.filterCheckServiceNodes(&v.ImportedNodes) {\n\t\t\tv.QueryMeta.ResultsFilteredByACLs = true\n\t\t}\n\n\tdefault:\n\t\tpanic(fmt.Errorf(\"Unhandled type passed to ACL filter: %T %#v\", subject, subject))\n\t}\n}", "is_vulnerable": 1}
{"code": "func (mm *userMetricsMetadata) add(metric string, metadata *cortexpb.MetricMetadata) error {\n\tmm.mtx.Lock()\n\tdefer mm.mtx.Unlock()\n\n\t// As we get the set, we also validate two things:\n\t// 1. The user is allowed to create new metrics to add metadata to.\n\t// 2. If the metadata set is already present, it hasn't reached the limit of metadata we can append.\n\tset, ok := mm.metricToMetadata[metric]\n\tif !ok {\n\t\t// Verify that the user can create more metric metadata given we don't have a set for that metric name.\n\t\tif err := mm.limiter.AssertMaxMetricsWithMetadataPerUser(mm.userID, len(mm.metricToMetadata)); err != nil {\n\t\t\tvalidation.DiscardedMetadata.WithLabelValues(mm.userID, perUserMetadataLimit).Inc()\n\t\t\treturn makeLimitError(perUserMetadataLimit, mm.limiter.FormatError(mm.userID, err))\n\t\t}\n\t\tset = metricMetadataSet{}\n\t\tmm.metricToMetadata[metric] = set\n\t}\n\n\tif err := mm.limiter.AssertMaxMetadataPerMetric(mm.userID, len(set)); err != nil {\n\t\tvalidation.DiscardedMetadata.WithLabelValues(mm.userID, perMetricMetadataLimit).Inc()\n\t\treturn makeLimitError(perMetricMetadataLimit, mm.limiter.FormatError(mm.userID, err))\n\t}\n\n\t// if we have seen this metadata before, it is a no-op and we don't need to change our metrics.\n\t_, ok = set[*metadata]\n\tif !ok {\n\t\tmm.metrics.memMetadata.Inc()\n\t\tmm.metrics.memMetadataCreatedTotal.WithLabelValues(mm.userID).Inc()\n\t}\n\n\tmm.metricToMetadata[metric][*metadata] = time.Now()\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func evaluatePSS(level *api.LevelVersion, pod corev1.Pod) (results []pssutils.PSSCheckResult) {\n\tchecks := policy.DefaultChecks()\n\n\tfor _, check := range checks {\n\t\tif level.Level == api.LevelBaseline && check.Level != level.Level {\n\t\t\tcontinue\n\t\t}\n\t\t// check version\n\t\tappliedOnce := true\n\t\tfor _, versionCheck := range check.Versions {\n\t\t\t// the latest check returned twice, skip duplicate application\n\t\t\tif level.Version == api.LatestVersion() {\n\t\t\t\tif !appliedOnce {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} else if level.Version != api.LatestVersion() && level.Version.Older(versionCheck.MinimumVersion) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcheckResult := versionCheck.CheckPod(&pod.ObjectMeta, &pod.Spec)\n\t\t\t// Append only if the checkResult is not already in pssCheckResult\n\t\t\tif !checkResult.Allowed {\n\t\t\t\tresults = append(results, pssutils.PSSCheckResult{\n\t\t\t\t\tID:               string(check.ID),\n\t\t\t\t\tCheckResult:      checkResult,\n\t\t\t\t\tRestrictedFields: GetRestrictedFields(check),\n\t\t\t\t})\n\t\t\t}\n\t\t\tappliedOnce = false\n\t\t}\n\t}\n\treturn results\n}", "is_vulnerable": 1}
{"code": "func (c *ConfigurationWatcher) preLoadConfiguration(configMsg dynamic.Message) {\n\tcurrentConfigurations := c.currentConfigurations.Get().(dynamic.Configurations)\n\n\tlogger := log.WithoutContext().WithField(log.ProviderName, configMsg.ProviderName)\n\tif log.GetLevel() == logrus.DebugLevel {\n\t\tcopyConf := configMsg.Configuration.DeepCopy()\n\t\tif copyConf.TLS != nil {\n\t\t\tcopyConf.TLS.Certificates = nil\n\n\t\t\tfor _, v := range copyConf.TLS.Stores {\n\t\t\t\tv.DefaultCertificate = nil\n\t\t\t}\n\t\t}\n\n\t\tjsonConf, err := json.Marshal(copyConf)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(\"Could not marshal dynamic configuration: %v\", err)\n\t\t\tlogger.Debugf(\"Configuration received from provider %s: [struct] %#v\", configMsg.ProviderName, copyConf)\n\t\t} else {\n\t\t\tlogger.Debugf(\"Configuration received from provider %s: %s\", configMsg.ProviderName, string(jsonConf))\n\t\t}\n\t}\n\n\tif isEmptyConfiguration(configMsg.Configuration) {\n\t\tlogger.Infof(\"Skipping empty Configuration for provider %s\", configMsg.ProviderName)\n\t\treturn\n\t}\n\n\tif reflect.DeepEqual(currentConfigurations[configMsg.ProviderName], configMsg.Configuration) {\n\t\tlogger.Infof(\"Skipping same configuration for provider %s\", configMsg.ProviderName)\n\t\treturn\n\t}\n\n\tproviderConfigUpdateCh, ok := c.providerConfigUpdateMap[configMsg.ProviderName]\n\tif !ok {\n\t\tproviderConfigUpdateCh = make(chan dynamic.Message)\n\t\tc.providerConfigUpdateMap[configMsg.ProviderName] = providerConfigUpdateCh\n\t\tc.routinesPool.GoCtx(func(ctxPool context.Context) {\n\t\t\tc.throttleProviderConfigReload(ctxPool, c.providersThrottleDuration, c.configurationValidatedChan, providerConfigUpdateCh)\n\t\t})\n\t}\n\n\tproviderConfigUpdateCh <- configMsg\n}", "is_vulnerable": 1}
{"code": "func getCSRF() csrf.CSRF {\n\treturn csrf.NewCookieCSRF(\"csrf\", \"/\", \"\", false, false)\n}", "is_vulnerable": 1}
{"code": "func (m *Field) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowType\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Field: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Field: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Kind\", wireType)\n\t\t\t}\n\t\t\tm.Kind = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Kind |= Field_Kind(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Cardinality\", wireType)\n\t\t\t}\n\t\t\tm.Cardinality = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Cardinality |= Field_Cardinality(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Number\", wireType)\n\t\t\t}\n\t\t\tm.Number = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Number |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field TypeUrl\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.TypeUrl = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field OneofIndex\", wireType)\n\t\t\t}\n\t\t\tm.OneofIndex = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.OneofIndex |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Packed\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Packed = bool(v != 0)\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Options\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Options = append(m.Options, &Option{})\n\t\t\tif err := m.Options[len(m.Options)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field JsonName\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.JsonName = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field DefaultValue\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.DefaultValue = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipType(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestRequest(t *testing.T) {\n\tresp, err := DefaultClient.Get(\"http://www.example.org\")\n\tif err != nil && resp.StatusCode == 200 {\n\t\tt.Error(\"The request with an ordinal url should be successful\")\n\t}\n\n\tresp, err = DefaultClient.Get(\"http://localhost\")\n\tif err == nil {\n\t\tt.Errorf(\"The request for localhost should be fail\")\n\t}\n\n\tif _, err := DefaultClient.Get(\"http://192.168.0.1\"); err == nil {\n\t\tt.Errorf(\"The request for localhost should be fail\")\n\t}\n\n\tif _, err := DefaultClient.Get(\"http://[::]\"); err == nil {\n\t\tt.Errorf(\"The request for IPv6 unspecified address should be fail\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func yaml_parser_fetch_stream_start(parser *yaml_parser_t) bool {\n\n\t// Set the initial indentation.\n\tparser.indent = -1\n\n\t// Initialize the simple key stack.\n\tparser.simple_keys = append(parser.simple_keys, yaml_simple_key_t{})\n\n\tparser.simple_keys_by_tok = make(map[int]int)\n\n\t// A simple key is allowed at the beginning of the stream.\n\tparser.simple_key_allowed = true\n\n\t// We have started.\n\tparser.stream_start_produced = true\n\n\t// Create the STREAM-START token and append it to the queue.\n\ttoken := yaml_token_t{\n\t\ttyp:        yaml_STREAM_START_TOKEN,\n\t\tstart_mark: parser.mark,\n\t\tend_mark:   parser.mark,\n\t\tencoding:   parser.encoding,\n\t}\n\tyaml_insert_token(parser, -1, &token)\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (spt *ServicePrincipalToken) UnmarshalJSON(data []byte) error {\n\t// need to determine the token type\n\traw := map[string]interface{}{}\n\terr := json.Unmarshal(data, &raw)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsecret := raw[\"secret\"].(map[string]interface{})\n\tswitch secret[\"type\"] {\n\tcase \"ServicePrincipalNoSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalNoSecret{}\n\tcase \"ServicePrincipalTokenSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalTokenSecret{}\n\tcase \"ServicePrincipalCertificateSecret\":\n\t\treturn errors.New(\"unmarshalling ServicePrincipalCertificateSecret is not supported\")\n\tcase \"ServicePrincipalMSISecret\":\n\t\treturn errors.New(\"unmarshalling ServicePrincipalMSISecret is not supported\")\n\tcase \"ServicePrincipalUsernamePasswordSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalUsernamePasswordSecret{}\n\tcase \"ServicePrincipalAuthorizationCodeSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalAuthorizationCodeSecret{}\n\tdefault:\n\t\treturn fmt.Errorf(\"unrecognized token type '%s'\", secret[\"type\"])\n\t}\n\terr = json.Unmarshal(data, &spt.inner)\n\tif err != nil {\n\t\treturn err\n\t}\n\tspt.refreshLock = &sync.RWMutex{}\n\tspt.sender = &http.Client{}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (lr ListResult) listResultPreparer(ctx context.Context) (*http.Request, error) {\n\tif lr.NextLink == nil || len(to.String(lr.NextLink)) < 1 {\n\t\treturn nil, nil\n\t}\n\treturn autorest.Prepare((&http.Request{}).WithContext(ctx),\n\t\tautorest.AsJSON(),\n\t\tautorest.AsGet(),\n\t\tautorest.WithBaseURL(to.String(lr.NextLink)))\n}", "is_vulnerable": 0}
{"code": "func (src *PortalSuspended) Encode(dst []byte) ([]byte, error) {\n\treturn append(dst, 's', 0, 0, 0, 4), nil\n}", "is_vulnerable": 0}
{"code": "func (store *Storage) AuthPlain(username, password string) error {\n\t// TODO: Pass session context there.\n\tdefer trace.StartRegion(context.Background(), \"sql/AuthPlain\").End()\n\n\taccountName, err := prepareUsername(username)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tpassword, err = precis.OpaqueString.CompareKey(password)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// TODO: Make go-imap-sql CheckPlain return an actual error.\n\tif !store.Back.CheckPlain(accountName, password) {\n\t\treturn module.ErrUnknownCredentials\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (r *Reconciler) reconcile(ctx context.Context, spcps *v1alpha1.SecretProviderClassPodStatus) (err error) {\n\tbegin := time.Now()\n\terrorReason := internalerrors.FailedToRotate\n\t// requiresUpdate is set to true when the new object versions differ from the current object versions\n\t// after the provider mount request is complete\n\tvar requiresUpdate bool\n\tvar providerName string\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tr.reporter.reportRotationErrorCtMetric(providerName, errorReason, requiresUpdate)\n\t\t\treturn\n\t\t}\n\t\tr.reporter.reportRotationCtMetric(providerName, requiresUpdate)\n\t\tr.reporter.reportRotationDuration(time.Since(begin).Seconds())\n\t}()\n\n\tspcName, spcNamespace := spcps.Status.SecretProviderClassName, spcps.Namespace\n\n\t// get the secret provider class the pod status is referencing from informer cache\n\tspc, err := r.store.GetSecretProviderClass(spcName, spcNamespace)\n\tif err != nil {\n\t\terrorReason = internalerrors.SecretProviderClassNotFound\n\t\treturn fmt.Errorf(\"failed to get secret provider class %s/%s, err: %+v\", spcNamespace, spcName, err)\n\t}\n\t// get pod from informer cache\n\tpodName, podNamespace := spcps.Status.PodName, spcps.Namespace\n\tpod, err := r.store.GetPod(podName, podNamespace)\n\tif err != nil {\n\t\terrorReason = internalerrors.PodNotFound\n\t\treturn fmt.Errorf(\"failed to get pod %s/%s, err: %+v\", podNamespace, podName, err)\n\t}\n\n\t// determine which pod volume this is associated with\n\tpodVol := k8sutil.SPCVolume(pod, spc.Name)\n\tif podVol == nil {\n\t\terrorReason = internalerrors.PodVolumeNotFound\n\t\treturn fmt.Errorf(\"could not find secret provider class pod status volume for pod %s/%s\", podNamespace, podName)\n\t}\n\n\t// validate TargetPath\n\tif fileutil.GetPodUIDFromTargetPath(spcps.Status.TargetPath) != string(pod.UID) {\n\t\terrorReason = internalerrors.UnexpectedTargetPath\n\t\treturn fmt.Errorf(\"secret provider class pod status targetPath did not match pod UID for pod %s/%s\", podNamespace, podName)\n\t}\n\tif fileutil.GetVolumeNameFromTargetPath(spcps.Status.TargetPath) != podVol.Name {\n\t\terrorReason = internalerrors.UnexpectedTargetPath\n\t\treturn fmt.Errorf(\"secret provider class pod status volume name did not match pod Volume for pod %s/%s\", podNamespace, podName)\n\t}\n\n\tparameters := make(map[string]string)\n\tif spc.Spec.Parameters != nil {\n\t\tparameters = spc.Spec.Parameters\n\t}\n\t// Set these parameters to mimic the exact same attributes we get as part of NodePublishVolumeRequest\n\tparameters[csipodname] = podName\n\tparameters[csipodnamespace] = podNamespace\n\tparameters[csipoduid] = string(pod.UID)\n\tparameters[csipodsa] = pod.Spec.ServiceAccountName\n\n\tparamsJSON, err := json.Marshal(parameters)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal parameters, err: %+v\", err)\n\t}\n\tpermissionJSON, err := json.Marshal(permission)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal permission, err: %+v\", err)\n\t}\n\n\t// check if the volume pertaining to the current spc is using nodePublishSecretRef for\n\t// accessing external secrets store\n\tnodePublishSecretRef := podVol.CSI.NodePublishSecretRef\n\n\tvar secretsJSON []byte\n\tnodePublishSecretData := make(map[string]string)\n\t// read the Kubernetes secret referenced in NodePublishSecretRef and marshal it\n\t// This comprises the secret parameter in the MountRequest to the provider\n\tif nodePublishSecretRef != nil {\n\t\tsecretName := strings.TrimSpace(nodePublishSecretRef.Name)\n\t\tsecretNamespace := spcps.Namespace\n\n\t\t// read secret from the informer cache\n\t\tsecret, err := r.store.GetSecret(secretName, secretNamespace)\n\t\tif err != nil {\n\t\t\terrorReason = internalerrors.NodePublishSecretRefNotFound\n\t\t\tr.generateEvent(pod, v1.EventTypeWarning, mountRotationFailedReason, fmt.Sprintf(\"failed to get node publish secret %s/%s, err: %+v\", secretNamespace, secretName, err))\n\t\t\treturn fmt.Errorf(\"failed to get node publish secret %s/%s, err: %+v\", secretNamespace, secretName, err)\n\t\t}\n\n\t\tfor k, v := range secret.Data {\n\t\t\tnodePublishSecretData[k] = string(v)\n\t\t}\n\t}\n\n\tsecretsJSON, err = json.Marshal(nodePublishSecretData)\n\tif err != nil {\n\t\tr.generateEvent(pod, v1.EventTypeWarning, mountRotationFailedReason, fmt.Sprintf(\"failed to marshal node publish secret data, err: %+v\", err))\n\t\treturn fmt.Errorf(\"failed to marshal node publish secret data, err: %+v\", err)\n\t}\n\n\t// generate a map with the current object versions stored in spc pod status\n\t// the old object versions are passed on to the provider as part of the MountRequest.\n\t// the provider can use these current object versions to decide if any action is required\n\t// and if the objects need to be rotated\n\toldObjectVersions := make(map[string]string)\n\tfor _, obj := range spcps.Status.Objects {\n\t\toldObjectVersions[obj.ID] = obj.Version\n\t}\n\n\tproviderName = string(spc.Spec.Provider)\n\tproviderClient, err := r.getProviderClient(providerName)\n\tif err != nil {\n\t\terrorReason = internalerrors.FailedToCreateProviderGRPCClient\n\t\tr.generateEvent(pod, v1.EventTypeWarning, mountRotationFailedReason, fmt.Sprintf(\"failed to create provider client, err: %+v\", err))\n\t\treturn fmt.Errorf(\"failed to create provider client, err: %+v\", err)\n\t}\n\tnewObjectVersions, errorReason, err := providerClient.MountContent(ctx, string(paramsJSON), string(secretsJSON), spcps.Status.TargetPath, string(permissionJSON), oldObjectVersions)\n\tif err != nil {\n\t\tr.generateEvent(pod, v1.EventTypeWarning, mountRotationFailedReason, fmt.Sprintf(\"provider mount err: %+v\", err))\n\t\treturn fmt.Errorf(\"failed to rotate objects for pod %s/%s, err: %+v\", spcps.Namespace, spcps.Status.PodName, err)\n\t}\n\n\t// compare the old object versions and new object versions to check if any of the objects\n\t// have been updated by the provider\n\tfor k, v := range newObjectVersions {\n\t\tversion, ok := oldObjectVersions[strings.TrimSpace(k)]\n\t\tif ok && strings.TrimSpace(version) == strings.TrimSpace(v) {\n\t\t\tcontinue\n\t\t}\n\t\trequiresUpdate = true\n\t\tbreak\n\t}\n\t// if the spc was updated after initial deployment to remove an existing object, then we\n\t// need to update the objects list with the current list to reflect only what's in the pod\n\tif len(oldObjectVersions) != len(newObjectVersions) {\n\t\trequiresUpdate = true\n\t}\n\n\tvar errs []error\n\t// this loop is executed if there is a difference in the current versions cached in\n\t// the secret provider class pod status and the new versions returned by the provider.\n\t// the diff in versions is populated in the secret provider class pod status and if the\n\t// secret provider class contains secret objects, then the corresponding kubernetes secrets\n\t// data is updated with the latest versions\n\tif requiresUpdate {\n\t\t// generate an event for successful mount update\n\t\tr.generateEvent(pod, v1.EventTypeNormal, mountRotationCompleteReason, fmt.Sprintf(\"successfully rotated mounted contents for spc %s/%s\", spcNamespace, spcName))\n\t\tlog.Infof(\"updating versions in secret provider class pod status %s/%s\", spcps.Namespace, spcps.Name)\n\n\t\tvar ov []v1alpha1.SecretProviderClassObject\n\t\tfor k, v := range newObjectVersions {\n\t\t\tov = append(ov, v1alpha1.SecretProviderClassObject{ID: strings.TrimSpace(k), Version: strings.TrimSpace(v)})\n\t\t}\n\t\tspcps.Status.Objects = ov\n\n\t\tupdateFn := func() (bool, error) {\n\t\t\terr = r.updateSecretProviderClassPodStatus(ctx, spcps)\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"failed to update latest versions in spc pod status, err: %+v\", err)\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t\treturn true, nil\n\t\t}\n\n\t\tif err := wait.ExponentialBackoff(wait.Backoff{\n\t\t\tSteps:    5,\n\t\t\tDuration: 1 * time.Millisecond,\n\t\t\tFactor:   1.0,\n\t\t\tJitter:   0.1,\n\t\t}, updateFn); err != nil {\n\t\t\tr.generateEvent(pod, v1.EventTypeWarning, mountRotationFailedReason, fmt.Sprintf(\"failed to update versions in spc pod status %s, err: %+v\", spcName, err))\n\t\t\treturn fmt.Errorf(\"failed to update spc pod status, err: %+v\", err)\n\t\t}\n\t}\n\n\tif len(spc.Spec.SecretObjects) == 0 {\n\t\tlog.Debugf(\"spc %s/%s doesn't contain secret objects for pod %s/%s\", spcNamespace, spcName, podNamespace, podName)\n\t\treturn nil\n\t}\n\tfiles, err := fileutil.GetMountedFiles(spcps.Status.TargetPath)\n\tif err != nil {\n\t\tr.generateEvent(pod, v1.EventTypeWarning, k8sSecretRotationFailedReason, fmt.Sprintf(\"failed to get mounted files, err: %+v\", err))\n\t\treturn fmt.Errorf(\"failed to get mounted files, err: %+v\", err)\n\t}\n\tfor _, secretObj := range spc.Spec.SecretObjects {\n\t\tsecretName := strings.TrimSpace(secretObj.SecretName)\n\n\t\tif err = secretutil.ValidateSecretObject(*secretObj); err != nil {\n\t\t\tr.generateEvent(pod, v1.EventTypeWarning, k8sSecretRotationFailedReason, fmt.Sprintf(\"failed validation for secret object in spc %s/%s, err: %+v\", spcNamespace, spcName, err))\n\t\t\tlog.Errorf(\"failed validation for secret object in spc %s/%s, err: %+v\", spcNamespace, spcName, err)\n\t\t\terrs = append(errs, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tsecretType := secretutil.GetSecretType(strings.TrimSpace(secretObj.Type))\n\t\tvar datamap map[string][]byte\n\t\tif datamap, err = secretutil.GetSecretData(secretObj.Data, secretType, files); err != nil {\n\t\t\tr.generateEvent(pod, v1.EventTypeWarning, k8sSecretRotationFailedReason, fmt.Sprintf(\"failed to get data in spc %s/%s for secret %s, err: %+v\", spcNamespace, spcName, secretName, err))\n\t\t\tlog.Errorf(\"failed to get data in spc %s/%s for secret %s, err: %+v\", spcNamespace, spcName, secretName, err)\n\t\t\terrs = append(errs, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tpatchFn := func() (bool, error) {\n\t\t\t// patch secret data with the new contents\n\t\t\tif err := r.patchSecret(ctx, secretObj.SecretName, spcps.Namespace, datamap); err != nil {\n\t\t\t\tlog.Errorf(\"failed to patch secret %s/%s, err: %+v\", spcps.Namespace, secretName, err)\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t\treturn true, nil\n\t\t}\n\n\t\tif err := wait.ExponentialBackoff(wait.Backoff{\n\t\t\tSteps:    5,\n\t\t\tDuration: 1 * time.Millisecond,\n\t\t\tFactor:   1.0,\n\t\t\tJitter:   0.1,\n\t\t}, patchFn); err != nil {\n\t\t\tr.generateEvent(pod, v1.EventTypeWarning, k8sSecretRotationFailedReason, fmt.Sprintf(\"failed to patch secret %s with new data, err: %+v\", secretName, err))\n\t\t\t// continue to ensure error in a single secret doesn't block the updates\n\t\t\t// for all other secret objects defined in SPC\n\t\t\tcontinue\n\t\t}\n\t\tr.generateEvent(pod, v1.EventTypeNormal, k8sSecretRotationCompleteReason, fmt.Sprintf(\"successfully rotated K8s secret %s\", secretName))\n\t}\n\n\t// for errors with individual secret objects in spc, we continue to the next secret object\n\t// to prevent error with one secret from affecting rotation of all other k8s secret\n\t// this consolidation of errors within the loop determines if the spc pod status still needs\n\t// to be retried at the end of this rotation reconcile loop\n\tif len(errs) > 0 {\n\t\treturn fmt.Errorf(\"failed to rotate one or more k8s secrets, err: %+v\", errs)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\terr = filepath.Walk(\"testdata/fakesource\", func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif info.IsDir() {\n\t\t\treturn nil\n\t\t}\n\t\tdstBase := filepath.Base(path)\n\t\treturn fsCopyFile(path, filepath.Join(gitRoot, dstBase))\n\t})", "is_vulnerable": 0}
{"code": "func downloadToFileWithPostProcess(client *http.Client, url, file string, postProcess postProcessFunc) error {\n\tresp, err := client.Get(url)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn fmt.Errorf(\"bad status: %s\", resp.Status)\n\t}\n\n\tb, err := safeio.ReadAllLimit(resp.Body, safeio.MB)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tb, err = postProcess(b)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn os.WriteFile(file, b, 0644)\n}", "is_vulnerable": 0}
{"code": "\tsort.Slice(tags, func(i, j int) bool {\n\t\treturn tags[i] < tags[j]\n\t})", "is_vulnerable": 0}
{"code": "func (sc sslCipher) GetDocumentation() parser.AnnotationFields {\n\treturn sc.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func (batch *syncMemBatch) hasCode(hash common.Hash) bool {\n\t_, ok := batch.codes[hash]\n\treturn ok\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) GetSessions(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Sessions, error) {\n\tout := new(clientpb.Sessions)\n\terr := c.cc.Invoke(ctx, SliverRPC_GetSessions_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (client DeploymentsClient) CancelSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (router *Router) parseAndValidateBitbucketServerRequest(writer http.ResponseWriter, request *http.Request) ([]byte, error) {\n\trequest.Body = http.MaxBytesReader(writer, request.Body, 65536)\n\tbody, err := io.ReadAll(request.Body)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to parse request body\")\n\t}\n\n\tif len(router.hookSecret) != 0 {\n\t\tsignature := request.Header.Get(\"X-Hub-Signature\")\n\t\tif len(signature) == 0 {\n\t\t\treturn nil, errors.New(\"missing signature header\")\n\t\t}\n\n\t\tmac := hmac.New(sha256.New, []byte(router.hookSecret))\n\t\t_, _ = mac.Write(body)\n\t\texpectedMAC := hex.EncodeToString(mac.Sum(nil))\n\n\t\tif !hmac.Equal([]byte(signature[7:]), []byte(expectedMAC)) {\n\t\t\treturn nil, errors.New(\"hmac verification failed\")\n\t\t}\n\t}\n\n\treturn body, nil\n}", "is_vulnerable": 0}
{"code": "func (m *Option) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowType\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Option: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Option: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Value == nil {\n\t\t\t\tm.Value = &Any{}\n\t\t\t}\n\t\t\tif err := m.Value.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipType(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func emptyContainer(c *C) *snapdir.SnapDir {\n\td := c.MkDir()\n\tc.Assert(os.Chmod(d, 0755), IsNil)\n\tc.Assert(os.Mkdir(filepath.Join(d, \"meta\"), 0755), IsNil)\n\tc.Assert(os.WriteFile(filepath.Join(d, \"meta\", \"snap.yaml\"), nil, 0444), IsNil)\n\treturn snapdir.New(d)\n}", "is_vulnerable": 1}
{"code": "\t\tDone: func() []Msg {\n\t\t\tmutex.Lock()\n\t\t\tdefer mutex.Unlock()\n\n\t\t\tfinalizeLog()\n\t\t\tsort.Stable(msgs)\n\t\t\treturn msgs\n\t\t},\n\t}", "is_vulnerable": 1}
{"code": "func FsGet(c *gin.Context) {\n\tvar req FsGetReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\treq.Path = stdpath.Join(user.BasePath, req.Path)\n\tmeta, err := db.GetNearestMeta(req.Path)\n\tif err != nil {\n\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\tcommon.ErrorResp(c, err, 500)\n\t\t\treturn\n\t\t}\n\t}\n\tc.Set(\"meta\", meta)\n\tif !canAccess(user, meta, req.Path, req.Password) {\n\t\tcommon.ErrorStrResp(c, \"password is incorrect\", 403)\n\t\treturn\n\t}\n\tobj, err := fs.Get(c, req.Path)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\tvar rawURL string\n\n\tstorage, err := fs.GetStorage(req.Path)\n\tprovider := \"unknown\"\n\tif err == nil {\n\t\tprovider = storage.Config().Name\n\t}\n\tif !obj.IsDir() {\n\t\tif err != nil {\n\t\t\tcommon.ErrorResp(c, err, 500)\n\t\t\treturn\n\t\t}\n\t\tif storage.Config().MustProxy() || storage.GetStorage().WebProxy {\n\t\t\tif storage.GetStorage().DownProxyUrl != \"\" {\n\t\t\t\trawURL = fmt.Sprintf(\"%s%s?sign=%s\",\n\t\t\t\t\tstrings.Split(storage.GetStorage().DownProxyUrl, \"\\n\")[0],\n\t\t\t\t\tutils.EncodePath(req.Path, true),\n\t\t\t\t\tsign.Sign(req.Path))\n\t\t\t} else {\n\t\t\t\trawURL = fmt.Sprintf(\"%s/p%s?sign=%s\",\n\t\t\t\t\tcommon.GetApiUrl(c.Request),\n\t\t\t\t\tutils.EncodePath(req.Path, true),\n\t\t\t\t\tsign.Sign(req.Path))\n\t\t\t}\n\t\t} else {\n\t\t\t// file have raw url\n\t\t\tif u, ok := obj.(model.URL); ok {\n\t\t\t\trawURL = u.URL()\n\t\t\t} else {\n\t\t\t\t// if storage is not proxy, use raw url by fs.Link\n\t\t\t\tlink, _, err := fs.Link(c, req.Path, model.LinkArgs{IP: c.ClientIP(), Header: c.Request.Header})\n\t\t\t\tif err != nil {\n\t\t\t\t\tcommon.ErrorResp(c, err, 500)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\trawURL = link.URL\n\t\t\t}\n\t\t}\n\t}\n\tvar related []model.Obj\n\tparentPath := stdpath.Dir(req.Path)\n\tsameLevelFiles, err := fs.List(c, parentPath)\n\tif err == nil {\n\t\trelated = filterRelated(sameLevelFiles, obj)\n\t}\n\tparentMeta, _ := db.GetNearestMeta(parentPath)\n\tcommon.SuccessResp(c, FsGetResp{\n\t\tObjResp: ObjResp{\n\t\t\tName:     utils.MappingName(obj.GetName(), conf.FilenameCharMap),\n\t\t\tSize:     obj.GetSize(),\n\t\t\tIsDir:    obj.IsDir(),\n\t\t\tModified: obj.ModTime(),\n\t\t\tSign:     common.Sign(obj, parentPath, isEncrypt(meta, req.Path)),\n\t\t\tType:     utils.GetFileType(obj.GetName()),\n\t\t},\n\t\tRawURL:   rawURL,\n\t\tReadme:   getReadme(meta, req.Path),\n\t\tProvider: provider,\n\t\tRelated:  toObjResp(related, parentPath, isEncrypt(parentMeta, parentPath)),\n\t})\n}", "is_vulnerable": 1}
{"code": "func innerNodes(first, last []byte, includeLeft, includeRight bool, nodes map[string]common.Hash, t *testing.T) (map[string]common.Hash, []byte, []byte) {\n\tvar (\n\t\tleftRoot  []byte\n\t\trightRoot []byte\n\t\tfirstHex  = byteToHex(first)\n\t\tlastHex   = byteToHex(last)\n\t\tinner     = make(map[string]common.Hash)\n\t)\n\tfor path, hash := range nodes {\n\t\tif hash == (common.Hash{}) {\n\t\t\tt.Fatalf(\"Unexpected deletion, %v\", []byte(path))\n\t\t}\n\t\t// Filter out the siblings on the left side or the left boundary nodes.\n\t\tif !includeLeft && (bytes.Compare(firstHex, []byte(path)) > 0 || bytes.HasPrefix(firstHex, []byte(path))) {\n\t\t\tcontinue\n\t\t}\n\t\t// Filter out the siblings on the right side or the right boundary nodes.\n\t\tif !includeRight && (bytes.Compare(lastHex, []byte(path)) < 0 || bytes.HasPrefix(lastHex, []byte(path))) {\n\t\t\tcontinue\n\t\t}\n\t\tinner[path] = hash\n\n\t\t// Track the path of the leftmost sub trie root\n\t\tif leftRoot == nil || bytes.Compare(leftRoot, []byte(path)) > 0 {\n\t\t\tleftRoot = []byte(path)\n\t\t}\n\t\t// Track the path of the rightmost sub trie root\n\t\tif rightRoot == nil ||\n\t\t\t(bytes.Compare(rightRoot, []byte(path)) < 0) ||\n\t\t\t(bytes.Compare(rightRoot, []byte(path)) > 0 && bytes.HasPrefix(rightRoot, []byte(path))) {\n\t\t\trightRoot = []byte(path)\n\t\t}\n\t}\n\treturn inner, leftRoot, rightRoot\n}", "is_vulnerable": 0}
{"code": "func TestStoreGateway_InitialSyncWithWaitRingStability(t *testing.T) {\n\t//parallel testing causes data race\n\tbucketClient, storageDir := cortex_testutil.PrepareFilesystemBucket(t)\n\n\t// This tests uses real TSDB blocks. 24h time range, 2h block range period,\n\t// 2 users = total (24 / 12) * 2 = 24 blocks.\n\tnumUsers := 2\n\tnumBlocks := numUsers * 12\n\tnow := time.Now()\n\tmockTSDB(t, path.Join(storageDir, \"user-1\"), 24, 12, now.Add(-24*time.Hour).Unix()*1000, now.Unix()*1000)\n\tmockTSDB(t, path.Join(storageDir, \"user-2\"), 24, 12, now.Add(-24*time.Hour).Unix()*1000, now.Unix()*1000)\n\n\t// Write the bucket index.\n\tfor _, userID := range []string{\"user-1\", \"user-2\"} {\n\t\tcreateBucketIndex(t, bucketClient, userID)\n\t}\n\n\ttests := map[string]struct {\n\t\tshardingStrategy     string\n\t\ttenantShardSize      float64 // Used only when the sharding strategy is shuffle-sharding.\n\t\treplicationFactor    int\n\t\tnumGateways          int\n\t\texpectedBlocksLoaded int\n\t}{\n\t\t\"default sharding strategy, 1 gateway, RF = 1\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyDefault,\n\t\t\treplicationFactor:    1,\n\t\t\tnumGateways:          1,\n\t\t\texpectedBlocksLoaded: numBlocks,\n\t\t},\n\t\t\"default sharding strategy, 2 gateways, RF = 1\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyDefault,\n\t\t\treplicationFactor:    1,\n\t\t\tnumGateways:          2,\n\t\t\texpectedBlocksLoaded: numBlocks, // blocks are sharded across gateways\n\t\t},\n\t\t\"default sharding strategy, 3 gateways, RF = 2\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyDefault,\n\t\t\treplicationFactor:    2,\n\t\t\tnumGateways:          3,\n\t\t\texpectedBlocksLoaded: 2 * numBlocks, // blocks are replicated 2 times\n\t\t},\n\t\t\"default sharding strategy, 5 gateways, RF = 3\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyDefault,\n\t\t\treplicationFactor:    3,\n\t\t\tnumGateways:          5,\n\t\t\texpectedBlocksLoaded: 3 * numBlocks, // blocks are replicated 3 times\n\t\t},\n\t\t\"shuffle sharding strategy, 1 gateway, RF = 1, SS = 1\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyShuffle,\n\t\t\ttenantShardSize:      1,\n\t\t\treplicationFactor:    1,\n\t\t\tnumGateways:          1,\n\t\t\texpectedBlocksLoaded: numBlocks,\n\t\t},\n\t\t\"shuffle sharding strategy, 5 gateways, RF = 2, SS = 3\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyShuffle,\n\t\t\ttenantShardSize:      3,\n\t\t\treplicationFactor:    2,\n\t\t\tnumGateways:          5,\n\t\t\texpectedBlocksLoaded: 2 * numBlocks, // blocks are replicated 2 times\n\t\t},\n\t\t\"shuffle sharding strategy, 20 gateways, RF = 3, SS = 3\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyShuffle,\n\t\t\ttenantShardSize:      3,\n\t\t\treplicationFactor:    3,\n\t\t\tnumGateways:          20,\n\t\t\texpectedBlocksLoaded: 3 * numBlocks, // blocks are replicated 3 times\n\t\t},\n\t\t\"shuffle sharding strategy, 20 gateways, RF = 3, SS = 0.5\": {\n\t\t\tshardingStrategy:     util.ShardingStrategyShuffle,\n\t\t\ttenantShardSize:      0.5,\n\t\t\treplicationFactor:    3,\n\t\t\tnumGateways:          20,\n\t\t\texpectedBlocksLoaded: 3 * numBlocks, // blocks are replicated 3 times\n\t\t},\n\t}\n\n\tfor testName, testData := range tests {\n\t\tfor _, bucketIndexEnabled := range []bool{true, false} {\n\t\t\tt.Run(fmt.Sprintf(\"%s (bucket index enabled = %v)\", testName, bucketIndexEnabled), func(t *testing.T) {\n\t\t\t\t//parallel testing causes data race\n\t\t\t\t// Randomise the seed but log it in case we need to reproduce the test on failure.\n\t\t\t\tseed := time.Now().UnixNano()\n\t\t\t\trand.Seed(seed)\n\t\t\t\tt.Log(\"random generator seed:\", seed)\n\n\t\t\t\tctx := context.Background()\n\t\t\t\tringStore, closer := consul.NewInMemoryClientWithConfig(ring.GetCodec(), consul.Config{\n\t\t\t\t\tMaxCasRetries: 20,\n\t\t\t\t\tCasRetryDelay: 500 * time.Millisecond,\n\t\t\t\t}, log.NewNopLogger(), nil)\n\t\t\t\tt.Cleanup(func() { assert.NoError(t, closer.Close()) })\n\n\t\t\t\t// Create the configured number of gateways.\n\t\t\t\tvar gateways []*StoreGateway\n\t\t\t\tregistries := util.NewUserRegistries()\n\n\t\t\t\tfor i := 1; i <= testData.numGateways; i++ {\n\t\t\t\t\tinstanceID := fmt.Sprintf(\"gateway-%d\", i)\n\n\t\t\t\t\tstorageCfg := mockStorageConfig(t)\n\t\t\t\t\tstorageCfg.BucketStore.SyncInterval = time.Hour // Do not trigger the periodic sync in this test. We want the initial sync only.\n\t\t\t\t\tstorageCfg.BucketStore.BucketIndex.Enabled = bucketIndexEnabled\n\n\t\t\t\t\tlimits := defaultLimitsConfig()\n\t\t\t\t\tgatewayCfg := mockGatewayConfig()\n\t\t\t\t\tgatewayCfg.ShardingRing.ReplicationFactor = testData.replicationFactor\n\t\t\t\t\tgatewayCfg.ShardingRing.InstanceID = instanceID\n\t\t\t\t\tgatewayCfg.ShardingRing.InstanceAddr = fmt.Sprintf(\"127.0.0.%d\", i)\n\t\t\t\t\tgatewayCfg.ShardingRing.RingCheckPeriod = time.Hour // Do not check the ring topology changes in this test. We want the initial sync only.\n\t\t\t\t\tgatewayCfg.ShardingRing.WaitStabilityMinDuration = 2 * time.Second\n\t\t\t\t\tgatewayCfg.ShardingRing.WaitStabilityMaxDuration = 30 * time.Second\n\t\t\t\t\tgatewayCfg.ShardingEnabled = true\n\t\t\t\t\tgatewayCfg.ShardingStrategy = testData.shardingStrategy\n\t\t\t\t\tlimits.StoreGatewayTenantShardSize = testData.tenantShardSize\n\n\t\t\t\t\toverrides, err := validation.NewOverrides(limits, nil)\n\t\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\t\treg := prometheus.NewPedanticRegistry()\n\t\t\t\t\tg, err := newStoreGateway(gatewayCfg, storageCfg, bucketClient, ringStore, overrides, mockLoggingLevel(), log.NewNopLogger(), reg)\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\tdefer services.StopAndAwaitTerminated(ctx, g) //nolint:errcheck\n\n\t\t\t\t\tgateways = append(gateways, g)\n\t\t\t\t\tregistries.AddUserRegistry(instanceID, reg)\n\t\t\t\t}\n\n\t\t\t\t// Start all gateways concurrently.\n\t\t\t\tfor _, g := range gateways {\n\t\t\t\t\trequire.NoError(t, g.StartAsync(ctx))\n\t\t\t\t}\n\n\t\t\t\t// Wait until all gateways are running.\n\t\t\t\tfor _, g := range gateways {\n\t\t\t\t\trequire.NoError(t, g.AwaitRunning(ctx))\n\t\t\t\t}\n\n\t\t\t\t// At this point we expect that all gateways have done the initial sync and\n\t\t\t\t// they have synched only their own blocks, because they waited for a stable\n\t\t\t\t// ring before starting the initial sync.\n\t\t\t\tmetrics := registries.BuildMetricFamiliesPerUser()\n\t\t\t\tassert.Equal(t, float64(testData.expectedBlocksLoaded), metrics.GetSumOfGauges(\"cortex_bucket_store_blocks_loaded\"))\n\t\t\t\tassert.Equal(t, float64(2*testData.numGateways), metrics.GetSumOfGauges(\"cortex_bucket_stores_tenants_discovered\"))\n\n\t\t\t\tif testData.shardingStrategy == util.ShardingStrategyShuffle {\n\t\t\t\t\tshards := util.DynamicShardSize(testData.tenantShardSize, testData.numGateways)\n\t\t\t\t\tassert.Equal(t, float64(shards*numBlocks), metrics.GetSumOfGauges(\"cortex_blocks_meta_synced\"))\n\t\t\t\t\tassert.Equal(t, float64(shards*numUsers), metrics.GetSumOfGauges(\"cortex_bucket_stores_tenants_synced\"))\n\t\t\t\t} else {\n\t\t\t\t\tassert.Equal(t, float64(testData.numGateways*numBlocks), metrics.GetSumOfGauges(\"cortex_blocks_meta_synced\"))\n\t\t\t\t\tassert.Equal(t, float64(testData.numGateways*numUsers), metrics.GetSumOfGauges(\"cortex_bucket_stores_tenants_synced\"))\n\t\t\t\t}\n\n\t\t\t\t// We expect that all gateways have only run the initial sync and not the periodic one.\n\t\t\t\tassert.Equal(t, float64(testData.numGateways), metrics.GetSumOfCounters(\"cortex_storegateway_bucket_sync_total\"))\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *Signature) UnmarshalJSON(data []byte) error {\n\tvar sup signatureUnmarshalProbe\n\tsup.Header = NewHeaders()\n\tif err := json.Unmarshal(data, &sup); err != nil {\n\t\treturn errors.Wrap(err, `failed to unmarshal signature into temporary struct`)\n\t}\n\n\ts.headers = sup.Header\n\tif buf := sup.Protected; buf != nil {\n\t\tsrc := []byte(*buf)\n\t\tif !bytes.HasPrefix(src, []byte{'{'}) {\n\t\t\tdecoded, err := base64.Decode(src)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, `failed to base64 decode protected headers`)\n\t\t\t}\n\t\t\tsrc = decoded\n\t\t}\n\n\t\tprt := NewHeaders()\n\t\t//nolint:forcetypeassert\n\t\tprt.(*stdHeaders).SetDecodeCtx(s.DecodeCtx())\n\t\tif err := json.Unmarshal(src, prt); err != nil {\n\t\t\treturn errors.Wrap(err, `failed to unmarshal protected headers`)\n\t\t}\n\t\t//nolint:forcetypeassert\n\t\tprt.(*stdHeaders).SetDecodeCtx(nil)\n\t\ts.protected = prt\n\t}\n\n\tdecoded, err := base64.DecodeString(*sup.Signature)\n\tif err != nil {\n\t\treturn errors.Wrap(err, `failed to base decode signature`)\n\t}\n\ts.signature = decoded\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c Config) validate() (*Config, error) {\n\terr := c.authMethod.validate()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &c, nil\n}", "is_vulnerable": 1}
{"code": "func RunTestDeleteWithSuggestionAndConflict(ctx context.Context, t *testing.T, store storage.Interface) {\n\tkey, originalPod := testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"name\"}})\n\n\t// First update, so originalPod is outdated.\n\tupdatedPod := &example.Pod{}\n\tif err := store.GuaranteedUpdate(ctx, key, updatedPod, false, nil,\n\t\tstorage.SimpleUpdate(func(obj runtime.Object) (runtime.Object, error) {\n\t\t\tpod := obj.(*example.Pod)\n\t\t\tpod.ObjectMeta.Labels = map[string]string{\"foo\": \"bar\"}\n\t\t\treturn pod, nil\n\t\t}), nil); err != nil {\n\t\tt.Errorf(\"Unexpected failure during updated: %v\", err)\n\t}\n\n\tout := &example.Pod{}\n\tif err := store.Delete(ctx, key, out, nil, storage.ValidateAllObjectFunc, originalPod); err != nil {\n\t\tt.Errorf(\"Unexpected failure during deletion: %v\", err)\n\t}\n\n\tif err := store.Get(ctx, key, storage.GetOptions{}, &example.Pod{}); !storage.IsNotFound(err) {\n\t\tt.Errorf(\"Unexpected error on reading object: %v\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestAffinitySession(t *testing.T) {\n\tec := NewAnnotationExtractor(mockCfg{})\n\ting := buildIngress()\n\n\tfooAnns := []struct {\n\t\tannotations    map[string]string\n\t\taffinitytype   string\n\t\taffinitymode   string\n\t\tcookiename     string\n\t\tcanarybehavior string\n\t}{\n\t\t{map[string]string{annotationAffinityType: \"cookie\", annotationAffinityMode: \"balanced\", annotationAffinityCookieName: \"route\", annotationAffinityCanaryBehavior: \"\"}, \"cookie\", \"balanced\", \"route\", \"\"},\n\t\t{map[string]string{annotationAffinityType: \"cookie\", annotationAffinityMode: \"persistent\", annotationAffinityCookieName: \"route1\", annotationAffinityCanaryBehavior: \"sticky\"}, \"cookie\", \"persistent\", \"route1\", \"sticky\"},\n\t\t{map[string]string{annotationAffinityType: \"cookie\", annotationAffinityMode: \"balanced\", annotationAffinityCookieName: \"\", annotationAffinityCanaryBehavior: \"legacy\"}, \"cookie\", \"balanced\", \"INGRESSCOOKIE\", \"legacy\"},\n\t\t{map[string]string{}, \"\", \"\", \"\", \"\"},\n\t\t{nil, \"\", \"\", \"\", \"\"},\n\t}\n\n\tfor _, foo := range fooAnns {\n\t\ting.SetAnnotations(foo.annotations)\n\t\tr := ec.Extract(ing).SessionAffinity\n\t\tt.Logf(\"Testing pass %v %v\", foo.affinitytype, foo.cookiename)\n\n\t\tif r.Type != foo.affinitytype {\n\t\t\tt.Errorf(\"Returned %v but expected %v for Type\", r.Type, foo.affinitytype)\n\t\t}\n\n\t\tif r.Mode != foo.affinitymode {\n\t\t\tt.Errorf(\"Returned %v but expected %v for Mode\", r.Mode, foo.affinitymode)\n\t\t}\n\n\t\tif r.CanaryBehavior != foo.canarybehavior {\n\t\t\tt.Errorf(\"Returned %v but expected %v for CanaryBehavior\", r.CanaryBehavior, foo.canarybehavior)\n\t\t}\n\n\t\tif r.Cookie.Name != foo.cookiename {\n\t\t\tt.Errorf(\"Returned %v but expected %v for Cookie.Name\", r.Cookie.Name, foo.cookiename)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *MockRequester) SetSession(arg0 fosite.Session) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"SetSession\", arg0)\n}", "is_vulnerable": 0}
{"code": "func Equal(t TestingT, expected interface{}, actual interface{}, msgAndArgs ...interface{}) {\n\tif assert.Equal(t, expected, actual, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (a ratelimit) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "\tusers, err := ParsePasswdFilter(passwd, func(u User) bool {\n\t\tif userArg == \"\" {\n\t\t\treturn u.Uid == user.Uid\n\t\t}\n\t\treturn u.Name == userArg || strconv.Itoa(u.Uid) == userArg\n\t})", "is_vulnerable": 1}
{"code": "func ExcludedRoute(route string) bool {\n\tfor _, r := range excludedRoutes {\n\t\tif strings.Contains(route, r) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func CsrfFromHeader(param string) func(c *fiber.Ctx) (string, error) {\n\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.Get(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", ErrMissingHeader\n\t\t}\n\t\treturn token, nil\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) CheckExistence(ctx context.Context, resourceGroupName string, deploymentName string) (result autorest.Response, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/DeploymentsClient.CheckExistence\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response != nil {\n\t\t\t\tsc = result.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.DeploymentsClient\", \"CheckExistence\", err.Error())\n\t}\n\n\treq, err := client.CheckExistencePreparer(ctx, resourceGroupName, deploymentName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.CheckExistenceSender(req)\n\tif err != nil {\n\t\tresult.Response = resp\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.CheckExistenceResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (m *NestedDefinition_NestedMessage) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMessage: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMessage: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NestedField1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.NestedField1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NNM\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NNM == nil {\n\t\t\t\tm.NNM = &NestedDefinition_NestedMessage_NestedNestedMsg{}\n\t\t\t}\n\t\t\tif err := m.NNM.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (client Client) GetSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) Patch(ctx context.Context, resourceGroupName string, parameters Group) (result Group, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupsClient.Patch\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.GroupsClient\", \"Patch\", err.Error())\n\t}\n\n\treq, err := client.PatchPreparer(ctx, resourceGroupName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"Patch\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.PatchSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"Patch\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.PatchResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"Patch\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (p *build) saveInputTx(tx Tx, buildID int, input BuildInput) error {\n\tversionJSON, err := json.Marshal(input.Version)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = psql.Insert(\"build_resource_config_version_inputs\").\n\t\tColumns(\"build_id\", \"resource_id\", \"version_md5\", \"name\").\n\t\tValues(buildID, input.ResourceID, sq.Expr(fmt.Sprintf(\"md5('%s')\", versionJSON)), input.Name).\n\t\tSuffix(\"ON CONFLICT DO NOTHING\").\n\t\tRunWith(tx).\n\t\tExec()\n\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func Test_isURLSchemeAllowed(t *testing.T) {\n\ttype testdata struct {\n\t\tname     string\n\t\tscheme   string\n\t\tallowed  []string\n\t\texpected bool\n\t}\n\tvar tts []testdata = []testdata{\n\t\t{\n\t\t\tname:     \"Allowed scheme matches\",\n\t\t\tscheme:   \"http\",\n\t\t\tallowed:  []string{\"http\", \"https\"},\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"Allowed scheme matches only partially\",\n\t\t\tscheme:   \"http\",\n\t\t\tallowed:  []string{\"https\"},\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"Scheme is not allowed\",\n\t\t\tscheme:   \"file\",\n\t\t\tallowed:  []string{\"http\", \"https\"},\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"Empty scheme with valid allowances is forbidden\",\n\t\t\tscheme:   \"\",\n\t\t\tallowed:  []string{\"http\", \"https\"},\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"Empty scheme with empty allowances is forbidden\",\n\t\t\tscheme:   \"\",\n\t\t\tallowed:  []string{},\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"Some scheme with empty allowances is forbidden\",\n\t\t\tscheme:   \"file\",\n\t\t\tallowed:  []string{},\n\t\t\texpected: false,\n\t\t},\n\t}\n\tfor _, tt := range tts {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tr := isURLSchemeAllowed(tt.scheme, tt.allowed)\n\t\t\tassert.Equal(t, tt.expected, r)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c Criteria) OrderBy() string {\n\tif c.Sort == \"\" {\n\t\tc.Sort = \"title\"\n\t}\n\tf := fieldMap[strings.ToLower(c.Sort)]\n\tvar mapped string\n\tif f == nil {\n\t\tlog.Error(\"Invalid field in 'sort' field. Using 'title'\", \"sort\", c.Sort)\n\t\tmapped = fieldMap[\"title\"].field\n\t} else {\n\t\tif f.order == \"\" {\n\t\t\tmapped = f.field\n\t\t} else {\n\t\t\tmapped = f.order\n\t\t}\n\t}\n\tif c.Order != \"\" {\n\t\tif strings.EqualFold(c.Order, \"asc\") || strings.EqualFold(c.Order, \"desc\") {\n\t\t\tmapped = mapped + \" \" + c.Order\n\t\t} else {\n\t\t\tlog.Error(\"Invalid value in 'order' field. Valid values: 'asc', 'desc'\", \"order\", c.Order)\n\t\t}\n\t}\n\treturn mapped\n}", "is_vulnerable": 0}
{"code": "func newCommandAuth(authHandle tpmutil.Handle, nonceEven Nonce, nonceOdd *Nonce, key []byte, params []interface{}) (*commandAuth, error) {\n\t// Auth = HMAC-SHA1(key, SHA1(params) || NonceEven || NonceOdd || ContSession)\n\tdigestBytes, err := tpmutil.Pack(params...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdigest := sha1.Sum(digestBytes)\n\n\t// Use the passed-in nonce if non-nil, otherwise generate it now.\n\tvar odd Nonce\n\tif nonceOdd != nil {\n\t\todd = *nonceOdd\n\t} else {\n\t\tif _, err := rand.Read(odd[:]); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tca := &commandAuth{\n\t\tAuthHandle: authHandle,\n\t\tNonceOdd:   odd,\n\t}\n\n\tauthBytes, err := tpmutil.Pack(digest, nonceEven, ca.NonceOdd, ca.ContSession)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thm2 := hmac.New(sha1.New, key)\n\thm2.Write(authBytes)\n\tauth := hm2.Sum(nil)\n\tcopy(ca.Auth[:], auth[:])\n\treturn ca, nil\n}", "is_vulnerable": 0}
{"code": "func safeAddr(ctx context.Context, resolver *net.Resolver, hostport string, opts ...Option) (string, error) {\n\tc := basicConfig()\n\tfor _, opt := range opts {\n\t\topt(c)\n\t}\n\thost, port, err := net.SplitHostPort(hostport)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tip := net.ParseIP(host)\n\tif ip != nil {\n\t\tif ip.IsUnspecified() || (ip.To4() != nil && c.isIPForbidden(ip)) {\n\t\t\treturn \"\", fmt.Errorf(\"bad ip is detected: %v\", ip)\n\t\t}\n\t\treturn net.JoinHostPort(ip.String(), port), nil\n\t}\n\n\tif c.isHostForbidden(host) {\n\t\treturn \"\", fmt.Errorf(\"bad host is detected: %v\", host)\n\t}\n\n\tr := resolver\n\tif r == nil {\n\t\tr = net.DefaultResolver\n\t}\n\taddrs, err := r.LookupIPAddr(ctx, host)\n\tif err != nil || len(addrs) <= 0 {\n\t\treturn \"\", err\n\t}\n\tsafeAddrs := make([]net.IPAddr, 0, len(addrs))\n\tfor _, addr := range addrs {\n\t\t// only support IPv4 address\n\t\tif addr.IP.To4() == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif c.isIPForbidden(addr.IP) {\n\t\t\treturn \"\", fmt.Errorf(\"bad ip is detected: %v\", addr.IP)\n\t\t}\n\t\tsafeAddrs = append(safeAddrs, addr)\n\t}\n\tif len(safeAddrs) == 0 {\n\t\treturn \"\", fmt.Errorf(\"fail to lookup ip addr: %v\", host)\n\t}\n\treturn net.JoinHostPort(safeAddrs[0].IP.String(), port), nil\n}", "is_vulnerable": 0}
{"code": "func (g *Git) Clone(branch string) error {\n\tif branch == \"\" {\n\t\treturn g.git(\"clone\", \"--depth=1\", \"-n\", g.URL, g.Directory)\n\t}\n\treturn g.git(\"clone\", \"--depth=1\", \"-n\", \"--branch\", branch, g.URL, g.Directory)\n}", "is_vulnerable": 1}
{"code": "func userByID(ctx context.Context, viewProvider userViewProvider, eventProvider userEventProvider, userID string) (_ *user_model.UserView, err error) {\n\tctx, span := tracing.NewSpan(ctx)\n\tdefer func() { span.EndWithError(err) }()\n\n\tuser, viewErr := viewProvider.UserByID(userID, authz.GetInstance(ctx).InstanceID())\n\tif viewErr != nil && !zerrors.IsNotFound(viewErr) {\n\t\treturn nil, viewErr\n\t} else if user == nil {\n\t\tuser = new(user_view_model.UserView)\n\t}\n\tevents, err := eventProvider.UserEventsByID(ctx, userID, user.ChangeDate, user.EventTypes())\n\tif err != nil {\n\t\tlogging.WithFields(\"traceID\", tracing.TraceIDFromCtx(ctx)).WithError(err).Debug(\"error retrieving new events\")\n\t\treturn user_view_model.UserToModel(user), nil\n\t}\n\tif len(events) == 0 {\n\t\tif viewErr != nil {\n\t\t\treturn nil, viewErr\n\t\t}\n\t\treturn user_view_model.UserToModel(user), viewErr\n\t}\n\tuserCopy := *user\n\tfor _, event := range events {\n\t\tif err := userCopy.AppendEvent(event); err != nil {\n\t\t\treturn user_view_model.UserToModel(user), nil\n\t\t}\n\t}\n\tif userCopy.State == int32(user_model.UserStateDeleted) {\n\t\treturn nil, zerrors.ThrowNotFound(nil, \"EVENT-3F9so\", \"Errors.User.NotFound\")\n\t}\n\treturn user_view_model.UserToModel(&userCopy), nil\n}", "is_vulnerable": 1}
{"code": "func publicKeyFromKeyPair(t *testing.T, pair nkeys.KeyPair) (pkey string) {\n\tvar err error\n\tif pkey, err = pair.PublicKey(); err != nil {\n\t\tt.Fatalf(\"Expected no error %v\", err)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func key(qname string, m *dns.Msg, t response.Type, do bool) (bool, uint64) {\n\t// We don't store truncated responses.\n\tif m.Truncated {\n\t\treturn false, 0\n\t}\n\t// Nor errors or Meta or Update.\n\tif t == response.OtherError || t == response.Meta || t == response.Update {\n\t\treturn false, 0\n\t}\n\n\treturn true, hash(qname, m.Question[0].Qtype, do)\n}", "is_vulnerable": 1}
{"code": "func (us *UserService) RetrievePassWord(ctx context.Context, req *schema.UserRetrievePassWordRequest) error {\n\tuserInfo, has, err := us.userRepo.GetByEmail(ctx, req.Email)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !has {\n\t\treturn nil\n\t}\n\n\t// send email\n\tdata := &schema.EmailCodeContent{\n\t\tEmail:  req.Email,\n\t\tUserID: userInfo.ID,\n\t}\n\tcode := uuid.NewString()\n\tverifyEmailURL := fmt.Sprintf(\"%s/users/password-reset?code=%s\", us.getSiteUrl(ctx), code)\n\ttitle, body, err := us.emailService.PassResetTemplate(ctx, verifyEmailURL)\n\tif err != nil {\n\t\treturn err\n\t}\n\tgo us.emailService.SendAndSaveCode(ctx, userInfo.ID, req.Email, title, body, code, data.ToJSONString())\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *criService) containerSpec(id string, sandboxID string, sandboxPid uint32, netNSPath string, containerName string,\n\tconfig *runtime.ContainerConfig, sandboxConfig *runtime.PodSandboxConfig, imageConfig *imagespec.ImageConfig,\n\textraMounts []*runtime.Mount, ociRuntime config.Runtime) (_ *runtimespec.Spec, retErr error) {\n\n\tspecOpts := []oci.SpecOpts{\n\t\tcustomopts.WithoutRunMount,\n\t}\n\t// only clear the default security settings if the runtime does not have a custom\n\t// base runtime spec spec.  Admins can use this functionality to define\n\t// default ulimits, seccomp, or other default settings.\n\tif ociRuntime.BaseRuntimeSpec == \"\" {\n\t\tspecOpts = append(specOpts, customopts.WithoutDefaultSecuritySettings)\n\t}\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithRelativeRoot(relativeRootfsPath),\n\t\tcustomopts.WithProcessArgs(config, imageConfig),\n\t\toci.WithDefaultPathEnv,\n\t\t// this will be set based on the security context below\n\t\toci.WithNewPrivileges,\n\t)\n\tif config.GetWorkingDir() != \"\" {\n\t\tspecOpts = append(specOpts, oci.WithProcessCwd(config.GetWorkingDir()))\n\t} else if imageConfig.WorkingDir != \"\" {\n\t\tspecOpts = append(specOpts, oci.WithProcessCwd(imageConfig.WorkingDir))\n\t}\n\n\tif config.GetTty() {\n\t\tspecOpts = append(specOpts, oci.WithTTY)\n\t}\n\n\t// Add HOSTNAME env.\n\tvar (\n\t\terr      error\n\t\thostname = sandboxConfig.GetHostname()\n\t)\n\tif hostname == \"\" {\n\t\tif hostname, err = c.os.Hostname(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tspecOpts = append(specOpts, oci.WithEnv([]string{hostnameEnv + \"=\" + hostname}))\n\n\t// Apply envs from image config first, so that envs from container config\n\t// can override them.\n\tenv := imageConfig.Env\n\tfor _, e := range config.GetEnvs() {\n\t\tenv = append(env, e.GetKey()+\"=\"+e.GetValue())\n\t}\n\tspecOpts = append(specOpts, oci.WithEnv(env))\n\n\tsecurityContext := config.GetLinux().GetSecurityContext()\n\tlabelOptions, err := toLabel(securityContext.GetSelinuxOptions())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(labelOptions) == 0 {\n\t\t// Use pod level SELinux config\n\t\tif sandbox, err := c.sandboxStore.Get(sandboxID); err == nil {\n\t\t\tlabelOptions, err = selinux.DupSecOpt(sandbox.ProcessLabel)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\tprocessLabel, mountLabel, err := label.InitLabels(labelOptions)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to init selinux options %+v\", securityContext.GetSelinuxOptions())\n\t}\n\tdefer func() {\n\t\tif retErr != nil {\n\t\t\t_ = label.ReleaseLabel(processLabel)\n\t\t}\n\t}()\n\n\tspecOpts = append(specOpts, customopts.WithMounts(c.os, config, extraMounts, mountLabel), customopts.WithRelabeledContainerMounts(mountLabel))\n\n\tif !c.config.DisableProcMount {\n\t\t// Apply masked paths if specified.\n\t\t// If the container is privileged, this will be cleared later on.\n\t\tif maskedPaths := securityContext.GetMaskedPaths(); maskedPaths != nil {\n\t\t\tspecOpts = append(specOpts, oci.WithMaskedPaths(maskedPaths))\n\t\t}\n\n\t\t// Apply readonly paths if specified.\n\t\t// If the container is privileged, this will be cleared later on.\n\t\tif readonlyPaths := securityContext.GetReadonlyPaths(); readonlyPaths != nil {\n\t\t\tspecOpts = append(specOpts, oci.WithReadonlyPaths(readonlyPaths))\n\t\t}\n\t}\n\n\tif securityContext.GetPrivileged() {\n\t\tif !sandboxConfig.GetLinux().GetSecurityContext().GetPrivileged() {\n\t\t\treturn nil, errors.New(\"no privileged container allowed in sandbox\")\n\t\t}\n\t\tspecOpts = append(specOpts, oci.WithPrivileged)\n\t\tif !ociRuntime.PrivilegedWithoutHostDevices {\n\t\t\tspecOpts = append(specOpts, oci.WithHostDevices, oci.WithAllDevicesAllowed)\n\t\t} else {\n\t\t\t// add requested devices by the config as host devices are not automatically added\n\t\t\tspecOpts = append(specOpts, customopts.WithDevices(c.os, config), customopts.WithCapabilities(securityContext))\n\t\t}\n\t} else { // not privileged\n\t\tspecOpts = append(specOpts, customopts.WithDevices(c.os, config), customopts.WithCapabilities(securityContext))\n\t}\n\n\t// Clear all ambient capabilities. The implication of non-root + caps\n\t// is not clearly defined in Kubernetes.\n\t// See https://github.com/kubernetes/kubernetes/issues/56374\n\t// Keep docker's behavior for now.\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithoutAmbientCaps,\n\t\tcustomopts.WithSelinuxLabels(processLabel, mountLabel),\n\t)\n\n\t// TODO: Figure out whether we should set no new privilege for sandbox container by default\n\tif securityContext.GetNoNewPrivs() {\n\t\tspecOpts = append(specOpts, oci.WithNoNewPrivileges)\n\t}\n\t// TODO(random-liu): [P1] Set selinux options (privileged or not).\n\tif securityContext.GetReadonlyRootfs() {\n\t\tspecOpts = append(specOpts, oci.WithRootFSReadonly())\n\t}\n\n\tif c.config.DisableCgroup {\n\t\tspecOpts = append(specOpts, customopts.WithDisabledCgroups)\n\t} else {\n\t\tspecOpts = append(specOpts, customopts.WithResources(config.GetLinux().GetResources(), c.config.TolerateMissingHugetlbController, c.config.DisableHugetlbController))\n\t\tif sandboxConfig.GetLinux().GetCgroupParent() != \"\" {\n\t\t\tcgroupsPath := getCgroupsPath(sandboxConfig.GetLinux().GetCgroupParent(), id)\n\t\t\tspecOpts = append(specOpts, oci.WithCgroup(cgroupsPath))\n\t\t}\n\t}\n\n\tsupplementalGroups := securityContext.GetSupplementalGroups()\n\n\tfor pKey, pValue := range getPassthroughAnnotations(sandboxConfig.Annotations,\n\t\tociRuntime.PodAnnotations) {\n\t\tspecOpts = append(specOpts, customopts.WithAnnotation(pKey, pValue))\n\t}\n\n\tfor pKey, pValue := range getPassthroughAnnotations(config.Annotations,\n\t\tociRuntime.ContainerAnnotations) {\n\t\tspecOpts = append(specOpts, customopts.WithAnnotation(pKey, pValue))\n\t}\n\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithOOMScoreAdj(config, c.config.RestrictOOMScoreAdj),\n\t\tcustomopts.WithPodNamespaces(securityContext, sandboxPid),\n\t\tcustomopts.WithSupplementalGroups(supplementalGroups),\n\t\tcustomopts.WithAnnotation(annotations.ContainerType, annotations.ContainerTypeContainer),\n\t\tcustomopts.WithAnnotation(annotations.SandboxID, sandboxID),\n\t\tcustomopts.WithAnnotation(annotations.ContainerName, containerName),\n\t)\n\t// cgroupns is used for hiding /sys/fs/cgroup from containers.\n\t// For compatibility, cgroupns is not used when running in cgroup v1 mode or in privileged.\n\t// https://github.com/containers/libpod/issues/4363\n\t// https://github.com/kubernetes/enhancements/blob/0e409b47497e398b369c281074485c8de129694f/keps/sig-node/20191118-cgroups-v2.md#cgroup-namespace\n\tif cgroups.Mode() == cgroups.Unified && !securityContext.GetPrivileged() {\n\t\tspecOpts = append(specOpts, oci.WithLinuxNamespace(\n\t\t\truntimespec.LinuxNamespace{\n\t\t\t\tType: runtimespec.CgroupNamespace,\n\t\t\t}))\n\t}\n\treturn c.runtimeSpec(id, ociRuntime.BaseRuntimeSpec, specOpts...)\n}", "is_vulnerable": 0}
{"code": "func TestIndex(t *testing.T) {\n\tt.Run(\"Invalid\", func(t *testing.T) {\n\t\tclient := NewClient(\"\", Creds{}, false, \"\")\n\t\t_, err := client.GetIndex(false)\n\t\tassert.Error(t, err)\n\t})\n\tt.Run(\"Stable\", func(t *testing.T) {\n\t\tclient := NewClient(\"https://argoproj.github.io/argo-helm\", Creds{}, false, \"\")\n\t\tindex, err := client.GetIndex(false)\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, index)\n\t})\n\tt.Run(\"BasicAuth\", func(t *testing.T) {\n\t\tclient := NewClient(\"https://argoproj.github.io/argo-helm\", Creds{\n\t\t\tUsername: \"my-password\",\n\t\t\tPassword: \"my-username\",\n\t\t}, false, \"\")\n\t\tindex, err := client.GetIndex(false)\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, index)\n\t})\n\n\tt.Run(\"Cached\", func(t *testing.T) {\n\t\tfakeIndex := Index{Entries: map[string]Entries{\"fake\": {}}}\n\t\tdata := bytes.Buffer{}\n\t\terr := yaml.NewEncoder(&data).Encode(fakeIndex)\n\t\trequire.NoError(t, err)\n\n\t\tclient := NewClient(\"https://argoproj.github.io/argo-helm\", Creds{}, false, \"\", WithIndexCache(&fakeIndexCache{data: data.Bytes()}))\n\t\tindex, err := client.GetIndex(false)\n\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, fakeIndex, *index)\n\t})\n\n}", "is_vulnerable": 1}
{"code": "func Test3p(t *testing.T) {\n\tfor _, s := range []string{thirdPartyJwt, \"InvalidToken\"} {\n\t\tif IsK8SUnbound(s) {\n\t\t\tt.Error(\"Expecting bound token, detected unbound \", s)\n\t\t}\n\t}\n\tfor _, s := range []string{firstPartyJwt, \".bnVsbM.\"} {\n\t\tif !IsK8SUnbound(s) {\n\t\t\tt.Error(\"Expecting unbound, detected bound \", s)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *Validate) PatchFilter(config *extensioncommon.RuntimeConfig, filter *envoy_listener_v3.Filter, _ bool) (*envoy_listener_v3.Filter, bool, error) {\n\t// If a single filter exists for a listener we say it exists.\n\tp.listener = true\n\n\tif httpConfig := envoy_resource_v3.GetHTTPConnectionManager(filter); httpConfig != nil {\n\t\t// If the http filter uses RDS, then the clusters we need to validate exist in the route, and there's nothing\n\t\t// else we need to do with the filter.\n\t\tif httpConfig.GetRds() != nil {\n\t\t\tp.usesRDS = true\n\n\t\t\t// Edit the runtime configuration to add an envoy ID based on the route name in the filter. This is because\n\t\t\t// routes are matched by envoyID and in the transparent proxy case, we only have the VIP set in the\n\t\t\t// RuntimeConfig.\n\t\t\tp.envoyID = httpConfig.GetRds().RouteConfigName\n\t\t\temptyServiceKey := api.CompoundServiceName{}\n\t\t\tupstream, ok := config.Upstreams[emptyServiceKey]\n\t\t\tif ok {\n\t\t\t\tupstream.EnvoyID = p.envoyID\n\t\t\t}\n\t\t\treturn filter, true, nil\n\t\t}\n\t}\n\n\t// FilterClusterNames handles the filter being an http or tcp filter.\n\tfor sni := range extensioncommon.FilterClusterNames(filter) {\n\t\t// Mark any clusters we see as required resources.\n\t\tif r, ok := p.resources[sni]; ok {\n\t\t\tr.required = true\n\t\t} else {\n\t\t\tp.resources[sni] = &resource{required: true}\n\t\t}\n\t}\n\n\treturn filter, true, nil\n}", "is_vulnerable": 0}
{"code": "func (m *NidOptCustom) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidOptCustom: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidOptCustom: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Id\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Id.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Value.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"either url or urlSecret must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"amqp.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.AMQP)\n\n\tfor _, value := range eventSource.Spec.AMQP {\n\t\tl := &EventListener{\n\t\t\tAMQPEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (h *AuthHandlers) HostKeyAuth(addr string, remote net.Addr, key ssh.PublicKey) error {\n\t// Check if the given host key was signed by a Teleport certificate\n\t// authority (CA) or fallback to host key checking if it's allowed.\n\tcertChecker := utils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsHostAuthority: h.IsHostAuthority,\n\t\t\tHostKeyFallback: h.hostKeyCallback,\n\t\t},\n\t\tFIPS: h.FIPS,\n\t}\n\terr := certChecker.CheckHostKey(addr, remote, key)\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (a proxy) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func Marshal(obj interface{}) ([]byte, error) {\n\tjsonBytes, err := json.Marshal(obj)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error marshaling into JSON: %w\", err)\n\t}\n\n\treturn JSONToYAML(jsonBytes)\n}", "is_vulnerable": 0}
{"code": "func (m *mockLayer) Digest() (v1.Hash, error)            { panic(\"not implemented\") }", "is_vulnerable": 0}
{"code": "func (h *Handler) AuthHandler(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {\n\tvar ctx = r.Context()\n\n\tauthorizeRequest, err := h.r.OAuth2Provider().NewAuthorizeRequest(ctx, r)\n\tif err != nil {\n\t\tx.LogError(err, h.r.Logger())\n\t\th.writeAuthorizeError(w, r, authorizeRequest, err)\n\t\treturn\n\t}\n\n\tsession, err := h.r.ConsentStrategy().HandleOAuth2AuthorizationRequest(w, r, authorizeRequest)\n\tif errors.Cause(err) == consent.ErrAbortOAuth2Request {\n\t\t// do nothing\n\t\treturn\n\t} else if err != nil {\n\t\tx.LogError(err, h.r.Logger())\n\t\th.writeAuthorizeError(w, r, authorizeRequest, err)\n\t\treturn\n\t}\n\n\tfor _, scope := range session.GrantedScope {\n\t\tauthorizeRequest.GrantScope(scope)\n\t}\n\n\tfor _, audience := range session.GrantedAudience {\n\t\tauthorizeRequest.GrantAudience(audience)\n\t}\n\n\topenIDKeyID, err := h.r.OpenIDJWTStrategy().GetPublicKeyID(r.Context())\n\tif err != nil {\n\t\tx.LogError(err, h.r.Logger())\n\t\th.writeAuthorizeError(w, r, authorizeRequest, err)\n\t\treturn\n\t}\n\n\tvar accessTokenKeyID string\n\tif h.c.AccessTokenStrategy() == \"jwt\" {\n\t\taccessTokenKeyID, err = h.r.AccessTokenJWTStrategy().GetPublicKeyID(r.Context())\n\t\tif err != nil {\n\t\t\tx.LogError(err, h.r.Logger())\n\t\t\th.writeAuthorizeError(w, r, authorizeRequest, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tauthorizeRequest.SetID(session.Challenge)\n\n\tclaims := &jwt.IDTokenClaims{\n\t\tSubject:     session.ConsentRequest.SubjectIdentifier,\n\t\tIssuer:      strings.TrimRight(h.c.IssuerURL().String(), \"/\") + \"/\",\n\t\tIssuedAt:    time.Now().UTC(),\n\t\tAuthTime:    time.Time(session.AuthenticatedAt),\n\t\tRequestedAt: session.RequestedAt,\n\t\tExtra:       session.Session.IDToken,\n\t\tAuthenticationContextClassReference: session.ConsentRequest.ACR,\n\n\t\t// We do not need to pass the audience because it's included directly by ORY Fosite\n\t\t// Audience:    []string{authorizeRequest.GetClient().GetID()},\n\n\t\t// This is set by the fosite strategy\n\t\t// ExpiresAt:   time.Now().Add(h.IDTokenLifespan).UTC(),\n\t}\n\tclaims.Add(\"sid\", session.ConsentRequest.LoginSessionID)\n\n\t// done\n\tresponse, err := h.r.OAuth2Provider().NewAuthorizeResponse(ctx, authorizeRequest, &Session{\n\t\tDefaultSession: &openid.DefaultSession{\n\t\t\tClaims: claims,\n\t\t\tHeaders: &jwt.Headers{Extra: map[string]interface{}{\n\t\t\t\t// required for lookup on jwk endpoint\n\t\t\t\t\"kid\": openIDKeyID,\n\t\t\t}},\n\t\t\tSubject: session.ConsentRequest.Subject,\n\t\t},\n\t\tExtra:            session.Session.AccessToken,\n\t\tKID:              accessTokenKeyID,\n\t\tClientID:         authorizeRequest.GetClient().GetID(),\n\t\tConsentChallenge: session.Challenge,\n\t})\n\tif err != nil {\n\t\tx.LogError(err, h.r.Logger())\n\t\th.writeAuthorizeError(w, r, authorizeRequest, err)\n\t\treturn\n\t}\n\n\th.r.OAuth2Provider().WriteAuthorizeResponse(w, authorizeRequest, response)\n}", "is_vulnerable": 1}
{"code": "func (v *V002Entry) Unmarshal(pe models.ProposedEntry) error {\n\tit, ok := pe.(*models.Intoto)\n\tif !ok {\n\t\treturn errors.New(\"cannot unmarshal non Intoto v0.0.2 type\")\n\t}\n\n\tvar err error\n\tif err := types.DecodeEntry(it.Spec, &v.IntotoObj); err != nil {\n\t\treturn err\n\t}\n\n\t// field validation\n\tif err := v.IntotoObj.Validate(strfmt.Default); err != nil {\n\t\treturn err\n\t}\n\n\tif string(v.IntotoObj.Content.Envelope.Payload) == \"\" {\n\t\treturn nil\n\t}\n\n\tenv := &dsse.Envelope{\n\t\tPayload:     string(v.IntotoObj.Content.Envelope.Payload),\n\t\tPayloadType: *v.IntotoObj.Content.Envelope.PayloadType,\n\t}\n\n\tallPubKeyBytes := make([][]byte, 0)\n\tfor _, sig := range v.IntotoObj.Content.Envelope.Signatures {\n\t\tenv.Signatures = append(env.Signatures, dsse.Signature{\n\t\t\tKeyID: sig.Keyid,\n\t\t\tSig:   string(sig.Sig),\n\t\t})\n\n\t\tallPubKeyBytes = append(allPubKeyBytes, sig.PublicKey)\n\t}\n\n\tif _, err := verifyEnvelope(allPubKeyBytes, env); err != nil {\n\t\treturn err\n\t}\n\n\tv.env = *env\n\n\tdecodedPayload, err := base64.StdEncoding.DecodeString(string(v.IntotoObj.Content.Envelope.Payload))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not decode envelope payload: %w\", err)\n\t}\n\n\th := sha256.Sum256(decodedPayload)\n\tv.IntotoObj.Content.PayloadHash = &models.IntotoV002SchemaContentPayloadHash{\n\t\tAlgorithm: swag.String(models.IntotoV002SchemaContentPayloadHashAlgorithmSha256),\n\t\tValue:     swag.String(hex.EncodeToString(h[:])),\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func queryMatches(rp *arrayPathResult, value Result) bool {\n\trpv := rp.query.value\n\tif len(rpv) > 0 && rpv[0] == '~' {\n\t\t// convert to bool\n\t\trpv = rpv[1:]\n\t\tif value.Bool() {\n\t\t\tvalue = Result{Type: True}\n\t\t} else {\n\t\t\tvalue = Result{Type: False}\n\t\t}\n\t}\n\tif !value.Exists() {\n\t\treturn false\n\t}\n\tif rp.query.op == \"\" {\n\t\t// the query is only looking for existence, such as:\n\t\t//   friends.#(name)\n\t\t// which makes sure that the array \"friends\" has an element of\n\t\t// \"name\" that exists\n\t\treturn true\n\t}\n\tswitch value.Type {\n\tcase String:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn value.Str == rpv\n\t\tcase \"!=\":\n\t\t\treturn value.Str != rpv\n\t\tcase \"<\":\n\t\t\treturn value.Str < rpv\n\t\tcase \"<=\":\n\t\t\treturn value.Str <= rpv\n\t\tcase \">\":\n\t\t\treturn value.Str > rpv\n\t\tcase \">=\":\n\t\t\treturn value.Str >= rpv\n\t\tcase \"%\":\n\t\t\treturn match.Match(value.Str, rpv)\n\t\tcase \"!%\":\n\t\t\treturn !match.Match(value.Str, rpv)\n\t\t}\n\tcase Number:\n\t\trpvn, _ := strconv.ParseFloat(rpv, 64)\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn value.Num == rpvn\n\t\tcase \"!=\":\n\t\t\treturn value.Num != rpvn\n\t\tcase \"<\":\n\t\t\treturn value.Num < rpvn\n\t\tcase \"<=\":\n\t\t\treturn value.Num <= rpvn\n\t\tcase \">\":\n\t\t\treturn value.Num > rpvn\n\t\tcase \">=\":\n\t\t\treturn value.Num >= rpvn\n\t\t}\n\tcase True:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn rpv == \"true\"\n\t\tcase \"!=\":\n\t\t\treturn rpv != \"true\"\n\t\tcase \">\":\n\t\t\treturn rpv == \"false\"\n\t\tcase \">=\":\n\t\t\treturn true\n\t\t}\n\tcase False:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn rpv == \"false\"\n\t\tcase \"!=\":\n\t\t\treturn rpv != \"false\"\n\t\tcase \"<\":\n\t\t\treturn rpv == \"true\"\n\t\tcase \"<=\":\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func TestSyncHelm(t *testing.T) {\n\tctx := context.Background()\n\tappServer := newTestAppServer(t)\n\ttestApp := newTestApp()\n\ttestApp.Spec.Source.RepoURL = \"https://argoproj.github.io/argo-helm\"\n\ttestApp.Spec.Source.Path = \"\"\n\ttestApp.Spec.Source.Chart = \"argo-cd\"\n\ttestApp.Spec.Source.TargetRevision = \"0.7.*\"\n\n\tappServer.repoClientset = &mocks.Clientset{RepoServerServiceClient: fakeRepoServerClient(true)}\n\n\tapp, err := appServer.Create(ctx, &application.ApplicationCreateRequest{Application: testApp})\n\tassert.NoError(t, err)\n\n\tapp, err = appServer.Sync(ctx, &application.ApplicationSyncRequest{Name: &app.Name})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, app)\n\tassert.NotNil(t, app.Operation)\n\n\tevents, err := appServer.kubeclientset.CoreV1().Events(appServer.ns).List(context.Background(), metav1.ListOptions{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"Unknown user initiated sync to 0.7.* (0.7.2)\", events.Items[1].Message)\n}", "is_vulnerable": 0}
{"code": "func isMatchingAsLoopback(requested *url.URL, registeredURI string) bool {\n\tregistered, err := url.Parse(registeredURI)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\t// Native apps that are able to open a port on the loopback network\n\t// interface without needing special permissions (typically, those on\n\t// desktop operating systems) can use the loopback interface to receive\n\t// the OAuth redirect.\n\t//\n\t// Loopback redirect URIs use the \"http\" scheme and are constructed with\n\t// the loopback IP literal and whatever port the client is listening on.\n\t//\n\t// Source: https://tools.ietf.org/html/rfc8252#section-7.3\n\tif requested.Scheme == \"http\" &&\n\t\tisLoopbackAddress(requested.Host) &&\n\t\tregistered.Hostname() == requested.Hostname() &&\n\t\t// The port is skipped here - see codedoc above!\n\t\tregistered.Path == requested.Path &&\n\t\tregistered.RawQuery == requested.RawQuery {\n\t\treturn true\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func TestImportValidationSigningKey(t *testing.T) {\n\tak := createAccountNKey(t)\n\tak2 := createAccountNKey(t)\n\tak2Sk := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\takp2 := publicKey(ak2, t)\n\ti := &Import{Subject: \"test\", Account: akp2, To: \"bar\", Type: Stream}\n\n\tactivation := NewActivationClaims(akp)\n\tactivation.Expires = time.Now().Add(time.Hour).UTC().Unix()\n\tactivation.ImportSubject = \"test\"\n\tactivation.ImportType = Stream\n\tactivation.IssuerAccount = akp2\n\ti.Token = encode(activation, ak2Sk, t)\n\tvr := CreateValidationResults()\n\ti.Validate(akp, vr)\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"Expired import needs to not result in an error\")\n\t}\n}", "is_vulnerable": 1}
{"code": "\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tevent, err = formatter.Process(ctx, event)\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t\t_, err := sink.Process(ctx, event)\n\t\t\tif err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "var _ = Describe(\"Clawback Vesting Accounts\", Ordered, func() {\n\t// Monthly vesting period\n\tstakeDenom := utils.BaseDenom\n\tamt := math.NewInt(1e17)\n\tvestingLength := int64(60 * 60 * 24 * 30) // in seconds\n\tvestingAmt := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt))\n\tvestingPeriod := sdkvesting.Period{Length: vestingLength, Amount: vestingAmt}\n\n\t// 4 years vesting total\n\tperiodsTotal := int64(48)\n\tvestingAmtTotal := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(periodsTotal))))\n\n\t// 6 month cliff\n\tcliff := int64(6)\n\tcliffLength := vestingLength * cliff\n\tcliffAmt := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(cliff))))\n\tcliffPeriod := sdkvesting.Period{Length: cliffLength, Amount: cliffAmt}\n\n\t// 12 month lockup\n\tlockup := int64(12) // 12 months\n\tlockupLength := vestingLength * lockup\n\t// Unlock at 12 and 24 months\n\tnumLockupPeriods := int64(2)\n\t// Unlock 1/4th of the total vest in each unlock event. By default, all tokens are\n\t// unlocked after surpassing the final period.\n\tunlockedPerLockup := vestingAmtTotal.QuoInt(math.NewInt(4))\n\tunlockedPerLockupAmt := unlockedPerLockup[0].Amount\n\tlockupPeriod := sdkvesting.Period{Length: lockupLength, Amount: unlockedPerLockup}\n\tlockupPeriods := make(sdkvesting.Periods, numLockupPeriods)\n\tfor i := range lockupPeriods {\n\t\tlockupPeriods[i] = lockupPeriod\n\t}\n\n\t// Create vesting periods with initial cliff\n\tvestingPeriods := sdkvesting.Periods{cliffPeriod}\n\tfor p := int64(1); p <= periodsTotal-cliff; p++ {\n\t\tvestingPeriods = append(vestingPeriods, vestingPeriod)\n\t}\n\n\t// Create test accounts with private keys for signing\n\tnumTestAccounts := 4\n\ttestAccounts := make([]TestClawbackAccount, numTestAccounts)\n\tfor i := range testAccounts {\n\t\taddress, privKey := utiltx.NewAddrKey()\n\t\ttestAccounts[i] = TestClawbackAccount{\n\t\t\tprivKey: privKey,\n\t\t\taddress: address.Bytes(),\n\t\t}\n\t}\n\tnumTestMsgs := 3\n\n\taccountGasCoverage := sdk.NewCoins(sdk.NewCoin(stakeDenom, math.NewInt(1e16)))\n\n\tvar (\n\t\tclawbackAccount   *types.ClawbackVestingAccount\n\t\tunvested          sdk.Coins\n\t\tvested            sdk.Coins\n\t\ttwoThirdsOfVested sdk.Coins\n\t)\n\n\tdest := sdk.AccAddress(utiltx.GenerateAddress().Bytes())\n\tfunder := sdk.AccAddress(utiltx.GenerateAddress().Bytes())\n\n\tBeforeEach(func() {\n\t\ts.SetupTest()\n\n\t\t// Initialize all test accounts\n\t\tfor i, account := range testAccounts {\n\t\t\t// Create and fund periodic vesting account\n\t\t\tvestingStart := s.ctx.BlockTime()\n\t\t\tbaseAccount := authtypes.NewBaseAccountWithAddress(account.address)\n\t\t\tclawbackAccount = types.NewClawbackVestingAccount(\n\t\t\t\tbaseAccount,\n\t\t\t\tfunder,\n\t\t\t\tvestingAmtTotal,\n\t\t\t\tvestingStart,\n\t\t\t\tlockupPeriods,\n\t\t\t\tvestingPeriods,\n\t\t\t)\n\n\t\t\terr := testutil.FundAccount(s.ctx, s.app.BankKeeper, account.address, vestingAmtTotal)\n\t\t\ts.Require().NoError(err)\n\t\t\tacc := s.app.AccountKeeper.NewAccount(s.ctx, clawbackAccount)\n\t\t\ts.app.AccountKeeper.SetAccount(s.ctx, acc)\n\n\t\t\t// Check if all tokens are unvested at vestingStart\n\t\t\tunvested = clawbackAccount.GetUnvestedOnly(s.ctx.BlockTime())\n\t\t\tvested = clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\ts.Require().Equal(vestingAmtTotal, unvested)\n\t\t\ts.Require().True(vested.IsZero())\n\n\t\t\t// Grant gas stipend to cover EVM fees\n\t\t\terr = testutil.FundAccount(s.ctx, s.app.BankKeeper, clawbackAccount.GetAddress(), accountGasCoverage)\n\t\t\ts.Require().NoError(err)\n\t\t\tgranteeBalance := s.app.BankKeeper.GetBalance(s.ctx, account.address, stakeDenom)\n\t\t\ts.Require().Equal(granteeBalance, accountGasCoverage[0].Add(vestingAmtTotal[0]))\n\n\t\t\t// Update testAccounts clawbackAccount reference\n\t\t\ttestAccounts[i].clawbackAccount = clawbackAccount\n\t\t}\n\t})\n\n\tContext(\"before first vesting period\", func() {\n\t\tBeforeEach(func() {\n\t\t\t// Add a commit to instantiate blocks\n\t\t\ts.Commit()\n\n\t\t\t// Ensure no tokens are vested\n\t\t\tvested := clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\tunlocked := clawbackAccount.GetUnlockedOnly(s.ctx.BlockTime())\n\t\t\tzeroCoins := sdk.NewCoins(sdk.NewCoin(stakeDenom, math.ZeroInt()))\n\t\t\ts.Require().Equal(zeroCoins, vested)\n\t\t\ts.Require().Equal(zeroCoins, unlocked)\n\t\t})\n\n\t\tIt(\"cannot delegate tokens\", func() {\n\t\t\t_, err := delegate(testAccounts[0], accountGasCoverage.Add(sdk.NewCoin(stakeDenom, math.NewInt(1))))\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"can transfer spendable tokens\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\t// Fund account with new spendable tokens\n\t\t\terr := testutil.FundAccount(s.ctx, s.app.BankKeeper, account.address, unvested)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\terr = s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\taccount.address,\n\t\t\t\tdest,\n\t\t\t\tunvested,\n\t\t\t)\n\t\t\tExpect(err).To(BeNil())\n\t\t})\n\n\t\tIt(\"cannot transfer unvested tokens\", func() {\n\t\t\terr := s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\tclawbackAccount.GetAddress(),\n\t\t\t\tdest,\n\t\t\t\tunvested,\n\t\t\t)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"can perform Ethereum tx with spendable balance\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\t// Fund account with new spendable tokens\n\t\t\terr := testutil.FundAccount(s.ctx, s.app.BankKeeper, account.address, unlockedPerLockup)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, unlockedPerLockupAmt, stakeDenom, msg)\n\t\t})\n\n\t\tIt(\"cannot perform Ethereum tx with unvested balance\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msg)\n\t\t})\n\t})\n\n\tContext(\"after first vesting period and before lockup\", func() {\n\t\tBeforeEach(func() {\n\t\t\t// Surpass cliff but none of lockup duration\n\t\t\tcliffDuration := time.Duration(cliffLength)\n\t\t\ts.CommitAfter(cliffDuration * time.Second)\n\n\t\t\t// Check if some, but not all tokens are vested\n\t\t\tvested = clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\texpVested := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(cliff))))\n\t\t\ts.Require().NotEqual(vestingAmtTotal, vested)\n\t\t\ts.Require().Equal(expVested, vested)\n\n\t\t\ttwoThirdsOfVested = vested.Sub(vested.QuoInt(math.NewInt(3))...)\n\t\t})\n\n\t\tIt(\"can delegate vested tokens and update spendable balance\", func() {\n\t\t\ttestAccount := testAccounts[0]\n\t\t\t// Verify that the total spendable coins decreases after staking\n\t\t\t// vested tokens.\n\t\t\tspendablePre := s.app.BankKeeper.SpendableCoins(s.ctx, testAccount.address)\n\n\t\t\t_, err := delegate(testAccount, vested)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tspendablePost := s.app.BankKeeper.SpendableCoins(s.ctx, testAccount.address)\n\t\t\tExpect(spendablePost.AmountOf(stakeDenom).GT(spendablePre.AmountOf(stakeDenom)))\n\t\t})\n\n\t\tIt(\"cannot delegate unvested tokens\", func() {\n\t\t\t_, err := delegate(testAccounts[0], vestingAmtTotal)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"cannot delegate unvested tokens in batches\", func() {\n\t\t\tmsg, err := delegate(testAccounts[0], twoThirdsOfVested)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tmsgServer := stakingkeeper.NewMsgServerImpl(&s.app.StakingKeeper)\n\t\t\t_, err = msgServer.Delegate(s.ctx, msg)\n\t\t\tExpect(err).ToNot(HaveOccurred(), \"error while executing the delegate message\")\n\n\t\t\t_, err = delegate(testAccounts[0], twoThirdsOfVested)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"cannot delegate then send tokens\", func() {\n\t\t\t_, err := delegate(testAccounts[0], twoThirdsOfVested)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\terr = s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\tclawbackAccount.GetAddress(),\n\t\t\t\tdest,\n\t\t\t\ttwoThirdsOfVested,\n\t\t\t)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"cannot transfer vested tokens\", func() {\n\t\t\terr := s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\tclawbackAccount.GetAddress(),\n\t\t\t\tdest,\n\t\t\t\tvested,\n\t\t\t)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"can perform Ethereum tx with spendable balance\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\t// Fund account with new spendable tokens\n\t\t\terr := testutil.FundAccount(s.ctx, s.app.BankKeeper, account.address, unlockedPerLockup)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, unlockedPerLockupAmt, stakeDenom, msg)\n\t\t})\n\n\t\tIt(\"cannot perform Ethereum tx with locked balance\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\ttxAmount := vested.AmountOf(stakeDenom).BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msg)\n\t\t})\n\t})\n\n\tContext(\"Between first and second lockup periods\", func() {\n\t\tBeforeEach(func() {\n\t\t\t// Surpass first lockup\n\t\t\tvestDuration := time.Duration(lockupLength)\n\t\t\ts.CommitAfter(vestDuration * time.Second)\n\n\t\t\t// Check if some, but not all tokens are vested and unlocked\n\t\t\tfor _, account := range testAccounts {\n\t\t\t\tvested := account.clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\t\tunlocked := account.clawbackAccount.GetUnlockedOnly(s.ctx.BlockTime())\n\t\t\t\texpVested := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(lockup))))\n\n\t\t\t\ts.Require().NotEqual(vestingAmtTotal, vested)\n\t\t\t\ts.Require().Equal(expVested, vested)\n\t\t\t\ts.Require().Equal(unlocked, unlockedPerLockup)\n\t\t\t}\n\t\t})\n\n\t\tIt(\"should enable access to unlocked EVM tokens (single-account, single-msg)\", func() {\n\t\t\taccount := testAccounts[0]\n\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, unlockedPerLockupAmt, stakeDenom, msg)\n\t\t})\n\n\t\tIt(\"should enable access to unlocked EVM tokens (single-account, multiple-msgs)\", func() {\n\t\t\taccount := testAccounts[0]\n\n\t\t\t// Split the total unlocked amount into numTestMsgs equally sized tx's\n\t\t\tmsgs := make([]sdk.Msg, numTestMsgs)\n\t\t\ttxAmount := unlockedPerLockupAmt.QuoRaw(int64(numTestMsgs)).BigInt()\n\n\t\t\tfor i := 0; i < numTestMsgs; i++ {\n\t\t\t\tmsgs[i], err = utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, i)\n\t\t\t\tExpect(err).To(BeNil())\n\t\t\t}\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, unlockedPerLockupAmt, stakeDenom, msgs...)\n\t\t})\n\n\t\tIt(\"should enable access to unlocked EVM tokens (multi-account, single-msg)\", func() {\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\n\t\t\tmsgs := make([]sdk.Msg, numTestAccounts)\n\t\t\tfor i, grantee := range testAccounts {\n\t\t\t\tmsgs[i], err = utiltx.CreateEthTx(s.ctx, s.app, grantee.privKey, grantee.address, dest, txAmount, 0)\n\t\t\t\tExpect(err).To(BeNil())\n\t\t\t}\n\n\t\t\tassertEthSucceeds(testAccounts, funder, dest, unlockedPerLockupAmt, stakeDenom, msgs...)\n\t\t})\n\n\t\tIt(\"should enable access to unlocked EVM tokens (multi-account, multiple-msgs)\", func() {\n\t\t\tmsgs := []sdk.Msg{}\n\t\t\ttxAmount := unlockedPerLockupAmt.QuoRaw(int64(numTestMsgs)).BigInt()\n\n\t\t\tfor _, grantee := range testAccounts {\n\t\t\t\tfor j := 0; j < numTestMsgs; j++ {\n\t\t\t\t\taddedMsg, err := utiltx.CreateEthTx(s.ctx, s.app, grantee.privKey, grantee.address, dest, txAmount, j)\n\t\t\t\t\tExpect(err).To(BeNil())\n\t\t\t\t\tmsgs = append(msgs, addedMsg)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEthSucceeds(testAccounts, funder, dest, unlockedPerLockupAmt, stakeDenom, msgs...)\n\t\t})\n\n\t\tIt(\"should not enable access to locked EVM tokens (single-account, single-msg)\", func() {\n\t\t\ttestAccount := testAccounts[0]\n\t\t\t// Attempt to spend entire vesting balance\n\t\t\ttxAmount := vestingAmtTotal.AmountOf(stakeDenom).BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, testAccount.privKey, testAccount.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msg)\n\t\t})\n\n\t\tIt(\"should not enable access to locked EVM tokens (single-account, multiple-msgs)\", func() {\n\t\t\tmsgs := make([]sdk.Msg, numTestMsgs+1)\n\t\t\ttxAmount := unlockedPerLockupAmt.QuoRaw(int64(numTestMsgs)).BigInt()\n\t\t\ttestAccount := testAccounts[0]\n\n\t\t\t// Add additional message that exceeds unlocked balance\n\t\t\tfor i := 0; i < numTestMsgs+1; i++ {\n\t\t\t\tmsgs[i], err = utiltx.CreateEthTx(s.ctx, s.app, testAccount.privKey, testAccount.address, dest, txAmount, i)\n\t\t\t\tExpect(err).To(BeNil())\n\t\t\t}\n\n\t\t\tassertEthFails(msgs...)\n\t\t})\n\n\t\tIt(\"should not enable access to locked EVM tokens (multi-account, single-msg)\", func() {\n\t\t\tmsgs := make([]sdk.Msg, numTestAccounts+1)\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\n\t\t\tfor i, account := range testAccounts {\n\t\t\t\tmsgs[i], err = utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\t\tExpect(err).To(BeNil())\n\t\t\t}\n\n\t\t\t// Add additional message that exceeds unlocked balance\n\t\t\tmsgs[numTestAccounts], err = utiltx.CreateEthTx(s.ctx, s.app, testAccounts[0].privKey, testAccounts[0].address, dest, txAmount, 1)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msgs...)\n\t\t})\n\n\t\tIt(\"should not enable access to locked EVM tokens (multi-account, multiple-msgs)\", func() {\n\t\t\tmsgs := []sdk.Msg{}\n\t\t\ttxAmount := unlockedPerLockupAmt.QuoRaw(int64(numTestMsgs)).BigInt()\n\t\t\tvar addedMsg sdk.Msg\n\n\t\t\tfor _, account := range testAccounts {\n\t\t\t\tfor j := 0; j < numTestMsgs; j++ {\n\t\t\t\t\taddedMsg, err = utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, j)\n\t\t\t\t\tmsgs = append(msgs, addedMsg)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Add additional message that exceeds unlocked balance\n\t\t\taddedMsg, err = utiltx.CreateEthTx(s.ctx, s.app, testAccounts[0].privKey, testAccounts[0].address, dest, txAmount, numTestMsgs)\n\t\t\tExpect(err).To(BeNil())\n\t\t\tmsgs = append(msgs, addedMsg)\n\n\t\t\tassertEthFails(msgs...)\n\t\t})\n\n\t\tIt(\"should not short-circuit with a normal account\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\taddress, privKey := utiltx.NewAccAddressAndKey()\n\n\t\t\ttxAmount := vestingAmtTotal.AmountOf(stakeDenom).BigInt()\n\n\t\t\t// Fund a normal account to try to short-circuit the AnteHandler\n\t\t\terr = testutil.FundAccount(s.ctx, s.app.BankKeeper, address, vestingAmtTotal.MulInt(math.NewInt(2)))\n\t\t\tExpect(err).To(BeNil())\n\t\t\tnormalAccMsg, err := utiltx.CreateEthTx(s.ctx, s.app, privKey, address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\t// Attempt to spend entire balance\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\t\t\terr = validateEthVestingTransactionDecorator(normalAccMsg, msg)\n\t\t\tExpect(err).ToNot(BeNil())\n\n\t\t\t_, err = testutil.DeliverEthTx(s.app, nil, msg)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\t})\n\n\tContext(\"after first lockup and additional vest\", func() {\n\t\tBeforeEach(func() {\n\t\t\tvestDuration := time.Duration(lockupLength + vestingLength)\n\t\t\ts.CommitAfter(vestDuration * time.Second)\n\n\t\t\tvested = clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\texpVested := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(lockup+1))))\n\n\t\t\tunlocked := clawbackAccount.GetUnlockedOnly(s.ctx.BlockTime())\n\t\t\texpUnlocked := unlockedPerLockup\n\n\t\t\ts.Require().Equal(expVested, vested)\n\t\t\ts.Require().Equal(expUnlocked, unlocked)\n\t\t})\n\n\t\tIt(\"should enable access to unlocked EVM tokens\", func() {\n\t\t\ttestAccount := testAccounts[0]\n\n\t\t\ttxAmount := unlockedPerLockupAmt.BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, testAccount.privKey, testAccount.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{testAccount}, funder, dest, unlockedPerLockupAmt, stakeDenom, msg)\n\t\t})\n\n\t\tIt(\"should not enable access to locked EVM tokens\", func() {\n\t\t\ttestAccount := testAccounts[0]\n\n\t\t\ttxAmount := vested.AmountOf(stakeDenom).BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, testAccount.privKey, testAccount.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msg)\n\t\t})\n\t})\n\n\tContext(\"after half of vesting period and both lockups\", func() {\n\t\tBeforeEach(func() {\n\t\t\t// Surpass lockup duration\n\t\t\tlockupDuration := time.Duration(lockupLength * numLockupPeriods)\n\t\t\ts.CommitAfter(lockupDuration * time.Second)\n\n\t\t\t// Check if some, but not all tokens are vested\n\t\t\tunvested = clawbackAccount.GetUnvestedOnly(s.ctx.BlockTime())\n\t\t\tvested = clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\texpVested := sdk.NewCoins(sdk.NewCoin(stakeDenom, amt.Mul(math.NewInt(lockup*numLockupPeriods))))\n\t\t\ts.Require().NotEqual(vestingAmtTotal, vested)\n\t\t\ts.Require().Equal(expVested, vested)\n\t\t})\n\n\t\tIt(\"can delegate vested tokens\", func() {\n\t\t\t_, err := delegate(testAccounts[0], vested)\n\t\t\tExpect(err).To(BeNil())\n\t\t})\n\n\t\tIt(\"cannot delegate unvested tokens\", func() {\n\t\t\t_, err := delegate(testAccounts[0], vestingAmtTotal)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"can transfer vested tokens\", func() {\n\t\t\terr := s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\tclawbackAccount.GetAddress(),\n\t\t\t\tsdk.AccAddress(utiltx.GenerateAddress().Bytes()),\n\t\t\t\tvested,\n\t\t\t)\n\t\t\tExpect(err).To(BeNil())\n\t\t})\n\n\t\tIt(\"cannot transfer unvested tokens\", func() {\n\t\t\terr := s.app.BankKeeper.SendCoins(\n\t\t\t\ts.ctx,\n\t\t\t\tclawbackAccount.GetAddress(),\n\t\t\t\tsdk.AccAddress(utiltx.GenerateAddress().Bytes()),\n\t\t\t\tvestingAmtTotal,\n\t\t\t)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t})\n\n\t\tIt(\"can perform Ethereum tx with spendable balance\", func() {\n\t\t\taccount := testAccounts[0]\n\n\t\t\ttxAmount := vested.AmountOf(stakeDenom).BigInt()\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount, 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, vested.AmountOf(stakeDenom), stakeDenom, msg)\n\t\t})\n\t})\n\n\tContext(\"after entire vesting period and both lockups\", func() {\n\t\tBeforeEach(func() {\n\t\t\t// Surpass vest duration\n\t\t\tvestDuration := time.Duration(vestingLength * periodsTotal)\n\t\t\ts.CommitAfter(vestDuration * time.Second)\n\n\t\t\t// Check that all tokens are vested and unlocked\n\t\t\tunvested = clawbackAccount.GetUnvestedOnly(s.ctx.BlockTime())\n\t\t\tvested = clawbackAccount.GetVestedOnly(s.ctx.BlockTime())\n\t\t\tlocked := clawbackAccount.LockedCoins(s.ctx.BlockTime())\n\n\t\t\tzeroCoins := sdk.NewCoins(sdk.NewCoin(stakeDenom, math.ZeroInt()))\n\t\t\ts.Require().Equal(vestingAmtTotal, vested)\n\t\t\ts.Require().Equal(zeroCoins, locked)\n\t\t\ts.Require().Equal(zeroCoins, unvested)\n\t\t})\n\n\t\tIt(\"can send entire balance\", func() {\n\t\t\taccount := testAccounts[0]\n\n\t\t\ttxAmount := vestingAmtTotal.AmountOf(stakeDenom)\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount.BigInt(), 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthSucceeds([]TestClawbackAccount{account}, funder, dest, txAmount, stakeDenom, msg)\n\t\t})\n\n\t\tIt(\"cannot exceed balance\", func() {\n\t\t\taccount := testAccounts[0]\n\n\t\t\ttxAmount := vestingAmtTotal.AmountOf(stakeDenom).Mul(math.NewInt(2))\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, txAmount.BigInt(), 0)\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tassertEthFails(msg)\n\t\t})\n\n\t\tIt(\"should short-circuit with zero balance\", func() {\n\t\t\taccount := testAccounts[0]\n\t\t\tbalance := s.app.BankKeeper.GetBalance(s.ctx, account.address, stakeDenom)\n\n\t\t\t// Drain account balance\n\t\t\terr := s.app.BankKeeper.SendCoins(s.ctx, account.address, dest, sdk.NewCoins(balance))\n\t\t\tExpect(err).To(BeNil())\n\n\t\t\tmsg, err := utiltx.CreateEthTx(s.ctx, s.app, account.privKey, account.address, dest, big.NewInt(0), 0)\n\t\t\tExpect(err).To(BeNil())\n\t\t\terr = validateEthVestingTransactionDecorator(msg)\n\t\t\tExpect(err).ToNot(BeNil())\n\t\t\tExpect(strings.Contains(err.Error(), \"no balance\")).To(BeTrue())\n\t\t})\n\t})\n})", "is_vulnerable": 1}
{"code": "func (m *Foo_Bar) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue617\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue617(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue617\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func Test_CORS_Negative_MaxAge(t *testing.T) {\n\tt.Parallel()\n\n\tapp := fiber.New()\n\tapp.Use(New(Config{MaxAge: -1}))\n\n\tctx := &fasthttp.RequestCtx{}\n\tctx.Request.Header.SetMethod(fiber.MethodOptions)\n\tctx.Request.Header.Set(fiber.HeaderOrigin, \"http://localhost\")\n\tapp.Handler()(ctx)\n\n\tutils.AssertEqual(t, \"0\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlMaxAge)))\n}", "is_vulnerable": 0}
{"code": "func TestParse(t *testing.T) {\n\tannotation := parser.GetAnnotationWithPrefix(configurationSnippetAnnotation)\n\n\tap := NewParser(&resolver.Mock{})\n\tif ap == nil {\n\t\tt.Fatalf(\"expected a parser.IngressAnnotation but returned nil\")\n\t}\n\n\ttestCases := []struct {\n\t\tannotations map[string]string\n\t\texpected    string\n\t}{\n\t\t{map[string]string{annotation: \"more_headers\"}, \"more_headers\"},\n\t\t{map[string]string{annotation: \"false\"}, \"false\"},\n\t\t{map[string]string{}, \"\"},\n\t\t{nil, \"\"},\n\t}\n\n\ting := &networking.Ingress{\n\t\tObjectMeta: meta_v1.ObjectMeta{\n\t\t\tName:      \"foo\",\n\t\t\tNamespace: api.NamespaceDefault,\n\t\t},\n\t\tSpec: networking.IngressSpec{},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ting.SetAnnotations(testCase.annotations)\n\t\tresult, _ := ap.Parse(ing)\n\t\tif result != testCase.expected {\n\t\t\tt.Errorf(\"expected %v but returned %v, annotations: %s\", testCase.expected, result, testCase.annotations)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func Error(t TestingT, err error, msgAndArgs ...interface{}) {\n\tif assert.Error(t, err, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func TestClusterToSecret_LastAppliedConfigurationRejected(t *testing.T) {\n\tcluster := &appv1.Cluster{\n\t\tServer:      \"server\",\n\t\tAnnotations: map[string]string{v1.LastAppliedConfigAnnotation: \"val2\"},\n\t\tName:        \"test\",\n\t\tConfig:      v1alpha1.ClusterConfig{},\n\t\tProject:     \"project\",\n\t\tNamespaces:  []string{\"default\"},\n\t}\n\ts := &v1.Secret{}\n\terr := clusterToSecret(cluster, s)\n\trequire.Error(t, err)\n\trequire.Equal(t, codes.InvalidArgument, status.Code(err))\n}", "is_vulnerable": 0}
{"code": "func (m *CustomMap) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomMap: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomMap: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Nullable128S\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Nullable128S == nil {\n\t\t\t\tm.Nullable128S = make(map[string]*github_com_gogo_protobuf_test_custom.Uint128)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Nullable128S[mapkey] = ((*github_com_gogo_protobuf_test_custom.Uint128)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint128S\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Uint128S == nil {\n\t\t\t\tm.Uint128S = make(map[string]github_com_gogo_protobuf_test_custom.Uint128)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint128S[mapkey] = ((github_com_gogo_protobuf_test_custom.Uint128)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableIds\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableIds == nil {\n\t\t\t\tm.NullableIds = make(map[string]*github_com_gogo_protobuf_test.Uuid)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test.Uuid\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableIds[mapkey] = ((*github_com_gogo_protobuf_test.Uuid)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Ids\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Ids == nil {\n\t\t\t\tm.Ids = make(map[string]github_com_gogo_protobuf_test.Uuid)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test.Uuid\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Ids[mapkey] = ((github_com_gogo_protobuf_test.Uuid)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestBearerAuthenticator(t *testing.T) {\n\tcfg := createDefaultConfig().(*Config)\n\tcfg.BearerToken = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n\n\tbauth := newBearerTokenAuth(cfg, nil)\n\tassert.NotNil(t, bauth)\n\n\tassert.Nil(t, bauth.Start(context.Background(), componenttest.NewNopHost()))\n\tcredential, err := bauth.PerRPCCredentials()\n\n\tassert.NoError(t, err)\n\tassert.NotNil(t, credential)\n\n\tmd, err := credential.GetRequestMetadata(context.Background())\n\texpectedMd := map[string]string{\n\t\t\"authorization\": fmt.Sprintf(\"Bearer %s\", string(cfg.BearerToken)),\n\t}\n\tassert.Equal(t, md, expectedMd)\n\tassert.NoError(t, err)\n\tassert.True(t, credential.RequireTransportSecurity())\n\n\troundTripper, _ := bauth.RoundTripper(&mockRoundTripper{})\n\torgHeaders := http.Header{\n\t\t\"Foo\": {\"bar\"},\n\t}\n\texpectedHeaders := http.Header{\n\t\t\"Foo\":           {\"bar\"},\n\t\t\"Authorization\": {bauth.bearerToken()},\n\t}\n\n\tresp, err := roundTripper.RoundTrip(&http.Request{Header: orgHeaders})\n\tassert.NoError(t, err)\n\tassert.Equal(t, expectedHeaders, resp.Header)\n\tassert.Nil(t, bauth.Shutdown(context.Background()))\n}", "is_vulnerable": 1}
{"code": "func (batch *Batch) ExecParams(sql string, paramValues [][]byte, paramOIDs []uint32, paramFormats []int16, resultFormats []int16) {\n\tif batch.err != nil {\n\t\treturn\n\t}\n\n\tbatch.buf, batch.err = (&pgproto3.Parse{Query: sql, ParameterOIDs: paramOIDs}).Encode(batch.buf)\n\tif batch.err != nil {\n\t\treturn\n\t}\n\tbatch.ExecPrepared(\"\", paramValues, paramFormats, resultFormats)\n}", "is_vulnerable": 0}
{"code": "func characterEscape(s string, escapeChar string) string {\n\treturn strings.Replace(s, escapeChar, url.QueryEscape(escapeChar), -1)\n}", "is_vulnerable": 0}
{"code": "func runUsingChrootMain() {\n\tvar options runUsingChrootSubprocOptions\n\n\truntime.LockOSThread()\n\n\t// Set logging.\n\tif level := os.Getenv(\"LOGLEVEL\"); level != \"\" {\n\t\tif ll, err := strconv.Atoi(level); err == nil {\n\t\t\tlogrus.SetLevel(logrus.Level(ll))\n\t\t}\n\t\tos.Unsetenv(\"LOGLEVEL\")\n\t}\n\n\t// Unpack our configuration.\n\tconfPipe := os.NewFile(3, \"confpipe\")\n\tif confPipe == nil {\n\t\tfmt.Fprintf(os.Stderr, \"error reading options pipe\\n\")\n\t\tos.Exit(1)\n\t}\n\tdefer confPipe.Close()\n\tif err := json.NewDecoder(confPipe).Decode(&options); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error decoding options: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\tif options.Spec == nil || options.Spec.Process == nil {\n\t\tfmt.Fprintf(os.Stderr, \"invalid options spec in runUsingChrootMain\\n\")\n\t\tos.Exit(1)\n\t}\n\n\t// Prepare to shuttle stdio back and forth.\n\trootUID32, rootGID32, err := util.GetHostRootIDs(options.Spec)\n\tif err != nil {\n\t\tlogrus.Errorf(\"error determining ownership for container stdio\")\n\t\tos.Exit(1)\n\t}\n\trootUID := int(rootUID32)\n\trootGID := int(rootGID32)\n\trelays := make(map[int]int)\n\tcloseOnceRunning := []*os.File{}\n\tvar ctty *os.File\n\tvar stdin io.Reader\n\tvar stdinCopy io.WriteCloser\n\tvar stdout io.Writer\n\tvar stderr io.Writer\n\tfdDesc := make(map[int]string)\n\tif options.Spec.Process.Terminal {\n\t\t// Create a pseudo-terminal -- open a copy of the master side.\n\t\tptyMasterFd, err := unix.Open(\"/dev/ptmx\", os.O_RDWR, 0600)\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening PTY master using /dev/ptmx: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Set the kernel's lock to \"unlocked\".\n\t\tlocked := 0\n\t\tif result, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCSPTLCK, uintptr(unsafe.Pointer(&locked))); int(result) == -1 {\n\t\t\tlogrus.Errorf(\"error locking PTY descriptor: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Get a handle for the other end.\n\t\tptyFd, _, err := unix.Syscall(unix.SYS_IOCTL, uintptr(ptyMasterFd), unix.TIOCGPTPEER, unix.O_RDWR|unix.O_NOCTTY)\n\t\tif int(ptyFd) == -1 {\n\t\t\tif errno, isErrno := err.(syscall.Errno); !isErrno || (errno != syscall.EINVAL && errno != syscall.ENOTTY) {\n\t\t\t\tlogrus.Errorf(\"error getting PTY descriptor: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\t// EINVAL means the kernel's too old to understand TIOCGPTPEER.  Try TIOCGPTN.\n\t\t\tptyN, err := unix.IoctlGetInt(ptyMasterFd, unix.TIOCGPTN)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error getting PTY number: %v\", err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyName := fmt.Sprintf(\"/dev/pts/%d\", ptyN)\n\t\t\tfd, err := unix.Open(ptyName, unix.O_RDWR|unix.O_NOCTTY, 0620)\n\t\t\tif err != nil {\n\t\t\t\tlogrus.Errorf(\"error opening PTY %q: %v\", ptyName, err)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tptyFd = uintptr(fd)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[ptyMasterFd] = unix.Stdout\n\t\trelays[unix.Stdin] = ptyMasterFd\n\t\tfdDesc[ptyMasterFd] = \"container terminal\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\twinsize := &unix.Winsize{}\n\t\t// Set the pseudoterminal's size to the configured size, or our own.\n\t\tif options.Spec.Process.ConsoleSize != nil {\n\t\t\t// Use configured sizes.\n\t\t\twinsize.Row = uint16(options.Spec.Process.ConsoleSize.Height)\n\t\t\twinsize.Col = uint16(options.Spec.Process.ConsoleSize.Width)\n\t\t} else {\n\t\t\tif terminal.IsTerminal(unix.Stdin) {\n\t\t\t\t// Use the size of our terminal.\n\t\t\t\twinsize, err = unix.IoctlGetWinsize(unix.Stdin, unix.TIOCGWINSZ)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlogrus.Debugf(\"error reading current terminal's size\")\n\t\t\t\t\twinsize.Row = 0\n\t\t\t\t\twinsize.Col = 0\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif winsize.Row != 0 && winsize.Col != 0 {\n\t\t\tif err = unix.IoctlSetWinsize(int(ptyFd), unix.TIOCSWINSZ, winsize); err != nil {\n\t\t\t\tlogrus.Warnf(\"error setting terminal size for pty\")\n\t\t\t}\n\t\t\t// FIXME - if we're connected to a terminal, we should\n\t\t\t// be passing the updated terminal size down when we\n\t\t\t// receive a SIGWINCH.\n\t\t}\n\t\t// Open an *os.File object that we can pass to our child.\n\t\tctty = os.NewFile(ptyFd, \"/dev/tty\")\n\t\t// Set ownership for the PTY.\n\t\tif err = ctty.Chown(rootUID, rootGID); err != nil {\n\t\t\tvar cttyInfo unix.Stat_t\n\t\t\terr2 := unix.Fstat(int(ptyFd), &cttyInfo)\n\t\t\tfrom := \"\"\n\t\t\top := \"setting\"\n\t\t\tif err2 == nil {\n\t\t\t\top = \"changing\"\n\t\t\t\tfrom = fmt.Sprintf(\"from %d/%d \", cttyInfo.Uid, cttyInfo.Gid)\n\t\t\t}\n\t\t\tlogrus.Warnf(\"error %s ownership of container PTY %sto %d/%d: %v\", op, from, rootUID, rootGID, err)\n\t\t}\n\t\t// Set permissions on the PTY.\n\t\tif err = ctty.Chmod(0620); err != nil {\n\t\t\tlogrus.Errorf(\"error setting permissions of container PTY: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the PTY connected to its stdio, and that we should\n\t\t// close it once it's running.\n\t\tstdin = ctty\n\t\tstdout = ctty\n\t\tstderr = ctty\n\t\tcloseOnceRunning = append(closeOnceRunning, ctty)\n\t} else {\n\t\t// Create pipes for stdio.\n\t\tstdinRead, stdinWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdin: %v\", err)\n\t\t}\n\t\tstdoutRead, stdoutWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stdout: %v\", err)\n\t\t}\n\t\tstderrRead, stderrWrite, err := os.Pipe()\n\t\tif err != nil {\n\t\t\tlogrus.Errorf(\"error opening pipe for stderr: %v\", err)\n\t\t}\n\t\t// Make notes about what's going where.\n\t\trelays[unix.Stdin] = int(stdinWrite.Fd())\n\t\trelays[int(stdoutRead.Fd())] = unix.Stdout\n\t\trelays[int(stderrRead.Fd())] = unix.Stderr\n\t\tfdDesc[int(stdinWrite.Fd())] = \"container stdin pipe\"\n\t\tfdDesc[int(stdoutRead.Fd())] = \"container stdout pipe\"\n\t\tfdDesc[int(stderrRead.Fd())] = \"container stderr pipe\"\n\t\tfdDesc[unix.Stdin] = \"stdin\"\n\t\tfdDesc[unix.Stdout] = \"stdout\"\n\t\tfdDesc[unix.Stderr] = \"stderr\"\n\t\t// Set ownership for the pipes.\n\t\tif err = stdinRead.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdin pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stdoutWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stdout pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = stderrWrite.Chown(rootUID, rootGID); err != nil {\n\t\t\tlogrus.Errorf(\"error setting ownership of container stderr pipe: %v\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t\t// Make a note that our child (the parent subprocess) should\n\t\t// have the pipes connected to its stdio, and that we should\n\t\t// close its ends of them once it's running.\n\t\tstdin = stdinRead\n\t\tstdout = stdoutWrite\n\t\tstderr = stderrWrite\n\t\tcloseOnceRunning = append(closeOnceRunning, stdinRead, stdoutWrite, stderrWrite)\n\t\tstdinCopy = stdinWrite\n\t\tdefer stdoutRead.Close()\n\t\tdefer stderrRead.Close()\n\t}\n\tfor readFd, writeFd := range relays {\n\t\tif err := unix.SetNonblock(readFd, true); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) non-blocking: %v\", readFd, fdDesc[readFd], err)\n\t\t\treturn\n\t\t}\n\t\tif err := unix.SetNonblock(writeFd, false); err != nil {\n\t\t\tlogrus.Errorf(\"error setting descriptor %d (%s) blocking: %v\", relays[writeFd], fdDesc[writeFd], err)\n\t\t\treturn\n\t\t}\n\t}\n\tif err := unix.SetNonblock(relays[unix.Stdin], true); err != nil {\n\t\tlogrus.Errorf(\"error setting %d to nonblocking: %v\", relays[unix.Stdin], err)\n\t}\n\tgo func() {\n\t\tbuffers := make(map[int]*bytes.Buffer)\n\t\tfor _, writeFd := range relays {\n\t\t\tbuffers[writeFd] = new(bytes.Buffer)\n\t\t}\n\t\tpollTimeout := -1\n\t\tstdinClose := false\n\t\tfor len(relays) > 0 {\n\t\t\tfds := make([]unix.PollFd, 0, len(relays))\n\t\t\tfor fd := range relays {\n\t\t\t\tfds = append(fds, unix.PollFd{Fd: int32(fd), Events: unix.POLLIN | unix.POLLHUP})\n\t\t\t}\n\t\t\t_, err := unix.Poll(fds, pollTimeout)\n\t\t\tif !util.LogIfNotRetryable(err, fmt.Sprintf(\"poll: %v\", err)) {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tremoveFds := make(map[int]struct{})\n\t\t\tfor _, rfd := range fds {\n\t\t\t\tif rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLNVAL == unix.POLLNVAL {\n\t\t\t\t\tlogrus.Debugf(\"error polling descriptor %s: closed?\", fdDesc[int(rfd.Fd)])\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t\tif rfd.Revents&unix.POLLIN == 0 {\n\t\t\t\t\tif stdinClose && stdinCopy == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tb := make([]byte, 8192)\n\t\t\t\tnread, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\tif nread > 0 {\n\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nread])\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif nwritten != nread {\n\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nread, nwritten)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// If this is the last of the data we'll be able to read\n\t\t\t\t\t// from this descriptor, read as much as there is to read.\n\t\t\t\t\tfor rfd.Revents&unix.POLLHUP == unix.POLLHUP {\n\t\t\t\t\t\tnr, err := unix.Read(int(rfd.Fd), b)\n\t\t\t\t\t\tutil.LogIfUnexpectedWhileDraining(err, fmt.Sprintf(\"read %s: %v\", fdDesc[int(rfd.Fd)], err))\n\t\t\t\t\t\tif nr <= 0 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif wfd, ok := relays[int(rfd.Fd)]; ok {\n\t\t\t\t\t\t\tnwritten, err := buffers[wfd].Write(b[:nr])\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: %v\", err)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif nwritten != nr {\n\t\t\t\t\t\t\t\tlogrus.Debugf(\"buffer: expected to buffer %d bytes, wrote %d\", nr, nwritten)\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif nread == 0 {\n\t\t\t\t\tremoveFds[int(rfd.Fd)] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\t\t\tpollTimeout = -1\n\t\t\tfor wfd, buffer := range buffers {\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tnwritten, err := unix.Write(wfd, buffer.Bytes())\n\t\t\t\t\tutil.LogIfNotRetryable(err, fmt.Sprintf(\"write %s: %v\", fdDesc[wfd], err))\n\t\t\t\t\tif nwritten >= 0 {\n\t\t\t\t\t\t_ = buffer.Next(nwritten)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif buffer.Len() > 0 {\n\t\t\t\t\tpollTimeout = 100\n\t\t\t\t}\n\t\t\t\tif wfd == relays[unix.Stdin] && stdinClose && buffer.Len() == 0 {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t\tdelete(relays, unix.Stdin)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor rfd := range removeFds {\n\t\t\t\tif rfd == unix.Stdin {\n\t\t\t\t\tbuffer, found := buffers[relays[unix.Stdin]]\n\t\t\t\t\tif found && buffer.Len() > 0 {\n\t\t\t\t\t\tstdinClose = true\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif !options.Spec.Process.Terminal && rfd == unix.Stdin {\n\t\t\t\t\tstdinCopy.Close()\n\t\t\t\t}\n\t\t\t\tdelete(relays, rfd)\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Set up mounts and namespaces, and run the parent subprocess.\n\tstatus, err := runUsingChroot(options.Spec, options.BundlePath, ctty, stdin, stdout, stderr, closeOnceRunning)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error running subprocess: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Pass the process's exit status back to the caller by exiting with the same status.\n\tif status.Exited() {\n\t\tif status.ExitStatus() != 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"subprocess exited with status %d\\n\", status.ExitStatus())\n\t\t}\n\t\tos.Exit(status.ExitStatus())\n\t} else if status.Signaled() {\n\t\tfmt.Fprintf(os.Stderr, \"subprocess exited on %s\\n\", status.Signal())\n\t\tos.Exit(1)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Configurator) OutgoingRPCWrapper() DCWrapper {\n\tc.log(\"OutgoingRPCWrapper\")\n\tif c.outgoingRPCTLSDisabled() {\n\t\treturn nil\n\t}\n\n\t// Generate the wrapper based on dc\n\treturn func(dc string, conn net.Conn) (net.Conn, error) {\n\t\treturn c.wrapTLSClient(dc, conn)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestFilesystem_SafePath(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\tprefix := filepath.Join(rfs.root, \"/server\")\n\n\tg.Describe(\"SafePath\", func() {\n\t\tg.It(\"returns a cleaned path to a given file\", func() {\n\t\t\tp, err := fs.SafePath(\"test.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/test.txt\")\n\n\t\t\tp, err = fs.SafePath(\"/test.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/test.txt\")\n\n\t\t\tp, err = fs.SafePath(\"./test.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/test.txt\")\n\n\t\t\tp, err = fs.SafePath(\"/foo/../test.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/test.txt\")\n\n\t\t\tp, err = fs.SafePath(\"/foo/bar\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/foo/bar\")\n\t\t})\n\n\t\tg.It(\"handles root directory access\", func() {\n\t\t\tp, err := fs.SafePath(\"/\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix)\n\n\t\t\tp, err = fs.SafePath(\"\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix)\n\t\t})\n\n\t\tg.It(\"removes trailing slashes from paths\", func() {\n\t\t\tp, err := fs.SafePath(\"/foo/bar/\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/foo/bar\")\n\t\t})\n\n\t\tg.It(\"handles deeply nested directories that do not exist\", func() {\n\t\t\tp, err := fs.SafePath(\"/foo/bar/baz/quaz/../../ducks/testing.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(p).Equal(prefix + \"/foo/bar/ducks/testing.txt\")\n\t\t})\n\n\t\tg.It(\"blocks access to files outside the root directory\", func() {\n\t\t\tp, err := fs.SafePath(\"../test.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t\tg.Assert(p).Equal(\"\")\n\n\t\t\tp, err = fs.SafePath(\"/../test.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t\tg.Assert(p).Equal(\"\")\n\n\t\t\tp, err = fs.SafePath(\"./foo/../../test.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t\tg.Assert(p).Equal(\"\")\n\n\t\t\tp, err = fs.SafePath(\"..\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t\tg.Assert(p).Equal(\"\")\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func (a *Assertions) Greaterf(e1 interface{}, e2 interface{}, msg string, args ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tGreaterf(a.t, e1, e2, msg, args...)\n}", "is_vulnerable": 0}
{"code": "func NewGroupListResultIterator(page GroupListResultPage) GroupListResultIterator {\n\treturn original.NewGroupListResultIterator(page)\n}", "is_vulnerable": 0}
{"code": "func (s *Sync) commit(req *request) (err error) {\n\t// Write the node content to the membatch\n\ts.membatch.batch[req.hash] = req.data\n\n\tdelete(s.requests, req.hash)\n\n\t// Check all parents for completion\n\tfor _, parent := range req.parents {\n\t\tparent.deps--\n\t\tif parent.deps == 0 {\n\t\t\tif err := s.commit(parent); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (fs *UnixFS) Remove(name string) error {\n\tdirfd, name, closeFd, err := fs.safePath(name)\n\tdefer closeFd()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Prevent trying to Remove the base directory.\n\tif name == \".\" {\n\t\treturn &PathError{\n\t\t\tOp:   \"remove\",\n\t\t\tPath: name,\n\t\t\tErr:  ErrBadPathResolution,\n\t\t}\n\t}\n\n\t// System call interface forces us to know\n\t// whether name is a file or directory.\n\t// Try both: it is cheaper on average than\n\t// doing a Stat plus the right one.\n\terr = fs.unlinkat(dirfd, name, 0)\n\tif err == nil {\n\t\treturn nil\n\t}\n\terr1 := fs.unlinkat(dirfd, name, AT_REMOVEDIR) // Rmdir\n\tif err1 == nil {\n\t\treturn nil\n\t}\n\n\t// Both failed: figure out which error to return.\n\t// OS X and Linux differ on whether unlink(dir)\n\t// returns EISDIR, so can't use that. However,\n\t// both agree that rmdir(file) returns ENOTDIR,\n\t// so we can use that to decide which error is real.\n\t// Rmdir might also return ENOTDIR if given a bad\n\t// file path, like /etc/passwd/foo, but in that case,\n\t// both errors will be ENOTDIR, so it's okay to\n\t// use the error from unlink.\n\tif err1 != unix.ENOTDIR {\n\t\terr = err1\n\t}\n\treturn convertErrorType(&PathError{Op: \"remove\", Path: name, Err: err})\n}", "is_vulnerable": 0}
{"code": "func (d *DescriptionEntityManager) ListDescriptionEntity(ctx context.Context, request admin.DescriptionEntityListRequest) (*admin.DescriptionEntityList, error) {\n\t// Check required fields\n\tif err := validation.ValidateDescriptionEntityListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\tif request.ResourceType == core.ResourceType_WORKFLOW {\n\t\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\t} else {\n\t\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\t}\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.ResourceTypeToEntity[request.ResourceType])\n\tif err != nil {\n\t\tlogger.Error(ctx, \"failed to get database filter\")\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.DescriptionEntityColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistDescriptionEntitiesInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := d.db.DescriptionEntityRepo().List(ctx, listDescriptionEntitiesInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tdescriptionEntityList, err := transformers.FromDescriptionEntityModels(output.Entities)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Entities, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\treturn &admin.DescriptionEntityList{\n\t\tDescriptionEntities: descriptionEntityList,\n\t\tToken:               token,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (mr *MockRefreshTokenStrategyMockRecorder) RefreshTokenSignature(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"RefreshTokenSignature\", reflect.TypeOf((*MockRefreshTokenStrategy)(nil).RefreshTokenSignature), arg0)\n}", "is_vulnerable": 0}
{"code": "func (b *BearerTokenAuth) RoundTripper(base http.RoundTripper) (http.RoundTripper, error) {\n\treturn &BearerAuthRoundTripper{\n\t\tbaseTransport:   base,\n\t\tbearerTokenFunc: b.bearerToken,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (va ClawbackVestingAccount) GetUnlockedCoins(blockTime time.Time) sdk.Coins {\n\treturn ReadSchedule(va.GetStartTime(), va.EndTime, va.LockupPeriods, va.OriginalVesting, blockTime.Unix())\n}", "is_vulnerable": 0}
{"code": "func (l *limitedWrappedReaderCloser) Read(p []byte) (n int, err error) {\n\treturn l.underlying.Read(p)\n}", "is_vulnerable": 0}
{"code": "func TestOperatorSigningKeys(t *testing.T) {\n\ts, opts := runOperatorServer(t)\n\tdefer s.Shutdown()\n\n\t// Create an account with a signing key, not the master key.\n\takp := createAccountForOperatorKey(t, s, skSeed)\n\n\t// Make sure we can set system account.\n\tif err := s.SetSystemAccount(publicKeyFromKeyPair(t, akp)); err != nil {\n\t\tt.Fatalf(\"Expected this succeed, got %v\", err)\n\t}\n\n\t// Make sure we can create users with it too.\n\turl := fmt.Sprintf(\"nats://%s:%d\", opts.Host, opts.Port)\n\tnc, err := nats.Connect(url, createUserCreds(t, s, akp))\n\tif err != nil {\n\t\tt.Fatalf(\"Error on connect: %v\", err)\n\t}\n\tnc.Close()\n}", "is_vulnerable": 0}
{"code": "func (p *Plugin) httpOAuth1aDisconnect(w http.ResponseWriter, r *http.Request, instanceID types.ID) (int, error) {\n\tmattermostUserID := r.Header.Get(\"Mattermost-User-Id\")\n\t_, err := p.DisconnectUser(instanceID.String(), types.ID(mattermostUserID))\n\tif err != nil {\n\t\treturn respondErr(w, http.StatusInternalServerError, err)\n\t}\n\n\treturn p.respondSpecialTemplate(w, \"/other/message.html\", http.StatusOK,\n\t\t\"text/html\", struct {\n\t\t\tHeader  string\n\t\t\tMessage string\n\t\t}{\n\t\t\tHeader:  \"Disconnected from Jira.\",\n\t\t\tMessage: \"It is now safe to close this browser window.\",\n\t\t})\n}", "is_vulnerable": 1}
{"code": "func (spt *ServicePrincipalToken) UnmarshalJSON(data []byte) error {\n\t// need to determine the token type\n\traw := map[string]interface{}{}\n\terr := json.Unmarshal(data, &raw)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsecret := raw[\"secret\"].(map[string]interface{})\n\tswitch secret[\"type\"] {\n\tcase \"ServicePrincipalNoSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalNoSecret{}\n\tcase \"ServicePrincipalTokenSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalTokenSecret{}\n\tcase \"ServicePrincipalCertificateSecret\":\n\t\treturn errors.New(\"unmarshalling ServicePrincipalCertificateSecret is not supported\")\n\tcase \"ServicePrincipalMSISecret\":\n\t\treturn errors.New(\"unmarshalling ServicePrincipalMSISecret is not supported\")\n\tcase \"ServicePrincipalUsernamePasswordSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalUsernamePasswordSecret{}\n\tcase \"ServicePrincipalAuthorizationCodeSecret\":\n\t\tspt.inner.Secret = &ServicePrincipalAuthorizationCodeSecret{}\n\tdefault:\n\t\treturn fmt.Errorf(\"unrecognized token type '%s'\", secret[\"type\"])\n\t}\n\terr = json.Unmarshal(data, &spt.inner)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Don't override the refreshLock or the sender if those have been already set.\n\tif spt.refreshLock == nil {\n\t\tspt.refreshLock = &sync.RWMutex{}\n\t}\n\tif spt.sender == nil {\n\t\tspt.sender = sender()\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func ApplyClusterPatches(\n\tpatchContext networking.EnvoyFilter_PatchContext,\n\tproxy *model.Proxy,\n\tpush *model.PushContext,\n\tclusters []*xdsapi.Cluster) (out []*xdsapi.Cluster) {\n\tdefer util.HandleCrash(func() {\n\t\tlog.Errorf(\"clusters patch caused panic, so the patches did not take effect\")\n\t})\n\t// In case the patches cause panic, use the clusters generated before to reduce the influence.\n\tout = clusters\n\n\tenvoyFilterWrappers := push.EnvoyFilters(proxy)\n\tclustersRemoved := false\n\tfor _, efw := range envoyFilterWrappers {\n\t\tfor _, cp := range efw.Patches[networking.EnvoyFilter_CLUSTER] {\n\t\t\tif cp.Operation != networking.EnvoyFilter_Patch_REMOVE &&\n\t\t\t\tcp.Operation != networking.EnvoyFilter_Patch_MERGE {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor i := range clusters {\n\t\t\t\tif clusters[i] == nil {\n\t\t\t\t\t// deleted by the remove operation\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif commonConditionMatch(proxy, patchContext, cp) && clusterMatch(clusters[i], cp) {\n\t\t\t\t\tif cp.Operation == networking.EnvoyFilter_Patch_REMOVE {\n\t\t\t\t\t\tclusters[i] = nil\n\t\t\t\t\t\tclustersRemoved = true\n\t\t\t\t\t} else {\n\t\t\t\t\t\tproto.Merge(clusters[i], cp.Value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Add cluster if the operation is add, and patch context matches\n\t\tfor _, cp := range efw.Patches[networking.EnvoyFilter_CLUSTER] {\n\t\t\tif cp.Operation == networking.EnvoyFilter_Patch_ADD {\n\t\t\t\tif commonConditionMatch(proxy, patchContext, cp) {\n\t\t\t\t\tclusters = append(clusters, proto.Clone(cp.Value).(*xdsapi.Cluster))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif clustersRemoved {\n\t\ttrimmedClusters := make([]*xdsapi.Cluster, 0, len(clusters))\n\t\tfor i := range clusters {\n\t\t\tif clusters[i] == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ttrimmedClusters = append(trimmedClusters, clusters[i])\n\t\t}\n\t\tclusters = trimmedClusters\n\t}\n\treturn clusters\n}", "is_vulnerable": 0}
{"code": "\treturn func(host string, a net.Addr, hostKey ssh.PublicKey) error {\n\t\tclusterCert, ok := hostKey.(*ssh.Certificate)\n\t\tif ok {\n\t\t\thostKey = clusterCert.SignatureKey\n\t\t}\n\t\tfor _, trustedKey := range trustedKeys {\n\t\t\tif KeysEqual(trustedKey, hostKey) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn trace.AccessDenied(\"host %v is untrusted or Teleport CA has been rotated; try getting new credentials by logging in again ('tsh login') or re-exporting the identity file ('tctl auth sign' or 'tsh login -o'), depending on how you got them initially\", host)\n\t}, nil", "is_vulnerable": 1}
{"code": "func TestIngressAnnotationServiceUpstreamSetFalse(t *testing.T) {\n\ting := buildIngress()\n\n\t// Test with explicitly set to false\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"service-upstream\")] = \"false\"\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\tenabled, ok := val.(bool)\n\tif !ok {\n\t\tt.Errorf(\"expected a bool type\")\n\t}\n\n\tif enabled {\n\t\tt.Errorf(\"expected annotation value to be false, got true\")\n\t}\n\n\t// Test with no annotation specified, should default to false\n\tdata = map[string]string{}\n\ting.SetAnnotations(data)\n\n\tval, _ = NewParser(&resolver.Mock{}).Parse(ing)\n\tenabled, ok = val.(bool)\n\tif !ok {\n\t\tt.Errorf(\"expected a bool type\")\n\t}\n\n\tif enabled {\n\t\tt.Errorf(\"expected annotation value to be false, got true\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestBuildVersion3RegionQueries(t *testing.T) {\n\tdb, mock, err := sqlmock.New()\n\trequire.NoError(t, err)\n\tdefer func() {\n\t\trequire.NoError(t, db.Close())\n\t}()\n\n\tconn, err := db.Conn(context.Background())\n\trequire.NoError(t, err)\n\tbaseConn := newBaseConn(conn, true, nil)\n\ttctx, cancel := tcontext.Background().WithLogger(appLogger).WithCancel()\n\toldOpenFunc := openDBFunc\n\tdefer func() {\n\t\topenDBFunc = oldOpenFunc\n\t}()\n\topenDBFunc = func(_, _ string) (*sql.DB, error) {\n\t\treturn db, nil\n\t}\n\n\tconf := DefaultConfig()\n\tconf.ServerInfo = version.ServerInfo{\n\t\tHasTiKV:       true,\n\t\tServerType:    version.ServerTypeTiDB,\n\t\tServerVersion: decodeRegionVersion,\n\t}\n\tdatabase := \"test\"\n\tconf.Tables = DatabaseTables{\n\t\tdatabase: []*TableInfo{\n\t\t\t{\"t1\", 0, TableTypeBase},\n\t\t\t{\"t2\", 0, TableTypeBase},\n\t\t\t{\"t3\", 0, TableTypeBase},\n\t\t\t{\"t4\", 0, TableTypeBase},\n\t\t},\n\t}\n\tmetrics := newMetrics(promutil.NewDefaultFactory(), nil)\n\n\td := &Dumper{\n\t\ttctx:                      tctx,\n\t\tconf:                      conf,\n\t\tcancelCtx:                 cancel,\n\t\tmetrics:                   metrics,\n\t\tselectTiDBTableRegionFunc: selectTiDBTableRegion,\n\t}\n\tshowStatsHistograms := buildMockNewRows(mock, []string{\"Db_name\", \"Table_name\", \"Partition_name\", \"Column_name\", \"Is_index\", \"Update_time\", \"Distinct_count\", \"Null_count\", \"Avg_col_size\", \"Correlation\"},\n\t\t[][]driver.Value{\n\t\t\t{\"test\", \"t2\", \"p0\", \"a\", 0, \"2021-06-27 17:43:51\", 1999999, 0, 8, 0},\n\t\t\t{\"test\", \"t2\", \"p1\", \"a\", 0, \"2021-06-22 20:30:16\", 1260000, 0, 8, 0},\n\t\t\t{\"test\", \"t2\", \"p2\", \"a\", 0, \"2021-06-22 20:32:16\", 1230000, 0, 8, 0},\n\t\t\t{\"test\", \"t2\", \"p3\", \"a\", 0, \"2021-06-22 20:36:19\", 2000000, 0, 8, 0},\n\t\t\t{\"test\", \"t1\", \"\", \"a\", 0, \"2021-04-22 15:23:58\", 7100000, 0, 8, 0},\n\t\t\t{\"test\", \"t3\", \"\", \"PRIMARY\", 1, \"2021-06-27 22:08:43\", 4980000, 0, 0, 0},\n\t\t\t{\"test\", \"t4\", \"p0\", \"PRIMARY\", 1, \"2021-06-28 10:54:06\", 2000000, 0, 0, 0},\n\t\t\t{\"test\", \"t4\", \"p1\", \"PRIMARY\", 1, \"2021-06-28 10:55:04\", 1300000, 0, 0, 0},\n\t\t\t{\"test\", \"t4\", \"p2\", \"PRIMARY\", 1, \"2021-06-28 10:57:05\", 1830000, 0, 0, 0},\n\t\t\t{\"test\", \"t4\", \"p3\", \"PRIMARY\", 1, \"2021-06-28 10:59:04\", 2000000, 0, 0, 0},\n\t\t\t{\"mysql\", \"global_priv\", \"\", \"PRIMARY\", 1, \"2021-06-04 20:39:44\", 0, 0, 0, 0},\n\t\t})\n\tselectMySQLStatsHistograms := buildMockNewRows(mock, []string{\"TABLE_ID\", \"VERSION\", \"DISTINCT_COUNT\"},\n\t\t[][]driver.Value{\n\t\t\t{15, \"1970-01-01 08:00:00\", 0},\n\t\t\t{15, \"1970-01-01 08:00:00\", 0},\n\t\t\t{15, \"1970-01-01 08:00:00\", 0},\n\t\t\t{41, \"2021-04-22 15:23:58\", 7100000},\n\t\t\t{41, \"2021-04-22 15:23:59\", 7100000},\n\t\t\t{41, \"2021-04-22 15:23:59\", 7100000},\n\t\t\t{41, \"2021-04-22 15:23:59\", 7100000},\n\t\t\t{27, \"1970-01-01 08:00:00\", 0},\n\t\t\t{27, \"1970-01-01 08:00:00\", 0},\n\t\t\t{25, \"1970-01-01 08:00:00\", 0},\n\t\t\t{25, \"1970-01-01 08:00:00\", 0},\n\t\t\t{2098, \"2021-06-04 20:39:41\", 0},\n\t\t\t{2101, \"2021-06-04 20:39:44\", 0},\n\t\t\t{2101, \"2021-06-04 20:39:44\", 0},\n\t\t\t{2101, \"2021-06-04 20:39:44\", 0},\n\t\t\t{2101, \"2021-06-04 20:39:44\", 0},\n\t\t\t{2128, \"2021-06-22 20:29:19\", 1991680},\n\t\t\t{2128, \"2021-06-22 20:29:19\", 1991680},\n\t\t\t{2128, \"2021-06-22 20:29:19\", 1991680},\n\t\t\t{2129, \"2021-06-22 20:30:16\", 1260000},\n\t\t\t{2129, \"2021-06-22 20:30:16\", 1237120},\n\t\t\t{2129, \"2021-06-22 20:30:16\", 1237120},\n\t\t\t{2129, \"2021-06-22 20:30:16\", 1237120},\n\t\t\t{2130, \"2021-06-22 20:32:16\", 1230000},\n\t\t\t{2130, \"2021-06-22 20:32:16\", 1216128},\n\t\t\t{2130, \"2021-06-22 20:32:17\", 1216128},\n\t\t\t{2130, \"2021-06-22 20:32:17\", 1216128},\n\t\t\t{2131, \"2021-06-22 20:36:19\", 2000000},\n\t\t\t{2131, \"2021-06-22 20:36:19\", 1959424},\n\t\t\t{2131, \"2021-06-22 20:36:19\", 1959424},\n\t\t\t{2131, \"2021-06-22 20:36:19\", 1959424},\n\t\t\t{2128, \"2021-06-27 17:43:51\", 1999999},\n\t\t\t{2136, \"2021-06-27 22:08:38\", 4860000},\n\t\t\t{2136, \"2021-06-27 22:08:38\", 4860000},\n\t\t\t{2136, \"2021-06-27 22:08:38\", 4860000},\n\t\t\t{2136, \"2021-06-27 22:08:38\", 4860000},\n\t\t\t{2136, \"2021-06-27 22:08:43\", 4980000},\n\t\t\t{2139, \"2021-06-28 10:54:05\", 1991680},\n\t\t\t{2139, \"2021-06-28 10:54:05\", 1991680},\n\t\t\t{2139, \"2021-06-28 10:54:05\", 1991680},\n\t\t\t{2139, \"2021-06-28 10:54:05\", 1991680},\n\t\t\t{2139, \"2021-06-28 10:54:06\", 2000000},\n\t\t\t{2140, \"2021-06-28 10:55:02\", 1246336},\n\t\t\t{2140, \"2021-06-28 10:55:02\", 1246336},\n\t\t\t{2140, \"2021-06-28 10:55:02\", 1246336},\n\t\t\t{2140, \"2021-06-28 10:55:03\", 1246336},\n\t\t\t{2140, \"2021-06-28 10:55:04\", 1300000},\n\t\t\t{2141, \"2021-06-28 10:57:03\", 1780000},\n\t\t\t{2141, \"2021-06-28 10:57:03\", 1780000},\n\t\t\t{2141, \"2021-06-28 10:57:03\", 1780000},\n\t\t\t{2141, \"2021-06-28 10:57:03\", 1780000},\n\t\t\t{2141, \"2021-06-28 10:57:05\", 1830000},\n\t\t\t{2142, \"2021-06-28 10:59:03\", 1959424},\n\t\t\t{2142, \"2021-06-28 10:59:03\", 1959424},\n\t\t\t{2142, \"2021-06-28 10:59:03\", 1959424},\n\t\t\t{2142, \"2021-06-28 10:59:03\", 1959424},\n\t\t\t{2142, \"2021-06-28 10:59:04\", 2000000},\n\t\t})\n\tselectRegionStatusHistograms := buildMockNewRows(mock, []string{\"REGION_ID\", \"START_KEY\", \"END_KEY\"}, readRegionCsvDriverValues(t))\n\tselectInformationSchemaTables := buildMockNewRows(mock, []string{\"TABLE_SCHEMA\", \"TABLE_NAME\", \"TIDB_TABLE_ID\"},\n\t\t[][]driver.Value{\n\t\t\t{\"mysql\", \"expr_pushdown_blacklist\", 39},\n\t\t\t{\"mysql\", \"user\", 5},\n\t\t\t{\"mysql\", \"db\", 7},\n\t\t\t{\"mysql\", \"tables_priv\", 9},\n\t\t\t{\"mysql\", \"stats_top_n\", 37},\n\t\t\t{\"mysql\", \"columns_priv\", 11},\n\t\t\t{\"mysql\", \"bind_info\", 35},\n\t\t\t{\"mysql\", \"default_roles\", 33},\n\t\t\t{\"mysql\", \"role_edges\", 31},\n\t\t\t{\"mysql\", \"stats_feedback\", 29},\n\t\t\t{\"mysql\", \"gc_delete_range_done\", 27},\n\t\t\t{\"mysql\", \"gc_delete_range\", 25},\n\t\t\t{\"mysql\", \"help_topic\", 17},\n\t\t\t{\"mysql\", \"global_priv\", 2101},\n\t\t\t{\"mysql\", \"stats_histograms\", 21},\n\t\t\t{\"mysql\", \"opt_rule_blacklist\", 2098},\n\t\t\t{\"mysql\", \"stats_meta\", 19},\n\t\t\t{\"mysql\", \"stats_buckets\", 23},\n\t\t\t{\"mysql\", \"tidb\", 15},\n\t\t\t{\"mysql\", \"GLOBAL_VARIABLES\", 13},\n\t\t\t{\"test\", \"t2\", 2127},\n\t\t\t{\"test\", \"t1\", 41},\n\t\t\t{\"test\", \"t3\", 2136},\n\t\t\t{\"test\", \"t4\", 2138},\n\t\t})\n\tmock.ExpectQuery(\"SHOW STATS_HISTOGRAMS\").\n\t\tWillReturnRows(showStatsHistograms)\n\tmock.ExpectQuery(\"SELECT TABLE_ID,FROM_UNIXTIME\").\n\t\tWillReturnRows(selectMySQLStatsHistograms)\n\tmock.ExpectQuery(\"SELECT TABLE_SCHEMA,TABLE_NAME,TIDB_TABLE_ID FROM INFORMATION_SCHEMA.TABLES ORDER BY TABLE_SCHEMA\").\n\t\tWillReturnRows(selectInformationSchemaTables)\n\tmock.ExpectQuery(\"SELECT REGION_ID,START_KEY,END_KEY FROM INFORMATION_SCHEMA.TIKV_REGION_STATUS ORDER BY START_KEY;\").\n\t\tWillReturnRows(selectRegionStatusHistograms)\n\n\trequire.NoError(t, d.renewSelectTableRegionFuncForLowerTiDB(tctx))\n\trequire.NoError(t, mock.ExpectationsWereMet())\n\n\ttestCases := []struct {\n\t\ttableName            string\n\t\thandleColNames       []string\n\t\thandleColTypes       []string\n\t\texpectedWhereClauses []string\n\t\thasTiDBRowID         bool\n\t}{\n\t\t{\n\t\t\t\"t1\",\n\t\t\t[]string{\"a\"},\n\t\t\t[]string{\"INT\"},\n\t\t\t[]string{\n\t\t\t\t\"`a`<960001\",\n\t\t\t\t\"`a`>=960001 and `a`<1920001\",\n\t\t\t\t\"`a`>=1920001 and `a`<2880001\",\n\t\t\t\t\"`a`>=2880001 and `a`<3840001\",\n\t\t\t\t\"`a`>=3840001 and `a`<4800001\",\n\t\t\t\t\"`a`>=4800001 and `a`<5760001\",\n\t\t\t\t\"`a`>=5760001 and `a`<6720001\",\n\t\t\t\t\"`a`>=6720001\",\n\t\t\t},\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"t2\",\n\t\t\t[]string{\"a\"},\n\t\t\t[]string{\"INT\"},\n\t\t\t[]string{\n\t\t\t\t\"`a`<960001\",\n\t\t\t\t\"`a`>=960001 and `a`<2960001\",\n\t\t\t\t\"`a`>=2960001 and `a`<4960001\",\n\t\t\t\t\"`a`>=4960001 and `a`<6960001\",\n\t\t\t\t\"`a`>=6960001\",\n\t\t\t},\n\t\t\tfalse,\n\t\t},\n\t\t{\n\t\t\t\"t3\",\n\t\t\t[]string{\"_tidb_rowid\"},\n\t\t\t[]string{\"BIGINT\"},\n\t\t\t[]string{\n\t\t\t\t\"`_tidb_rowid`<81584\",\n\t\t\t\t\"`_tidb_rowid`>=81584 and `_tidb_rowid`<1041584\",\n\t\t\t\t\"`_tidb_rowid`>=1041584 and `_tidb_rowid`<2001584\",\n\t\t\t\t\"`_tidb_rowid`>=2001584 and `_tidb_rowid`<2961584\",\n\t\t\t\t\"`_tidb_rowid`>=2961584 and `_tidb_rowid`<3921584\",\n\t\t\t\t\"`_tidb_rowid`>=3921584 and `_tidb_rowid`<4881584\",\n\t\t\t\t\"`_tidb_rowid`>=4881584 and `_tidb_rowid`<5841584\",\n\t\t\t\t\"`_tidb_rowid`>=5841584 and `_tidb_rowid`<6801584\",\n\t\t\t\t\"`_tidb_rowid`>=6801584\",\n\t\t\t},\n\t\t\ttrue,\n\t\t},\n\t\t{\n\t\t\t\"t4\",\n\t\t\t[]string{\"_tidb_rowid\"},\n\t\t\t[]string{\"BIGINT\"},\n\t\t\t[]string{\n\t\t\t\t\"`_tidb_rowid`<180001\",\n\t\t\t\t\"`_tidb_rowid`>=180001 and `_tidb_rowid`<1140001\",\n\t\t\t\t\"`_tidb_rowid`>=1140001 and `_tidb_rowid`<2200001\",\n\t\t\t\t\"`_tidb_rowid`>=2200001 and `_tidb_rowid`<3160001\",\n\t\t\t\t\"`_tidb_rowid`>=3160001 and `_tidb_rowid`<4160001\",\n\t\t\t\t\"`_tidb_rowid`>=4160001 and `_tidb_rowid`<5120001\",\n\t\t\t\t\"`_tidb_rowid`>=5120001 and `_tidb_rowid`<6170001\",\n\t\t\t\t\"`_tidb_rowid`>=6170001 and `_tidb_rowid`<7130001\",\n\t\t\t\t\"`_tidb_rowid`>=7130001\",\n\t\t\t},\n\t\t\ttrue,\n\t\t},\n\t}\n\n\tfor i, testCase := range testCases {\n\t\tt.Logf(\"case #%d\", i)\n\t\ttable := testCase.tableName\n\t\thandleColNames := testCase.handleColNames\n\t\thandleColTypes := testCase.handleColTypes\n\n\t\t// Test build tasks through table region\n\t\ttaskChan := make(chan Task, 128)\n\t\tmeta := &mockTableIR{\n\t\t\tdbName:           database,\n\t\t\ttblName:          table,\n\t\t\tselectedField:    \"*\",\n\t\t\thasImplicitRowID: testCase.hasTiDBRowID,\n\t\t\tcolNames:         handleColNames,\n\t\t\tcolTypes:         handleColTypes,\n\t\t\tspecCmt: []string{\n\t\t\t\t\"/*!40101 SET NAMES binary*/;\",\n\t\t\t},\n\t\t}\n\n\t\tif !testCase.hasTiDBRowID {\n\t\t\trows := sqlmock.NewRows(showIndexHeaders)\n\t\t\tfor i, handleColName := range handleColNames {\n\t\t\t\trows.AddRow(table, 0, \"PRIMARY\", i, handleColName, \"A\", 0, nil, nil, \"\", \"BTREE\", \"\", \"\")\n\t\t\t}\n\t\t\tmock.ExpectQuery(fmt.Sprintf(\"SHOW INDEX FROM `%s`.`%s`\", database, table)).WillReturnRows(rows)\n\t\t}\n\n\t\torderByClause := buildOrderByClauseString(handleColNames)\n\t\trequire.NoError(t, d.concurrentDumpTable(tctx, baseConn, meta, taskChan))\n\t\trequire.NoError(t, mock.ExpectationsWereMet())\n\n\t\tchunkIdx := 0\n\t\tfor _, w := range testCase.expectedWhereClauses {\n\t\t\tquery := buildSelectQuery(database, table, \"*\", \"\", buildWhereCondition(d.conf, w), orderByClause)\n\t\t\ttask := <-taskChan\n\t\t\ttaskTableData, ok := task.(*TaskTableData)\n\t\t\trequire.True(t, ok)\n\t\t\trequire.Equal(t, chunkIdx, taskTableData.ChunkIndex)\n\n\t\t\tdata, ok := taskTableData.Data.(*tableData)\n\t\t\trequire.True(t, ok)\n\t\t\trequire.Equal(t, query, data.query)\n\n\t\t\tchunkIdx++\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func WriteAuthorizationModelTest(t *testing.T, datastore storage.OpenFGADatastore) {\n\tstoreID, err := id.NewString()\n\trequire.NoError(t, err)\n\n\titems := make([]*openfgapb.TypeDefinition, datastore.MaxTypesInTypeDefinition()+1)\n\tfor i := 0; i < datastore.MaxTypesInTypeDefinition(); i++ {\n\t\titems[i] = &openfgapb.TypeDefinition{\n\t\t\tType: fmt.Sprintf(\"type%v\", i),\n\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\"admin\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t},\n\t\t}\n\t}\n\n\tvar tests = []struct {\n\t\tname    string\n\t\trequest *openfgapb.WriteAuthorizationModelRequest\n\t\terr     error\n\t}{\n\t\t{\n\t\t\tname: \"succeeds\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"admin\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"succeeds part II\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: \"somestoreid\",\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"group\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"owner\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{Relation: \"writer\"},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tTupleset:        &openfgapb.ObjectRelation{Relation: \"owner\"},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{Relation: \"member\"},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"fails if too many types\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId:         storeID,\n\t\t\t\tTypeDefinitions: items,\n\t\t\t},\n\t\t\terr: serverErrors.ExceededEntityLimit(\"type definitions in an authorization model\", datastore.MaxTypesInTypeDefinition()),\n\t\t},\n\t\t{\n\t\t\tname: \"empty relations is valid\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"zero length relations is valid\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType:      \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfSameTypeTwice\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"admin\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"admin\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.ErrDuplicateTypes),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfEmptyRewrites\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"owner\": {},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.InvalidRelationError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInComputedUserset\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tObject:   \"\",\n\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInTupleToUserset\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInUnion\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInDifferenceBaseArgument\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInDifferenceSubtractArgument\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInTupleToUsersetTupleset\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"from\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInTupleToUsersetComputedUserset\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfTupleToUsersetReferencesUnknownRelation\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"foo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"reader\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"bar\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"owner\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"bar\", \"writer\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnknownRelationInIntersection\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"writer\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.RelationDoesNotExistError(\"repo\", \"owner\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfDifferenceIncludesSameRelationTwice\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.InvalidRelationError(\"repo\", \"viewer\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfUnionIncludesSameRelationTwice\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.InvalidRelationError(\"repo\", \"viewer\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWriteFailsIfIntersectionIncludesSameRelationTwice\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"repo\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(typesystem.InvalidRelationError(\"repo\", \"viewer\")),\n\t\t},\n\t\t{\n\t\t\tname: \"Union Rewrite Contains Repeated Definitions\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\t\"viewer\": typesystem.Union(\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\"editor\": typesystem.Union(typesystem.This(), typesystem.This()),\n\t\t\t\t\t\t\t\"manage\": typesystem.Union(\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Intersection Rewrite Contains Repeated Definitions\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\t\"viewer\": typesystem.Intersection(\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\"editor\": typesystem.Intersection(typesystem.This(), typesystem.This()),\n\t\t\t\t\t\t\t\"manage\": typesystem.Intersection(\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Exclusion Rewrite Contains Repeated Definitions\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\t\"viewer\": typesystem.Difference(\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t\ttypesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\"editor\": typesystem.Difference(typesystem.This(), typesystem.This()),\n\t\t\t\t\t\t\t\"manage\": typesystem.Difference(\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t\ttypesystem.TupleToUserset(\"parent\", \"manage\"),\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Tupleset relation involves ComputedUserset rewrite\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"ancestor\": typesystem.This(),\n\t\t\t\t\t\t\t\"parent\":   typesystem.ComputedUserset(\"ancestor\"),\n\t\t\t\t\t\t\t\"viewer\":   typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"the 'document#parent' relation is referenced in at least one tupleset and thus must be a direct relation\"),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname: \"Tupleset relation involves Union rewrite\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"ancestor\": typesystem.This(),\n\t\t\t\t\t\t\t\"parent\":   typesystem.Union(typesystem.This(), typesystem.ComputedUserset(\"ancestor\")),\n\t\t\t\t\t\t\t\"viewer\":   typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"the 'document#parent' relation is referenced in at least one tupleset and thus must be a direct relation\"),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname: \"Tupleset relation involves Intersection rewrite\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"ancestor\": typesystem.This(),\n\t\t\t\t\t\t\t\"parent\":   typesystem.Intersection(typesystem.This(), typesystem.ComputedUserset(\"ancestor\")),\n\t\t\t\t\t\t\t\"viewer\":   typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"the 'document#parent' relation is referenced in at least one tupleset and thus must be a direct relation\"),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname: \"Tupleset relation involves Exclusion rewrite\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"restricted\": typesystem.This(),\n\t\t\t\t\t\t\t\"parent\":     typesystem.Difference(typesystem.This(), typesystem.ComputedUserset(\"restricted\")),\n\t\t\t\t\t\t\t\"viewer\":     typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"the 'document#parent' relation is referenced in at least one tupleset and thus must be a direct relation\"),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname: \"Tupleset relation involves TupleToUserset rewrite\",\n\t\t\trequest: &openfgapb.WriteAuthorizationModelRequest{\n\t\t\t\tStoreId: storeID,\n\t\t\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t\t{\n\t\t\t\t\t\tType: \"document\",\n\t\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\t\"ancestor\": typesystem.This(),\n\t\t\t\t\t\t\t\"parent\":   typesystem.TupleToUserset(\"ancestor\", \"viewer\"),\n\t\t\t\t\t\t\t\"viewer\":   typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"the 'document#parent' relation is referenced in at least one tupleset and thus must be a direct relation\"),\n\t\t\t),\n\t\t},\n\t}\n\n\tctx := context.Background()\n\tlogger := logger.NewNoopLogger()\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tcmd := commands.NewWriteAuthorizationModelCommand(datastore, logger)\n\t\t\tresp, err := cmd.Execute(ctx, test.request)\n\t\t\trequire.ErrorIs(t, err, test.err)\n\n\t\t\tif err == nil {\n\t\t\t\trequire.True(t, id.IsValid(resp.AuthorizationModelId))\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func IsRiskyAnnotationError(e error) bool {\n\t_, ok := e.(ValidationError)\n\treturn ok\n}", "is_vulnerable": 0}
{"code": "func (c *configurations) Supported() bool {\n\treturn c.platform == \"kubernetes\" || c.platform == \"standalone\"\n}", "is_vulnerable": 1}
{"code": "func (maap *MesheryApplicationPersister) GetMesheryApplications(search, order string, page, pageSize uint64, updatedAfter string) ([]byte, error) {\n\torder = SanitizeOrderInput(order, []string{\"created_at\", \"updated_at\", \"name\"})\n\n\tif order == \"\" {\n\t\torder = \"updated_at desc\"\n\t}\n\n\tcount := int64(0)\n\tapplications := []*MesheryApplication{}\n\n\tquery := maap.DB.Where(\"updated_at > ?\", updatedAfter).Order(order)\n\n\tif search != \"\" {\n\t\tlike := \"%\" + strings.ToLower(search) + \"%\"\n\t\tquery = query.Where(\"(lower(meshery_applications.name) like ?)\", like)\n\t}\n\n\tquery.Table(\"meshery_applications\").Count(&count)\n\n\tPaginate(uint(page), uint(pageSize))(query).Find(&applications)\n\n\tmesheryApplicationPage := &MesheryApplicationPage{\n\t\tPage:         page,\n\t\tPageSize:     pageSize,\n\t\tTotalCount:   int(count),\n\t\tApplications: applications,\n\t}\n\n\treturn marshalMesheryApplicationPage(mesheryApplicationPage), nil\n}", "is_vulnerable": 0}
{"code": "\trequire.Panics(t, func() {\n\t\t_ = limits.markAlreadyPublished(1)\n\t})", "is_vulnerable": 0}
{"code": "func NewCryptoManager(config_obj *config_proto.Config,\n\tclient_id string,\n\tprivate_key_pem []byte,\n\tpublic_key_resolver PublicKeyResolver,\n\tlogger *logging.LogContext) (\n\t*CryptoManager, error) {\n\tprivate_key, err := crypto_utils.ParseRsaPrivateKeyFromPemStr(private_key_pem)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &CryptoManager{\n\t\tconfig:      config_obj,\n\t\tprivate_key: private_key,\n\t\tclient_id:   client_id,\n\t\tResolver:    public_key_resolver,\n\t\tcipher_lru:  NewCipherLRU(config_obj.Frontend.Resources.ExpectedClients),\n\t\tlogger:      logging.GetLogger(config_obj, &logging.ClientComponent),\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func GetGitAuth(gitURL string) (*gitHttp.BasicAuth, error) {\n\tlogger := clog.NewLogger(slog.Default()) // TODO: plumb through context, everywhere\n\n\tparsedURL, err := ParseGitURL(gitURL)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse git URL %q: %w\", gitURL, err)\n\t}\n\n\t// Only use GITHUB_TOKEN for github.com URLs\n\tif parsedURL.Host != \"github.com\" {\n\t\tlogger.Warnf(\"host %q is not github.com, not using GITHUB_TOKEN for authentication\", parsedURL.Host)\n\t\treturn nil, nil\n\t}\n\n\tgitToken := os.Getenv(\"GITHUB_TOKEN\")\n\n\tif gitToken == \"\" {\n\t\t// If the token is empty, there's no way we can return a usable authentication\n\t\t// anyway. Whereas if we return nil, and don't auth, we have a chance at\n\t\t// succeeding with access of a public repo.\n\t\treturn &gitHttp.BasicAuth{}, nil\n\t}\n\n\treturn &gitHttp.BasicAuth{\n\t\tUsername: \"abc123\",\n\t\tPassword: gitToken,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestGenerateContainerConfigWithMemoryQoSEnforced(t *testing.T) {\n\t_, _, m, err := createTestRuntimeManager()\n\tassert.NoError(t, err)\n\n\tpod1 := &v1.Pod{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tUID:       \"12345678\",\n\t\t\tName:      \"bar\",\n\t\t\tNamespace: \"new\",\n\t\t},\n\t\tSpec: v1.PodSpec{\n\t\t\tContainers: []v1.Container{\n\t\t\t\t{\n\t\t\t\t\tName:            \"foo\",\n\t\t\t\t\tImage:           \"busybox\",\n\t\t\t\t\tImagePullPolicy: v1.PullIfNotPresent,\n\t\t\t\t\tCommand:         []string{\"testCommand\"},\n\t\t\t\t\tWorkingDir:      \"testWorkingDir\",\n\t\t\t\t\tResources: v1.ResourceRequirements{\n\t\t\t\t\t\tRequests: v1.ResourceList{\n\t\t\t\t\t\t\tv1.ResourceMemory: resource.MustParse(\"128Mi\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tLimits: v1.ResourceList{\n\t\t\t\t\t\t\tv1.ResourceMemory: resource.MustParse(\"256Mi\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tpod2 := &v1.Pod{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tUID:       \"12345678\",\n\t\t\tName:      \"bar\",\n\t\t\tNamespace: \"new\",\n\t\t},\n\t\tSpec: v1.PodSpec{\n\t\t\tContainers: []v1.Container{\n\t\t\t\t{\n\t\t\t\t\tName:            \"foo\",\n\t\t\t\t\tImage:           \"busybox\",\n\t\t\t\t\tImagePullPolicy: v1.PullIfNotPresent,\n\t\t\t\t\tCommand:         []string{\"testCommand\"},\n\t\t\t\t\tWorkingDir:      \"testWorkingDir\",\n\t\t\t\t\tResources: v1.ResourceRequirements{\n\t\t\t\t\t\tRequests: v1.ResourceList{\n\t\t\t\t\t\t\tv1.ResourceMemory: resource.MustParse(\"128Mi\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tmemoryNodeAllocatable := resource.MustParse(fakeNodeAllocatableMemory)\n\tpod2MemoryHigh := float64(memoryNodeAllocatable.Value()) * m.memoryThrottlingFactor\n\n\ttype expectedResult struct {\n\t\tcontainerConfig *runtimeapi.LinuxContainerConfig\n\t\tmemoryLow       int64\n\t\tmemoryHigh      int64\n\t}\n\tl1, _ := m.generateLinuxContainerConfig(&pod1.Spec.Containers[0], pod1, new(int64), \"\", nil, true)\n\tl2, _ := m.generateLinuxContainerConfig(&pod2.Spec.Containers[0], pod2, new(int64), \"\", nil, true)\n\ttests := []struct {\n\t\tname     string\n\t\tpod      *v1.Pod\n\t\texpected *expectedResult\n\t}{\n\t\t{\n\t\t\tname: \"Request128MBLimit256MB\",\n\t\t\tpod:  pod1,\n\t\t\texpected: &expectedResult{\n\t\t\t\tl1,\n\t\t\t\t128 * 1024 * 1024,\n\t\t\t\tint64(float64(256*1024*1024) * m.memoryThrottlingFactor),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Request128MBWithoutLimit\",\n\t\t\tpod:  pod2,\n\t\t\texpected: &expectedResult{\n\t\t\t\tl2,\n\t\t\t\t128 * 1024 * 1024,\n\t\t\t\tint64(pod2MemoryHigh),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tlinuxConfig, err := m.generateLinuxContainerConfig(&test.pod.Spec.Containers[0], test.pod, new(int64), \"\", nil, true)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, test.expected.containerConfig, linuxConfig, test.name)\n\t\tassert.Equal(t, linuxConfig.GetResources().GetUnified()[\"memory.min\"], strconv.FormatInt(test.expected.memoryLow, 10), test.name)\n\t\tassert.Equal(t, linuxConfig.GetResources().GetUnified()[\"memory.high\"], strconv.FormatInt(test.expected.memoryHigh, 10), test.name)\n\t}\n}", "is_vulnerable": 0}
{"code": "\terr := atxs.IterateIDsByEpoch(db, e1, func(total int, id types.ATXID) error {\n\t\trequire.Equal(t, 4, total)\n\t\tdelete(m, id)\n\t\tn++\n\t\tif n >= 2 {\n\t\t\treturn errors.New(\"test error\")\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "func ForceRemount() LocalMounterOpt {\n\treturn func(lm *localMounter) {\n\t\tlm.forceRemount = true\n\t}\n}", "is_vulnerable": 0}
{"code": "func (g *HgGetter) clone(ctx context.Context, dst string, u *url.URL) error {\n\tcmd := exec.CommandContext(ctx, \"hg\", \"clone\", \"-U\", \"--\", u.String(), dst)\n\treturn getRunCommand(cmd)\n}", "is_vulnerable": 0}
{"code": "func QueryDbToArray(db *sql.DB, toLower bool, sqlStatement string, sqlParams ...interface{}) ([][]string, error) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t}()\n\n\tSqlSafe(&sqlStatement)\n\n\tvar results [][]string\n\tif strings.HasPrefix(strings.ToUpper(sqlStatement), \"SELECT\") {\n\t\trows, err := db.Query(sqlStatement, sqlParams...)\n\t\tif err != nil {\n\t\t\treturn results, err\n\t\t}\n\t\tcols, _ := rows.Columns()\n\t\tif toLower {\n\t\t\tcolsLower := make([]string, len(cols))\n\t\t\tfor i, v := range cols {\n\t\t\t\tcolsLower[i] = strings.ToLower(v)\n\t\t\t}\n\t\t\tresults = append(results, colsLower)\n\t\t} else {\n\t\t\tresults = append(results, cols)\n\t\t}\n\n\t\trawResult := make([][]byte, len(cols))\n\n\t\tdest := make([]interface{}, len(cols)) // A temporary interface{} slice\n\t\tfor i, _ := range rawResult {\n\t\t\tdest[i] = &rawResult[i] // Put pointers to each string in the interface slice\n\t\t}\n\n\t\tfor rows.Next() {\n\t\t\tresult := make([]string, len(cols))\n\t\t\trows.Scan(dest...)\n\t\t\tfor i, raw := range rawResult {\n\t\t\t\tif raw == nil {\n\t\t\t\t\tresult[i] = \"\"\n\t\t\t\t} else {\n\t\t\t\t\tresult[i] = string(raw)\n\t\t\t\t}\n\t\t\t}\n\t\t\tresults = append(results, result)\n\t\t}\n\t}\n\treturn results, nil\n}", "is_vulnerable": 0}
{"code": "func (s *KeyAgentTestSuite) TestLoadKey(c *check.C) {\n\tuserdata := []byte(\"hello, world\")\n\n\t// make a new local agent\n\tkeystore, err := NewFSLocalKeyStore(s.keyDir)\n\tc.Assert(err, check.IsNil)\n\tlka, err := NewLocalAgent(keystore, s.hostname, s.username, AddKeysToAgentAuto)\n\tc.Assert(err, check.IsNil)\n\n\t// unload any keys that might be in the agent for this user\n\terr = lka.UnloadKey()\n\tc.Assert(err, check.IsNil)\n\n\t// get all the keys in the teleport and system agent\n\tteleportAgentKeys, err := lka.Agent.List()\n\tc.Assert(err, check.IsNil)\n\tteleportAgentInitialKeyCount := len(teleportAgentKeys)\n\tsystemAgentKeys, err := lka.sshAgent.List()\n\tc.Assert(err, check.IsNil)\n\tsystemAgentInitialKeyCount := len(systemAgentKeys)\n\n\t// load the key to the twice, this should only\n\t// result in one key for this user in the agent\n\t_, err = lka.LoadKey(*s.key)\n\tc.Assert(err, check.IsNil)\n\t_, err = lka.LoadKey(*s.key)\n\tc.Assert(err, check.IsNil)\n\n\t// get all the keys in the teleport and system agent\n\tteleportAgentKeys, err = lka.Agent.List()\n\tc.Assert(err, check.IsNil)\n\tsystemAgentKeys, err = lka.sshAgent.List()\n\tc.Assert(err, check.IsNil)\n\n\t// check if we have the correct counts\n\tc.Assert(teleportAgentKeys, check.HasLen, teleportAgentInitialKeyCount+2)\n\tc.Assert(systemAgentKeys, check.HasLen, systemAgentInitialKeyCount+2)\n\n\t// now sign data using the teleport agent and system agent\n\tteleportAgentSignature, err := lka.Agent.Sign(teleportAgentKeys[0], userdata)\n\tc.Assert(err, check.IsNil)\n\tsystemAgentSignature, err := lka.sshAgent.Sign(systemAgentKeys[0], userdata)\n\tc.Assert(err, check.IsNil)\n\n\t// parse the pem bytes for the private key, create a signer, and extract the public key\n\tsshPrivateKey, err := ssh.ParseRawPrivateKey(s.key.Priv)\n\tc.Assert(err, check.IsNil)\n\tsshSigner, err := ssh.NewSignerFromKey(sshPrivateKey)\n\tc.Assert(err, check.IsNil)\n\tsshPublicKey := sshSigner.PublicKey()\n\n\t// verify data signed by both the teleport agent and system agent was signed correctly\n\terr = sshPublicKey.Verify(userdata, teleportAgentSignature)\n\tc.Assert(err, check.IsNil)\n\terr = sshPublicKey.Verify(userdata, systemAgentSignature)\n\tc.Assert(err, check.IsNil)\n\n\t// unload all keys from the teleport agent and system agent\n\terr = lka.UnloadKey()\n\tc.Assert(err, check.IsNil)\n}", "is_vulnerable": 1}
{"code": "func (a *Assertions) YAMLEqf(expected string, actual string, msg string, args ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tYAMLEqf(a.t, expected, actual, msg, args...)\n}", "is_vulnerable": 0}
{"code": "func TestAgent_SetupProxyManager(t *testing.T) {\n\tt.Parallel()\n\tdataDir := testutil.TempDir(t, \"agent\") // we manage the data dir\n\tdefer os.RemoveAll(dataDir)\n\thcl := `\n\t\tports { http = -1 }\n\t\tdata_dir = \"` + dataDir + `\"\n\t`\n\tc := TestConfig(\n\t\t// randomPortsSource(false),\n\t\tconfig.Source{Name: t.Name(), Format: \"hcl\", Data: hcl},\n\t)\n\ta, err := New(c)\n\trequire.NoError(t, err)\n\trequire.Error(t, a.setupProxyManager(), \"setupProxyManager should fail with invalid HTTP API config\")\n\n\thcl = `\n\t\tports { http = 8001 }\n\t\tdata_dir = \"` + dataDir + `\"\n\t`\n\tc = TestConfig(\n\t\t// randomPortsSource(false),\n\t\tconfig.Source{Name: t.Name(), Format: \"hcl\", Data: hcl},\n\t)\n\ta, err = New(c)\n\trequire.NoError(t, err)\n\trequire.NoError(t, a.setupProxyManager())\n}", "is_vulnerable": 1}
{"code": "func TestResourceQuotaStore(t *testing.T) {\n\t// Fixed metadata on type and help text. We prepend this to every expected\n\t// output so we only have to modify a single place when doing adjustments.\n\tconst metadata = `\n\t# HELP kube_resourcequota Information about resource quota.\n\t# TYPE kube_resourcequota gauge\n\t# HELP kube_resourcequota_created Unix creation timestamp\n\t# TYPE kube_resourcequota_created gauge\n\t# HELP kube_resourcequota_annotations Kubernetes annotations converted to Prometheus labels.\n\t# TYPE kube_resourcequota_annotations gauge\n\t`\n\tcases := []generateMetricsTestCase{\n\t\t// Verify populating base metric and that metric for unset fields are skipped.\n\t\t{\n\t\t\tObj: &v1.ResourceQuota{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:              \"quotaTest\",\n\t\t\t\t\tCreationTimestamp: metav1.Time{Time: time.Unix(1500000000, 0)},\n\t\t\t\t\tNamespace:         \"testNS\",\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"rq\": \"rq\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: v1.ResourceQuotaStatus{},\n\t\t\t},\n\t\t\tWant: `\n\t\t\tkube_resourcequota_created{namespace=\"testNS\",resourcequota=\"quotaTest\"} 1.5e+09\n\t\t\tkube_resourcequota_annotations{namespace=\"testNS\",resourcequota=\"quotaTest\",annotation_rq=\"rq\"} 1\n\t\t\t`,\n\t\t},\n\t\t// Verify resource metric.\n\t\t{\n\t\t\tObj: &v1.ResourceQuota{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      \"quotaTest\",\n\t\t\t\t\tNamespace: \"testNS\",\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"RQ\": \"RQ\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tSpec: v1.ResourceQuotaSpec{\n\t\t\t\t\tHard: v1.ResourceList{\n\t\t\t\t\t\tv1.ResourceCPU:                    resource.MustParse(\"4.3\"),\n\t\t\t\t\t\tv1.ResourceMemory:                 resource.MustParse(\"2.1G\"),\n\t\t\t\t\t\tv1.ResourceStorage:                resource.MustParse(\"10G\"),\n\t\t\t\t\t\tv1.ResourcePods:                   resource.MustParse(\"9\"),\n\t\t\t\t\t\tv1.ResourceServices:               resource.MustParse(\"8\"),\n\t\t\t\t\t\tv1.ResourceReplicationControllers: resource.MustParse(\"7\"),\n\t\t\t\t\t\tv1.ResourceQuotas:                 resource.MustParse(\"6\"),\n\t\t\t\t\t\tv1.ResourceSecrets:                resource.MustParse(\"5\"),\n\t\t\t\t\t\tv1.ResourceConfigMaps:             resource.MustParse(\"4\"),\n\t\t\t\t\t\tv1.ResourcePersistentVolumeClaims: resource.MustParse(\"3\"),\n\t\t\t\t\t\tv1.ResourceServicesNodePorts:      resource.MustParse(\"2\"),\n\t\t\t\t\t\tv1.ResourceServicesLoadBalancers:  resource.MustParse(\"1\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: v1.ResourceQuotaStatus{\n\t\t\t\t\tHard: v1.ResourceList{\n\t\t\t\t\t\tv1.ResourceCPU:                    resource.MustParse(\"4.3\"),\n\t\t\t\t\t\tv1.ResourceMemory:                 resource.MustParse(\"2.1G\"),\n\t\t\t\t\t\tv1.ResourceStorage:                resource.MustParse(\"10G\"),\n\t\t\t\t\t\tv1.ResourcePods:                   resource.MustParse(\"9\"),\n\t\t\t\t\t\tv1.ResourceServices:               resource.MustParse(\"8\"),\n\t\t\t\t\t\tv1.ResourceReplicationControllers: resource.MustParse(\"7\"),\n\t\t\t\t\t\tv1.ResourceQuotas:                 resource.MustParse(\"6\"),\n\t\t\t\t\t\tv1.ResourceSecrets:                resource.MustParse(\"5\"),\n\t\t\t\t\t\tv1.ResourceConfigMaps:             resource.MustParse(\"4\"),\n\t\t\t\t\t\tv1.ResourcePersistentVolumeClaims: resource.MustParse(\"3\"),\n\t\t\t\t\t\tv1.ResourceServicesNodePorts:      resource.MustParse(\"2\"),\n\t\t\t\t\t\tv1.ResourceServicesLoadBalancers:  resource.MustParse(\"1\"),\n\t\t\t\t\t},\n\t\t\t\t\tUsed: v1.ResourceList{\n\t\t\t\t\t\tv1.ResourceCPU:                    resource.MustParse(\"2.1\"),\n\t\t\t\t\t\tv1.ResourceMemory:                 resource.MustParse(\"500M\"),\n\t\t\t\t\t\tv1.ResourceStorage:                resource.MustParse(\"9G\"),\n\t\t\t\t\t\tv1.ResourcePods:                   resource.MustParse(\"8\"),\n\t\t\t\t\t\tv1.ResourceServices:               resource.MustParse(\"7\"),\n\t\t\t\t\t\tv1.ResourceReplicationControllers: resource.MustParse(\"6\"),\n\t\t\t\t\t\tv1.ResourceQuotas:                 resource.MustParse(\"5\"),\n\t\t\t\t\t\tv1.ResourceSecrets:                resource.MustParse(\"4\"),\n\t\t\t\t\t\tv1.ResourceConfigMaps:             resource.MustParse(\"3\"),\n\t\t\t\t\t\tv1.ResourcePersistentVolumeClaims: resource.MustParse(\"2\"),\n\t\t\t\t\t\tv1.ResourceServicesNodePorts:      resource.MustParse(\"1\"),\n\t\t\t\t\t\tv1.ResourceServicesLoadBalancers:  resource.MustParse(\"0\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"configmaps\",resourcequota=\"quotaTest\",type=\"hard\"} 4\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"configmaps\",resourcequota=\"quotaTest\",type=\"used\"} 3\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"cpu\",resourcequota=\"quotaTest\",type=\"hard\"} 4.3\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"cpu\",resourcequota=\"quotaTest\",type=\"used\"} 2.1\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"memory\",resourcequota=\"quotaTest\",type=\"hard\"} 2.1e+09\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"memory\",resourcequota=\"quotaTest\",type=\"used\"} 5e+08\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"persistentvolumeclaims\",resourcequota=\"quotaTest\",type=\"hard\"} 3\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"persistentvolumeclaims\",resourcequota=\"quotaTest\",type=\"used\"} 2\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"pods\",resourcequota=\"quotaTest\",type=\"hard\"} 9\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"pods\",resourcequota=\"quotaTest\",type=\"used\"} 8\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"replicationcontrollers\",resourcequota=\"quotaTest\",type=\"hard\"} 7\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"replicationcontrollers\",resourcequota=\"quotaTest\",type=\"used\"} 6\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"resourcequotas\",resourcequota=\"quotaTest\",type=\"hard\"} 6\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"resourcequotas\",resourcequota=\"quotaTest\",type=\"used\"} 5\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"secrets\",resourcequota=\"quotaTest\",type=\"hard\"} 5\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"secrets\",resourcequota=\"quotaTest\",type=\"used\"} 4\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services\",resourcequota=\"quotaTest\",type=\"hard\"} 8\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services\",resourcequota=\"quotaTest\",type=\"used\"} 7\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services.loadbalancers\",resourcequota=\"quotaTest\",type=\"hard\"} 1\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services.loadbalancers\",resourcequota=\"quotaTest\",type=\"used\"} 0\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services.nodeports\",resourcequota=\"quotaTest\",type=\"hard\"} 2\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"services.nodeports\",resourcequota=\"quotaTest\",type=\"used\"} 1\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"storage\",resourcequota=\"quotaTest\",type=\"hard\"} 1e+10\n\t\t\tkube_resourcequota{namespace=\"testNS\",resource=\"storage\",resourcequota=\"quotaTest\",type=\"used\"} 9e+09\n\t\t\tkube_resourcequota_annotations{namespace=\"testNS\",resourcequota=\"quotaTest\",annotation_RQ=\"RQ\"} 1\n\t\t\t`,\n\t\t},\n\t}\n\tfor i, c := range cases {\n\t\tc.Func = metric.ComposeMetricGenFuncs(resourceQuotaMetricFamilies)\n\t\tif err := c.run(); err != nil {\n\t\t\tt.Errorf(\"unexpected collecting result in %vth run:\\n%s\", i, err)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tCallback: func(p string, e *godirwalk.Dirent) error {\n\t\t\t// If this is a symlink then resolve the final destination of it before trying to continue walking\n\t\t\t// over its contents. If it resolves outside the server data directory just skip everything else for\n\t\t\t// it. Otherwise, allow it to continue.\n\t\t\tif e.IsSymlink() {\n\t\t\t\tif _, err := fs.SafePath(p); err != nil {\n\t\t\t\t\tif IsErrorCode(err, ErrCodePathResolution) {\n\t\t\t\t\t\treturn godirwalk.SkipThis\n\t\t\t\t\t}\n\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !e.IsDir() {\n\t\t\t\t_ = syscall.Lstat(p, &st)\n\t\t\t\tatomic.AddInt64(&size, st.Size)\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t})", "is_vulnerable": 1}
{"code": "func reqRepoAdmin() macaron.Handler {\n\treturn func(c *context.Context) {\n\t\tif !c.Repo.IsAdmin() {\n\t\t\tc.Error(http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockStorage) GetClient(arg0 context.Context, arg1 string) (fosite.Client, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetClient\", arg0, arg1)\n\tret0, _ := ret[0].(fosite.Client)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func TestDecoder_SetMaxSize(t *testing.T) {\n\n\tt.Run(\"default maxsize should be equal to given constant\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tdec := NewDecoder()\n\t\tif !reflect.DeepEqual(dec.maxSize, defaultMaxSize) {\n\t\t\tt.Errorf(\"unexpected default max size\")\n\t\t}\n\t})\n\n\tt.Run(\"configured maxsize should be set properly\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\tconfiguredMaxSize := 50\n\t\tlimitedMaxSizeDecoder := NewDecoder()\n\t\tlimitedMaxSizeDecoder.MaxSize(configuredMaxSize)\n\t\tif !reflect.DeepEqual(limitedMaxSizeDecoder.maxSize, configuredMaxSize) {\n\t\t\tt.Errorf(\"invalid decoder maxsize, expected: %d, got: %d\",\n\t\t\t\tconfiguredMaxSize, limitedMaxSizeDecoder.maxSize)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func Len(t TestingT, object interface{}, length int, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Len(t, object, length, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tDescribeTable(fmt.Sprintf(\"should fund the vesting account from tx origin when defining only vesting (%s)\", callType.name), func(tc testCase) {\n\t\t\t\t\tif callType.directCall {\n\t\t\t\t\t\tSkip(\"this should only be run for smart contract calls\")\n\t\t\t\t\t}\n\t\t\t\t\t// if not specified, default the transferTo to the funder address\n\t\t\t\t\tif tc.transferTo == nil {\n\t\t\t\t\t\ttc.transferTo = &s.address\n\t\t\t\t\t}\n\t\t\t\t\tfundVestingAccArgs := args.\n\t\t\t\t\t\tWithArgs(\n\t\t\t\t\t\t\ts.address,\n\t\t\t\t\t\t\ttoAddr,\n\t\t\t\t\t\t\t*tc.transferTo,\n\t\t\t\t\t\t\tuint64(time.Now().Unix()),\n\t\t\t\t\t\t\temptyPeriods,\n\t\t\t\t\t\t\tdefaultPeriods,\n\t\t\t\t\t\t\ttc.before, tc.after, // transfer funds to the funder according to test case\n\t\t\t\t\t\t).\n\t\t\t\t\t\tWithGasPrice(gasPrice.BigInt())\n\n\t\t\t\t\tfundClawbackVestingCheck := passCheck.\n\t\t\t\t\t\tWithExpEvents(vesting.EventTypeFundVestingAccount)\n\n\t\t\t\t\tres, _, err := contracts.CallContractAndCheckLogs(s.ctx, s.app, fundVestingAccArgs, fundClawbackVestingCheck)\n\t\t\t\t\tExpect(err).ToNot(HaveOccurred(), \"error while calling the contract: %v\", err)\n\n\t\t\t\t\tfees := gasPrice.MulRaw(res.GasUsed)\n\n\t\t\t\t\ttransferredToAmt := math.ZeroInt()\n\t\t\t\t\tfor _, transferred := range []bool{tc.before, tc.after} {\n\t\t\t\t\t\tif transferred {\n\t\t\t\t\t\t\ttransferredToAmt = transferredToAmt.AddRaw(15)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Check the vesting account\n\t\t\t\t\t//\n\t\t\t\t\t// NOTE: The vesting account is created with the vesting periods only, since the lockup periods are empty.\n\t\t\t\t\t// The lockup periods are defaulted to instant unlocking, i.e. period length = 0.\n\t\t\t\t\ts.ExpectVestingAccount(toAddr, instantPeriods, defaultPeriods)\n\n\t\t\t\t\t// check the contract's balance was deducted to fund the vesting account\n\t\t\t\t\tcontractFinalBal := s.app.BankKeeper.GetBalance(s.ctx, contractAddr.Bytes(), s.bondDenom)\n\t\t\t\t\tExpect(contractFinalBal.Amount).To(Equal(contractInitialBalance.Sub(transferredToAmt)))\n\n\t\t\t\t\t// check that the vesting account received the funds\n\t\t\t\t\tvestCoinsAmt := math.NewIntFromBigInt(defaultPeriods[0].Amount[0].Amount)\n\t\t\t\t\tvestAccFinalBal := s.app.BankKeeper.GetBalance(s.ctx, toAddr.Bytes(), s.bondDenom)\n\t\t\t\t\texpVestAccFinalBal := vestingAccInitialBal.Amount.Add(vestCoinsAmt)\n\t\t\t\t\tif *tc.transferTo == toAddr {\n\t\t\t\t\t\texpVestAccFinalBal = expVestAccFinalBal.Add(transferredToAmt)\n\t\t\t\t\t}\n\n\t\t\t\t\tExpect(vestAccFinalBal.Amount).To(Equal(expVestAccFinalBal))\n\n\t\t\t\t\t// check that funder balance is reduced by the fees paid, the amt to fund the vesting account,\n\t\t\t\t\t// but also got the funds sent from the contract (when corresponds)\n\t\t\t\t\tfunderFinalBal := s.app.BankKeeper.GetBalance(s.ctx, s.address.Bytes(), s.bondDenom)\n\n\t\t\t\t\texpFunderFinalBal := funderInitialBal.Amount.Sub(fees).Sub(vestCoinsAmt)\n\t\t\t\t\tif *tc.transferTo == s.address {\n\t\t\t\t\t\texpFunderFinalBal = expFunderFinalBal.Add(transferredToAmt)\n\t\t\t\t\t}\n\n\t\t\t\t\tExpect(funderFinalBal.Amount).To(Equal(expFunderFinalBal))\n\t\t\t\t},", "is_vulnerable": 0}
{"code": "func (t Token) Expires() time.Time {\n\ts, err := strconv.Atoi(t.ExpiresOn)\n\tif err != nil {\n\t\ts = -3600\n\t}\n\n\texpiration := date.NewUnixTimeFromSeconds(float64(s))\n\n\treturn time.Time(expiration).UTC()\n}", "is_vulnerable": 1}
{"code": "\t\treturn httpclient.RoundTripperFunc(func(req *http.Request) (*http.Response, error) {\n\t\t\tfor _, cookie := range forwardedCookies {\n\t\t\t\treq.AddCookie(cookie)\n\t\t\t}\n\t\t\tproxyutil.ClearCookieHeader(req, allowedCookies)\n\t\t\treturn next.RoundTrip(req)\n\t\t})", "is_vulnerable": 1}
{"code": "func PrintVerificationHeader(imgRef string, co *cosign.CheckOpts, bundleVerified bool) {\n\tfmt.Fprintf(os.Stderr, \"\\nVerification for %s --\\n\", imgRef)\n\tfmt.Fprintln(os.Stderr, \"The following checks were performed on each of these signatures:\")\n\tif co.ClaimVerifier != nil {\n\t\tif co.Annotations != nil {\n\t\t\tfmt.Fprintln(os.Stderr, \"  - The specified annotations were verified.\")\n\t\t}\n\t\tfmt.Fprintln(os.Stderr, \"  - The cosign claims were validated\")\n\t}\n\tif bundleVerified {\n\t\tfmt.Fprintln(os.Stderr, \"  - Existence of the claims in the transparency log was verified offline\")\n\t} else if co.RekorClient != nil {\n\t\tfmt.Fprintln(os.Stderr, \"  - The claims were present in the transparency log\")\n\t\tfmt.Fprintln(os.Stderr, \"  - The signatures were integrated into the transparency log when the certificate was valid\")\n\t}\n\tif co.SigVerifier != nil {\n\t\tfmt.Fprintln(os.Stderr, \"  - The signatures were verified against the specified public key\")\n\t}\n\tfmt.Fprintln(os.Stderr, \"  - Any certificates were verified against the Fulcio roots.\")\n}", "is_vulnerable": 1}
{"code": "func newTestCache(ttl time.Duration) (*Cache, *ResponseWriter) {\n\tc := New()\n\tc.pttl = ttl\n\tc.nttl = ttl\n\n\tcrr := &ResponseWriter{ResponseWriter: nil, Cache: c}\n\tcrr.nexcept = []string{\"neg-disabled.example.org.\"}\n\tcrr.pexcept = []string{\"pos-disabled.example.org.\"}\n\n\treturn c, crr\n}", "is_vulnerable": 1}
{"code": "func doesPolicySignatureV2Match(formValues http.Header) APIErrorCode {\n\tcred := globalActiveCred\n\taccessKey := formValues.Get(xhttp.AmzAccessKeyID)\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\tpolicy := formValues.Get(\"Policy\")\n\tsignature := formValues.Get(xhttp.AmzSignatureV2)\n\tif !compareSignatureV2(signature, calculateSignatureV2(policy, cred.SecretKey)) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}", "is_vulnerable": 1}
{"code": "func (kl *Kubelet) syncNetworkUtil() {\n\tif kl.iptablesMasqueradeBit < 0 || kl.iptablesMasqueradeBit > 31 {\n\t\tklog.Errorf(\"invalid iptables-masquerade-bit %v not in [0, 31]\", kl.iptablesMasqueradeBit)\n\t\treturn\n\t}\n\n\tif kl.iptablesDropBit < 0 || kl.iptablesDropBit > 31 {\n\t\tklog.Errorf(\"invalid iptables-drop-bit %v not in [0, 31]\", kl.iptablesDropBit)\n\t\treturn\n\t}\n\n\tif kl.iptablesDropBit == kl.iptablesMasqueradeBit {\n\t\tklog.Errorf(\"iptables-masquerade-bit %v and iptables-drop-bit %v must be different\", kl.iptablesMasqueradeBit, kl.iptablesDropBit)\n\t\treturn\n\t}\n\n\t// Setup KUBE-MARK-DROP rules\n\tdropMark := getIPTablesMark(kl.iptablesDropBit)\n\tif _, err := kl.iptClient.EnsureChain(utiliptables.TableNAT, KubeMarkDropChain); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s exists: %v\", utiliptables.TableNAT, KubeMarkDropChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Append, utiliptables.TableNAT, KubeMarkDropChain, \"-j\", \"MARK\", \"--set-xmark\", dropMark); err != nil {\n\t\tklog.Errorf(\"Failed to ensure marking rule for %v: %v\", KubeMarkDropChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureChain(utiliptables.TableFilter, KubeFirewallChain); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s exists: %v\", utiliptables.TableFilter, KubeFirewallChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Append, utiliptables.TableFilter, KubeFirewallChain,\n\t\t\"-m\", \"comment\", \"--comment\", \"kubernetes firewall for dropping marked packets\",\n\t\t\"-m\", \"mark\", \"--mark\", dropMark,\n\t\t\"-j\", \"DROP\"); err != nil {\n\t\tklog.Errorf(\"Failed to ensure rule to drop packet marked by %v in %v chain %v: %v\", KubeMarkDropChain, utiliptables.TableFilter, KubeFirewallChain, err)\n\t\treturn\n\t}\n\n\t// drop all non-local packets to localhost if they're not part of an existing\n\t// forwarded connection. See #90259\n\tif !kl.iptClient.IsIPv6() { // ipv6 doesn't have this issue\n\t\tif _, err := kl.iptClient.EnsureRule(utiliptables.Append, utiliptables.TableFilter, KubeFirewallChain,\n\t\t\t\"-m\", \"comment\", \"--comment\", \"block incoming localnet connections\",\n\t\t\t\"--dst\", \"127.0.0.0/8\",\n\t\t\t\"!\", \"--src\", \"127.0.0.0/8\",\n\t\t\t\"-m\", \"conntrack\",\n\t\t\t\"!\", \"--ctstate\", \"RELATED,ESTABLISHED,DNAT\",\n\t\t\t\"-j\", \"DROP\"); err != nil {\n\t\t\tklog.Errorf(\"Failed to ensure rule to drop invalid localhost packets in %v chain %v: %v\", utiliptables.TableFilter, KubeFirewallChain, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Prepend, utiliptables.TableFilter, utiliptables.ChainOutput, \"-j\", string(KubeFirewallChain)); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s jumps to %s: %v\", utiliptables.TableFilter, utiliptables.ChainOutput, KubeFirewallChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Prepend, utiliptables.TableFilter, utiliptables.ChainInput, \"-j\", string(KubeFirewallChain)); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s jumps to %s: %v\", utiliptables.TableFilter, utiliptables.ChainInput, KubeFirewallChain, err)\n\t\treturn\n\t}\n\n\t// Setup KUBE-MARK-MASQ rules\n\tmasqueradeMark := getIPTablesMark(kl.iptablesMasqueradeBit)\n\tif _, err := kl.iptClient.EnsureChain(utiliptables.TableNAT, KubeMarkMasqChain); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s exists: %v\", utiliptables.TableNAT, KubeMarkMasqChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureChain(utiliptables.TableNAT, KubePostroutingChain); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s exists: %v\", utiliptables.TableNAT, KubePostroutingChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Append, utiliptables.TableNAT, KubeMarkMasqChain, \"-j\", \"MARK\", \"--set-xmark\", masqueradeMark); err != nil {\n\t\tklog.Errorf(\"Failed to ensure marking rule for %v: %v\", KubeMarkMasqChain, err)\n\t\treturn\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Prepend, utiliptables.TableNAT, utiliptables.ChainPostrouting,\n\t\t\"-m\", \"comment\", \"--comment\", \"kubernetes postrouting rules\", \"-j\", string(KubePostroutingChain)); err != nil {\n\t\tklog.Errorf(\"Failed to ensure that %s chain %s jumps to %s: %v\", utiliptables.TableNAT, utiliptables.ChainPostrouting, KubePostroutingChain, err)\n\t\treturn\n\t}\n\t// Establish the masquerading rule.\n\t// NB: THIS MUST MATCH the corresponding code in the iptables and ipvs\n\t// modes of kube-proxy\n\tmasqRule := []string{\n\t\t\"-m\", \"comment\", \"--comment\", \"kubernetes service traffic requiring SNAT\",\n\t\t\"-m\", \"mark\", \"--mark\", masqueradeMark,\n\t\t\"-j\", \"MASQUERADE\",\n\t}\n\tif kl.iptClient.HasRandomFully() {\n\t\tmasqRule = append(masqRule, \"--random-fully\")\n\t}\n\tif _, err := kl.iptClient.EnsureRule(utiliptables.Append, utiliptables.TableNAT, KubePostroutingChain, masqRule...); err != nil {\n\t\tklog.Errorf(\"Failed to ensure SNAT rule for packets marked by %v in %v chain %v: %v\", KubeMarkMasqChain, utiliptables.TableNAT, KubePostroutingChain, err)\n\t\treturn\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Execute(ctx context.Context, in *sliverpb.ExecuteReq, opts ...grpc.CallOption) (*sliverpb.Execute, error) {\n\tout := new(sliverpb.Execute)\n\terr := c.cc.Invoke(ctx, SliverRPC_Execute_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockAccessRequester) GetGrantTypes() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetGrantTypes\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func createMountpoint(rootfs string, m *configs.Mount, mountFd *int, source string) (string, error) {\n\tdest, err := securejoin.SecureJoin(rootfs, m.Destination)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif err := checkProcMount(rootfs, dest, m, source); err != nil {\n\t\treturn \"\", fmt.Errorf(\"check proc-safety of %s mount: %w\", m.Destination, err)\n\t}\n\n\tswitch m.Device {\n\tcase \"bind\":\n\t\tsource := m.Source\n\t\tif mountFd != nil {\n\t\t\tsource = \"/proc/self/fd/\" + strconv.Itoa(*mountFd)\n\t\t}\n\n\t\tfi, err := os.Stat(source)\n\t\tif err != nil {\n\t\t\t// Error out if the source of a bind mount does not exist as we\n\t\t\t// will be unable to bind anything to it.\n\t\t\treturn \"\", fmt.Errorf(\"bind mount source stat: %w\", err)\n\t\t}\n\t\t// If the original source is not a directory, make the target a file.\n\t\tif !fi.IsDir() {\n\t\t\t// Make sure we aren't tricked into trying to make the root a file.\n\t\t\tif rootfs == dest {\n\t\t\t\treturn \"\", fmt.Errorf(\"%w: file bind mount over rootfs\", errRootfsToFile)\n\t\t\t}\n\t\t\t// Make the parent directory.\n\t\t\tif err := os.MkdirAll(filepath.Dir(dest), 0o755); err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"make parent dir of file bind-mount: %w\", err)\n\t\t\t}\n\t\t\t// Make the target file.\n\t\t\tf, err := os.OpenFile(dest, os.O_CREATE, 0o755)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"create target of file bind-mount: %w\", err)\n\t\t\t}\n\t\t\t_ = f.Close()\n\t\t\t// Nothing left to do.\n\t\t\treturn dest, nil\n\t\t}\n\n\tcase \"tmpfs\":\n\t\t// If the original target exists, copy the mode for the tmpfs mount.\n\t\tif stat, err := os.Stat(dest); err == nil {\n\t\t\tdt := fmt.Sprintf(\"mode=%04o\", syscallMode(stat.Mode()))\n\t\t\tif m.Data != \"\" {\n\t\t\t\tdt = dt + \",\" + m.Data\n\t\t\t}\n\t\t\tm.Data = dt\n\n\t\t\t// Nothing left to do.\n\t\t\treturn dest, nil\n\t\t}\n\t}\n\n\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn dest, nil\n}", "is_vulnerable": 0}
{"code": "func (mt *MultiTenantServicePrincipalToken) EnsureFreshWithContext(ctx context.Context) error {\n\tif err := mt.PrimaryToken.EnsureFreshWithContext(ctx); err != nil {\n\t\treturn fmt.Errorf(\"failed to refresh primary token: %v\", err)\n\t}\n\tfor _, aux := range mt.AuxiliaryTokens {\n\t\tif err := aux.EnsureFreshWithContext(ctx); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to refresh auxiliary token: %v\", err)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tproxy.OnRequest().DoFunc(func(req *http.Request, pctx *goproxy.ProxyCtx) (*http.Request, *http.Response) {\n\n\t\t// We are intentionally *not* setting pctx.HTTPErrorHandler because with traditional HTTP\n\t\t// proxy requests we are able to specify the request during the call to OnResponse().\n\t\tsctx := newContext(config, httpProxy, req)\n\n\t\t// Attach smokescreenContext to goproxy.ProxyCtx\n\t\tpctx.UserData = sctx\n\n\t\t// Delete Smokescreen specific headers before goproxy forwards the request\n\t\tdefer func() {\n\t\t\treq.Header.Del(roleHeader)\n\t\t\treq.Header.Del(traceHeader)\n\t\t}()\n\n\t\t// Set this on every request as every request mints a new goproxy.ProxyCtx\n\t\tpctx.RoundTripper = rtFn\n\n\t\t// Build an address parsable by net.ResolveTCPAddr\n\t\tremoteHost := req.Host\n\t\tif strings.LastIndex(remoteHost, \":\") <= strings.LastIndex(remoteHost, \"]\") {\n\t\t\tswitch req.URL.Scheme {\n\t\t\tcase \"http\":\n\t\t\t\tremoteHost = net.JoinHostPort(remoteHost, \"80\")\n\t\t\tcase \"https\":\n\t\t\t\tremoteHost = net.JoinHostPort(remoteHost, \"443\")\n\t\t\tdefault:\n\t\t\t\tremoteHost = net.JoinHostPort(remoteHost, \"0\")\n\t\t\t}\n\t\t}\n\n\t\tsctx.logger.WithField(\"url\", req.RequestURI).Debug(\"received HTTP proxy request\")\n\n\t\tsctx.decision, sctx.lookupTime, pctx.Error = checkIfRequestShouldBeProxied(config, req, remoteHost)\n\n\t\t// Returning any kind of response in this handler is goproxy's way of short circuiting\n\t\t// the request. The original request will never be sent, and goproxy will invoke our\n\t\t// response filter attached via the OnResponse() handler.\n\t\tif pctx.Error != nil {\n\t\t\treturn req, rejectResponse(pctx, pctx.Error)\n\t\t}\n\t\tif !sctx.decision.allow {\n\t\t\treturn req, rejectResponse(pctx, denyError{errors.New(sctx.decision.reason)})\n\t\t}\n\n\t\t// Proceed with proxying the request\n\t\treturn req, nil\n\t})", "is_vulnerable": 1}
{"code": "func (i *File) Delete() error {\n\treturn os.RemoveAll(filepath.Dir(i.Path))\n}", "is_vulnerable": 0}
{"code": "func (client ProvidersClient) Get(ctx context.Context, resourceProviderNamespace string, expand string) (result Provider, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/ProvidersClient.Get\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\treq, err := client.GetPreparer(ctx, resourceProviderNamespace, expand)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.ProvidersClient\", \"Get\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.GetSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.ProvidersClient\", \"Get\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.GetResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.ProvidersClient\", \"Get\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (g *Getter) Mode(ctx context.Context, u *url.URL) (getter.Mode, error) {\n\t// Parse URL\n\tregion, bucket, path, _, creds, err := g.parseUrl(u)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Create client config\n\tclient, err := g.newS3Client(region, u, creds)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// List the object(s) at the given prefix\n\treq := &s3.ListObjectsInput{\n\t\tBucket: aws.String(bucket),\n\t\tPrefix: aws.String(path),\n\t}\n\tresp, err := client.ListObjects(req)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tfor _, o := range resp.Contents {\n\t\t// Use file mode on exact match.\n\t\tif *o.Key == path {\n\t\t\treturn getter.ModeFile, nil\n\t\t}\n\n\t\t// Use dir mode if child keys are found.\n\t\tif strings.HasPrefix(*o.Key, path+\"/\") {\n\t\t\treturn getter.ModeDir, nil\n\t\t}\n\t}\n\n\t// There was no match, so just return file mode. The download is going\n\t// to fail but we will let S3 return the proper error later.\n\treturn getter.ModeFile, nil\n}", "is_vulnerable": 1}
{"code": "func writeSettings(ctx context.Context, settings lsp.Settings, initialize bool) {\n\temptySettings := lsp.Settings{}\n\tif reflect.DeepEqual(settings, emptySettings) {\n\t\treturn\n\t}\n\tupdateToken(settings.Token)\n\tupdateProductEnablement(settings)\n\tupdateCliConfig(settings)\n\tupdateApiEndpoints(ctx, settings, initialize)\n\tupdateEnvironment(settings)\n\tupdatePath(settings)\n\tupdateTelemetry(settings)\n\tupdateOrganization(settings)\n\tmanageBinariesAutomatically(settings)\n\tupdateTrustedFolders(settings)\n}", "is_vulnerable": 0}
{"code": "func TestManager_Get(t *testing.T) {\n\tdynamicConfigs := []*CertAndStores{{\n\t\tCertificate: Certificate{\n\t\t\tCertFile: localhostCert,\n\t\t\tKeyFile:  localhostKey,\n\t\t},\n\t}}\n\n\ttlsConfigs := map[string]Options{\n\t\t\"foo\": {MinVersion: \"VersionTLS12\"},\n\t\t\"bar\": {MinVersion: \"VersionTLS11\"},\n\t}\n\n\ttestCases := []struct {\n\t\tdesc               string\n\t\ttlsOptionsName     string\n\t\texpectedMinVersion uint16\n\t\texpectedError      bool\n\t}{\n\t\t{\n\t\t\tdesc:               \"Get a tls config from a valid name\",\n\t\t\ttlsOptionsName:     \"foo\",\n\t\t\texpectedMinVersion: uint16(tls.VersionTLS12),\n\t\t},\n\t\t{\n\t\t\tdesc:               \"Get another tls config from a valid name\",\n\t\t\ttlsOptionsName:     \"bar\",\n\t\t\texpectedMinVersion: uint16(tls.VersionTLS11),\n\t\t},\n\t\t{\n\t\t\tdesc:           \"Get an tls config from an invalid name\",\n\t\t\ttlsOptionsName: \"unknown\",\n\t\t\texpectedError:  true,\n\t\t},\n\t\t{\n\t\t\tdesc:           \"Get an tls config from unexisting 'default' name\",\n\t\t\ttlsOptionsName: \"default\",\n\t\t\texpectedError:  true,\n\t\t},\n\t}\n\n\ttlsManager := NewManager()\n\ttlsManager.UpdateConfigs(context.Background(), nil, tlsConfigs, dynamicConfigs)\n\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\tconfig, err := tlsManager.Get(\"default\", test.tlsOptionsName)\n\t\t\tif test.expectedError {\n\t\t\t\tassert.Error(t, err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, config.MinVersion, test.expectedMinVersion)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (client GroupsClient) CheckExistence(ctx context.Context, resourceGroupName string) (result autorest.Response, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupsClient.CheckExistence\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response != nil {\n\t\t\t\tsc = result.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.GroupsClient\", \"CheckExistence\", err.Error())\n\t}\n\n\treq, err := client.CheckExistencePreparer(ctx, resourceGroupName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"CheckExistence\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.CheckExistenceSender(req)\n\tif err != nil {\n\t\tresult.Response = resp\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"CheckExistence\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.CheckExistenceResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"CheckExistence\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func newHandlerClusterRoleBinding(namespace string) *rbacv1.ClusterRoleBinding {\n\treturn &rbacv1.ClusterRoleBinding{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"ClusterRoleBinding\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: HandlerServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: \"rbac.authorization.k8s.io\",\n\t\t\tKind:     \"ClusterRole\",\n\t\t\tName:     HandlerServiceAccountName,\n\t\t},\n\t\tSubjects: []rbacv1.Subject{\n\t\t\t{\n\t\t\t\tKind:      \"ServiceAccount\",\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      HandlerServiceAccountName,\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func prepareBindMount(m *configs.Mount, rootfs string, mountFd *int) error {\n\tsource := m.Source\n\tif mountFd != nil {\n\t\tsource = \"/proc/self/fd/\" + strconv.Itoa(*mountFd)\n\t}\n\n\tstat, err := os.Stat(source)\n\tif err != nil {\n\t\t// error out if the source of a bind mount does not exist as we will be\n\t\t// unable to bind anything to it.\n\t\treturn err\n\t}\n\t// ensure that the destination of the bind mount is resolved of symlinks at mount time because\n\t// any previous mounts can invalidate the next mount's destination.\n\t// this can happen when a user specifies mounts within other mounts to cause breakouts or other\n\t// evil stuff to try to escape the container's rootfs.\n\tvar dest string\n\tif dest, err = securejoin.SecureJoin(rootfs, m.Destination); err != nil {\n\t\treturn err\n\t}\n\tif err := checkProcMount(rootfs, dest, source); err != nil {\n\t\treturn err\n\t}\n\tif err := createIfNotExists(dest, stat.IsDir()); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func rebuildImpl(args rebuildArgs, oldSummary buildSummary) rebuildState {\n\tlog := logger.NewStderrLog(args.logOptions)\n\n\t// Convert and validate the buildOpts\n\trealFS, err := fs.RealFS(fs.RealFSOptions{\n\t\tAbsWorkingDir: args.absWorkingDir,\n\t\tWantWatchData: args.options.WatchMode,\n\t})\n\tif err != nil {\n\t\t// This should already have been checked by the caller\n\t\tpanic(err.Error())\n\t}\n\n\tvar result BuildResult\n\tvar watchData fs.WatchData\n\tvar toWriteToStdout []byte\n\n\tvar timer *helpers.Timer\n\tif api_helpers.UseTimer {\n\t\ttimer = &helpers.Timer{}\n\t}\n\n\t// Scan over the bundle\n\tbundle := bundler.ScanBundle(log, realFS, args.caches, args.entryPoints, args.options, timer)\n\twatchData = realFS.WatchData()\n\n\t// The new build summary remains the same as the old one when there are\n\t// errors. A failed build shouldn't erase the previous successful build.\n\tnewSummary := oldSummary\n\n\t// Stop now if there were errors\n\tif !log.HasErrors() {\n\t\t// Compile the bundle\n\t\tresult.MangleCache = cloneMangleCache(log, args.mangleCache)\n\t\tresults, metafile := bundle.Compile(log, timer, result.MangleCache, linker.Link)\n\n\t\t// Stop now if there were errors\n\t\tif !log.HasErrors() {\n\t\t\tresult.Metafile = metafile\n\n\t\t\t// Populate the results to return\n\t\t\tresult.OutputFiles = make([]OutputFile, len(results))\n\t\t\tfor i, item := range results {\n\t\t\t\tif args.options.WriteToStdout {\n\t\t\t\t\titem.AbsPath = \"<stdout>\"\n\t\t\t\t}\n\t\t\t\tresult.OutputFiles[i] = OutputFile{\n\t\t\t\t\tPath:     item.AbsPath,\n\t\t\t\t\tContents: item.Contents,\n\t\t\t\t}\n\t\t\t}\n\t\t\tnewSummary = summarizeOutputFiles(result.OutputFiles)\n\n\t\t\t// Write output files before \"OnEnd\" callbacks run so they can expect\n\t\t\t// output files to exist on the file system. \"OnEnd\" callbacks can be\n\t\t\t// used to move output files to a different location after the build.\n\t\t\tif args.write {\n\t\t\t\ttimer.Begin(\"Write output files\")\n\t\t\t\tif args.options.WriteToStdout {\n\t\t\t\t\t// Special-case writing to stdout\n\t\t\t\t\tif len(results) != 1 {\n\t\t\t\t\t\tlog.AddError(nil, logger.Range{}, fmt.Sprintf(\n\t\t\t\t\t\t\t\"Internal error: did not expect to generate %d files when writing to stdout\", len(results)))\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Print this later on, at the end of the current function\n\t\t\t\t\t\ttoWriteToStdout = results[0].Contents\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// Delete old files that are no longer relevant\n\t\t\t\t\tvar toDelete []string\n\t\t\t\t\tfor absPath := range oldSummary {\n\t\t\t\t\t\tif _, ok := newSummary[absPath]; !ok {\n\t\t\t\t\t\t\ttoDelete = append(toDelete, absPath)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Process all file operations in parallel\n\t\t\t\t\twaitGroup := sync.WaitGroup{}\n\t\t\t\t\twaitGroup.Add(len(results) + len(toDelete))\n\t\t\t\t\tfor _, result := range results {\n\t\t\t\t\t\tgo func(result graph.OutputFile) {\n\t\t\t\t\t\t\tdefer waitGroup.Done()\n\t\t\t\t\t\t\tfs.BeforeFileOpen()\n\t\t\t\t\t\t\tdefer fs.AfterFileClose()\n\t\t\t\t\t\t\tif oldHash, ok := oldSummary[result.AbsPath]; ok && oldHash == newSummary[result.AbsPath] {\n\t\t\t\t\t\t\t\tif contents, err := ioutil.ReadFile(result.AbsPath); err == nil && bytes.Equal(contents, result.Contents) {\n\t\t\t\t\t\t\t\t\t// Skip writing out files that haven't changed since last time\n\t\t\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif err := fs.MkdirAll(realFS, realFS.Dir(result.AbsPath), 0755); err != nil {\n\t\t\t\t\t\t\t\tlog.AddError(nil, logger.Range{}, fmt.Sprintf(\n\t\t\t\t\t\t\t\t\t\"Failed to create output directory: %s\", err.Error()))\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tvar mode os.FileMode = 0644\n\t\t\t\t\t\t\t\tif result.IsExecutable {\n\t\t\t\t\t\t\t\t\tmode = 0755\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif err := ioutil.WriteFile(result.AbsPath, result.Contents, mode); err != nil {\n\t\t\t\t\t\t\t\t\tlog.AddError(nil, logger.Range{}, fmt.Sprintf(\n\t\t\t\t\t\t\t\t\t\t\"Failed to write to output file: %s\", err.Error()))\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}(result)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, absPath := range toDelete {\n\t\t\t\t\t\tgo func(absPath string) {\n\t\t\t\t\t\t\tdefer waitGroup.Done()\n\t\t\t\t\t\t\tfs.BeforeFileOpen()\n\t\t\t\t\t\t\tdefer fs.AfterFileClose()\n\t\t\t\t\t\t\tos.Remove(absPath)\n\t\t\t\t\t\t}(absPath)\n\t\t\t\t\t}\n\t\t\t\t\twaitGroup.Wait()\n\t\t\t\t}\n\t\t\t\ttimer.End(\"Write output files\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Only return the mangle cache for a successful build\n\tif log.HasErrors() {\n\t\tresult.MangleCache = nil\n\t}\n\n\t// Populate the result object with the messages so far\n\tmsgs := log.Peek()\n\tresult.Errors = convertMessagesToPublic(logger.Error, msgs)\n\tresult.Warnings = convertMessagesToPublic(logger.Warning, msgs)\n\n\t// Run any registered \"OnEnd\" callbacks now\n\ttimer.Begin(\"On-end callbacks\")\n\tfor _, onEnd := range args.onEndCallbacks {\n\t\tfromPlugin, thrown := onEnd.fn(&result)\n\n\t\t// Report errors and warnings generated by the plugin\n\t\tfor i := range fromPlugin.Errors {\n\t\t\tif fromPlugin.Errors[i].PluginName == \"\" {\n\t\t\t\tfromPlugin.Errors[i].PluginName = onEnd.pluginName\n\t\t\t}\n\t\t}\n\t\tfor i := range fromPlugin.Warnings {\n\t\t\tif fromPlugin.Warnings[i].PluginName == \"\" {\n\t\t\t\tfromPlugin.Warnings[i].PluginName = onEnd.pluginName\n\t\t\t}\n\t\t}\n\n\t\t// Report errors thrown by the plugin itself\n\t\tif thrown != nil {\n\t\t\tfromPlugin.Errors = append(fromPlugin.Errors, Message{\n\t\t\t\tPluginName: onEnd.pluginName,\n\t\t\t\tText:       thrown.Error(),\n\t\t\t})\n\t\t}\n\n\t\t// Log any errors and warnings generated above\n\t\tfor _, msg := range convertErrorsAndWarningsToInternal(fromPlugin.Errors, fromPlugin.Warnings) {\n\t\t\tlog.AddMsg(msg)\n\t\t}\n\n\t\t// Add the errors and warnings to the result object\n\t\tresult.Errors = append(result.Errors, fromPlugin.Errors...)\n\t\tresult.Warnings = append(result.Warnings, fromPlugin.Warnings...)\n\n\t\t// Stop if an \"onEnd\" callback failed. This counts as a build failure.\n\t\tif len(fromPlugin.Errors) > 0 {\n\t\t\tbreak\n\t\t}\n\t}\n\ttimer.End(\"On-end callbacks\")\n\n\t// Log timing information now that we're all done\n\ttimer.Log(log)\n\n\t// End the log after \"OnEnd\" callbacks have added any additional errors and/or\n\t// warnings. This may may print any warnings that were deferred up until this\n\t// point, as well as a message with the number of errors and/or warnings\n\t// omitted due to the configured log limit.\n\tlog.Done()\n\n\t// Only write to stdout after the log has been finalized. We want this output\n\t// to show up in the terminal after the message that was printed above.\n\tif toWriteToStdout != nil {\n\t\tos.Stdout.Write(toWriteToStdout)\n\t}\n\n\treturn rebuildState{\n\t\tresult:    result,\n\t\tsummary:   newSummary,\n\t\toptions:   args.options,\n\t\twatchData: watchData,\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestConfigFromBlockBadInput(t *testing.T) {\n\tfor _, testCase := range []struct {\n\t\tname          string\n\t\tblock         *common.Block\n\t\texpectedError string\n\t}{\n\t\t{\n\t\t\tname:          \"nil block\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         nil,\n\t\t},\n\t\t{\n\t\t\tname:          \"nil block data\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         &common.Block{},\n\t\t},\n\t\t{\n\t\t\tname:          \"no data in block\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid payload\",\n\t\t\texpectedError: \"error unmarshaling Envelope: proto: common.Envelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{Data: [][]byte{{1, 2, 3}}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"bad genesis block\",\n\t\t\texpectedError: \"invalid config envelope: proto: common.ConfigEnvelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{}, Data: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tData: []byte{1, 2, 3},\n\t\t\t\t\t}),\n\t\t\t\t})}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid envelope in block\",\n\t\t\texpectedError: \"error unmarshaling Envelope: proto: common.Envelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{Data: [][]byte{{1, 2, 3}}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid payload in block envelope\",\n\t\t\texpectedError: \"error unmarshaling Payload: proto: common.Payload: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{Data: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\tPayload: []byte{1, 2, 3},\n\t\t\t})}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid channel header\",\n\t\t\texpectedError: \"error unmarshaling ChannelHeader: proto: common.ChannelHeader: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{Number: 1},\n\t\t\t\tData: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tHeader: &common.Header{\n\t\t\t\t\t\t\tChannelHeader: []byte{1, 2, 3},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t})}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid config block\",\n\t\t\texpectedError: \"invalid config envelope: proto: common.ConfigEnvelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{},\n\t\t\t\tData: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tData: []byte{1, 2, 3},\n\t\t\t\t\t\tHeader: &common.Header{\n\t\t\t\t\t\t\tChannelHeader: protoutil.MarshalOrPanic(&common.ChannelHeader{\n\t\t\t\t\t\t\t\tType: int32(common.HeaderType_CONFIG),\n\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t})}}},\n\t\t},\n\t} {\n\t\tt.Run(testCase.name, func(t *testing.T) {\n\t\t\tconf, err := cluster.ConfigFromBlock(testCase.block)\n\t\t\tassert.Nil(t, conf)\n\t\t\tassert.EqualError(t, err, testCase.expectedError)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func MakeIdentity(rw io.ReadWriter, srkAuth []byte, ownerAuth []byte, aikAuth []byte, pk crypto.PublicKey, label []byte) ([]byte, error) {\n\t// Run OSAP for the SRK, reading a random OddOSAP for our initial command\n\t// and getting back a secret and a handle.\n\tsharedSecretSRK, osaprSRK, err := newOSAPSession(rw, etSRK, khSRK, srkAuth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer osaprSRK.Close(rw)\n\tdefer zeroBytes(sharedSecretSRK[:])\n\n\t// Run OSAP for the Owner, reading a random OddOSAP for our initial command\n\t// and getting back a secret and a handle.\n\tsharedSecretOwn, osaprOwn, err := newOSAPSession(rw, etOwner, khOwner, ownerAuth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer osaprOwn.Close(rw)\n\tdefer zeroBytes(sharedSecretOwn[:])\n\n\t// EncAuth for a MakeIdentity command is computed as\n\t//\n\t// encAuth = XOR(aikAuth, SHA1(sharedSecretOwn || <lastEvenNonce>))\n\t//\n\t// In this case, the last even nonce is NonceEven from OSAP for the Owner.\n\txorData, err := tpmutil.Pack(sharedSecretOwn, osaprOwn.NonceEven)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer zeroBytes(xorData)\n\n\tencAuthData := sha1.Sum(xorData)\n\tvar encAuth Digest\n\tfor i := range encAuth {\n\t\tencAuth[i] = aikAuth[i] ^ encAuthData[i]\n\t}\n\n\tvar caDigest Digest\n\tif (pk != nil) != (label != nil) {\n\t\treturn nil, errors.New(\"inconsistent null values between the pk and the label\")\n\t}\n\n\tif pk != nil {\n\t\tpubKey, err := convertPubKey(pk)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// We can't pack the pair of values directly, since the label is\n\t\t// included directly as bytes, without any length.\n\t\tfullpkb, err := tpmutil.Pack(pubKey)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcaDigestBytes := append(label, fullpkb...)\n\t\tcaDigest = sha1.Sum(caDigestBytes)\n\t}\n\n\trsaAIKParams := rsaKeyParams{\n\t\tKeyLength: 2048,\n\t\tNumPrimes: 2,\n\t\t//Exponent:  big.NewInt(0x10001).Bytes(), // 65537. Implicit?\n\t}\n\tpackedParams, err := tpmutil.Pack(rsaAIKParams)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\taikParams := keyParams{\n\t\tAlgID:     AlgRSA,\n\t\tEncScheme: esNone,\n\t\tSigScheme: ssRSASaPKCS1v15SHA1,\n\t\tParams:    packedParams,\n\t}\n\n\taik := &key{\n\t\tVersion:         0x01010000,\n\t\tKeyUsage:        keyIdentity,\n\t\tKeyFlags:        0,\n\t\tAuthDataUsage:   authAlways,\n\t\tAlgorithmParams: aikParams,\n\t}\n\n\t// The digest input for MakeIdentity authentication is\n\t//\n\t// digest = SHA1(ordMakeIdentity || encAuth || caDigest || aik)\n\t//\n\tauthIn := []interface{}{ordMakeIdentity, encAuth, caDigest, aik}\n\tca1, err := newCommandAuth(osaprSRK.AuthHandle, osaprSRK.NonceEven, sharedSecretSRK[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tca2, err := newCommandAuth(osaprOwn.AuthHandle, osaprOwn.NonceEven, sharedSecretOwn[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tk, sig, ra1, ra2, ret, err := makeIdentity(rw, encAuth, caDigest, aik, ca1, ca2)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check response authentication.\n\traIn := []interface{}{ret, ordMakeIdentity, k, tpmutil.U32Bytes(sig)}\n\tif err := ra1.verify(ca1.NonceOdd, sharedSecretSRK[:], raIn); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := ra2.verify(ca2.NonceOdd, sharedSecretOwn[:], raIn); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// TODO(tmroeder): check the signature against the pubEK.\n\tblob, err := tpmutil.Pack(k)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn blob, nil\n}", "is_vulnerable": 1}
{"code": "func (client Client) ListSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (s *Server) CreateToken(ctx context.Context, q *project.ProjectTokenCreateRequest) (*project.ProjectTokenResponse, error) {\n\tprj, err := s.appclientset.ArgoprojV1alpha1().AppProjects(s.ns).Get(ctx, q.Project, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = validateProject(prj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ts.projectLock.Lock(q.Project)\n\tdefer s.projectLock.Unlock(q.Project)\n\n\trole, _, err := prj.GetRoleByName(q.Role)\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.NotFound, \"project '%s' does not have role '%s'\", q.Project, q.Role)\n\t}\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceProjects, rbacpolicy.ActionUpdate, q.Project); err != nil {\n\t\tif !jwtutil.IsMember(jwtutil.Claims(ctx.Value(\"claims\")), role.Groups, s.policyEnf.GetScopes()) {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tid := q.Id\n\tif err := prj.ValidateJWTTokenID(q.Role, q.Id); err != nil {\n\t\treturn nil, status.Errorf(codes.InvalidArgument, err.Error())\n\t}\n\tif id == \"\" {\n\t\tuniqueId, _ := uuid.NewRandom()\n\t\tid = uniqueId.String()\n\t}\n\tsubject := fmt.Sprintf(JWTTokenSubFormat, q.Project, q.Role)\n\tjwtToken, err := s.sessionMgr.Create(subject, q.ExpiresIn, id)\n\tif err != nil {\n\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n\t}\n\tparser := &jwt.Parser{\n\t\tValidationHelper: jwt.NewValidationHelper(jwt.WithoutClaimsValidation()),\n\t}\n\tclaims := jwt.StandardClaims{}\n\t_, _, err = parser.ParseUnverified(jwtToken, &claims)\n\tif err != nil {\n\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n\t}\n\tvar issuedAt, expiresAt int64\n\tif claims.IssuedAt != nil {\n\t\tissuedAt = claims.IssuedAt.Unix()\n\t}\n\tif claims.ExpiresAt != nil {\n\t\texpiresAt = claims.ExpiresAt.Unix()\n\t}\n\tid = claims.ID\n\n\titems := append(prj.Status.JWTTokensByRole[q.Role].Items, v1alpha1.JWTToken{IssuedAt: issuedAt, ExpiresAt: expiresAt, ID: id})\n\tif _, found := prj.Status.JWTTokensByRole[q.Role]; found {\n\t\tprj.Status.JWTTokensByRole[q.Role] = v1alpha1.JWTTokens{Items: items}\n\t} else {\n\t\ttokensMap := make(map[string]v1alpha1.JWTTokens)\n\t\ttokensMap[q.Role] = v1alpha1.JWTTokens{Items: items}\n\t\tprj.Status.JWTTokensByRole = tokensMap\n\t}\n\n\tprj.NormalizeJWTTokens()\n\n\t_, err = s.appclientset.ArgoprojV1alpha1().AppProjects(s.ns).Update(ctx, prj, metav1.UpdateOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ts.logEvent(prj, ctx, argo.EventReasonResourceCreated, \"created token\")\n\treturn &project.ProjectTokenResponse{Token: jwtToken}, nil\n\n}", "is_vulnerable": 1}
{"code": "func InotifyInit() (fd int, err error) {\n\treturn InotifyInit1(0)\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_OutgoingRPCConfig(t *testing.T) {\n\tc := Configurator{base: &Config{}}\n\trequire.Nil(t, c.OutgoingRPCConfig())\n\tc.base.VerifyOutgoing = true\n\trequire.NotNil(t, c.OutgoingRPCConfig())\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) genQuotaCmd(value *JuiceFS, mount datav1alpha1.Mount) error {\n\toptions := mount.Options\n\tfor k, v := range options {\n\t\tif k == \"quota\" {\n\t\t\tqs, err := j.getQuota(v)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"invalid quota %s\", v)\n\t\t\t}\n\t\t\tif value.Fuse.SubPath == \"\" {\n\t\t\t\treturn fmt.Errorf(\"subPath must be set when quota is enabled\")\n\t\t\t}\n\t\t\tif value.Edition == CommunityEdition {\n\t\t\t\t// ce\n\t\t\t\t// juicefs quota set ${metaurl} --path ${path} --capacity ${capacity}\n\t\t\t\tvalue.Configs.QuotaCmd = fmt.Sprintf(\"%s quota set %s --path %s --capacity %d\", common.JuiceCeCliPath, value.Source, security.EscapeBashStr(value.Fuse.SubPath), qs)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\t// ee\n\t\t\t// juicefs quota set ${metaurl} --path ${path} --capacity ${capacity}\n\t\t\tcli := common.JuiceCliPath\n\t\t\tvalue.Configs.QuotaCmd = fmt.Sprintf(\"%s quota set %s --path %s --capacity %d\", cli, value.Source, security.EscapeBashStr(value.Fuse.SubPath), qs)\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (e *ExecCommandError) DetailedError() string {\n\treturn fmt.Sprintf(\"failed executing %s %v, env vars %v, error %s, waitStatus %d, Output \\\"%s\\\"\", e.Command, removePullSecret(e.Args), removePullSecret(e.Env), e.ExitErr, e.WaitStatus, e.Output)\n}", "is_vulnerable": 0}
{"code": "func NewUsageClient(subscriptionID string) UsageClient {\n\treturn original.NewUsageClient(subscriptionID)\n}", "is_vulnerable": 1}
{"code": "\terr := h.cdb.WithTx(ctx, func(tx *sql.Tx) error {\n\t\tvar err error\n\t\tproof, err = h.checkMalicious(ctx, tx, atx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"check malicious: %w\", err)\n\t\t}\n\t\tnonce, err = atxs.AddGettingNonce(tx, atx)\n\t\tif err != nil && !errors.Is(err, sql.ErrObjectExists) {\n\t\t\treturn fmt.Errorf(\"add atx to db: %w\", err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (v *BlockValidator) ValidateState(block *types.Block, statedb *state.StateDB, receipts types.Receipts, usedGas uint64) error {\n\theader := block.Header()\n\tif block.GasUsed() != usedGas {\n\t\treturn fmt.Errorf(\"invalid gas used (remote: %d local: %d)\", block.GasUsed(), usedGas)\n\t}\n\t// Validate the received block's bloom with the one derived from the generated receipts.\n\t// For valid blocks this should always validate to true.\n\trbloom := types.CreateBloom(receipts)\n\tif rbloom != header.Bloom {\n\t\treturn fmt.Errorf(\"invalid bloom (remote: %x  local: %x)\", header.Bloom, rbloom)\n\t}\n\t// Tre receipt Trie's root (R = (Tr [[H1, R1], ... [Hn, R1]]))\n\treceiptSha := types.DeriveSha(receipts)\n\tif receiptSha != header.ReceiptHash {\n\t\treturn fmt.Errorf(\"invalid receipt root hash (remote: %x local: %x)\", header.ReceiptHash, receiptSha)\n\t}\n\t// Validate the state root against the received state root and throw\n\t// an error if they don't match.\n\tif root := statedb.IntermediateRoot(v.config.IsEIP158(header.Number)); header.Root != root {\n\t\treturn fmt.Errorf(\"invalid merkle root (remote: %x local: %x)\", header.Root, root)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *UnrecognizedWithInner) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: UnrecognizedWithInner: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: UnrecognizedWithInner: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Embedded\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Embedded = append(m.Embedded, &UnrecognizedWithInner_Inner{})\n\t\t\tif err := m.Embedded[len(m.Embedded)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Field2 = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestValidate(t *testing.T) {\n\ttests := []struct {\n\t\tmd  *Metadata\n\t\terr error\n\t}{\n\t\t{\n\t\t\tnil,\n\t\t\tValidationError(\"chart.metadata is required\"),\n\t\t},\n\t\t{\n\t\t\t&Metadata{Name: \"test\", Version: \"1.0\"},\n\t\t\tValidationError(\"chart.metadata.apiVersion is required\"),\n\t\t},\n\t\t{\n\t\t\t&Metadata{APIVersion: \"v2\", Version: \"1.0\"},\n\t\t\tValidationError(\"chart.metadata.name is required\"),\n\t\t},\n\t\t{\n\t\t\t&Metadata{Name: \"test\", APIVersion: \"v2\"},\n\t\t\tValidationError(\"chart.metadata.version is required\"),\n\t\t},\n\t\t{\n\t\t\t&Metadata{Name: \"test\", APIVersion: \"v2\", Version: \"1.0\", Type: \"test\"},\n\t\t\tValidationError(\"chart.metadata.type must be application or library\"),\n\t\t},\n\t\t{\n\t\t\t&Metadata{Name: \"test\", APIVersion: \"v2\", Version: \"1.0\", Type: \"application\"},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t&Metadata{\n\t\t\t\tName:       \"test\",\n\t\t\t\tAPIVersion: \"v2\",\n\t\t\t\tVersion:    \"1.0\",\n\t\t\t\tType:       \"application\",\n\t\t\t\tDependencies: []*Dependency{\n\t\t\t\t\t{Name: \"dependency\", Alias: \"legal-alias\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t&Metadata{\n\t\t\t\tName:       \"test\",\n\t\t\t\tAPIVersion: \"v2\",\n\t\t\t\tVersion:    \"1.0\",\n\t\t\t\tType:       \"application\",\n\t\t\t\tDependencies: []*Dependency{\n\t\t\t\t\t{Name: \"bad\", Alias: \"illegal alias\"},\n\t\t\t\t},\n\t\t\t},\n\t\t\tValidationError(\"dependency \\\"bad\\\" has disallowed characters in the alias\"),\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tresult := tt.md.Validate()\n\t\tif result != tt.err {\n\t\t\tt.Errorf(\"expected '%s', got '%s'\", tt.err, result)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestConfigFromBlockBadInput(t *testing.T) {\n\tfor _, testCase := range []struct {\n\t\tname          string\n\t\tblock         *common.Block\n\t\texpectedError string\n\t}{\n\t\t{\n\t\t\tname:          \"nil block\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         nil,\n\t\t},\n\t\t{\n\t\t\tname:          \"nil block data\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         &common.Block{},\n\t\t},\n\t\t{\n\t\t\tname:          \"no data in block\",\n\t\t\texpectedError: \"empty block\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid payload\",\n\t\t\texpectedError: \"error unmarshaling Envelope: proto: common.Envelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{Data: [][]byte{{1, 2, 3}}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"bad genesis block\",\n\t\t\texpectedError: \"invalid config envelope: proto: common.ConfigEnvelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{}, Data: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tData: []byte{1, 2, 3},\n\t\t\t\t\t}),\n\t\t\t\t})}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid envelope in block\",\n\t\t\texpectedError: \"error unmarshaling Envelope: proto: common.Envelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock:         &common.Block{Data: &common.BlockData{Data: [][]byte{{1, 2, 3}}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid payload in block envelope\",\n\t\t\texpectedError: \"error unmarshaling Payload: proto: common.Payload: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{Data: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\tPayload: []byte{1, 2, 3},\n\t\t\t})}}},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid channel header\",\n\t\t\texpectedError: \"error unmarshaling ChannelHeader: proto: common.ChannelHeader: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{Number: 1},\n\t\t\t\tData: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tHeader: &common.Header{\n\t\t\t\t\t\t\tChannelHeader: []byte{1, 2, 3},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t})}},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:          \"invalid config block\",\n\t\t\texpectedError: \"invalid config envelope: proto: common.ConfigEnvelope: illegal tag 0 (wire type 1)\",\n\t\t\tblock: &common.Block{\n\t\t\t\tHeader: &common.BlockHeader{},\n\t\t\t\tData: &common.BlockData{Data: [][]byte{protoutil.MarshalOrPanic(&common.Envelope{\n\t\t\t\t\tPayload: protoutil.MarshalOrPanic(&common.Payload{\n\t\t\t\t\t\tData: []byte{1, 2, 3},\n\t\t\t\t\t\tHeader: &common.Header{\n\t\t\t\t\t\t\tChannelHeader: protoutil.MarshalOrPanic(&common.ChannelHeader{\n\t\t\t\t\t\t\t\tType: int32(common.HeaderType_CONFIG),\n\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t})}},\n\t\t\t},\n\t\t},\n\t} {\n\t\tt.Run(testCase.name, func(t *testing.T) {\n\t\t\tconf, err := cluster.ConfigFromBlock(testCase.block)\n\t\t\tassert.Nil(t, conf)\n\t\t\tassert.EqualError(t, err, testCase.expectedError)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\tfunc(server string) bool {\n\t\t\t\treturn !strings.Contains(server, `more_set_headers \"Foo1: Bar1\";`)\n\t\t\t})", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) GetCompiler(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Compiler, error) {\n\tout := new(clientpb.Compiler)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetCompiler\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func testPrecompiledFailure(addr string, test precompiledFailureTest, t *testing.T) {\n\tp := allPrecompiles[common.HexToAddress(addr)]\n\tin := common.Hex2Bytes(test.Input)\n\tcontract := NewContract(AccountRef(common.HexToAddress(\"31337\")),\n\t\tnil, new(big.Int), p.RequiredGas(in))\n\n\tt.Run(test.Name, func(t *testing.T) {\n\t\t_, err := RunPrecompiledContract(p, in, contract)\n\t\tif err.Error() != test.ExpectedError {\n\t\t\tt.Errorf(\"Expected error [%v], got [%v]\", test.ExpectedError, err)\n\t\t}\n\t\t// Verify that the precompile did not touch the input buffer\n\t\texp := common.Hex2Bytes(test.Input)\n\t\tif !bytes.Equal(in, exp) {\n\t\t\tt.Errorf(\"Precompiled %v modified input data\", addr)\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func (a *awsLambda) PatchFilter(_ *extensioncommon.RuntimeConfig, filter *envoy_listener_v3.Filter, isInboundListener bool) (*envoy_listener_v3.Filter, bool, error) {\n\t// Only patch outbound filters.\n\tif isInboundListener {\n\t\treturn filter, false, nil\n\t}\n\n\tif filter.Name != \"envoy.filters.network.http_connection_manager\" {\n\t\treturn filter, false, nil\n\t}\n\tif typedConfig := filter.GetTypedConfig(); typedConfig == nil {\n\t\treturn filter, false, errors.New(\"error getting typed config for http filter\")\n\t}\n\n\tconfig := envoy_resource_v3.GetHTTPConnectionManager(filter)\n\tif config == nil {\n\t\treturn filter, false, errors.New(\"error unmarshalling filter\")\n\t}\n\n\tlambdaHttpFilter, err := extensioncommon.MakeEnvoyHTTPFilter(\n\t\t\"envoy.filters.http.aws_lambda\",\n\t\t&envoy_lambda_v3.Config{\n\t\t\tArn:                a.ARN,\n\t\t\tPayloadPassthrough: a.PayloadPassthrough,\n\t\t\tInvocationMode:     toEnvoyInvocationMode(a.InvocationMode),\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn filter, false, err\n\t}\n\n\t// We need to be careful about overwriting http filters completely because\n\t// http filters validates intentions with the RBAC filter. This inserts the\n\t// lambda filter before `envoy.filters.http.router` while keeping everything\n\t// else intact.\n\tchangedFilters := make([]*envoy_http_v3.HttpFilter, 0, len(config.HttpFilters)+1)\n\tvar changed bool\n\tfor _, httpFilter := range config.HttpFilters {\n\t\tif httpFilter.Name == \"envoy.filters.http.router\" {\n\t\t\tchangedFilters = append(changedFilters, lambdaHttpFilter)\n\t\t\tchanged = true\n\t\t}\n\t\tchangedFilters = append(changedFilters, httpFilter)\n\t}\n\tif changed {\n\t\tconfig.HttpFilters = changedFilters\n\t}\n\n\t// StripPortMode must be set to true since all requests have to be signed using the AWS v4 signature and\n\t// if the port is included in the request, it will be used in the signature calculation causing AWS to reject the\n\t// Lambda HTTP request.\n\tconfig.StripPortMode = &envoy_http_v3.HttpConnectionManager_StripAnyHostPort{\n\t\tStripAnyHostPort: true,\n\t}\n\tnewFilter, err := extensioncommon.MakeFilter(\"envoy.filters.network.http_connection_manager\", config)\n\tif err != nil {\n\t\treturn filter, false, errors.New(\"error making new filter\")\n\t}\n\n\treturn newFilter, true, nil\n}", "is_vulnerable": 0}
{"code": "func (a sslpt) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, sslPassthroughAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func parseTemplateConfigs(config *TaskTemplateManagerConfig) (map[*ctconf.TemplateConfig]*structs.Template, error) {\n\tallowAbs := config.ClientConfig.ReadBoolDefault(hostSrcOption, true)\n\ttaskEnv := config.EnvBuilder.Build()\n\n\tctmpls := make(map[*ctconf.TemplateConfig]*structs.Template, len(config.Templates))\n\tfor _, tmpl := range config.Templates {\n\t\tvar src, dest string\n\t\tif tmpl.SourcePath != \"\" {\n\t\t\tif filepath.IsAbs(tmpl.SourcePath) {\n\t\t\t\tif !allowAbs {\n\t\t\t\t\treturn nil, fmt.Errorf(\"Specifying absolute template paths disallowed by client config: %q\", tmpl.SourcePath)\n\t\t\t\t}\n\n\t\t\t\tsrc = tmpl.SourcePath\n\t\t\t} else {\n\t\t\t\tsrc = filepath.Join(config.TaskDir, taskEnv.ReplaceEnv(tmpl.SourcePath))\n\t\t\t}\n\t\t}\n\t\tif tmpl.DestPath != \"\" {\n\t\t\tdest = filepath.Join(config.TaskDir, taskEnv.ReplaceEnv(tmpl.DestPath))\n\t\t}\n\n\t\tct := ctconf.DefaultTemplateConfig()\n\t\tct.Source = &src\n\t\tct.Destination = &dest\n\t\tct.Contents = &tmpl.EmbeddedTmpl\n\t\tct.LeftDelim = &tmpl.LeftDelim\n\t\tct.RightDelim = &tmpl.RightDelim\n\t\tct.FunctionBlacklist = config.ClientConfig.TemplateConfig.FunctionBlacklist\n\t\tif !config.ClientConfig.TemplateConfig.DisableSandbox {\n\t\t\tct.SandboxPath = &config.TaskDir\n\t\t}\n\n\t\t// Set the permissions\n\t\tif tmpl.Perms != \"\" {\n\t\t\tv, err := strconv.ParseUint(tmpl.Perms, 8, 12)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"Failed to parse %q as octal: %v\", tmpl.Perms, err)\n\t\t\t}\n\t\t\tm := os.FileMode(v)\n\t\t\tct.Perms = &m\n\t\t}\n\t\tct.Finalize()\n\n\t\tctmpls[ct] = tmpl\n\t}\n\n\treturn ctmpls, nil\n}", "is_vulnerable": 1}
{"code": "func normalizeRawStringReader(raw string) *strings.Reader {\n\tvar builder strings.Builder\n\n\traw = strings.Trim(raw, `\"`)\n\traw = strings.ReplaceAll(raw, \"\\\\n\", \"\\n\")\n\traw = strings.ReplaceAll(raw, \"\\\\r\", \"\\r\")\n\tbuilder.WriteString(raw)\n\tbuilder.WriteString(\"\\r\\n\\r\\n\")\n\n\treturn strings.NewReader(builder.String())\n}\n\n// getClientIP to get client IP address from request\nfunc getClientIP(r *http.Request) string {\n\t// Get the client's IP address from the X-Real-Ip header field\n\tclientIP := r.Header.Get(\"X-Real-Ip\")\n\n\t// If the X-Real-Ip header field is not present, try the X-Forwarded-For header field\n\tif clientIP == \"\" {\n\t\tclientIP = r.Header.Get(\"X-Forwarded-For\")\n\t}\n\n\t// If the X-Forwarded-For header field is not present, use the RemoteAddr field\n\tif clientIP == \"\" {\n\t\tclientIP = r.RemoteAddr\n\t}\n\n\t// Returning client IP address\n\treturn clientIP\n}\n\n// setReqIdHeader to set teler request ID header response\nfunc setReqIdHeader(w http.ResponseWriter) string {\n\t// Generate a unique ID using the gouid package.\n\tid := gouid.Bytes(10)\n\n\t// Set the \"X-Teler-Req-Id\" header in the response with the unique ID.\n\tw.Header().Set(xTelerReqId, id.String())\n\n\treturn id.String()\n}\n\n// removeSpecialChars to remove special characters with empty string\n// includes line feed/newline, horizontal tab, backspace & form feed\nfunc removeSpecialChars(str string) string {\n\tstr = strings.Replace(str, \"\\n\", \"\", -1) // Replace all newline\n\tstr = strings.Replace(str, \"\\r\", \"\", -1) // Replace all carriage return\n\tstr = strings.Replace(str, \"\\t\", \"\", -1) // Replace all horizontal tab\n\tstr = strings.Replace(str, \"\\b\", \"\", -1) // Replace all backspace\n\tstr = strings.Replace(str, \"\\f\", \"\", -1) // Replace all form feed\n\n\treturn str\n}\n\n// getCache returns the cached error value for the given key.\n// If the key is not found in the cache or the value is nil, it returns nil, false.\n// When development flag is not set it will always return nil, false\nfunc (t *Teler) getCache(key string) (error, bool) {\n\tif t.opt.Development {\n\t\treturn nil, false\n\t}\n\n\tif msg, ok := t.cache.Get(key); ok {\n\t\tif msg == nil {\n\t\t\treturn nil, ok\n\t\t}\n\n\t\treturn msg.(error), ok\n\t}\n\n\treturn nil, false\n}\n\n// setCache sets the error value for the given key in the cache.\n// if msg is empty it sets a nil error, otherwise it creates a new error with the msg.\n// When development flag is not set it will return without setting anything in the cache\nfunc (t *Teler) setCache(key string, msg string) {\n\tif t.opt.Development {\n\t\treturn\n\t}\n\n\tvar err error\n\n\tif msg != \"\" {\n\t\terr = errors.New(msg)\n\t} else {\n\t\terr = nil\n\t}\n\n\tt.cache.Set(key, err, cache.DefaultExpiration)\n}", "is_vulnerable": 0}
{"code": "func (iv *ImageVerification) Validate(isAuditFailureAction bool, path *field.Path) (errs field.ErrorList) {\n\tcopy := iv\n\n\tif isAuditFailureAction && iv.MutateDigest {\n\t\terrs = append(errs, field.Invalid(path.Child(\"mutateDigest\"), iv.MutateDigest, \"mutateDigest must be set to false for \u2018Audit\u2019 failure action\"))\n\t}\n\n\tif len(copy.ImageReferences) == 0 {\n\t\terrs = append(errs, field.Invalid(path, iv, \"An image reference is required\"))\n\t}\n\n\tasPath := path.Child(\"attestations\")\n\tfor i, attestation := range copy.Attestations {\n\t\tattestationErrors := attestation.Validate(asPath.Index(i))\n\t\terrs = append(errs, attestationErrors...)\n\t}\n\n\tattestorsPath := path.Child(\"attestors\")\n\tfor i, as := range copy.Attestors {\n\t\tattestorErrors := as.Validate(attestorsPath.Index(i))\n\t\terrs = append(errs, attestorErrors...)\n\t}\n\n\tif iv.Type == Notary {\n\t\tfor _, attestorSet := range iv.Attestors {\n\t\t\tfor _, attestor := range attestorSet.Entries {\n\t\t\t\tif attestor.Keyless != nil {\n\t\t\t\t\terrs = append(errs, field.Invalid(attestorsPath, iv, \"Keyless field is not allowed for type notary\"))\n\t\t\t\t}\n\t\t\t\tif attestor.Keys != nil {\n\t\t\t\t\terrs = append(errs, field.Invalid(attestorsPath, iv, \"Keys field is not allowed for type notary\"))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "is_vulnerable": 0}
{"code": "func TestServer_LANReap(t *testing.T) {\n\tdir1, s1 := testServerWithConfig(t, func(c *Config) {\n\t\tc.Datacenter = \"dc1\"\n\t\tc.Bootstrap = true\n\t\tc.SerfFloodInterval = 100 * time.Millisecond\n\t\tc.SerfLANConfig.ReconnectTimeout = 250 * time.Millisecond\n\t\tc.SerfLANConfig.ReapInterval = 300 * time.Millisecond\n\t})\n\tdefer os.RemoveAll(dir1)\n\tdefer s1.Shutdown()\n\n\tdir2, s2 := testServerWithConfig(t, func(c *Config) {\n\t\tc.Datacenter = \"dc1\"\n\t\tc.Bootstrap = false\n\t\tc.SerfFloodInterval = 100 * time.Millisecond\n\t\tc.SerfLANConfig.ReconnectTimeout = 250 * time.Millisecond\n\t\tc.SerfLANConfig.ReapInterval = 300 * time.Millisecond\n\t})\n\tdefer os.RemoveAll(dir2)\n\n\tdir3, s3 := testServerWithConfig(t, func(c *Config) {\n\t\tc.Datacenter = \"dc1\"\n\t\tc.Bootstrap = false\n\t\tc.SerfFloodInterval = 100 * time.Millisecond\n\t\tc.SerfLANConfig.ReconnectTimeout = 250 * time.Millisecond\n\t\tc.SerfLANConfig.ReapInterval = 300 * time.Millisecond\n\t})\n\tdefer os.RemoveAll(dir3)\n\tdefer s3.Shutdown()\n\n\t// Try to join\n\tjoinLAN(t, s2, s1)\n\tjoinLAN(t, s3, s1)\n\n\ttestrpc.WaitForLeader(t, s1.RPC, \"dc1\")\n\ttestrpc.WaitForLeader(t, s2.RPC, \"dc1\")\n\ttestrpc.WaitForLeader(t, s3.RPC, \"dc1\")\n\n\tretry.Run(t, func(r *retry.R) {\n\t\trequire.Len(r, s1.LANMembers(), 3)\n\t\trequire.Len(r, s2.LANMembers(), 3)\n\t\trequire.Len(r, s3.LANMembers(), 3)\n\t})\n\n\t// Check the router has both\n\tretry.Run(t, func(r *retry.R) {\n\t\trequire.Len(r, s1.serverLookup.Servers(), 3)\n\t\trequire.Len(r, s2.serverLookup.Servers(), 3)\n\t\trequire.Len(r, s3.serverLookup.Servers(), 3)\n\t})\n\n\t// shutdown the second dc\n\ts2.Shutdown()\n\n\tretry.Run(t, func(r *retry.R) {\n\t\trequire.Len(r, s1.LANMembers(), 2)\n\t\tservers := s1.serverLookup.Servers()\n\t\trequire.Len(r, servers, 2)\n\t\t// require.Equal(r, s1.config.NodeName, servers[0].Name)\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestDownloadArtifactFile(t *testing.T) {\n\tassert := assert.New(t)\n\n\tvar memfs = fstest.MapFS(map[string]*fstest.MapFile{\n\t\t\"artifact/server/path/1/some/file\": {\n\t\t\tData: []byte(\"content\"),\n\t\t},\n\t})\n\n\trouter := httprouter.New()\n\tdownloads(router, \"artifact/server/path\", memfs)\n\n\treq, _ := http.NewRequest(\"GET\", \"http://localhost/artifact/1/some/file\", nil)\n\trr := httptest.NewRecorder()\n\n\trouter.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tassert.FailNow(fmt.Sprintf(\"Wrong status: %d\", status))\n\t}\n\n\tdata := rr.Body.Bytes()\n\n\tassert.Equal(\"content\", string(data))\n}", "is_vulnerable": 0}
{"code": "func (mr *MockTransactionalMockRecorder) Commit(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Commit\", reflect.TypeOf((*MockTransactional)(nil).Commit), arg0)\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) GetGrantTypes() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetGrantTypes\", reflect.TypeOf((*MockAccessRequester)(nil).GetGrantTypes))\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) assignStorageTasks(success chan *storageResponse, fail chan *storageRequest, cancel chan struct{}) {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\t// Sort the peers by download capacity to use faster ones if many available\n\tidlers := &capacitySort{\n\t\tids:  make([]string, 0, len(s.storageIdlers)),\n\t\tcaps: make([]int, 0, len(s.storageIdlers)),\n\t}\n\ttargetTTL := s.rates.TargetTimeout()\n\tfor id := range s.storageIdlers {\n\t\tif _, ok := s.statelessPeers[id]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tidlers.ids = append(idlers.ids, id)\n\t\tidlers.caps = append(idlers.caps, s.rates.Capacity(id, StorageRangesMsg, targetTTL))\n\t}\n\tif len(idlers.ids) == 0 {\n\t\treturn\n\t}\n\tsort.Sort(sort.Reverse(idlers))\n\n\t// Iterate over all the tasks and try to find a pending one\n\tfor _, task := range s.tasks {\n\t\t// Skip any tasks not in the storage retrieval phase\n\t\tif task.res == nil {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip tasks that are already retrieving (or done with) all small states\n\t\tstorageTasks := task.activeSubTasks()\n\t\tif len(storageTasks) == 0 && len(task.stateTasks) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Task pending retrieval, try to find an idle peer. If no such peer\n\t\t// exists, we probably assigned tasks for all (or they are stateless).\n\t\t// Abort the entire assignment mechanism.\n\t\tif len(idlers.ids) == 0 {\n\t\t\treturn\n\t\t}\n\t\tvar (\n\t\t\tidle = idlers.ids[0]\n\t\t\tpeer = s.peers[idle]\n\t\t\tcap  = idlers.caps[0]\n\t\t)\n\t\tidlers.ids, idlers.caps = idlers.ids[1:], idlers.caps[1:]\n\n\t\t// Matched a pending task to an idle peer, allocate a unique request id\n\t\tvar reqid uint64\n\t\tfor {\n\t\t\treqid = uint64(rand.Int63())\n\t\t\tif reqid == 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, ok := s.storageReqs[reqid]; ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\t// Generate the network query and send it to the peer. If there are\n\t\t// large contract tasks pending, complete those before diving into\n\t\t// even more new contracts.\n\t\tif cap > maxRequestSize {\n\t\t\tcap = maxRequestSize\n\t\t}\n\t\tif cap < minRequestSize { // Don't bother with peers below a bare minimum performance\n\t\t\tcap = minRequestSize\n\t\t}\n\t\tstorageSets := cap / 1024\n\n\t\tvar (\n\t\t\taccounts = make([]common.Hash, 0, storageSets)\n\t\t\troots    = make([]common.Hash, 0, storageSets)\n\t\t\tsubtask  *storageTask\n\t\t)\n\t\tfor account, subtasks := range storageTasks {\n\t\t\tfor _, st := range subtasks {\n\t\t\t\t// Skip any subtasks already filling\n\t\t\t\tif st.req != nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// Found an incomplete storage chunk, schedule it\n\t\t\t\taccounts = append(accounts, account)\n\t\t\t\troots = append(roots, st.root)\n\t\t\t\tsubtask = st\n\t\t\t\tbreak // Large contract chunks are downloaded individually\n\t\t\t}\n\t\t\tif subtask != nil {\n\t\t\t\tbreak // Large contract chunks are downloaded individually\n\t\t\t}\n\t\t}\n\t\tif subtask == nil {\n\t\t\t// No large contract required retrieval, but small ones available\n\t\t\tfor account, root := range task.stateTasks {\n\t\t\t\tdelete(task.stateTasks, account)\n\n\t\t\t\taccounts = append(accounts, account)\n\t\t\t\troots = append(roots, root)\n\n\t\t\t\tif len(accounts) >= storageSets {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// If nothing was found, it means this task is actually already fully\n\t\t// retrieving, but large contracts are hard to detect. Skip to the next.\n\t\tif len(accounts) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\treq := &storageRequest{\n\t\t\tpeer:     idle,\n\t\t\tid:       reqid,\n\t\t\ttime:     time.Now(),\n\t\t\tdeliver:  success,\n\t\t\trevert:   fail,\n\t\t\tcancel:   cancel,\n\t\t\tstale:    make(chan struct{}),\n\t\t\taccounts: accounts,\n\t\t\troots:    roots,\n\t\t\tmainTask: task,\n\t\t\tsubTask:  subtask,\n\t\t}\n\t\tif subtask != nil {\n\t\t\treq.origin = subtask.Next\n\t\t\treq.limit = subtask.Last\n\t\t}\n\t\treq.timeout = time.AfterFunc(s.rates.TargetTimeout(), func() {\n\t\t\tpeer.Log().Debug(\"Storage request timed out\", \"reqid\", reqid)\n\t\t\ts.rates.Update(idle, StorageRangesMsg, 0, 0)\n\t\t\ts.scheduleRevertStorageRequest(req)\n\t\t})\n\t\ts.storageReqs[reqid] = req\n\t\tdelete(s.storageIdlers, idle)\n\n\t\ts.pend.Add(1)\n\t\tgo func(root common.Hash) {\n\t\t\tdefer s.pend.Done()\n\n\t\t\t// Attempt to send the remote request and revert if it fails\n\t\t\tvar origin, limit []byte\n\t\t\tif subtask != nil {\n\t\t\t\torigin, limit = req.origin[:], req.limit[:]\n\t\t\t}\n\t\t\tif err := peer.RequestStorageRanges(reqid, root, accounts, origin, limit, uint64(cap)); err != nil {\n\t\t\t\tlog.Debug(\"Failed to request storage\", \"err\", err)\n\t\t\t\ts.scheduleRevertStorageRequest(req)\n\t\t\t}\n\t\t}(s.root)\n\n\t\t// Inject the request into the subtask to block further assignments\n\t\tif subtask != nil {\n\t\t\tsubtask.req = req\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func UtxoToken(sc *SmartContract, toID int64, value string) (flag bool, err error) {\n\n\tcache := sc.PrevSysPar\n\tgetParams := func(name string) (map[int64]string, error) {\n\t\tres := make(map[int64]string)\n\t\tif len(cache[name]) > 0 {\n\t\t\tifuels := make([][]string, 0)\n\t\t\terr = json.Unmarshal([]byte(cache[name]), &ifuels)\n\t\t\tif err != nil {\n\t\t\t\tlog.WithFields(log.Fields{\"type\": consts.JSONUnmarshallError, \"error\": err}).Error(\"unmarshalling params from json\")\n\t\t\t\treturn res, err\n\t\t\t}\n\t\t\tfor _, item := range ifuels {\n\t\t\t\tif len(item) < 2 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tres[converter.StrToInt64(item[0])] = item[1]\n\t\t\t}\n\t\t}\n\t\treturn res, nil\n\t}\n\tvar fuels = make(map[int64]string)\n\tvar wallets = make(map[int64]string)\n\tvar expediteFee decimal.Decimal\n\tfuels, err = getParams(syspar.FuelRate)\n\twallets, err = getParams(syspar.TaxesWallet)\n\n\tfromID := sc.TxSmart.KeyID\n\toutputsMap := sc.OutputsMap\n\ttxInputsMap := sc.TxInputsMap\n\ttxOutputsMap := sc.TxOutputsMap\n\tcomPercents := sc.ComPercents\n\t//txHash := sc.Hash\n\tecosystem := sc.TxSmart.EcosystemID\n\tblockId := sc.BlockHeader.BlockId\n\t//dbTx := sc.DbTransaction\n\tkeyUTXO := sqldb.KeyUTXO{Ecosystem: ecosystem, KeyId: fromID}\n\n\ttxInputs := sqldb.GetUnusedOutputsMap(keyUTXO, outputsMap)\n\tif len(txInputs) == 0 {\n\t\treturn false, fmt.Errorf(eEcoCurrentBalance, converter.IDToAddress(fromID), ecosystem)\n\t}\n\tif expediteFee, err = sc.expediteFee(); err != nil {\n\t\treturn false, err\n\t}\n\ttotalAmount := decimal.Zero\n\n\tvar txOutputs []sqldb.SpentInfo\n\n\tfor _, input := range txInputs {\n\t\toutputValue, _ := decimal.NewFromString(input.OutputValue)\n\t\ttotalAmount = totalAmount.Add(outputValue)\n\t}\n\n\tvar outputIndex int32 = 0\n\n\t// taxes_size = 3\n\tTaxesSize := syspar.SysInt64(syspar.TaxesSize)\n\n\t// if : ecosystem = 2 ,rule : taxes ecosystem 1 and 2\n\tif ecosystem != consts.DefaultTokenEcosystem {\n\t\t// rule : taxes ecosystem 1\n\t\t{\n\t\t\tvar txOutputs1 []sqldb.SpentInfo\n\t\t\tecosystem1 := int64(consts.DefaultTokenEcosystem)\n\t\t\tkeyUTXO1 := sqldb.KeyUTXO{Ecosystem: ecosystem1, KeyId: fromID}\n\t\t\ttxInputs1 := sqldb.GetUnusedOutputsMap(keyUTXO1, outputsMap)\n\t\t\tif len(txInputs1) == 0 {\n\t\t\t\treturn false, fmt.Errorf(eEcoCurrentBalance, converter.IDToAddress(fromID), ecosystem1)\n\t\t\t}\n\t\t\ttotalAmount1 := decimal.Zero\n\n\t\t\tfor _, input1 := range txInputs1 {\n\t\t\t\toutputValue1, _ := decimal.NewFromString(input1.OutputValue)\n\t\t\t\ttotalAmount1 = totalAmount1.Add(outputValue1)\n\t\t\t}\n\t\t\tvar money1 = decimal.Zero\n\t\t\tvar fuelRate1 = decimal.Zero\n\t\t\tvar taxes1 = decimal.Zero\n\t\t\tif ret, ok := fuels[ecosystem1]; ok {\n\n\t\t\t\tfuelRate1, err = decimal.NewFromString(ret)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t\t//\tecosystem fuelRate /10 *( bit + len(input))\n\t\t\t\tmoney1 = fuelRate1.Div(decimal.NewFromInt(10)).Mul(decimal.NewFromInt(sc.TxSize).Add(decimal.NewFromInt(int64(len(txInputs1)))))\n\t\t\t\t// utxo ecosystem 1 expediteFee\n\t\t\t\tmoney1 = money1.Add(expediteFee.Mul(fuelRate1))\n\t\t\t\tif money1.GreaterThan(totalAmount1) {\n\t\t\t\t\tmoney1 = totalAmount1\n\t\t\t\t}\n\n\t\t\t\ttaxes1 = money1.Mul(decimal.NewFromInt(TaxesSize)).Div(decimal.New(100, 0)).Floor()\n\n\t\t\t}\n\t\t\tif money1.GreaterThan(decimal.Zero) && taxes1.GreaterThan(decimal.Zero) {\n\t\t\t\tif taxesWallet, ok := wallets[ecosystem1]; ok {\n\t\t\t\t\ttaxesID := converter.StrToInt64(taxesWallet)\n\n\t\t\t\t\tflag = true\n\t\t\t\t\t// 97%\n\t\t\t\t\ttxOutputs1 = append(txOutputs1, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: sc.BlockHeader.KeyId, OutputValue: money1.Sub(taxes1).String(), BlockId: blockId, Ecosystem: ecosystem1, Type: consts.UTXO_Type_Packaging})\n\t\t\t\t\toutputIndex++\n\t\t\t\t\t// 3%\n\t\t\t\t\ttxOutputs1 = append(txOutputs1, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: taxesID, OutputValue: taxes1.String(), BlockId: blockId, Ecosystem: ecosystem1, Type: consts.UTXO_Type_Taxes})\n\t\t\t\t\toutputIndex++\n\t\t\t\t\ttotalAmount1 = totalAmount1.Sub(money1)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif totalAmount1.GreaterThan(decimal.Zero) {\n\t\t\t\ttxOutputs1 = append(txOutputs1, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: fromID, OutputValue: totalAmount1.String(), BlockId: blockId, Ecosystem: ecosystem1, Type: consts.UTXO_Type_Output}) // The change\n\t\t\t\toutputIndex++\n\t\t\t}\n\n\t\t\tif len(txInputs1) > 0 && len(txOutputs1) > 0 {\n\t\t\t\tsqldb.PutAllOutputsMap(txInputs1, txInputsMap)\n\t\t\t\tsqldb.PutAllOutputsMap(txOutputs1, txOutputsMap)\n\t\t\t}\n\n\t\t}\n\t\t// rule : taxes ecosystem 2\n\t\t{\n\t\t\tecosystem2 := ecosystem\n\t\t\tvar money2 = decimal.Zero\n\t\t\tvar fuelRate2 = decimal.Zero\n\t\t\tvar taxes2 = decimal.Zero\n\t\t\tret, ok := fuels[ecosystem2]\n\t\t\tpercent, hasPercent := comPercents[ecosystem2]\n\t\t\tif ok && hasPercent {\n\n\t\t\t\tfuelRate2, err = decimal.NewFromString(ret)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t\t//\tecosystem fuelRate /10 *( bit + len(input))\n\t\t\t\tmoney2 = fuelRate2.Div(decimal.NewFromInt(10)).Mul(decimal.NewFromInt(sc.TxSize).Add(decimal.NewFromInt(int64(len(txInputs)))))\n\n\t\t\t\tif money2.GreaterThan(totalAmount) {\n\t\t\t\t\tmoney2 = totalAmount\n\t\t\t\t}\n\t\t\t\tpercentMoney2 := decimal.Zero\n\t\t\t\tif percent > 0 && money2.GreaterThan(decimal.Zero) {\n\t\t\t\t\tpercentMoney2 = money2.Mul(decimal.NewFromInt(percent)).Div(decimal.New(100, 0)).Floor()\n\t\t\t\t\tif percentMoney2.GreaterThan(decimal.Zero) {\n\t\t\t\t\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: 0, OutputValue: percentMoney2.String(), BlockId: blockId, Ecosystem: ecosystem2, Type: consts.UTXO_Type_Combustion})\n\t\t\t\t\t\toutputIndex++\n\t\t\t\t\t\tmoney2 = money2.Sub(percentMoney2)\n\t\t\t\t\t\ttotalAmount = totalAmount.Sub(percentMoney2)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttaxes2 = money2.Mul(decimal.NewFromInt(TaxesSize)).Div(decimal.New(100, 0)).Floor()\n\t\t\t}\n\t\t\tif money2.GreaterThan(decimal.Zero) && taxes2.GreaterThan(decimal.Zero) {\n\t\t\t\tif taxesWallet, ok := wallets[ecosystem2]; ok {\n\t\t\t\t\ttaxesID := converter.StrToInt64(taxesWallet)\n\n\t\t\t\t\tflag = true\n\t\t\t\t\t// 97%\n\t\t\t\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: sc.BlockHeader.KeyId, OutputValue: money2.Sub(taxes2).String(), BlockId: blockId, Ecosystem: ecosystem2, Type: consts.UTXO_Type_Packaging})\n\t\t\t\t\toutputIndex++\n\t\t\t\t\t// 3%\n\t\t\t\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: taxesID, OutputValue: taxes2.String(), BlockId: blockId, Ecosystem: ecosystem2, Type: consts.UTXO_Type_Taxes})\n\t\t\t\t\toutputIndex++\n\t\t\t\t\ttotalAmount = totalAmount.Sub(money2)\n\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// if : ecosystem = 1 , rule : taxes ecosystem 1\n\tif ecosystem == consts.DefaultTokenEcosystem {\n\t\tecosystem1 := int64(consts.DefaultTokenEcosystem)\n\t\tvar money1 = decimal.Zero\n\t\tvar fuelRate1 = decimal.Zero\n\t\tvar taxes1 = decimal.Zero\n\t\tif ret, ok := fuels[ecosystem1]; ok {\n\n\t\t\tfuelRate1, err = decimal.NewFromString(ret)\n\t\t\tif err != nil {\n\t\t\t\treturn false, err\n\t\t\t} else {\n\t\t\t\t//\tecosystem fuelRate /10 *( bit + len(input))\n\t\t\t\tmoney1 = fuelRate1.Div(decimal.NewFromInt(10)).Mul(decimal.NewFromInt(sc.TxSize).Add(decimal.NewFromInt(int64(len(txInputs)))))\n\t\t\t\t// utxo ecosystem 1 expediteFee\n\t\t\t\tmoney1 = money1.Add(expediteFee.Mul(fuelRate1))\n\t\t\t\tif money1.GreaterThan(totalAmount) {\n\t\t\t\t\tmoney1 = totalAmount\n\t\t\t\t}\n\t\t\t\ttaxes1 = money1.Mul(decimal.NewFromInt(TaxesSize)).Div(decimal.New(100, 0)).Floor()\n\t\t\t}\n\t\t}\n\t\tif money1.GreaterThan(decimal.Zero) && taxes1.GreaterThan(decimal.Zero) {\n\t\t\tif taxesWallet, ok := wallets[ecosystem1]; ok {\n\t\t\t\ttaxesID := converter.StrToInt64(taxesWallet)\n\n\t\t\t\tflag = true\n\t\t\t\t// 97%\n\t\t\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: sc.BlockHeader.KeyId, OutputValue: money1.Sub(taxes1).String(), BlockId: blockId, Ecosystem: ecosystem1, Type: consts.UTXO_Type_Packaging})\n\t\t\t\toutputIndex++\n\t\t\t\t// 3%\n\t\t\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: taxesID, OutputValue: taxes1.String(), BlockId: blockId, Ecosystem: ecosystem1, Type: consts.UTXO_Type_Taxes})\n\t\t\t\toutputIndex++\n\t\t\t\ttotalAmount = totalAmount.Sub(money1)\n\n\t\t\t}\n\t\t}\n\n\t}\n\n\tpayValue, _ := decimal.NewFromString(value)\n\tif totalAmount.GreaterThanOrEqual(payValue) && payValue.GreaterThan(decimal.Zero) {\n\t\tflag = true // The transfer was successful\n\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: toID, OutputValue: value, BlockId: blockId, Ecosystem: ecosystem, Type: consts.UTXO_Type_Transfer})\n\t\toutputIndex++\n\t\ttotalAmount = totalAmount.Sub(payValue)\n\t} else {\n\t\tflag = false\n\t\terr = fmt.Errorf(eEcoCurrentBalance, converter.IDToAddress(fromID), ecosystem)\n\t}\n\n\t// The change\n\tif totalAmount.GreaterThan(decimal.Zero) {\n\t\ttxOutputs = append(txOutputs, sqldb.SpentInfo{OutputIndex: outputIndex, OutputKeyId: fromID, OutputValue: totalAmount.String(), BlockId: blockId, Ecosystem: ecosystem, Type: consts.UTXO_Type_Output}) // The change\n\t\toutputIndex++\n\t}\n\tif len(txInputs) > 0 && len(txOutputs) > 0 {\n\t\tsqldb.PutAllOutputsMap(txInputs, txInputsMap)\n\t\tsqldb.PutAllOutputsMap(txOutputs, txOutputsMap)\n\t}\n\tsc.TxInputsMap = txInputsMap\n\tsc.TxOutputsMap = txOutputsMap\n\treturn flag, err\n}", "is_vulnerable": 0}
{"code": "func (src *NoticeResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'N')\n\tdst = (*ErrorResponse)(src).appendFields(dst)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func cmdList(args *docopt.Args, client *tuf.Client) error {\n\tif _, err := client.Update(); err != nil && !tuf.IsLatestSnapshot(err) {\n\t\treturn err\n\t}\n\ttargets, err := client.Targets()\n\tif err != nil {\n\t\treturn err\n\t}\n\tw := tabwriter.NewWriter(os.Stdout, 1, 2, 2, ' ', 0)\n\tdefer w.Flush()\n\tfmt.Fprintln(w, \"PATH\\tSIZE\")\n\tfor path, meta := range targets {\n\t\tfmt.Fprintf(w, \"%s\\t%s\\n\", path, humanize.Bytes(uint64(meta.Length)))\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tdir := \"../../examples/event-sources\"\n\tdirEntries, err := os.ReadDir(dir)\n\tassert.Nil(t, err)\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar es *v1alpha1.EventSource\n\t\terr = yaml.Unmarshal(content, &es)\n\t\tassert.Nil(t, err)\n\t\tes.Namespace = testNamespace\n\t\tnewEs := es.DeepCopy()\n\t\tnewEs.Generation++\n\t\tv := NewEventSourceValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, es, newEs)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_IncomingRPCConfig(t *testing.T) {\n\tc, err := NewConfigurator(Config{\n\t\tVerifyIncomingRPC: true,\n\t\tCAFile:            \"../test/ca/root.cer\",\n\t\tCertFile:          \"../test/key/ourdomain.cer\",\n\t\tKeyFile:           \"../test/key/ourdomain.key\",\n\t}, nil)\n\trequire.NoError(t, err)\n\ttlsConf := c.IncomingRPCConfig()\n\trequire.Equal(t, tls.RequireAndVerifyClientCert, tlsConf.ClientAuth)\n\trequire.NotNil(t, tlsConf.GetConfigForClient)\n\ttlsConf, err = tlsConf.GetConfigForClient(nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, tls.RequireAndVerifyClientCert, tlsConf.ClientAuth)\n}", "is_vulnerable": 0}
{"code": "func TestIngressRewriteLogConfig(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"enable-rewrite-log\")] = \"true\"\n\ting.SetAnnotations(data)\n\n\tlog, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\tnginxLogs, ok := log.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected a Config type\")\n\t}\n\n\tif !nginxLogs.Rewrite {\n\t\tt.Errorf(\"expected rewrite log to be enabled but it is disabled\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (ev *WebSocketEvent) DeepCopy() *WebSocketEvent {\n\tevCopy := &WebSocketEvent{\n\t\tevent:           ev.event,\n\t\tdata:            copyMap(ev.data),\n\t\tbroadcast:       ev.broadcast.copy(),\n\t\tsequence:        ev.sequence,\n\t\tprecomputedJSON: ev.precomputedJSON.copy(),\n\t}\n\treturn evCopy\n}", "is_vulnerable": 0}
{"code": "func (context *DatabaseContext) buildSequenceQuery(sequences []uint64) (statement string) {\n\n\tsequenceQueryStatement := replaceSyncTokensQuery(QuerySequences.statement, context.UseXattrs())\n\n\t// Convert []uint64 to N1QL array predicate format, e.g. [1,4,5], and replace token in QueryStarChannelWithSequences\n\tsequenceArrayString := fmt.Sprint(sequences)\n\tcommaDelimitedSequences := strings.Replace(sequenceArrayString, \" \", \",\", -1)\n\tsequenceQueryStatement = strings.Replace(sequenceQueryStatement, \"$\"+QueryParamInSequences, commaDelimitedSequences, -1)\n\n\treturn sequenceQueryStatement\n}", "is_vulnerable": 1}
{"code": "func generateManifestHash(un *unstructured.Unstructured, ignores []v1alpha1.ResourceIgnoreDifferences, overrides map[string]v1alpha1.ResourceOverride) (string, error) {\n\tnormalizer, err := normalizers.NewIgnoreNormalizer(ignores, overrides)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error creating normalizer: %w\", err)\n\t}\n\n\tresource := un.DeepCopy()\n\terr = normalizer.Normalize(resource)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error normalizing resource: %w\", err)\n\t}\n\n\tdata, err := resource.MarshalJSON()\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"error marshaling resource: %w\", err)\n\t}\n\thash := hash(data)\n\treturn hash, nil\n}", "is_vulnerable": 1}
{"code": "func (rq *resourceQueue) addPossibleResource(pr possibleResource) {\n\trq.lock.Lock()\n\tdefer rq.lock.Unlock()\n\n\tif pr.lookupResult != nil {\n\t\trq.toPublish[pr.orderingIndex] = pr\n\t} else {\n\t\trq.toProcess[pr.orderingIndex] = pr\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *Pull) Run(chartRef string) (string, error) {\n\tvar out strings.Builder\n\n\tc := downloader.ChartDownloader{\n\t\tOut:     &out,\n\t\tKeyring: p.Keyring,\n\t\tVerify:  downloader.VerifyNever,\n\t\tGetters: getter.All(p.Settings),\n\t\tOptions: []getter.Option{\n\t\t\tgetter.WithBasicAuth(p.Username, p.Password),\n\t\t\tgetter.WithTLSClientConfig(p.CertFile, p.KeyFile, p.CaFile),\n\t\t\tgetter.WithInsecureSkipVerifyTLS(p.InsecureSkipTLSverify),\n\t\t},\n\t\tRepositoryConfig: p.Settings.RepositoryConfig,\n\t\tRepositoryCache:  p.Settings.RepositoryCache,\n\t}\n\n\tif strings.HasPrefix(chartRef, \"oci://\") {\n\t\tif p.Version == \"\" {\n\t\t\treturn out.String(), errors.Errorf(\"--version flag is explicitly required for OCI registries\")\n\t\t}\n\n\t\tc.Options = append(c.Options,\n\t\t\tgetter.WithRegistryClient(p.cfg.RegistryClient),\n\t\t\tgetter.WithTagName(p.Version))\n\t}\n\n\tif p.Verify {\n\t\tc.Verify = downloader.VerifyAlways\n\t} else if p.VerifyLater {\n\t\tc.Verify = downloader.VerifyLater\n\t}\n\n\t// If untar is set, we fetch to a tempdir, then untar and copy after\n\t// verification.\n\tdest := p.DestDir\n\tif p.Untar {\n\t\tvar err error\n\t\tdest, err = ioutil.TempDir(\"\", \"helm-\")\n\t\tif err != nil {\n\t\t\treturn out.String(), errors.Wrap(err, \"failed to untar\")\n\t\t}\n\t\tdefer os.RemoveAll(dest)\n\t}\n\n\tif p.RepoURL != \"\" {\n\t\tchartURL, err := repo.FindChartInAuthAndTLSRepoURL(p.RepoURL, p.Username, p.Password, chartRef, p.Version, p.CertFile, p.KeyFile, p.CaFile, p.InsecureSkipTLSverify, getter.All(p.Settings))\n\t\tif err != nil {\n\t\t\treturn out.String(), err\n\t\t}\n\t\tchartRef = chartURL\n\t}\n\n\tsaved, v, err := c.DownloadTo(chartRef, p.Version, dest)\n\tif err != nil {\n\t\treturn out.String(), err\n\t}\n\n\tif p.Verify {\n\t\tfor name := range v.SignedBy.Identities {\n\t\t\tfmt.Fprintf(&out, \"Signed by: %v\\n\", name)\n\t\t}\n\t\tfmt.Fprintf(&out, \"Using Key With Fingerprint: %X\\n\", v.SignedBy.PrimaryKey.Fingerprint)\n\t\tfmt.Fprintf(&out, \"Chart Hash Verified: %s\\n\", v.FileHash)\n\t}\n\n\t// After verification, untar the chart into the requested directory.\n\tif p.Untar {\n\t\tud := p.UntarDir\n\t\tif !filepath.IsAbs(ud) {\n\t\t\tud = filepath.Join(p.DestDir, ud)\n\t\t}\n\t\t// Let udCheck to check conflict file/dir without replacing ud when untarDir is the current directory(.).\n\t\tudCheck := ud\n\t\tif udCheck == \".\" {\n\t\t\t_, udCheck = filepath.Split(chartRef)\n\t\t} else {\n\t\t\t_, chartName := filepath.Split(chartRef)\n\t\t\tudCheck = filepath.Join(udCheck, chartName)\n\t\t}\n\n\t\tif _, err := os.Stat(udCheck); err != nil {\n\t\t\tif err := os.MkdirAll(udCheck, 0755); err != nil {\n\t\t\t\treturn out.String(), errors.Wrap(err, \"failed to untar (mkdir)\")\n\t\t\t}\n\n\t\t} else {\n\t\t\treturn out.String(), errors.Errorf(\"failed to untar: a file or directory with the name %s already exists\", udCheck)\n\t\t}\n\n\t\treturn out.String(), chartutil.ExpandFile(ud, saved)\n\t}\n\treturn out.String(), nil\n}", "is_vulnerable": 1}
{"code": "func (g *Getter) Get(ctx context.Context, req *getter.Request) error {\n\n\tif g.Timeout > 0 {\n\t\tvar cancel context.CancelFunc\n\t\tctx, cancel = context.WithTimeout(ctx, g.Timeout)\n\t\tdefer cancel()\n\t}\n\n\t// Parse URL\n\tregion, bucket, path, _, creds, err := g.parseUrl(req.URL())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Remove destination if it already exists\n\t_, err = os.Stat(req.Dst)\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\n\tif err == nil {\n\t\t// Remove the destination\n\t\tif err := os.RemoveAll(req.Dst); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Create all the parent directories\n\tif err := os.MkdirAll(filepath.Dir(req.Dst), req.Mode(0755)); err != nil {\n\t\treturn err\n\t}\n\n\tclient, err := g.newS3Client(region, req.URL(), creds)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// List files in path, keep listing until no more objects are found\n\tlastMarker := \"\"\n\thasMore := true\n\tfor hasMore {\n\t\ts3Req := &s3.ListObjectsInput{\n\t\t\tBucket: aws.String(bucket),\n\t\t\tPrefix: aws.String(path),\n\t\t}\n\t\tif lastMarker != \"\" {\n\t\t\ts3Req.Marker = aws.String(lastMarker)\n\t\t}\n\n\t\tresp, err := client.ListObjectsWithContext(ctx, s3Req)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thasMore = aws.BoolValue(resp.IsTruncated)\n\n\t\t// Get each object storing each file relative to the destination path\n\t\tfor _, object := range resp.Contents {\n\t\t\tlastMarker = aws.StringValue(object.Key)\n\t\t\tobjPath := aws.StringValue(object.Key)\n\n\t\t\t// If the key ends with a backslash assume it is a directory and ignore\n\t\t\tif strings.HasSuffix(objPath, \"/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Get the object destination path\n\t\t\tobjDst, err := filepath.Rel(path, objPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tobjDst = filepath.Join(req.Dst, objDst)\n\n\t\t\tif err := g.getObject(ctx, client, req, objDst, bucket, objPath, \"\"); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func RunTestWatchContextCancel(ctx context.Context, t *testing.T, store storage.Interface) {\n\tcanceledCtx, cancel := context.WithCancel(ctx)\n\tcancel()\n\t// When we watch with a canceled context, we should detect that it's context canceled.\n\t// We won't take it as error and also close the watcher.\n\tw, err := store.Watch(canceledCtx, \"/abc\", storage.ListOptions{\n\t\tResourceVersion: \"0\",\n\t\tPredicate:       storage.Everything,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tselect {\n\tcase _, ok := <-w.ResultChan():\n\t\tif ok {\n\t\t\tt.Error(\"ResultChan() should be closed\")\n\t\t}\n\tcase <-time.After(wait.ForeverTestTimeout):\n\t\tt.Errorf(\"timeout after %v\", wait.ForeverTestTimeout)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (l *peerLedger) CancelWant(p peer.ID, k cid.Cid) bool {\n\twants, ok := l.peers[p]\n\tif !ok {\n\t\treturn false\n\t}\n\tdelete(wants, k)\n\tif len(wants) == 0 {\n\t\tdelete(l.peers, p)\n\t}\n\n\tl.removePeerFromCid(p, k)\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func ExampleDial() {\n\tvar hostKey ssh.PublicKey\n\t// An SSH client is represented with a ClientConn.\n\t//\n\t// To authenticate with the remote server you must pass at least one\n\t// implementation of AuthMethod via the Auth field in ClientConfig,\n\t// and provide a HostKeyCallback.\n\tconfig := &ssh.ClientConfig{\n\t\tUser: \"username\",\n\t\tAuth: []ssh.AuthMethod{\n\t\t\tssh.Password(\"yourpassword\"),\n\t\t},\n\t\tHostKeyCallback: ssh.FixedHostKey(hostKey),\n\t}\n\tclient, err := ssh.Dial(\"tcp\", \"yourserver.com:22\", config)\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to dial: \", err)\n\t}\n\n\t// Each ClientConn can support multiple interactive sessions,\n\t// represented by a Session.\n\tsession, err := client.NewSession()\n\tif err != nil {\n\t\tlog.Fatal(\"Failed to create session: \", err)\n\t}\n\tdefer session.Close()\n\n\t// Once a Session is created, you can execute a single command on\n\t// the remote side using the Run method.\n\tvar b bytes.Buffer\n\tsession.Stdout = &b\n\tif err := session.Run(\"/usr/bin/whoami\"); err != nil {\n\t\tlog.Fatal(\"Failed to run: \" + err.Error())\n\t}\n\tfmt.Println(b.String())\n}", "is_vulnerable": 0}
{"code": "func TestHttpGetter_metaSubdir(t *testing.T) {\n\tln := testHttpServer(t)\n\tdefer ln.Close()\n\tctx := context.Background()\n\n\tg := new(HttpGetter)\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/meta-subdir\"\n\n\treq := &Request{\n\t\tDst: dst,\n\t\tu:   &u,\n\t}\n\n\t// Get it!\n\tif err := g.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\t// Verify the main file exists\n\tmainPath := filepath.Join(dst, \"sub.tf\")\n\tif _, err := os.Stat(mainPath); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (src *GSSEncRequest) Encode(dst []byte) ([]byte, error) {\n\tdst = pgio.AppendInt32(dst, 8)\n\tdst = pgio.AppendInt32(dst, gssEncReqNumber)\n\treturn dst, nil\n}", "is_vulnerable": 0}
{"code": "func (c *managedIdentityClient) createServiceFabricAuthRequest(ctx context.Context, id ManagedIDKind, scopes []string) (*policy.Request, error) {\n\trequest, err := runtime.NewRequest(ctx, http.MethodGet, c.endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tq := request.Raw().URL.Query()\n\trequest.Raw().Header.Set(\"Accept\", \"application/json\")\n\trequest.Raw().Header.Set(\"Secret\", os.Getenv(identityHeader))\n\tq.Add(\"api-version\", serviceFabricAPIVersion)\n\tq.Add(\"resource\", strings.Join(scopes, \" \"))\n\tif id != nil {\n\t\tlog.Write(EventAuthentication, \"WARNING: Service Fabric doesn't support selecting a user-assigned identity at runtime\")\n\t\tif id.idKind() == miResourceID {\n\t\t\tq.Add(miResID, id.String())\n\t\t} else {\n\t\t\tq.Add(qpClientID, id.String())\n\t\t}\n\t}\n\trequest.Raw().URL.RawQuery = q.Encode()\n\treturn request, nil\n}", "is_vulnerable": 1}
{"code": "func NewClientWithBaseURI(baseURI string, subscriptionID string) Client {\n\treturn original.NewClientWithBaseURI(baseURI, subscriptionID)\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tcmdFunc = unsquashfsSandboxCmd\n}", "is_vulnerable": 0}
{"code": "\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.Params(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", errMissingParam\n\t\t}\n\t\treturn token, nil\n\t}", "is_vulnerable": 1}
{"code": "func TestAgent_SetupProxyManager(t *testing.T) {\n\tt.Parallel()\n\tdataDir := testutil.TempDir(t, \"agent\") // we manage the data dir\n\tdefer os.RemoveAll(dataDir)\n\thcl := `\n\t\tports { http = -1 }\n\t\tdata_dir = \"` + dataDir + `\"\n\t`\n\ta, err := NewUnstartedAgent(t, t.Name(), hcl)\n\trequire.NoError(t, err)\n\trequire.Error(t, a.setupProxyManager(), \"setupProxyManager should fail with invalid HTTP API config\")\n\n\thcl = `\n\t\tports { http = 8001 }\n\t\tdata_dir = \"` + dataDir + `\"\n\t`\n\ta, err = NewUnstartedAgent(t, t.Name(), hcl)\n\trequire.NoError(t, err)\n\trequire.NoError(t, a.setupProxyManager())\n}", "is_vulnerable": 0}
{"code": "func NewKMSContextKeyGenerator(client kmsiface.KMSAPI, cmkID string) CipherDataGeneratorWithCEKAlg {\n\treturn NewKMSContextKeyGeneratorWithMatDesc(client, cmkID, MaterialDescription{})\n}", "is_vulnerable": 0}
{"code": "func NotSubset(t TestingT, list interface{}, subset interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotSubset(t, list, subset, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (k *Key) Invalid() bool {\n\tres := C.key_invalid(k.k) != 0\n\truntime.KeepAlive(k)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn ratelimit{r}\n}", "is_vulnerable": 1}
{"code": "func (page *ProviderListResultPage) NextWithContext(ctx context.Context) (err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/ProviderListResultPage.NextWithContext\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif page.Response().Response.Response != nil {\n\t\t\t\tsc = page.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tnext, err := page.fn(ctx, page.plr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpage.plr = next\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func MountStubsCleaner(ctx context.Context, dir string, mounts []Mount, recursive bool) func() {\n\tnames := []string{\"/etc/resolv.conf\", \"/etc/hosts\"}\n\n\tfor _, m := range mounts {\n\t\tnames = append(names, m.Dest)\n\t}\n\n\tpaths := make([]string, 0, len(names))\n\n\tfor _, p := range names {\n\t\tp = filepath.Join(\"/\", p)\n\t\tif p == \"/\" {\n\t\t\tcontinue\n\t\t}\n\t\trealPath, err := fs.RootPath(dir, p)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor {\n\t\t\t_, err = os.Lstat(realPath)\n\t\t\tif !(errors.Is(err, os.ErrNotExist) || errors.Is(err, syscall.ENOTDIR)) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpaths = append(paths, realPath)\n\n\t\t\tif !recursive {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\trealPathNext := filepath.Dir(realPath)\n\t\t\tif realPath == realPathNext || realPathNext == dir {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\trealPath = realPathNext\n\t\t}\n\t}\n\n\treturn func() {\n\t\tfor _, p := range paths {\n\t\t\tp, err := fs.RootPath(dir, strings.TrimPrefix(p, dir))\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tst, err := os.Lstat(p)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif st.IsDir() {\n\t\t\t\tentries, err := os.ReadDir(p)\n\t\t\t\tif err != nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif len(entries) != 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} else if st.Size() != 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Back up the timestamps of the dir for reproducible builds\n\t\t\t// https://github.com/moby/buildkit/issues/3148\n\t\t\tparent := filepath.Dir(p)\n\t\t\tif realPath, err := fs.RootPath(dir, strings.TrimPrefix(parent, dir)); err != nil || realPath != parent {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdirSt, err := os.Stat(parent)\n\t\t\tif err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to stat %q (parent of mount stub %q)\", dir, p)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tmtime := dirSt.ModTime()\n\t\t\tatime, err := system.Atime(dirSt)\n\t\t\tif err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to stat atime of %q (parent of mount stub %q)\", dir, p)\n\t\t\t\tatime = mtime\n\t\t\t}\n\n\t\t\tif err := os.Remove(p); err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to remove mount stub %q\", p)\n\t\t\t}\n\n\t\t\t// Restore the timestamps of the dir\n\t\t\tif err := os.Chtimes(parent, atime, mtime); err != nil {\n\t\t\t\tbklog.G(ctx).WithError(err).Warnf(\"Failed to restore time time mount stub timestamp (os.Chtimes(%q, %v, %v))\", dir, atime, mtime)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewHeadersRequestFromPolicy(policy *config.Policy, hostname string) *HeadersRequest {\n\tinput := new(HeadersRequest)\n\tinput.EnableGoogleCloudServerlessAuthentication = policy.EnableGoogleCloudServerlessAuthentication\n\tinput.EnableRoutingKey = policy.EnvoyOpts.GetLbPolicy() == envoy_config_cluster_v3.Cluster_RING_HASH ||\n\t\tpolicy.EnvoyOpts.GetLbPolicy() == envoy_config_cluster_v3.Cluster_MAGLEV\n\tinput.Issuer = hostname\n\tinput.KubernetesServiceAccountToken = policy.KubernetesServiceAccountToken\n\tfor _, wu := range policy.To {\n\t\tinput.ToAudience = \"https://\" + wu.URL.Hostname()\n\t}\n\tinput.PassAccessToken = policy.GetSetAuthorizationHeader() == configpb.Route_ACCESS_TOKEN\n\tinput.PassIDToken = policy.GetSetAuthorizationHeader() == configpb.Route_ID_TOKEN\n\treturn input\n}", "is_vulnerable": 1}
{"code": "func (m *B) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowGogovanity\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: B: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: B: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field String_\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowGogovanity\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthGogovanity\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthGogovanity\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.String_ = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int64\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowGogovanity\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int64 = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowGogovanity\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int32 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipGogovanity(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthGogovanity\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthGogovanity\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *shard) serialize(ls *ipld.LinkSystem) (ipld.Link, uint64, error) {\n\tbm, err := s.bitmap()\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\tufd, err := BuildUnixFS(func(b *Builder) {\n\t\tDataType(b, data.Data_HAMTShard)\n\t\tHashType(b, s.hasher)\n\t\tData(b, bm)\n\t\tFanout(b, uint64(s.size))\n\t})\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\tpbb := dagpb.Type.PBNode.NewBuilder()\n\tpbm, err := pbb.BeginMap(2)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\tif err = pbm.AssembleKey().AssignString(\"Data\"); err != nil {\n\t\treturn nil, 0, err\n\t}\n\tif err = pbm.AssembleValue().AssignBytes(data.EncodeUnixFSData(ufd)); err != nil {\n\t\treturn nil, 0, err\n\t}\n\tif err = pbm.AssembleKey().AssignString(\"Links\"); err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tlnkBuilder := dagpb.Type.PBLinks.NewBuilder()\n\tlnks, err := lnkBuilder.BeginList(int64(len(s.children)))\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\t// sorting happens in codec-dagpb\n\tvar totalSize uint64\n\tfor idx, e := range s.children {\n\t\tvar lnk dagpb.PBLink\n\t\tif e.shard != nil {\n\t\t\tipldLnk, sz, err := e.shard.serialize(ls)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, 0, err\n\t\t\t}\n\t\t\ttotalSize += sz\n\t\t\tfullName := s.formatLinkName(\"\", idx)\n\t\t\tlnk, err = BuildUnixFSDirectoryEntry(fullName, int64(sz), ipldLnk)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, 0, err\n\t\t\t}\n\t\t} else {\n\t\t\tfullName := s.formatLinkName(e.Name.Must().String(), idx)\n\t\t\tsz := e.Tsize.Must().Int()\n\t\t\ttotalSize += uint64(sz)\n\t\t\tlnk, err = BuildUnixFSDirectoryEntry(fullName, sz, e.Hash.Link())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, 0, err\n\t\t}\n\t\tif err := lnks.AssembleValue().AssignNode(lnk); err != nil {\n\t\t\treturn nil, 0, err\n\t\t}\n\t}\n\tif err := lnks.Finish(); err != nil {\n\t\treturn nil, 0, err\n\t}\n\tpbm.AssembleValue().AssignNode(lnkBuilder.Build())\n\tif err := pbm.Finish(); err != nil {\n\t\treturn nil, 0, err\n\t}\n\tnode := pbb.Build()\n\tlnk, sz, err := sizedStore(ls, fileLinkProto, node)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\treturn lnk, totalSize + sz, nil\n}", "is_vulnerable": 0}
{"code": "func (va ClawbackVestingAccount) ComputeClawback(\n\tclawbackTime int64,\n) (ClawbackVestingAccount, sdk.Coins) {\n\ttotalVested := va.GetVestedCoins(time.Unix(clawbackTime, 0))\n\ttotalUnvested := va.GetVestingCoins(time.Unix(clawbackTime, 0))\n\n\t// Remove all unvested periods from the schedule\n\tpassedPeriodID := va.GetPassedPeriodCount(time.Unix(clawbackTime, 0))\n\tnewVestingPeriods := va.VestingPeriods[:passedPeriodID]\n\tnewVestingEnd := va.GetStartTime() + newVestingPeriods.TotalLength()\n\n\t// Cap the unlocking schedule to the new total vested.\n\t//  - If lockup has already passed, all vested coins are unlocked.\n\t//  - If lockup has not passed, the vested coins, are still locked.\n\tcapPeriods := sdkvesting.Periods{\n\t\t{\n\t\t\tLength: 0,\n\t\t\tAmount: totalVested,\n\t\t},\n\t}\n\n\t// minimum of the 2 periods\n\t_, newLockingEnd, newLockupPeriods := ConjunctPeriods(va.GetStartTime(), va.GetStartTime(), va.LockupPeriods, capPeriods)\n\n\t// Now construct the new account state\n\tva.OriginalVesting = totalVested\n\tva.EndTime = Max64(newVestingEnd, newLockingEnd)\n\tva.LockupPeriods = newLockupPeriods\n\tva.VestingPeriods = newVestingPeriods\n\n\treturn va, totalUnvested\n}", "is_vulnerable": 0}
{"code": "func (a *Adaptor) newTLSConfig() *tls.Config {\n\t// Import server certificate\n\tvar certpool *x509.CertPool\n\tif len(a.ServerCert()) > 0 {\n\t\tcertpool = x509.NewCertPool()\n\t\tpemCerts, err := ioutil.ReadFile(a.ServerCert())\n\t\tif err == nil {\n\t\t\tcertpool.AppendCertsFromPEM(pemCerts)\n\t\t}\n\t}\n\n\t// Import client certificate/key pair\n\tvar certs []tls.Certificate\n\tif len(a.ClientCert()) > 0 && len(a.ClientKey()) > 0 {\n\t\tcert, err := tls.LoadX509KeyPair(a.ClientCert(), a.ClientKey())\n\t\tif err != nil {\n\t\t\t// TODO: proper error handling\n\t\t\tpanic(err)\n\t\t}\n\t\tcerts = append(certs, cert)\n\t}\n\n\t// Create tls.Config with desired tls properties\n\treturn &tls.Config{\n\t\t// RootCAs = certs used to verify server cert.\n\t\tRootCAs: certpool,\n\t\t// ClientAuth = whether to request cert from server.\n\t\t// Since the server is set up for SSL, this happens\n\t\t// anyways.\n\t\tClientAuth: tls.NoClientCert,\n\t\t// ClientCAs = certs used to validate client cert.\n\t\tClientCAs: nil,\n\t\t// InsecureSkipVerify = verify that cert contents\n\t\t// match server. IP matches what is in cert etc.\n\t\tInsecureSkipVerify: false,\n\t\t// Certificates = list of certs client sends to server.\n\t\tCertificates: certs,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (o *PackageOptions) UpdatePackageCmd(ctx context.Context) error {\n\t// clone the melange config git repo into a temp folder so we can work with it\n\ttempDir, err := os.MkdirTemp(\"\", \"wolfictl\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create temporary folder to clone package configs into: %w\", err)\n\t}\n\tif o.DryRun {\n\t\to.Logger.Printf(\"using working directory %s\", tempDir)\n\t} else {\n\t\tdefer os.Remove(tempDir)\n\t}\n\n\tgitAuth, err := wolfigit.GetGitAuth(o.TargetRepo)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get git auth: %w\", err)\n\t}\n\n\tcloneOpts := &git.CloneOptions{\n\t\tURL:               o.TargetRepo,\n\t\tProgress:          os.Stdout,\n\t\tRecurseSubmodules: git.NoRecurseSubmodules,\n\t\tAuth:              gitAuth,\n\t\tDepth:             1,\n\t}\n\n\trepo, err := git.PlainClone(tempDir, false, cloneOpts)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to clone repository %s into %s: %w\", o.TargetRepo, tempDir, err)\n\t}\n\n\t// first, let's get the melange package(s) from the target git repo, that we want to check for updates\n\to.PackageConfig, err = melange.ReadPackageConfigs(ctx, []string{o.PackageName}, tempDir)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to get package config for package name %s: %w\", o.PackageName, err)\n\t}\n\n\tuo := New(ctx)\n\tuo.PackageConfigs = o.PackageConfig\n\tuo.DryRun = o.DryRun\n\tuo.PullRequestBaseBranch = o.PullRequestBaseBranch\n\tuo.PullRequestTitle = \"%s/%s package update\"\n\tuo.UseGitSign = o.UseGitSign\n\n\t// let's work on a branch when updating package versions, so we can create a PR from that branch later\n\tref, err := uo.createBranch(repo)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to switch to working git branch: %w\", err)\n\t}\n\n\t// optionally update advisories based on commit since the previous release\n\tif o.Advisories {\n\t\terr := o.updateAdvisories(ctx, repo)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to update advisories: %w\", err)\n\t\t}\n\t}\n\n\t// update melange configs in our cloned git repository with any new package versions\n\tv := strings.TrimPrefix(o.Version, \"v\")\n\n\tnvr := NewVersionResults{\n\t\tVersion: v,\n\t}\n\terrorMessage, err := uo.updateGitPackage(ctx, repo, o.PackageName, nvr, ref)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to update package in git repository: %w\", err)\n\t}\n\tif errorMessage != \"\" {\n\t\treturn errors.New(errorMessage)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func normalizeOrigin(origin string) (bool, string) {\n\tparsedOrigin, err := url.Parse(origin)\n\tif err != nil {\n\t\treturn false, \"\"\n\t}\n\n\t// Validate the scheme is either http or https\n\tif parsedOrigin.Scheme != \"http\" && parsedOrigin.Scheme != \"https\" {\n\t\treturn false, \"\"\n\t}\n\n\t// Validate there is a host present. The presence of a path, query, or fragment components\n\t// is checked, but a trailing \"/\" (indicative of the root) is allowed for the path and will be normalized\n\tif parsedOrigin.Host == \"\" || (parsedOrigin.Path != \"\" && parsedOrigin.Path != \"/\") || parsedOrigin.RawQuery != \"\" || parsedOrigin.Fragment != \"\" {\n\t\treturn false, \"\"\n\t}\n\n\t// Normalize the origin by constructing it from the scheme and host.\n\t// The path or trailing slash is not included in the normalized origin.\n\treturn true, strings.ToLower(parsedOrigin.Scheme) + \"://\" + strings.ToLower(parsedOrigin.Host)\n}", "is_vulnerable": 0}
{"code": "func parseV2(r *bufio.Reader) (*HeaderV2, error) {\n\tbuf := make([]byte, 232)\n\tn, err := io.ReadFull(r, buf[:16])\n\tif err != nil {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:n], error: err}\n\t}\n\tvar rawHdr rawV2\n\terr = binary.Read(bytes.NewReader(buf), binary.BigEndian, &rawHdr)\n\tif err != nil {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: err}\n\t}\n\tif !bytes.Equal(rawHdr.Sig[:], sigV2) {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: errors.New(\"invalid signature\")}\n\t}\n\t// highest 4 indicate version\n\tif (rawHdr.VerCmd >> 4) != 2 {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: errors.New(\"invalid v2 version value\")}\n\t}\n\tvar h HeaderV2\n\t// lowest 4 = command (0xf == 0b00001111)\n\th.Command = Cmd(rawHdr.VerCmd & 0xf)\n\tif h.Command > CmdProxy {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: errors.New(\"invalid v2 command\")}\n\t}\n\n\t// highest 4 indicate address family\n\tif (rawHdr.FamProto >> 4) > 3 {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: errors.New(\"invalid v2 address family\")}\n\t}\n\n\t// lowest 4 = transport protocol (0xf == 0b00001111)\n\tif (rawHdr.FamProto & 0xf) > 2 {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16], error: errors.New(\"invalid v2 transport protocol\")}\n\t}\n\n\tif 16+int(rawHdr.Len) > len(buf) {\n\t\tnewBuf := make([]byte, 16+int(rawHdr.Len))\n\t\tcopy(newBuf, buf[:16])\n\t\tbuf = newBuf\n\t} else {\n\t\tbuf = buf[:16+int(rawHdr.Len)]\n\t}\n\n\tn, err = io.ReadFull(r, buf[16:])\n\tif err != nil {\n\t\treturn nil, &InvalidHeaderErr{Read: buf[:16+n], error: err}\n\t}\n\n\tif h.Command == CmdLocal {\n\t\t// ignore address information for local\n\t\treturn &h, nil\n\t}\n\n\tswitch rawHdr.FamProto {\n\tcase 0x11: // TCP over IPv4\n\t\th.Src = &net.TCPAddr{\n\t\t\tIP:   net.IP(buf[16:20]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[24:])),\n\t\t}\n\t\th.Dest = &net.TCPAddr{\n\t\t\tIP:   net.IP(buf[20:24]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[26:])),\n\t\t}\n\tcase 0x12: // UDP over IPv4\n\t\th.Src = &net.UDPAddr{\n\t\t\tIP:   net.IP(buf[16:20]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[24:])),\n\t\t}\n\t\th.Dest = &net.UDPAddr{\n\t\t\tIP:   net.IP(buf[20:24]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[26:])),\n\t\t}\n\tcase 0x21: // TCP over IPv6\n\t\th.Src = &net.TCPAddr{\n\t\t\tIP:   net.IP(buf[16:32]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[48:])),\n\t\t}\n\t\th.Dest = &net.TCPAddr{\n\t\t\tIP:   net.IP(buf[32:48]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[50:])),\n\t\t}\n\tcase 0x22: // UDP over IPv6\n\t\th.Src = &net.UDPAddr{\n\t\t\tIP:   net.IP(buf[16:32]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[48:])),\n\t\t}\n\t\th.Dest = &net.UDPAddr{\n\t\t\tIP:   net.IP(buf[32:48]),\n\t\t\tPort: int(binary.BigEndian.Uint16(buf[50:])),\n\t\t}\n\tcase 0x31: // UNIX stream\n\t\th.Src = &net.UnixAddr{\n\t\t\tNet:  \"unix\",\n\t\t\tName: strings.TrimRight(string(buf[16:124]), \"\\x00\"),\n\t\t}\n\t\th.Dest = &net.UnixAddr{\n\t\t\tNet:  \"unix\",\n\t\t\tName: strings.TrimRight(string(buf[124:232]), \"\\x00\"),\n\t\t}\n\tcase 0x32: // UNIX datagram\n\t\th.Src = &net.UnixAddr{\n\t\t\tNet:  \"unixgram\",\n\t\t\tName: strings.TrimRight(string(buf[16:124]), \"\\x00\"),\n\t\t}\n\t\th.Dest = &net.UnixAddr{\n\t\t\tNet:  \"unixgram\",\n\t\t\tName: strings.TrimRight(string(buf[124:232]), \"\\x00\"),\n\t\t}\n\t}\n\n\treturn &h, nil\n}", "is_vulnerable": 1}
