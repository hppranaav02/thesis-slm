{"code": "func (ev *WebSocketEvent) DeepCopy() *WebSocketEvent {\n\tvar dataCopy map[string]any\n\tif ev.data != nil {\n\t\tdataCopy = make(map[string]any, len(ev.data))\n\t\tfor k, v := range ev.data {\n\t\t\tdataCopy[k] = v\n\t\t}\n\t}\n\n\tevCopy := &WebSocketEvent{\n\t\tevent:           ev.event,\n\t\tdata:            dataCopy,\n\t\tbroadcast:       ev.broadcast.copy(),\n\t\tsequence:        ev.sequence,\n\t\tprecomputedJSON: ev.precomputedJSON.copy(),\n\t}\n\treturn evCopy\n}", "is_vulnerable": 1}
{"code": "func inSelectIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase ErrorToken:\n\t\t// Stop parsing.\n\t\treturn true\n\tcase TextToken:\n\t\tp.addText(strings.Replace(p.tok.Data, \"\\x00\", \"\", -1))\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\treturn inBodyIM(p)\n\t\tcase a.Option:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Optgroup:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tif p.top().DataAtom == a.Optgroup {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Select:\n\t\t\tp.tok.Type = EndTagToken\n\t\t\treturn false\n\t\tcase a.Input, a.Keygen, a.Textarea:\n\t\t\tif p.elementInScope(selectScope, a.Select) {\n\t\t\t\tp.parseImpliedToken(EndTagToken, a.Select, a.Select.String())\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// In order to properly ignore <textarea>, we need to change the tokenizer mode.\n\t\t\tp.tokenizer.NextIsNotRawText()\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\tcase a.Script:\n\t\t\treturn inHeadIM(p)\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Option:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\tcase a.Optgroup:\n\t\t\ti := len(p.oe) - 1\n\t\t\tif p.oe[i].DataAtom == a.Option {\n\t\t\t\ti--\n\t\t\t}\n\t\t\tif p.oe[i].DataAtom == a.Optgroup {\n\t\t\t\tp.oe = p.oe[:i]\n\t\t\t}\n\t\tcase a.Select:\n\t\t\tif p.popUntil(selectScope, a.Select) {\n\t\t\t\tp.resetInsertionMode()\n\t\t\t}\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\tcase DoctypeToken:\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\n\treturn true\n}", "is_vulnerable": 1}
{"code": "func TestStaticFilesDelivery(t *testing.T) {\n\timportPath := filepath.Join(testdataBaseDir(), \"webapp1\")\n\tts := newTestServer(t, importPath)\n\tdefer ts.Close()\n\n\tt.Logf(\"Test Server URL [Static Files Delivery]: %s\", ts.URL)\n\n\thttpClient := new(http.Client)\n\n\t// Static File - /robots.txt\n\tt.Log(\"Static File - /robots.txt\")\n\tresp, err := httpClient.Get(ts.URL + \"/robots.txt\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.True(t, strings.Contains(responseBody(resp), \"User-agent: *\"))\n\tassert.Equal(t, \"no-cache, no-store, must-revalidate\", resp.Header.Get(ahttp.HeaderCacheControl))\n\n\t// Static File - /assets/css/aah.css\n\tt.Log(\"Static File - /assets/css/aah.css\")\n\tresp, err = httpClient.Get(ts.URL + \"/assets/css/aah.css\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.True(t, strings.Contains(responseBody(resp), \"Minimal aah framework application template CSS.\"))\n\tassert.Equal(t, \"no-cache, no-store, must-revalidate\", resp.Header.Get(ahttp.HeaderCacheControl))\n\n\t// Directory Listing - /assets\n\tt.Log(\"Directory Listing - /assets\")\n\tresp, err = httpClient.Get(ts.URL + \"/assets\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, resp.StatusCode)\n\tbody := responseBody(resp)\n\tassert.True(t, strings.Contains(body, \"<title>Listing of /assets/</title>\"))\n\tassert.True(t, strings.Contains(body, \"<h1>Listing of /assets/</h1><hr>\"))\n\tassert.True(t, strings.Contains(body, `<a href=\"robots.txt\">robots.txt</a>`))\n\tassert.Equal(t, \"\", resp.Header.Get(ahttp.HeaderCacheControl))\n\n\t// Static File - /assets/img/aah-framework-logo.png\n\tt.Log(\"Static File - /assets/img/aah-framework-logo.png\")\n\tresp, err = httpClient.Get(ts.URL + \"/assets/img/aah-framework-logo.png\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.Equal(t, \"image/png\", resp.Header.Get(ahttp.HeaderContentType))\n\tassert.Equal(t, \"6990\", resp.Header.Get(ahttp.HeaderContentLength))\n\tassert.Equal(t, \"no-cache, no-store, must-revalidate\", resp.Header.Get(ahttp.HeaderCacheControl))\n\n\t// Static File - /assets/img/notfound/file.txt\n\tt.Log(\"Static File - /assets/img/notfound/file.txt\")\n\tresp, err = httpClient.Get(ts.URL + \"/assets/img/notfound/file.txt\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, 200, resp.StatusCode)\n\tassert.Equal(t, \"0\", resp.Header.Get(ahttp.HeaderContentLength))\n}", "is_vulnerable": 1}
{"code": "func (p *mockPlugin) GenerateEnvelope(ctx context.Context, req *proto.GenerateEnvelopeRequest) (*proto.GenerateEnvelopeResponse, error) {\n\tinternalPluginSigner := pluginSigner{\n\t\tplugin: newMockPlugin(p.key, p.certs, p.keySpec),\n\t}\n\n\tif p.failEnvelope {\n\t\treturn nil, errors.New(\"failed GenerateEnvelope\")\n\t}\n\tif p.invalidDescriptor {\n\t\tvar payload map[string]interface{}\n\t\tif err := json.Unmarshal(req.Payload, &payload); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tpayload[\"additional_field\"] = \"some_string\"\n\n\t\tupdatedPayload, err := json.Marshal(payload)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tprimitivePluginSigner := &pluginPrimitiveSigner{\n\t\t\tctx:          ctx,\n\t\t\tplugin:       internalPluginSigner.plugin,\n\t\t\tkeyID:        internalPluginSigner.keyID,\n\t\t\tpluginConfig: req.PluginConfig,\n\t\t\tkeySpec:      p.keySpec,\n\t\t}\n\n\t\tsignReq := &signature.SignRequest{\n\t\t\tPayload: signature.Payload{\n\t\t\t\tContentType: envelope.MediaTypePayloadV1,\n\t\t\t\tContent:     updatedPayload,\n\t\t\t},\n\t\t\tSigner:                   primitivePluginSigner,\n\t\t\tSigningTime:              time.Now(),\n\t\t\tExtendedSignedAttributes: nil,\n\t\t\tSigningScheme:            signature.SigningSchemeX509,\n\t\t\tSigningAgent:             \"testing agent\",\n\t\t}\n\n\t\tsigEnv, err := signature.NewEnvelope(req.SignatureEnvelopeType)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tsig, err := sigEnv.Sign(signReq)\n\t\treturn &proto.GenerateEnvelopeResponse{\n\t\t\tSignatureEnvelope:     sig,\n\t\t\tSignatureEnvelopeType: req.SignatureEnvelopeType,\n\t\t}, err\n\t}\n\tif p.wantEnvelope {\n\t\tvar payload envelope.Payload\n\t\tif err := json.Unmarshal(req.Payload, &payload); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tvalidSignOpts.SignatureMediaType = req.SignatureEnvelopeType\n\t\tdata, _, err := internalPluginSigner.Sign(ctx, payload.TargetArtifact, validSignOpts)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &proto.GenerateEnvelopeResponse{\n\t\t\tSignatureEnvelope:     data,\n\t\t\tSignatureEnvelopeType: req.SignatureEnvelopeType,\n\t\t\tAnnotations: p.annotations,\n\t\t}, nil\n\t}\n\treturn &proto.GenerateEnvelopeResponse{}, nil\n}", "is_vulnerable": 1}
{"code": "func SanitizeContent(content []byte) ([]byte, error) {\n\tbodyString := string(content)\n\n\tbm := bluemonday.UGCPolicy()\n\treturn []byte(bm.Sanitize(bodyString)), nil\n}", "is_vulnerable": 0}
{"code": "func isRepositoryGitPath(path string) bool {\n\treturn strings.HasSuffix(path, \".git\") ||\n\t\tstrings.Contains(path, \".git/\") ||\n\t\tstrings.Contains(path, `.git\\`) ||\n\t\t// Windows treats \".git.\" the same as \".git\"\n\t\tstrings.HasSuffix(path, \".git.\") ||\n\t\tstrings.Contains(path, \".git./\") ||\n\t\tstrings.Contains(path, `.git.\\`)\n}", "is_vulnerable": 0}
{"code": "func findScopeMetricAttribute(sm metricdata.ScopeMetrics, key attribute.Key) (attribute.KeyValue, bool) {\n\tfor _, m := range sm.Metrics {\n\t\t// This only needs to cover data types used by the instrumentation.\n\t\tswitch d := m.Data.(type) {\n\t\tcase metricdata.Histogram[int64]:\n\t\t\tfor _, dp := range d.DataPoints {\n\t\t\t\tif kv, ok := findAttribute(dp.Attributes.ToSlice(), key); ok {\n\t\t\t\t\treturn kv, true\n\t\t\t\t}\n\t\t\t}\n\t\tcase metricdata.Histogram[float64]:\n\t\t\tfor _, dp := range d.DataPoints {\n\t\t\t\tif kv, ok := findAttribute(dp.Attributes.ToSlice(), key); ok {\n\t\t\t\t\treturn kv, true\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unexpected data type %T - name %s\", d, m.Name))\n\t\t}\n\t}\n\treturn attribute.KeyValue{}, false\n}", "is_vulnerable": 1}
{"code": "func TestVerifyCommand_BasicArgs(t *testing.T) {\n\topts := &verifyOpts{}\n\tcommand := verifyCommand(opts)\n\texpected := &verifyOpts{\n\t\treference: \"ref\",\n\t\tSecureFlagOpts: SecureFlagOpts{\n\t\t\tUsername: \"user\",\n\t\t\tPassword: \"password\",\n\t\t},\n\t\tpluginConfig:         []string{\"key1=val1\"},\n\t\tmaxSignatureAttempts: 100,\n\t}\n\tif err := command.ParseFlags([]string{\n\t\texpected.reference,\n\t\t\"--username\", expected.Username,\n\t\t\"--password\", expected.Password,\n\t\t\"--plugin-config\", \"key1=val1\"}); err != nil {\n\t\tt.Fatalf(\"Parse Flag failed: %v\", err)\n\t}\n\tif err := command.Args(command, command.Flags().Args()); err != nil {\n\t\tt.Fatalf(\"Parse args failed: %v\", err)\n\t}\n\tif !reflect.DeepEqual(*expected, *opts) {\n\t\tt.Fatalf(\"Expect verify opts: %v, got: %v\", expected, opts)\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tRunE: func(c *cobra.Command, args []string) error {\n\t\t\tctx, cancel := context.WithCancel(c.Context())\n\t\t\tdefer cancel()\n\n\t\t\tvers := common.GetVersion()\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\t\t\tvers.LogStartupInfo(\n\t\t\t\t\"ArgoCD Application Controller\",\n\t\t\t\tmap[string]any{\n\t\t\t\t\t\"namespace\": namespace,\n\t\t\t\t},\n\t\t\t)\n\n\t\t\tcli.SetLogFormat(cmdutil.LogFormat)\n\t\t\tcli.SetLogLevel(cmdutil.LogLevel)\n\t\t\tcli.SetGLogLevel(glogLevel)\n\n\t\t\tconfig, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\terrors.CheckError(v1alpha1.SetK8SConfigDefaults(config))\n\t\t\tconfig.UserAgent = fmt.Sprintf(\"argocd-application-controller/%s (%s)\", vers.Version, vers.Platform)\n\n\t\t\tkubeClient := kubernetes.NewForConfigOrDie(config)\n\t\t\tappClient := appclientset.NewForConfigOrDie(config)\n\n\t\t\thardResyncDuration := time.Duration(appHardResyncPeriod) * time.Second\n\n\t\t\tvar resyncDuration time.Duration\n\t\t\tif appResyncPeriod == 0 {\n\t\t\t\t// Re-sync should be disabled if period is 0. Set duration to a very long duration\n\t\t\t\tresyncDuration = time.Hour * 24 * 365 * 100\n\t\t\t} else {\n\t\t\t\tresyncDuration = time.Duration(appResyncPeriod) * time.Second\n\t\t\t}\n\n\t\t\ttlsConfig := apiclient.TLSConfiguration{\n\t\t\t\tDisableTLS:       repoServerPlaintext,\n\t\t\t\tStrictValidation: repoServerStrictTLS,\n\t\t\t}\n\n\t\t\t// Load CA information to use for validating connections to the\n\t\t\t// repository server, if strict TLS validation was requested.\n\t\t\tif !repoServerPlaintext && repoServerStrictTLS {\n\t\t\t\tpool, err := tls.LoadX509CertPool(\n\t\t\t\t\tfmt.Sprintf(\"%s/controller/tls/tls.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t\tfmt.Sprintf(\"%s/controller/tls/ca.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t\t}\n\t\t\t\ttlsConfig.Certificates = pool\n\t\t\t}\n\n\t\t\trepoClientset := apiclient.NewRepoServerClientset(repoServerAddress, repoServerTimeoutSeconds, tlsConfig)\n\n\t\t\tcache, err := cacheSrc()\n\t\t\terrors.CheckError(err)\n\t\t\tcache.Cache.SetClient(cacheutil.NewTwoLevelClient(cache.Cache.GetClient(), 10*time.Minute))\n\n\t\t\tvar appController *controller.ApplicationController\n\n\t\t\tsettingsMgr := settings.NewSettingsManager(ctx, kubeClient, namespace, settings.WithRepoOrClusterChangedHandler(func() {\n\t\t\t\tappController.InvalidateProjectsCache()\n\t\t\t}))\n\t\t\tkubectl := kubeutil.NewKubectl()\n\t\t\tclusterFilter := getClusterFilter(kubeClient, settingsMgr, shardingAlgorithm)\n\t\t\tappController, err = controller.NewApplicationController(\n\t\t\t\tnamespace,\n\t\t\t\tsettingsMgr,\n\t\t\t\tkubeClient,\n\t\t\t\tappClient,\n\t\t\t\trepoClientset,\n\t\t\t\tcache,\n\t\t\t\tkubectl,\n\t\t\t\tresyncDuration,\n\t\t\t\thardResyncDuration,\n\t\t\t\ttime.Duration(selfHealTimeoutSeconds)*time.Second,\n\t\t\t\tmetricsPort,\n\t\t\t\tmetricsCacheExpiration,\n\t\t\t\tmetricsAplicationLabels,\n\t\t\t\tkubectlParallelismLimit,\n\t\t\t\tpersistResourceHealth,\n\t\t\t\tclusterFilter,\n\t\t\t\tapplicationNamespaces,\n\t\t\t\tignoreNormalizerOpts,\n\t\t\t)\n\t\t\terrors.CheckError(err)\n\t\t\tcacheutil.CollectMetrics(redisClient, appController.GetMetricsServer())\n\n\t\t\tstats.RegisterStackDumper()\n\t\t\tstats.StartStatsTicker(10 * time.Minute)\n\t\t\tstats.RegisterHeapDumper(\"memprofile\")\n\n\t\t\tif otlpAddress != \"\" {\n\t\t\t\tcloseTracer, err := trace.InitTracer(ctx, \"argocd-controller\", otlpAddress)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"failed to initialize tracing: %v\", err)\n\t\t\t\t}\n\t\t\t\tdefer closeTracer()\n\t\t\t}\n\n\t\t\tgo appController.Run(ctx, statusProcessors, operationProcessors)\n\n\t\t\t// Wait forever\n\t\t\tselect {}\n\t\t},\n\t}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tt.Setenv(\"OLLAMA_MODELS\", dir)\n\n\t\t\tgot, err := GetBlobsPath(tc.digest)\n\n\t\t\tassert.ErrorIs(t, tc.err, err, tc.name)\n\t\t\tassert.Equal(t, tc.expected, got, tc.name)\n\t\t})", "is_vulnerable": 0}
{"code": "func getLoginOauth2AuthResponse(lr *models.LoginOauth2AuthRequest) (*models.LoginResponse, *models.Error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 20*time.Second)\n\tdefer cancel()\n\tif oauth2.IsIDPEnabled() {\n\t\t// initialize new oauth2 client\n\t\toauth2Client, err := oauth2.NewOauth2ProviderClient(nil, GetConsoleHTTPClient())\n\t\tif err != nil {\n\t\t\treturn nil, prepareError(err)\n\t\t}\n\t\t// initialize new identity provider\n\t\tidentityProvider := auth.IdentityProvider{Client: oauth2Client}\n\t\t// Validate user against IDP\n\t\tuserCredentials, err := verifyUserAgainstIDP(ctx, identityProvider, *lr.Code, *lr.State)\n\t\tif err != nil {\n\t\t\treturn nil, prepareError(err)\n\t\t}\n\t\t// initialize admin client\n\t\t// login user against console and generate session token\n\t\ttoken, err := login(&ConsoleCredentials{\n\t\t\tConsoleCredentials: userCredentials,\n\t\t\tAccountAccessKey:   \"\",\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, prepareError(err)\n\t\t}\n\t\t// serialize output\n\t\tloginResponse := &models.LoginResponse{\n\t\t\tSessionID: *token,\n\t\t}\n\t\treturn loginResponse, nil\n\t}\n\treturn nil, prepareError(ErrorGeneric)\n}", "is_vulnerable": 0}
{"code": "func Test_populateHelmAppDetails_values_symlinks(t *testing.T) {\n\tt.Run(\"inbound\", func(t *testing.T) {\n\t\tres := apiclient.RepoAppDetailsResponse{}\n\t\tq := apiclient.RepoServerAppDetailsQuery{Repo: &argoappv1.Repository{}, Source: &argoappv1.ApplicationSource{}}\n\t\terr := populateHelmAppDetails(&res, \"./testdata/in-bounds-values-file-link/\", \"./testdata/in-bounds-values-file-link/\", &q)\n\t\trequire.NoError(t, err)\n\t\tassert.NotEmpty(t, res.Helm.Values)\n\t\tassert.NotEmpty(t, res.Helm.Parameters)\n\t})\n\n\tt.Run(\"out of bounds\", func(t *testing.T) {\n\t\tres := apiclient.RepoAppDetailsResponse{}\n\t\tq := apiclient.RepoServerAppDetailsQuery{Repo: &argoappv1.Repository{}, Source: &argoappv1.ApplicationSource{}}\n\t\terr := populateHelmAppDetails(&res, \"./testdata/out-of-bounds-values-file-link/\", \"./testdata/out-of-bounds-values-file-link/\", &q)\n\t\trequire.NoError(t, err)\n\t\tassert.Empty(t, res.Helm.Values)\n\t\tassert.Empty(t, res.Helm.Parameters)\n\t})\n}", "is_vulnerable": 0}
{"code": "func importConfig(\n\tctx context.Context,\n\tclient *admin.AdminAPI,\n\tfilename string,\n\toldConfig admin.Config,\n\toldConfigFull admin.Config,\n\tschema admin.ConfigSchema,\n\tall bool,\n) (err error) {\n\treadbackBytes, err := os.ReadFile(filename)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error reading file %s: %v\", filename, err)\n\t}\n\tvar readbackConfig admin.Config\n\terr = yaml.Unmarshal(readbackBytes, &readbackConfig)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing edited config: %v\", err)\n\t}\n\n\ttype propertyDelta struct {\n\t\tProperty string\n\t\tOldValue string\n\t\tNewValue string\n\t}\n\tvar propertyDeltas []propertyDelta\n\n\t// Calculate deltas\n\tupsert := make(map[string]interface{})\n\tremove := make([]string, 0)\n\tfor k, v := range readbackConfig {\n\t\toldVal, haveOldVal := oldConfig[k]\n\t\toldValMaterialized, haveOldValMaterialized := oldConfigFull[k]\n\n\t\tif meta, ok := schema[k]; ok {\n\t\t\t// For numeric types need special handling because\n\t\t\t// yaml encoding will see '1' as an integer, even\n\t\t\t// if it is given as the value for a floating point\n\t\t\t// ('number') config property, and vice versa.\n\t\t\tif meta.Type == \"integer\" {\n\t\t\t\tif vFloat, ok := v.(float64); ok {\n\t\t\t\t\tv = int(vFloat)\n\t\t\t\t}\n\n\t\t\t\tif oldVal != nil {\n\t\t\t\t\toldVal = int(oldVal.(float64))\n\t\t\t\t}\n\t\t\t\tif oldValMaterialized != nil {\n\t\t\t\t\toldValMaterialized = int(oldValMaterialized.(float64))\n\t\t\t\t}\n\t\t\t} else if meta.Type == \"number\" {\n\t\t\t\tif vInt, ok := v.(int); ok {\n\t\t\t\t\tv = float64(vInt)\n\t\t\t\t}\n\t\t\t} else if meta.Type == \"array\" && meta.Items.Type == \"string\" {\n\t\t\t\tswitch vArray := v.(type) {\n\t\t\t\tcase []interface{}:\n\t\t\t\t\t// Normal case: user input is a yaml array\n\t\t\t\t\tv = loadStringArray(vArray)\n\t\t\t\tdefault:\n\t\t\t\t\t// Pass, let the server attempt validation\n\t\t\t\t}\n\t\t\t\tif oldVal != nil {\n\t\t\t\t\toldVal = loadStringArray(oldVal.([]interface{}))\n\t\t\t\t}\n\t\t\t\tif oldValMaterialized != nil {\n\t\t\t\t\toldValMaterialized = loadStringArray(oldValMaterialized.([]interface{}))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// For types that aren't numeric or array, pass them through as-is\n\t\t}\n\n\t\t// We exclude cluster_id from upsert here and remove below to avoid any\n\t\t// accidental duplication of the ID from one cluster to another\n\t\tif k == \"cluster_id\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tif haveOldVal {\n\t\t\t// Since the admin endpoint will redact secret fields, ignore any\n\t\t\t// such sentinel strings we've been given, to avoid accidentally\n\t\t\t// setting configs to this value.\n\t\t\t// TODO: why doesn't this work with DeepEqual?\n\t\t\tif fmt.Sprintf(\"%v\", oldVal) == \"[secret]\" && fmt.Sprintf(\"%v\", v) == \"[secret]\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// If value changed, add it to list of updates.\n\t\t\t// DeepEqual because values can be slices.\n\t\t\tif !reflect.DeepEqual(oldVal, v) {\n\t\t\t\tpropertyDeltas = append(propertyDeltas, propertyDelta{k, fmt.Sprintf(\"%v\", oldVal), fmt.Sprintf(\"%v\", v)})\n\t\t\t\tupsert[k] = v\n\t\t\t}\n\t\t} else {\n\t\t\t// Present in input but not original config, insert if it differs\n\t\t\t// from the materialized current value (which may be a default)\n\t\t\tif !haveOldValMaterialized || !reflect.DeepEqual(oldValMaterialized, v) {\n\t\t\t\tupsert[k] = v\n\t\t\t\tpropertyDeltas = append(propertyDeltas, propertyDelta{k, fmt.Sprintf(\"%v\", oldValMaterialized), fmt.Sprintf(\"%v\", v)})\n\t\t\t}\n\t\t}\n\t}\n\n\tfor k := range oldConfigFull {\n\t\tif _, found := readbackConfig[k]; !found {\n\t\t\tif k == \"cluster_id\" {\n\t\t\t\t// see above\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tmeta, inSchema := schema[k]\n\t\t\tif !inSchema {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif !all && meta.Visibility == \"tunable\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\toldValue, found := oldConfig[k]\n\t\t\tif found {\n\t\t\t\tpropertyDeltas = append(propertyDeltas, propertyDelta{k, fmt.Sprintf(\"%v\", oldValue), \"\"})\n\t\t\t\tremove = append(remove, k)\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(upsert) == 0 && len(remove) == 0 {\n\t\tfmt.Println(\"No changes were made.\")\n\t\treturn nil\n\t}\n\n\ttw := out.NewTable(\"PROPERTY\", \"PRIOR\", \"NEW\")\n\tfor _, pd := range propertyDeltas {\n\t\ttw.PrintStructFields(pd)\n\t}\n\ttw.Flush()\n\n\t// Newline between table and result of write\n\tfmt.Printf(\"\\n\")\n\n\t// PUT to admin API\n\tresult, err := client.PatchClusterConfig(ctx, upsert, remove)\n\tif he := (*admin.HTTPResponseError)(nil); errors.As(err, &he) {\n\t\t// Special case 400 (validation) errors with friendly output\n\t\t// about which configuration properties were invalid.\n\t\tif he.Response.StatusCode == 400 {\n\t\t\tve, err := formatValidationError(err, he)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error setting config: %v\", err)\n\t\t\t}\n\t\t\treturn &formattedError{ve}\n\t\t}\n\t}\n\n\t// If we didn't handle a structured 400 error, check for other errors.\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error setting config: %v\", err)\n\t}\n\n\tfmt.Printf(\"Successfully updated configuration. New configuration version is %d.\\n\", result.ConfigVersion)\n\n\tstatus, err := client.ClusterConfigStatus(ctx, true)\n\tout.MaybeDie(err, \"unable to check if the cluster needs to be restarted: %v\\nCheck the status with 'rpk cluster config status'.\", err)\n\tfor _, value := range status {\n\t\tif value.Restart {\n\t\t\tfmt.Print(\"\\nCluster needs to be restarted. See more details with 'rpk cluster config status'.\\n\")\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) IncomingRPCConfig() *tls.Config {\n\tc.log(\"IncomingRPCConfig\")\n\tconfig := c.commonTLSConfig(c.verifyIncomingRPC())\n\tconfig.GetConfigForClient = func(*tls.ClientHelloInfo) (*tls.Config, error) {\n\t\treturn c.IncomingRPCConfig(), nil\n\t}\n\treturn config\n}", "is_vulnerable": 0}
{"code": "func (s *SecurityGroupForVpc) SetPrimaryVpcId(v string) *SecurityGroupForVpc {\n\ts.PrimaryVpcId = &v\n\treturn s\n}", "is_vulnerable": 0}
{"code": "\t\tAction: func(ctx *cli.Context) error {\n\t\t\tlevel, err := log.ParseLevel(ctx.String(\"log-level\"))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tlog.SetLevel(level)\n\n\t\t\tlogFormat := ctx.String(\"log-format\")\n\t\t\tif !isValidLogFormat(logFormat) {\n\t\t\t\treturn fmt.Errorf(\"not a valid log-format: %v\", logFormat)\n\t\t\t}\n\t\t\tif logFormat == \"json\" {\n\t\t\t\tlog.SetFormatter(&log.JSONFormatter{})\n\t\t\t}\n\n\t\t\tlog.Info(\"starting sshpiperd version: \", version())\n\t\t\td, err := newDaemon(ctx)\n\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tquit := make(chan error)\n\t\t\td.lis = &proxyproto.Listener{Listener: d.lis}\n\n\t\t\tvar plugins []*plugin.GrpcPlugin\n\n\t\t\targs := ctx.Args().Slice()\n\t\t\tremain := args\n\n\t\t\tfor {\n\t\t\t\tif len(remain) <= 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\targs, remain = splitByDash(remain)\n\n\t\t\t\tif len(args) <= 0 {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tvar p *plugin.GrpcPlugin\n\n\t\t\t\tswitch args[0] {\n\t\t\t\tcase \"grpc\":\n\t\t\t\t\tlog.Info(\"starting net grpc plugin: \")\n\n\t\t\t\t\tgrpcplugin, err := createNetGrpcPlugin(args)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tp = grpcplugin\n\n\t\t\t\tdefault:\n\t\t\t\t\tcmdplugin, err := createCmdPlugin(args)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tgo func() {\n\t\t\t\t\t\tquit <- <-cmdplugin.Quit\n\t\t\t\t\t}()\n\n\t\t\t\t\tp = &cmdplugin.GrpcPlugin\n\t\t\t\t}\n\n\t\t\t\tgo func() {\n\t\t\t\t\tif err := p.RecvLogs(log.StandardLogger().Out); err != nil {\n\t\t\t\t\t\tlog.Errorf(\"plugin %v recv logs error: %v\", p.Name, err)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t\tplugins = append(plugins, p)\n\t\t\t}\n\n\t\t\tif err := d.install(plugins...); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\td.recorddir = ctx.String(\"typescript-log-dir\")\n\t\t\td.filterHostkeysReqeust = ctx.Bool(\"drop-hostkeys-message\")\n\n\t\t\tgo func() {\n\t\t\t\tquit <- d.run()\n\t\t\t}()\n\n\t\t\treturn <-quit\n\t\t},\n\t}", "is_vulnerable": 1}
{"code": "func TestTeamMembersAPIEndpoint_userLoggedIn(t *testing.T) {\n\tsettings := setting.NewCfg()\n\tsqlStore := sqlstore.InitTestDB(t)\n\ths := &HTTPServer{\n\t\tCfg:      settings,\n\t\tLicense:  &licensing.OSSLicensingService{},\n\t\tSQLStore: sqlStore,\n\t}\n\tmock := mockstore.NewSQLStoreMock()\n\n\tloggedInUserScenarioWithRole(t, \"When calling GET on\", \"GET\", \"api/teams/1/members\",\n\t\t\"api/teams/:teamId/members\", models.ROLE_ADMIN, func(sc *scenarioContext) {\n\t\t\tsetUpGetTeamMembersHandler(t, sqlStore)\n\n\t\t\tsc.handlerFunc = hs.GetTeamMembers\n\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{}).exec()\n\n\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\n\t\t\tvar resp []models.TeamMemberDTO\n\t\t\terr := json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\trequire.NoError(t, err)\n\t\t\tassert.Len(t, resp, 3)\n\t\t}, mock)\n\n\tt.Run(\"Given there is two hidden users\", func(t *testing.T) {\n\t\tsettings.HiddenUsers = map[string]struct{}{\n\t\t\t\"user1\":       {},\n\t\t\ttestUserLogin: {},\n\t\t}\n\t\tt.Cleanup(func() { settings.HiddenUsers = make(map[string]struct{}) })\n\n\t\tloggedInUserScenarioWithRole(t, \"When calling GET on\", \"GET\", \"api/teams/1/members\",\n\t\t\t\"api/teams/:teamId/members\", models.ROLE_ADMIN, func(sc *scenarioContext) {\n\t\t\t\tsetUpGetTeamMembersHandler(t, sqlStore)\n\n\t\t\t\tsc.handlerFunc = hs.GetTeamMembers\n\t\t\t\tsc.fakeReqWithParams(\"GET\", sc.url, map[string]string{}).exec()\n\n\t\t\t\trequire.Equal(t, http.StatusOK, sc.resp.Code)\n\n\t\t\t\tvar resp []models.TeamMemberDTO\n\t\t\t\terr := json.Unmarshal(sc.resp.Body.Bytes(), &resp)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tassert.Len(t, resp, 3)\n\t\t\t\tassert.Equal(t, \"loginuser0\", resp[0].Login)\n\t\t\t\tassert.Equal(t, \"loginuser1\", resp[1].Login)\n\t\t\t\tassert.Equal(t, \"loginuser2\", resp[2].Login)\n\t\t\t}, mock)\n\t})\n}", "is_vulnerable": 1}
{"code": "func fakeRepoServerClient(isHelm bool) *mocks.RepoServerServiceClient {\n\tmockRepoServiceClient := mocks.RepoServerServiceClient{}\n\tmockRepoServiceClient.On(\"ListApps\", mock.Anything, mock.Anything).Return(fakeAppList(), nil)\n\tmockRepoServiceClient.On(\"GenerateManifest\", mock.Anything, mock.Anything).Return(&apiclient.ManifestResponse{}, nil)\n\tmockRepoServiceClient.On(\"GetAppDetails\", mock.Anything, mock.Anything).Return(&apiclient.RepoAppDetailsResponse{}, nil)\n\tmockRepoServiceClient.On(\"TestRepository\", mock.Anything, mock.Anything).Return(&apiclient.TestRepositoryResponse{}, nil)\n\tmockRepoServiceClient.On(\"GetRevisionMetadata\", mock.Anything, mock.Anything).Return(&appsv1.RevisionMetadata{}, nil)\n\tmockWithFilesClient := &mocks.RepoServerService_GenerateManifestWithFilesClient{}\n\tmockWithFilesClient.On(\"Send\", mock.Anything).Return(nil)\n\tmockWithFilesClient.On(\"CloseAndRecv\").Return(&apiclient.ManifestResponse{}, nil)\n\tmockRepoServiceClient.On(\"GenerateManifestWithFiles\", mock.Anything, mock.Anything).Return(mockWithFilesClient, nil)\n\n\tif isHelm {\n\t\tmockRepoServiceClient.On(\"ResolveRevision\", mock.Anything, mock.Anything).Return(fakeResolveRevesionResponseHelm(), nil)\n\t} else {\n\t\tmockRepoServiceClient.On(\"ResolveRevision\", mock.Anything, mock.Anything).Return(fakeResolveRevesionResponse(), nil)\n\t}\n\n\treturn &mockRepoServiceClient\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessRequester) GetGrantedScopes() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetGrantedScopes\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func TestBuilder_BuildBootstrapLayeredRuntime(t *testing.T) {\n\tb := New(\"localhost:1111\", \"localhost:2222\", filemgr.NewManager(), nil)\n\tstaticCfg, err := b.BuildBootstrapLayeredRuntime()\n\tassert.NoError(t, err)\n\ttestutil.AssertProtoJSONEqual(t, `\n\t\t{ \"layers\": [{\n\t\t\t\"name\": \"static_layer_0\",\n\t\t\t\"staticLayer\": {\n\t\t\t\t\"overload\": {\n\t\t\t\t\t\"global_downstream_max_connections\": 50000\n\t\t\t\t}\n\t\t\t}\n\t\t}] }\n\t`, staticCfg)\n}", "is_vulnerable": 1}
{"code": "func ApplyListenerPatches(\n\tpatchContext networking.EnvoyFilter_PatchContext,\n\tproxy *model.Proxy,\n\tpush *model.PushContext,\n\tlisteners []*xdsapi.Listener,\n\tskipAdds bool) (out []*xdsapi.Listener) {\n\tdefer util.HandleCrash(func() {\n\t\tlog.Errorf(\"listeners patch caused panic, so the patches did not take effect\")\n\t})\n\t// In case the patches cause panic, use the listeners generated before to reduce the influence.\n\tout = listeners\n\n\tenvoyFilterWrappers := push.EnvoyFilters(proxy)\n\treturn doListenerListOperation(proxy, patchContext, envoyFilterWrappers, listeners, skipAdds)\n}", "is_vulnerable": 0}
{"code": "\tContext(\"with VirtualMachineInstance metadata\", func() {\n\t\tDescribeTable(\n\t\t\t\"Should allow VMI creation with kubevirt.io/ labels only for kubevirt service accounts\",\n\t\t\tfunc(vmiLabels map[string]string, userAccount string, positive bool) {\n\t\t\t\tvmi := api.NewMinimalVMI(\"testvmi\")\n\t\t\t\tvmi.Labels = vmiLabels\n\t\t\t\tvmiBytes, _ := json.Marshal(&vmi)\n\t\t\t\tar := &admissionv1.AdmissionReview{\n\t\t\t\t\tRequest: &admissionv1.AdmissionRequest{\n\t\t\t\t\t\tOperation: admissionv1.Create,\n\t\t\t\t\t\tUserInfo:  authv1.UserInfo{Username: \"system:serviceaccount:kubevirt:\" + userAccount},\n\t\t\t\t\t\tResource:  webhooks.VirtualMachineInstanceGroupVersionResource,\n\t\t\t\t\t\tObject: runtime.RawExtension{\n\t\t\t\t\t\t\tRaw: vmiBytes,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tresp := vmiCreateAdmitter.Admit(ar)\n\t\t\t\tif positive {\n\t\t\t\t\tExpect(resp.Allowed).To(BeTrue())\n\t\t\t\t} else {\n\t\t\t\t\tExpect(resp.Allowed).To(BeFalse())\n\t\t\t\t\tExpect(resp.Result.Details.Causes).To(HaveLen(1))\n\t\t\t\t\tExpect(resp.Result.Details.Causes[0].Message).To(Equal(\"creation of the following reserved kubevirt.io/ labels on a VMI object is prohibited\"))\n\t\t\t\t}\n\t\t\t},\n\t\t\tEntry(\"Create restricted label by API\",\n\t\t\t\tmap[string]string{v1.NodeNameLabel: \"someValue\"},\n\t\t\t\tcomponents.ApiServiceAccountName,\n\t\t\t\ttrue,\n\t\t\t),\n\t\t\tEntry(\"Create restricted label by Handler\",\n\t\t\t\tmap[string]string{v1.NodeNameLabel: \"someValue\"},\n\t\t\t\tcomponents.HandlerServiceAccountName,\n\t\t\t\ttrue,\n\t\t\t),\n\t\t\tEntry(\"Create restricted label by Controller\",\n\t\t\t\tmap[string]string{v1.NodeNameLabel: \"someValue\"},\n\t\t\t\tcomponents.ControllerServiceAccountName,\n\t\t\t\ttrue,\n\t\t\t),\n\t\t\tEntry(\"Create restricted label by non kubevirt user\",\n\t\t\t\tmap[string]string{v1.NodeNameLabel: \"someValue\"},\n\t\t\t\t\"user-account\",\n\t\t\t\tfalse,\n\t\t\t),\n\t\t\tEntry(\"Create non restricted kubevirt.io prefixed label by non kubevirt user\",\n\t\t\t\tmap[string]string{\"kubevirt.io/l\": \"someValue\"},\n\t\t\t\t\"user-account\",\n\t\t\t\ttrue,\n\t\t\t),\n\t\t)\n\t\tDescribeTable(\"should reject annotations which require feature gate enabled\", func(annotations map[string]string, expectedMsg string) {\n\t\t\tvmi := api.NewMinimalVMI(\"testvmi\")\n\t\t\tvmi.ObjectMeta = metav1.ObjectMeta{\n\t\t\t\tAnnotations: annotations,\n\t\t\t}\n\n\t\t\tcauses := ValidateVirtualMachineInstanceMetadata(k8sfield.NewPath(\"metadata\"), &vmi.ObjectMeta, config, \"fake-account\")\n\t\t\tExpect(causes).To(HaveLen(1))\n\t\t\tExpect(causes[0].Type).To(Equal(metav1.CauseTypeFieldValueInvalid))\n\t\t\tExpect(causes[0].Message).To(ContainSubstring(expectedMsg))\n\t\t},\n\t\t\tEntry(\"without ExperimentalIgnitionSupport feature gate enabled\",\n\t\t\t\tmap[string]string{v1.IgnitionAnnotation: \"fake-data\"},\n\t\t\t\tfmt.Sprintf(\"invalid entry metadata.annotations.%s\", v1.IgnitionAnnotation),\n\t\t\t),\n\t\t\tEntry(\"without sidecar feature gate enabled\",\n\t\t\t\tmap[string]string{hooks.HookSidecarListAnnotationName: \"[{'image': 'fake-image'}]\"},\n\t\t\t\tfmt.Sprintf(\"invalid entry metadata.annotations.%s\", hooks.HookSidecarListAnnotationName),\n\t\t\t),\n\t\t)\n\n\t\tDescribeTable(\"should accept annotations which require feature gate enabled\", func(annotations map[string]string, featureGate string) {\n\t\t\tenableFeatureGate(featureGate)\n\t\t\tvmi := api.NewMinimalVMI(\"testvmi\")\n\t\t\tvmi.ObjectMeta = metav1.ObjectMeta{\n\t\t\t\tAnnotations: annotations,\n\t\t\t}\n\t\t\tcauses := ValidateVirtualMachineInstanceMetadata(k8sfield.NewPath(\"metadata\"), &vmi.ObjectMeta, config, \"fake-account\")\n\t\t\tExpect(causes).To(BeEmpty())\n\t\t},\n\t\t\tEntry(\"with ExperimentalIgnitionSupport feature gate enabled\",\n\t\t\t\tmap[string]string{v1.IgnitionAnnotation: \"fake-data\"},\n\t\t\t\tvirtconfig.IgnitionGate,\n\t\t\t),\n\t\t\tEntry(\"with sidecar feature gate enabled\",\n\t\t\t\tmap[string]string{hooks.HookSidecarListAnnotationName: \"[{'image': 'fake-image'}]\"},\n\t\t\t\tvirtconfig.SidecarGate,\n\t\t\t),\n\t\t)\n\t})", "is_vulnerable": 0}
{"code": "func NewParser(authDirectory string, r resolver.Resolver) parser.IngressAnnotation {\n\treturn auth{\n\t\tr:                r,\n\t\tauthDirectory:    authDirectory,\n\t\tannotationConfig: authSecretAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\tgo func() {\n\t\t\t\terr := reverseExpandQuery.Execute(timeoutCtx, test.request, resultChan, resolutionMetadata)\n\t\t\t\tif err != nil {\n\t\t\t\t\treverseExpandErrCh <- err\n\t\t\t\t\tt.Logf(\"sent err %s\", err)\n\t\t\t\t}\n\t\t\t}()", "is_vulnerable": 0}
{"code": "func (c *Configurator) UpdateAutoTLS(manualCAPems, connectCAPems []string, pub, priv string, verifyServerHostname bool) error {\n\t// order of defers matters because log acquires a RLock()\n\tdefer c.log(\"UpdateAutoEncrypt\")\n\tcert, err := tls.X509KeyPair([]byte(pub), []byte(priv))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to load cert/key pair: %v\", err)\n\t}\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tpool, err := pool(append(c.manual.caPems, append(manualCAPems, connectCAPems...)...))\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.autoTLS.manualCAPems = manualCAPems\n\tc.autoTLS.connectCAPems = connectCAPems\n\tc.autoTLS.cert = &cert\n\tc.caPool = pool\n\tc.autoTLS.verifyServerHostname = verifyServerHostname\n\tc.version++\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func GenerateSelfSignedCA(entity pkix.Name, dnsNames []string, ttl time.Duration) ([]byte, []byte, error) {\n\tpriv, err := rsa.GenerateKey(rand.Reader, teleport.RSAKeySize)\n\tif err != nil {\n\t\treturn nil, nil, trace.Wrap(err)\n\t}\n\treturn GenerateSelfSignedCAWithPrivateKey(priv, entity, dnsNames, ttl)\n}", "is_vulnerable": 1}
{"code": "\terr = listSignatures(ctx, sigRepo, manifestDesc, opts.maxSignatures, func(sigManifestDesc ocispec.Descriptor) error {\n\t\tsigBlob, sigDesc, err := sigRepo.FetchSignatureBlob(ctx, sigManifestDesc)\n\t\tif err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"Warning: unable to fetch signature %s due to error: %v\\n\", sigManifestDesc.Digest.String(), err)\n\t\t\tskippedSignatures = true\n\t\t\treturn nil\n\t\t}\n\n\t\tsigEnvelope, err := signature.ParseEnvelope(sigDesc.MediaType, sigBlob)\n\t\tif err != nil {\n\t\t\tlogSkippedSignature(sigManifestDesc, err)\n\t\t\tskippedSignatures = true\n\t\t\treturn nil\n\t\t}\n\n\t\tenvelopeContent, err := sigEnvelope.Content()\n\t\tif err != nil {\n\t\t\tlogSkippedSignature(sigManifestDesc, err)\n\t\t\tskippedSignatures = true\n\t\t\treturn nil\n\t\t}\n\n\t\tsignedArtifactDesc, err := envelope.DescriptorFromSignaturePayload(&envelopeContent.Payload)\n\t\tif err != nil {\n\t\t\tlogSkippedSignature(sigManifestDesc, err)\n\t\t\tskippedSignatures = true\n\t\t\treturn nil\n\t\t}\n\n\t\tsignatureAlgorithm, err := proto.EncodeSigningAlgorithm(envelopeContent.SignerInfo.SignatureAlgorithm)\n\t\tif err != nil {\n\t\t\tlogSkippedSignature(sigManifestDesc, err)\n\t\t\tskippedSignatures = true\n\t\t\treturn nil\n\t\t}\n\n\t\tsig := signatureOutput{\n\t\t\tMediaType:             sigDesc.MediaType,\n\t\t\tDigest:                sigManifestDesc.Digest.String(),\n\t\t\tSignatureAlgorithm:    string(signatureAlgorithm),\n\t\t\tSignedAttributes:      getSignedAttributes(opts.outputFormat, envelopeContent),\n\t\t\tUserDefinedAttributes: signedArtifactDesc.Annotations,\n\t\t\tUnsignedAttributes:    getUnsignedAttributes(envelopeContent),\n\t\t\tCertificates:          getCertificates(opts.outputFormat, envelopeContent),\n\t\t\tSignedArtifact:        *signedArtifactDesc,\n\t\t}\n\n\t\t// clearing annotations from the SignedArtifact field since they're already\n\t\t// displayed as UserDefinedAttributes\n\t\tsig.SignedArtifact.Annotations = nil\n\n\t\toutput.Signatures = append(output.Signatures, sig)\n\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn ratelimit{\n\t\tr:                r,\n\t\tannotationConfig: rateLimitAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewUserGrantPreConditionReadModel(userID, projectID, projectGrantID string) *UserGrantPreConditionReadModel {\n\treturn &UserGrantPreConditionReadModel{\n\t\tUserID:         userID,\n\t\tProjectID:      projectID,\n\t\tProjectGrantID: projectGrantID,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e *Export) isRevoked(pubKey string, claimIssuedAt time.Time) bool {\n\treturn e.Revocations.IsRevoked(pubKey, claimIssuedAt)\n}", "is_vulnerable": 0}
{"code": "func flight4Parse(ctx context.Context, c flightConn, state *State, cache *handshakeCache, cfg *handshakeConfig) (flightVal, *alert.Alert, error) { //nolint:gocognit\n\tseq, msgs, ok := cache.fullPullMap(state.handshakeRecvSequence, state.cipherSuite,\n\t\thandshakeCachePullRule{handshake.TypeCertificate, cfg.initialEpoch, true, true},\n\t\thandshakeCachePullRule{handshake.TypeClientKeyExchange, cfg.initialEpoch, true, false},\n\t\thandshakeCachePullRule{handshake.TypeCertificateVerify, cfg.initialEpoch, true, true},\n\t)\n\tif !ok {\n\t\t// No valid message received. Keep reading\n\t\treturn 0, nil, nil\n\t}\n\n\t// Validate type\n\tvar clientKeyExchange *handshake.MessageClientKeyExchange\n\tif clientKeyExchange, ok = msgs[handshake.TypeClientKeyExchange].(*handshake.MessageClientKeyExchange); !ok {\n\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, nil\n\t}\n\n\tif h, hasCert := msgs[handshake.TypeCertificate].(*handshake.MessageCertificate); hasCert {\n\t\tstate.PeerCertificates = h.Certificate\n\t\t// If the client offer its certificate, just disable session resumption.\n\t\t// Otherwise, we have to store the certificate identitfication and expire time.\n\t\t// And we have to check whether this certificate expired, revoked or changed.\n\t\t//\n\t\t// https://curl.se/docs/CVE-2016-5419.html\n\t\tstate.SessionID = nil\n\t}\n\n\tif h, hasCertVerify := msgs[handshake.TypeCertificateVerify].(*handshake.MessageCertificateVerify); hasCertVerify {\n\t\tif state.PeerCertificates == nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.NoCertificate}, errCertificateVerifyNoCertificate\n\t\t}\n\n\t\tplainText := cache.pullAndMerge(\n\t\t\thandshakeCachePullRule{handshake.TypeClientHello, cfg.initialEpoch, true, false},\n\t\t\thandshakeCachePullRule{handshake.TypeServerHello, cfg.initialEpoch, false, false},\n\t\t\thandshakeCachePullRule{handshake.TypeCertificate, cfg.initialEpoch, false, false},\n\t\t\thandshakeCachePullRule{handshake.TypeServerKeyExchange, cfg.initialEpoch, false, false},\n\t\t\thandshakeCachePullRule{handshake.TypeCertificateRequest, cfg.initialEpoch, false, false},\n\t\t\thandshakeCachePullRule{handshake.TypeServerHelloDone, cfg.initialEpoch, false, false},\n\t\t\thandshakeCachePullRule{handshake.TypeCertificate, cfg.initialEpoch, true, false},\n\t\t\thandshakeCachePullRule{handshake.TypeClientKeyExchange, cfg.initialEpoch, true, false},\n\t\t)\n\n\t\t// Verify that the pair of hash algorithm and signiture is listed.\n\t\tvar validSignatureScheme bool\n\t\tfor _, ss := range cfg.localSignatureSchemes {\n\t\t\tif ss.Hash == h.HashAlgorithm && ss.Signature == h.SignatureAlgorithm {\n\t\t\t\tvalidSignatureScheme = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !validSignatureScheme {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InsufficientSecurity}, errNoAvailableSignatureSchemes\n\t\t}\n\n\t\tif err := verifyCertificateVerify(plainText, h.HashAlgorithm, h.Signature, state.PeerCertificates); err != nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.BadCertificate}, err\n\t\t}\n\t\tvar chains [][]*x509.Certificate\n\t\tvar err error\n\t\tvar verified bool\n\t\tif cfg.clientAuth >= VerifyClientCertIfGiven {\n\t\t\tif chains, err = verifyClientCert(state.PeerCertificates, cfg.clientCAs); err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.BadCertificate}, err\n\t\t\t}\n\t\t\tverified = true\n\t\t}\n\t\tif cfg.verifyPeerCertificate != nil {\n\t\t\tif err := cfg.verifyPeerCertificate(state.PeerCertificates, chains); err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.BadCertificate}, err\n\t\t\t}\n\t\t}\n\t\tstate.peerCertificatesVerified = verified\n\t} else if state.PeerCertificates != nil {\n\t\t// A certificate was received, but we haven't seen a CertificateVerify\n\t\t// keep reading until we receieve one\n\t\treturn 0, nil, nil\n\t}\n\n\tif !state.cipherSuite.IsInitialized() {\n\t\tserverRandom := state.localRandom.MarshalFixed()\n\t\tclientRandom := state.remoteRandom.MarshalFixed()\n\n\t\tvar err error\n\t\tvar preMasterSecret []byte\n\t\tif state.cipherSuite.AuthenticationType() == CipherSuiteAuthenticationTypePreSharedKey {\n\t\t\tvar psk []byte\n\t\t\tif psk, err = cfg.localPSKCallback(clientKeyExchange.IdentityHint); err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t\t}\n\t\t\tstate.IdentityHint = clientKeyExchange.IdentityHint\n\t\t\tswitch state.cipherSuite.KeyExchangeAlgorithm() {\n\t\t\tcase CipherSuiteKeyExchangeAlgorithmPsk:\n\t\t\t\tpreMasterSecret = prf.PSKPreMasterSecret(psk)\n\t\t\tcase (CipherSuiteKeyExchangeAlgorithmPsk | CipherSuiteKeyExchangeAlgorithmEcdhe):\n\t\t\t\tif preMasterSecret, err = prf.EcdhePSKPreMasterSecret(psk, clientKeyExchange.PublicKey, state.localKeypair.PrivateKey, state.localKeypair.Curve); err != nil {\n\t\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, errInvalidCipherSuite\n\t\t\t}\n\t\t} else {\n\t\t\tpreMasterSecret, err = prf.PreMasterSecret(clientKeyExchange.PublicKey, state.localKeypair.PrivateKey, state.localKeypair.Curve)\n\t\t\tif err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.IllegalParameter}, err\n\t\t\t}\n\t\t}\n\n\t\tif state.extendedMasterSecret {\n\t\t\tvar sessionHash []byte\n\t\t\tsessionHash, err = cache.sessionHash(state.cipherSuite.HashFunc(), cfg.initialEpoch)\n\t\t\tif err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t\t}\n\n\t\t\tstate.masterSecret, err = prf.ExtendedMasterSecret(preMasterSecret, sessionHash, state.cipherSuite.HashFunc())\n\t\t\tif err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t\t}\n\t\t} else {\n\t\t\tstate.masterSecret, err = prf.MasterSecret(preMasterSecret, clientRandom[:], serverRandom[:], state.cipherSuite.HashFunc())\n\t\t\tif err != nil {\n\t\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t\t}\n\t\t}\n\n\t\tif err := state.cipherSuite.Init(state.masterSecret, clientRandom[:], serverRandom[:], false); err != nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t}\n\t\tcfg.writeKeyLog(keyLogLabelTLS12, clientRandom[:], state.masterSecret)\n\t}\n\n\tif len(state.SessionID) > 0 {\n\t\ts := Session{\n\t\t\tID:     state.SessionID,\n\t\t\tSecret: state.masterSecret,\n\t\t}\n\t\tcfg.log.Tracef(\"[handshake] save new session: %x\", s.ID)\n\t\tif err := cfg.sessionStore.Set(state.SessionID, s); err != nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t\t}\n\t}\n\n\t// Now, encrypted packets can be handled\n\tif err := c.handleQueuedPackets(ctx); err != nil {\n\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, err\n\t}\n\n\tseq, msgs, ok = cache.fullPullMap(seq, state.cipherSuite,\n\t\thandshakeCachePullRule{handshake.TypeFinished, cfg.initialEpoch + 1, true, false},\n\t)\n\tif !ok {\n\t\t// No valid message received. Keep reading\n\t\treturn 0, nil, nil\n\t}\n\tstate.handshakeRecvSequence = seq\n\n\tif _, ok = msgs[handshake.TypeFinished].(*handshake.MessageFinished); !ok {\n\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.InternalError}, nil\n\t}\n\n\tif state.cipherSuite.AuthenticationType() == CipherSuiteAuthenticationTypeAnonymous {\n\t\treturn flight6, nil, nil\n\t}\n\n\tswitch cfg.clientAuth {\n\tcase RequireAnyClientCert:\n\t\tif state.PeerCertificates == nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.NoCertificate}, errClientCertificateRequired\n\t\t}\n\tcase VerifyClientCertIfGiven:\n\t\tif state.PeerCertificates != nil && !state.peerCertificatesVerified {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.BadCertificate}, errClientCertificateNotVerified\n\t\t}\n\tcase RequireAndVerifyClientCert:\n\t\tif state.PeerCertificates == nil {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.NoCertificate}, errClientCertificateRequired\n\t\t}\n\t\tif !state.peerCertificatesVerified {\n\t\t\treturn 0, &alert.Alert{Level: alert.Fatal, Description: alert.BadCertificate}, errClientCertificateNotVerified\n\t\t}\n\tcase NoClientCert, RequestClientCert:\n\t\treturn flight6, nil, nil\n\t}\n\n\treturn flight6, nil, nil\n}", "is_vulnerable": 0}
{"code": "func NewEgressDNS(addressSetFactory addressset.AddressSetFactory, controllerStop <-chan struct{}) (*EgressDNS, error) {\n\tdnsInfo, err := util.NewDNS(\"/etc/resolv.conf\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tegressDNS := &EgressDNS{\n\t\tdns:               dnsInfo,\n\t\tdnsEntries:        make(map[string]*dnsEntry),\n\t\taddressSetFactory: addressSetFactory,\n\n\t\tadded:          make(chan struct{}),\n\t\tstopChan:       make(chan struct{}),\n\t\tcontrollerStop: controllerStop,\n\t}\n\n\treturn egressDNS, nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(name, func(t *testing.T) {\n\t\t\tbuilder := Builder{\n\t\t\t\tSource: KubernetesCache{\n\t\t\t\t\tFieldLogger: fixture.NewTestLogger(t),\n\t\t\t\t},\n\t\t\t\tProcessors: []Processor{\n\t\t\t\t\t&IngressProcessor{\n\t\t\t\t\t\tFieldLogger: fixture.NewTestLogger(t),\n\t\t\t\t\t},\n\t\t\t\t\t&HTTPProxyProcessor{\n\t\t\t\t\t\tDisablePermitInsecure: tc.disablePermitInsecure,\n\t\t\t\t\t\tFallbackCertificate: &types.NamespacedName{\n\t\t\t\t\t\t\tName:      tc.fallbackCertificateName,\n\t\t\t\t\t\t\tNamespace: tc.fallbackCertificateNamespace,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t&ListenerProcessor{},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tfor _, o := range tc.objs {\n\t\t\t\tbuilder.Source.Insert(o)\n\t\t\t}\n\t\t\tdag := builder.Build()\n\n\t\t\tgot := make(map[int]*Listener)\n\t\t\tdag.Visit(listenerMap(got).Visit)\n\n\t\t\twant := make(map[int]*Listener)\n\t\t\tfor _, v := range tc.want {\n\t\t\t\tif l, ok := v.(*Listener); ok {\n\t\t\t\t\twant[l.Port] = l\n\t\t\t\t}\n\t\t\t}\n\t\t\tassert.Equal(t, want, got)\n\t\t})", "is_vulnerable": 1}
{"code": "func doDecryptCtx(dctx *decryptCtx) ([]byte, error) {\n\tm := dctx.msg\n\talg := dctx.alg\n\tkey := dctx.key\n\n\tif jwkKey, ok := key.(jwk.Key); ok {\n\t\tvar raw interface{}\n\t\tif err := jwkKey.Raw(&raw); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, `failed to retrieve raw key from %T`, key)\n\t\t}\n\t\tkey = raw\n\t}\n\n\tvar err error\n\tctx := context.TODO()\n\th, err := m.protectedHeaders.Clone(ctx)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, `failed to copy protected headers`)\n\t}\n\th, err = h.Merge(ctx, m.unprotectedHeaders)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to merge headers for message decryption\")\n\t}\n\n\tenc := m.protectedHeaders.ContentEncryption()\n\tvar aad []byte\n\tif aadContainer := m.authenticatedData; aadContainer != nil {\n\t\taad = base64.Encode(aadContainer)\n\t}\n\n\tvar computedAad []byte\n\tif len(m.rawProtectedHeaders) > 0 {\n\t\tcomputedAad = m.rawProtectedHeaders\n\t} else {\n\t\t// this is probably not required once msg.Decrypt is deprecated\n\t\tvar err error\n\t\tcomputedAad, err = m.protectedHeaders.Encode()\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to encode protected headers\")\n\t\t}\n\t}\n\n\tdec := NewDecrypter(alg, enc, key).\n\t\tAuthenticatedData(aad).\n\t\tComputedAuthenticatedData(computedAad).\n\t\tInitializationVector(m.initializationVector).\n\t\tTag(m.tag)\n\n\tvar plaintext []byte\n\tvar lastError error\n\n\t// if we have no recipients, pretend like we only have one\n\trecipients := m.recipients\n\tif len(recipients) == 0 {\n\t\tr := NewRecipient()\n\t\tif err := r.SetHeaders(m.protectedHeaders); err != nil {\n\t\t\treturn nil, errors.Wrap(err, `failed to set headers to recipient`)\n\t\t}\n\t\trecipients = append(recipients, r)\n\t}\n\n\tfor _, recipient := range recipients {\n\t\t// strategy: try each recipient. If we fail in one of the steps,\n\t\t// keep looping because there might be another key with the same algo\n\t\tif recipient.Headers().Algorithm() != alg {\n\t\t\t// algorithms don't match\n\t\t\tcontinue\n\t\t}\n\n\t\th2, err := h.Clone(ctx)\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to copy headers (1)`)\n\t\t\tcontinue\n\t\t}\n\n\t\th2, err = h2.Merge(ctx, recipient.Headers())\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to copy headers (2)`)\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch alg {\n\t\tcase jwa.ECDH_ES, jwa.ECDH_ES_A128KW, jwa.ECDH_ES_A192KW, jwa.ECDH_ES_A256KW:\n\t\t\tepkif, ok := h2.Get(EphemeralPublicKeyKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'epk' field\")\n\t\t\t}\n\t\t\tswitch epk := epkif.(type) {\n\t\t\tcase jwk.ECDSAPublicKey:\n\t\t\t\tvar pubkey ecdsa.PublicKey\n\t\t\t\tif err := epk.Raw(&pubkey); err != nil {\n\t\t\t\t\treturn nil, errors.Wrap(err, \"failed to get public key\")\n\t\t\t\t}\n\t\t\t\tdec.PublicKey(&pubkey)\n\t\t\tcase jwk.OKPPublicKey:\n\t\t\t\tvar pubkey interface{}\n\t\t\t\tif err := epk.Raw(&pubkey); err != nil {\n\t\t\t\t\treturn nil, errors.Wrap(err, \"failed to get public key\")\n\t\t\t\t}\n\t\t\t\tdec.PublicKey(pubkey)\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.Errorf(\"unexpected 'epk' type %T for alg %s\", epkif, alg)\n\t\t\t}\n\n\t\t\tif apu := h2.AgreementPartyUInfo(); len(apu) > 0 {\n\t\t\t\tdec.AgreementPartyUInfo(apu)\n\t\t\t}\n\n\t\t\tif apv := h2.AgreementPartyVInfo(); len(apv) > 0 {\n\t\t\t\tdec.AgreementPartyVInfo(apv)\n\t\t\t}\n\t\tcase jwa.A128GCMKW, jwa.A192GCMKW, jwa.A256GCMKW:\n\t\t\tivB64, ok := h2.Get(InitializationVectorKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'iv' field\")\n\t\t\t}\n\t\t\tivB64Str, ok := ivB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'iv': %T\", ivB64)\n\t\t\t}\n\t\t\ttagB64, ok := h2.Get(TagKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'tag' field\")\n\t\t\t}\n\t\t\ttagB64Str, ok := tagB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'tag': %T\", tagB64)\n\t\t\t}\n\t\t\tiv, err := base64.DecodeString(ivB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'iv'\")\n\t\t\t}\n\t\t\ttag, err := base64.DecodeString(tagB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'tag'\")\n\t\t\t}\n\t\t\tdec.KeyInitializationVector(iv)\n\t\t\tdec.KeyTag(tag)\n\t\tcase jwa.PBES2_HS256_A128KW, jwa.PBES2_HS384_A192KW, jwa.PBES2_HS512_A256KW:\n\t\t\tsaltB64, ok := h2.Get(SaltKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'p2s' field\")\n\t\t\t}\n\t\t\tsaltB64Str, ok := saltB64.(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'p2s': %T\", saltB64)\n\t\t\t}\n\n\t\t\tcount, ok := h2.Get(CountKey)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"failed to get 'p2c' field\")\n\t\t\t}\n\t\t\tcountFlt, ok := count.(float64)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.Errorf(\"unexpected type for 'p2c': %T\", count)\n\t\t\t}\n\t\t\t// in v1, this number is hardcoded to 10000. Use v2 if you need to\n\t\t\t// finetune this value\n\t\t\tif countFlt > 10000 {\n\t\t\t\treturn nil, errors.Errorf(\"invalid value for 'p2c'\")\n\t\t\t}\n\t\t\tsalt, err := base64.DecodeString(saltB64Str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to b64-decode 'salt'\")\n\t\t\t}\n\t\t\tdec.KeySalt(salt)\n\t\t\tdec.KeyCount(int(countFlt))\n\t\t}\n\n\t\tplaintext, err = dec.Decrypt(recipient.EncryptedKey(), m.cipherText)\n\t\tif err != nil {\n\t\t\tlastError = errors.Wrap(err, `failed to decrypt`)\n\t\t\tcontinue\n\t\t}\n\n\t\tif h2.Compression() == jwa.Deflate {\n\t\t\tbuf, err := uncompress(plaintext)\n\t\t\tif err != nil {\n\t\t\t\tlastError = errors.Wrap(err, `failed to uncompress payload`)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tplaintext = buf\n\t\t}\n\t\tbreak\n\t}\n\n\tif plaintext == nil {\n\t\tif lastError != nil {\n\t\t\treturn nil, errors.Errorf(`failed to find matching recipient to decrypt key (last error = %s)`, lastError)\n\t\t}\n\t\treturn nil, errors.New(\"failed to find matching recipient\")\n\t}\n\n\treturn plaintext, nil\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) IncomingRPCConfig() (*tls.Config, error) {\n\treturn c.commonTLSConfig(c.base.VerifyIncomingRPC)\n}", "is_vulnerable": 1}
{"code": "func (i *instances) GetContainers(scope string, id string) []string {\n\tctx := context.Background()\n\tif i.kubeClient != nil {\n\t\tresp, err := i.kubeClient.AppsV1().Deployments(scope).List(ctx, (meta_v1.ListOptions{}))\n\t\tif err != nil || len(resp.Items) == 0 {\n\t\t\treturn nil\n\t\t}\n\n\t\tfor _, d := range resp.Items {\n\t\t\tif d.Spec.Template.Annotations[daprEnabledAnnotation] != \"\" {\n\t\t\t\tdaprID := d.Spec.Template.Annotations[daprIDAnnotation]\n\t\t\t\tif daprID == id {\n\t\t\t\t\tpods, err := i.kubeClient.CoreV1().Pods(d.GetNamespace()).List(ctx, meta_v1.ListOptions{\n\t\t\t\t\t\tLabelSelector: labels.SelectorFromSet(d.Spec.Selector.MatchLabels).String(),\n\t\t\t\t\t})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Println(err)\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(pods.Items) > 0 {\n\t\t\t\t\t\tp := pods.Items[0]\n\t\t\t\t\t\tout := []string{}\n\t\t\t\t\t\tfor _, container := range p.Spec.Containers {\n\t\t\t\t\t\t\tout = append(out, container.Name)\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn out\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c CanonType) Compose(part ...interface{}) (t Tag, err error) {\n\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tt = Tag{}\n\t\t\terr = language.ErrSyntax\n\t\t}\n\t}()\n\n\tvar b language.Builder\n\tif err = update(&b, part...); err != nil {\n\t\treturn und, err\n\t}\n\tb.Tag, _ = canonicalize(c, b.Tag)\n\treturn makeTag(b.Make()), err\n}", "is_vulnerable": 0}
{"code": "func NewShareRepository(ctx context.Context, db dbx.Builder) model.ShareRepository {\n\tr := &shareRepository{}\n\tr.ctx = ctx\n\tr.db = db\n\tr.tableName = \"share\"\n\treturn r\n}", "is_vulnerable": 1}
{"code": "\t\tapp.WithOnInvokeFn(func(ctx context.Context, _ *commonv1.InvokeRequest) (*commonv1.InvokeResponse, error) {\n\t\t\tmd, ok := metadata.FromIncomingContext(ctx)\n\t\t\trequire.True(t, ok)\n\t\t\tb.ch <- md\n\t\t\treturn new(commonv1.InvokeResponse), nil\n\t\t}),", "is_vulnerable": 0}
{"code": "func mapStatus(pid string, status *Status) (*Status, error) {\n\tuidMap, err := ReadMappings(fmt.Sprintf(\"/proc/%s/uid_map\", pid))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tgidMap, err := ReadMappings(fmt.Sprintf(\"/proc/%s/gid_map\", pid))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\toverflowUid, overflowGid := overflowIds()\n\tfor i := range status.Uids {\n\t\tmapStatusField(&status.Uids[i], uidMap, overflowUid)\n\t}\n\tfor i := range status.Gids {\n\t\tmapStatusField(&status.Gids[i], gidMap, overflowGid)\n\t}\n\tfor i := range status.Groups {\n\t\tmapStatusField(&status.Groups[i], gidMap, overflowGid)\n\t}\n\treturn status, nil\n}", "is_vulnerable": 0}
{"code": "func SetProcessPrivileges(privs *Privileges) error {\n\tlog.Printf(\"Setting euid=%d egid=%d groups=%v\", privs.euid, privs.egid, privs.groups)\n\n\t// If setting privs as root, we need to set the euid to 0 first, so that\n\t// we will have the necessary permissions to make the other changes to\n\t// the groups/egid/euid, regardless of our original euid.\n\tC.seteuid(0)\n\n\t// Seperately handle the case where the user is in no groups.\n\tnumGroups := C.size_t(len(privs.groups))\n\tgroupsPtr := (*C.gid_t)(nil)\n\tif numGroups > 0 {\n\t\tgroupsPtr = &privs.groups[0]\n\t}\n\n\tif res, err := C.setgroups(numGroups, groupsPtr); res < 0 {\n\t\treturn errors.Wrapf(err.(syscall.Errno), \"setting groups\")\n\t}\n\tif res, err := C.setegid(privs.egid); res < 0 {\n\t\treturn errors.Wrapf(err.(syscall.Errno), \"setting egid\")\n\t}\n\tif res, err := C.seteuid(privs.euid); res < 0 {\n\t\treturn errors.Wrapf(err.(syscall.Errno), \"setting euid\")\n\t}\n\tProcessPrivileges()\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Wilson) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Wilson: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Wilson: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int64\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int64 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *Nil) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestFilesystem_Delete(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\n\tg.Describe(\"Delete\", func() {\n\t\tg.BeforeEach(func() {\n\t\t\tif err := rfs.CreateServerFileFromString(\"source.txt\", \"test content\"); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\n\t\t\tfs.unixFS.SetUsage(int64(utf8.RuneCountInString(\"test content\")))\n\t\t})\n\n\t\tg.It(\"does not delete files outside the root directory\", func() {\n\t\t\terr := rfs.CreateServerFileFromString(\"/../ext-source.txt\", \"external content\")\n\n\t\t\terr = fs.Delete(\"../ext-source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, ufs.ErrBadPathResolution)).IsTrue(\"err is not ErrBadPathResolution\")\n\t\t})\n\n\t\tg.It(\"does not allow the deletion of the root directory\", func() {\n\t\t\terr := fs.Delete(\"/\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, ufs.ErrBadPathResolution)).IsTrue(\"err is not ErrBadPathResolution\")\n\t\t})\n\n\t\tg.It(\"does not return an error if the target does not exist\", func() {\n\t\t\terr := fs.Delete(\"missing.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tst, err := rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(st.Name()).Equal(\"source.txt\")\n\t\t})\n\n\t\tg.It(\"deletes files and subtracts their size from the disk usage\", func() {\n\t\t\terr := fs.Delete(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t_, err = rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, ufs.ErrNotExist)).IsTrue(\"err is not ErrNotExist\")\n\n\t\t\tg.Assert(fs.CachedUsage()).Equal(int64(0))\n\t\t})\n\n\t\tg.It(\"deletes all items inside a directory if the directory is deleted\", func() {\n\t\t\tsources := []string{\n\t\t\t\t\"foo/source.txt\",\n\t\t\t\t\"foo/bar/source.txt\",\n\t\t\t\t\"foo/bar/baz/source.txt\",\n\t\t\t}\n\n\t\t\terr := os.MkdirAll(filepath.Join(rfs.root, \"/server/foo/bar/baz\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tfor _, s := range sources {\n\t\t\t\terr = rfs.CreateServerFileFromString(s, \"test content\")\n\t\t\t\tg.Assert(err).IsNil()\n\t\t\t}\n\n\t\t\tfs.unixFS.SetUsage(int64(utf8.RuneCountInString(\"test content\") * 3))\n\n\t\t\terr = fs.Delete(\"foo\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(fs.unixFS.Usage()).Equal(int64(0))\n\n\t\t\tfor _, s := range sources {\n\t\t\t\t_, err = rfs.StatServerFile(s)\n\t\t\t\tg.Assert(err).IsNotNil()\n\t\t\t\tg.Assert(errors.Is(err, ufs.ErrNotExist)).IsTrue(\"err is not ErrNotExist\")\n\t\t\t}\n\t\t})\n\n\t\tg.It(\"deletes a symlink but not it's target within the root directory\", func() {\n\t\t\t// Symlink to a file inside the root directory.\n\t\t\terr := os.Symlink(filepath.Join(rfs.root, \"server/source.txt\"), filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink itself.\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the symlink was deleted.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNotNil()\n\n\t\t\t// Ensure the symlink target still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked outside of the root directory\", func() {\n\t\t\t// Create a file outside the root directory.\n\t\t\terr := rfs.CreateServerFileFromString(\"/../source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a symlink to the file outside the root directory.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"source.txt\"), filepath.Join(rfs.root, \"/server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink. (This should pass as we will delete the symlink itself, not it's target)\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a file inside the directory that is outside the root.\n\t\t\terr = rfs.CreateServerFileFromString(\"/../foo/source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, ufs.ErrBadPathResolution)).IsTrue(\"err is not ErrBadPathResolution\")\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"foo/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"returns an error when trying to delete a non-existent file symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo2\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo2\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, ufs.ErrBadPathResolution)).IsTrue(\"err is not ErrBadPathResolution\")\n\t\t})\n\n\t\tg.AfterEach(func() {\n\t\t\t_ = fs.TruncateRootDirectory()\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (m *Castaway) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Castaway: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Castaway: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32Ptr\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int32Ptr = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int32\", wireType)\n\t\t\t}\n\t\t\tm.Int32 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Int32 |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyUint64Ptr\", wireType)\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_casttype.MyUint64Type\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.MyUint64Ptr = &v\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyUint64\", wireType)\n\t\t\t}\n\t\t\tm.MyUint64 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.MyUint64 |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyFloat32Ptr\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tv2 := github_com_gogo_protobuf_test_casttype.MyFloat32Type(math.Float32frombits(v))\n\t\t\tm.MyFloat32Ptr = &v2\n\t\tcase 6:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyFloat32\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.MyFloat32 = github_com_gogo_protobuf_test_casttype.MyFloat32Type(math.Float32frombits(v))\n\t\tcase 7:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyFloat64Ptr\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tv2 := github_com_gogo_protobuf_test_casttype.MyFloat64Type(math.Float64frombits(v))\n\t\t\tm.MyFloat64Ptr = &v2\n\t\tcase 8:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyFloat64\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.MyFloat64 = github_com_gogo_protobuf_test_casttype.MyFloat64Type(math.Float64frombits(v))\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyBytes\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.MyBytes = append(m.MyBytes[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.MyBytes == nil {\n\t\t\t\tm.MyBytes = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NormalBytes\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NormalBytes = append(m.NormalBytes[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.NormalBytes == nil {\n\t\t\t\tm.NormalBytes = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v github_com_gogo_protobuf_test_casttype.MyUint64Type\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.MyUint64S = append(m.MyUint64S, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.MyUint64S) == 0 {\n\t\t\t\t\tm.MyUint64S = make([]github_com_gogo_protobuf_test_casttype.MyUint64Type, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v github_com_gogo_protobuf_test_casttype.MyUint64Type\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.MyUint64S = append(m.MyUint64S, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyUint64S\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.MyMap == nil {\n\t\t\t\tm.MyMap = make(github_com_gogo_protobuf_test_casttype.MyMapType)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue uint64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.MyMap[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyCustomMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.MyCustomMap == nil {\n\t\t\t\tm.MyCustomMap = make(map[github_com_gogo_protobuf_test_casttype.MyStringType]github_com_gogo_protobuf_test_casttype.MyUint64Type)\n\t\t\t}\n\t\t\tvar mapkey github_com_gogo_protobuf_test_casttype.MyStringType\n\t\t\tvar mapvalue uint64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = github_com_gogo_protobuf_test_casttype.MyStringType(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapvalue |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.MyCustomMap[github_com_gogo_protobuf_test_casttype.MyStringType(mapkey)] = ((github_com_gogo_protobuf_test_casttype.MyUint64Type)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyNullableMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.MyNullableMap == nil {\n\t\t\t\tm.MyNullableMap = make(map[github_com_gogo_protobuf_test_casttype.MyInt32Type]*Wilson)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tvar mapvalue *Wilson\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Wilson{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.MyNullableMap[github_com_gogo_protobuf_test_casttype.MyInt32Type(mapkey)] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyEmbeddedMap\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.MyEmbeddedMap == nil {\n\t\t\t\tm.MyEmbeddedMap = make(map[github_com_gogo_protobuf_test_casttype.MyInt32Type]Wilson)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := &Wilson{}\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Wilson{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.MyEmbeddedMap[github_com_gogo_protobuf_test_casttype.MyInt32Type(mapkey)] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field String_\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := github_com_gogo_protobuf_test_casttype.MyStringType(dAtA[iNdEx:postIndex])\n\t\t\tm.String_ = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func getStateFile(ctx *cli.Context) error {\n\tlogrus.Infof(\"Retrieving state file from cluster\")\n\t// Check if we can successfully connect to the cluster using the existing kubeconfig file\n\tlocalKubeConfig := pki.GetLocalKubeConfig(ctx.String(\"config\"), \"\")\n\tclusterFile, clusterFilePath, err := resolveClusterFile(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to resolve cluster file: %v\", err)\n\t}\n\t// setting up the flags\n\tflags := cluster.GetExternalFlags(false, false, false, false, \"\", clusterFilePath)\n\n\t// not going to use a k8s dialer here.. this is a CLI command\n\tserverVersion, err := cluster.GetK8sVersion(localKubeConfig, nil)\n\tif err != nil {\n\t\tlogrus.Infof(\"Unable to connect to server using kubeconfig, trying to get state from Control Plane node(s), error: %v\", err)\n\t\t// We need to retrieve the state file using Docker on the node(s)\n\n\t\trkeConfig, err := cluster.ParseConfig(clusterFile)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to parse cluster file: %v\", err)\n\t\t}\n\n\t\trkeConfig, err = setOptionsFromCLI(ctx, rkeConfig)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t_, _, _, _, _, err = RetrieveClusterStateConfigMap(context.Background(), rkeConfig, hosts.DialersOptions{}, flags, map[string]interface{}{})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\treturn nil\n\t}\n\n\tlogrus.Infof(\"Successfully connected to server using kubeconfig, retrieved server version [%s]\", serverVersion)\n\n\tk8sClient, err := k8s.NewClient(localKubeConfig, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Try fetch full cluster state from a secret. In older versions of RKE, this was stored in a configmap, but it\n\t// is now a secret.\n\trkeFullState, err := cluster.GetFullStateFromK8s(context.Background(), k8sClient)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error getting full cluster state from secret: %w\", err)\n\t}\n\n\t// Move current state file\n\tstateFilePath := cluster.GetStateFilePath(flags.ClusterFilePath, flags.ConfigDir)\n\terr = util.ReplaceFileWithBackup(stateFilePath, \"rkestate\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Write new state file\n\terr = rkeFullState.WriteStateFile(context.Background(), stateFilePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func WithRelabeledContainerMounts(mountLabel string) oci.SpecOpts {\n\treturn func(ctx context.Context, client oci.Client, _ *containers.Container, s *runtimespec.Spec) (err error) {\n\t\tif mountLabel == \"\" {\n\t\t\treturn nil\n\t\t}\n\t\tfor _, m := range s.Mounts {\n\t\t\tswitch m.Destination {\n\t\t\tcase etcHosts, etcHostname, resolvConfPath:\n\t\t\t\tif err := label.Relabel(m.Source, mountLabel, false); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewLoginNoContent() *LoginNoContent {\n\n\treturn &LoginNoContent{}\n}", "is_vulnerable": 0}
{"code": "func (client *DecryptionClient) contentCipherFromEnvelope(ctx aws.Context, env Envelope) (ContentCipher, error) {\n\twrap, err := client.wrapFromEnvelope(env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn client.cekFromEnvelope(ctx, env, wrap)\n}", "is_vulnerable": 1}
{"code": "func OpenTPM(path string) (io.ReadWriteCloser, error) {\n\treturn openAndStartupTPM(path, false)\n}", "is_vulnerable": 0}
{"code": "func (query *ExpandQuery) resolveTupleToUserset(\n\tctx context.Context,\n\tstore, modelID string,\n\tuserset *openfgapb.TupleToUserset,\n\ttk *openfgapb.TupleKey,\n\ttypesys *typesystem.TypeSystem,\n) (*openfgapb.UsersetTree_Node, error) {\n\tctx, span := query.tracer.Start(ctx, \"resolveTupleToUserset\")\n\tdefer span.End()\n\n\ttargetObject := tk.GetObject()\n\n\ttupleset := userset.GetTupleset().GetRelation()\n\n\tobjectType, _ := tupleUtils.SplitObject(targetObject)\n\trelation, err := typesys.GetRelation(objectType, tupleset)\n\tif err != nil {\n\t\tif errors.Is(err, typesystem.ErrObjectTypeUndefined) {\n\t\t\treturn nil, serverErrors.TypeNotFound(objectType)\n\t\t}\n\n\t\tif errors.Is(err, typesystem.ErrRelationUndefined) {\n\t\t\treturn nil, serverErrors.RelationNotFound(tupleset, objectType, tupleUtils.NewTupleKey(tk.Object, tupleset, tk.User))\n\t\t}\n\t}\n\n\ttuplesetRewrite := relation.GetRewrite().GetUserset()\n\tif tuplesetRewrite != nil && reflect.TypeOf(tuplesetRewrite) != reflect.TypeOf(&openfgapb.Userset_This{}) {\n\t\tquery.logger.Warn(\n\t\t\tfmt.Sprintf(\"unexpected rewrite on tupleset relation '%s#%s'\", objectType, tupleset),\n\t\t\tzap.String(\"store_id\", store),\n\t\t\tzap.String(\"authorization_model_id\", modelID),\n\t\t\tzap.String(\"object_type\", objectType),\n\t\t\tzap.String(\"relation\", tupleset),\n\t\t)\n\n\t\treturn nil, serverErrors.InvalidAuthorizationModelInput(\n\t\t\tfmt.Errorf(\"unexpected rewrite on relation '%s#%s'\", objectType, tupleset),\n\t\t)\n\t}\n\n\ttsKey := &openfgapb.TupleKey{\n\t\tObject:   targetObject,\n\t\tRelation: tupleset,\n\t}\n\n\tif tsKey.GetRelation() == \"\" {\n\t\ttsKey.Relation = tk.GetRelation()\n\t}\n\n\titer, err := query.datastore.Read(ctx, store, tsKey)\n\tif err != nil {\n\t\treturn nil, serverErrors.HandleError(\"\", err)\n\t}\n\tdefer iter.Stop()\n\n\tvar computed []*openfgapb.UsersetTree_Computed\n\tseen := make(map[string]bool)\n\tfor {\n\t\ttuple, err := iter.Next()\n\t\tif err != nil {\n\t\t\tif err == storage.ErrIteratorDone {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, serverErrors.HandleError(\"\", err)\n\t\t}\n\t\tuser := tuple.GetKey().GetUser()\n\n\t\tif user == Wildcard {\n\t\t\tobjectType, _ := tupleUtils.SplitObject(targetObject)\n\n\t\t\tquery.logger.WarnWithContext(\n\t\t\t\tctx,\n\t\t\t\tfmt.Sprintf(\"unexpected wildcard evaluated on tupleset relation '%s'\", tupleset),\n\t\t\t\tzap.String(\"store_id\", store),\n\t\t\t\tzap.String(\"authorization_model_id\", modelID),\n\t\t\t\tzap.String(\"object_type\", objectType),\n\t\t\t)\n\n\t\t\treturn nil, serverErrors.InvalidTuple(\n\t\t\t\tfmt.Sprintf(\"unexpected wildcard evaluated on relation '%s#%s'\", objectType, tupleset),\n\t\t\t\ttupleUtils.NewTupleKey(targetObject, tupleset, Wildcard),\n\t\t\t)\n\t\t}\n\n\t\t// user must contain a type (i.e., be an object or userset)\n\t\tif tupleUtils.GetType(user) == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\ttObject, tRelation := tupleUtils.SplitObjectRelation(user)\n\t\t// We only proceed in the case that tRelation == userset.GetComputedUserset().GetRelation().\n\t\t// tRelation may be empty, and in this case, we set it to userset.GetComputedUserset().GetRelation().\n\t\tif tRelation == \"\" {\n\t\t\ttRelation = userset.GetComputedUserset().GetRelation()\n\t\t}\n\n\t\tif tRelation != userset.GetComputedUserset().GetRelation() {\n\t\t\tcontinue\n\t\t}\n\n\t\tcs := &openfgapb.TupleKey{\n\t\t\tObject:   tObject,\n\t\t\tRelation: tRelation,\n\t\t}\n\n\t\tcomputedRelation := toObjectRelation(cs)\n\t\tif !seen[computedRelation] {\n\t\t\tcomputed = append(computed, &openfgapb.UsersetTree_Computed{Userset: computedRelation})\n\t\t\tseen[computedRelation] = true\n\t\t}\n\t}\n\n\treturn &openfgapb.UsersetTree_Node{\n\t\tName: toObjectRelation(tk),\n\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_TupleToUserset{\n\t\t\t\t\tTupleToUserset: &openfgapb.UsersetTree_TupleToUserset{\n\t\t\t\t\t\tTupleset: toObjectRelation(tsKey),\n\t\t\t\t\t\tComputed: computed,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (w *Workspace) ScanWorkspace(ctx context.Context) {\n\tfor _, folder := range w.folders {\n\t\tgo folder.ScanFolder(ctx)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (svc *Service) ListHostDeviceMapping(ctx context.Context, id uint) ([]*fleet.HostDeviceMapping, error) {\n\tif !svc.authz.IsAuthenticatedWith(ctx, authz_ctx.AuthnDeviceToken) {\n\t\tif err := svc.authz.Authorize(ctx, &fleet.Host{}, fleet.ActionList); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\thost, err := svc.ds.HostLite(ctx, id)\n\t\tif err != nil {\n\t\t\treturn nil, ctxerr.Wrap(ctx, err, \"get host\")\n\t\t}\n\n\t\t// Authorize again with team loaded now that we have team_id\n\t\tif err := svc.authz.Authorize(ctx, host, fleet.ActionRead); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn svc.ds.ListHostDeviceMapping(ctx, id)\n}", "is_vulnerable": 1}
{"code": "func TestListObjects_UnhappyPaths(t *testing.T) {\n\tctx := context.Background()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgav1.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: []*openfgav1.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"document\",\n\t\t\t\tRelations: map[string]*openfgav1.Userset{\n\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t},\n\t\t\t\tMetadata: &openfgav1.Metadata{\n\t\t\t\t\tRelations: map[string]*openfgav1.RelationMetadata{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgav1.RelationReference{\n\t\t\t\t\t\t\t\ttypesystem.DirectRelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t\ttypesystem.WildcardRelationReference(\"user\"),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, storage.ReadStartingWithUserFilter{\n\t\tObjectType: \"document\",\n\t\tRelation:   \"viewer\",\n\t\tUserFilter: []*openfgav1.ObjectRelation{\n\t\t\t{Object: \"user:*\"},\n\t\t\t{Object: \"user:bob\"},\n\t\t}}).AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := MustNewServerWithOpts(\n\t\tWithDatastore(mockDatastore),\n\t)\n\n\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\tres, err := s.ListObjects(ctx, &openfgav1.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t})\n\n\t\trequire.Nil(t, res)\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgav1.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t}, NewMockStreamServer())\n\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n}", "is_vulnerable": 1}
{"code": "func (dl *Download) Execute() error {\n\tctx, cancel := context.WithTimeout(context.Background(), time.Hour*12)\n\tdl.cancelFunc = &cancel\n\tdefer dl.Cancel()\n\n\t// Always ensure that we're checking the destination for the download to avoid a malicious\n\t// user from accessing internal network resources.\n\tif err := dl.isExternalNetwork(ctx); err != nil {\n\t\treturn err\n\t}\n\n\t// At this point we have verified the destination is not within the local network, so we can\n\t// now make a request to that URL and pull down the file, saving it to the server's data\n\t// directory.\n\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, dl.req.URL.String(), nil)\n\tif err != nil {\n\t\treturn errors.WrapIf(err, \"downloader: failed to create request\")\n\t}\n\n\treq.Header.Set(\"User-Agent\", \"Pterodactyl Panel (https://pterodactyl.io)\")\n\tres, err := client.Do(req)\n\tif err != nil {\n\t\treturn ErrDownloadFailed\n\t}\n\tdefer res.Body.Close()\n\tif res.StatusCode != http.StatusOK {\n\t\treturn errors.New(\"downloader: got bad response status from endpoint: \" + res.Status)\n\t}\n\n\tif res.ContentLength < 1 {\n\t\treturn errors.New(\"downloader: request is missing ContentLength\")\n\t}\n\n\tif dl.req.UseHeader {\n\t\tif contentDisposition := res.Header.Get(\"Content-Disposition\"); contentDisposition != \"\" {\n\t\t\t_, params, err := mime.ParseMediaType(contentDisposition)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.WrapIf(err, \"downloader: invalid \\\"Content-Disposition\\\" header\")\n\t\t\t}\n\n\t\t\tif v, ok := params[\"filename\"]; ok {\n\t\t\t\tdl.path = v\n\t\t\t}\n\t\t}\n\t}\n\tif dl.path == \"\" {\n\t\tif dl.req.FileName != \"\" {\n\t\t\tdl.path = dl.req.FileName\n\t\t} else {\n\t\t\tparts := strings.Split(dl.req.URL.Path, \"/\")\n\t\t\tdl.path = parts[len(parts)-1]\n\t\t}\n\t}\n\n\tp := dl.Path()\n\tdl.server.Log().WithField(\"path\", p).Debug(\"writing remote file to disk\")\n\n\t// Write the file while tracking the progress, Write will check that the\n\t// size of the file won't exceed the disk limit.\n\tr := io.TeeReader(res.Body, dl.counter(res.ContentLength))\n\tif err := dl.server.Filesystem().Write(p, r, res.ContentLength, 0o644); err != nil {\n\t\treturn errors.WrapIf(err, \"downloader: failed to write file to server directory\")\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func Panics(t TestingT, f assert.PanicTestFunc, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Panics(t, f, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func uncompress(plaintext []byte) ([]byte, error) {\n\treturn ioutil.ReadAll(flate.NewReader(bytes.NewReader(plaintext)))\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tapp := fiber.New()\n\t\t\tapp.Use(\"/\", New(tc.Config))\n\n\t\t\thandler := app.Handler()\n\n\t\t\tctx := &fasthttp.RequestCtx{}\n\t\t\tctx.Request.SetRequestURI(\"/\")\n\t\t\tctx.Request.Header.SetMethod(fiber.MethodOptions)\n\t\t\tctx.Request.Header.Set(fiber.HeaderOrigin, tc.RequestOrigin)\n\n\t\t\thandler(ctx)\n\n\t\t\tif tc.Config.AllowCredentials {\n\t\t\t\tutils.AssertEqual(t, \"true\", string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowCredentials)))\n\t\t\t}\n\t\t\tutils.AssertEqual(t, tc.ResponseOrigin, string(ctx.Response.Header.Peek(fiber.HeaderAccessControlAllowOrigin)))\n\t\t})", "is_vulnerable": 1}
{"code": "func TestPathRoleSet_UpdateKeyRoleSet(t *testing.T) {\n\trsName := \"test-updatekeyrs\"\n\tinitRoles := util.StringSet{\n\t\t\"roles/viewer\": struct{}{},\n\t}\n\tupdatedRoles := util.StringSet{\n\t\t\"roles/browser\":         struct{}{},\n\t\t\"roles/cloudsql.client\": struct{}{},\n\t}\n\n\t// Initial test set up - backend, initial config, test resources in project\n\ttd := setupTest(t, \"0s\", \"2h\")\n\tdefer cleanup(t, td, rsName, initRoles.Union(updatedRoles))\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create role set\n\texpectedBinds := ResourceBindings{projRes: initRoles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":     td.Project,\n\t\t\t\"secret_type\": SecretTypeKey,\n\t\t\t\"bindings\":    bindsRaw,\n\t\t})\n\n\t// Verify\n\trespData := testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\tverifyReadData(t, respData, map[string]interface{}{\n\t\t\"secret_type\": SecretTypeKey,\n\t\t\"project\":     td.Project,\n\t\t\"bindings\":    expectedBinds,\n\t})\n\n\tinitSa := getServiceAccount(t, td.IamAdmin, respData)\n\tverifyProjectBinding(t, td, initSa.Email, initRoles)\n\n\t// Verify theses updates don't work:\n\terrCases := []map[string]interface{}{\n\t\t{\n\t\t\t// new project should not be allowed\n\t\t\t\"project\": \"diff-proj\",\n\t\t},\n\t\t{\n\t\t\t// Cannot be applied to key role sets\n\t\t\t\"secret_type\": SecretTypeAccessToken,\n\t\t},\n\t}\n\tfor _, d := range errCases {\n\t\tresp, err := td.B.HandleRequest(context.Background(), &logical.Request{\n\t\t\tOperation: logical.UpdateOperation,\n\t\t\tPath:      fmt.Sprintf(\"roleset/%s\", rsName),\n\t\t\tData:      d,\n\t\t\tStorage:   td.S,\n\t\t})\n\t\tif err == nil && (resp != nil && !resp.IsError()) {\n\t\t\tt.Fatalf(\"expected update to fail; data: %v\", d)\n\t\t}\n\t}\n\n\t// Update role set\n\texpectedBinds = ResourceBindings{projRes: updatedRoles}\n\tbindsRaw, err = util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetUpdate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":     td.Project,\n\t\t\t\"secret_type\": SecretTypeKey,\n\t\t\t\"bindings\":    bindsRaw,\n\t\t})\n\n\t// Verify\n\trespData = testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\tverifyReadData(t, respData, map[string]interface{}{\n\t\t\"secret_type\": SecretTypeKey, // default\n\t\t\"project\":     td.Project,\n\t\t\"bindings\":    expectedBinds,\n\t})\n\n\tnewSa := getServiceAccount(t, td.IamAdmin, respData)\n\tif newSa.Name == initSa.Name {\n\t\tt.Fatalf(\"expected role set to have new service account after update\")\n\t}\n\tverifyProjectBinding(t, td, newSa.Email, updatedRoles)\n\n\tverifyServiceAccountDeleted(t, td.IamAdmin, initSa.Name)\n\tverifyProjectBindingsRemoved(t, td, initSa.Email, updatedRoles)\n\n\t// 4. Delete role set\n\ttestRoleSetDelete(t, td, rsName, newSa.Name)\n\tverifyProjectBindingsRemoved(t, td, newSa.Email, updatedRoles)\n}", "is_vulnerable": 0}
{"code": "func (s *Sync) schedule(req *request) {\n\tvar reqset = s.nodeReqs\n\tif req.code {\n\t\treqset = s.codeReqs\n\t}\n\t// If we're already requesting this node, add a new reference and stop\n\tif old, ok := reqset[req.hash]; ok {\n\t\told.parents = append(old.parents, req.parents...)\n\t\treturn\n\t}\n\treqset[req.hash] = req\n\n\t// Schedule the request for future retrieval. This queue is shared\n\t// by both node requests and code requests. It can happen that there\n\t// is a trie node and code has same hash. In this case two elements\n\t// with same hash and same or different depth will be pushed. But it's\n\t// ok the worst case is the second response will be treated as duplicated.\n\ts.queue.Push(req.hash, int64(req.depth))\n}", "is_vulnerable": 0}
{"code": "func TestUpdateSnapshotClass(t *testing.T) {\n\ttests := []controllerTest{\n\t\t{\n\t\t\t// default snapshot class name should be set\n\t\t\tname:                  \"1-1 - default snapshot class name should be set\",\n\t\t\tinitialContents:       nocontents,\n\t\t\tinitialSnapshots:      newSnapshotArray(\"snap1-1\", \"snapuid1-1\", \"claim1-1\", \"\", \"\", \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\texpectedSnapshots:     newSnapshotArray(\"snap1-1\", \"snapuid1-1\", \"claim1-1\", \"\", defaultClass, \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\tinitialClaims:         newClaimArray(\"claim1-1\", \"pvc-uid1-1\", \"1Gi\", \"volume1-1\", v1.ClaimBound, &sameDriver),\n\t\t\tinitialVolumes:        newVolumeArray(\"volume1-1\", \"pv-uid1-1\", \"pv-handle1-1\", \"1Gi\", \"pvc-uid1-1\", \"claim1-1\", v1.VolumeBound, v1.PersistentVolumeReclaimDelete, classEmpty),\n\t\t\tinitialStorageClasses: []*storage.StorageClass{sameDriverStorageClass},\n\t\t\texpectedEvents:        noevents,\n\t\t\terrors:                noerrors,\n\t\t\ttest:                  testUpdateSnapshotClass,\n\t\t},\n\t\t{\n\t\t\t// snapshot class name already set\n\t\t\tname:                  \"1-2 - snapshot class name already set\",\n\t\t\tinitialContents:       nocontents,\n\t\t\tinitialSnapshots:      newSnapshotArray(\"snap1-2\", \"snapuid1-2\", \"claim1-2\", \"\", defaultClass, \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\texpectedSnapshots:     newSnapshotArray(\"snap1-2\", \"snapuid1-2\", \"claim1-2\", \"\", defaultClass, \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\tinitialClaims:         newClaimArray(\"claim1-2\", \"pvc-uid1-2\", \"1Gi\", \"volume1-2\", v1.ClaimBound, &sameDriver),\n\t\t\tinitialVolumes:        newVolumeArray(\"volume1-2\", \"pv-uid1-2\", \"pv-handle1-2\", \"1Gi\", \"pvc-uid1-2\", \"claim1-2\", v1.VolumeBound, v1.PersistentVolumeReclaimDelete, classEmpty),\n\t\t\tinitialStorageClasses: []*storage.StorageClass{sameDriverStorageClass},\n\t\t\texpectedEvents:        noevents,\n\t\t\terrors:                noerrors,\n\t\t\ttest:                  testUpdateSnapshotClass,\n\t\t},\n\t\t{\n\t\t\t// default snapshot class not found\n\t\t\tname:                  \"1-3 - snapshot class name not found\",\n\t\t\tinitialContents:       nocontents,\n\t\t\tinitialSnapshots:      newSnapshotArray(\"snap1-3\", \"snapuid1-3\", \"claim1-3\", \"\", \"missing-class\", \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\texpectedSnapshots:     newSnapshotArray(\"snap1-3\", \"snapuid1-3\", \"claim1-3\", \"\", \"missing-class\", \"\", &False, nil, nil, newVolumeError(\"Failed to get snapshot class with error volumesnapshotclass.snapshot.storage.k8s.io \\\"missing-class\\\" not found\"), false, true, nil),\n\t\t\tinitialClaims:         newClaimArray(\"claim1-3\", \"pvc-uid1-3\", \"1Gi\", \"volume1-3\", v1.ClaimBound, &sameDriver),\n\t\t\tinitialVolumes:        newVolumeArray(\"volume1-3\", \"pv-uid1-3\", \"pv-handle1-3\", \"1Gi\", \"pvc-uid1-3\", \"claim1-3\", v1.VolumeBound, v1.PersistentVolumeReclaimDelete, classEmpty),\n\t\t\tinitialStorageClasses: []*storage.StorageClass{sameDriverStorageClass},\n\t\t\texpectedEvents:        []string{\"Warning GetSnapshotClassFailed\"},\n\t\t\terrors:                noerrors,\n\t\t\ttest:                  testUpdateSnapshotClass,\n\t\t},\n\t\t{\n\t\t\t// failed to get snapshot class from name\n\t\t\tname:                  \"1-4 - snapshot update with default class name failed because storageclass not found\",\n\t\t\tinitialContents:       nocontents,\n\t\t\tinitialSnapshots:      newSnapshotArray(\"snap1-4\", \"snapuid1-4\", \"claim1-4\", \"\", \"\", \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\texpectedSnapshots:     newSnapshotArray(\"snap1-4\", \"snapuid1-4\", \"claim1-4\", \"\", \"\", \"\", &False, nil, nil, newVolumeError(\"Failed to set default snapshot class with error mock update error\"), false, true, nil),\n\t\t\tinitialClaims:         newClaimArray(\"claim1-4\", \"pvc-uid1-4\", \"1Gi\", \"volume1-4\", v1.ClaimBound, &sameDriver),\n\t\t\tinitialVolumes:        newVolumeArray(\"volume1-4\", \"pv-uid1-4\", \"pv-handle1-4\", \"1Gi\", \"pvc-uid1-4\", \"claim1-4\", v1.VolumeBound, v1.PersistentVolumeReclaimDelete, classEmpty),\n\t\t\tinitialStorageClasses: []*storage.StorageClass{sameDriverStorageClass},\n\t\t\texpectedEvents:        []string{\"Warning SetDefaultSnapshotClassFailed\"},\n\t\t\terrors: []reactorError{\n\t\t\t\t{\"get\", \"storageclasses\", errors.New(\"mock update error\")},\n\t\t\t},\n\t\t\ttest: testUpdateSnapshotClass,\n\t\t},\n\t\t{\n\t\t\t// PVC does not exist\n\t\t\tname:                  \"1-5 - snapshot update with default class name failed because PVC was not found\",\n\t\t\tinitialContents:       nocontents,\n\t\t\tinitialSnapshots:      newSnapshotArray(\"snap1-5\", \"snapuid1-5\", \"claim1-5\", \"\", \"\", \"\", &True, nil, nil, nil, false, true, nil),\n\t\t\texpectedSnapshots:     newSnapshotArray(\"snap1-5\", \"snapuid1-5\", \"claim1-5\", \"\", \"\", \"\", &False, nil, nil, newVolumeError(\"Failed to set default snapshot class with error failed to retrieve PVC claim1-5 from the lister: \\\"persistentvolumeclaim \\\\\\\"claim1-5\\\\\\\" not found\\\"\"), false, true, nil),\n\t\t\tinitialClaims:         nil,\n\t\t\tinitialVolumes:        nil,\n\t\t\tinitialStorageClasses: []*storage.StorageClass{},\n\t\t\texpectedEvents:        []string{\"Warning SetDefaultSnapshotClassFailed\"},\n\t\t\terrors:                noerrors,\n\t\t\ttest:                  testUpdateSnapshotClass,\n\t\t},\n\t}\n\n\trunUpdateSnapshotClassTests(t, tests, snapshotClasses)\n}", "is_vulnerable": 0}
{"code": "func TestGetRuntimeConfigurations_TerminatingGateway(t *testing.T) {\n\tsnap := proxycfg.TestConfigSnapshotTerminatingGatewayWithLambdaServiceAndServiceResolvers(t)\n\n\twebService := api.CompoundServiceName{\n\t\tName:      \"web\",\n\t\tNamespace: \"default\",\n\t\tPartition: \"default\",\n\t}\n\tdbService := api.CompoundServiceName{\n\t\tName:      \"db\",\n\t\tNamespace: \"default\",\n\t\tPartition: \"default\",\n\t}\n\tcacheService := api.CompoundServiceName{\n\t\tName:      \"cache\",\n\t\tNamespace: \"default\",\n\t\tPartition: \"default\",\n\t}\n\tapiService := api.CompoundServiceName{\n\t\tName:      \"api\",\n\t\tNamespace: \"default\",\n\t\tPartition: \"default\",\n\t}\n\n\texpected := map[api.CompoundServiceName][]extensioncommon.RuntimeConfig{\n\t\tapiService:   {},\n\t\tcacheService: {},\n\t\tdbService:    {},\n\t\twebService: {\n\t\t\t{\n\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\tName: api.BuiltinAWSLambdaExtension,\n\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\"ARN\":                \"arn:aws:lambda:us-east-1:111111111111:function:lambda-1234\",\n\t\t\t\t\t\t\"PayloadPassthrough\": true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tServiceName: webService,\n\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\tapiService: {\n\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\"api.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tEnvoyID:           \"api\",\n\t\t\t\t\t\tOutgoingProxyKind: \"terminating-gateway\",\n\t\t\t\t\t},\n\t\t\t\t\tcacheService: {\n\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\"cache.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tEnvoyID:           \"cache\",\n\t\t\t\t\t\tOutgoingProxyKind: \"terminating-gateway\",\n\t\t\t\t\t},\n\t\t\t\t\tdbService: {\n\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tEnvoyID:           \"db\",\n\t\t\t\t\t\tOutgoingProxyKind: \"terminating-gateway\",\n\t\t\t\t\t},\n\t\t\t\t\twebService: {\n\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\"canary1.web.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\"canary2.web.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\"web.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\":         {},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tEnvoyID:           \"web\",\n\t\t\t\t\t\tOutgoingProxyKind: \"terminating-gateway\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tKind: api.ServiceKindTerminatingGateway,\n\t\t\t},\n\t\t},\n\t}\n\n\trequire.Equal(t, expected, GetRuntimeConfigurations(snap))\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tfield, msg, ok := validateWebhook(test.actor, l, test.webhook)\n\t\t\tassert.Equal(t, test.expOK, ok)\n\t\t\tassert.Equal(t, test.expMsg, msg)\n\t\t\tassert.Equal(t, test.expField, field)\n\t\t})", "is_vulnerable": 1}
{"code": "func initSettings(settingsService portainer.SettingsService, flags *portainer.CLIFlags) error {\n\t_, err := settingsService.Settings()\n\tif err == portainer.ErrObjectNotFound {\n\t\tsettings := &portainer.Settings{\n\t\t\tLogoURL:              *flags.Logo,\n\t\t\tAuthenticationMethod: portainer.AuthenticationInternal,\n\t\t\tLDAPSettings: portainer.LDAPSettings{\n\t\t\t\tAnonymousMode:   true,\n\t\t\t\tAutoCreateUsers: true,\n\t\t\t\tTLSConfig:       portainer.TLSConfiguration{},\n\t\t\t\tSearchSettings: []portainer.LDAPSearchSettings{\n\t\t\t\t\tportainer.LDAPSearchSettings{},\n\t\t\t\t},\n\t\t\t\tGroupSearchSettings: []portainer.LDAPGroupSearchSettings{\n\t\t\t\t\tportainer.LDAPGroupSearchSettings{},\n\t\t\t\t},\n\t\t\t},\n\t\t\tOAuthSettings:                       portainer.OAuthSettings{},\n\t\t\tAllowBindMountsForRegularUsers:      true,\n\t\t\tAllowPrivilegedModeForRegularUsers:  true,\n\t\t\tAllowVolumeBrowserForRegularUsers:   false,\n\t\t\tAllowDeviceMappingForRegularUsers:   true,\n\t\t\tAllowStackManagementForRegularUsers: true,\n\t\t\tEnableHostManagementFeatures:        false,\n\t\t\tAllowHostNamespaceForRegularUsers:   true,\n\t\t\tSnapshotInterval:                    *flags.SnapshotInterval,\n\t\t\tEdgeAgentCheckinInterval:            portainer.DefaultEdgeAgentCheckinIntervalInSeconds,\n\t\t}\n\n\t\tif *flags.Templates != \"\" {\n\t\t\tsettings.TemplatesURL = *flags.Templates\n\t\t}\n\n\t\tif *flags.Labels != nil {\n\t\t\tsettings.BlackListedLabels = *flags.Labels\n\t\t} else {\n\t\t\tsettings.BlackListedLabels = make([]portainer.Pair, 0)\n\t\t}\n\n\t\treturn settingsService.UpdateSettings(settings)\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tclustercache.SetPopulateResourceInfoHandler(func(un *unstructured.Unstructured, isRoot bool) (interface{}, bool) {\n\t\t\tres := &ResourceInfo{}\n\t\t\tpopulateNodeInfo(un, res, resourceCustomLabels)\n\t\t\tc.lock.RLock()\n\t\t\tcacheSettings := c.cacheSettings\n\t\t\tc.lock.RUnlock()\n\n\t\t\tres.Health, _ = health.GetResourceHealth(un, cacheSettings.clusterSettings.ResourceHealthOverride)\n\n\t\t\tappName := c.resourceTracking.GetAppName(un, cacheSettings.appInstanceLabelKey, cacheSettings.trackingMethod)\n\t\t\tif isRoot && appName != \"\" {\n\t\t\t\tres.AppName = appName\n\t\t\t}\n\n\t\t\tgvk := un.GroupVersionKind()\n\n\t\t\tif cacheSettings.ignoreResourceUpdatesEnabled && shouldHashManifest(appName, gvk) {\n\t\t\t\thash, err := generateManifestHash(un, nil, cacheSettings.resourceOverrides, c.ignoreNormalizerOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorf(\"Failed to generate manifest hash: %v\", err)\n\t\t\t\t} else {\n\t\t\t\t\tres.manifestHash = hash\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// edge case. we do not label CRDs, so they miss the tracking label we inject. But we still\n\t\t\t// want the full resource to be available in our cache (to diff), so we store all CRDs\n\t\t\treturn res, res.AppName != \"\" || gvk.Kind == kube.CustomResourceDefinitionKind\n\t\t}),", "is_vulnerable": 0}
{"code": "func newApiServerServiceAccount(namespace string) *corev1.ServiceAccount {\n\treturn &corev1.ServiceAccount{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: \"v1\",\n\t\t\tKind:       \"ServiceAccount\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tNamespace: namespace,\n\t\t\tName:      ApiServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func (t *Teler) checkCustomRules(r *http.Request) error {\n\t// Converts map of headers to RAW string\n\theaders := headersToRawString(r.Header)\n\n\t// Decode the URL-encoded and unescape HTML entities request URI of the URL\n\turi := stringDeUnescape(r.URL.RequestURI())\n\n\t// Declare byte slice for request body.\n\tvar body string\n\n\t// Initialize buffer to hold request body.\n\tbuf := &bytes.Buffer{}\n\n\t// Use io.Copy to copy the request body to the buffer.\n\t_, err := io.Copy(buf, r.Body)\n\tif err == nil {\n\t\t// If the read not fails, replace the request body\n\t\t// with a new io.ReadCloser that reads from the buffer.\n\t\tr.Body = io.NopCloser(buf)\n\n\t\t// Convert the buffer to a string.\n\t\tbody = buf.String()\n\t}\n\n\t// Decode the URL-encoded and unescape HTML entities of body\n\tbody = stringDeUnescape(body)\n\n\t// Check if the request is in cache\n\tkey := headers + uri + body\n\tif err, ok := t.getCache(key); ok {\n\t\treturn err\n\t}\n\n\t// Iterate over the Customs field of the Teler struct, which is a slice of custom rules\n\tfor _, rule := range t.opt.Customs {\n\t\t// Initialize the found match counter to zero\n\t\tf := 0\n\n\t\t// Iterate over the Rules field of the current custom rule, which is a slice of rule conditions\n\t\tfor _, cond := range rule.Rules {\n\t\t\tok := false\n\n\t\t\t// Check if the Method field of the current rule condition matches the request method\n\t\t\t// If the Method field is ALL, match any request method\n\t\t\tswitch {\n\t\t\tcase cond.Method == request.ALL:\n\t\t\tcase string(cond.Method) == r.Method:\n\t\t\t\tok = true\n\t\t\t}\n\n\t\t\t// If the request method doesn't match, skip the current rule condition\n\t\t\tif !ok {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tok = false\n\n\t\t\t// Get the compiled regex pattern for the current rule condition\n\t\t\tpattern := cond.patternRegex\n\n\t\t\t// Check if the Element field of the current rule condition matches the request URI, headers, body, or any of them\n\t\t\t// If it matches, set ok to true\n\t\t\tswitch cond.Element {\n\t\t\tcase request.URI:\n\t\t\t\tok = pattern.MatchString(uri)\n\t\t\tcase request.Headers:\n\t\t\t\tok = pattern.MatchString(headers)\n\t\t\tcase request.Body:\n\t\t\t\tok = pattern.MatchString(body)\n\t\t\tcase request.Any:\n\t\t\t\tok = (pattern.MatchString(uri) || pattern.MatchString(headers) || pattern.MatchString(body))\n\t\t\t}\n\n\t\t\t// If the rule condition is satisfied, increment the found match counter\n\t\t\tif ok {\n\t\t\t\t// If the rule condition \"or\", cache the request and return an error with\n\t\t\t\t// the Name field of the custom rule as the message.\n\t\t\t\t// If the rule condition is \"and\", increment the found match counter\n\t\t\t\tswitch rule.Condition {\n\t\t\t\tcase \"or\":\n\t\t\t\t\tt.setCache(key, rule.Name)\n\t\t\t\t\treturn errors.New(rule.Name)\n\t\t\t\tcase \"and\":\n\t\t\t\t\tf++\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// If the rule condition is \"and\", and number of found matches is equal to the number of rule conditions,\n\t\t// cache the request and return an error with the Name field of the custom rule as the message\n\t\tif rule.Condition == \"and\" && f >= len(rule.Rules) {\n\t\t\tt.setCache(key, rule.Name)\n\t\t\treturn errors.New(rule.Name)\n\t\t}\n\t}\n\n\t// Cache the request\n\tt.setCache(key, \"\")\n\n\t// If no custom rules were violated, return nil\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func Send(r *http.Request, decorators ...SendDecorator) (*http.Response, error) {\n\treturn SendWithSender(&http.Client{}, r, decorators...)\n}", "is_vulnerable": 1}
{"code": "func equalFold(a, b string) bool {\n\tif len(a) != len(b) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(a); i++ {\n\t\tif toUpper(a[i]) != toUpper(b[i]) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (m *Message) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowEnumdeclall\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Message: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Message: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field EnumeratedField\", wireType)\n\t\t\t}\n\t\t\tm.EnumeratedField = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowEnumdeclall\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.EnumeratedField |= MyEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field OtherenumeratedField\", wireType)\n\t\t\t}\n\t\t\tm.OtherenumeratedField = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowEnumdeclall\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.OtherenumeratedField |= MyOtherEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipEnumdeclall(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthEnumdeclall\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthEnumdeclall\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func safePrefix(req *http.Request) string {\n\tprefix := req.Header.Get(\"X-Forwarded-Prefix\")\n\tif prefix == \"\" {\n\t\treturn \"\"\n\t}\n\n\tparse, err := url.Parse(prefix)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\n\tif parse.Host != \"\" {\n\t\treturn \"\"\n\t}\n\n\treturn parse.Path\n}", "is_vulnerable": 0}
{"code": "\tprocessHtlcResolution := func(e invoices.HtlcResolution) (\n\t\tContractResolver, error) {\n\n\t\t// Take action based on the type of resolution we have\n\t\t// received.\n\t\tswitch resolution := e.(type) {\n\n\t\t// If the htlc resolution was a settle, apply the\n\t\t// preimage and return a success resolver.\n\t\tcase *invoices.HtlcSettleResolution:\n\t\t\terr := applyPreimage(resolution.Preimage)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\treturn &h.htlcSuccessResolver, nil\n\n\t\t// If the htlc was failed, mark the htlc as\n\t\t// resolved.\n\t\tcase *invoices.HtlcFailResolution:\n\t\t\tlog.Infof(\"%T(%v): Exit hop HTLC canceled \"+\n\t\t\t\t\"(expiry=%v, height=%v), abandoning\", h,\n\t\t\t\th.htlcResolution.ClaimOutpoint,\n\t\t\t\th.htlcExpiry, currentHeight)\n\n\t\t\th.resolved = true\n\n\t\t\t// Checkpoint our resolver with an abandoned outcome\n\t\t\t// because we take no further action on this htlc.\n\t\t\treport := h.report().resolverReport(\n\t\t\t\tnil, channeldb.ResolverTypeIncomingHtlc,\n\t\t\t\tchanneldb.ResolverOutcomeAbandoned,\n\t\t\t)\n\t\t\treturn nil, h.Checkpoint(h, report)\n\n\t\t// Error if the resolution type is unknown, we are only\n\t\t// expecting settles and fails.\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unknown resolution\"+\n\t\t\t\t\" type: %v\", e)\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func TestPasswordDuplicates(t *testing.T) {\n\tseen := map[string]bool{}\n\tfor i := 0; i < 100; i++ {\n\t\ts, err := Password(64)\n\t\trequire.NoError(t, err)\n\t\tassert.False(t, seen[s])\n\t\tseen[s] = true\n\t}\n}", "is_vulnerable": 0}
{"code": "func mockExecCommandInContainerForUsedStorageBytes() (stdout string, stderr string, err error) {\n\tr := `JuiceFS:test 207300683100160  41460043776 207259223056384   1% /juicefs/juicefs/test/juicefs-fuse`\n\treturn r, \"\", nil\n}", "is_vulnerable": 0}
{"code": "func create(cmd *cobra.Command, args []string) error {\n\tvar (\n\t\terr     error\n\t\tpodIDFD *os.File\n\t)\n\tcreateOptions.Labels, err = parse.GetAllLabels(labelFile, labels)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"unable to process labels\")\n\t}\n\n\tif !createOptions.Infra {\n\t\tlogrus.Debugf(\"Not creating an infra container\")\n\t\tif cmd.Flag(\"infra-conmon-pidfile\").Changed {\n\t\t\treturn errors.New(\"cannot set infra-conmon-pid without an infra container\")\n\t\t}\n\t\tif cmd.Flag(\"infra-command\").Changed {\n\t\t\treturn errors.New(\"cannot set infra-command without an infra container\")\n\t\t}\n\t\tif cmd.Flag(\"infra-image\").Changed {\n\t\t\treturn errors.New(\"cannot set infra-image without an infra container\")\n\t\t}\n\t\tcreateOptions.InfraImage = \"\"\n\n\t\tif cmd.Flag(\"share\").Changed && share != \"none\" && share != \"\" {\n\t\t\treturn fmt.Errorf(\"cannot set share(%s) namespaces without an infra container\", cmd.Flag(\"share\").Value)\n\t\t}\n\t\tcreateOptions.Share = nil\n\t} else {\n\t\tcreateOptions.Share = strings.Split(share, \",\")\n\t\tif cmd.Flag(\"infra-command\").Changed {\n\t\t\t// Only send content to server side if user changed defaults\n\t\t\tcreateOptions.InfraCommand, err = cmd.Flags().GetString(\"infra-command\")\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif cmd.Flag(\"infra-image\").Changed {\n\t\t\t// Only send content to server side if user changed defaults\n\t\t\tcreateOptions.InfraImage, err = cmd.Flags().GetString(\"infra-image\")\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif cmd.Flag(\"pod-id-file\").Changed {\n\t\tpodIDFD, err = util.OpenExclusiveFile(podIDFile)\n\t\tif err != nil && os.IsExist(err) {\n\t\t\treturn errors.Errorf(\"pod id file exists. Ensure another pod is not using it or delete %s\", podIDFile)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn errors.Errorf(\"error opening pod-id-file %s\", podIDFile)\n\t\t}\n\t\tdefer errorhandling.CloseQuiet(podIDFD)\n\t\tdefer errorhandling.SyncQuiet(podIDFD)\n\t}\n\n\tcreateOptions.Net, err = common.NetFlagsToNetOptions(cmd, createOptions.Infra)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(createOptions.Net.PublishPorts) > 0 {\n\t\tif !createOptions.Infra {\n\t\t\treturn errors.Errorf(\"you must have an infra container to publish port bindings to the host\")\n\t\t}\n\t}\n\n\tcreateOptions.CreateCommand = os.Args\n\n\tif replace {\n\t\tif err := replacePod(createOptions.Name); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tresponse, err := registry.ContainerEngine().PodCreate(context.Background(), createOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(podIDFile) > 0 {\n\t\tif err = ioutil.WriteFile(podIDFile, []byte(response.Id), 0644); err != nil {\n\t\t\treturn errors.Wrapf(err, \"failed to write pod ID to file\")\n\t\t}\n\t}\n\tfmt.Println(response.Id)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "var _ = Describe(\"ExecCommandError\", func() {\n\tpullSecret := \"TEST-TOKEN\"\n\tconfig.GlobalConfig.PullSecretToken = pullSecret\n\n\tIt(\"Creates the correct error for mkdir\", func() {\n\t\terr := &ExecCommandError{\n\t\t\tCommand: \"mkdir\",\n\t\t\tArgs:    []string{\"-p\", \"/somedir\"},\n\t\t\tEnv:     []string{\"HOME=/home/userZ\"},\n\t\t\tExitErr: fmt.Errorf(\"Permission denied\"),\n\t\t\tOutput:  \"mkdir: cannot create directory \u2018/somedir\u2019: Permission denied\",\n\t\t}\n\t\twantError := \"failed executing mkdir [-p /somedir], Error Permission denied, LastOutput \\\"mkdir: cannot create directory \u2018/somedir\u2019: Permission denied\\\"\"\n\t\twantDetailedError := \"failed executing mkdir [-p /somedir], env vars [HOME=/home/userZ], error Permission denied, waitStatus 0, Output \\\"mkdir: cannot create directory \u2018/somedir\u2019: Permission denied\\\"\"\n\n\t\tExpect(err.Error()).To(Equal(wantError))\n\t\tExpect(err.DetailedError()).To(Equal(wantDetailedError))\n\t})\n\n\tIt(\"Creates the correct error for ignition extract\", func() {\n\t\terr := &ExecCommandError{\n\t\t\tCommand:    \"nsenter\",\n\t\t\tArgs:       []string{\"-t\", \"1\", \"-m\", \"-i\", \"--\", \"podman\", \"run\", \"--net\", \"host\", \"--volume\", \"/:/rootfs:rw\", \"--volume\", \"/usr/bin/rpm-ostree:/usr/bin/rpm-ostree\", \"--privileged\", \"--entrypoint\", \"/usr/bin/machine-config-daemon\", \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:dc1a34f55c712b2b9c5e5a14dd85e67cbdae11fd147046ac2fef9eaf179ab221\", \"start\", \"--node-name\", \"localhost\", \"--root-mount\", \"/rootfs\", \"--once-from\", \"/opt/install-dir/bootstrap.ign\", \"--skip-reboot\", \"--pull-secret\", pullSecret},\n\t\t\tEnv:        []string{\"HOME=/home/userZ\", fmt.Sprintf(\"PULL_SECRET_TOKEN=%s\", pullSecret)},\n\t\t\tExitErr:    fmt.Errorf(\"exit status 255\"),\n\t\t\tWaitStatus: 255,\n\t\t\tOutput:     \"Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:dc1a34f55c712b2b9c5e5a14dd85e67cbdae11fd147046ac2fef9eaf179ab221...\\nGetting image source signatures\\nCopying blob sha256:74cbb6607642df5f9f70e8588e3c56d6de795d1a9af22866ea4cc82f2dad4f14\\nCopying blob sha256:c9fa7d57b9028d4bd02b51cef3c3039fa7b23a8b2d9d26a6ce66b3428f6e2457\\nCopying blob sha256:c676df4ac84e718ecee4f8129e43e9c2b7492942606cc65f1fc5e6f3da413160\\nCopying blob sha256:b147db91a07555d29ed6085e4733f34dbaa673076488caa8f95f4677f55b3a5c\\nCopying blob sha256:ad956945835b7630565fc23fcbd8194eef32b4300c28546d574b2a377fe5d0a5\\nCopying config sha256:c4356549f53a30a1baefc5d1515ec1ab8b3786a4bf1738c0abaedc0e44829498\\nWriting manifest to image destination\\nStoring signatures\\nI1019 19:03:28.797092 1 start.go:108] Version: v4.6.0-202008262209.p0-dirty (16d243c4bed178f5d4fd400c0518ebf1dbaface8)\\nI1019 19:03:28.797227 1 start.go:118] Calling chroot(\\\"/rootfs\\\")\\nI1019 19:03:28.797307 1 rpm-ostree.go:261] Running captured: rpm-ostree status --json\\nerror: Timeout was reached\\nF1019 19:04:35.869592 1 start.go:147] Failed to initialize single run daemon: error reading osImageURL from rpm-ostree: error running rpm-ostree status --json: : exit status 1)\",\n\t\t}\n\t\twantError := `failed executing nsenter [-t 1 -m -i -- podman run --net host --volume /:/rootfs:rw --volume /usr/bin/rpm-ostree:/usr/bin/rpm-ostree --privileged --entrypoint /usr/bin/machine-config-daemon quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:dc1a34f55c712b2b9c5e5a14dd85e67cbdae11fd147046ac2fef9eaf179ab221 start --node-name localhost --root-mount /rootfs --once-from /opt/install-dir/bootstrap.ign --skip-reboot --pull-secret <SECRET>], Error exit status 255, LastOutput \"... or: Timeout was reached\nF1019 19:04:35.869592 1 start.go:147] Failed to initialize single run daemon: error reading osImageURL from rpm-ostree: error running rpm-ostree status --json: : exit status 1)\"`\n\t\twantDetailedError := `failed executing nsenter [-t 1 -m -i -- podman run --net host --volume /:/rootfs:rw --volume /usr/bin/rpm-ostree:/usr/bin/rpm-ostree --privileged --entrypoint /usr/bin/machine-config-daemon quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:dc1a34f55c712b2b9c5e5a14dd85e67cbdae11fd147046ac2fef9eaf179ab221 start --node-name localhost --root-mount /rootfs --once-from /opt/install-dir/bootstrap.ign --skip-reboot --pull-secret <SECRET>], env vars [HOME=/home/userZ PULL_SECRET_TOKEN=<SECRET>], error exit status 255, waitStatus 255, Output \"Trying to pull quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:dc1a34f55c712b2b9c5e5a14dd85e67cbdae11fd147046ac2fef9eaf179ab221...\nGetting image source signatures\nCopying blob sha256:74cbb6607642df5f9f70e8588e3c56d6de795d1a9af22866ea4cc82f2dad4f14\nCopying blob sha256:c9fa7d57b9028d4bd02b51cef3c3039fa7b23a8b2d9d26a6ce66b3428f6e2457\nCopying blob sha256:c676df4ac84e718ecee4f8129e43e9c2b7492942606cc65f1fc5e6f3da413160\nCopying blob sha256:b147db91a07555d29ed6085e4733f34dbaa673076488caa8f95f4677f55b3a5c\nCopying blob sha256:ad956945835b7630565fc23fcbd8194eef32b4300c28546d574b2a377fe5d0a5\nCopying config sha256:c4356549f53a30a1baefc5d1515ec1ab8b3786a4bf1738c0abaedc0e44829498\nWriting manifest to image destination\nStoring signatures\nI1019 19:03:28.797092 1 start.go:108] Version: v4.6.0-202008262209.p0-dirty (16d243c4bed178f5d4fd400c0518ebf1dbaface8)\nI1019 19:03:28.797227 1 start.go:118] Calling chroot(\"/rootfs\")\nI1019 19:03:28.797307 1 rpm-ostree.go:261] Running captured: rpm-ostree status --json\nerror: Timeout was reached\nF1019 19:04:35.869592 1 start.go:147] Failed to initialize single run daemon: error reading osImageURL from rpm-ostree: error running rpm-ostree status --json: : exit status 1)\"`\n\n\t\tExpect(err.Error()).To(Equal(wantError))\n\t\tExpect(err.DetailedError()).To(Equal(wantDetailedError))\n\t})\n})", "is_vulnerable": 0}
{"code": "func SaveFullStateToK8s(ctx context.Context, k8sClient kubernetes.Interface, fullState *FullState) error {\n\tlog.Infof(ctx, \"[state] Saving full cluster state to Kubernetes\")\n\n\tif fullState == nil {\n\t\treturn ErrFullStateIsNil\n\t}\n\n\tsecrets := k8sClient.CoreV1().Secrets(metav1.NamespaceSystem)\n\tconfigMaps := k8sClient.CoreV1().ConfigMaps(metav1.NamespaceSystem)\n\tstateBytes, err := json.Marshal(fullState)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"[state] error marshalling full state to JSON: %w\", err)\n\t}\n\n\t// Back off for 1s between attempts.\n\tbackoff := wait.Backoff{\n\t\tDuration: time.Second,\n\t\tSteps:    int(UpdateStateTimeout.Seconds()),\n\t}\n\n\t// Try to create or update the secret and delete the old configmap in k8s, if it still exists.\n\tsaveState := func(ctx context.Context) (bool, error) {\n\t\t// Check if the secret already exists.\n\t\texistingSecret, err := secrets.Get(ctx, FullStateSecretName, metav1.GetOptions{})\n\t\tif err == nil {\n\t\t\t// The secret already exists, update it.\n\t\t\texistingSecretCopy := existingSecret.DeepCopy()\n\t\t\texistingSecretCopy.Data[FullStateSecretName] = stateBytes\n\t\t\tif _, err := secrets.Update(ctx, existingSecretCopy, metav1.UpdateOptions{}); err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"[state] error updating secret: %w\", err)\n\t\t\t}\n\t\t} else if apierrors.IsNotFound(err) {\n\t\t\t// The secret does not exist, create it.\n\t\t\t_, err := secrets.Create(ctx, &v1.Secret{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      FullStateSecretName,\n\t\t\t\t\tNamespace: metav1.NamespaceSystem,\n\t\t\t\t},\n\t\t\t\tData: map[string][]byte{\n\t\t\t\t\tFullStateSecretName: stateBytes,\n\t\t\t\t},\n\t\t\t}, metav1.CreateOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"[state] error creating secret: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\treturn false, fmt.Errorf(\"[state] error getting secret: %w\", err)\n\t\t}\n\n\t\t// Delete the old configmap.\n\t\terr = configMaps.Delete(ctx, FullStateConfigMapName, metav1.DeleteOptions{})\n\t\tif err != nil && !apierrors.IsNotFound(err) {\n\t\t\treturn false, fmt.Errorf(\"[state] error deleting configmap: %w\", err)\n\t\t}\n\n\t\treturn true, nil\n\t}\n\n\t// Retry until success or backoff.Steps has been reached ctx is cancelled.\n\tif err = wait.ExponentialBackoffWithContext(ctx, backoff, saveState); err != nil {\n\t\treturn fmt.Errorf(\"[state] error updating secret: %w\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\t\thandler := sshutils.NewChanHandlerFunc(func(_ context.Context, ccx *sshutils.ConnectionContext, nch ssh.NewChannel) {\n\t\t\t\tch, _, err := nch.Accept()\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NoError(t, ch.Close())\n\t\t\t})", "is_vulnerable": 0}
{"code": "func TakeOwnership(rw io.ReadWriter, newOwnerAuth Digest, newSRKAuth Digest, pubEK []byte) error {\n\n\t// Encrypt the owner and SRK auth with the endorsement key.\n\tek, err := UnmarshalPubRSAPublicKey(pubEK)\n\tif err != nil {\n\t\treturn err\n\t}\n\tencOwnerAuth, err := rsa.EncryptOAEP(sha1.New(), rand.Reader, ek, newOwnerAuth[:], oaepLabel)\n\tif err != nil {\n\t\treturn err\n\t}\n\tencSRKAuth, err := rsa.EncryptOAEP(sha1.New(), rand.Reader, ek, newSRKAuth[:], oaepLabel)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// The params for the SRK have very tight requirements:\n\t// - KeyLength must be 2048\n\t// - alg must be RSA\n\t// - Enc must be OAEP SHA1 MGF1\n\t// - Sig must be None\n\t// - Key usage must be Storage\n\t// - Key must not be migratable\n\tsrkRSAParams := rsaKeyParams{\n\t\tKeyLength: 2048,\n\t\tNumPrimes: 2,\n\t}\n\tsrkpb, err := tpmutil.Pack(srkRSAParams)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsrkParams := keyParams{\n\t\tAlgID:     AlgRSA,\n\t\tEncScheme: esRSAEsOAEPSHA1MGF1,\n\t\tSigScheme: ssNone,\n\t\tParams:    srkpb,\n\t}\n\tsrk := &key{\n\t\tVersion:         0x01010000,\n\t\tKeyUsage:        keyStorage,\n\t\tKeyFlags:        0,\n\t\tAuthDataUsage:   authAlways,\n\t\tAlgorithmParams: srkParams,\n\t}\n\n\t// Get command auth using OIAP with the new owner auth.\n\toiapr, err := oiap(rw)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer oiapr.Close(rw)\n\n\t// The digest for TakeOwnership is\n\t//\n\t// SHA1(ordTakeOwnership || pidOwner || encOwnerAuth || encSRKAuth || srk)\n\tauthIn := []interface{}{ordTakeOwnership, pidOwner, tpmutil.U32Bytes(encOwnerAuth), tpmutil.U32Bytes(encSRKAuth), srk}\n\tca, err := newCommandAuth(oiapr.AuthHandle, oiapr.NonceEven, nil, newOwnerAuth[:], authIn)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tk, ra, ret, err := takeOwnership(rw, encOwnerAuth, encSRKAuth, srk, ca)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\traIn := []interface{}{ret, ordTakeOwnership, k}\n\treturn ra.verify(ca.NonceOdd, newOwnerAuth[:], raIn)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tkp, _ := nkeys.FromSeed(oSeed)\n\t\t\takp, _ := nkeys.CreateAccount()\n\t\t\tapub, _ := akp.PublicKey()\n\t\t\tnac := jwt.NewAccountClaims(apub)\n\t\t\tajwt, err := nac.Encode(kp)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Error generating account JWT: %v\", err)\n\t\t\t}\n\n\t\t\thf := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\tw.Write([]byte(ajwt))\n\t\t\t})\n\t\t\tvar ts *httptest.Server\n\t\t\tif test.useTLS {\n\t\t\t\tts = httptest.NewTLSServer(hf)\n\t\t\t} else {\n\t\t\t\tts = httptest.NewServer(hf)\n\t\t\t}\n\t\t\tdefer ts.Close()\n\n\t\t\tconfTemplate := `\n\t\t\t\toperator: %s\n\t\t\t\tlisten: -1\n\t\t\t\tresolver: URL(\"%s/ngs/v1/accounts/jwt/\")\n\t\t\t\tresolver_tls {\n\t\t\t\t\tinsecure: true\n\t\t\t\t}\n\t\t\t`\n\t\t\tconf := createConfFile(t, []byte(fmt.Sprintf(confTemplate, ojwt, ts.URL)))\n\t\t\tdefer os.Remove(conf)\n\n\t\t\ts, opts := RunServerWithConfig(conf)\n\t\t\tpub, _ := kp.PublicKey()\n\t\t\topts.TrustedKeys = []string{pub}\n\t\t\tdefer s.Shutdown()\n\n\t\t\tacc, _ := s.LookupAccount(apub)\n\t\t\tif acc == nil {\n\t\t\t\tt.Fatalf(\"Expected to receive an account\")\n\t\t\t}\n\t\t\tif acc.Name != apub {\n\t\t\t\tt.Fatalf(\"Account name did not match claim key\")\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func (m *NinRepNativeUnsafe) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNativeUnsafe: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNativeUnsafe: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipPacked(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (k *Key) Protocol() Protocol {\n\treturn Protocol(k.k.protocol)\n}", "is_vulnerable": 1}
{"code": "func TestDuplicateTlogEntries(t *testing.T) {\n\tvirtualSigstore, err := ca.NewVirtualSigstore()\n\tassert.NoError(t, err)\n\n\tstatement := []byte(`{\"_type\":\"https://in-toto.io/Statement/v0.1\",\"predicateType\":\"customFoo\",\"subject\":[{\"name\":\"subject\",\"digest\":{\"sha256\":\"deadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeefdeadbeef\"}}],\"predicate\":{}}`)\n\tentity, err := virtualSigstore.Attest(\"foo@example.com\", \"issuer\", statement)\n\tassert.NoError(t, err)\n\n\t_, err = verify.VerifyArtifactTransparencyLog(&dupTlogEntity{entity}, virtualSigstore, 1, true, false)\n\tassert.ErrorContains(t, err, \"duplicate tlog entries found\") // duplicate tlog entries should fail to verify\n}", "is_vulnerable": 0}
{"code": "func TestDecodeSensor(t *testing.T) {\n\tb, err := ioutil.ReadFile(\"../../examples/sensors/multi-trigger-sensor.yaml\")\n\tassert.Nil(t, err)\n\t_, err = decodeAndUnstructure(b)\n\tassert.Nil(t, err)\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_ErrorPropagation(t *testing.T) {\n\ttype variant struct {\n\t\tconfig       Config\n\t\tshouldErr    bool\n\t\texcludeCheck bool\n\t}\n\tcafile := \"../test/ca/root.cer\"\n\tcapath := \"../test/ca_path\"\n\tcertfile := \"../test/key/ourdomain.cer\"\n\tkeyfile := \"../test/key/ourdomain.key\"\n\tvariants := []variant{\n\t\t{Config{}, false, false},                                              // 1\n\t\t{Config{TLSMinVersion: \"tls9\"}, true, false},                          // 1\n\t\t{Config{TLSMinVersion: \"\"}, false, false},                             // 2\n\t\t{Config{VerifyOutgoing: true, CAFile: \"\", CAPath: \"\"}, true, false},   // 6\n\t\t{Config{VerifyOutgoing: false, CAFile: \"\", CAPath: \"\"}, false, false}, // 7\n\t\t{Config{VerifyOutgoing: false, CAFile: cafile, CAPath: \"\"},\n\t\t\tfalse, false}, // 8\n\t\t{Config{VerifyOutgoing: false, CAFile: \"\", CAPath: capath},\n\t\t\tfalse, false}, // 9\n\t\t{Config{VerifyOutgoing: false, CAFile: cafile, CAPath: capath},\n\t\t\tfalse, false}, // 10\n\t\t{Config{VerifyOutgoing: true, CAFile: cafile, CAPath: \"\"},\n\t\t\tfalse, false}, // 11\n\t\t{Config{VerifyOutgoing: true, CAFile: \"\", CAPath: capath},\n\t\t\tfalse, false}, // 12\n\t\t{Config{VerifyOutgoing: true, CAFile: cafile, CAPath: capath},\n\t\t\tfalse, false}, // 13\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: \"\"}, true, false}, // 14\n\t\t{Config{VerifyIncomingRPC: true, CAFile: \"\", CAPath: \"\"},\n\t\t\ttrue, false}, // 15\n\t\t{Config{VerifyIncomingHTTPS: true, CAFile: \"\", CAPath: \"\"},\n\t\t\ttrue, false}, // 16\n\t\t{Config{VerifyIncoming: true, CAFile: cafile, CAPath: \"\"}, true, false}, // 17\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: capath}, true, false}, // 18\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: capath,\n\t\t\tCertFile: certfile, KeyFile: keyfile}, false, false}, // 19\n\t\t{Config{CertFile: \"bogus\", KeyFile: \"bogus\"}, true, true},                   // 20\n\t\t{Config{CAFile: \"bogus\"}, true, true},                                       // 21\n\t\t{Config{CAPath: \"bogus\"}, true, true},                                       // 22\n\t\t{Config{VerifyIncoming: true, CAFile: cafile, AutoTLS: true}, false, false}, // 22\n\t}\n\tfor _, v := range tlsVersions() {\n\t\tvariants = append(variants, variant{Config{TLSMinVersion: v}, false, false})\n\t}\n\n\tc := Configurator{autoTLS: &autoTLS{}, manual: &manual{}}\n\tfor i, v := range variants {\n\t\tinfo := fmt.Sprintf(\"case %d, config: %+v\", i, v.config)\n\t\t_, err1 := NewConfigurator(v.config, nil)\n\t\terr2 := c.Update(v.config)\n\n\t\tvar err3 error\n\t\tif !v.excludeCheck {\n\t\t\tcert, err := v.config.KeyPair()\n\t\t\trequire.NoError(t, err, info)\n\t\t\tpems, err := LoadCAs(v.config.CAFile, v.config.CAPath)\n\t\t\trequire.NoError(t, err, info)\n\t\t\tpool, err := pool(pems)\n\t\t\trequire.NoError(t, err, info)\n\t\t\terr3 = c.check(v.config, pool, cert)\n\t\t}\n\t\tif v.shouldErr {\n\t\t\trequire.Error(t, err1, info)\n\t\t\trequire.Error(t, err2, info)\n\t\t\tif !v.excludeCheck {\n\t\t\t\trequire.Error(t, err3, info)\n\t\t\t}\n\t\t} else {\n\t\t\trequire.NoError(t, err1, info)\n\t\t\trequire.NoError(t, err2, info)\n\t\t\tif !v.excludeCheck {\n\t\t\t\trequire.NoError(t, err3, info)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestMakePluginResourceRequest(t *testing.T) {\n\tpluginClient := &fakePluginClient{}\n\ths := HTTPServer{\n\t\tCfg:          setting.NewCfg(),\n\t\tlog:          log.New(),\n\t\tpluginClient: pluginClient,\n\t}\n\treq := httptest.NewRequest(http.MethodGet, \"/\", nil)\n\tresp := httptest.NewRecorder()\n\tpCtx := backend.PluginContext{}\n\terr := hs.makePluginResourceRequest(resp, req, pCtx)\n\trequire.NoError(t, err)\n\n\tfor {\n\t\tif resp.Flushed {\n\t\t\tbreak\n\t\t}\n\t}\n\n\trequire.Equal(t, \"sandbox\", resp.Header().Get(\"Content-Security-Policy\"))\n}", "is_vulnerable": 0}
{"code": "func TestPermissions(t *testing.T) {\n\tEnsureCleanState(t)\n\tappName := Name()\n\t_, err := RunCli(\"proj\", \"create\", \"test\")\n\tassert.NoError(t, err)\n\n\t// make sure app cannot be created without permissions in project\n\t_, err = RunCli(\"app\", \"create\", appName, \"--repo\", RepoURL(RepoURLTypeFile),\n\t\t\"--path\", guestbookPath, \"--project\", \"test\", \"--dest-server\", KubernetesInternalAPIServerAddr, \"--dest-namespace\", DeploymentNamespace())\n\tassert.Error(t, err)\n\tsourceError := fmt.Sprintf(\"application repo %s is not permitted in project 'test'\", RepoURL(RepoURLTypeFile))\n\tdestinationError := fmt.Sprintf(\"application destination {%s %s} is not permitted in project 'test'\", KubernetesInternalAPIServerAddr, DeploymentNamespace())\n\n\tassert.Contains(t, err.Error(), sourceError)\n\tassert.Contains(t, err.Error(), destinationError)\n\n\tproj, err := AppClientset.ArgoprojV1alpha1().AppProjects(ArgoCDNamespace).Get(context.Background(), \"test\", metav1.GetOptions{})\n\tassert.NoError(t, err)\n\n\tproj.Spec.Destinations = []ApplicationDestination{{Server: \"*\", Namespace: \"*\"}}\n\tproj.Spec.SourceRepos = []string{\"*\"}\n\tproj, err = AppClientset.ArgoprojV1alpha1().AppProjects(ArgoCDNamespace).Update(context.Background(), proj, metav1.UpdateOptions{})\n\tassert.NoError(t, err)\n\n\t// make sure controller report permissions issues in conditions\n\t_, err = RunCli(\"app\", \"create\", appName, \"--repo\", RepoURL(RepoURLTypeFile),\n\t\t\"--path\", guestbookPath, \"--project\", \"test\", \"--dest-server\", KubernetesInternalAPIServerAddr, \"--dest-namespace\", DeploymentNamespace())\n\tassert.NoError(t, err)\n\tdefer func() {\n\t\terr = AppClientset.ArgoprojV1alpha1().Applications(ArgoCDNamespace).Delete(context.Background(), appName, metav1.DeleteOptions{})\n\t\tassert.NoError(t, err)\n\t}()\n\n\tproj.Spec.Destinations = []ApplicationDestination{}\n\tproj.Spec.SourceRepos = []string{}\n\t_, err = AppClientset.ArgoprojV1alpha1().AppProjects(ArgoCDNamespace).Update(context.Background(), proj, metav1.UpdateOptions{})\n\tassert.NoError(t, err)\n\ttime.Sleep(1 * time.Second)\n\tcloser, client, err := ArgoCDClientset.NewApplicationClient()\n\tassert.NoError(t, err)\n\tdefer io.Close(closer)\n\n\trefresh := string(RefreshTypeNormal)\n\tapp, err := client.Get(context.Background(), &applicationpkg.ApplicationQuery{Name: &appName, Refresh: &refresh})\n\tassert.NoError(t, err)\n\n\tdestinationErrorExist := false\n\tsourceErrorExist := false\n\tfor i := range app.Status.Conditions {\n\t\tif strings.Contains(app.Status.Conditions[i].Message, destinationError) {\n\t\t\tdestinationErrorExist = true\n\t\t}\n\t\tif strings.Contains(app.Status.Conditions[i].Message, sourceError) {\n\t\t\tsourceErrorExist = true\n\t\t}\n\t}\n\tassert.True(t, destinationErrorExist)\n\tassert.True(t, sourceErrorExist)\n}", "is_vulnerable": 1}
{"code": "func (pk *PublicKey) EncapsulateTo(ct []byte, ss []byte, seed []byte) {\n\tif seed == nil {\n\t\tseed = make([]byte, EncapsulationSeedSize)\n\t\tif _, err := cryptoRand.Read(seed[:]); err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}\n\tif len(seed) != EncapsulationSeedSize {\n\t\tpanic(\"seed must be of length EncapsulationSeedSize\")\n\t}\n\tif len(ct) != CiphertextSize {\n\t\tpanic(\"ct must be of length CiphertextSize\")\n\t}\n\tif len(ss) != SharedKeySize {\n\t\tpanic(\"ss must be of length SharedKeySize\")\n\t}\n\n\tvar G2out [2 * SharedKeySize]byte\n\n\tvar SpEpEpp [(paramN * paramNbar) + (paramN * paramNbar) + (paramNbar * paramNbar)]uint16\n\tvar byteSpEpEpp [2 * len(SpEpEpp)]byte\n\tSp := SpEpEpp[:paramN*paramNbar]\n\tEp := SpEpEpp[paramN*paramNbar : 2*paramN*paramNbar]\n\tEpp := SpEpEpp[2*paramN*paramNbar:]\n\n\tvar Bp nbarByNU16\n\n\tvar V nbarByNbarU16\n\tvar C nbarByNbarU16\n\n\tvar A nByNU16\n\n\tvar hpk [pkHashSize]byte\n\n\tvar mu [messageSize]byte\n\tcopy(mu[:], seed[:messageSize])\n\n\t// compute hpk = G_1(packed(pk))\n\tshake128 := sha3.NewShake128()\n\tvar ppk [PublicKeySize]byte\n\tpk.Pack(ppk[:])\n\t_, _ = shake128.Write(ppk[:])\n\t_, _ = shake128.Read(hpk[:])\n\n\t// compute (seedSE || k) = G_2(hpk || mu)\n\tshake128.Reset()\n\t_, _ = shake128.Write(hpk[:])\n\t_, _ = shake128.Write(mu[:])\n\t_, _ = shake128.Read(G2out[:])\n\n\t// Generate Sp, Ep, Epp, and A, and compute:\n\t// Bp = Sp*A + Ep\n\t// V = Sp*B + Epp\n\tshake128.Reset()\n\t_, _ = shake128.Write([]byte{0x96})\n\t_, _ = shake128.Write(G2out[:SharedKeySize])\n\t_, _ = shake128.Read(byteSpEpEpp[:])\n\tfor i := range SpEpEpp {\n\t\tSpEpEpp[i] = uint16(byteSpEpEpp[i*2]) | (uint16(byteSpEpEpp[(i*2)+1]) << 8)\n\t}\n\tsample(SpEpEpp[:])\n\n\texpandSeedIntoA(&A, &pk.seedA, &shake128)\n\tmulAddSAPlusE(&Bp, Sp, &A, Ep)\n\n\tmulAddSBPlusE(&V, Sp, &pk.matrixB, Epp)\n\n\t// Encode mu, and compute C = V + enc(mu) (mod q)\n\tencodeMessage(&C, &mu)\n\tadd(&C, &V, &C)\n\n\t// Prepare the ciphertext\n\tpack(ct[:matrixBpPackedSize], Bp[:])\n\tpack(ct[matrixBpPackedSize:], C[:])\n\n\t// Compute ss = F(ct||k)\n\tshake128.Reset()\n\t_, _ = shake128.Write(ct[:])\n\t_, _ = shake128.Write(G2out[SharedKeySize:])\n\t_, _ = shake128.Read(ss[:])\n}", "is_vulnerable": 0}
{"code": "func (p Precompile) Transfer(\n\tctx sdk.Context,\n\torigin common.Address,\n\tcontract *vm.Contract,\n\tstateDB vm.StateDB,\n\tmethod *abi.Method,\n\targs []interface{},\n) ([]byte, error) {\n\tmsg, sender, err := NewMsgTransfer(method, args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// check if channel exists and is open\n\tif !p.channelKeeper.HasChannel(ctx, msg.SourcePort, msg.SourceChannel) {\n\t\treturn nil, errorsmod.Wrapf(channeltypes.ErrChannelNotFound, \"port ID (%s) channel ID (%s)\", msg.SourcePort, msg.SourceChannel)\n\t}\n\n\t// isCallerSender is true when the contract caller is the same as the sender\n\tisCallerSender := contract.CallerAddress == sender\n\n\t// If the contract caller is not the same as the sender, the sender must be the origin\n\tif !isCallerSender && origin != sender {\n\t\treturn nil, fmt.Errorf(ErrDifferentOriginFromSender, origin.String(), sender.String())\n\t}\n\n\t// no need to have authorization when the contract caller is the same as origin (owner of funds)\n\t// and the sender is the origin\n\tresp, expiration, err := CheckAndAcceptAuthorizationIfNeeded(ctx, contract, origin, p.AuthzKeeper, msg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tres, err := p.transferKeeper.Transfer(sdk.WrapSDKContext(ctx), msg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := UpdateGrantIfNeeded(ctx, contract, p.AuthzKeeper, origin, expiration, resp); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err = EmitIBCTransferEvent(\n\t\tctx,\n\t\tstateDB,\n\t\tp.ABI.Events[EventTypeIBCTransfer],\n\t\tp.Address(),\n\t\tsender,\n\t\tmsg.Receiver,\n\t\tmsg.SourcePort,\n\t\tmsg.SourceChannel,\n\t\tmsg.Token,\n\t\tmsg.Memo,\n\t); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// NOTE: This ensures that the changes in the bank keeper are correctly mirrored to the EVM stateDB.\n\t// This prevents the stateDB from overwriting the changed balance in the bank keeper when committing the EVM state.\n\tif isCallerSender && msg.Token.Denom == p.stakingKeeper.BondDenom(ctx) {\n\t\tstateDB.(*statedb.StateDB).SubBalance(contract.CallerAddress, msg.Token.Amount.BigInt())\n\t}\n\n\treturn method.Outputs.Pack(res.Sequence)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tmd := metadata.MD{}\n\t\t\tif len(tt.xfccHeader) > 0 {\n\t\t\t\tmd.Append(xfccparser.ForwardedClientCertHeader, tt.xfccHeader)\n\t\t\t}\n\t\t\tctx := peer.NewContext(context.Background(), &peer.Peer{Addr: &net.IPAddr{IP: net.ParseIP(\"127.0.0.1\").To4()}})\n\t\t\tctx = metadata.NewIncomingContext(ctx, md)\n\t\t\tresult, err := auth.Authenticate(security.AuthContext{GrpcContext: ctx})\n\t\t\tif len(tt.authenticateErrMsg) > 0 {\n\t\t\t\tif err == nil {\n\t\t\t\t\tt.Errorf(\"Succeeded. Error expected: %v\", err)\n\t\t\t\t} else if err.Error() != tt.authenticateErrMsg {\n\t\t\t\t\tt.Errorf(\"Incorrect error message: want %s but got %s\",\n\t\t\t\t\t\ttt.authenticateErrMsg, err.Error())\n\t\t\t\t}\n\t\t\t} else if err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected Error: %v\", err)\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(tt.caller, result) {\n\t\t\t\tt.Errorf(\"Unexpected authentication result: want %v but got %v\",\n\t\t\t\t\ttt.caller, result)\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (m *MyType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowAsym\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: MyType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: MyType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipAsym(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthAsym\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (i *File) Update() error {\n\tb, err := json.Marshal(i)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tpath := filepath.Dir(i.Path)\n\n\toldumask := syscall.Umask(0)\n\tdefer syscall.Umask(oldumask)\n\n\tif err := os.MkdirAll(path, 0755); err != nil {\n\t\treturn err\n\t}\n\tfile, err := os.OpenFile(i.Path, os.O_CREATE|os.O_TRUNC|os.O_WRONLY|syscall.O_NOFOLLOW, 0644)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\n\tif _, err := file.Write(b); err != nil {\n\t\treturn fmt.Errorf(\"failed to write instance file %s: %s\", i.Path, err)\n\t}\n\n\treturn file.Sync()\n}", "is_vulnerable": 1}
{"code": "func signEdgeCert(w http.ResponseWriter, r *http.Request) {\n\tr.Body = http.MaxBytesReader(w, r.Body, constants.MaxRespBodyLength)\n\tcsrContent, err := io.ReadAll(r.Body)\n\tif err != nil {\n\t\tklog.Errorf(\"fail to read file when signing the cert for edgenode:%s! error:%v\", r.Header.Get(constants.NodeName), err)\n\t\treturn\n\t}\n\tcsr, err := x509.ParseCertificateRequest(csrContent)\n\tif err != nil {\n\t\tklog.Errorf(\"fail to ParseCertificateRequest of edgenode: %s! error:%v\", r.Header.Get(constants.NodeName), err)\n\t\treturn\n\t}\n\tusagesStr := r.Header.Get(\"ExtKeyUsages\")\n\tvar usages []x509.ExtKeyUsage\n\tif usagesStr == \"\" {\n\t\tusages = []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}\n\t} else {\n\t\terr := json.Unmarshal([]byte(usagesStr), &usages)\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"unmarshal http header ExtKeyUsages fail, err: %v\", err)\n\t\t\treturn\n\t\t}\n\t}\n\tklog.V(4).Infof(\"receive sign crt request, ExtKeyUsages: %v\", usages)\n\tclientCertDER, err := signCerts(csr.Subject, csr.PublicKey, usages)\n\tif err != nil {\n\t\tklog.Errorf(\"fail to signCerts for edgenode:%s! error:%v\", r.Header.Get(constants.NodeName), err)\n\t\treturn\n\t}\n\n\tif _, err := w.Write(clientCertDER); err != nil {\n\t\tklog.Errorf(\"write error %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func isAdminOfTheModifiedTeams(currentUser *fleet.User, originalUserTeams, newUserTeams []fleet.UserTeam) bool {\n\t// Global admins can modify all user teams roles.\n\tif currentUser.GlobalRole != nil && *currentUser.GlobalRole == fleet.RoleAdmin {\n\t\treturn true\n\t}\n\n\t// Otherwise, make a map of the original and resulting teams.\n\tnewTeams := make(map[uint]string)\n\tfor _, team := range newUserTeams {\n\t\tnewTeams[team.ID] = team.Role\n\t}\n\toriginalTeams := make(map[uint]struct{})\n\tfor _, team := range originalUserTeams {\n\t\toriginalTeams[team.ID] = struct{}{}\n\t}\n\n\t// See which ones were removed or changed from the original.\n\tteamsAffected := make(map[uint]struct{})\n\tfor _, team := range originalUserTeams {\n\t\tif newTeams[team.ID] != team.Role {\n\t\t\tteamsAffected[team.ID] = struct{}{}\n\t\t}\n\t}\n\n\t// See which ones of the new are not in the original.\n\tfor _, team := range newUserTeams {\n\t\tif _, ok := originalTeams[team.ID]; !ok {\n\t\t\tteamsAffected[team.ID] = struct{}{}\n\t\t}\n\t}\n\n\t// Then gather the teams the current user is admin for.\n\tcurrentUserTeamAdmin := make(map[uint]struct{})\n\tfor _, team := range currentUser.Teams {\n\t\tif team.Role == fleet.RoleAdmin {\n\t\t\tcurrentUserTeamAdmin[team.ID] = struct{}{}\n\t\t}\n\t}\n\n\t// And finally, let's check that the teams that were either removed\n\t// or changed are also teams this user is an admin of.\n\tfor teamID := range teamsAffected {\n\t\tif _, ok := currentUserTeamAdmin[teamID]; !ok {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func V1(parent iris.Party) {\n\tv1 := parent.Party(\"/v1\")\n\tauthParty := v1.Party(\"/auth\")\n\tmvc.New(authParty.Party(\"/session\")).HandleError(ErrorHandler).Handle(controller.NewSessionController())\n\tmvc.New(v1.Party(\"/user\")).HandleError(ErrorHandler).Handle(controller.NewForgotPasswordController())\n\tAuthScope = v1.Party(\"/\")\n\tAuthScope.Use(middleware.JWTMiddleware().Serve)\n\tAuthScope.Use(middleware.UserMiddleware)\n\tAuthScope.Use(middleware.RBACMiddleware())\n\tAuthScope.Use(middleware.PagerMiddleware)\n\tAuthScope.Use(middleware.ForceMiddleware)\n\tmvc.New(AuthScope.Party(\"/clusters\")).HandleError(ErrorHandler).Handle(controller.NewClusterController())\n\tmvc.New(AuthScope.Party(\"/credentials\")).HandleError(ErrorHandler).Handle(controller.NewCredentialController())\n\tmvc.New(AuthScope.Party(\"/hosts\")).HandleError(ErrorHandler).Handle(controller.NewHostController())\n\tmvc.New(AuthScope.Party(\"/users\")).HandleError(ErrorHandler).Handle(controller.NewUserController())\n\tmvc.New(AuthScope.Party(\"/dashboard\")).HandleError(ErrorHandler).Handle(controller.NewKubePiController())\n\tmvc.New(AuthScope.Party(\"/regions\")).HandleError(ErrorHandler).Handle(controller.NewRegionController())\n\tmvc.New(AuthScope.Party(\"/zones\")).HandleError(ErrorHandler).Handle(controller.NewZoneController())\n\tmvc.New(AuthScope.Party(\"/plans\")).HandleError(ErrorHandler).Handle(controller.NewPlanController())\n\tmvc.New(AuthScope.Party(\"/settings\")).HandleError(ErrorHandler).Handle(controller.NewSystemSettingController())\n\tmvc.New(AuthScope.Party(\"/ntp\")).HandleError(ErrorHandler).Handle(controller.NewNtpServerController())\n\tmvc.New(AuthScope.Party(\"/logs\")).HandleError(ErrorHandler).Handle(controller.NewSystemLogController())\n\tmvc.New(AuthScope.Party(\"/projects\")).HandleError(ErrorHandler).Handle(controller.NewProjectController())\n\tmvc.New(AuthScope.Party(\"/clusters/provisioner\")).HandleError(ErrorHandler).Handle(controller.NewProvisionerController())\n\tmvc.New(AuthScope.Party(\"/kubernetes\")).HandleError(ErrorHandler).Handle(controller.NewKubernetesController())\n\tmvc.New(AuthScope.Party(\"/clusters/tool\")).HandleError(ErrorHandler).Handle(controller.NewClusterToolController())\n\tmvc.New(AuthScope.Party(\"/backupaccounts\")).HandleError(ErrorHandler).Handle(controller.NewBackupAccountController())\n\tmvc.New(AuthScope.Party(\"/clusters/backup\")).HandleError(ErrorHandler).Handle(controller.NewClusterBackupStrategyController())\n\tmvc.New(AuthScope.Party(\"/clusters/monitor\")).HandleError(ErrorHandler).Handle(controller.NewMonitorController())\n\tmvc.New(AuthScope.Party(\"/tasks\")).Handle(ErrorHandler).Handle(controller.NewTaskLogController())\n\tmvc.New(AuthScope.Party(\"/components\")).Handle(ErrorHandler).Handle(controller.NewComponentController())\n\tmvc.New(AuthScope.Party(\"/license\")).Handle(ErrorHandler).Handle(controller.NewLicenseController())\n\tmvc.New(AuthScope.Party(\"/clusters/backup/files\")).HandleError(ErrorHandler).Handle(controller.NewClusterBackupFileController())\n\tmvc.New(AuthScope.Party(\"/clusters/velero/{cluster}/{operate}\")).HandleError(ErrorHandler).Handle(controller.NewClusterVeleroBackupController())\n\tmvc.New(AuthScope.Party(\"/manifests\")).HandleError(ErrorHandler).Handle(controller.NewManifestController())\n\tmvc.New(AuthScope.Party(\"/vmconfigs\")).HandleError(ErrorHandler).Handle(controller.NewVmConfigController())\n\tmvc.New(AuthScope.Party(\"/ippools\")).HandleError(ErrorHandler).Handle(controller.NewIpPoolController())\n\tmvc.New(AuthScope.Party(\"/ippools/{name}/ips\")).HandleError(ErrorHandler).Handle(controller.NewIpController())\n\tmvc.New(AuthScope.Party(\"/projects/{project}/resources\")).HandleError(ErrorHandler).Handle(controller.NewProjectResourceController())\n\tmvc.New(AuthScope.Party(\"/projects/{project}/members\")).HandleError(ErrorHandler).Handle(controller.NewProjectMemberController())\n\tmvc.New(AuthScope.Party(\"/projects/{project}/clusters/{cluster}/members\")).HandleError(ErrorHandler).Handle(controller.NewClusterMemberController())\n\tmvc.New(AuthScope.Party(\"/projects/{project}/clusters/{cluster}/resources\")).HandleError(ErrorHandler).Handle(controller.NewClusterResourceController())\n\tmvc.New(AuthScope.Party(\"/templates\")).HandleError(ErrorHandler).Handle(controller.NewTemplateConfigController())\n\tmvc.New(AuthScope.Party(\"/clusters/grade\")).HandleError(ErrorHandler).Handle(controller.NewGradeController())\n\tmvc.New(AuthScope.Party(\"/ldap\")).HandleError(ErrorHandler).Handle(controller.NewLdapController())\n\tmvc.New(AuthScope.Party(\"/msg/accounts\")).HandleError(ErrorHandler).Handle(controller.NewMessageAccountController())\n\tmvc.New(AuthScope.Party(\"/msg/subscribes\")).HandleError(ErrorHandler).Handle(controller.NewMessageSubscribeController())\n\tmvc.New(AuthScope.Party(\"/user/messages\")).HandleError(ErrorHandler).Handle(controller.NewUserMsgController())\n\tmvc.New(AuthScope.Party(\"/user/settings\")).HandleError(ErrorHandler).Handle(controller.NewUserSettingController())\n\tAuthScope.Get(\"/clusters/kubeconfig/{name}\", downloadKubeconfig)\n\tWhiteScope = v1.Party(\"/\")\n\tWhiteScope.Get(\"/captcha\", generateCaptcha)\n\tmvc.New(WhiteScope.Party(\"/theme\")).HandleError(ErrorHandler).Handle(controller.NewThemeController())\n\n}", "is_vulnerable": 0}
{"code": "func (c *Configurator) IncomingHTTPSConfig() (*tls.Config, error) {\n\treturn c.commonTLSConfig(c.base.VerifyIncomingHTTPS)\n}", "is_vulnerable": 1}
{"code": "func (c *Compactor) write(path string, iter KeyIterator) error {\n\tif _, err := os.Stat(path); !os.IsNotExist(err) {\n\t\treturn fmt.Errorf(\"%v already file exists. aborting\", path)\n\t}\n\n\tfd, err := os.OpenFile(path, os.O_CREATE|os.O_RDWR, 0666)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Create the write for the new TSM file.\n\tw, err := NewTSMWriter(fd)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer w.Close()\n\n\tfor iter.Next() {\n\t\tselect {\n\t\tcase <-c.Cancel:\n\t\t\treturn fmt.Errorf(\"compaction aborted\")\n\t\tdefault:\n\t\t}\n\n\t\t// Each call to read returns the next sorted key (or the prior one if there are\n\t\t// more values to write).  The size of values will be less than or equal to our\n\t\t// chunk size (1000)\n\t\tkey, values, err := iter.Read()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Write the key and value\n\t\tif err := w.Write(key, values); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If we have a max file size configured and we're over it, close out the file\n\t\t// and return the error.\n\t\tif w.Size() > maxTSMFileSize {\n\t\t\tif err := w.WriteIndex(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn errMaxFileExceeded\n\t\t}\n\t}\n\n\t// We're all done.  Close out the file.\n\tif err := w.WriteIndex(); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestSortableRoute(t *testing.T) {\n\tarr := SortableRoute{\n\t\t{\n\t\t\tName: \"regex match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/.*\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex/.*/long\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"regex match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\n\t\t{\n\t\t\tName: \"regex match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_SafeRegex{\n\t\t\t\t\tSafeRegex: &envoy_type_matcher_v3.RegexMatcher{\n\t\t\t\t\t\tRegex: \"/regex\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\n\t\t{\n\t\t\tName: \"exact match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/longest\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{\n\t\t\t\t\tPath: \"/exact/match/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match short\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match long\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/prefix/match/long\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with one header\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with one header and one query\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tQueryParameters: []*envoy_config_route_v3.QueryParameterMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"query1\",\n\t\t\t\t\t\tQueryParameterMatchSpecifier: &envoy_config_route_v3.QueryParameterMatcher_PresentMatch{\n\t\t\t\t\t\t\tPresentMatch: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match with two headers\",\n\t\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_PathSeparatedPrefix{\n\t\t\t\t\tPathSeparatedPrefix: \"/header\",\n\t\t\t\t},\n\t\t\t\tHeaders: []*envoy_config_route_v3.HeaderMatcher{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header1\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value1\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"header2\",\n\t\t\t\t\t\tHeaderMatchSpecifier: &envoy_config_route_v3.HeaderMatcher_StringMatch{\n\t\t\t\t\t\t\tStringMatch: &envoy_type_matcher_v3.StringMatcher{\n\t\t\t\t\t\t\t\tMatchPattern: &envoy_type_matcher_v3.StringMatcher_Exact{\n\t\t\t\t\t\t\t\t\tExact: \"value2\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// This assertion is to it easier to tell how\n\t// the array is rearranged by the sorting.\n\t// It also effectively ensures that buildNameSlice is\n\t// working correctly.\n\tnamesBeforeSort := buildNameSlice(arr)\n\tassert.Equal(t, []string{\n\t\t\"regex match short\",\n\t\t\"regex match long\",\n\t\t\"regex match with one header\",\n\t\t\"regex match with one header and one query\",\n\t\t\"regex match with two headers\",\n\t\t\"exact match short\",\n\t\t\"exact match long\",\n\t\t\"exact match with one header\",\n\t\t\"exact match with one header and one query\",\n\t\t\"exact match with two headers\",\n\t\t\"prefix match short\",\n\t\t\"prefix match long\",\n\t\t\"prefix match with one header\",\n\t\t\"prefix match with one header and one query\",\n\t\t\"prefix match with two headers\",\n\t}, namesBeforeSort)\n\n\tsort.Sort(arr)\n\n\tnamesAfterSort := buildNameSlice(arr)\n\tassert.Equal(t, []string{\n\t\t\"exact match long\",\n\t\t\"exact match with two headers\",\n\t\t\"exact match with one header and one query\",\n\t\t\"exact match with one header\",\n\t\t\"exact match short\",\n\t\t\"regex match long\",\n\t\t\"regex match with two headers\",\n\t\t\"regex match with one header and one query\",\n\t\t\"regex match with one header\",\n\t\t\"regex match short\",\n\t\t\"prefix match long\",\n\t\t\"prefix match short\",\n\t\t\"prefix match with two headers\",\n\t\t\"prefix match with one header and one query\",\n\t\t\"prefix match with one header\",\n\t}, namesAfterSort)\n\n}", "is_vulnerable": 1}
{"code": "func EncryptCCA(rand io.Reader, public *PublicParams, policy *Policy, msg []byte) ([]byte, error) {\n\tseed := make([]byte, macKeySeedSize)\n\t_, err := rand.Read(seed)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tid, macKey, err := expandSeed(seed)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnumid := &pairing.Scalar{}\n\tnumid.SetBytes(id)\n\n\tencPolicy := policy.transformBK(numid)\n\n\theader, encPoint, err := encapsulate(rand, public, encPolicy)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Send the policy that was not enhanced. The receiver will recover with the ID.\n\t// This avoids a bug where we omit the check that the ID is correct\n\theader.p = policy\n\tC1, err := header.marshalBinary()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tenv := make([]byte, len(seed)+len(msg))\n\tcopy(env[0:len(seed)], seed)\n\tcopy(env[len(seed):], msg)\n\n\tencKey, err := encPoint.MarshalBinary()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thashedEncKey := blake2b.Sum256(encKey)\n\n\tenv, err = blakeEncrypt(hashedEncKey[:], env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmacData := appendLenPrefixed(nil, C1)\n\tmacData = appendLenPrefixed(macData, env)\n\n\ttag, err := blakeMac(macKey, macData)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tret := appendLenPrefixed(nil, id)\n\tret = appendLenPrefixed(ret, macData)\n\tret = appendLenPrefixed(ret, tag)\n\n\treturn ret, nil\n}", "is_vulnerable": 1}
{"code": "func (s *DiscoveryServer) generateRawRoutes(con *XdsConnection, push *model.PushContext) []*xdsapi.RouteConfiguration {\n\trawRoutes := s.ConfigGenerator.BuildHTTPRoutes(s.Env, con.modelNode, push, con.Routes)\n\t// Now validate each route\n\tfor _, r := range rawRoutes {\n\t\tif err := r.Validate(); err != nil {\n\t\t\tretErr := fmt.Errorf(\"RDS: Generated invalid route %s for node %v: %v\", r.Name, con.modelNode, err)\n\t\t\tadsLog.Errorf(\"RDS: Generated invalid routes for route:%s for node:%v: %v, %v\", r.Name, con.modelNode.ID, err, r)\n\t\t\trdsBuildErrPushes.Increment()\n\t\t\t// Generating invalid routes is a bug.\n\t\t\t// Panic instead of trying to recover from that, since we can't\n\t\t\t// assume anything about the state.\n\t\t\tpanic(retErr.Error())\n\t\t}\n\t}\n\treturn rawRoutes\n}", "is_vulnerable": 1}
{"code": "func TestPathRoleSet_RotateTokenRoleSet(t *testing.T) {\n\trsName := \"test-rotatetokenrs\"\n\troles := util.StringSet{\n\t\t\"roles/viewer\": struct{}{},\n\t}\n\n\t// Initial test set up - backend, initial config, test resources in project\n\ttd := setupTest(t)\n\tdefer cleanup(t, td, rsName, roles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create role set\n\texpectedBinds := ResourceBindings{projRes: roles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":      td.Project,\n\t\t\t\"secret_type\":  SecretTypeAccessToken,\n\t\t\t\"bindings\":     bindsRaw,\n\t\t\t\"token_scopes\": []string{\"https://www.googleapis.com/auth/cloud-platform\"},\n\t\t})\n\n\t// Verify initial role set.\n\trespData := testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\tinitSa := getServiceAccount(t, td.IamAdmin, respData)\n\tverifyProjectBinding(t, td, initSa.Email, roles)\n\n\t// Rotate account and verify is new account.\n\ttestRoleSetRotate(t, td, rsName)\n\tnewSa := getServiceAccount(t, td.IamAdmin, testRoleSetRead(t, td, rsName))\n\tif newSa.Name == initSa.Name {\n\t\tt.Fatalf(\"expected role set to have new service account after rotation (update)\")\n\t}\n\tverifyProjectBinding(t, td, newSa.Email, roles)\n\n\t// Verify old account/bindings deleted.\n\tverifyServiceAccountDeleted(t, td.IamAdmin, initSa.Name)\n\tverifyProjectBindingsRemoved(t, td, initSa.Email, roles)\n\n\t// Get RoleSet object for confirming key rotation:\n\toldK := verifyRoleSetTokenKey(t, td, rsName)\n\n\t// Rotate key only - should only change key, not service account\n\ttestRoleSetRotateKey(t, td, rsName)\n\tsaAfterRotate := getServiceAccount(t, td.IamAdmin, testRoleSetRead(t, td, rsName))\n\tif saAfterRotate.Name != newSa.Name {\n\t\tt.Fatalf(\"expected same service account (%s) after rotate key, instead got new account: %s\", newSa.Name, saAfterRotate.Name)\n\t}\n\n\t// Verify old key was deleted\n\tresult, err := td.IamAdmin.Projects.ServiceAccounts.Keys.Get(oldK.Name).Do()\n\tif err == nil && result != nil {\n\t\tt.Fatalf(\"old key was supposed to be deleted but get succeded\")\n\t} else if err != nil && !isGoogleAccountKeyNotFoundErr(err) {\n\t\tt.Fatalf(\"got an error while trying to confirm service account key was deleted: %v\", err)\n\t}\n\n\t// Verify new key != old key\n\tnewK := verifyRoleSetTokenKey(t, td, rsName)\n\tif newK.Name == oldK.Name {\n\t\tt.Fatalf(\"expected new key to have been created in rotate\")\n\t}\n\tif newK.PrivateKeyData == oldK.PrivateKeyData {\n\t\tt.Fatalf(\"expected new key data to have been created and saved in rotate\")\n\t}\n\n\t// 4. Delete role set\n\ttestRoleSetDelete(t, td, rsName, newSa.Name)\n\tverifyProjectBindingsRemoved(t, td, newSa.Email, roles)\n}", "is_vulnerable": 1}
{"code": "func TestReachableResourcesWithUnexpectedContextCancelation(t *testing.T) {\n\tdefer goleak.VerifyNone(t, goleakIgnores...)\n\n\trawDS, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\trequire.NoError(t, err)\n\n\ttestRels := make([]*core.RelationTuple, 0)\n\n\tfor i := 0; i < 410; i++ {\n\t\ttestRels = append(testRels, tuple.MustParse(fmt.Sprintf(\"resource:res%03d#viewer@user:tom\", i)))\n\t}\n\n\tbaseds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(\n\t\trawDS,\n\t\t`\n\t\t\tdefinition user {}\n\n\t\t\tdefinition resource {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission edit = editor\n\t\t\t\tpermission view = viewer + edit\n\t\t\t}\n\t\t`,\n\t\ttestRels,\n\t\trequire.New(t),\n\t)\n\n\tdispatcher := NewLocalOnlyDispatcher(2)\n\n\tctx := log.Logger.WithContext(datastoremw.ContextWithHandle(context.Background()))\n\n\tcds := cancelingDatastore{baseds}\n\trequire.NoError(t, datastoremw.SetInContext(ctx, cds))\n\n\tctxWithCancel, cancel := context.WithCancel(ctx)\n\tstream := dispatch.NewCollectingDispatchStream[*v1.DispatchReachableResourcesResponse](ctxWithCancel)\n\terr = dispatcher.DispatchReachableResources(&v1.DispatchReachableResourcesRequest{\n\t\tResourceRelation: RR(\"resource\", \"view\"),\n\t\tSubjectRelation: &core.RelationReference{\n\t\t\tNamespace: \"user\",\n\t\t\tRelation:  \"...\",\n\t\t},\n\t\tSubjectIds: []string{\"tom\"},\n\t\tMetadata: &v1.ResolverMeta{\n\t\t\tAtRevision:     revision.String(),\n\t\t\tDepthRemaining: 50,\n\t\t},\n\t}, stream)\n\trequire.Error(t, err)\n\trequire.ErrorIs(t, err, context.Canceled)\n\tdefer cancel()\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\thandler := sshutils.NewChanHandlerFunc(func(_ context.Context, ccx *sshutils.ConnectionContext, nch ssh.NewChannel) {\n\t\t\t\tch, _, err := nch.Accept()\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NoError(t, ch.Close())\n\t\t\t})\n\t\t\tsshServer, err := sshutils.NewServer(\n\t\t\t\t\"test\",\n\t\t\t\tutils.NetAddr{AddrNetwork: \"tcp\", Addr: \"localhost:0\"},\n\t\t\t\thandler,\n\t\t\t\t[]ssh.Signer{test.cert},\n\t\t\t\tsshutils.AuthMethods{NoClient: true},\n\t\t\t\tsshutils.SetInsecureSkipHostValidation(),\n\t\t\t)\n\t\t\trequire.NoError(t, err)\n\t\t\tt.Cleanup(func() { sshServer.Close() })\n\t\t\trequire.NoError(t, sshServer.Start())\n\n\t\t\tidentity, err := GenerateIdentity(authServer, IdentityID{\n\t\t\t\tRole:     teleport.RoleNode,\n\t\t\t\tHostUUID: uuid.New(),\n\t\t\t\tNodeName: \"node-1\",\n\t\t\t}, nil, nil)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tsshClientConfig, err := identity.SSHClientConfig(false)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tdialer := proxy.DialerFromEnvironment(sshServer.Addr())\n\t\t\tsconn, err := dialer.Dial(\"tcp\", sshServer.Addr(), sshClientConfig)\n\t\t\tif test.err {\n\t\t\t\trequire.Error(t, err)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NoError(t, sconn.Close())\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) AppendRequestedScope(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AppendRequestedScope\", reflect.TypeOf((*MockAccessRequester)(nil).AppendRequestedScope), arg0)\n}", "is_vulnerable": 0}
{"code": "func TestCursorNonIntSection(t *testing.T) {\n\tlimits := newLimitTracker(10)\n\trevision := revision.NewFromDecimal(decimal.NewFromInt(1))\n\n\tci, err := newCursorInformation(&v1.Cursor{\n\t\tAtRevision: revision.String(),\n\t\tSections:   []string{\"first\", \"one\", \"second\", \"two\"},\n\t}, revision, limits)\n\trequire.NoError(t, err)\n\n\thasFirst, err := ci.hasHeadSection(\"first\")\n\trequire.True(t, hasFirst)\n\trequire.NoError(t, err)\n\n\tvalue, err := ci.sectionValue(\"first\")\n\trequire.NoError(t, err)\n\trequire.Equal(t, value, \"one\")\n\n\t_, err = ci.integerSectionValue(\"first\")\n\trequire.Error(t, err)\n}", "is_vulnerable": 0}
{"code": "func Build(options BuildOptions) BuildResult {\n\tstart := time.Now()\n\n\tctx, errors := contextImpl(options)\n\tif ctx == nil {\n\t\treturn BuildResult{Errors: errors}\n\t}\n\n\tresult := ctx.Rebuild()\n\n\t// Print a summary of the generated files to stderr. Except don't do\n\t// this if the terminal is already being used for something else.\n\tif ctx.args.logOptions.LogLevel <= logger.LevelInfo && !ctx.args.options.WriteToStdout {\n\t\tprintSummary(ctx.args.logOptions.Color, result.OutputFiles, start)\n\t}\n\n\tctx.Dispose()\n\treturn result\n}", "is_vulnerable": 0}
{"code": "func stateTestCmd(ctx *cli.Context) error {\n\tif len(ctx.Args().First()) == 0 {\n\t\treturn errors.New(\"path-to-test argument required\")\n\t}\n\t// Configure the go-ethereum logger\n\tglogger := log.NewGlogHandler(log.StreamHandler(os.Stderr, log.TerminalFormat(false)))\n\tglogger.Verbosity(log.Lvl(ctx.GlobalInt(VerbosityFlag.Name)))\n\tlog.Root().SetHandler(glogger)\n\n\t// Configure the EVM logger\n\tconfig := &vm.LogConfig{\n\t\tDisableMemory:     ctx.GlobalBool(DisableMemoryFlag.Name),\n\t\tDisableStack:      ctx.GlobalBool(DisableStackFlag.Name),\n\t\tDisableStorage:    ctx.GlobalBool(DisableStorageFlag.Name),\n\t\tDisableReturnData: ctx.GlobalBool(DisableReturnDataFlag.Name),\n\t}\n\tvar (\n\t\ttracer   vm.Tracer\n\t\tdebugger *vm.StructLogger\n\t)\n\tswitch {\n\tcase ctx.GlobalBool(MachineFlag.Name):\n\t\ttracer = vm.NewJSONLogger(config, os.Stderr)\n\n\tcase ctx.GlobalBool(DebugFlag.Name):\n\t\tdebugger = vm.NewStructLogger(config)\n\t\ttracer = debugger\n\n\tdefault:\n\t\tdebugger = vm.NewStructLogger(config)\n\t}\n\t// Load the test content from the input file\n\tsrc, err := ioutil.ReadFile(ctx.Args().First())\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar tests map[string]tests.StateTest\n\tif err = json.Unmarshal(src, &tests); err != nil {\n\t\treturn err\n\t}\n\t// Iterate over all the tests, run them and aggregate the results\n\tcfg := vm.Config{\n\t\tTracer: tracer,\n\t\tDebug:  ctx.GlobalBool(DebugFlag.Name) || ctx.GlobalBool(MachineFlag.Name),\n\t}\n\tresults := make([]StatetestResult, 0, len(tests))\n\tfor key, test := range tests {\n\t\tfor _, st := range test.Subtests() {\n\t\t\t// Run the test and aggregate the result\n\t\t\tresult := &StatetestResult{Name: key, Fork: st.Fork, Pass: true}\n\t\t\t_, state, err := test.Run(st, cfg, false)\n\t\t\t// print state root for evmlab tracing\n\t\t\tif ctx.GlobalBool(MachineFlag.Name) && state != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"{\\\"stateRoot\\\": \\\"%x\\\"}\\n\", state.IntermediateRoot(false))\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\t// Test failed, mark as so and dump any state to aid debugging\n\t\t\t\tresult.Pass, result.Error = false, err.Error()\n\t\t\t\tif ctx.GlobalBool(DumpFlag.Name) && state != nil {\n\t\t\t\t\tdump := state.RawDump(false, false, true)\n\t\t\t\t\tresult.State = &dump\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tresults = append(results, *result)\n\n\t\t\t// Print any structured logs collected\n\t\t\tif ctx.GlobalBool(DebugFlag.Name) {\n\t\t\t\tif debugger != nil {\n\t\t\t\t\tfmt.Fprintln(os.Stderr, \"#### TRACE ####\")\n\t\t\t\t\tvm.WriteTrace(os.Stderr, debugger.StructLogs())\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tout, _ := json.MarshalIndent(results, \"\", \"  \")\n\tfmt.Println(string(out))\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestOSAP(t *testing.T) {\n\trwc := openTPMOrSkip(t)\n\tdefer rwc.Close()\n\n\t// Try to run OSAP for the SRK.\n\tosapc := &osapCommand{\n\t\tEntityType:  etSRK,\n\t\tEntityValue: khSRK,\n\t}\n\n\tif _, err := rand.Read(osapc.OddOSAP[:]); err != nil {\n\t\tt.Fatal(\"Couldn't get a random odd OSAP nonce\")\n\t}\n\n\t_, err := osap(rwc, osapc)\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't run OSAP:\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func newReturnStack() *ReturnStack {\n\treturn &ReturnStack{data: make([]uint64, 0, 1024)}\n}", "is_vulnerable": 1}
{"code": "func TestStartSandboxKataAgentSuccessful(t *testing.T) {\n\tassert := assert.New(t)\n\tif tc.NotValid(ktu.NeedRoot()) {\n\t\tt.Skip(testDisabledAsNonRoot)\n\t}\n\n\tdefer cleanUp()\n\n\tconfig := newTestSandboxConfigKataAgent()\n\n\tsockDir, err := testGenerateKataProxySockDir()\n\tassert.NoError(err)\n\tdefer os.RemoveAll(sockDir)\n\n\ttestKataProxyURL := fmt.Sprintf(testKataProxyURLTempl, sockDir)\n\tnoopProxyURL = testKataProxyURL\n\n\timpl := &gRPCProxy{}\n\n\tkataProxyMock := mock.ProxyGRPCMock{\n\t\tGRPCImplementer: impl,\n\t\tGRPCRegister:    gRPCRegister,\n\t}\n\terr = kataProxyMock.Start(testKataProxyURL)\n\tassert.NoError(err)\n\tdefer kataProxyMock.Stop()\n\n\tctx := context.Background()\n\tp, _, err := createAndStartSandbox(ctx, config)\n\tassert.NoError(err)\n\tassert.NotNil(p)\n\n\tpImpl, ok := p.(*Sandbox)\n\tassert.True(ok)\n\n\t// TODO: defaultSharedDir is a hyper var = /run/hyper/shared/sandboxes\n\t// do we need to unmount sandboxes and containers?\n\terr = bindUnmountAllRootfs(ctx, testDir, pImpl)\n\tassert.NoError(err)\n}", "is_vulnerable": 1}
{"code": "func TestFSM_SnapshotRestore_OSS(t *testing.T) {\n\tt.Parallel()\n\n\tassert := assert.New(t)\n\trequire := require.New(t)\n\tlogger := testutil.Logger(t)\n\tfsm, err := New(nil, logger)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Add some state\n\tnode1 := &structs.Node{\n\t\tID:         \"610918a6-464f-fa9b-1a95-03bd6e88ed92\",\n\t\tNode:       \"foo\",\n\t\tDatacenter: \"dc1\",\n\t\tAddress:    \"127.0.0.1\",\n\t}\n\tnode2 := &structs.Node{\n\t\tID:         \"40e4a748-2192-161a-0510-9bf59fe950b5\",\n\t\tNode:       \"baz\",\n\t\tDatacenter: \"dc1\",\n\t\tAddress:    \"127.0.0.2\",\n\t\tTaggedAddresses: map[string]string{\n\t\t\t\"hello\": \"1.2.3.4\",\n\t\t},\n\t\tMeta: map[string]string{\n\t\t\t\"testMeta\": \"testing123\",\n\t\t},\n\t}\n\trequire.NoError(fsm.state.EnsureNode(1, node1))\n\trequire.NoError(fsm.state.EnsureNode(2, node2))\n\n\t// Add a service instance with Connect config.\n\tconnectConf := structs.ServiceConnect{\n\t\tNative: true,\n\t}\n\tfsm.state.EnsureService(3, \"foo\", &structs.NodeService{\n\t\tID:      \"web\",\n\t\tService: \"web\",\n\t\tTags:    nil,\n\t\tAddress: \"127.0.0.1\",\n\t\tPort:    80,\n\t\tConnect: connectConf,\n\t})\n\tfsm.state.EnsureService(4, \"foo\", &structs.NodeService{ID: \"db\", Service: \"db\", Tags: []string{\"primary\"}, Address: \"127.0.0.1\", Port: 5000})\n\tfsm.state.EnsureService(5, \"baz\", &structs.NodeService{ID: \"web\", Service: \"web\", Tags: nil, Address: \"127.0.0.2\", Port: 80})\n\tfsm.state.EnsureService(6, \"baz\", &structs.NodeService{ID: \"db\", Service: \"db\", Tags: []string{\"secondary\"}, Address: \"127.0.0.2\", Port: 5000})\n\tfsm.state.EnsureCheck(7, &structs.HealthCheck{\n\t\tNode:      \"foo\",\n\t\tCheckID:   \"web\",\n\t\tName:      \"web connectivity\",\n\t\tStatus:    api.HealthPassing,\n\t\tServiceID: \"web\",\n\t})\n\tfsm.state.KVSSet(8, &structs.DirEntry{\n\t\tKey:   \"/test\",\n\t\tValue: []byte(\"foo\"),\n\t})\n\tsession := &structs.Session{ID: generateUUID(), Node: \"foo\"}\n\tfsm.state.SessionCreate(9, session)\n\n\tpolicy := &structs.ACLPolicy{\n\t\tID:          structs.ACLPolicyGlobalManagementID,\n\t\tName:        \"global-management\",\n\t\tDescription: \"Builtin Policy that grants unlimited access\",\n\t\tRules:       structs.ACLPolicyGlobalManagement,\n\t\tSyntax:      acl.SyntaxCurrent,\n\t}\n\tpolicy.SetHash(true)\n\trequire.NoError(fsm.state.ACLPolicySet(1, policy))\n\n\trole := &structs.ACLRole{\n\t\tID:          \"86dedd19-8fae-4594-8294-4e6948a81f9a\",\n\t\tName:        \"some-role\",\n\t\tDescription: \"test snapshot role\",\n\t\tServiceIdentities: []*structs.ACLServiceIdentity{\n\t\t\t&structs.ACLServiceIdentity{\n\t\t\t\tServiceName: \"example\",\n\t\t\t},\n\t\t},\n\t}\n\trole.SetHash(true)\n\trequire.NoError(fsm.state.ACLRoleSet(1, role))\n\n\ttoken := &structs.ACLToken{\n\t\tAccessorID:  \"30fca056-9fbb-4455-b94a-bf0e2bc575d6\",\n\t\tSecretID:    \"cbe1c6fd-d865-4034-9d6d-64fef7fb46a9\",\n\t\tDescription: \"Bootstrap Token (Global Management)\",\n\t\tPolicies: []structs.ACLTokenPolicyLink{\n\t\t\t{\n\t\t\t\tID: structs.ACLPolicyGlobalManagementID,\n\t\t\t},\n\t\t},\n\t\tCreateTime: time.Now(),\n\t\tLocal:      false,\n\t\t// DEPRECATED (ACL-Legacy-Compat) - This is used so that the bootstrap token is still visible via the v1 acl APIs\n\t\tType: structs.ACLTokenTypeManagement,\n\t}\n\trequire.NoError(fsm.state.ACLBootstrap(10, 0, token, false))\n\n\tmethod := &structs.ACLAuthMethod{\n\t\tName:        \"some-method\",\n\t\tType:        \"testing\",\n\t\tDescription: \"test snapshot auth method\",\n\t\tConfig: map[string]interface{}{\n\t\t\t\"SessionID\": \"952ebfa8-2a42-46f0-bcd3-fd98a842000e\",\n\t\t},\n\t}\n\trequire.NoError(fsm.state.ACLAuthMethodSet(1, method))\n\n\tbindingRule := &structs.ACLBindingRule{\n\t\tID:          \"85184c52-5997-4a84-9817-5945f2632a17\",\n\t\tDescription: \"test snapshot binding rule\",\n\t\tAuthMethod:  \"some-method\",\n\t\tSelector:    \"serviceaccount.namespace==default\",\n\t\tBindType:    structs.BindingRuleBindTypeService,\n\t\tBindName:    \"${serviceaccount.name}\",\n\t}\n\trequire.NoError(fsm.state.ACLBindingRuleSet(1, bindingRule))\n\n\tfsm.state.KVSSet(11, &structs.DirEntry{\n\t\tKey:   \"/remove\",\n\t\tValue: []byte(\"foo\"),\n\t})\n\tfsm.state.KVSDelete(12, \"/remove\", nil)\n\tidx, _, err := fsm.state.KVSList(nil, \"/remove\", nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif idx != 12 {\n\t\tt.Fatalf(\"bad index: %d\", idx)\n\t}\n\n\tupdates := structs.Coordinates{\n\t\t&structs.Coordinate{\n\t\t\tNode:  \"baz\",\n\t\t\tCoord: generateRandomCoordinate(),\n\t\t},\n\t\t&structs.Coordinate{\n\t\t\tNode:  \"foo\",\n\t\t\tCoord: generateRandomCoordinate(),\n\t\t},\n\t}\n\tif err := fsm.state.CoordinateBatchUpdate(13, updates); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\tquery := structs.PreparedQuery{\n\t\tID: generateUUID(),\n\t\tService: structs.ServiceQuery{\n\t\t\tService: \"web\",\n\t\t},\n\t\tRaftIndex: structs.RaftIndex{\n\t\t\tCreateIndex: 14,\n\t\t\tModifyIndex: 14,\n\t\t},\n\t}\n\tif err := fsm.state.PreparedQuerySet(14, &query); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\tautopilotConf := &autopilot.Config{\n\t\tCleanupDeadServers:   true,\n\t\tLastContactThreshold: 100 * time.Millisecond,\n\t\tMaxTrailingLogs:      222,\n\t}\n\tif err := fsm.state.AutopilotSetConfig(15, autopilotConf); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\t// Intentions\n\tixn := structs.TestIntention(t)\n\tixn.ID = generateUUID()\n\tixn.RaftIndex = structs.RaftIndex{\n\t\tCreateIndex: 14,\n\t\tModifyIndex: 14,\n\t}\n\trequire.NoError(fsm.state.IntentionSet(14, ixn))\n\n\t// CA Roots\n\troots := []*structs.CARoot{\n\t\tconnect.TestCA(t, nil),\n\t\tconnect.TestCA(t, nil),\n\t}\n\tfor _, r := range roots[1:] {\n\t\tr.Active = false\n\t}\n\tok, err := fsm.state.CARootSetCAS(15, 0, roots)\n\trequire.NoError(err)\n\tassert.True(ok)\n\n\tok, err = fsm.state.CASetProviderState(16, &structs.CAConsulProviderState{\n\t\tID:         \"asdf\",\n\t\tPrivateKey: \"foo\",\n\t\tRootCert:   \"bar\",\n\t})\n\trequire.NoError(err)\n\tassert.True(ok)\n\n\t// CA Config\n\tcaConfig := &structs.CAConfiguration{\n\t\tClusterID: \"foo\",\n\t\tProvider:  \"consul\",\n\t\tConfig: map[string]interface{}{\n\t\t\t\"foo\": \"asdf\",\n\t\t\t\"bar\": 6.5,\n\t\t},\n\t}\n\terr = fsm.state.CASetConfig(17, caConfig)\n\trequire.NoError(err)\n\n\t// Config entries\n\tserviceConfig := &structs.ServiceConfigEntry{\n\t\tKind:     structs.ServiceDefaults,\n\t\tName:     \"foo\",\n\t\tProtocol: \"http\",\n\t}\n\tproxyConfig := &structs.ProxyConfigEntry{\n\t\tKind: structs.ProxyDefaults,\n\t\tName: \"global\",\n\t}\n\trequire.NoError(fsm.state.EnsureConfigEntry(18, serviceConfig, structs.DefaultEnterpriseMeta()))\n\trequire.NoError(fsm.state.EnsureConfigEntry(19, proxyConfig, structs.DefaultEnterpriseMeta()))\n\n\tingress := &structs.IngressGatewayConfigEntry{\n\t\tKind: structs.IngressGateway,\n\t\tName: \"ingress\",\n\t\tListeners: []structs.IngressListener{\n\t\t\t{\n\t\t\t\tPort:     8080,\n\t\t\t\tProtocol: \"http\",\n\t\t\t\tServices: []structs.IngressService{\n\t\t\t\t\t{\n\t\t\t\t\t\tName: \"foo\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\trequire.NoError(fsm.state.EnsureConfigEntry(20, ingress, structs.DefaultEnterpriseMeta()))\n\t_, gatewayServices, err := fsm.state.GatewayServices(nil, \"ingress\", structs.DefaultEnterpriseMeta())\n\trequire.NoError(err)\n\n\t// Raft Chunking\n\tchunkState := &raftchunking.State{\n\t\tChunkMap: make(raftchunking.ChunkMap),\n\t}\n\tchunkState.ChunkMap[0] = []*raftchunking.ChunkInfo{\n\t\t{\n\t\t\tOpNum:       0,\n\t\t\tSequenceNum: 0,\n\t\t\tNumChunks:   3,\n\t\t\tData:        []byte(\"foo\"),\n\t\t},\n\t\tnil,\n\t\t{\n\t\t\tOpNum:       0,\n\t\t\tSequenceNum: 2,\n\t\t\tNumChunks:   3,\n\t\t\tData:        []byte(\"bar\"),\n\t\t},\n\t}\n\tchunkState.ChunkMap[20] = []*raftchunking.ChunkInfo{\n\t\tnil,\n\t\t{\n\t\t\tOpNum:       20,\n\t\t\tSequenceNum: 1,\n\t\t\tNumChunks:   2,\n\t\t\tData:        []byte(\"bar\"),\n\t\t},\n\t}\n\terr = fsm.chunker.RestoreState(chunkState)\n\trequire.NoError(err)\n\n\t// Federation states\n\tfedState1 := &structs.FederationState{\n\t\tDatacenter: \"dc1\",\n\t\tMeshGateways: []structs.CheckServiceNode{\n\t\t\t{\n\t\t\t\tNode: &structs.Node{\n\t\t\t\t\tID:         \"664bac9f-4de7-4f1b-ad35-0e5365e8f329\",\n\t\t\t\t\tNode:       \"gateway1\",\n\t\t\t\t\tDatacenter: \"dc1\",\n\t\t\t\t\tAddress:    \"1.2.3.4\",\n\t\t\t\t},\n\t\t\t\tService: &structs.NodeService{\n\t\t\t\t\tID:      \"mesh-gateway\",\n\t\t\t\t\tService: \"mesh-gateway\",\n\t\t\t\t\tKind:    structs.ServiceKindMeshGateway,\n\t\t\t\t\tPort:    1111,\n\t\t\t\t\tMeta:    map[string]string{structs.MetaWANFederationKey: \"1\"},\n\t\t\t\t},\n\t\t\t\tChecks: []*structs.HealthCheck{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:      \"web connectivity\",\n\t\t\t\t\t\tStatus:    api.HealthPassing,\n\t\t\t\t\t\tServiceID: \"mesh-gateway\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tNode: &structs.Node{\n\t\t\t\t\tID:         \"3fb9a696-8209-4eee-a1f7-48600deb9716\",\n\t\t\t\t\tNode:       \"gateway2\",\n\t\t\t\t\tDatacenter: \"dc1\",\n\t\t\t\t\tAddress:    \"9.8.7.6\",\n\t\t\t\t},\n\t\t\t\tService: &structs.NodeService{\n\t\t\t\t\tID:      \"mesh-gateway\",\n\t\t\t\t\tService: \"mesh-gateway\",\n\t\t\t\t\tKind:    structs.ServiceKindMeshGateway,\n\t\t\t\t\tPort:    2222,\n\t\t\t\t\tMeta:    map[string]string{structs.MetaWANFederationKey: \"1\"},\n\t\t\t\t},\n\t\t\t\tChecks: []*structs.HealthCheck{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:      \"web connectivity\",\n\t\t\t\t\t\tStatus:    api.HealthPassing,\n\t\t\t\t\t\tServiceID: \"mesh-gateway\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tUpdatedAt: time.Now().UTC(),\n\t}\n\tfedState2 := &structs.FederationState{\n\t\tDatacenter: \"dc2\",\n\t\tMeshGateways: []structs.CheckServiceNode{\n\t\t\t{\n\t\t\t\tNode: &structs.Node{\n\t\t\t\t\tID:         \"0f92b02e-9f51-4aa2-861b-4ddbc3492724\",\n\t\t\t\t\tNode:       \"gateway1\",\n\t\t\t\t\tDatacenter: \"dc2\",\n\t\t\t\t\tAddress:    \"8.8.8.8\",\n\t\t\t\t},\n\t\t\t\tService: &structs.NodeService{\n\t\t\t\t\tID:      \"mesh-gateway\",\n\t\t\t\t\tService: \"mesh-gateway\",\n\t\t\t\t\tKind:    structs.ServiceKindMeshGateway,\n\t\t\t\t\tPort:    3333,\n\t\t\t\t\tMeta:    map[string]string{structs.MetaWANFederationKey: \"1\"},\n\t\t\t\t},\n\t\t\t\tChecks: []*structs.HealthCheck{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:      \"web connectivity\",\n\t\t\t\t\t\tStatus:    api.HealthPassing,\n\t\t\t\t\t\tServiceID: \"mesh-gateway\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tNode: &structs.Node{\n\t\t\t\t\tID:         \"99a76121-1c3f-4023-88ef-805248beb10b\",\n\t\t\t\t\tNode:       \"gateway2\",\n\t\t\t\t\tDatacenter: \"dc2\",\n\t\t\t\t\tAddress:    \"5.5.5.5\",\n\t\t\t\t},\n\t\t\t\tService: &structs.NodeService{\n\t\t\t\t\tID:      \"mesh-gateway\",\n\t\t\t\t\tService: \"mesh-gateway\",\n\t\t\t\t\tKind:    structs.ServiceKindMeshGateway,\n\t\t\t\t\tPort:    4444,\n\t\t\t\t\tMeta:    map[string]string{structs.MetaWANFederationKey: \"1\"},\n\t\t\t\t},\n\t\t\t\tChecks: []*structs.HealthCheck{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:      \"web connectivity\",\n\t\t\t\t\t\tStatus:    api.HealthPassing,\n\t\t\t\t\t\tServiceID: \"mesh-gateway\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tUpdatedAt: time.Now().UTC(),\n\t}\n\trequire.NoError(fsm.state.FederationStateSet(21, fedState1))\n\trequire.NoError(fsm.state.FederationStateSet(22, fedState2))\n\n\t// Snapshot\n\tsnap, err := fsm.Snapshot()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tdefer snap.Release()\n\n\t// Persist\n\tbuf := bytes.NewBuffer(nil)\n\tsink := &MockSink{buf, false}\n\tif err := snap.Persist(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Try to restore on a new FSM\n\tfsm2, err := New(nil, logger)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Do a restore\n\tif err := fsm2.Restore(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Verify the contents\n\t_, nodes, err := fsm2.state.Nodes(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif len(nodes) != 2 {\n\t\tt.Fatalf(\"bad: %v\", nodes)\n\t}\n\tif nodes[0].ID != node2.ID ||\n\t\tnodes[0].Node != \"baz\" ||\n\t\tnodes[0].Datacenter != \"dc1\" ||\n\t\tnodes[0].Address != \"127.0.0.2\" ||\n\t\tlen(nodes[0].Meta) != 1 ||\n\t\tnodes[0].Meta[\"testMeta\"] != \"testing123\" ||\n\t\tlen(nodes[0].TaggedAddresses) != 1 ||\n\t\tnodes[0].TaggedAddresses[\"hello\"] != \"1.2.3.4\" {\n\t\tt.Fatalf(\"bad: %v\", nodes[0])\n\t}\n\tif nodes[1].ID != node1.ID ||\n\t\tnodes[1].Node != \"foo\" ||\n\t\tnodes[1].Datacenter != \"dc1\" ||\n\t\tnodes[1].Address != \"127.0.0.1\" ||\n\t\tlen(nodes[1].TaggedAddresses) != 0 {\n\t\tt.Fatalf(\"bad: %v\", nodes[1])\n\t}\n\n\t_, fooSrv, err := fsm2.state.NodeServices(nil, \"foo\", nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif len(fooSrv.Services) != 2 {\n\t\tt.Fatalf(\"Bad: %v\", fooSrv)\n\t}\n\tif !stringslice.Contains(fooSrv.Services[\"db\"].Tags, \"primary\") {\n\t\tt.Fatalf(\"Bad: %v\", fooSrv)\n\t}\n\tif fooSrv.Services[\"db\"].Port != 5000 {\n\t\tt.Fatalf(\"Bad: %v\", fooSrv)\n\t}\n\tconnectSrv := fooSrv.Services[\"web\"]\n\tif !reflect.DeepEqual(connectSrv.Connect, connectConf) {\n\t\tt.Fatalf(\"got: %v, want: %v\", connectSrv.Connect, connectConf)\n\t}\n\n\t_, checks, err := fsm2.state.NodeChecks(nil, \"foo\", nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif len(checks) != 1 {\n\t\tt.Fatalf(\"Bad: %v\", checks)\n\t}\n\n\t// Verify key is set\n\t_, d, err := fsm2.state.KVSGet(nil, \"/test\", nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif string(d.Value) != \"foo\" {\n\t\tt.Fatalf(\"bad: %v\", d)\n\t}\n\n\t// Verify session is restored\n\tidx, s, err := fsm2.state.SessionGet(nil, session.ID, nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif s.Node != \"foo\" {\n\t\tt.Fatalf(\"bad: %v\", s)\n\t}\n\tif idx <= 1 {\n\t\tt.Fatalf(\"bad index: %d\", idx)\n\t}\n\n\t// Verify ACL Binding Rule is restored\n\t_, bindingRule2, err := fsm2.state.ACLBindingRuleGetByID(nil, bindingRule.ID, nil)\n\trequire.NoError(err)\n\trequire.Equal(bindingRule, bindingRule2)\n\n\t// Verify ACL Auth Method is restored\n\t_, method2, err := fsm2.state.ACLAuthMethodGetByName(nil, method.Name, nil)\n\trequire.NoError(err)\n\trequire.Equal(method, method2)\n\n\t// Verify ACL Token is restored\n\t_, token2, err := fsm2.state.ACLTokenGetByAccessor(nil, token.AccessorID, nil)\n\trequire.NoError(err)\n\t{\n\t\t// time.Time is tricky to compare generically when it takes a ser/deserialization round trip.\n\t\trequire.True(token.CreateTime.Equal(token2.CreateTime))\n\t\ttoken2.CreateTime = token.CreateTime\n\t}\n\trequire.Equal(token, token2)\n\n\t// Verify the acl-token-bootstrap index was restored\n\tcanBootstrap, index, err := fsm2.state.CanBootstrapACLToken()\n\trequire.False(canBootstrap)\n\trequire.True(index > 0)\n\n\t// Verify ACL Role is restored\n\t_, role2, err := fsm2.state.ACLRoleGetByID(nil, role.ID, nil)\n\trequire.NoError(err)\n\trequire.Equal(role, role2)\n\n\t// Verify ACL Policy is restored\n\t_, policy2, err := fsm2.state.ACLPolicyGetByID(nil, structs.ACLPolicyGlobalManagementID, nil)\n\trequire.NoError(err)\n\trequire.Equal(policy, policy2)\n\n\t// Verify tombstones are restored\n\tfunc() {\n\t\tsnap := fsm2.state.Snapshot()\n\t\tdefer snap.Close()\n\t\tstones, err := snap.Tombstones()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %s\", err)\n\t\t}\n\t\tstone := stones.Next().(*state.Tombstone)\n\t\tif stone == nil {\n\t\t\tt.Fatalf(\"missing tombstone\")\n\t\t}\n\t\tif stone.Key != \"/remove\" || stone.Index != 12 {\n\t\t\tt.Fatalf(\"bad: %v\", stone)\n\t\t}\n\t\tif stones.Next() != nil {\n\t\t\tt.Fatalf(\"unexpected extra tombstones\")\n\t\t}\n\t}()\n\n\t// Verify coordinates are restored\n\t_, coords, err := fsm2.state.Coordinates(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif !reflect.DeepEqual(coords, updates) {\n\t\tt.Fatalf(\"bad: %#v\", coords)\n\t}\n\n\t// Verify queries are restored.\n\t_, queries, err := fsm2.state.PreparedQueryList(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif len(queries) != 1 {\n\t\tt.Fatalf(\"bad: %#v\", queries)\n\t}\n\tif !reflect.DeepEqual(queries[0], &query) {\n\t\tt.Fatalf(\"bad: %#v\", queries[0])\n\t}\n\n\t// Verify autopilot config is restored.\n\t_, restoredConf, err := fsm2.state.AutopilotConfig()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\tif !reflect.DeepEqual(restoredConf, autopilotConf) {\n\t\tt.Fatalf(\"bad: %#v, %#v\", restoredConf, autopilotConf)\n\t}\n\n\t// Verify intentions are restored.\n\t_, ixns, err := fsm2.state.Intentions(nil)\n\trequire.NoError(err)\n\tassert.Len(ixns, 1)\n\tassert.Equal(ixn, ixns[0])\n\n\t// Verify CA roots are restored.\n\t_, roots, err = fsm2.state.CARoots(nil)\n\trequire.NoError(err)\n\tassert.Len(roots, 2)\n\n\t// Verify provider state is restored.\n\t_, state, err := fsm2.state.CAProviderState(\"asdf\")\n\trequire.NoError(err)\n\tassert.Equal(\"foo\", state.PrivateKey)\n\tassert.Equal(\"bar\", state.RootCert)\n\n\t// Verify CA configuration is restored.\n\t_, caConf, err := fsm2.state.CAConfig(nil)\n\trequire.NoError(err)\n\tassert.Equal(caConfig, caConf)\n\n\t// Verify config entries are restored\n\t_, serviceConfEntry, err := fsm2.state.ConfigEntry(nil, structs.ServiceDefaults, \"foo\", structs.DefaultEnterpriseMeta())\n\trequire.NoError(err)\n\tassert.Equal(serviceConfig, serviceConfEntry)\n\n\t_, proxyConfEntry, err := fsm2.state.ConfigEntry(nil, structs.ProxyDefaults, \"global\", structs.DefaultEnterpriseMeta())\n\trequire.NoError(err)\n\tassert.Equal(proxyConfig, proxyConfEntry)\n\n\t_, ingressRestored, err := fsm2.state.ConfigEntry(nil, structs.IngressGateway, \"ingress\", structs.DefaultEnterpriseMeta())\n\trequire.NoError(err)\n\tassert.Equal(ingress, ingressRestored)\n\n\t_, restoredGatewayServices, err := fsm2.state.GatewayServices(nil, \"ingress\", structs.DefaultEnterpriseMeta())\n\trequire.NoError(err)\n\trequire.Equal(gatewayServices, restoredGatewayServices)\n\n\tnewChunkState, err := fsm2.chunker.CurrentState()\n\trequire.NoError(err)\n\tassert.Equal(newChunkState, chunkState)\n\n\t// Verify federation states are restored.\n\t_, fedStateLoaded1, err := fsm2.state.FederationStateGet(nil, \"dc1\")\n\trequire.NoError(err)\n\tassert.Equal(fedState1, fedStateLoaded1)\n\t_, fedStateLoaded2, err := fsm2.state.FederationStateGet(nil, \"dc2\")\n\trequire.NoError(err)\n\tassert.Equal(fedState2, fedStateLoaded2)\n\n\t// Snapshot\n\tsnap, err = fsm2.Snapshot()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tdefer snap.Release()\n\n\t// Persist\n\tbuf = bytes.NewBuffer(nil)\n\tsink = &MockSink{buf, false}\n\tif err := snap.Persist(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Try to restore on the old FSM and make sure it abandons the old state\n\t// store.\n\tabandonCh := fsm.state.AbandonCh()\n\tif err := fsm.Restore(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tselect {\n\tcase <-abandonCh:\n\tdefault:\n\t\tt.Fatalf(\"bad\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) OutgoingTLSConfigForCheck(skipVerify bool) *tls.Config {\n\tc.log(\"OutgoingTLSConfigForCheck\")\n\tif !c.enableAgentTLSForChecks() {\n\t\treturn &tls.Config{\n\t\t\tInsecureSkipVerify: skipVerify,\n\t\t}\n\t}\n\n\tconfig := c.commonTLSConfig(false)\n\tconfig.InsecureSkipVerify = skipVerify\n\tconfig.ServerName = c.serverNameOrNodeName()\n\n\treturn config\n}", "is_vulnerable": 0}
{"code": "func FsRemove(c *gin.Context) {\n\tvar req RemoveReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tif len(req.Names) == 0 {\n\t\tcommon.ErrorStrResp(c, \"Empty file names\", 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\tif !user.CanRemove() {\n\t\tcommon.ErrorResp(c, errs.PermissionDenied, 403)\n\t\treturn\n\t}\n\treq.Dir = stdpath.Join(user.BasePath, req.Dir)\n\tfor _, name := range req.Names {\n\t\terr := fs.Remove(c, stdpath.Join(req.Dir, name))\n\t\tif err != nil {\n\t\t\tcommon.ErrorResp(c, err, 500)\n\t\t\treturn\n\t\t}\n\t}\n\t//fs.ClearCache(req.Dir)\n\tcommon.SuccessResp(c)\n}", "is_vulnerable": 1}
{"code": "func ReadMappings(path string) ([]idtools.IDMap, error) {\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"cannot open %s\", path)\n\t}\n\tdefer file.Close()\n\n\tvar mappings []idtools.IDMap\n\n\tbuf := bufio.NewReader(file)\n\tfor {\n\t\tline, _, err := buf.ReadLine()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn mappings, nil\n\t\t\t}\n\t\t\treturn nil, errors.Wrapf(err, \"cannot read line from %s\", path)\n\t\t}\n\t\tif line == nil {\n\t\t\treturn mappings, nil\n\t\t}\n\n\t\tvar containerID, hostID, size int\n\t\tif _, err := fmt.Sscanf(string(line), \"%d %d %d\", &containerID, &hostID, &size); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"cannot parse %s\", string(line))\n\t\t}\n\t\tmappings = append(mappings, idtools.IDMap{ContainerID: containerID, HostID: hostID, Size: size})\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.description, func(t *testing.T) {\n\t\t\tgotSig, err := signatures(test.sigRef, \"\")\n\t\t\tif test.shouldErr && err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif test.shouldErr {\n\t\t\t\tt.Fatal(\"should have received an error\")\n\t\t\t}\n\t\t\tif gotSig != sig {\n\t\t\t\tt.Fatalf(\"unexpected signature, expected: %s got: %s\", sig, gotSig)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func (g *GitGetter) Get(ctx context.Context, req *Request) error {\n\tif _, err := exec.LookPath(\"git\"); err != nil {\n\t\treturn fmt.Errorf(\"git must be available and on the PATH\")\n\t}\n\n\t// The port number must be parseable as an integer. If not, the user\n\t// was probably trying to use a scp-style address, in which case the\n\t// ssh:// prefix must be removed to indicate that.\n\t//\n\t// This is not necessary in versions of Go which have patched\n\t// CVE-2019-14809 (e.g. Go 1.12.8+)\n\tif portStr := req.u.Port(); portStr != \"\" {\n\t\tif _, err := strconv.ParseUint(portStr, 10, 16); err != nil {\n\t\t\treturn fmt.Errorf(\"invalid port number %q; if using the \\\"scp-like\\\" git address scheme where a colon introduces the path instead, remove the ssh:// portion and use just the git:: prefix\", portStr)\n\t\t}\n\t}\n\n\t// Extract some query parameters we use\n\tvar ref, sshKey string\n\tvar depth int\n\tq := req.u.Query()\n\tif len(q) > 0 {\n\t\tref = q.Get(\"ref\")\n\t\tq.Del(\"ref\")\n\n\t\tsshKey = q.Get(\"sshkey\")\n\t\tq.Del(\"sshkey\")\n\n\t\tif n, err := strconv.Atoi(q.Get(\"depth\")); err == nil {\n\t\t\tdepth = n\n\t\t}\n\t\tq.Del(\"depth\")\n\n\t\t// Copy the URL\n\t\tvar newU url.URL = *req.u\n\t\treq.u = &newU\n\t\treq.u.RawQuery = q.Encode()\n\t}\n\n\tvar sshKeyFile string\n\tif sshKey != \"\" {\n\t\t// Check that the git version is sufficiently new.\n\t\tif err := checkGitVersion(\"2.3\"); err != nil {\n\t\t\treturn fmt.Errorf(\"Error using ssh key: %v\", err)\n\t\t}\n\n\t\t// We have an SSH key - decode it.\n\t\traw, err := base64.StdEncoding.DecodeString(sshKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Create a temp file for the key and ensure it is removed.\n\t\tfh, err := ioutil.TempFile(\"\", \"go-getter\")\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsshKeyFile = fh.Name()\n\t\tdefer os.Remove(sshKeyFile)\n\n\t\t// Set the permissions prior to writing the key material.\n\t\tif err := os.Chmod(sshKeyFile, 0600); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Write the raw key into the temp file.\n\t\t_, err = fh.Write(raw)\n\t\tfh.Close()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Clone or update the repository\n\t_, err := os.Stat(req.Dst)\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\tif err == nil {\n\t\terr = g.update(ctx, req.Dst, sshKeyFile, ref, depth)\n\t} else {\n\t\terr = g.clone(ctx, sshKeyFile, depth, req)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Next: check out the proper tag/branch if it is specified, and checkout\n\tif ref != \"\" {\n\t\tif err := g.checkout(req.Dst, ref); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Lastly, download any/all submodules.\n\treturn g.fetchSubmodules(ctx, req.Dst, sshKeyFile, depth)\n}", "is_vulnerable": 1}
{"code": "func newDiffNormalizer(ignore []v1alpha1.ResourceIgnoreDifferences, overrides map[string]v1alpha1.ResourceOverride) (diff.Normalizer, error) {\n\tignoreNormalizer, err := normalizers.NewIgnoreNormalizer(ignore, overrides)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tknownTypesNorm, err := normalizers.NewKnownTypesNormalizer(overrides)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &composableNormalizer{normalizers: []diff.Normalizer{ignoreNormalizer, knownTypesNorm}}, nil\n}", "is_vulnerable": 1}
{"code": "func (a snippet) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, configurationSnippetAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (m *Bar1) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar1: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar1: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Str = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func RandString(n int) string {\n\treturn RandStringCharset(n, letterBytes)\n}", "is_vulnerable": 1}
{"code": "func New(client dockerpkg.Client, config *api.Config, fs fs.FileSystem, overrides build.Overrides) (*STI, error) {\n\texcludePattern, err := regexp.Compile(config.ExcludeRegExp)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdocker := dockerpkg.New(client, config.PullAuthentication)\n\tvar incrementalDocker dockerpkg.Docker\n\tif config.Incremental {\n\t\tincrementalDocker = dockerpkg.New(client, config.IncrementalAuthentication)\n\t}\n\n\tinst := scripts.NewInstaller(\n\t\tconfig.BuilderImage,\n\t\tconfig.ScriptsURL,\n\t\tconfig.ScriptDownloadProxyConfig,\n\t\tdocker,\n\t\tconfig.PullAuthentication,\n\t\tfs,\n\t)\n\ttarHandler := tar.NewParanoid(fs)\n\ttarHandler.SetExclusionPattern(excludePattern)\n\n\tbuilder := &STI{\n\t\tinstaller:              inst,\n\t\tconfig:                 config,\n\t\tdocker:                 docker,\n\t\tincrementalDocker:      incrementalDocker,\n\t\tgit:                    git.New(fs, cmd.NewCommandRunner()),\n\t\tfs:                     fs,\n\t\ttar:                    tarHandler,\n\t\tcallbackInvoker:        util.NewCallbackInvoker(),\n\t\trequiredScripts:        []string{api.Assemble, api.Run},\n\t\toptionalScripts:        []string{api.SaveArtifacts},\n\t\toptionalRuntimeScripts: []string{api.AssembleRuntime},\n\t\texternalScripts:        map[string]bool{},\n\t\tinstalledScripts:       map[string]bool{},\n\t\tscriptsURL:             map[string]string{},\n\t\tnewLabels:              map[string]string{},\n\t}\n\n\tif len(config.RuntimeImage) > 0 {\n\t\tbuilder.runtimeDocker = dockerpkg.New(client, config.RuntimeAuthentication)\n\n\t\tbuilder.runtimeInstaller = scripts.NewInstaller(\n\t\t\tconfig.RuntimeImage,\n\t\t\tconfig.ScriptsURL,\n\t\t\tconfig.ScriptDownloadProxyConfig,\n\t\t\tbuilder.runtimeDocker,\n\t\t\tconfig.RuntimeAuthentication,\n\t\t\tbuilder.fs,\n\t\t)\n\t}\n\n\t// The sources are downloaded using the Git downloader.\n\t// TODO: Add more SCM in future.\n\t// TODO: explicit decision made to customize processing for usage specifically vs.\n\t// leveraging overrides; also, we ultimately want to simplify s2i usage a good bit,\n\t// which would lead to replacing this quick short circuit (so this change is tactical)\n\tbuilder.source = overrides.Downloader\n\tif builder.source == nil && !config.Usage {\n\t\tdownloader, err := scm.DownloaderForSource(builder.fs, config.Source, config.ForceCopy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tbuilder.source = downloader\n\t}\n\tbuilder.garbage = build.NewDefaultCleaner(builder.fs, builder.docker)\n\n\tbuilder.layered, err = layered.New(client, config, builder.fs, builder, overrides)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Set interfaces\n\tbuilder.preparer = builder\n\t// later on, if we support say .gitignore func in addition to .dockerignore\n\t// func, setting ignorer will be based on config setting\n\tbuilder.ignorer = &ignore.DockerIgnorer{}\n\tbuilder.artifacts = builder\n\tbuilder.scripts = builder\n\tbuilder.postExecutor = builder\n\tbuilder.initPostExecutorSteps()\n\n\treturn builder, nil\n}", "is_vulnerable": 0}
{"code": "func ReadMappings(path string) ([]idtools.IDMap, error) {\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer file.Close()\n\n\tvar mappings []idtools.IDMap\n\n\tbuf := bufio.NewReader(file)\n\tfor {\n\t\tline, _, err := buf.ReadLine()\n\t\tif err != nil {\n\t\t\tif err == io.EOF { //nolint:errorlint // False positive, see https://github.com/polyfloyd/go-errorlint/pull/12\n\t\t\t\treturn mappings, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"cannot read line from %s: %w\", path, err)\n\t\t}\n\t\tif line == nil {\n\t\t\treturn mappings, nil\n\t\t}\n\n\t\tvar containerID, hostID, size int\n\t\tif _, err := fmt.Sscanf(string(line), \"%d %d %d\", &containerID, &hostID, &size); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot parse %s: %w\", string(line), err)\n\t\t}\n\t\tmappings = append(mappings, idtools.IDMap{ContainerID: containerID, HostID: hostID, Size: size})\n\t}\n}", "is_vulnerable": 0}
{"code": "func SubdirGlob(dst, subDir string) (string, error) {\n\tmatches, err := filepath.Glob(filepath.Join(dst, subDir))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif len(matches) == 0 {\n\t\treturn \"\", fmt.Errorf(\"subdir %q not found\", subDir)\n\t}\n\n\tif len(matches) > 1 {\n\t\treturn \"\", fmt.Errorf(\"subdir %q matches multiple paths\", subDir)\n\t}\n\n\treturn matches[0], nil\n}", "is_vulnerable": 1}
{"code": "func TestInvalidMultipartCT(t *testing.T) {\n\tpayload := strings.TrimSpace(`\n-----------------------------9051914041544843365972754266\nContent-Disposition: form-data; name=\"text\"\n\ntext default\n-----------------------------9051914041544843365972754266\n`)\n\tmp := multipartProcessor(t)\n\tv := corazawaf.NewTransactionVariables()\n\tif err := mp.ProcessRequest(strings.NewReader(payload), v, plugintypes.BodyProcessorOptions{\n\t\tMime: \"multipart/form-data; boundary=---------------------------9051914041544843365972754266; a=1; a=2\",\n\t}); err == nil {\n\t\tt.Error(\"multipart processor should fail for invalid content-type\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Mount(ctx context.Context, in *sliverpb.MountReq, opts ...grpc.CallOption) (*sliverpb.Mount, error) {\n\tout := new(sliverpb.Mount)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Mount\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tindex := sort.Search(len(res.hashes[i]), func(k int) bool {\n\t\t\t\t\tcmp := res.hashes[i][k].Big().Cmp(last)\n\t\t\t\t\tif cmp >= 0 {\n\t\t\t\t\t\tres.cont = false\n\t\t\t\t\t}\n\t\t\t\t\treturn cmp > 0\n\t\t\t\t})\n\t\t\t\tif index >= 0 {\n\t\t\t\t\t// cut off excess\n\t\t\t\t\tres.hashes[i] = res.hashes[i][:index]\n\t\t\t\t\tres.slots[i] = res.slots[i][:index]\n\t\t\t\t}\n\t\t\t\t// Forward the relevant storage chunk (even if created just now)\n\t\t\t\tif res.cont {\n\t\t\t\t\tres.subTask.Next = incHash(res.hashes[i][len(res.hashes[i])-1])\n\t\t\t\t} else {\n\t\t\t\t\tres.subTask.done = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// Iterate over all the complete contracts, reconstruct the trie nodes and\n\t\t// push them to disk. If the contract is chunked, the trie nodes will be\n\t\t// reconstructed later.\n\t\tslots += len(res.hashes[i])\n\n\t\tif i < len(res.hashes)-1 || res.subTask == nil {\n\t\t\t// no need to make local reassignment of account: this closure does not outlive the loop\n\t\t\tvar tr genTrie\n\t\t\tif s.scheme == rawdb.HashScheme {\n\t\t\t\ttr = newHashTrie(batch)\n\t\t\t}\n\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t// Keep the left boundary as it's complete\n\t\t\t\ttr = newPathTrie(account, false, s.db, batch)\n\t\t\t}\n\t\t\tfor j := 0; j < len(res.hashes[i]); j++ {\n\t\t\t\ttr.update(res.hashes[i][j][:], res.slots[i][j])\n\t\t\t}\n\t\t\ttr.commit(true)\n\t\t}\n\t\t// Persist the received storage segments. These flat state maybe\n\t\t// outdated during the sync, but it can be fixed later during the\n\t\t// snapshot generation.\n\t\tfor j := 0; j < len(res.hashes[i]); j++ {\n\t\t\trawdb.WriteStorageSnapshot(batch, account, res.hashes[i][j], res.slots[i][j])\n\n\t\t\t// If we're storing large contracts, generate the trie nodes\n\t\t\t// on the fly to not trash the gluing points\n\t\t\tif i == len(res.hashes)-1 && res.subTask != nil {\n\t\t\t\tres.subTask.genTrie.update(res.hashes[i][j][:], res.slots[i][j])\n\t\t\t}\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func Openat(dir *os.File, path string, flags int, mode uint32) (*os.File, error) {\n\tdirFd, fullPath := prepareAt(dir, path)\n\tfd, err := unix.Openat(dirFd, path, flags, mode)\n\tif err != nil {\n\t\treturn nil, &os.PathError{Op: \"openat\", Path: fullPath, Err: err}\n\t}\n\truntime.KeepAlive(dir)\n\treturn os.NewFile(uintptr(fd), fullPath), nil\n}", "is_vulnerable": 0}
{"code": "\t\twriteTxLookupEntries func(ethdb.Writer, *types.Block)\n\t}{\n\t\t{\n\t\t\t\"DatabaseV6\",\n\t\t\tfunc(db ethdb.Writer, block *types.Block) {\n\t\t\t\tWriteTxLookupEntries(db, block)\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"DatabaseV4-V5\",\n\t\t\tfunc(db ethdb.Writer, block *types.Block) {\n\t\t\t\tfor _, tx := range block.Transactions() {\n\t\t\t\t\tdb.Put(txLookupKey(tx.Hash()), block.Hash().Bytes())\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"DatabaseV3\",\n\t\t\tfunc(db ethdb.Writer, block *types.Block) {\n\t\t\t\tfor index, tx := range block.Transactions() {\n\t\t\t\t\tentry := LegacyTxLookupEntry{\n\t\t\t\t\t\tBlockHash:  block.Hash(),\n\t\t\t\t\t\tBlockIndex: block.NumberU64(),\n\t\t\t\t\t\tIndex:      uint64(index),\n\t\t\t\t\t}\n\t\t\t\t\tdata, _ := rlp.EncodeToBytes(entry)\n\t\t\t\t\tdb.Put(txLookupKey(tx.Hash()), data)\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdb := NewMemoryDatabase()\n\n\t\t\ttx1 := types.NewTransaction(1, common.BytesToAddress([]byte{0x11}), big.NewInt(111), 1111, big.NewInt(11111), []byte{0x11, 0x11, 0x11})\n\t\t\ttx2 := types.NewTransaction(2, common.BytesToAddress([]byte{0x22}), big.NewInt(222), 2222, big.NewInt(22222), []byte{0x22, 0x22, 0x22})\n\t\t\ttx3 := types.NewTransaction(3, common.BytesToAddress([]byte{0x33}), big.NewInt(333), 3333, big.NewInt(33333), []byte{0x33, 0x33, 0x33})\n\t\t\ttxs := []*types.Transaction{tx1, tx2, tx3}\n\n\t\t\tblock := types.NewBlock(&types.Header{Number: big.NewInt(314)}, txs, nil, nil, newHasher())\n\n\t\t\t// Check that no transactions entries are in a pristine database\n\t\t\tfor i, tx := range txs {\n\t\t\t\tif txn, _, _, _ := ReadTransaction(db, tx.Hash()); txn != nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: non existent transaction returned: %v\", i, tx.Hash(), txn)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Insert all the transactions into the database, and verify contents\n\t\t\tWriteCanonicalHash(db, block.Hash(), block.NumberU64())\n\t\t\tWriteBlock(db, block)\n\t\t\ttc.writeTxLookupEntries(db, block)\n\n\t\t\tfor i, tx := range txs {\n\t\t\t\tif txn, hash, number, index := ReadTransaction(db, tx.Hash()); txn == nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: transaction not found\", i, tx.Hash())\n\t\t\t\t} else {\n\t\t\t\t\tif hash != block.Hash() || number != block.NumberU64() || index != uint64(i) {\n\t\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: positional metadata mismatch: have %x/%d/%d, want %x/%v/%v\", i, tx.Hash(), hash, number, index, block.Hash(), block.NumberU64(), i)\n\t\t\t\t\t}\n\t\t\t\t\tif tx.Hash() != txn.Hash() {\n\t\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: transaction mismatch: have %v, want %v\", i, tx.Hash(), txn, tx)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Delete the transactions and check purge\n\t\t\tfor i, tx := range txs {\n\t\t\t\tDeleteTxLookupEntry(db, tx.Hash())\n\t\t\t\tif txn, _, _, _ := ReadTransaction(db, tx.Hash()); txn != nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: deleted transaction returned: %v\", i, tx.Hash(), txn)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (*cacheClient) Scan(ctx context.Context, match string) (cache.Iterator, error) {\n\treturn cache.LayerCache().Scan(ctx, match)\n}", "is_vulnerable": 0}
{"code": "func (j *jwtTokenAuthenticator) AuthenticateToken(ctx context.Context, tokenData string) (*authenticator.Response, bool, error) {\n\tif !j.hasCorrectIssuer(tokenData) {\n\t\treturn nil, false, nil\n\t}\n\n\ttok, err := jwt.ParseSigned(tokenData)\n\tif err != nil {\n\t\treturn nil, false, nil\n\t}\n\n\tpublic := &jwt.Claims{}\n\tprivate := j.validator.NewPrivateClaims()\n\n\t// TODO: Pick the key that has the same key ID as `tok`, if one exists.\n\tvar (\n\t\tfound   bool\n\t\terrlist []error\n\t)\n\tfor _, key := range j.keys {\n\t\tif err := tok.Claims(key, public, private); err != nil {\n\t\t\terrlist = append(errlist, err)\n\t\t\tcontinue\n\t\t}\n\t\tfound = true\n\t\tbreak\n\t}\n\n\tif !found {\n\t\treturn nil, false, utilerrors.NewAggregate(errlist)\n\t}\n\n\t// sanity check issuer since we parsed it out before signature validation\n\tif !j.issuers[public.Issuer] {\n\t\treturn nil, false, fmt.Errorf(\"token issuer %q is invalid\", public.Issuer)\n\t}\n\n\ttokenAudiences := authenticator.Audiences(public.Audience)\n\tif len(tokenAudiences) == 0 {\n\t\t// only apiserver audiences are allowed for legacy tokens\n\t\taudit.AddAuditAnnotation(ctx, \"authentication.k8s.io/legacy-token\", public.Subject)\n\t\tlegacyTokensTotal.WithContext(ctx).Inc()\n\t\ttokenAudiences = j.implicitAuds\n\t}\n\n\trequestedAudiences, ok := authenticator.AudiencesFrom(ctx)\n\tif !ok {\n\t\t// default to apiserver audiences\n\t\trequestedAudiences = j.implicitAuds\n\t}\n\n\tauds := authenticator.Audiences(tokenAudiences).Intersect(requestedAudiences)\n\tif len(auds) == 0 && len(j.implicitAuds) != 0 {\n\t\treturn nil, false, fmt.Errorf(\"token audiences %q is invalid for the target audiences %q\", tokenAudiences, requestedAudiences)\n\t}\n\n\t// If we get here, we have a token with a recognized signature and\n\t// issuer string.\n\tsa, err := j.validator.Validate(ctx, tokenData, public, private)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\n\treturn &authenticator.Response{\n\t\tUser:      sa.UserInfo(),\n\t\tAudiences: auds,\n\t}, true, nil\n}", "is_vulnerable": 0}
{"code": "func (c *repositoryClient) PushSignature(ctx context.Context, mediaType string, blob []byte, subject ocispec.Descriptor, annotations map[string]string) (blobDesc, manifestDesc ocispec.Descriptor, err error) {\n\treturn ocispec.Descriptor{}, ocispec.Descriptor{}, fmt.Errorf(\"push signature is not implemented\")\n}", "is_vulnerable": 0}
{"code": "func main() {\n\tif reexec.Init() {\n\t\treturn\n\t}\n\n\tsigs := make(chan os.Signal, 1)\n\tsignal.Notify(sigs, syscall.SIGTERM)\n\tgo func() {\n\t\t<-sigs\n\t\tfmt.Println(\"Error: received unexpected terminate signal\")\n\t\tos.Exit(1)\n\t}()\n\n\tlogs.InitLogs()\n\tdefer logs.FlushLogs()\n\tdefer serviceability.BehaviorOnPanic(os.Getenv(\"OPENSHIFT_ON_PANIC\"), version.Get())()\n\tdefer serviceability.Profile(os.Getenv(\"OPENSHIFT_PROFILE\")).Stop()\n\n\trand.Seed(time.Now().UTC().UnixNano())\n\tif len(os.Getenv(\"GOMAXPROCS\")) == 0 {\n\t\truntime.GOMAXPROCS(runtime.NumCPU())\n\t}\n\n\tconst tlsCertRoot = \"/etc/pki/tls/certs\"\n\tconst runtimeCertRoot = \"/etc/docker/certs.d\"\n\n\tclusterCASrc := fmt.Sprintf(\"%s/ca.crt\", builder.SecretCertsMountPath)\n\tclusterCADst := fmt.Sprintf(\"%s/cluster.crt\", tlsCertRoot)\n\terr := CopyFileIfExists(clusterCASrc, clusterCADst)\n\tif err != nil {\n\t\tfmt.Printf(\"Error setting up cluster CA cert: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\truntimeCASrc := fmt.Sprintf(\"%s/certs.d\", builder.ConfigMapCertsMountPath)\n\terr = CopyDirIfExists(runtimeCASrc, runtimeCertRoot)\n\tif err != nil {\n\t\tfmt.Printf(\"Error setting up service CA cert: %v\", err)\n\t\tos.Exit(1)\n\t}\n\n\tbasename := filepath.Base(os.Args[0])\n\tcommand := CommandFor(basename)\n\tif err := command.Execute(); err != nil {\n\t\tos.Exit(1)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (a *Assertions) Same(expected interface{}, actual interface{}, msgAndArgs ...interface{}) bool {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn Same(a.t, expected, actual, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func (k *Key) CanAuthenticate() bool {\n\treturn C.key_can_authenticate(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "func TestCachedCheckDatastoreQueryCount(t *testing.T) {\n\tt.Parallel()\n\n\tds := memory.New()\n\tdefer ds.Close()\n\n\tstoreID := ulid.Make().String()\n\n\terr := ds.Write(context.Background(), storeID, nil, []*openfgav1.TupleKey{\n\t\ttuple.NewTupleKey(\"document:x\", \"a\", \"user:jon\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"a\", \"user:maria\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"b\", \"user:maria\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"parent\", \"org:fga\"),\n\t\ttuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t})\n\trequire.NoError(t, err)\n\n\tmodel := testutils.MustTransformDSLToProtoWithID(`model\n\tschema 1.1\ntype user\n\ntype org\n  relations\n\tdefine member: [user]\n\ntype document\n  relations\n\tdefine a: [user]\n\tdefine b: [user]\n\tdefine union: a or b\n\tdefine union_rewrite: union\n\tdefine intersection: a and b\n\tdefine difference: a but not b\n\tdefine ttu: member from parent\n\tdefine union_and_ttu: union and ttu\n\tdefine union_or_ttu: union or ttu or union_rewrite\n\tdefine intersection_of_ttus: union_or_ttu and union_and_ttu\n\tdefine parent: [org]`)\n\n\tctx := typesystem.ContextWithTypesystem(\n\t\tcontext.Background(),\n\t\ttypesystem.New(model),\n\t)\n\n\tctx = storage.ContextWithRelationshipTupleReader(ctx, ds)\n\n\tcheckCache := ccache.New(\n\t\tccache.Configure[*ResolveCheckResponse]().MaxSize(100),\n\t)\n\tdefer checkCache.Stop()\n\n\tcachedCheckResolver := NewCachedCheckResolver(\n\t\tWithExistingCache(checkCache),\n\t\tWithCacheTTL(10*time.Hour),\n\t)\n\tdefer cachedCheckResolver.Close()\n\n\t// Running the first check\n\tlocalCheckResolver := NewLocalChecker(\n\t\tWithMaxConcurrentReads(1),\n\t)\n\tdefer localCheckResolver.Close()\n\n\tcachedCheckResolver.SetDelegate(localCheckResolver)\n\tlocalCheckResolver.SetDelegate(cachedCheckResolver)\n\n\tres, err := cachedCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(1), res.GetResolutionMetadata().DatastoreQueryCount)\n\n\tres, err = cachedCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(0), res.GetResolutionMetadata().DatastoreQueryCount)\n\n\t// The ttuLocalChecker will use partial result from the cache and partial result from the local checker\n\n\tttuLocalChecker := NewLocalChecker(\n\t\tWithMaxConcurrentReads(1),\n\t)\n\tttuLocalChecker.SetDelegate(cachedCheckResolver)\n\n\tres, err = ttuLocalChecker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"document:x\", \"ttu\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\tttuLocalChecker.Close()\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(1), res.GetResolutionMetadata().DatastoreQueryCount)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) GetCredsByHashType(ctx context.Context, in *clientpb.Credential, opts ...grpc.CallOption) (*clientpb.Credentials, error) {\n\tout := new(clientpb.Credentials)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetCredsByHashType\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func New(\n\tlocalGRPCAddress string,\n\tlocalHTTPAddress string,\n\tfileManager *filemgr.Manager,\n\treproxyHandler *reproxy.Handler,\n) *Builder {\n\treturn &Builder{\n\t\tlocalGRPCAddress: localGRPCAddress,\n\t\tlocalHTTPAddress: localHTTPAddress,\n\t\tfilemgr:          fileManager,\n\t\treproxy:          reproxyHandler,\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestValidateTrustedIdentities(t *testing.T) {\n\n\t// No trusted identity prefix throws error\n\tpolicyDoc := dummyPolicyDocument()\n\tpolicyStatement := dummyPolicyStatement()\n\tpolicyStatement.TrustedIdentities = []string{\"C=US, ST=WA, O=wabbit-network.io, OU=org1\"}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr := policyDoc.Validate()\n\tif err == nil || err.Error() != \"trust policy statement \\\"test-statement-name\\\" has trusted identity \\\"C=US, ST=WA, O=wabbit-network.io, OU=org1\\\" missing separator\" {\n\t\tt.Fatalf(\"trusted identity without separator should return error\")\n\t}\n\n\t// Accept unknown identity prefixes\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tpolicyStatement.TrustedIdentities = []string{\"unknown:my-trusted-idenity\"}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"unknown identity prefix should not return an error. Error: %q\", err)\n\t}\n\n\t// Validate x509.subject identities\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN := \"x509.subject:,,,\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"parsing distinguished name (DN) \\\",,,\\\" failed with err: incomplete type, value pair. A valid DN must contain 'C', 'ST', and 'O' RDN attributes at a minimum, and follow RFC 4514 standard\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// Validate duplicate RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN = \"x509.subject:C=US,C=IN\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US,C=IN\\\" has duplicate RDN attribute for \\\"C\\\", DN can only have unique RDN attributes\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// Validate mandatory RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN = \"x509.subject:C=US,ST=WA\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US,ST=WA\\\" has no mandatory RDN attribute for \\\"O\\\", it must contain 'C', 'ST', and 'O' RDN attributes at a minimum\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// DN may have optional RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN := \"x509.subject:C=US,ST=WA,O=MyOrg,CustomRDN=CustomValue\"\n\tpolicyStatement.TrustedIdentities = []string{validDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"valid x509.subject identity should not return error. Error : %q\", err)\n\t}\n\n\t// Validate rfc4514 DNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN1 := \"x509.subject:C=US,ST=WA,O=MyOrg\"\n\tvalidDN2 := \"x509.subject:C=US,ST=WA,O=  My.  Org\"\n\tvalidDN3 := \"x509.subject:C=US,ST=WA,O=My \\\"special\\\" Org \\\\, \\\\; \\\\\\\\ others\"\n\tpolicyStatement.TrustedIdentities = []string{validDN1, validDN2, validDN3}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"valid x509.subject identity should not return error. Error : %q\", err)\n\t}\n\n\t// Validate overlapping DNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN1 = \"x509.subject:C=US,ST=WA,O=MyOrg\"\n\tvalidDN2 = \"x509.subject:C=US,ST=WA,O=MyOrg,X=Y\"\n\tpolicyStatement.TrustedIdentities = []string{validDN1, validDN2}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"trust policy statement \\\"test-statement-name\\\" has overlapping x509 trustedIdentities, \\\"x509.subject:C=US,ST=WA,O=MyOrg\\\" overlaps with \\\"x509.subject:C=US,ST=WA,O=MyOrg,X=Y\\\"\" {\n\t\tt.Fatalf(\"overlapping DNs should return error\")\n\t}\n\n\t// Validate multi-valued RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tmultiValduedRDN := \"x509.subject:C=US+ST=WA,O=MyOrg\"\n\tpolicyStatement.TrustedIdentities = []string{multiValduedRDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US+ST=WA,O=MyOrg\\\" has multi-valued RDN attributes, remove multi-valued RDN attributes as they are not supported\" {\n\t\tt.Fatalf(\"multi-valued RDN should return error. Error : %q\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestSupported(t *testing.T) {\n\tvar scenarios = []struct {\n\t\tplatform platforms.Platform\n\t\twant     bool\n\t}{\n\t\t{platforms.Kubernetes, true},\n\t\t{platforms.Standalone, true},\n\t\t{platforms.DockerCompose, true},\n\t}\n\n\tfor _, scenario := range scenarios {\n\t\tt.Run(fmt.Sprintf(\"Platform %s should be supported\", scenario.platform), func(t *testing.T) {\n\t\t\ttarget := NewInstances(scenario.platform, nil, \"\")\n\t\t\tisSupported := target.Supported()\n\t\t\tassert.Equal(t, scenario.want, isSupported)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *SshExecutor) DeviceTeardown(host, device, vgid string) error {\n\n\t// Setup commands\n\tcommands := []string{\n\t\tfmt.Sprintf(\"vgremove %v\", s.vgName(vgid)),\n\t\tfmt.Sprintf(\"pvremove '%v'\", device),\n\t}\n\n\t// Execute command\n\t_, err := s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\tlogger.LogError(\"Error while deleting device %v on %v with id %v\",\n\t\t\tdevice, host, vgid)\n\t}\n\n\tcommands = []string{\n\t\tfmt.Sprintf(\"ls %v/%v\", rootMountPoint, s.vgName(vgid)),\n\t}\n\t_, err = s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tcommands = []string{\n\t\tfmt.Sprintf(\"rmdir %v/%v\", rootMountPoint, s.vgName(vgid)),\n\t}\n\n\t_, err = s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\tlogger.LogError(\"Error while removing the VG directory\")\n\t\treturn nil\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func FsDirs(c *gin.Context) {\n\tvar req DirReq\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tcommon.ErrorResp(c, err, 400)\n\t\treturn\n\t}\n\tuser := c.MustGet(\"user\").(*model.User)\n\tvar reqPath string\n\tif req.ForceRoot {\n\t\tif !user.IsAdmin() {\n\t\t\tcommon.ErrorStrResp(c, \"Permission denied\", 403)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\ttmp, err := user.JoinPath(req.Path)\n\t\tif err != nil {\n\t\t\tcommon.ErrorResp(c, err, 403)\n\t\t\treturn\n\t\t}\n\t\treqPath = tmp\n\t}\n\tmeta, err := db.GetNearestMeta(reqPath)\n\tif err != nil {\n\t\tif !errors.Is(errors.Cause(err), errs.MetaNotFound) {\n\t\t\tcommon.ErrorResp(c, err, 500, true)\n\t\t\treturn\n\t\t}\n\t}\n\tc.Set(\"meta\", meta)\n\tif !common.CanAccess(user, meta, reqPath, req.Password) {\n\t\tcommon.ErrorStrResp(c, \"password is incorrect\", 403)\n\t\treturn\n\t}\n\tobjs, err := fs.List(c, reqPath)\n\tif err != nil {\n\t\tcommon.ErrorResp(c, err, 500)\n\t\treturn\n\t}\n\tdirs := filterDirs(objs)\n\tcommon.SuccessResp(c, dirs)\n}", "is_vulnerable": 0}
{"code": "func (query *ExpandQuery) resolveUserset(\n\tctx context.Context,\n\tstore, modelID string,\n\tuserset *openfgapb.Userset,\n\ttk *openfgapb.TupleKey,\n\tmetadata *utils.ResolutionMetadata,\n) (*openfgapb.UsersetTree_Node, error) {\n\tctx, span := query.tracer.Start(ctx, \"resolveUserset\")\n\tdefer span.End()\n\n\tswitch us := userset.Userset.(type) {\n\tcase nil, *openfgapb.Userset_This:\n\t\treturn query.resolveThis(ctx, store, tk, metadata)\n\tcase *openfgapb.Userset_ComputedUserset:\n\t\treturn query.resolveComputedUserset(ctx, us.ComputedUserset, tk, metadata)\n\tcase *openfgapb.Userset_TupleToUserset:\n\t\treturn query.resolveTupleToUserset(ctx, store, modelID, us.TupleToUserset, tk, metadata)\n\tcase *openfgapb.Userset_Union:\n\t\treturn query.resolveUnionUserset(ctx, store, modelID, us.Union, tk, metadata)\n\tcase *openfgapb.Userset_Difference:\n\t\treturn query.resolveDifferenceUserset(ctx, store, modelID, us.Difference, tk, metadata)\n\tcase *openfgapb.Userset_Intersection:\n\t\treturn query.resolveIntersectionUserset(ctx, store, modelID, us.Intersection, tk, metadata)\n\tdefault:\n\t\treturn nil, serverErrors.UnsupportedUserSet\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestCheckQuery(t *testing.T, datastore storage.OpenFGADatastore) {\n\tvar tests = []struct {\n\t\tname             string\n\t\ttypeDefinitions  []*openfgapb.TypeDefinition\n\t\ttuples           []*openfgapb.TupleKey\n\t\tresolveNodeLimit uint32\n\t\trequest          *openfgapb.CheckRequest\n\t\terr              error\n\t\tresponse         *openfgapb.CheckResponse\n\t}{\n\t\t{\n\t\t\tname: \"ExecuteWithEmptyTupleKey\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType:      \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{},\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.InvalidCheckInput,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithEmptyObject\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType:      \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"\", \"reader\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.InvalidCheckInput,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithEmptyRelation\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType:      \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.InvalidCheckInput,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithEmptyUser\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType:      \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.InvalidCheckInput,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithRequestRelationInexistentInTypeDefinition\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType:      \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"inexistent\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.RelationNotFound(\"inexistent\", \"repo\", tuple.NewTupleKey(\"repo:openfga/openfga\", \"inexistent\", \"someUser\")),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteFailsWithInvalidUser\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"john:albert:doe\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.InvalidUser(\"john:albert:doe\"),\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsErrorNotStackOverflowForInfinitelyRecursiveResolution\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\tRelation: \"reader\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.AuthorizationModelResolutionTooComplex,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsResolutionTooComplexErrorForComplexResolution\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t},\n\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\tRelation: \"reader\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tresolveNodeLimit: 2,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"writer\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.AuthorizationModelResolutionTooComplex,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsResolutionTooComplexErrorForComplexUnionResolution\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t},\n\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t\tresolveNodeLimit: 2,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"someUser\"),\n\t\t\t},\n\t\t\t// output\n\t\t\terr: serverErrors.AuthorizationModelResolutionTooComplex,\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithExistingTupleKeyAndEmptyUserSetReturnsAllowed\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithAllowAllTupleKeyAndEmptyUserSetReturnsAllowed\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"*\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithNonExistingTupleKeyAndEmptyUserSetReturnsNotAllowed\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples:           []*openfgapb.TupleKey{},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithUnionAndDirectUserSetReturnsAllowedIfDirectTupleExists\",\n\t\t\t// state\n\t\t\t//relation {\n\t\t\t//\tname: \"admin\"\n\t\t\t//\tuserset_rewrite {\n\t\t\t//\t\tchild { _this {  }}\n\t\t\t//\t}\n\t\t\t//}\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{\n\t\t\t\t\t\t\t\t\tThis: &openfgapb.DirectUserset{},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.0(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithUnionAndDirectUserSetReturnsAllowedIfAllUsersTupleExists\",\n\t\t\t// state\n\t\t\t//relation {\n\t\t\t//\tname: \"admin\"\n\t\t\t//\tuserset_rewrite {\n\t\t\t//\t\tchild { _this {  }}\n\t\t\t//\t}\n\t\t\t//}\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{\n\t\t\t\t\t\t\t\t\tThis: &openfgapb.DirectUserset{},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"*\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.0(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithUnionAndComputedUserSetReturnsNotAllowedIfComputedUsersetDoesNotIncludeUser\",\n\t\t\t// state\n\t\t\t//relation {\n\t\t\t//\tname: \"admin\"\n\t\t\t//\tuserset_rewrite {\n\t\t\t//    child { computed_userset { relation: \"owner\" }}\n\t\t\t//\t}\n\t\t\t//}\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"owner\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"owner\", \"team/iam\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteWithUnionAndComputedUserSetReturnsAllowedIfComputedUsersetIncludesUser\",\n\t\t\t// state\n\t\t\t//relation {\n\t\t\t//\tname: \"reader\"\n\t\t\t//\tuserset_rewrite {\n\t\t\t//    child { _this {  }}\n\t\t\t//    child { computed_userset { relation: \"writer\" }}\n\t\t\t//\t}\n\t\t\t//}\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"writer\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"writer\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.1(computed-userset).repo:openfga/openfga#writer.(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteDirectSetReturnsAllowedIfUserHasRelationWithAnObjectThatHasUserAccessToTheTargetObject\",\n\t\t\t// state\n\t\t\t//relation {\n\t\t\t//\tname: \"reader\"\n\t\t\t//\tuserset_rewrite {\n\t\t\t//    child { _this {  }}\n\t\t\t//\t}\n\t\t\t//}\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, {\n\t\t\t\tType: \"team\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"team_member\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"team_member\", \"github|jose@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"team:iam#team_member\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".(direct).team:iam#team_member.(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsAllowedIfUserIsHasRelationToAnObjectThatIsInComputedUserSetForAnotherObject\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"repo\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"writer\": {},\n\t\t\t\t},\n\t\t\t}, {\n\t\t\t\tType: \"team\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"team_member\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"team_member\", \"github|jose@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"writer\", \"team:iam#team_member\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.1(computed-userset).repo:openfga/openfga#writer.(direct).team:iam#team_member.(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsNotAllowedIfIntersectionIsRequiredAndUserIsInOneUserSetButNotTheOther\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"openfga-store\",\n\t\t\t\t// pretend you can only create an organization user in an openfga store if\n\t\t\t\t// you can create a user AND write an organization in a store\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"create_organization_user\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"create_user\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"write_organization\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"create_user\":        {},\n\t\t\t\t\t\"write_organization\": {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_user\", \"github|yenkel@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_organization_user\", \"github|yenkel@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsAllowedIfIntersectionIsRequiredAndUserIsInAllUserSets\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"openfga-store\",\n\t\t\t\t// pretend you can only create an organization user in an openfga store if\n\t\t\t\t// you can create a user AND write an organization in a store\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"create_organization_user\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"create_user\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"write_organization\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"write_organization\": {},\n\t\t\t\t\t\"create_user\":        {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_user\", \"github|yenkel@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"write_organization\", \"github|yenkel@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_organization_user\", \"github|yenkel@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".[.0(computed-userset).openfga-store:yenkel-dev#create_user.(direct).,.1(computed-userset).openfga-store:yenkel-dev#write_organization.(direct).]\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteSupportsNestedIntersectionAndCorrectlyTraces\",\n\t\t\t// state\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{{\n\t\t\t\tType: \"openfga-store\",\n\t\t\t\t// pretend you can only create an organization user in an openfga store if\n\t\t\t\t// you can create a user AND write an organization in a store\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"create_organization_user\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"create_user\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"write_organization\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"create_user\": {\n\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"create_user_a\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"create_user_b\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t\"write_organization\": {},\n\t\t\t\t\t\"create_user_a\":      {},\n\t\t\t\t\t\"create_user_b\":      {},\n\t\t\t\t},\n\t\t\t}},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_user_a\", \"github|yenkel@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_user_b\", \"github|yenkel@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"write_organization\", \"github|yenkel@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\t// input\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"openfga-store:yenkel-dev\", \"create_organization_user\", \"github|yenkel@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\t// output\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".[.0(computed-userset).openfga-store:yenkel-dev#create_user.[.0(computed-userset).openfga-store:yenkel-dev#create_user.0(computed-userset).openfga-store:yenkel-dev#create_user_a.(direct).,.0(computed-userset).openfga-store:yenkel-dev#create_user.1(computed-userset).openfga-store:yenkel-dev#create_user_b.(direct).],.1(computed-userset).openfga-store:yenkel-dev#write_organization.(direct).]\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsAllowedForUserNotRemovedByDifference\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"banned\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"banned\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"admin\", \"github|jon.allie@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"banned\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/canaveral\", \"admin\", \"github|jon.allie@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".0(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsNotAllowedForUserRemovedByDifference\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"banned\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"banned\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"admin\", \"github|jon.allie@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"banned\", \"github|jon.allie@openfga\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"banned\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/canaveral\", \"admin\", \"github|jon.allie@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteReturnsAllowedForTupleToUserset\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"manager\": typesystem.This(),\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_TupleToUserset{TupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t// implicit direct?\n\t\t\t\t\t\t\"repo_admin\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/canaveral\", \"manager\", \"org:openfga#repo_admin\"),\n\t\t\t\ttuple.NewTupleKey(\"org:openfga\", \"repo_admin\", \"github|jose@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/canaveral\", \"admin\", \"github|jose@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.1(tuple-to-userset).repo:openfga/canaveral#manager.org:openfga#repo_admin.(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteCanResolveRecursiveComputedUserSets\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_TupleToUserset{TupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"maintainer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"maintainer\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_TupleToUserset{TupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"repo_writer\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"triager\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"reader\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"triager\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_TupleToUserset{TupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"repo_reader\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"team\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\", \"writer\", \"team:openfga#member\"),\n\t\t\t\ttuple.NewTupleKey(\"team:openfga\", \"member\", \"github|iaco@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga/openfga\", \"reader\", \"github|iaco@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.1(computed-userset).repo:openfga/openfga#triager.union.1(computed-userset).repo:openfga/openfga#writer.union.0(direct).team:openfga#member.(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"ExecuteCanResolveRecursiveTupleToUserSets\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\"owner\":  {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\"editor\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{Child: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_ComputedUserset{ComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"editor\",\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t\t{Userset: &openfgapb.Userset_TupleToUserset{TupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"parent\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\tRelation: \"viewer\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}}},\n\t\t\t\t\t\t\t\t}},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:octo_v2_draft\", \"parent\", \"document:octo_folder\"),\n\t\t\t\ttuple.NewTupleKey(\"document:octo_folder\", \"editor\", \"google|iaco@openfga\"),\n\t\t\t},\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:octo_v2_draft\", \"viewer\", \"google|iaco@openfga\"),\n\t\t\t\tTrace:    true,\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed:    true,\n\t\t\t\tResolution: \".union.2(tuple-to-userset).document:octo_v2_draft#parent.document:octo_folder#viewer.union.1(computed-userset).document:octo_folder#editor.union.0(direct).\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"CheckWithUsersetAsUser\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"team:iam\", \"member\", \"org:openfga#member\"),\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"team\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"member\", \"team:engineering#member\"),\n\t\t\t\ttuple.NewTupleKey(\"team:engineering\", \"member\", \"org:openfga#member\"),\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"CheckUsersetAsUser_WithContextualTuples\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"team:iam\", \"member\", \"org:openfga#member\"),\n\t\t\t\tContextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\t\tTupleKeys: []*openfgapb.TupleKey{\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"member\", \"team:engineering#member\"),\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:engineering\", \"member\", \"org:openfga#member\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"team\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"CheckUsersetAsUser_WithContextualTuples\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"team:iam\", \"member\", \"org:openfga#member\"),\n\t\t\t\tContextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\t\tTupleKeys: []*openfgapb.TupleKey{\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"member\", \"team:engineering#member\"),\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:engineering\", \"member\", \"org:openfga#member\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"team\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"CheckUsersetAsUser_WithContextualTuples\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"team:iam\", \"member\", \"org:openfga#member\"),\n\t\t\t\tContextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\t\tTupleKeys: []*openfgapb.TupleKey{\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:iam\", \"member\", \"team:engineering#member\"),\n\t\t\t\t\t\ttuple.NewTupleKey(\"team:engineering\", \"member\", \"org:openfga#member\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"team\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"member\": {Userset: &openfgapb.Userset_This{}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"Check with TupleToUserset involving no object or userset\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:doc1\", \"viewer\", \"anne\"),\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleset:        &openfgapb.ObjectRelation{Relation: \"parent\"},\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{Relation: \"viewer\"},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"folder\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"folder1\"), // folder1 isn't an object or userset\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"anne\"),\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"TupleToUserset Check Passes when at least one tupleset relation resolves\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:doc1\", \"viewer\", \"anne\"),\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleset:        &openfgapb.ObjectRelation{Relation: \"parent\"},\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{Relation: \"viewer\"},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"folder\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"folder1\"), // folder1 isn't an object or userset\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"folder:folder1\"),\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"anne\"),\n\t\t\t},\n\t\t\tresponse: &openfgapb.CheckResponse{\n\t\t\t\tAllowed: true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:             \"Error if * encountered in TupleToUserset evaluation\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:doc1\", \"viewer\", \"user:anne\"),\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\"viewer\": typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t},\n\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\ttypesystem.RelationReference(\"folder\", \"\"),\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"folder\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t\t},\n\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\ttypesystem.RelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"*\"), // wildcard not allowed on tupleset relations\n\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:anne\"),\n\t\t\t},\n\t\t\terr: serverErrors.InvalidTuple(\n\t\t\t\t\"unexpected wildcard evaluated on relation 'document#parent'\",\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", commands.Wildcard),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname:             \"Error if * encountered in TTU evaluation including ContextualTuples\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:doc1\", \"viewer\", \"user:anne\"),\n\t\t\t\tContextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\t\tTupleKeys: []*openfgapb.TupleKey{\n\t\t\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", \"*\"), // wildcard not allowed on tupleset relations\n\t\t\t\t\t\ttuple.NewTupleKey(\"folder:folder1\", \"viewer\", \"user:anne\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\"viewer\": typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t},\n\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\"parent\": {\n\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\ttypesystem.RelationReference(\"folder\", \"\"),\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"folder\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t\t},\n\t\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\t\ttypesystem.RelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidTuple(\n\t\t\t\t\"unexpected wildcard evaluated on relation 'document#parent'\",\n\t\t\t\ttuple.NewTupleKey(\"document:doc1\", \"parent\", commands.Wildcard),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\tname:             \"Error if rewrite encountered in tupleset relation\",\n\t\t\tresolveNodeLimit: defaultResolveNodeLimit,\n\t\t\trequest: &openfgapb.CheckRequest{\n\t\t\t\tTupleKey:         tuple.NewTupleKey(\"document:doc1\", \"viewer\", \"anne\"),\n\t\t\t\tContextualTuples: &openfgapb.ContextualTupleKeys{},\n\t\t\t},\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": typesystem.ComputedUserset(\"editor\"),\n\t\t\t\t\t\t\"editor\": typesystem.This(),\n\t\t\t\t\t\t\"viewer\": typesystem.TupleToUserset(\"parent\", \"viewer\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\terr: serverErrors.InvalidAuthorizationModelInput(\n\t\t\t\terrors.New(\"unexpected rewrite on relation 'document#parent'\"),\n\t\t\t),\n\t\t},\n\t}\n\n\tctx := context.Background()\n\ttracer := telemetry.NewNoopTracer()\n\tmeter := telemetry.NewNoopMeter()\n\tlogger := logger.NewNoopLogger()\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tstore := ulid.Make().String()\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              ulid.Make().String(),\n\t\t\t\tSchemaVersion:   typesystem.SchemaVersion1_0,\n\t\t\t\tTypeDefinitions: test.typeDefinitions,\n\t\t\t}\n\n\t\t\terr := datastore.WriteAuthorizationModel(ctx, store, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\tif test.tuples != nil {\n\t\t\t\terr := datastore.Write(ctx, store, nil, test.tuples)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\n\t\t\tcmd := commands.NewCheckQuery(datastore, tracer, meter, logger, test.resolveNodeLimit)\n\t\t\ttest.request.StoreId = store\n\t\t\ttest.request.AuthorizationModelId = model.Id\n\t\t\tresp, gotErr := cmd.Execute(ctx, test.request)\n\n\t\t\trequire.ErrorIs(t, gotErr, test.err)\n\n\t\t\tif test.response != nil {\n\t\t\t\trequire.NoError(t, gotErr)\n\n\t\t\t\trequire.Equal(t, test.response.Allowed, resp.Allowed)\n\n\t\t\t\tif test.response.Allowed {\n\t\t\t\t\trequire.Equal(t, test.response.Resolution, resp.Resolution)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *proxy) intercept(ctx context.Context, fullName string) (context.Context, *grpc.ClientConn, *grpcProxy.ProxyTarget, func(destroy bool), error) {\n\tmd, _ := metadata.FromIncomingContext(ctx)\n\n\tv := md[diagnostics.GRPCProxyAppIDKey]\n\tif len(v) == 0 {\n\t\treturn ctx, nil, nil, nopTeardown, fmt.Errorf(\"failed to proxy request: required metadata %s not found\", diagnostics.GRPCProxyAppIDKey)\n\t}\n\n\toutCtx := metadata.NewOutgoingContext(ctx, md.Copy())\n\tappID := v[0]\n\n\tif p.remoteAppFn == nil {\n\t\treturn ctx, nil, nil, nopTeardown, errors.New(\"failed to proxy request: proxy not initialized. daprd startup may be incomplete\")\n\t}\n\n\ttarget, isLocal, err := p.isLocal(appID)\n\tif err != nil {\n\t\treturn ctx, nil, nil, nopTeardown, err\n\t}\n\n\tif isLocal {\n\t\t// proxy locally to the app\n\t\tif p.acl != nil {\n\t\t\tok, authError := acl.ApplyAccessControlPolicies(ctx, fullName, common.HTTPExtension_NONE, false, p.acl) //nolint:nosnakecase\n\t\t\tif !ok {\n\t\t\t\treturn ctx, nil, nil, nopTeardown, status.Errorf(codes.PermissionDenied, authError)\n\t\t\t}\n\t\t}\n\n\t\tvar appClient grpc.ClientConnInterface\n\t\tappClient, err = p.appClientFn()\n\t\tif err != nil {\n\t\t\treturn ctx, nil, nil, nopTeardown, err\n\t\t}\n\t\treturn outCtx, appClient.(*grpc.ClientConn), nil, nopTeardown, nil\n\t}\n\n\t// proxy to a remote daprd\n\tconn, teardown, cErr := p.connectionFactory(outCtx, target.address, target.id, target.namespace,\n\t\tgrpc.WithDefaultCallOptions(grpc.CallContentSubtype((&codec.Proxy{}).Name())),\n\t)\n\toutCtx = p.telemetryFn(outCtx)\n\toutCtx = metadata.AppendToOutgoingContext(outCtx, invokev1.CallerIDHeader, p.appID, invokev1.CalleeIDHeader, target.id)\n\n\tappMetadataToken := security.GetAppToken()\n\tif appMetadataToken != \"\" {\n\t\toutCtx = metadata.AppendToOutgoingContext(outCtx, securityConsts.APITokenHeader, appMetadataToken)\n\t}\n\n\tpt := &grpcProxy.ProxyTarget{\n\t\tID:        target.id,\n\t\tNamespace: target.namespace,\n\t\tAddress:   target.address,\n\t}\n\n\treturn outCtx, conn, pt, teardown, cErr\n}", "is_vulnerable": 1}
{"code": "func (u *AuthService) LogOut(c *gin.Context) error {\n\tsID, _ := c.Cookie(constant.SessionName)\n\tif sID != \"\" {\n\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)\n\t\terr := global.SESSION.Delete(sID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func request_API_GetToolInfo_0(ctx context.Context, marshaler runtime.Marshaler, client APIClient, req *http.Request, pathParams map[string]string) (proto.Message, runtime.ServerMetadata, error) {\n\tvar protoReq proto_4.Tool\n\tvar metadata runtime.ServerMetadata\n\n\tif err := req.ParseForm(); err != nil {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", err)\n\t}\n\tif err := runtime.PopulateQueryParameters(&protoReq, req.Form, filter_API_GetToolInfo_0); err != nil {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", err)\n\t}\n\n\tmsg, err := client.GetToolInfo(ctx, &protoReq, grpc.Header(&metadata.HeaderMD), grpc.Trailer(&metadata.TrailerMD))\n\treturn msg, metadata, err\n\n}", "is_vulnerable": 1}
{"code": "func UpdateSecret(k8sClient kubernetes.Interface, secret *v1.Secret) error {\n\tvar err error\n\t_, err = k8sClient.CoreV1().Secrets(secret.Namespace).Update(context.TODO(), secret, metav1.UpdateOptions{})\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func isAppService() bool {\n\t_, asMSIEndpointEnvExists := os.LookupEnv(asMSIEndpointEnv)\n\t_, asMSISecretEnvExists := os.LookupEnv(asMSISecretEnv)\n\n\treturn asMSIEndpointEnvExists && asMSISecretEnvExists\n}", "is_vulnerable": 0}
{"code": "func TestVerifyImageSignatureWithSigVerifierAndRekor(t *testing.T) {\n\tsv, privKey, err := signature.NewDefaultECDSASignerVerifier()\n\tif err != nil {\n\t\tt.Fatalf(\"error generating verifier: %v\", err)\n\t}\n\n\tpayload := []byte{1, 2, 3, 4}\n\th := sha256.Sum256(payload)\n\tsig, _ := privKey.Sign(rand.Reader, h[:], crypto.SHA256)\n\tociSig, _ := static.NewSignature(payload, base64.StdEncoding.EncodeToString(sig))\n\n\t// Add a fake rekor client - this makes it look like there's a matching\n\t// tlog entry for the signature during validation (even though it does not\n\t// match the underlying data / key)\n\tmClient := new(client.Rekor)\n\tmClient.Entries = &mock.EntriesClient{\n\t\tEntries: &data,\n\t}\n\n\tif _, err := VerifyImageSignature(context.TODO(), ociSig, v1.Hash{}, &CheckOpts{\n\t\tSigVerifier: sv,\n\t\tRekorClient: mClient,\n\t}); err == nil || !strings.Contains(err.Error(), \"verifying inclusion proof\") {\n\t\t// TODO(wlynch): This is a weak test, since this is really failing because\n\t\t// there is no inclusion proof for the Rekor entry rather than failing to\n\t\t// validate the Rekor public key itself. At the very least this ensures\n\t\t// that we're hitting tlog validation during signature checking,\n\t\t// but we should look into improving this once there is an in-memory\n\t\t// Rekor client that is capable of performing inclusion proof validation\n\t\t// in unit tests.\n\t\tt.Fatal(\"expected error while verifying signature\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func Test_serverStream_handleRequest(t *testing.T) {\n\ttype fields struct {\n\t\tstream           stream\n\t\trequest          *fasthttp.Request\n\t\tconnection       *serverStreamConnection\n\t\tresponseDoneChan chan bool\n\t}\n\ttests := []struct {\n\t\tname   string\n\t\tfields fields\n\t}{\n\t\t// TODO: Add test cases.\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\ts := &serverStream{\n\t\t\t\tstream:           tt.fields.stream,\n\t\t\t\tconnection:       tt.fields.connection,\n\t\t\t\tresponseDoneChan: tt.fields.responseDoneChan,\n\t\t\t}\n\t\t\ts.handleRequest(nil)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAccessRequesterMockRecorder) GetGrantedAudience() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetGrantedAudience\", reflect.TypeOf((*MockAccessRequester)(nil).GetGrantedAudience))\n}", "is_vulnerable": 0}
{"code": "func NewOAuthConfigWithAPIVersion(activeDirectoryEndpoint, tenantID string, apiVersion *string) (*OAuthConfig, error) {\n\tif err := validateStringParam(activeDirectoryEndpoint, \"activeDirectoryEndpoint\"); err != nil {\n\t\treturn nil, err\n\t}\n\tapi := \"\"\n\t// it's legal for tenantID to be empty so don't validate it\n\tif apiVersion != nil {\n\t\tif err := validateStringParam(*apiVersion, \"apiVersion\"); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tapi = fmt.Sprintf(\"?api-version=%s\", *apiVersion)\n\t}\n\tu, err := url.Parse(activeDirectoryEndpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tauthorityURL, err := u.Parse(tenantID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tauthorizeURL, err := u.Parse(fmt.Sprintf(activeDirectoryEndpointTemplate, tenantID, \"authorize\", api))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttokenURL, err := u.Parse(fmt.Sprintf(activeDirectoryEndpointTemplate, tenantID, \"token\", api))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdeviceCodeURL, err := u.Parse(fmt.Sprintf(activeDirectoryEndpointTemplate, tenantID, \"devicecode\", api))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &OAuthConfig{\n\t\tAuthorityEndpoint:  *authorityURL,\n\t\tAuthorizeEndpoint:  *authorizeURL,\n\t\tTokenEndpoint:      *tokenURL,\n\t\tDeviceCodeEndpoint: *deviceCodeURL,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (err error) {\n\tif len(images) == 0 {\n\t\treturn flag.ErrHelp\n\t}\n\n\tif !options.OneOf(c.KeyRef, c.Sk, c.CertRef) && !options.EnableExperimental() {\n\t\treturn &options.KeyParseError{}\n\t}\n\n\tociremoteOpts, err := c.ClientOpts(ctx)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"constructing client options\")\n\t}\n\tco := &cosign.CheckOpts{\n\t\tRegistryClientOpts: ociremoteOpts,\n\t\tCertEmail:          c.CertEmail,\n\t\tCertOidcIssuer:     c.CertOidcIssuer,\n\t}\n\tif c.CheckClaims {\n\t\tco.ClaimVerifier = cosign.IntotoSubjectClaimVerifier\n\t}\n\tif options.EnableExperimental() {\n\t\tif c.RekorURL != \"\" {\n\t\t\trekorClient, err := rekor.NewClient(c.RekorURL)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"creating Rekor client\")\n\t\t\t}\n\t\t\tco.RekorClient = rekorClient\n\t\t}\n\t\tco.RootCerts = fulcio.GetRoots()\n\t}\n\tkeyRef := c.KeyRef\n\n\t// Keys are optional!\n\tswitch {\n\tcase keyRef != \"\":\n\t\tco.SigVerifier, err = sigs.PublicKeyFromKeyRef(ctx, keyRef)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"loading public key\")\n\t\t}\n\t\tpkcs11Key, ok := co.SigVerifier.(*pkcs11key.Key)\n\t\tif ok {\n\t\t\tdefer pkcs11Key.Close()\n\t\t}\n\tcase c.Sk:\n\t\tsk, err := pivkey.GetKeyWithSlot(c.Slot)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"opening piv token\")\n\t\t}\n\t\tdefer sk.Close()\n\t\tco.SigVerifier, err = sk.Verifier()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"initializing piv token verifier\")\n\t\t}\n\tcase c.CertRef != \"\":\n\t\tcert, err := loadCertFromFileOrURL(c.CertRef)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"loading certificate from reference\")\n\t\t}\n\t\tco.SigVerifier, err = signature.LoadECDSAVerifier(cert.PublicKey.(*ecdsa.PublicKey), crypto.SHA256)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"creating certificate verifier\")\n\t\t}\n\t}\n\n\t// NB: There are only 2 kinds of verification right now:\n\t// 1. You gave us the public key explicitly to verify against so co.SigVerifier is non-nil or,\n\t// 2. We're going to find an x509 certificate on the signature and verify against Fulcio root trust\n\t// TODO(nsmith5): Refactor this verification logic to pass back _how_ verification\n\t// was performed so we don't need to use this fragile logic here.\n\tfulcioVerified := (co.SigVerifier == nil)\n\n\tfor _, imageRef := range images {\n\t\tvar verified []oci.Signature\n\t\tvar bundleVerified bool\n\n\t\tif c.LocalImage {\n\t\t\tverified, bundleVerified, err = cosign.VerifyLocalImageAttestations(ctx, imageRef, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tref, err := name.ParseReference(imageRef)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tverified, bundleVerified, err = cosign.VerifyImageAttestations(ctx, ref, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tvar cuePolicies, regoPolicies []string\n\n\t\tfor _, policy := range c.Policies {\n\t\t\tswitch filepath.Ext(policy) {\n\t\t\tcase \".rego\":\n\t\t\t\tregoPolicies = append(regoPolicies, policy)\n\t\t\tcase \".cue\":\n\t\t\t\tcuePolicies = append(cuePolicies, policy)\n\t\t\tdefault:\n\t\t\t\treturn errors.New(\"invalid policy format, expected .cue or .rego\")\n\t\t\t}\n\t\t}\n\n\t\tvar validationErrors []error\n\t\tfor _, vp := range verified {\n\t\t\tvar payloadData map[string]interface{}\n\n\t\t\tp, err := vp.Payload()\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"could not get payload\")\n\t\t\t}\n\n\t\t\terr = json.Unmarshal(p, &payloadData)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unmarshal payload data\")\n\t\t\t}\n\n\t\t\tpredicateURI, ok := options.PredicateTypeMap[c.PredicateType]\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"invalid predicate type: %s\", c.PredicateType)\n\t\t\t}\n\n\t\t\t// sanity checks\n\t\t\tif val, ok := payloadData[\"payloadType\"]; ok {\n\t\t\t\t// we need to check only given type from the cli flag\n\t\t\t\t// so we are skipping other types\n\t\t\t\tif predicateURI != val {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"could not find 'payloadType' in payload data\")\n\t\t\t}\n\n\t\t\tvar decodedPayload []byte\n\t\t\tif val, ok := payloadData[\"payload\"]; ok {\n\t\t\t\tdecodedPayload, err = base64.StdEncoding.DecodeString(val.(string))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"could not decode 'payload': %w\", err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"could not find 'payload' in payload data\")\n\t\t\t}\n\n\t\t\tvar payload []byte\n\t\t\tswitch c.PredicateType {\n\t\t\tcase options.PredicateCustom:\n\t\t\t\tvar cosignStatement in_toto.Statement\n\t\t\t\tif err := json.Unmarshal(decodedPayload, &cosignStatement); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"unmarshal CosignStatement: %w\", err)\n\t\t\t\t}\n\t\t\t\tpayload, err = json.Marshal(cosignStatement)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"error when generating CosignStatement: %w\", err)\n\t\t\t\t}\n\t\t\tcase options.PredicateLink:\n\t\t\t\tvar linkStatement in_toto.LinkStatement\n\t\t\t\tif err := json.Unmarshal(decodedPayload, &linkStatement); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"unmarshal LinkStatement: %w\", err)\n\t\t\t\t}\n\t\t\t\tpayload, err = json.Marshal(linkStatement)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"error when generating LinkStatement: %w\", err)\n\t\t\t\t}\n\t\t\tcase options.PredicateSLSA:\n\t\t\t\tvar slsaProvenanceStatement in_toto.ProvenanceStatement\n\t\t\t\tif err := json.Unmarshal(decodedPayload, &slsaProvenanceStatement); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"unmarshal ProvenanceStatement: %w\", err)\n\t\t\t\t}\n\t\t\t\tpayload, err = json.Marshal(slsaProvenanceStatement)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"error when generating ProvenanceStatement: %w\", err)\n\t\t\t\t}\n\t\t\tcase options.PredicateSPDX:\n\t\t\t\tvar spdxStatement in_toto.SPDXStatement\n\t\t\t\tif err := json.Unmarshal(decodedPayload, &spdxStatement); err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"unmarshal SPDXStatement: %w\", err)\n\t\t\t\t}\n\t\t\t\tpayload, err = json.Marshal(spdxStatement)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"error when generating SPDXStatement: %w\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(cuePolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against CUE policies: %v\\n\", cuePolicies)\n\t\t\t\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\n\t\t\t\tif cueValidationErr != nil {\n\t\t\t\t\tvalidationErrors = append(validationErrors, cueValidationErr)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(regoPolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against Rego policies: %v\\n\", regoPolicies)\n\t\t\t\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\n\t\t\t\tif len(regoValidationErrs) > 0 {\n\t\t\t\t\tvalidationErrors = append(validationErrors, regoValidationErrs...)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif len(validationErrors) > 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"There are %d number of errors occurred during the validation:\\n\", len(validationErrors))\n\t\t\tfor _, v := range validationErrors {\n\t\t\t\t_, _ = fmt.Fprintf(os.Stderr, \"- %v\\n\", v)\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\n\t\t}\n\n\t\t// TODO: add CUE validation report to `PrintVerificationHeader`.\n\t\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\n\t\t// The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\n\t\tPrintVerification(imageRef, verified, \"text\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (a *AuthenticationGSSContinue) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'R')\n\tdst = pgio.AppendUint32(dst, AuthTypeGSSCont)\n\tdst = append(dst, a.Data...)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func TestGetStringAnnotation(t *testing.T) {\n\ting := buildIngress()\n\n\t_, err := GetStringAnnotation(\"\", nil, nil)\n\tif err == nil {\n\t\tt.Errorf(\"expected error but none returned\")\n\t}\n\n\ttests := []struct {\n\t\tname   string\n\t\tfield  string\n\t\tvalue  string\n\t\texp    string\n\t\texpErr bool\n\t}{\n\t\t{\"valid - A\", \"string\", \"A \", \"A\", false},\n\t\t{\"valid - B\", \"string\", \"\tB\", \"B\", false},\n\t\t{\"empty\", \"string\", \" \", \"\", true},\n\t\t{\"valid multiline\", \"string\", `\n\t\trewrite (?i)/arcgis/rest/services/Utilities/Geometry/GeometryServer(.*)$ /arcgis/rest/services/Utilities/Geometry/GeometryServer$1 break;\n\t\trewrite (?i)/arcgis/services/Utilities/Geometry/GeometryServer(.*)$ /arcgis/services/Utilities/Geometry/GeometryServer$1 break;\n\t\t`, `\nrewrite (?i)/arcgis/rest/services/Utilities/Geometry/GeometryServer(.*)$ /arcgis/rest/services/Utilities/Geometry/GeometryServer$1 break;\nrewrite (?i)/arcgis/services/Utilities/Geometry/GeometryServer(.*)$ /arcgis/services/Utilities/Geometry/GeometryServer$1 break;\n`,\n\t\t\tfalse},\n\t}\n\n\tdata := map[string]string{}\n\ting.SetAnnotations(data)\n\n\tfor _, test := range tests {\n\t\tdata[GetAnnotationWithPrefix(test.field)] = test.value\n\n\t\ts, err := GetStringAnnotation(test.field, ing, nil)\n\t\tif test.expErr {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"%v: expected error but none returned\", test.name)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif !test.expErr {\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"%v: didn't expected error but error was returned: %v\", test.name, err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif s != test.exp {\n\t\t\tt.Errorf(\"%v: expected \\\"%v\\\" but \\\"%v\\\" was returned\", test.name, test.exp, s)\n\t\t}\n\n\t\tdelete(data, test.field)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Server) handleRaftRPC(conn net.Conn) {\n\tif tlsConn, ok := conn.(*tls.Conn); ok {\n\t\terr := s.tlsConfigurator.AuthorizeServerConn(s.config.Datacenter, tlsConn)\n\t\tif err != nil {\n\t\t\ts.rpcLogger().Warn(err.Error(), \"from\", conn.RemoteAddr(), \"operation\", \"raft RPC\")\n\t\t\tconn.Close()\n\t\t\treturn\n\t\t}\n\t}\n\n\tmetrics.IncrCounter([]string{\"rpc\", \"raft_handoff\"}, 1)\n\ts.raftLayer.Handoff(conn)\n}", "is_vulnerable": 0}
{"code": "func TestCustomField(t *testing.T) {\n\t// XXX has global effect!!!\n\tjws.RegisterCustomField(`x-birthday`, time.Time{})\n\tdefer jws.RegisterCustomField(`x-birthday`, nil)\n\n\texpected := time.Date(2015, 11, 4, 5, 12, 52, 0, time.UTC)\n\tbdaybytes, _ := expected.MarshalText() // RFC3339\n\n\tpayload := \"Hello, World!\"\n\tprivkey, err := jwxtest.GenerateRsaJwk()\n\tif !assert.NoError(t, err, `jwxtest.GenerateRsaJwk() should succeed`) {\n\t\treturn\n\t}\n\n\thdrs := jws.NewHeaders()\n\thdrs.Set(`x-birthday`, string(bdaybytes))\n\n\tsigned, err := jws.Sign([]byte(payload), jws.WithKey(jwa.RS256, privkey, jws.WithProtectedHeaders(hdrs)))\n\tif !assert.NoError(t, err, `jws.Sign should succeed`) {\n\t\treturn\n\t}\n\n\tt.Run(\"jws.Parse + json.Unmarshal\", func(t *testing.T) {\n\t\tmsg, err := jws.Parse(signed)\n\t\tif !assert.NoError(t, err, `jws.Parse should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tv, ok := msg.Signatures()[0].ProtectedHeaders().Get(`x-birthday`)\n\t\tif !assert.True(t, ok, `msg.Signatures()[0].ProtectedHeaders().Get(\"x-birthday\") should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tif !assert.Equal(t, expected, v, `values should match`) {\n\t\t\treturn\n\t\t}\n\n\t\t// Create JSON from jws.Message\n\t\tbuf, err := json.Marshal(msg)\n\t\tif !assert.NoError(t, err, `json.Marshal should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tvar msg2 jws.Message\n\t\tif !assert.NoError(t, json.Unmarshal(buf, &msg2), `json.Unmarshal should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tv, ok = msg2.Signatures()[0].ProtectedHeaders().Get(`x-birthday`)\n\t\tif !assert.True(t, ok, `msg2.Signatures()[0].ProtectedHeaders().Get(\"x-birthday\") should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tif !assert.Equal(t, expected, v, `values should match`) {\n\t\t\treturn\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func Quote(rw io.ReadWriter, handle tpmutil.Handle, data []byte, pcrNums []int, aikAuth []byte) ([]byte, []byte, error) {\n\t// Run OSAP for the handle, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a response.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etKeyHandle, handle, aikAuth)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\t// Hash the data to get the value to pass to quote2.\n\thash := sha1.Sum(data)\n\tpcrSel, err := newPCRSelection(pcrNums)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tauthIn := []interface{}{ordQuote, hash, pcrSel}\n\tca, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, nil, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tpcrc, sig, ra, ret, err := quote(rw, handle, hash, pcrSel, ca)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Check response authentication.\n\traIn := []interface{}{ret, ordQuote, pcrc, tpmutil.U32Bytes(sig)}\n\tif err := ra.verify(ca.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn sig, pcrc.Values, nil\n}", "is_vulnerable": 0}
{"code": "func getSort(sort string, direction string, tableName string) string {\n\tdirection = getSortDirection(direction)\n\n\tconst randomSeedPrefix = \"random_\"\n\n\tswitch {\n\tcase strings.HasSuffix(sort, \"_count\"):\n\t\tvar relationTableName = strings.TrimSuffix(sort, \"_count\") // TODO: pluralize?\n\t\tcolName := getColumn(relationTableName, \"id\")\n\t\treturn \" ORDER BY COUNT(distinct \" + colName + \") \" + direction\n\tcase strings.Compare(sort, \"filesize\") == 0:\n\t\tcolName := getColumn(tableName, \"size\")\n\t\treturn \" ORDER BY \" + colName + \" \" + direction\n\tcase strings.HasPrefix(sort, randomSeedPrefix):\n\t\t// seed as a parameter from the UI\n\t\tseedStr := sort[len(randomSeedPrefix):]\n\t\tseed, err := strconv.ParseUint(seedStr, 10, 64)\n\t\tif err != nil {\n\t\t\t// fallback to a random seed\n\t\t\tseed = rand.Uint64()\n\t\t}\n\t\treturn getRandomSort(tableName, direction, seed)\n\tcase strings.Compare(sort, \"random\") == 0:\n\t\treturn getRandomSort(tableName, direction, rand.Uint64())\n\tdefault:\n\t\tcolName := getColumn(tableName, sort)\n\t\tif strings.Contains(sort, \".\") {\n\t\t\tcolName = sort\n\t\t}\n\t\tif strings.Compare(sort, \"name\") == 0 {\n\t\t\treturn \" ORDER BY \" + colName + \" COLLATE NATURAL_CI \" + direction\n\t\t}\n\t\tif strings.Compare(sort, \"title\") == 0 {\n\t\t\treturn \" ORDER BY \" + colName + \" COLLATE NATURAL_CI \" + direction\n\t\t}\n\n\t\treturn \" ORDER BY \" + colName + \" \" + direction\n\t}\n}", "is_vulnerable": 1}
{"code": "\tc.msRead = func(ms *runtime.MemStats) {\n\t\ttime.Sleep(20 * time.Millisecond)\n\t\tms.Alloc = 1\n\t}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Terminate(ctx context.Context, in *sliverpb.TerminateReq, opts ...grpc.CallOption) (*sliverpb.Terminate, error) {\n\tout := new(sliverpb.Terminate)\n\terr := c.cc.Invoke(ctx, SliverRPC_Terminate_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (p *ratelimit) CanApply(config *extensioncommon.RuntimeConfig) bool {\n\t// rate limit is only applied to the service itself since the limit is\n\t// aggregated from all downstream connections.\n\treturn string(config.Kind) == p.ProxyType && !config.IsUpstream()\n}", "is_vulnerable": 1}
{"code": "func _NewCipher(\n\tsource string,\n\tprivate_key *rsa.PrivateKey,\n\tpublic_key *rsa.PublicKey) (*_Cipher, error) {\n\n\tresult := &_Cipher{\n\t\tsource:   source,\n\t\tkey_size: 128,\n\t}\n\tresult.cipher_properties = &crypto_proto.CipherProperties{\n\t\tName:       \"aes_128_cbc\",\n\t\tKey:        make([]byte, result.key_size/8),\n\t\tMetadataIv: make([]byte, result.key_size/8),\n\t\tHmacKey:    make([]byte, result.key_size/8),\n\t\tHmacType:   crypto_proto.CipherProperties_FULL_HMAC,\n\t}\n\n\t_, err := rand.Read(result.cipher_properties.Key)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t_, err = rand.Read(result.cipher_properties.MetadataIv)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\t_, err = rand.Read(result.cipher_properties.HmacKey)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tresult.cipher_metadata = &crypto_proto.CipherMetadata{\n\t\tSource: source,\n\t}\n\n\tserialized_cipher, err := proto.Marshal(result.cipher_properties)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\thashed := sha256.Sum256(serialized_cipher)\n\tRsaSignCounter.Inc()\n\tsignature, err := rsa.SignPKCS1v15(\n\t\trand.Reader, private_key, crypto.SHA256, hashed[:])\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\tresult.cipher_metadata.Signature = signature\n\n\tRsaEncryptCounter.Inc()\n\tencrypted_cipher, err := rsa.EncryptOAEP(\n\t\tsha1.New(), rand.Reader,\n\t\tpublic_key,\n\t\tserialized_cipher, []byte(\"\"))\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tresult.encrypted_cipher = encrypted_cipher\n\n\tserialized_cipher_metadata, err := proto.Marshal(result.cipher_metadata)\n\tif err != nil {\n\t\treturn nil, errors.WithStack(err)\n\t}\n\n\tencrypted_cipher_metadata, err := encryptSymmetric(\n\t\tresult.cipher_properties,\n\t\tserialized_cipher_metadata,\n\t\tresult.cipher_properties.MetadataIv)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresult.encrypted_cipher_metadata = encrypted_cipher_metadata\n\n\treturn result, nil\n}", "is_vulnerable": 1}
{"code": "func (client Client) DeleteSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (p *OAuthProxy) OAuthCallback(rw http.ResponseWriter, req *http.Request) {\n\tremoteAddr := getRemoteAddr(req)\n\n\t// finish the oauth cycle\n\terr := req.ParseForm()\n\tif err != nil {\n\t\tp.ErrorPage(rw, 500, \"Internal Error\", err.Error())\n\t\treturn\n\t}\n\terrorString := req.Form.Get(\"error\")\n\tif errorString != \"\" {\n\t\tp.ErrorPage(rw, 403, \"Permission Denied\", errorString)\n\t\treturn\n\t}\n\n\tsession, err := p.redeemCode(req.Host, req.Form.Get(\"code\"))\n\tif err != nil {\n\t\tlog.Printf(\"%s error redeeming code %s\", remoteAddr, err)\n\t\tp.ErrorPage(rw, 500, \"Internal Error\", \"Internal Error\")\n\t\treturn\n\t}\n\n\tredirect := req.Form.Get(\"state\")\n\tif !strings.HasPrefix(redirect, \"/\") {\n\t\tredirect = \"/\"\n\t}\n\n\t// set cookie, or deny\n\tif p.Validator(session.Email) && p.provider.ValidateGroup(session.Email) {\n\t\tlog.Printf(\"%s authentication complete %s\", remoteAddr, session)\n\t\terr := p.SaveSession(rw, req, session)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"%s %s\", remoteAddr, err)\n\t\t\tp.ErrorPage(rw, 500, \"Internal Error\", \"Internal Error\")\n\t\t\treturn\n\t\t}\n\t\thttp.Redirect(rw, req, redirect, 302)\n\t} else {\n\t\tlog.Printf(\"%s Permission Denied: %q is unauthorized\", remoteAddr, session.Email)\n\t\tp.ErrorPage(rw, 403, \"Permission Denied\", \"Invalid Account\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (t *TableController) UpdateTableField(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tid, err := strconv.Atoi(ctx.Param(\"id\"))\n\tif err != nil {\n\t\te := &response.AdminError{\n\t\t\tErrorCode:    http.StatusBadRequest,\n\t\t\tErrorMessage: err.Error(),\n\t\t}\n\t\t_ = ctx.Error(e)\n\t\treturn\n\t}\n\tvar data request.TableFieldUpdateReq\n\tdata.Id = id\n\ttranslator, _ := t.translators[\"zh\"]\n\terr = utils.ValidatorBody[request.TableFieldUpdateReq](ctx, &data, translator)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\terr = t.sysTableService.UpdateTableField(ctx, data)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "\t\t\tmutate:      func(_ *corev1.Service) {},", "is_vulnerable": 0}
{"code": "func TestFilesystem_Openfile(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\n\tg.Describe(\"File\", func() {\n\t\tg.It(\"returns custom error when file does not exist\", func() {\n\t\t\t_, _, err := fs.File(\"foo/bar.txt\")\n\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\t// TODO\n\t\t\t//g.Assert(IsErrorCode(err, ErrNotExist)).IsTrue()\n\t\t})\n\n\t\tg.It(\"returns file stat information\", func() {\n\t\t\t_ = rfs.CreateServerFile(\"foo.txt\", []byte(\"hello world\"))\n\n\t\t\tf, st, err := fs.File(\"foo.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tg.Assert(st.Name()).Equal(\"foo.txt\")\n\t\t\tg.Assert(f).IsNotNil()\n\t\t\t_ = f.Close()\n\t\t})\n\n\t\tg.AfterEach(func() {\n\t\t\t_ = fs.TruncateRootDirectory()\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func getSocketDir() (string, error) {\n\ttmpDir, ok := os.LookupEnv(\"TMPDIR\")\n\tif !ok {\n\t\treturn \"\", errors.New(\"unable to resolve TMPDIR\")\n\t}\n\treturn tmpDir, nil\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"nats.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.NATS)\n\n\tfor name, value := range eventSource.Spec.NATS {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tNATSEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func openLock(path string, ro bool) (int, error) {\n\tif ro {\n\t\treturn unix.Open(path, os.O_RDONLY|unix.O_CLOEXEC, 0)\n\t}\n\treturn unix.Open(path, os.O_RDWR|unix.O_CLOEXEC|os.O_CREATE, unix.S_IRUSR|unix.S_IWUSR|unix.S_IRGRP|unix.S_IROTH)\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn affinity{\n\t\tr:                r,\n\t\tannotationConfig: sessionAffinityAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) loadSyncStatus() {\n\tvar progress SyncProgress\n\n\tif status := rawdb.ReadSnapshotSyncStatus(s.db); status != nil {\n\t\tif err := json.Unmarshal(status, &progress); err != nil {\n\t\t\tlog.Error(\"Failed to decode snap sync status\", \"err\", err)\n\t\t} else {\n\t\t\tfor _, task := range progress.Tasks {\n\t\t\t\tlog.Debug(\"Scheduled account sync task\", \"from\", task.Next, \"last\", task.Last)\n\t\t\t}\n\t\t\ts.tasks = progress.Tasks\n\t\t\tfor _, task := range s.tasks {\n\t\t\t\ttask := task // closure for task.genBatch in the stacktrie writer callback\n\n\t\t\t\t// Restore the completed storages\n\t\t\t\ttask.stateCompleted = make(map[common.Hash]struct{})\n\t\t\t\tfor _, hash := range task.StorageCompleted {\n\t\t\t\t\ttask.stateCompleted[hash] = struct{}{}\n\t\t\t\t}\n\t\t\t\ttask.StorageCompleted = nil\n\n\t\t\t\t// Allocate batch for account trie generation\n\t\t\t\ttask.genBatch = ethdb.HookedBatch{\n\t\t\t\t\tBatch: s.db.NewBatch(),\n\t\t\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\t\t\ts.accountBytes += common.StorageSize(len(key) + len(value))\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\toptions := trie.NewStackTrieOptions()\n\t\t\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\t\t\trawdb.WriteTrieNode(task.genBatch, common.Hash{}, path, hash, blob, s.scheme)\n\t\t\t\t})\n\t\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\t\t\ts.cleanPath(task.genBatch, common.Hash{}, path)\n\t\t\t\t\t})\n\t\t\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\t\t\toptions = options.WithSkipBoundary(task.Next != (common.Hash{}), task.Last != common.MaxHash, boundaryAccountNodesGauge)\n\t\t\t\t}\n\t\t\t\ttask.genTrie = trie.NewStackTrie(options)\n\n\t\t\t\t// Restore leftover storage tasks\n\t\t\t\tfor accountHash, subtasks := range task.SubTasks {\n\t\t\t\t\tfor _, subtask := range subtasks {\n\t\t\t\t\t\tsubtask := subtask // closure for subtask.genBatch in the stacktrie writer callback\n\n\t\t\t\t\t\tsubtask.genBatch = ethdb.HookedBatch{\n\t\t\t\t\t\t\tBatch: s.db.NewBatch(),\n\t\t\t\t\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\t\t\t\t\ts.storageBytes += common.StorageSize(len(key) + len(value))\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t}\n\t\t\t\t\t\towner := accountHash // local assignment for stacktrie writer closure\n\t\t\t\t\t\toptions := trie.NewStackTrieOptions()\n\t\t\t\t\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\t\t\t\t\trawdb.WriteTrieNode(subtask.genBatch, owner, path, hash, blob, s.scheme)\n\t\t\t\t\t\t})\n\t\t\t\t\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t\t\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t\t\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t\t\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\t\t\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\t\t\t\t\ts.cleanPath(subtask.genBatch, owner, path)\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t\t\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\t\t\t\t\toptions = options.WithSkipBoundary(subtask.Next != common.Hash{}, subtask.Last != common.MaxHash, boundaryStorageNodesGauge)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsubtask.genTrie = trie.NewStackTrie(options)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.lock.Lock()\n\t\t\tdefer s.lock.Unlock()\n\n\t\t\ts.snapped = len(s.tasks) == 0\n\n\t\t\ts.accountSynced = progress.AccountSynced\n\t\t\ts.accountBytes = progress.AccountBytes\n\t\t\ts.bytecodeSynced = progress.BytecodeSynced\n\t\t\ts.bytecodeBytes = progress.BytecodeBytes\n\t\t\ts.storageSynced = progress.StorageSynced\n\t\t\ts.storageBytes = progress.StorageBytes\n\n\t\t\ts.trienodeHealSynced = progress.TrienodeHealSynced\n\t\t\ts.trienodeHealBytes = progress.TrienodeHealBytes\n\t\t\ts.bytecodeHealSynced = progress.BytecodeHealSynced\n\t\t\ts.bytecodeHealBytes = progress.BytecodeHealBytes\n\t\t\treturn\n\t\t}\n\t}\n\t// Either we've failed to decode the previous state, or there was none.\n\t// Start a fresh sync by chunking up the account range and scheduling\n\t// them for retrieval.\n\ts.tasks = nil\n\ts.accountSynced, s.accountBytes = 0, 0\n\ts.bytecodeSynced, s.bytecodeBytes = 0, 0\n\ts.storageSynced, s.storageBytes = 0, 0\n\ts.trienodeHealSynced, s.trienodeHealBytes = 0, 0\n\ts.bytecodeHealSynced, s.bytecodeHealBytes = 0, 0\n\n\tvar next common.Hash\n\tstep := new(big.Int).Sub(\n\t\tnew(big.Int).Div(\n\t\t\tnew(big.Int).Exp(common.Big2, common.Big256, nil),\n\t\t\tbig.NewInt(int64(accountConcurrency)),\n\t\t), common.Big1,\n\t)\n\tfor i := 0; i < accountConcurrency; i++ {\n\t\tlast := common.BigToHash(new(big.Int).Add(next.Big(), step))\n\t\tif i == accountConcurrency-1 {\n\t\t\t// Make sure we don't overflow if the step is not a proper divisor\n\t\t\tlast = common.MaxHash\n\t\t}\n\t\tbatch := ethdb.HookedBatch{\n\t\t\tBatch: s.db.NewBatch(),\n\t\t\tOnPut: func(key []byte, value []byte) {\n\t\t\t\ts.accountBytes += common.StorageSize(len(key) + len(value))\n\t\t\t},\n\t\t}\n\t\toptions := trie.NewStackTrieOptions()\n\t\toptions = options.WithWriter(func(path []byte, hash common.Hash, blob []byte) {\n\t\t\trawdb.WriteTrieNode(batch, common.Hash{}, path, hash, blob, s.scheme)\n\t\t})\n\t\tif s.scheme == rawdb.PathScheme {\n\t\t\t// Configure the dangling node cleaner and also filter out boundary nodes\n\t\t\t// only in the context of the path scheme. Deletion is forbidden in the\n\t\t\t// hash scheme, as it can disrupt state completeness.\n\t\t\toptions = options.WithCleaner(func(path []byte) {\n\t\t\t\ts.cleanPath(batch, common.Hash{}, path)\n\t\t\t})\n\t\t\t// Skip the left boundary if it's not the first range.\n\t\t\t// Skip the right boundary if it's not the last range.\n\t\t\toptions = options.WithSkipBoundary(next != common.Hash{}, last != common.MaxHash, boundaryAccountNodesGauge)\n\t\t}\n\t\ts.tasks = append(s.tasks, &accountTask{\n\t\t\tNext:           next,\n\t\t\tLast:           last,\n\t\t\tSubTasks:       make(map[common.Hash][]*storageTask),\n\t\t\tgenBatch:       batch,\n\t\t\tstateCompleted: make(map[common.Hash]struct{}),\n\t\t\tgenTrie:        trie.NewStackTrie(options),\n\t\t})\n\t\tlog.Debug(\"Created account sync task\", \"from\", next, \"last\", last)\n\t\tnext = common.BigToHash(new(big.Int).Add(last.Big(), common.Big1))\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *MockCoreStorage) DeleteAccessTokenSession(arg0 context.Context, arg1 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"DeleteAccessTokenSession\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func TestLinearizedReadRevisionInvariant(t *testing.T) {\n\t// The etcd documentation [1] states that \"linearized requests must go through the Raft consensus process.\"\n\t// A full round of Raft consensus adds a new item to the Raft log, some of which is surfaced by etcd as a\n\t// higher store revision in the response header. Kubernetes exposes this header revision in e.g. List calls,\n\t// so it is ultimately client-facing. By default, all the requests that our *etcd3.store{} issues are\n\t// linearized. However, this also includes *read* requests, and we would not expect non-mutating requests\n\t// against etcd to, by \"go[ing] through the Raft consensus process,\" result in a higher resource version on\n\t// List calls. Today, the mechanism etcd uses to increment the store revision ensures that linearized reads\n\t// do *not* bump the key-value store revision. This test exists to ensure that we notice if this implementation\n\t// detail ever changes.\n\t// [1] https://etcd.io/docs/v3.5/learning/api_guarantees/#isolation-level-and-consistency-of-replicas\n\tctx, store, etcdClient := testSetup(t)\n\n\tdir := \"/testing\"\n\tkey := dir + \"/testkey\"\n\tout := &example.Pod{}\n\tobj := &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"foo\", SelfLink: \"testlink\"}}\n\n\tif err := store.Create(ctx, key, obj, out, 0); err != nil {\n\t\tt.Fatalf(\"Set failed: %v\", err)\n\t}\n\toriginalRevision := out.ResourceVersion\n\n\tfor i := 0; i < 5; i++ {\n\t\tif _, err := etcdClient.KV.Get(ctx, key); err != nil { // this is by default linearizable, the only option the client library exposes is WithSerializable() to make it *not* a linearized read\n\t\t\tt.Fatalf(\"failed to get key: %v\", err)\n\t\t}\n\t}\n\n\tlist := &example.PodList{}\n\tif err := store.GetList(ctx, dir, storage.ListOptions{Predicate: storage.Everything, Recursive: true}, list); err != nil {\n\t\tt.Errorf(\"Unexpected List error: %v\", err)\n\t}\n\tfinalRevision := list.ResourceVersion\n\n\tif originalRevision != finalRevision {\n\t\tt.Fatalf(\"original revision (%s) did not match final revision after linearized reads (%s)\", originalRevision, finalRevision)\n\t}\n}", "is_vulnerable": 0}
{"code": "func setUserSession(ctx echo.Context, user *api.User) error {\n\tsess, _ := session.Get(\"memos_session\", ctx)\n\tsess.Options = &sessions.Options{\n\t\tPath:     \"/\",\n\t\tMaxAge:   3600 * 24 * 30,\n\t\tHttpOnly: true,\n\t\tSecure:   true,\n\t}\n\tsess.Values[userIDContextKey] = user.ID\n\terr := sess.Save(ctx.Request(), ctx.Response())\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to set session, err: %w\", err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (data UserInfoData) ToJSON() map[string]any {\n\tm := map[string]any{}\n\tm[\"csrfToken\"] = data.CSRFToken\n\tm[\"isImpersonated\"] = data.IsImpersonated\n\tm[\"session\"] = data.sessionJSON()\n\tm[\"user\"] = data.userJSON()\n\tm[\"profile\"] = data.profileJSON()\n\tm[\"isEnterprise\"] = data.IsEnterprise\n\tif data.DirectoryUser != nil {\n\t\tm[\"directoryUser\"] = data.DirectoryUser\n\t}\n\tif len(data.DirectoryGroups) > 0 {\n\t\tm[\"directoryGroups\"] = data.DirectoryGroups\n\t}\n\tm[\"webAuthnCreationOptions\"] = data.WebAuthnCreationOptions\n\tm[\"webAuthnRequestOptions\"] = data.WebAuthnRequestOptions\n\tm[\"webAuthnUrl\"] = data.WebAuthnURL\n\thttputil.AddBrandingOptionsToMap(m, data.BrandingOptions)\n\treturn m\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Ls(ctx context.Context, in *sliverpb.LsReq, opts ...grpc.CallOption) (*sliverpb.Ls, error) {\n\tout := new(sliverpb.Ls)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Ls\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Pwd(ctx context.Context, in *sliverpb.PwdReq, opts ...grpc.CallOption) (*sliverpb.Pwd, error) {\n\tout := new(sliverpb.Pwd)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Pwd\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetArmor(yes bool) {\n\tC.gpgme_set_armor(c.ctx, cbool(yes))\n\truntime.KeepAlive(c)\n}", "is_vulnerable": 0}
{"code": "func configureClient(opts options.ToolOptions) (*mongo.Client, error) {\n\tif opts.URI == nil || opts.URI.ConnectionString == \"\" {\n\t\t// XXX Normal operations shouldn't ever reach here because a URI should\n\t\t// be created in options parsing, but tests still manually construct\n\t\t// options and generally don't construct a URI, so we invoke the URI\n\t\t// normalization routine here to correct for that.\n\t\topts.NormalizeOptionsAndURI()\n\t}\n\n\tclientopt := mopt.Client()\n\tcs := opts.URI.ParsedConnString()\n\n\tclientopt.Hosts = cs.Hosts\n\n\tif opts.RetryWrites != nil {\n\t\tclientopt.SetRetryWrites(*opts.RetryWrites)\n\t}\n\n\tclientopt.SetConnectTimeout(time.Duration(opts.Timeout) * time.Second)\n\tclientopt.SetSocketTimeout(time.Duration(opts.SocketTimeout) * time.Second)\n\tif opts.Connection.ServerSelectionTimeout > 0 {\n\t\tclientopt.SetServerSelectionTimeout(time.Duration(opts.Connection.ServerSelectionTimeout) * time.Second)\n\t}\n\tclientopt.SetReplicaSet(opts.ReplicaSetName)\n\n\tclientopt.SetAppName(opts.AppName)\n\tif opts.Direct {\n\t\tclientopt.SetDirect(true)\n\t\tt := true\n\t\tclientopt.AuthenticateToAnything = &t\n\t}\n\n\tif opts.ReadPreference != nil {\n\t\tclientopt.SetReadPreference(opts.ReadPreference)\n\t}\n\tif opts.WriteConcern != nil {\n\t\tclientopt.SetWriteConcern(opts.WriteConcern)\n\t} else {\n\t\t// If no write concern was specified, default to majority\n\t\tclientopt.SetWriteConcern(writeconcern.New(writeconcern.WMajority()))\n\t}\n\n\tif opts.Compressors != \"\" && opts.Compressors != \"none\" {\n\t\tclientopt.SetCompressors(strings.Split(opts.Compressors, \",\"))\n\t}\n\n\tif cs.ZlibLevelSet {\n\t\tclientopt.SetZlibLevel(cs.ZlibLevel)\n\t}\n\tif cs.ZstdLevelSet {\n\t\tclientopt.SetZstdLevel(cs.ZstdLevel)\n\t}\n\n\tif cs.HeartbeatIntervalSet {\n\t\tclientopt.SetHeartbeatInterval(cs.HeartbeatInterval)\n\t}\n\n\tif cs.LocalThresholdSet {\n\t\tclientopt.SetLocalThreshold(cs.LocalThreshold)\n\t}\n\n\tif cs.MaxConnIdleTimeSet {\n\t\tclientopt.SetMaxConnIdleTime(cs.MaxConnIdleTime)\n\t}\n\n\tif cs.MaxPoolSizeSet {\n\t\tclientopt.SetMaxPoolSize(cs.MaxPoolSize)\n\t}\n\n\tif cs.MinPoolSizeSet {\n\t\tclientopt.SetMinPoolSize(cs.MinPoolSize)\n\t}\n\n\tif cs.ReadConcernLevel != \"\" {\n\t\trc := readconcern.New(readconcern.Level(cs.ReadConcernLevel))\n\t\tclientopt.SetReadConcern(rc)\n\t}\n\n\tif cs.ReadPreference != \"\" || len(cs.ReadPreferenceTagSets) > 0 || cs.MaxStalenessSet {\n\t\treadPrefOpts := make([]readpref.Option, 0, 1)\n\n\t\ttagSets := tag.NewTagSetsFromMaps(cs.ReadPreferenceTagSets)\n\t\tif len(tagSets) > 0 {\n\t\t\treadPrefOpts = append(readPrefOpts, readpref.WithTagSets(tagSets...))\n\t\t}\n\n\t\tif cs.MaxStaleness != 0 {\n\t\t\treadPrefOpts = append(readPrefOpts, readpref.WithMaxStaleness(cs.MaxStaleness))\n\t\t}\n\n\t\tmode, err := readpref.ModeFromString(cs.ReadPreference)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treadPref, err := readpref.New(mode, readPrefOpts...)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tclientopt.SetReadPreference(readPref)\n\t}\n\n\tif cs.RetryReadsSet {\n\t\tclientopt.SetRetryReads(cs.RetryReads)\n\t}\n\n\tif cs.JSet || cs.WString != \"\" || cs.WNumberSet || cs.WTimeoutSet {\n\t\topts := make([]writeconcern.Option, 0, 1)\n\n\t\tif len(cs.WString) > 0 {\n\t\t\topts = append(opts, writeconcern.WTagSet(cs.WString))\n\t\t} else if cs.WNumberSet {\n\t\t\topts = append(opts, writeconcern.W(cs.WNumber))\n\t\t}\n\n\t\tif cs.JSet {\n\t\t\topts = append(opts, writeconcern.J(cs.J))\n\t\t}\n\n\t\tif cs.WTimeoutSet {\n\t\t\topts = append(opts, writeconcern.WTimeout(cs.WTimeout))\n\t\t}\n\n\t\tclientopt.SetWriteConcern(writeconcern.New(opts...))\n\t}\n\n\tif opts.Auth != nil && opts.Auth.IsSet() {\n\t\tcred := mopt.Credential{\n\t\t\tUsername:      opts.Auth.Username,\n\t\t\tPassword:      opts.Auth.Password,\n\t\t\tAuthSource:    opts.GetAuthenticationDatabase(),\n\t\t\tAuthMechanism: opts.Auth.Mechanism,\n\t\t}\n\t\tif cs.AuthMechanism == \"MONGODB-AWS\" {\n\t\t\tcred.Username = cs.Username\n\t\t\tcred.Password = cs.Password\n\t\t\tcred.AuthSource = cs.AuthSource\n\t\t\tcred.AuthMechanism = cs.AuthMechanism\n\t\t\tcred.AuthMechanismProperties = cs.AuthMechanismProperties\n\t\t}\n\t\t// Technically, an empty password is possible, but the tools don't have the\n\t\t// means to easily distinguish and so require a non-empty password.\n\t\tif cred.Password != \"\" {\n\t\t\tcred.PasswordSet = true\n\t\t}\n\t\tif opts.Kerberos != nil && cred.AuthMechanism == \"GSSAPI\" {\n\t\t\tprops := make(map[string]string)\n\t\t\tif opts.Kerberos.Service != \"\" {\n\t\t\t\tprops[\"SERVICE_NAME\"] = opts.Kerberos.Service\n\t\t\t}\n\t\t\t// XXX How do we use opts.Kerberos.ServiceHost if at all?\n\t\t\tcred.AuthMechanismProperties = props\n\t\t}\n\t\tclientopt.SetAuth(cred)\n\t}\n\n\tif opts.SSL != nil && opts.UseSSL {\n\t\t// Error on unsupported features\n\t\tif opts.SSLFipsMode {\n\t\t\treturn nil, fmt.Errorf(\"FIPS mode not supported\")\n\t\t}\n\t\tif opts.SSLCRLFile != \"\" {\n\t\t\treturn nil, fmt.Errorf(\"CRL files are not supported on this platform\")\n\t\t}\n\n\t\ttlsConfig := &tls.Config{}\n\t\tif opts.SSLAllowInvalidCert || opts.SSLAllowInvalidHost || opts.TLSInsecure {\n\t\t\ttlsConfig.InsecureSkipVerify = true\n\t\t}\n\n\t\tvar x509Subject string\n\t\tvar keyPasswd string\n\t\tvar err error\n\t\tif cs.SSLClientCertificateKeyPasswordSet && cs.SSLClientCertificateKeyPassword != nil {\n\t\t\tkeyPasswd = cs.SSLClientCertificateKeyPassword()\n\t\t}\n\t\tif cs.SSLClientCertificateKeyFileSet {\n\t\t\tx509Subject, err = addClientCertFromFile(tlsConfig, cs.SSLClientCertificateKeyFile, keyPasswd)\n\t\t} else if cs.SSLCertificateFileSet || cs.SSLPrivateKeyFileSet {\n\t\t\tx509Subject, err = addClientCertFromSeparateFiles(tlsConfig, cs.SSLCertificateFile, cs.SSLPrivateKeyFile, keyPasswd)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error configuring client, can't load client certificate: %v\", err)\n\t\t}\n\t\tif opts.SSLCAFile != \"\" {\n\t\t\tif err := addCACertsFromFile(tlsConfig, opts.SSLCAFile); err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error configuring client, can't load CA file: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\t// If a username wasn't specified for x509, add one from the certificate.\n\t\tif clientopt.Auth != nil && strings.ToLower(clientopt.Auth.AuthMechanism) == \"mongodb-x509\" && clientopt.Auth.Username == \"\" {\n\t\t\t// The Go x509 package gives the subject with the pairs in reverse order that we want.\n\t\t\tclientopt.Auth.Username = extractX509UsernameFromSubject(x509Subject)\n\t\t}\n\n\t\tclientopt.SetTLSConfig(tlsConfig)\n\t}\n\n\tif cs.SSLDisableOCSPEndpointCheckSet {\n\t\tclientopt.SetDisableOCSPEndpointCheck(cs.SSLDisableOCSPEndpointCheck)\n\t}\n\n\treturn mongo.NewClient(clientopt)\n}", "is_vulnerable": 0}
{"code": "func CsrfFromParam(param string) func(c *fiber.Ctx) (string, error) {\n\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.Params(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", errMissingParam\n\t\t}\n\t\treturn token, nil\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) WebsiteAddContent(ctx context.Context, in *clientpb.WebsiteAddContent, opts ...grpc.CallOption) (*clientpb.Website, error) {\n\tout := new(clientpb.Website)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/WebsiteAddContent\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\ttoken, err := jwt.ParseWithClaims(tokenString, &IanaClaims{}, func(token *jwt.Token) (interface{}, error) {\n\t\treturn []byte(Get().LoginToken.SigningKey), nil\n\t})", "is_vulnerable": 1}
{"code": "func checkProcMount(rootfs, dest, source string) error {\n\tconst procPath = \"/proc\"\n\t// White list, it should be sub directories of invalid destinations\n\tvalidDestinations := []string{\n\t\t// These entries can be bind mounted by files emulated by fuse,\n\t\t// so commands like top, free displays stats in container.\n\t\t\"/proc/cpuinfo\",\n\t\t\"/proc/diskstats\",\n\t\t\"/proc/meminfo\",\n\t\t\"/proc/stat\",\n\t\t\"/proc/swaps\",\n\t\t\"/proc/uptime\",\n\t\t\"/proc/loadavg\",\n\t\t\"/proc/net/dev\",\n\t}\n\tfor _, valid := range validDestinations {\n\t\tpath, err := filepath.Rel(filepath.Join(rootfs, valid), dest)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif path == \".\" {\n\t\t\treturn nil\n\t\t}\n\t}\n\tpath, err := filepath.Rel(filepath.Join(rootfs, procPath), dest)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// pass if the mount path is located outside of /proc\n\tif strings.HasPrefix(path, \"..\") {\n\t\treturn nil\n\t}\n\tif path == \".\" {\n\t\t// an empty source is pasted on restore\n\t\tif source == \"\" {\n\t\t\treturn nil\n\t\t}\n\t\t// only allow a mount on-top of proc if it's source is \"proc\"\n\t\tisproc, err := isProc(source)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// pass if the mount is happening on top of /proc and the source of\n\t\t// the mount is a proc filesystem\n\t\tif isproc {\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"%q cannot be mounted because it is not of type proc\", dest)\n\t}\n\treturn fmt.Errorf(\"%q cannot be mounted because it is inside /proc\", dest)\n}", "is_vulnerable": 0}
{"code": "var LoginHandler = UA(func(w http.ResponseWriter, r *http.Request, sess Session) {\n\tredirectURL, err := url.QueryUnescape(r.FormValue(\"next\"))\n\tif redirectURL == \"\" || err != nil {\n\t\tredirectURL = \"/\"\n\t}\n\tif sess.IsUserValid() {\n\t\thttp.Redirect(w, r, redirectURL, http.StatusSeeOther)\n\t\treturn\n\t}\n\n\tif r.Method == \"POST\" {\n\t\tuserName := r.PostFormValue(\"username\")\n\t\tpasswd := r.PostFormValue(\"passwd\")\n\t\tif len(userName) > 200 || len(passwd) > 200 {\n\t\t\tfmt.Fprint(w, \"username / password too long.\")\n\t\t\treturn\n\t\t}\n\t\tif err = sess.Authenticate(userName, passwd); err == nil {\n\t\t\thttp.Redirect(w, r, redirectURL, http.StatusSeeOther)\n\t\t\treturn\n\t\t} else {\n\t\t\tsess.SetFlashMsg(err.Error())\n\t\t\thttp.Redirect(w, r, \"/login?next=\"+redirectURL, http.StatusSeeOther)\n\t\t\treturn\n\t\t}\n\t}\n\ttemplates.Render(w, \"login.html\", map[string]interface{}{\n\t\t\"Common\":   readCommonData(r, sess),\n\t\t\"next\":     template.URL(url.QueryEscape(redirectURL)),\n\t\t\"LoginMsg\": models.Config(models.LoginMsg),\n\t})\n})", "is_vulnerable": 1}
{"code": "func containsUnsafePathSegments(id string) bool {\n\t// handle the relative reference to current and parent path.\n\tif id == \".\" || id == \"..\" {\n\t\treturn true\n\t}\n\n\treturn strings.ContainsAny(id, \"\\\\/\")\n}", "is_vulnerable": 0}
{"code": "func TestHostMatcher(t *testing.T) {\n\ttestCases := []struct {\n\t\tName   string\n\t\tK      string\n\t\tV      string\n\t\tExpect *routepb.HeaderMatcher\n\t}{\n\t\t{\n\t\t\tName: \"present match\",\n\t\t\tK:    \":authority\",\n\t\t\tV:    \"*\",\n\t\t\tExpect: &routepb.HeaderMatcher{\n\t\t\t\tName:                 \":authority\",\n\t\t\t\tHeaderMatchSpecifier: &routepb.HeaderMatcher_PresentMatch{PresentMatch: true},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"prefix match\",\n\t\t\tK:    \":authority\",\n\t\t\tV:    \"*.example.com\",\n\t\t\tExpect: &routepb.HeaderMatcher{\n\t\t\t\tName: \":authority\",\n\t\t\t\tHeaderMatchSpecifier: &routepb.HeaderMatcher_SafeRegexMatch{\n\t\t\t\t\tSafeRegexMatch: &matcherpb.RegexMatcher{\n\t\t\t\t\t\tEngineType: &matcherpb.RegexMatcher_GoogleRe2{\n\t\t\t\t\t\t\tGoogleRe2: &matcherpb.RegexMatcher_GoogleRE2{},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRegex: `(?i).*\\.example\\.com`,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"suffix match\",\n\t\t\tK:    \":authority\",\n\t\t\tV:    \"example.*\",\n\t\t\tExpect: &routepb.HeaderMatcher{\n\t\t\t\tName: \":authority\",\n\t\t\t\tHeaderMatchSpecifier: &routepb.HeaderMatcher_SafeRegexMatch{\n\t\t\t\t\tSafeRegexMatch: &matcherpb.RegexMatcher{\n\t\t\t\t\t\tEngineType: &matcherpb.RegexMatcher_GoogleRe2{\n\t\t\t\t\t\t\tGoogleRe2: &matcherpb.RegexMatcher_GoogleRE2{},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRegex: `(?i)example\\..*`,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"exact match\",\n\t\t\tK:    \":authority\",\n\t\t\tV:    \"example.com\",\n\t\t\tExpect: &routepb.HeaderMatcher{\n\t\t\t\tName: \":authority\",\n\t\t\t\tHeaderMatchSpecifier: &routepb.HeaderMatcher_SafeRegexMatch{\n\t\t\t\t\tSafeRegexMatch: &matcherpb.RegexMatcher{\n\t\t\t\t\t\tEngineType: &matcherpb.RegexMatcher_GoogleRe2{\n\t\t\t\t\t\t\tGoogleRe2: &matcherpb.RegexMatcher_GoogleRE2{},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRegex: `(?i)example\\.com`,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tactual := HostMatcher(tc.K, tc.V)\n\t\t\tif re := actual.GetSafeRegexMatch().GetRegex(); re != \"\" {\n\t\t\t\t_, err := regexp.Compile(re)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"failed to compile regex %s: %v\", re, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !cmp.Equal(tc.Expect, actual, protocmp.Transform()) {\n\t\t\t\tt.Errorf(\"expecting %v, but got %v\", tc.Expect, actual)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\tclusterInfo.IterateHierarchy(key, func(resource *clustercache.Resource, namespaceResources map[kube.ResourceKey]*clustercache.Resource) bool {\n\t\treturn action(asResourceNode(resource), getApp(resource, namespaceResources))\n\t})", "is_vulnerable": 0}
{"code": "func New(config *rest.Config) Engine {\n\treturn Engine{\n\t\tconfig: config,\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestClearCookieHeader(t *testing.T) {\n\tt.Run(\"Clear cookie header should clear Cookie header\", func(t *testing.T) {\n\t\treq, err := http.NewRequest(http.MethodGet, \"/\", nil)\n\t\trequire.NoError(t, err)\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie\"})\n\n\t\tClearCookieHeader(req, nil, nil)\n\t\trequire.NotContains(t, req.Header, \"Cookie\")\n\t})\n\n\tt.Run(\"Clear cookie header with cookies to keep should clear Cookie header and keep cookies\", func(t *testing.T) {\n\t\treq, err := http.NewRequest(http.MethodGet, \"/\", nil)\n\t\trequire.NoError(t, err)\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie1\"})\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie2\"})\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie3\"})\n\n\t\tClearCookieHeader(req, []string{\"cookie1\", \"cookie3\"}, nil)\n\t\trequire.Contains(t, req.Header, \"Cookie\")\n\t\trequire.Equal(t, \"cookie1=; cookie3=\", req.Header.Get(\"Cookie\"))\n\t})\n\n\tt.Run(\"Clear cookie header with cookies to keep and skip should clear Cookie header and keep cookies\", func(t *testing.T) {\n\t\treq, err := http.NewRequest(http.MethodGet, \"/\", nil)\n\t\trequire.NoError(t, err)\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie1\"})\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie2\"})\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie3\"})\n\n\t\tClearCookieHeader(req, []string{\"cookie1\", \"cookie3\"}, []string{\"cookie3\"})\n\t\trequire.Contains(t, req.Header, \"Cookie\")\n\t\trequire.Equal(t, \"cookie1=\", req.Header.Get(\"Cookie\"))\n\t})\n}", "is_vulnerable": 0}
{"code": "func (s *TestSuiteIAM) TestSTSForRoot(c *check) {\n\tctx, cancel := context.WithTimeout(context.Background(), testDefaultTimeout)\n\tdefer cancel()\n\n\tbucket := getRandomBucketName()\n\terr := s.client.MakeBucket(ctx, bucket, minio.MakeBucketOptions{})\n\tif err != nil {\n\t\tc.Fatalf(\"bucket create error: %v\", err)\n\t}\n\n\tassumeRole := cr.STSAssumeRole{\n\t\tClient:      s.TestSuiteCommon.client,\n\t\tSTSEndpoint: s.endPoint,\n\t\tOptions: cr.STSAssumeRoleOptions{\n\t\t\tAccessKey: globalActiveCred.AccessKey,\n\t\t\tSecretKey: globalActiveCred.SecretKey,\n\t\t\tLocation:  \"\",\n\t\t},\n\t}\n\n\tvalue, err := assumeRole.Retrieve()\n\tif err != nil {\n\t\tc.Fatalf(\"err calling assumeRole: %v\", err)\n\t}\n\n\tminioClient, err := minio.New(s.endpoint, &minio.Options{\n\t\tCreds:     cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure:    s.secure,\n\t\tTransport: s.TestSuiteCommon.client.Transport,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Error initializing client: %v\", err)\n\t}\n\n\t// Validate that the client from sts creds can access the bucket.\n\tc.mustListObjects(ctx, minioClient, bucket)\n\n\t// Validate that a bucket can be created\n\tbucket2 := getRandomBucketName()\n\terr = minioClient.MakeBucket(ctx, bucket2, minio.MakeBucketOptions{})\n\tif err != nil {\n\t\tc.Fatalf(\"bucket creat error: %v\", err)\n\t}\n\n\t// Validate that admin APIs can be called - create an madmin client with\n\t// user creds\n\tuserAdmClient, err := madmin.NewWithOptions(s.endpoint, &madmin.Options{\n\t\tCreds:  cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure: s.secure,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Err creating user admin client: %v\", err)\n\t}\n\tuserAdmClient.SetCustomTransport(s.TestSuiteCommon.client.Transport)\n\n\taccInfo, err := userAdmClient.AccountInfo(ctx, madmin.AccountOpts{})\n\tif err != nil {\n\t\tc.Fatalf(\"root user STS should be able to get account info: %v\", err)\n\t}\n\n\tgotBuckets := set.NewStringSet()\n\tfor _, b := range accInfo.Buckets {\n\t\tgotBuckets.Add(b.Name)\n\t\tif !(b.Access.Read && b.Access.Write) {\n\t\t\tc.Fatalf(\"root user should have read and write access to bucket: %v\", b.Name)\n\t\t}\n\t}\n\tshouldHaveBuckets := set.CreateStringSet(bucket2, bucket)\n\tif !gotBuckets.Equals(shouldHaveBuckets) {\n\t\tc.Fatalf(\"root user should have access to all buckets\")\n\t}\n\n\t// This must fail.\n\tif err := userAdmClient.AddUser(ctx, globalActiveCred.AccessKey, globalActiveCred.SecretKey); err == nil {\n\t\tc.Fatal(\"AddUser() for root credential must fail via root STS creds\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Server) Check(ctx context.Context, req *openfgapb.CheckRequest) (*openfgapb.CheckResponse, error) {\n\ttk := req.GetTupleKey()\n\tctx, span := tracer.Start(ctx, \"Check\", trace.WithAttributes(\n\t\tattribute.KeyValue{Key: \"object\", Value: attribute.StringValue(tk.GetObject())},\n\t\tattribute.KeyValue{Key: \"relation\", Value: attribute.StringValue(tk.GetRelation())},\n\t\tattribute.KeyValue{Key: \"user\", Value: attribute.StringValue(tk.GetUser())},\n\t))\n\tdefer span.End()\n\n\tif tk.GetUser() == \"\" || tk.GetRelation() == \"\" || tk.GetObject() == \"\" {\n\t\treturn nil, serverErrors.InvalidCheckInput\n\t}\n\n\tstoreID := req.GetStoreId()\n\n\tmodelID, err := s.resolveAuthorizationModelID(ctx, storeID, req.GetAuthorizationModelId())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmodel, err := s.datastore.ReadAuthorizationModel(ctx, storeID, modelID)\n\tif err != nil {\n\t\tif errors.Is(err, storage.ErrNotFound) {\n\t\t\treturn nil, serverErrors.AuthorizationModelNotFound(modelID)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tif !typesystem.IsSchemaVersionSupported(model.GetSchemaVersion()) {\n\t\treturn nil, serverErrors.ValidationError(typesystem.ErrInvalidSchemaVersion)\n\t}\n\n\ttypesys, err := typesystem.NewAndValidate(ctx, model)\n\tif err != nil {\n\t\treturn nil, serverErrors.ValidationError(typesystem.ErrInvalidModel)\n\t}\n\n\tif err := validation.ValidateUserObjectRelation(typesys, tk); err != nil {\n\t\treturn nil, serverErrors.ValidationError(err)\n\t}\n\n\tfor _, ctxTuple := range req.GetContextualTuples().GetTupleKeys() {\n\t\tif err := validation.ValidateTuple(typesys, ctxTuple); err != nil {\n\t\t\treturn nil, serverErrors.HandleTupleValidateError(err)\n\t\t}\n\t}\n\n\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\tcheckResolver := graph.NewLocalChecker(\n\t\tstorage.NewCombinedTupleReader(s.datastore, req.ContextualTuples.GetTupleKeys()),\n\t\tcheckConcurrencyLimit)\n\n\tresp, err := checkResolver.ResolveCheck(ctx, &graph.ResolveCheckRequest{\n\t\tStoreID:              req.GetStoreId(),\n\t\tAuthorizationModelID: req.GetAuthorizationModelId(),\n\t\tTupleKey:             req.GetTupleKey(),\n\t\tContextualTuples:     req.ContextualTuples.GetTupleKeys(),\n\t\tResolutionMetadata: &graph.ResolutionMetadata{\n\t\t\tDepth: s.config.ResolveNodeLimit,\n\t\t},\n\t})\n\tif err != nil {\n\t\tif errors.Is(err, graph.ErrResolutionDepthExceeded) {\n\t\t\treturn nil, serverErrors.AuthorizationModelResolutionTooComplex\n\t\t}\n\n\t\treturn nil, serverErrors.HandleError(\"\", err)\n\t}\n\n\tres := &openfgapb.CheckResponse{\n\t\tAllowed: resp.Allowed,\n\t}\n\n\tspan.SetAttributes(attribute.KeyValue{Key: \"allowed\", Value: attribute.BoolValue(res.GetAllowed())})\n\treturn res, nil\n}", "is_vulnerable": 0}
{"code": "func (e *EngineInfo) RequiredVersion() string {\n\treturn C.GoString(e.info.req_version)\n}", "is_vulnerable": 1}
{"code": "func (c *managedIdentityClient) createServiceFabricAuthRequest(ctx context.Context, id ManagedIDKind, scopes []string) (*policy.Request, error) {\n\trequest, err := azruntime.NewRequest(ctx, http.MethodGet, c.endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tq := request.Raw().URL.Query()\n\trequest.Raw().Header.Set(\"Accept\", \"application/json\")\n\trequest.Raw().Header.Set(\"Secret\", os.Getenv(identityHeader))\n\tq.Add(\"api-version\", serviceFabricAPIVersion)\n\tq.Add(\"resource\", strings.Join(scopes, \" \"))\n\tif id != nil {\n\t\tlog.Write(EventAuthentication, \"WARNING: Service Fabric doesn't support selecting a user-assigned identity at runtime\")\n\t\tif id.idKind() == miResourceID {\n\t\t\tq.Add(miResID, id.String())\n\t\t} else {\n\t\t\tq.Add(qpClientID, id.String())\n\t\t}\n\t}\n\trequest.Raw().URL.RawQuery = q.Encode()\n\treturn request, nil\n}", "is_vulnerable": 0}
{"code": "\tg.POST(\"/shortcut\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing user in session\")\n\t\t}\n\t\tshortcutCreate := &api.ShortcutCreate{\n\t\t\tCreatorID: userID,\n\t\t}\n\t\tif err := json.NewDecoder(c.Request().Body).Decode(shortcutCreate); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Malformatted post shortcut request\").SetInternal(err)\n\t\t}\n\n\t\tshortcut, err := s.Store.CreateShortcut(ctx, shortcutCreate)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to create shortcut\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"shortcut created\",\n\t\t})\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(shortcut)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode shortcut response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "func (c *Client) query(endpoint string, out interface{}, q *QueryOptions) (*QueryMeta, error) {\n\tr := c.newRequest(\"GET\", endpoint)\n\tr.setQueryOptions(q)\n\trtt, resp, err := requireOK(c.doRequest(r))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\n\tqm := &QueryMeta{}\n\tparseQueryMeta(resp, qm)\n\tqm.RequestTime = rtt\n\n\tif err := decodeBody(resp, out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn qm, nil\n}", "is_vulnerable": 1}
{"code": "func assertResourceActions(t *testing.T, appName string, successful bool) {\n\tassertError := func(err error, message string) {\n\t\tif successful {\n\t\t\tassert.NoError(t, err)\n\t\t} else {\n\t\t\tif assert.Error(t, err) {\n\t\t\t\tassert.Contains(t, err.Error(), message)\n\t\t\t}\n\t\t}\n\t}\n\n\tcloser, cdClient := ArgoCDClientset.NewApplicationClientOrDie()\n\tdefer io.Close(closer)\n\n\tdeploymentResource, err := KubeClientset.AppsV1().Deployments(DeploymentNamespace()).Get(context.Background(), \"guestbook-ui\", metav1.GetOptions{})\n\trequire.NoError(t, err)\n\n\tlogs, err := cdClient.PodLogs(context.Background(), &applicationpkg.ApplicationPodLogsQuery{\n\t\tGroup: pointer.String(\"apps\"), Kind: pointer.String(\"Deployment\"), Name: &appName, Namespace: DeploymentNamespace(),\n\t})\n\trequire.NoError(t, err)\n\t_, err = logs.Recv()\n\tassertError(err, \"EOF\")\n\n\texpectedError := fmt.Sprintf(\"Deployment apps guestbook-ui not found as part of application %s\", appName)\n\n\t_, err = cdClient.ListResourceEvents(context.Background(), &applicationpkg.ApplicationResourceEventsQuery{\n\t\tName: &appName, ResourceName: \"guestbook-ui\", ResourceNamespace: DeploymentNamespace(), ResourceUID: string(deploymentResource.UID)})\n\tassertError(err, fmt.Sprintf(\"%s not found as part of application %s\", \"guestbook-ui\", appName))\n\n\t_, err = cdClient.GetResource(context.Background(), &applicationpkg.ApplicationResourceRequest{\n\t\tName: &appName, ResourceName: \"guestbook-ui\", Namespace: DeploymentNamespace(), Version: \"v1\", Group: \"apps\", Kind: \"Deployment\"})\n\tassertError(err, expectedError)\n\n\t_, err = cdClient.DeleteResource(context.Background(), &applicationpkg.ApplicationResourceDeleteRequest{\n\t\tName: &appName, ResourceName: \"guestbook-ui\", Namespace: DeploymentNamespace(), Version: \"v1\", Group: \"apps\", Kind: \"Deployment\",\n\t})\n\tassertError(err, expectedError)\n\n\t_, err = cdClient.RunResourceAction(context.Background(), &applicationpkg.ResourceActionRunRequest{\n\t\tName: &appName, ResourceName: \"guestbook-ui\", Namespace: DeploymentNamespace(), Version: \"v1\", Group: \"apps\", Kind: \"Deployment\", Action: \"restart\",\n\t})\n\tassertError(err, expectedError)\n}", "is_vulnerable": 0}
{"code": "func (*internalContext) Serve(ServeOptions) (ServeResult, error) {\n\treturn ServeResult{}, fmt.Errorf(\"The \\\"serve\\\" API is not supported when using WebAssembly\")\n}", "is_vulnerable": 0}
{"code": "func (mr *MockResourceOwnerPasswordCredentialsGrantStorageMockRecorder) CreateAccessTokenSession(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"CreateAccessTokenSession\", reflect.TypeOf((*MockResourceOwnerPasswordCredentialsGrantStorage)(nil).CreateAccessTokenSession), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"authenticate\", func(t *testing.T) {\n\t\toptions := &config.Options{\n\t\t\tServices:                 \"all\",\n\t\t\tAuthenticateURLString:    \"https://authenticate.example.com\",\n\t\t\tAuthenticateCallbackPath: \"/oauth2/callback\",\n\t\t}\n\t\troutes, err := b.buildPomeriumHTTPRoutes(options, \"authenticate.example.com\", false)\n\t\trequire.NoError(t, err)\n\n\t\ttestutil.AssertProtoJSONEqual(t, `[\n\t\t\t`+routeString(\"path\", \"/.pomerium/jwt\", true)+`,\n\t\t\t`+routeString(\"path\", urlutil.WebAuthnURLPath, true)+`,\n\t\t\t`+routeString(\"path\", \"/ping\", false)+`,\n\t\t\t`+routeString(\"path\", \"/healthz\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.well-known/pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.well-known/pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/robots.txt\", false)+`,\n\t\t\t`+routeString(\"path\", \"/oauth2/callback\", false)+`,\n\t\t\t`+routeString(\"path\", \"/\", false)+`\n\t\t]`, routes)\n\t})", "is_vulnerable": 1}
{"code": "func (s *ctlcmdSuite) TestRootRequiredCommandFailureParsingTweak(c *C) {\n\t_, _, err := ctlcmd.Run(s.mockContext, []string{\"start\", \"--\", \"--help\"}, 1000)\n\n\tc.Check(err, FitsTypeOf, &ctlcmd.ForbiddenCommandError{})\n\tc.Check(err.Error(), Equals, `cannot use \"start\" with uid 1000, try with sudo`)\n}", "is_vulnerable": 0}
{"code": "func (e *Export) IsRevoked(pubKey string) bool {\n\treturn e.Revocations.IsRevoked(pubKey, time.Now())\n}", "is_vulnerable": 1}
{"code": "func run(args options, clientBuildFS fs.FS) {\n\t// configure config filename\n\tinitConfigFilename(args)\n\n\t// configure working dir and config path\n\tinitWorkingDir(args)\n\n\t// configure log level and output\n\tconfigureLogger(args)\n\n\t// Print the first message after logger is configured.\n\tlog.Println(version.Full())\n\tlog.Debug(\"current working directory is %s\", Context.workDir)\n\tif args.runningAsService {\n\t\tlog.Info(\"AdGuard Home is running as a service\")\n\t}\n\n\tsetupContext(args)\n\n\terr := configureOS(config)\n\tfatalOnError(err)\n\n\t// clients package uses filtering package's static data (filtering.BlockedSvcKnown()),\n\t//  so we have to initialize filtering's static data first,\n\t//  but also avoid relying on automatic Go init() function\n\tfiltering.InitModule()\n\n\terr = setupConfig(args)\n\tfatalOnError(err)\n\n\tif !Context.firstRun {\n\t\t// Save the updated config\n\t\terr = config.write()\n\t\tfatalOnError(err)\n\n\t\tif config.DebugPProf {\n\t\t\tmux := http.NewServeMux()\n\t\t\tmux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline)\n\t\t\tmux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile)\n\t\t\tmux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n\t\t\tmux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace)\n\t\t\tgo func() {\n\t\t\t\tlog.Info(\"pprof: listening on localhost:6060\")\n\t\t\t\tlerr := http.ListenAndServe(\"localhost:6060\", mux)\n\t\t\t\tlog.Error(\"Error while running the pprof server: %s\", lerr)\n\t\t\t}()\n\t\t}\n\t}\n\n\terr = os.MkdirAll(Context.getDataDir(), 0o755)\n\tif err != nil {\n\t\tlog.Fatalf(\"Cannot create DNS data dir at %s: %s\", Context.getDataDir(), err)\n\t}\n\n\tsessFilename := filepath.Join(Context.getDataDir(), \"sessions.db\")\n\tGLMode = args.glinetMode\n\tvar arl *authRateLimiter\n\tif config.AuthAttempts > 0 && config.AuthBlockMin > 0 {\n\t\tarl = newAuthRateLimiter(\n\t\t\ttime.Duration(config.AuthBlockMin)*time.Minute,\n\t\t\tconfig.AuthAttempts,\n\t\t)\n\t} else {\n\t\tlog.Info(\"authratelimiter is disabled\")\n\t}\n\n\tContext.auth = InitAuth(\n\t\tsessFilename,\n\t\tconfig.Users,\n\t\tconfig.WebSessionTTLHours*60*60,\n\t\tarl,\n\t)\n\tif Context.auth == nil {\n\t\tlog.Fatalf(\"Couldn't initialize Auth module\")\n\t}\n\tconfig.Users = nil\n\n\tContext.tls = tlsCreate(config.TLS)\n\tif Context.tls == nil {\n\t\tlog.Fatalf(\"Can't initialize TLS module\")\n\t}\n\n\tContext.web, err = initWeb(args, clientBuildFS)\n\tfatalOnError(err)\n\n\tif !Context.firstRun {\n\t\terr = initDNSServer()\n\t\tfatalOnError(err)\n\n\t\tContext.tls.Start()\n\n\t\tgo func() {\n\t\t\tserr := startDNSServer()\n\t\t\tif serr != nil {\n\t\t\t\tcloseDNSServer()\n\t\t\t\tfatalOnError(serr)\n\t\t\t}\n\t\t}()\n\n\t\tif Context.dhcpServer != nil {\n\t\t\terr = Context.dhcpServer.Start()\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"starting dhcp server: %s\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\tContext.web.Start()\n\n\t// wait indefinitely for other go-routines to complete their job\n\tselect {}\n}", "is_vulnerable": 1}
{"code": "func main() {\n\tlog.Println(\"[i] Server started\")\n\n\t// Connect to DB\n\tdb, err := sql.Open(\"postgres\", \"user=appread dbname='quantifiedSelf' sslmode=disable\")\n\tfailOnError(err, \"Error connecting to database\")\n\tdefer db.Close()\n\n\thttp.HandleFunc(\"/data/all/\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// TODO: Allow filtering via URL\n\t\t// Get rows from DB\n\t\tvar output string\n\t\terr := db.QueryRow(`SELECT json_agg(r) FROM (SELECT * FROM trello.cards) r;`).Scan(&output)\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tfmt.Fprint(w, output)\n\t})\n\n\t// Restful handler\n\tr := mux.NewRouter()\n\tr.HandleFunc(\"/api\", func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintln(w, \"dla;jfkdlsajflkdsa;jfk;ldsajfklds;a\")\n\t})\n\n\tr.HandleFunc(\"/api/totals/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, end_of_day_total from trello.dailytallies order by day DESC limit $1) r;`\n\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})\n\n\tr.HandleFunc(\"/api/diffs/last/{num}\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// Grab vars\n\t\tvars := mux.Vars(r)\n\n\t\tvar output string\n\t\t// This is bad... don't do this.... omg\n\t\tquery := `SELECT json_agg(r) FROM (select EXTRACT(epoch FROM day) as day, up_count, down_count, finished_count from trello.dailytallies order by day DESC limit $1) r;`\n\t\terr := db.QueryRow(query, vars[\"num\"]).Scan(&output)\n\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error retriving from DB, \", err)\n\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\tfmt.Fprintln(w, \"Error retriving from DB, \", err)\n\t\t\treturn\n\t\t}\n\n\t\t// Print out returned\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tfmt.Fprint(w, output)\n\t})\n\tr.PathPrefix(\"/\").Handler(http.FileServer(http.Dir(\"../ui\")))\n\thttp.Handle(\"/\", r)\n\n\t// Die gracefully\n\t// killchan := make(chan os.Signal)\n\t// signal.Notify(killchan, os.Interrupt, os.Kill)\n\n\tlog.Println(\"[i] Serving on \", servport, \"\\n\\tWaiting...\")\n\n\tlog.Fatal(http.ListenAndServe(servport, nil))\n\t// <-killchan\n\n\tlog.Println(\"[i] Shutting down...\")\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetGrantedScopes() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetGrantedScopes\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetGrantedScopes))\n}", "is_vulnerable": 0}
{"code": "func GenerateCryptoString(n int) (string, error) {\n\tconst chars = \"123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-\"\n\tret := make([]byte, n)\n\tfor i := range ret {\n\t\tnum, err := crand.Int(crand.Reader, big.NewInt(int64(len(chars))))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tret[i] = chars[num.Int64()]\n\t}\n\n\treturn string(ret), nil\n}", "is_vulnerable": 0}
{"code": "func doProcessRequirementsEnabled(c *chart.Chart, v *chart.Config, path string) error {\n\treqs, err := LoadRequirements(c)\n\tif err != nil {\n\t\t// if not just missing requirements file, return error\n\t\tif nerr, ok := err.(ErrNoRequirementsFile); !ok {\n\t\t\treturn nerr\n\t\t}\n\n\t\t// no requirements to process\n\t\treturn nil\n\t}\n\n\tvar chartDependencies []*chart.Chart\n\t// If any dependency is not a part of requirements.yaml\n\t// then this should be added to chartDependencies.\n\t// However, if the dependency is already specified in requirements.yaml\n\t// we should not add it, as it would be anyways processed from requirements.yaml\n\n\tfor _, existingDependency := range c.Dependencies {\n\t\tvar dependencyFound bool\n\t\tfor _, req := range reqs.Dependencies {\n\t\t\tif existingDependency.Metadata.Name == req.Name && version.IsCompatibleRange(req.Version, existingDependency.Metadata.Version) {\n\t\t\t\tdependencyFound = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !dependencyFound {\n\t\t\tchartDependencies = append(chartDependencies, existingDependency)\n\t\t}\n\t}\n\n\tfor _, req := range reqs.Dependencies {\n\t\tif chartDependency := getAliasDependency(c.Dependencies, req); chartDependency != nil {\n\t\t\tchartDependencies = append(chartDependencies, chartDependency)\n\t\t}\n\t\tif req.Alias != \"\" {\n\t\t\tif !aliasRegexp.MatchString(req.Alias) {\n\t\t\t\treturn fmt.Errorf(\"illegal alias name in %q\", req.Name)\n\t\t\t}\n\t\t\treq.Name = req.Alias\n\t\t}\n\t}\n\tc.Dependencies = chartDependencies\n\n\t// set all to true\n\tfor _, lr := range reqs.Dependencies {\n\t\tlr.Enabled = true\n\t}\n\tcvals, err := CoalesceValues(c, v)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// convert our values back into config\n\tyvals, err := cvals.YAML()\n\tif err != nil {\n\t\treturn err\n\t}\n\tcc := chart.Config{Raw: yvals}\n\t// flag dependencies as enabled/disabled\n\tProcessRequirementsTags(reqs, cvals)\n\tProcessRequirementsConditions(reqs, cvals, path)\n\t// make a map of charts to remove\n\trm := map[string]bool{}\n\tfor _, r := range reqs.Dependencies {\n\t\tif !r.Enabled {\n\t\t\t// remove disabled chart\n\t\t\trm[r.Name] = true\n\t\t}\n\t}\n\t// don't keep disabled charts in new slice\n\tcd := []*chart.Chart{}\n\tcopy(cd, c.Dependencies[:0])\n\tfor _, n := range c.Dependencies {\n\t\tif _, ok := rm[n.Metadata.Name]; !ok {\n\t\t\tcd = append(cd, n)\n\t\t}\n\n\t}\n\t// recursively call self to process sub dependencies\n\tfor _, t := range cd {\n\t\tsubpath := path + t.Metadata.Name + \".\"\n\t\terr := doProcessRequirementsEnabled(t, &cc, subpath)\n\t\t// if its not just missing requirements file, return error\n\t\tif nerr, ok := err.(ErrNoRequirementsFile); !ok && err != nil {\n\t\t\treturn nerr\n\t\t}\n\t}\n\tc.Dependencies = cd\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tlog.Debug(\"%s %v\", r.Method, r.URL)\n\n\t\tif r.Method != method {\n\t\t\taghhttp.Error(r, w, http.StatusMethodNotAllowed, \"only %s is allowed\", method)\n\n\t\t\treturn\n\t\t}\n\n\t\tif method == http.MethodPost || method == http.MethodPut || method == http.MethodDelete {\n\t\t\tif r.Header.Get(aghhttp.HdrNameContentType) != aghhttp.HdrValApplicationJSON {\n\t\t\t\taghhttp.Error(\n\t\t\t\t\tr,\n\t\t\t\t\tw,\n\t\t\t\t\thttp.StatusUnsupportedMediaType,\n\t\t\t\t\t\"only %s is allowed\",\n\t\t\t\t\taghhttp.HdrValApplicationJSON,\n\t\t\t\t)\n\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tContext.controlLock.Lock()\n\t\t\tdefer Context.controlLock.Unlock()\n\t\t}\n\n\t\thandler(w, r)\n\t}", "is_vulnerable": 0}
{"code": "func (expr *IntroducerExpr) eval(env *ExpressionEnv) (eval, error) {\n\te, err := expr.Inner.eval(env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif expr.TypedCollation.Collation == collations.CollationBinaryID {\n\t\treturn evalToBinary(e), nil\n\t}\n\treturn evalToVarchar(e, expr.TypedCollation.Collation, false)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Download(ctx context.Context, in *sliverpb.DownloadReq, opts ...grpc.CallOption) (*sliverpb.Download, error) {\n\tout := new(sliverpb.Download)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Download\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (client *DecryptionClient) getPadder(cekAlg string) Padder {\n\tpadder, ok := client.PadderRegistry[cekAlg]\n\tif !ok {\n\t\tpadder, ok = client.PadderRegistry[cekAlg[strings.LastIndex(cekAlg, \"/\")+1:]]\n\t\tif !ok {\n\t\t\treturn NoPadder\n\t\t}\n\t}\n\treturn padder\n}", "is_vulnerable": 1}
{"code": "func TestTrimURLPath(t *testing.T) {\n\ttests := []struct {\n\t\tpath, expected string\n\t}{\n\t\t{\"\", \"\"},\n\t\t{\"//\", \"\"},\n\t\t{\"/pods\", \"pods\"},\n\t\t{\"pods\", \"pods\"},\n\t\t{\"pods/\", \"pods\"},\n\t\t{\"good/\", \"good\"},\n\t\t{\"pods/probes\", \"pods\"},\n\t\t{\"metrics\", \"metrics\"},\n\t\t{\"metrics/resource\", \"metrics/resource\"},\n\t\t{\"metrics/hello\", \"metrics/hello\"},\n\t}\n\n\tfor _, test := range tests {\n\t\tassert.Equal(t, test.expected, getURLRootPath(test.path), fmt.Sprintf(\"path is: %s\", test.path))\n\t}\n}", "is_vulnerable": 0}
{"code": "func RedactURL(u *url.URL) string {\n\tif u == nil {\n\t\treturn \"\"\n\t}\n\n\tru := *u\n\tif _, has := ru.User.Password(); has {\n\t\tru.User = url.UserPassword(ru.User.Username(), \"xxxxx\")\n\t}\n\treturn ru.String()\n}", "is_vulnerable": 1}
{"code": "func (h *Handler) Filecmd(request *sftp.Request) error {\n\tif h.ro {\n\t\treturn sftp.ErrSSHFxOpUnsupported\n\t}\n\tl := h.logger.WithField(\"source\", request.Filepath)\n\tif request.Target != \"\" {\n\t\tl = l.WithField(\"target\", request.Target)\n\t}\n\n\tswitch request.Method {\n\t// Allows a user to make changes to the permissions of a given file or directory\n\t// on their server using their SFTP client.\n\tcase \"Setstat\":\n\t\tif !h.can(PermissionFileUpdate) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tmode := request.Attributes().FileMode().Perm()\n\t\t// If the client passes an invalid FileMode just use the default 0644.\n\t\tif mode == 0o000 {\n\t\t\tmode = os.FileMode(0o644)\n\t\t}\n\t\t// Force directories to be 0755.\n\t\tif request.Attributes().FileMode().IsDir() {\n\t\t\tmode = 0o755\n\t\t}\n\t\tif err := h.fs.Chmod(request.Filepath, mode); err != nil {\n\t\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\t\treturn sftp.ErrSSHFxNoSuchFile\n\t\t\t}\n\t\t\tl.WithField(\"error\", err).Error(\"failed to perform setstat on item\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\tbreak\n\t// Support renaming a file (aka Move).\n\tcase \"Rename\":\n\t\tif !h.can(PermissionFileUpdate) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tif err := h.fs.Rename(request.Filepath, request.Target); err != nil {\n\t\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\t\treturn sftp.ErrSSHFxNoSuchFile\n\t\t\t}\n\t\t\tl.WithField(\"error\", err).Error(\"failed to rename file\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\th.events.MustLog(server.ActivitySftpRename, FileAction{Entity: request.Filepath, Target: request.Target})\n\t\tbreak\n\t// Handle deletion of a directory. This will properly delete all of the files and\n\t// folders within that directory if it is not already empty (unlike a lot of SFTP\n\t// clients that must delete each file individually).\n\tcase \"Rmdir\":\n\t\tif !h.can(PermissionFileDelete) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tp := filepath.Clean(request.Filepath)\n\t\tif err := h.fs.Delete(p); err != nil {\n\t\t\tl.WithField(\"error\", err).Error(\"failed to remove directory\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\th.events.MustLog(server.ActivitySftpDelete, FileAction{Entity: request.Filepath})\n\t\treturn sftp.ErrSSHFxOk\n\t// Handle requests to create a new Directory.\n\tcase \"Mkdir\":\n\t\tif !h.can(PermissionFileCreate) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tname := strings.Split(filepath.Clean(request.Filepath), \"/\")\n\t\tp := strings.Join(name[0:len(name)-1], \"/\")\n\t\tif err := h.fs.CreateDirectory(name[len(name)-1], p); err != nil {\n\t\t\tl.WithField(\"error\", err).Error(\"failed to create directory\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\th.events.MustLog(server.ActivitySftpCreateDirectory, FileAction{Entity: request.Filepath})\n\t\tbreak\n\t// Support creating symlinks between files. The source and target must resolve within\n\t// the server home directory.\n\tcase \"Symlink\":\n\t\tif !h.can(PermissionFileCreate) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tsource, err := h.fs.SafePath(request.Filepath)\n\t\tif err != nil {\n\t\t\treturn sftp.ErrSSHFxNoSuchFile\n\t\t}\n\t\ttarget, err := h.fs.SafePath(request.Target)\n\t\tif err != nil {\n\t\t\treturn sftp.ErrSSHFxNoSuchFile\n\t\t}\n\t\tif err := os.Symlink(source, target); err != nil {\n\t\t\tl.WithField(\"target\", target).WithField(\"error\", err).Error(\"failed to create symlink\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\tbreak\n\t// Called when deleting a file.\n\tcase \"Remove\":\n\t\tif !h.can(PermissionFileDelete) {\n\t\t\treturn sftp.ErrSSHFxPermissionDenied\n\t\t}\n\t\tif err := h.fs.Delete(request.Filepath); err != nil {\n\t\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\t\treturn sftp.ErrSSHFxNoSuchFile\n\t\t\t}\n\t\t\tl.WithField(\"error\", err).Error(\"failed to remove a file\")\n\t\t\treturn sftp.ErrSSHFxFailure\n\t\t}\n\t\th.events.MustLog(server.ActivitySftpDelete, FileAction{Entity: request.Filepath})\n\t\treturn sftp.ErrSSHFxOk\n\tdefault:\n\t\treturn sftp.ErrSSHFxOpUnsupported\n\t}\n\n\ttarget := request.Filepath\n\tif request.Target != \"\" {\n\t\ttarget = request.Target\n\t}\n\t// Not failing here is intentional. We still made the file, it is just owned incorrectly\n\t// and will likely cause some issues. There is no logical check for if the file was removed\n\t// because both of those cases (Rmdir, Remove) have an explicit return rather than break.\n\tif err := h.fs.Chown(target); err != nil {\n\t\tl.WithField(\"error\", err).Warn(\"error chowning file\")\n\t}\n\n\treturn sftp.ErrSSHFxOk\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeRequester) GetRedirectURI() *url.URL {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetRedirectURI\")\n\tret0, _ := ret[0].(*url.URL)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func NewApiPluginProxy(ctx *models.ReqContext, proxyPath string, route *plugins.Route,\n\tappID string, cfg *setting.Cfg, secretsService secrets.Service) *httputil.ReverseProxy {\n\tdirector := func(req *http.Request) {\n\t\tquery := models.GetPluginSettingByIdQuery{OrgId: ctx.OrgId, PluginId: appID}\n\t\tif err := bus.Dispatch(ctx.Req.Context(), &query); err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to fetch plugin settings\", err)\n\t\t\treturn\n\t\t}\n\n\t\tsecureJsonData, err := secretsService.DecryptJsonData(ctx.Req.Context(), query.Result.SecureJsonData)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to decrypt plugin settings\", err)\n\t\t\treturn\n\t\t}\n\n\t\tdata := templateData{\n\t\t\tJsonData:       query.Result.JsonData,\n\t\t\tSecureJsonData: secureJsonData,\n\t\t}\n\n\t\tinterpolatedURL, err := interpolateString(route.URL, data)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Could not interpolate plugin route url\", err)\n\t\t\treturn\n\t\t}\n\t\ttargetURL, err := url.Parse(interpolatedURL)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Could not parse url\", err)\n\t\t\treturn\n\t\t}\n\t\treq.URL.Scheme = targetURL.Scheme\n\t\treq.URL.Host = targetURL.Host\n\t\treq.Host = targetURL.Host\n\t\treq.URL.Path = util.JoinURLFragments(targetURL.Path, proxyPath)\n\n\t\t// clear cookie headers\n\t\treq.Header.Del(\"Cookie\")\n\t\treq.Header.Del(\"Set-Cookie\")\n\n\t\tproxyutil.PrepareProxyRequest(req)\n\n\t\t// Create a HTTP header with the context in it.\n\t\tctxJSON, err := json.Marshal(ctx.SignedInUser)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"failed to marshal context to json.\", err)\n\t\t\treturn\n\t\t}\n\n\t\treq.Header.Set(\"X-Grafana-Context\", string(ctxJSON))\n\n\t\tapplyUserHeader(cfg.SendUserHeader, req, ctx.SignedInUser)\n\n\t\tif err := addHeaders(&req.Header, route, data); err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to render plugin headers\", err)\n\t\t\treturn\n\t\t}\n\n\t\tif err := setBodyContent(req, route, data); err != nil {\n\t\t\tlogger.Error(\"Failed to set plugin route body content\", \"error\", err)\n\t\t}\n\t}\n\n\treturn &httputil.ReverseProxy{Director: director, ModifyResponse: modifyResponse}\n}", "is_vulnerable": 0}
{"code": "func makeDirWidth(ds format.DAGService, size, width int) ([]string, *legacy.Shard, error) {\n\tctx := context.Background()\n\n\ts, _ := legacy.NewShard(ds, width)\n\n\tvar dirs []string\n\tfor i := 0; i < size; i++ {\n\t\tdirs = append(dirs, fmt.Sprintf(\"DIRNAME%d\", i))\n\t}\n\n\tshuffle(time.Now().UnixNano(), dirs)\n\n\tfor i := 0; i < len(dirs); i++ {\n\t\tnd := ft.EmptyDirNode()\n\t\tds.Add(ctx, nd)\n\t\terr := s.Set(ctx, dirs[i], nd)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t}\n\n\treturn dirs, s, nil\n}", "is_vulnerable": 1}
{"code": "func (srv *Server) serveTCP(l net.Listener) error {\n\tdefer l.Close()\n\n\tif srv.NotifyStartedFunc != nil {\n\t\tsrv.NotifyStartedFunc()\n\t}\n\n\treader := Reader(&defaultReader{srv})\n\tif srv.DecorateReader != nil {\n\t\treader = srv.DecorateReader(reader)\n\t}\n\n\thandler := srv.Handler\n\tif handler == nil {\n\t\thandler = DefaultServeMux\n\t}\n\trtimeout := srv.getReadTimeout()\n\t// deadline is not used here\n\tfor {\n\t\trw, err := l.Accept()\n\t\tsrv.lock.RLock()\n\t\tif !srv.started {\n\t\t\tsrv.lock.RUnlock()\n\t\t\treturn nil\n\t\t}\n\t\tsrv.lock.RUnlock()\n\t\tif err != nil {\n\t\t\tif neterr, ok := err.(net.Error); ok && neterr.Temporary() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tm, err := reader.ReadTCP(rw, rtimeout)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *BinaryProtocol) readStringBody(size int32) (value string, err error) {\n\tif size < 0 {\n\t\treturn \"\", nil\n\t}\n\tif uint64(size) > p.trans.RemainingBytes() {\n\t\treturn \"\", invalidDataLength\n\t}\n\tvar buf []byte\n\tif int(size) <= len(p.buffer) {\n\t\tbuf = p.buffer[0:size]\n\t} else {\n\t\tbuf = make([]byte, size)\n\t}\n\t_, e := io.ReadFull(p.trans, buf)\n\treturn string(buf), NewProtocolException(e)\n}", "is_vulnerable": 1}
{"code": "func (s *Sync) AddCodeEntry(hash common.Hash, depth int, parent common.Hash) {\n\t// Short circuit if the entry is empty or already known\n\tif hash == emptyState {\n\t\treturn\n\t}\n\tif s.membatch.hasCode(hash) {\n\t\treturn\n\t}\n\tif s.bloom == nil || s.bloom.Contains(hash[:]) {\n\t\t// Bloom filter says this might be a duplicate, double check.\n\t\t// If database says yes, the blob is present for sure.\n\t\t// Note we only check the existence with new code scheme, fast\n\t\t// sync is expected to run with a fresh new node. Even there\n\t\t// exists the code with legacy format, fetch and store with\n\t\t// new scheme anyway.\n\t\tif blob := rawdb.ReadCodeWithPrefix(s.database, hash); len(blob) > 0 {\n\t\t\treturn\n\t\t}\n\t\t// False positive, bump fault meter\n\t\tbloomFaultMeter.Mark(1)\n\t}\n\t// Assemble the new sub-trie sync request\n\treq := &request{\n\t\thash:  hash,\n\t\tcode:  true,\n\t\tdepth: depth,\n\t}\n\t// If this sub-trie has a designated parent, link them together\n\tif parent != (common.Hash{}) {\n\t\tancestor := s.nodeReqs[parent] // the parent of codereq can ONLY be nodereq\n\t\tif ancestor == nil {\n\t\t\tpanic(fmt.Sprintf(\"raw-entry ancestor not found: %x\", parent))\n\t\t}\n\t\tancestor.deps++\n\t\treq.parents = append(req.parents, ancestor)\n\t}\n\ts.schedule(req)\n}", "is_vulnerable": 0}
{"code": "func TestGH681(t *testing.T) {\n\tprivkey, err := jwxtest.GenerateRsaKey()\n\trequire.NoError(t, err, \"failed to create private key\")\n\n\tbuf, err := jws.Sign(nil, jws.WithKey(jwa.RS256, privkey), jws.WithDetachedPayload([]byte(\"Lorem ipsum\")))\n\trequire.NoError(t, err, \"failed to sign payload\")\n\n\tt.Logf(\"%s\", buf)\n\n\t_, err = jws.Verify(buf, jws.WithKey(jwa.RS256, &privkey.PublicKey), jws.WithDetachedPayload([]byte(\"Lorem ipsum\")))\n\trequire.NoError(t, err, \"failed to verify JWS message\")\n}", "is_vulnerable": 0}
{"code": "\t\tonEnd := func(fn func(*BuildResult) (OnEndResult, error)) {\n\t\t\tonEndCallbacks = append(onEndCallbacks, onEndCallback{\n\t\t\t\tpluginName: item.Name,\n\t\t\t\tfn:         fn,\n\t\t\t})\n\t\t}", "is_vulnerable": 0}
{"code": "func TestListObjects_UnhappyPaths_Known_Error(t *testing.T) {\n\tctx := context.Background()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgav1.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: []*openfgav1.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"document\",\n\t\t\t\tRelations: map[string]*openfgav1.Userset{\n\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t},\n\t\t\t\tMetadata: &openfgav1.Metadata{\n\t\t\t\t\tRelations: map[string]*openfgav1.RelationMetadata{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgav1.RelationReference{\n\t\t\t\t\t\t\t\ttypesystem.DirectRelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t\ttypesystem.WildcardRelationReference(\"user\"),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, storage.ReadStartingWithUserFilter{\n\t\tObjectType: \"document\",\n\t\tRelation:   \"viewer\",\n\t\tUserFilter: []*openfgav1.ObjectRelation{\n\t\t\t{Object: \"user:*\"},\n\t\t\t{Object: \"user:bob\"},\n\t\t}}).AnyTimes().Return(nil, serverErrors.AuthorizationModelResolutionTooComplex)\n\n\ts := MustNewServerWithOpts(\n\t\tWithDatastore(mockDatastore),\n\t)\n\n\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\tres, err := s.ListObjects(ctx, &openfgav1.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t})\n\n\t\trequire.Nil(t, res)\n\t\trequire.ErrorIs(t, err, serverErrors.AuthorizationModelResolutionTooComplex)\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgav1.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t}, NewMockStreamServer())\n\n\t\trequire.ErrorIs(t, err, serverErrors.AuthorizationModelResolutionTooComplex)\n\t})\n}", "is_vulnerable": 1}
{"code": "func (a *autoCodePgsql) GetColumn(tableName string, dbName string) (data []response.Column, err error) {\n\t// todo \u6570\u636e\u83b7\u53d6\u4e0d\u5168, \u5f85\u5b8c\u5584sql\n\tsql := `\n\t\tSELECT psc.COLUMN_NAME AS COLUMN_NAME,\n psc.udt_name AS data_type,\nCASE\n  psc.udt_name \n  WHEN 'text' THEN\n   concat_ws ( '', '', psc.CHARACTER_MAXIMUM_LENGTH ) \n  WHEN 'varchar' THEN\n   concat_ws ( '', '', psc.CHARACTER_MAXIMUM_LENGTH ) \n  WHEN 'smallint' THEN\n   concat_ws ( ',', psc.NUMERIC_PRECISION, psc.NUMERIC_SCALE ) \n  WHEN 'decimal' THEN\n   concat_ws ( ',', psc.NUMERIC_PRECISION, psc.NUMERIC_SCALE ) \n  WHEN 'integer' THEN\n   concat_ws ( '', '', psc.NUMERIC_PRECISION ) \n  WHEN 'int4' THEN\n   concat_ws ( '', '', psc.NUMERIC_PRECISION ) \n  WHEN 'int8' THEN\n   concat_ws ( '', '', psc.NUMERIC_PRECISION ) \n  WHEN 'bigint' THEN\n   concat_ws ( '', '', psc.NUMERIC_PRECISION ) \n  WHEN 'timestamp' THEN\n   concat_ws ( '', '', psc.datetime_precision ) \n  ELSE '' \n END AS data_type_long,\n (\n   SELECT\n    pd.description \n   FROM\n    pg_description pd \n   WHERE\n    (pd.objoid,pd.objsubid) in (\n       SELECT pa.attrelid,pa.attnum\n       FROM\n        pg_attribute pa \n      WHERE pa.attrelid = ( SELECT oid FROM pg_class pc WHERE \n      pc.relname = psc.table_name\n      ) \n      and attname = psc.column_name\n    ) \n ) AS column_comment \nFROM\n INFORMATION_SCHEMA.COLUMNS psc \nWHERE\n table_catalog = ?\n AND table_schema = 'public' \n AND TABLE_NAME = ?;\n\t`\n\tvar entities []response.Column\n\tdb, _err := gorm.Open(postgres.Open(global.GVA_CONFIG.Pgsql.LinkDsn(dbName)), &gorm.Config{Logger: logger.Default.LogMode(logger.Info)})\n\tif _err != nil {\n\t\treturn nil, errors.Wrapf(err, \"[pgsql] \u8fde\u63a5 \u6570\u636e\u5e93(%s)\u7684\u8868(%s)\u5931\u8d25!\", dbName, tableName)\n\t}\n\t//sql = strings.ReplaceAll(sql, \"@table_catalog\", dbName)\n\t//sql = strings.ReplaceAll(sql, \"@table_name\", tableName)\n\terr = db.Raw(sql, dbName, tableName).Scan(&entities).Error\n\treturn entities, err\n}", "is_vulnerable": 1}
{"code": "func (h *ContextHandler) initContextWithAPIKey(reqContext *models.ReqContext) bool {\n\theader := reqContext.Req.Header.Get(\"Authorization\")\n\tparts := strings.SplitN(header, \" \", 2)\n\tvar keyString string\n\tif len(parts) == 2 && parts[0] == \"Bearer\" {\n\t\tkeyString = parts[1]\n\t} else {\n\t\tusername, password, err := util.DecodeBasicAuthHeader(header)\n\t\tif err == nil && username == \"api_key\" {\n\t\t\tkeyString = password\n\t\t}\n\t}\n\n\tif keyString == \"\" {\n\t\treturn false\n\t}\n\n\t_, span := h.tracer.Start(reqContext.Req.Context(), \"initContextWithAPIKey\")\n\tdefer span.End()\n\n\tctx := WithAuthHTTPHeader(reqContext.Req.Context(), \"Authorization\")\n\t*reqContext.Req = *reqContext.Req.WithContext(ctx)\n\n\tvar (\n\t\tapikey *models.ApiKey\n\t\terrKey error\n\t)\n\tif strings.HasPrefix(keyString, apikeygenprefix.GrafanaPrefix) {\n\t\tapikey, errKey = h.getPrefixedAPIKey(reqContext.Req.Context(), keyString) // decode prefixed key\n\t} else {\n\t\tapikey, errKey = h.getAPIKey(reqContext.Req.Context(), keyString) // decode legacy api key\n\t}\n\n\tif errKey != nil {\n\t\tstatus := http.StatusInternalServerError\n\t\tif errors.Is(errKey, apikeygen.ErrInvalidApiKey) {\n\t\t\tstatus = http.StatusUnauthorized\n\t\t}\n\t\treqContext.JsonApiErr(status, InvalidAPIKey, errKey)\n\t\treturn true\n\t}\n\n\t// check for expiration\n\tgetTime := h.GetTime\n\tif getTime == nil {\n\t\tgetTime = time.Now\n\t}\n\tif apikey.Expires != nil && *apikey.Expires <= getTime().Unix() {\n\t\treqContext.JsonApiErr(http.StatusUnauthorized, \"Expired API key\", nil)\n\t\treturn true\n\t}\n\n\t// update api_key last used date\n\tif err := h.SQLStore.UpdateAPIKeyLastUsedDate(reqContext.Req.Context(), apikey.Id); err != nil {\n\t\treqContext.JsonApiErr(http.StatusInternalServerError, InvalidAPIKey, errKey)\n\t\treturn true\n\t}\n\n\tif apikey.ServiceAccountId == nil || *apikey.ServiceAccountId < 1 { //There is no service account attached to the apikey\n\t\t//Use the old APIkey method.  This provides backwards compatibility.\n\t\treqContext.SignedInUser = &models.SignedInUser{}\n\t\treqContext.OrgRole = apikey.Role\n\t\treqContext.ApiKeyId = apikey.Id\n\t\treqContext.OrgId = apikey.OrgId\n\t\treqContext.IsSignedIn = true\n\t\treturn true\n\t}\n\n\t//There is a service account attached to the API key\n\n\t//Use service account linked to API key as the signed in user\n\tquerySignedInUser := models.GetSignedInUserQuery{UserId: *apikey.ServiceAccountId, OrgId: apikey.OrgId}\n\tif err := h.SQLStore.GetSignedInUserWithCacheCtx(reqContext.Req.Context(), &querySignedInUser); err != nil {\n\t\treqContext.Logger.Error(\n\t\t\t\"Failed to link API key to service account in\",\n\t\t\t\"id\", querySignedInUser.UserId,\n\t\t\t\"org\", querySignedInUser.OrgId,\n\t\t\t\"err\", err,\n\t\t)\n\t\treqContext.JsonApiErr(http.StatusInternalServerError, \"Unable to link API key to service account\", err)\n\t\treturn true\n\t}\n\n\t// disabled service accounts are not allowed to access the API\n\tif querySignedInUser.Result.IsDisabled {\n\t\treqContext.JsonApiErr(http.StatusUnauthorized, \"Service account is disabled\", nil)\n\t\treturn true\n\t}\n\n\treqContext.IsSignedIn = true\n\treqContext.SignedInUser = querySignedInUser.Result\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (np *jqNormalizerPatch) Apply(data []byte) ([]byte, error) {\n\tdataJson := make(map[string]interface{})\n\terr := json.Unmarshal(data, &dataJson)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tctx, cancel := context.WithTimeout(context.Background(), np.jqExecutionTimeout)\n\tdefer cancel()\n\n\titer := np.code.RunWithContext(ctx, dataJson)\n\tfirst, ok := iter.Next()\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"JQ patch did not return any data\")\n\t}\n\tif err, ok = first.(error); ok {\n\t\tif err == context.DeadlineExceeded {\n\t\t\treturn nil, fmt.Errorf(\"JQ patch execution timed out (%v)\", np.jqExecutionTimeout.String())\n\t\t}\n\t\treturn nil, fmt.Errorf(\"JQ patch returned error: %w\", err)\n\t}\n\t_, ok = iter.Next()\n\tif ok {\n\t\treturn nil, fmt.Errorf(\"JQ patch returned multiple objects\")\n\t}\n\n\tpatchedData, err := json.Marshal(first)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn patchedData, err\n}", "is_vulnerable": 0}
{"code": "func (e *ListEnvoyExtender) Extend(resources *xdscommon.IndexedResources, config *RuntimeConfig) (*xdscommon.IndexedResources, error) {\n\tvar resultErr error\n\n\tswitch config.Kind {\n\tcase api.ServiceKindTerminatingGateway, api.ServiceKindConnectProxy:\n\tdefault:\n\t\treturn resources, nil\n\t}\n\n\tif !e.Extension.CanApply(config) {\n\t\treturn resources, nil\n\t}\n\n\tclusters := make(ClusterMap)\n\troutes := make(RouteMap)\n\tlisteners := make(ListenerMap)\n\tisUpstream := config.IsUpstream()\n\n\tfor _, indexType := range []string{\n\t\txdscommon.ListenerType,\n\t\txdscommon.RouteType,\n\t\txdscommon.ClusterType,\n\t} {\n\t\tfor nameOrSNI, msg := range resources.Index[indexType] {\n\t\t\tswitch resource := msg.(type) {\n\t\t\tcase *envoy_cluster_v3.Cluster:\n\t\t\t\t// If the Envoy extension configuration is for an upstream service, the Cluster's\n\t\t\t\t// name must match the upstream service's SNI.\n\t\t\t\tif isUpstream && !config.MatchesUpstreamServiceSNI(nameOrSNI) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// If the extension's config is for an an inbound listener, the Cluster's name\n\t\t\t\t// must be xdscommon.LocalAppClusterName.\n\t\t\t\tif !isUpstream && nameOrSNI == xdscommon.LocalAppClusterName {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tclusters[nameOrSNI] = resource\n\n\t\t\tcase *envoy_listener_v3.Listener:\n\t\t\t\tlisteners[nameOrSNI] = resource\n\n\t\t\tcase *envoy_route_v3.RouteConfiguration:\n\t\t\t\t// If the Envoy extension configuration is for an upstream service, the route's\n\t\t\t\t// name must match the upstream service's Envoy ID.\n\t\t\t\tmatchesEnvoyID := config.EnvoyID() == nameOrSNI\n\t\t\t\tif isUpstream && !config.MatchesUpstreamServiceSNI(nameOrSNI) && !matchesEnvoyID {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// There aren't routes for inbound services.\n\t\t\t\tif !isUpstream {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\troutes[nameOrSNI] = resource\n\n\t\t\tdefault:\n\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"unsupported type was skipped: %T\", resource))\n\t\t\t}\n\t\t}\n\t}\n\n\tpatchedClusters, err := e.Extension.PatchClusters(config, clusters)\n\tif err == nil {\n\t\tfor nameOrSNI, cluster := range patchedClusters {\n\t\t\tresources.Index[xdscommon.ClusterType][nameOrSNI] = cluster\n\t\t}\n\t} else {\n\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching clusters: %w\", err))\n\t}\n\n\tpatchedListeners, err := e.patchListeners(config, listeners)\n\tif err == nil {\n\t\tfor nameOrSNI, listener := range patchedListeners {\n\t\t\tresources.Index[xdscommon.ListenerType][nameOrSNI] = listener\n\t\t}\n\t} else {\n\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching listeners: %w\", err))\n\t}\n\n\tpatchedRoutes, err := e.Extension.PatchRoutes(config, routes)\n\tif err == nil {\n\t\tfor nameOrSNI, route := range patchedRoutes {\n\t\t\tresources.Index[xdscommon.RouteType][nameOrSNI] = route\n\t\t}\n\t} else {\n\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching routes: %w\", err))\n\t}\n\n\treturn resources, resultErr\n}", "is_vulnerable": 1}
{"code": "func (client ProvidersClient) UnregisterSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func RunTestDeleteWithSuggestionAndConflict(ctx context.Context, t *testing.T, store storage.Interface) {\n\tkey, originalPod := testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"name\", Namespace: \"test-ns\"}})\n\n\t// First update, so originalPod is outdated.\n\tupdatedPod := &example.Pod{}\n\tif err := store.GuaranteedUpdate(ctx, key, updatedPod, false, nil,\n\t\tstorage.SimpleUpdate(func(obj runtime.Object) (runtime.Object, error) {\n\t\t\tpod := obj.(*example.Pod)\n\t\t\tpod.ObjectMeta.Labels = map[string]string{\"foo\": \"bar\"}\n\t\t\treturn pod, nil\n\t\t}), nil); err != nil {\n\t\tt.Errorf(\"Unexpected failure during updated: %v\", err)\n\t}\n\n\tout := &example.Pod{}\n\tif err := store.Delete(ctx, key, out, nil, storage.ValidateAllObjectFunc, originalPod); err != nil {\n\t\tt.Errorf(\"Unexpected failure during deletion: %v\", err)\n\t}\n\n\tif err := store.Get(ctx, key, storage.GetOptions{}, &example.Pod{}); !storage.IsNotFound(err) {\n\t\tt.Errorf(\"Unexpected error on reading object: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Ping(ctx context.Context, in *sliverpb.Ping, opts ...grpc.CallOption) (*sliverpb.Ping, error) {\n\tout := new(sliverpb.Ping)\n\terr := c.cc.Invoke(ctx, SliverRPC_Ping_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (a ipdenylist) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func (m *MockResourceOwnerPasswordCredentialsGrantStorage) GetRefreshTokenSession(arg0 context.Context, arg1 string, arg2 fosite.Session) (fosite.Requester, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetRefreshTokenSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(fosite.Requester)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func GetSignatureFromData(data []byte) []byte {\n\treturn ReDigest.Find(data)\n}", "is_vulnerable": 1}
{"code": "func (c *Config) IsTrustedFolderFeatureEnabled() bool {\n\treturn c.trustedFoldersFeatureEnabled\n}", "is_vulnerable": 0}
{"code": "func findID(idStr string, mapping []idtools.IDMap, lookupFunc func(uid string) (string, error), overflowFile string) (string, error) {\n\tif len(mapping) == 0 {\n\t\treturn idStr, nil\n\t}\n\n\tid, err := strconv.ParseInt(idStr, 10, 0)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"cannot parse ID: %w\", err)\n\t}\n\tfor _, m := range mapping {\n\t\tif int(id) >= m.ContainerID && int(id) < m.ContainerID+m.Size {\n\t\t\tuser := fmt.Sprintf(\"%d\", m.HostID+(int(id)-m.ContainerID))\n\n\t\t\treturn lookupFunc(user)\n\t\t}\n\t}\n\n\t// User not found, read the overflow\n\toverflow, err := ioutil.ReadFile(overflowFile)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(overflow), nil\n}", "is_vulnerable": 0}
{"code": "func (es *EmailService) SendAndSaveCode(ctx context.Context, userID, toEmailAddr, subject, body, code, codeContent string) {\n\terr := es.emailRepo.SetCode(ctx, userID, code, codeContent, constant.UserEmailCodeCacheTime)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn\n\t}\n\tes.Send(ctx, toEmailAddr, subject, body)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) StartDNSListener(ctx context.Context, in *clientpb.DNSListenerReq, opts ...grpc.CallOption) (*clientpb.ListenerJob, error) {\n\tout := new(clientpb.ListenerJob)\n\terr := c.cc.Invoke(ctx, SliverRPC_StartDNSListener_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (svc Service) ModifyTeamScheduledQueries(ctx context.Context, teamID uint, scheduledQueryID uint, query fleet.ScheduledQueryPayload) (*fleet.ScheduledQuery, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.Pack{\n\t\tType: ptr.String(fmt.Sprintf(\"team-%d\", teamID)),\n\t}, fleet.ActionWrite); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgp, err := svc.ds.EnsureTeamPack(ctx, teamID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tquery.PackID = ptr.Uint(gp.ID)\n\n\treturn svc.unauthorizedModifyScheduledQuery(ctx, scheduledQueryID, query)\n}", "is_vulnerable": 0}
{"code": "func TestDecodeSensor(t *testing.T) {\n\tb, err := os.ReadFile(\"../../examples/sensors/multi-trigger-sensor.yaml\")\n\tassert.Nil(t, err)\n\t_, err = decodeAndUnstructure(b)\n\tassert.Nil(t, err)\n}", "is_vulnerable": 0}
{"code": "func (s *Server) handleNativeTLS(conn net.Conn) {\n\ts.rpcLogger().Trace(\n\t\t\"detected actual TLS over RPC port\",\n\t\t\"conn\", logConn(conn),\n\t)\n\n\ttlscfg := s.tlsConfigurator.IncomingALPNRPCConfig(pool.RPCNextProtos)\n\ttlsConn := tls.Server(conn, tlscfg)\n\n\t// Force the handshake to conclude.\n\tif err := tlsConn.Handshake(); err != nil {\n\t\ts.rpcLogger().Error(\n\t\t\t\"TLS handshake failed\",\n\t\t\t\"conn\", logConn(conn),\n\t\t\t\"error\", err,\n\t\t)\n\t\tconn.Close()\n\t\treturn\n\t}\n\n\t// Reset the deadline as we aren't sure what is expected next - it depends on\n\t// the protocol.\n\tif s.config.RPCHandshakeTimeout > 0 {\n\t\tconn.SetReadDeadline(time.Time{})\n\t}\n\n\tvar (\n\t\tcs        = tlsConn.ConnectionState()\n\t\tsni       = cs.ServerName\n\t\tnextProto = cs.NegotiatedProtocol\n\n\t\ttransport = s.memberlistTransportWAN\n\t)\n\n\ts.rpcLogger().Trace(\n\t\t\"accepted nativeTLS RPC\",\n\t\t\"sni\", sni,\n\t\t\"protocol\", nextProto,\n\t\t\"conn\", logConn(conn),\n\t)\n\n\tswitch nextProto {\n\tcase pool.ALPN_RPCConsul:\n\t\ts.handleConsulConn(tlsConn)\n\n\tcase pool.ALPN_RPCRaft:\n\t\ts.handleRaftRPC(tlsConn)\n\n\tcase pool.ALPN_RPCMultiplexV2:\n\t\ts.handleMultiplexV2(tlsConn)\n\n\tcase pool.ALPN_RPCSnapshot:\n\t\ts.handleSnapshotConn(tlsConn)\n\n\tcase pool.ALPN_RPCGRPC:\n\t\ts.grpcHandler.Handle(tlsConn)\n\n\tcase pool.ALPN_WANGossipPacket:\n\t\tif err := s.handleALPN_WANGossipPacketStream(tlsConn); err != nil && err != io.EOF {\n\t\t\ts.rpcLogger().Error(\n\t\t\t\t\"failed to ingest RPC\",\n\t\t\t\t\"sni\", sni,\n\t\t\t\t\"protocol\", nextProto,\n\t\t\t\t\"conn\", logConn(conn),\n\t\t\t\t\"error\", err,\n\t\t\t)\n\t\t}\n\n\tcase pool.ALPN_WANGossipStream:\n\t\t// No need to defer the conn.Close() here, the Ingest methods do that.\n\t\tif err := transport.IngestStream(tlsConn); err != nil {\n\t\t\ts.rpcLogger().Error(\n\t\t\t\t\"failed to ingest RPC\",\n\t\t\t\t\"sni\", sni,\n\t\t\t\t\"protocol\", nextProto,\n\t\t\t\t\"conn\", logConn(conn),\n\t\t\t\t\"error\", err,\n\t\t\t)\n\t\t}\n\n\tdefault:\n\t\tif !s.handleEnterpriseNativeTLSConn(nextProto, conn) {\n\t\t\ts.rpcLogger().Error(\n\t\t\t\t\"discarding RPC for unknown negotiated protocol\",\n\t\t\t\t\"failed to ingest RPC\",\n\t\t\t\t\"protocol\", nextProto,\n\t\t\t\t\"conn\", logConn(conn),\n\t\t\t)\n\t\t\tconn.Close()\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Config) ToTLSUtilConfig() tlsutil.Config {\n\treturn tlsutil.Config{\n\t\tVerifyIncoming:           c.VerifyIncoming,\n\t\tVerifyOutgoing:           c.VerifyOutgoing,\n\t\tCAFile:                   c.CAFile,\n\t\tCAPath:                   c.CAPath,\n\t\tCertFile:                 c.CertFile,\n\t\tKeyFile:                  c.KeyFile,\n\t\tNodeName:                 c.NodeName,\n\t\tServerName:               c.ServerName,\n\t\tTLSMinVersion:            c.TLSMinVersion,\n\t\tCipherSuites:             c.TLSCipherSuites,\n\t\tPreferServerCipherSuites: c.TLSPreferServerCipherSuites,\n\t}\n}", "is_vulnerable": 0}
{"code": "func loadCAs(caFile, caPath string) (*x509.CertPool, error) {\n\tif caFile != \"\" {\n\t\treturn rootcerts.LoadCAFile(caFile)\n\t} else if caPath != \"\" {\n\t\tpool, err := rootcerts.LoadCAPath(caPath)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// make sure to not return an empty pool because this is not\n\t\t// the users intention when providing a path for CAs.\n\t\tif len(pool.Subjects()) == 0 {\n\t\t\treturn nil, fmt.Errorf(\"Error loading CA: path %q has no CAs\", caPath)\n\t\t}\n\t\treturn pool, nil\n\t}\n\treturn nil, nil\n}", "is_vulnerable": 0}
{"code": "func (client UsageClient) ListSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (a servicePrincipalClientCertificateAuth) populateConfig(c *Config) error {\n\tc.AuthenticatedAsAServicePrincipal = true\n\tc.GetAuthenticatedObjectID = buildServicePrincipalObjectIDFunc(c)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (ns *nodeServer) NodeUnpublishVolume(ctx context.Context, req *csi.NodeUnpublishVolumeRequest) (nuvr *csi.NodeUnpublishVolumeResponse, err error) {\n\tvar podUID string\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tns.reporter.ReportNodeUnPublishErrorCtMetric()\n\t\t\treturn\n\t\t}\n\t\tns.reporter.ReportNodeUnPublishCtMetric()\n\t}()\n\n\t// Check arguments\n\tif len(req.GetVolumeId()) == 0 {\n\t\treturn nil, status.Error(codes.InvalidArgument, \"Volume ID missing in request\")\n\t}\n\tif len(req.GetTargetPath()) == 0 {\n\t\treturn nil, status.Error(codes.InvalidArgument, \"Target path missing in request\")\n\t}\n\ttargetPath := req.GetTargetPath()\n\tvolumeID := req.GetVolumeId()\n\t// Assume no mounted files if GetMountedFiles fails.\n\tfiles, _ := fileutil.GetMountedFiles(targetPath)\n\n\tif isMockTargetPath(targetPath) {\n\t\treturn &csi.NodeUnpublishVolumeResponse{}, nil\n\t}\n\n\tpodUID = fileutil.GetPodUIDFromTargetPath(targetPath)\n\tif len(podUID) == 0 {\n\t\treturn nil, status.Error(codes.InvalidArgument, \"Cannot get podUID from Target path\")\n\t}\n\t// remove files\n\tif runtime.GOOS == \"windows\" {\n\t\tfor _, file := range files {\n\t\t\terr = os.RemoveAll(file)\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"failed to remove file %s, err: %v for pod: %s\", file, err, podUID)\n\t\t\t\treturn nil, status.Error(codes.Internal, err.Error())\n\t\t\t}\n\t\t}\n\t}\n\terr = mount.CleanupMountPoint(targetPath, ns.mounter, false)\n\tif err != nil {\n\t\tlog.Errorf(\"error cleaning and unmounting target path %s, err: %v for pod: %s\", targetPath, err, podUID)\n\t\treturn nil, status.Error(codes.Internal, err.Error())\n\t}\n\n\tlog.Debugf(\"targetPath %s volumeID %s has been unmounted for pod: %s\", targetPath, volumeID, podUID)\n\treturn &csi.NodeUnpublishVolumeResponse{}, nil\n}", "is_vulnerable": 0}
{"code": "\t\tRunE: func(c *cobra.Command, args []string) error {\n\t\t\tctx, cancel := context.WithCancel(c.Context())\n\t\t\tdefer cancel()\n\n\t\t\tvers := common.GetVersion()\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\t\t\tvers.LogStartupInfo(\n\t\t\t\t\"ArgoCD Application Controller\",\n\t\t\t\tmap[string]any{\n\t\t\t\t\t\"namespace\": namespace,\n\t\t\t\t},\n\t\t\t)\n\n\t\t\tcli.SetLogFormat(cmdutil.LogFormat)\n\t\t\tcli.SetLogLevel(cmdutil.LogLevel)\n\t\t\tcli.SetGLogLevel(glogLevel)\n\n\t\t\tconfig, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\terrors.CheckError(v1alpha1.SetK8SConfigDefaults(config))\n\t\t\tconfig.UserAgent = fmt.Sprintf(\"%s/%s (%s)\", common.DefaultApplicationControllerName, vers.Version, vers.Platform)\n\n\t\t\tkubeClient := kubernetes.NewForConfigOrDie(config)\n\t\t\tappClient := appclientset.NewForConfigOrDie(config)\n\n\t\t\thardResyncDuration := time.Duration(appHardResyncPeriod) * time.Second\n\n\t\t\tvar resyncDuration time.Duration\n\t\t\tif appResyncPeriod == 0 {\n\t\t\t\t// Re-sync should be disabled if period is 0. Set duration to a very long duration\n\t\t\t\tresyncDuration = time.Hour * 24 * 365 * 100\n\t\t\t} else {\n\t\t\t\tresyncDuration = time.Duration(appResyncPeriod) * time.Second\n\t\t\t}\n\n\t\t\ttlsConfig := apiclient.TLSConfiguration{\n\t\t\t\tDisableTLS:       repoServerPlaintext,\n\t\t\t\tStrictValidation: repoServerStrictTLS,\n\t\t\t}\n\n\t\t\t// Load CA information to use for validating connections to the\n\t\t\t// repository server, if strict TLS validation was requested.\n\t\t\tif !repoServerPlaintext && repoServerStrictTLS {\n\t\t\t\tpool, err := tls.LoadX509CertPool(\n\t\t\t\t\tfmt.Sprintf(\"%s/controller/tls/tls.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t\tfmt.Sprintf(\"%s/controller/tls/ca.crt\", env.StringFromEnv(common.EnvAppConfigPath, common.DefaultAppConfigPath)),\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t\t}\n\t\t\t\ttlsConfig.Certificates = pool\n\t\t\t}\n\n\t\t\trepoClientset := apiclient.NewRepoServerClientset(repoServerAddress, repoServerTimeoutSeconds, tlsConfig)\n\n\t\t\tcache, err := cacheSource()\n\t\t\terrors.CheckError(err)\n\t\t\tcache.Cache.SetClient(cacheutil.NewTwoLevelClient(cache.Cache.GetClient(), 10*time.Minute))\n\n\t\t\tvar appController *controller.ApplicationController\n\n\t\t\tsettingsMgr := settings.NewSettingsManager(ctx, kubeClient, namespace, settings.WithRepoOrClusterChangedHandler(func() {\n\t\t\t\tappController.InvalidateProjectsCache()\n\t\t\t}))\n\t\t\tkubectl := kubeutil.NewKubectl()\n\t\t\tclusterFilter := getClusterFilter(kubeClient, settingsMgr, shardingAlgorithm, enableDynamicClusterDistribution)\n\t\t\terrors.CheckError(err)\n\t\t\tappController, err = controller.NewApplicationController(\n\t\t\t\tnamespace,\n\t\t\t\tsettingsMgr,\n\t\t\t\tkubeClient,\n\t\t\t\tappClient,\n\t\t\t\trepoClientset,\n\t\t\t\tcache,\n\t\t\t\tkubectl,\n\t\t\t\tresyncDuration,\n\t\t\t\thardResyncDuration,\n\t\t\t\ttime.Duration(selfHealTimeoutSeconds)*time.Second,\n\t\t\t\tmetricsPort,\n\t\t\t\tmetricsCacheExpiration,\n\t\t\t\tmetricsAplicationLabels,\n\t\t\t\tkubectlParallelismLimit,\n\t\t\t\tpersistResourceHealth,\n\t\t\t\tclusterFilter,\n\t\t\t\tapplicationNamespaces,\n\t\t\t\tignoreNormalizerOpts,\n\t\t\t)\n\t\t\terrors.CheckError(err)\n\t\t\tcacheutil.CollectMetrics(redisClient, appController.GetMetricsServer())\n\n\t\t\tstats.RegisterStackDumper()\n\t\t\tstats.StartStatsTicker(10 * time.Minute)\n\t\t\tstats.RegisterHeapDumper(\"memprofile\")\n\n\t\t\tif otlpAddress != \"\" {\n\t\t\t\tcloseTracer, err := trace.InitTracer(ctx, \"argocd-controller\", otlpAddress, otlpAttrs)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatalf(\"failed to initialize tracing: %v\", err)\n\t\t\t\t}\n\t\t\t\tdefer closeTracer()\n\t\t\t}\n\n\t\t\tgo appController.Run(ctx, statusProcessors, operationProcessors)\n\n\t\t\t// Wait forever\n\t\t\tselect {}\n\t\t},\n\t}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn serverSnippet{r}\n}", "is_vulnerable": 1}
{"code": "func (e errorTranslateChunkQuerier) LabelNames() ([]string, storage.Warnings, error) {\n\tvalues, warnings, err := e.q.LabelNames()\n\treturn values, warnings, e.fn(err)\n}", "is_vulnerable": 0}
{"code": "\t\tdefer func(startGas uint64, startTime time.Time) { // Lazy evaluation of the parameters\n\t\t\tevm.vmConfig.Tracer.CaptureEnd(ret, startGas-gas, time.Since(startTime), err)\n\t\t}(gas, time.Now())", "is_vulnerable": 0}
{"code": "func TestSyncProgressCompatibility(t *testing.T) {\n\t// Decode serialized bytes of legacy progress, backward compatibility\n\tlegacy := makeLegacyProgress()\n\tblob, err := json.Marshal(legacy)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to marshal progress %v\", err)\n\t}\n\tvar dec SyncProgress\n\tif err := json.Unmarshal(blob, &dec); err != nil {\n\t\tt.Fatalf(\"Failed to unmarshal progress %v\", err)\n\t}\n\tif !compareProgress(legacy, dec) {\n\t\tt.Fatal(\"sync progress is not backward compatible\")\n\t}\n\n\t// Decode serialized bytes of new format progress\n\tprogress := convertLegacy(legacy)\n\tblob, err = json.Marshal(progress)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to marshal progress %v\", err)\n\t}\n\tvar legacyDec legacyProgress\n\tif err := json.Unmarshal(blob, &legacyDec); err != nil {\n\t\tt.Fatalf(\"Failed to unmarshal progress %v\", err)\n\t}\n\tif !compareProgress(legacyDec, progress) {\n\t\tt.Fatal(\"sync progress is not forward compatible\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (q *QueryAnalysis) scopeToLabels(labels []string, by bool) QueryAnalysis {\n\tlabels = without(labels, excludedLabels)\n\n\tif q.shardingLabels == nil {\n\t\treturn QueryAnalysis{\n\t\t\tshardBy:        by,\n\t\t\tshardingLabels: labels,\n\t\t}\n\t}\n\n\tif q.shardBy && by {\n\t\treturn QueryAnalysis{\n\t\t\tshardBy:        true,\n\t\t\tshardingLabels: intersect(q.shardingLabels, labels),\n\t\t}\n\t}\n\n\tif !q.shardBy && !by {\n\t\treturn QueryAnalysis{\n\t\t\tshardBy:        false,\n\t\t\tshardingLabels: union(q.shardingLabels, labels),\n\t\t}\n\t}\n\n\t// If we are sharding by and without the same time,\n\t// keep the sharding by labels that are not in the without labels set.\n\tlabelsBy, labelsWithout := q.shardingLabels, labels\n\tif !q.shardBy {\n\t\tlabelsBy, labelsWithout = labelsWithout, labelsBy\n\t}\n\treturn QueryAnalysis{\n\t\tshardBy:        true,\n\t\tshardingLabels: without(labelsBy, labelsWithout),\n\t}\n}", "is_vulnerable": 1}
{"code": "func RunUsingChroot(spec *specs.Spec, bundlePath, homeDir string, stdin io.Reader, stdout, stderr io.Writer) (err error) {\n\tvar confwg sync.WaitGroup\n\tvar homeFound bool\n\tfor _, env := range spec.Process.Env {\n\t\tif strings.HasPrefix(env, \"HOME=\") {\n\t\t\thomeFound = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !homeFound {\n\t\tspec.Process.Env = append(spec.Process.Env, fmt.Sprintf(\"HOME=%s\", homeDir))\n\t}\n\truntime.LockOSThread()\n\tdefer runtime.UnlockOSThread()\n\n\t// Write the runtime configuration, mainly for debugging.\n\tspecbytes, err := json.Marshal(spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = ioutils.AtomicWriteFile(filepath.Join(bundlePath, \"config.json\"), specbytes, 0600); err != nil {\n\t\treturn errors.Wrapf(err, \"error storing runtime configuration\")\n\t}\n\tlogrus.Debugf(\"config = %v\", string(specbytes))\n\n\t// Default to using stdin/stdout/stderr if we weren't passed objects to use.\n\tif stdin == nil {\n\t\tstdin = os.Stdin\n\t}\n\tif stdout == nil {\n\t\tstdout = os.Stdout\n\t}\n\tif stderr == nil {\n\t\tstderr = os.Stderr\n\t}\n\n\t// Create a pipe for passing configuration down to the next process.\n\tpreader, pwriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error creating configuration pipe\")\n\t}\n\tconfig, conferr := json.Marshal(runUsingChrootSubprocOptions{\n\t\tSpec:       spec,\n\t\tBundlePath: bundlePath,\n\t})\n\tif conferr != nil {\n\t\treturn errors.Wrapf(conferr, \"error encoding configuration for %q\", runUsingChrootCommand)\n\t}\n\n\t// Set our terminal's mode to raw, to pass handling of special\n\t// terminal input to the terminal in the container.\n\tif spec.Process.Terminal && terminal.IsTerminal(unix.Stdin) {\n\t\tstate, err := terminal.MakeRaw(unix.Stdin)\n\t\tif err != nil {\n\t\t\tlogrus.Warnf(\"error setting terminal state: %v\", err)\n\t\t} else {\n\t\t\tdefer func() {\n\t\t\t\tif err = terminal.Restore(unix.Stdin, state); err != nil {\n\t\t\t\t\tlogrus.Errorf(\"unable to restore terminal state: %v\", err)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\t// Raise any resource limits that are higher than they are now, before\n\t// we drop any more privileges.\n\tif err = setRlimits(spec, false, true); err != nil {\n\t\treturn err\n\t}\n\n\t// Start the grandparent subprocess.\n\tcmd := unshare.Command(runUsingChrootCommand)\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = stdin, stdout, stderr\n\tcmd.Dir = \"/\"\n\tcmd.Env = append([]string{fmt.Sprintf(\"LOGLEVEL=%d\", logrus.GetLevel())}, os.Environ()...)\n\n\tlogrus.Debugf(\"Running %#v in %#v\", cmd.Cmd, cmd)\n\tconfwg.Add(1)\n\tgo func() {\n\t\t_, conferr = io.Copy(pwriter, bytes.NewReader(config))\n\t\tpwriter.Close()\n\t\tconfwg.Done()\n\t}()\n\tcmd.ExtraFiles = append([]*os.File{preader}, cmd.ExtraFiles...)\n\terr = cmd.Run()\n\tconfwg.Wait()\n\tif err == nil {\n\t\treturn conferr\n\t}\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (m *Message) Unmarshal(dAtA []byte) error {\n\tvar hasFields [1]uint64\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue498\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Message: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Message: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint8\", wireType)\n\t\t\t}\n\t\t\tvar v uint8\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue498\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint8(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint8 = &v\n\t\t\thasFields[0] |= uint64(0x00000001)\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint16\", wireType)\n\t\t\t}\n\t\t\tvar v uint16\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue498\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint16(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint16 = &v\n\t\t\thasFields[0] |= uint64(0x00000002)\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int8\", wireType)\n\t\t\t}\n\t\t\tvar v int8\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue498\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int8(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int8 = &v\n\t\t\thasFields[0] |= uint64(0x00000004)\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int16\", wireType)\n\t\t\t}\n\t\t\tvar v int16\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue498\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int16(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int16 = &v\n\t\t\thasFields[0] |= uint64(0x00000008)\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue498(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue498\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\tif hasFields[0]&uint64(0x00000001) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"uint8\")\n\t}\n\tif hasFields[0]&uint64(0x00000002) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"uint16\")\n\t}\n\tif hasFields[0]&uint64(0x00000004) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"int8\")\n\t}\n\tif hasFields[0]&uint64(0x00000008) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"int16\")\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func Test_resolveSymlinkRecursive(t *testing.T) {\n\tcwd, err := os.Getwd()\n\trequire.NoError(t, err)\n\terr = os.Chdir(\"testdata/symlinks\")\n\trequire.NoError(t, err)\n\tdefer func() {\n\t\terr := os.Chdir(cwd)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t}()\n\tt.Run(\"Resolve non-symlink\", func(t *testing.T) {\n\t\tr, err := resolveSymbolicLinkRecursive(\"foo\", 2)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"foo\", r)\n\t})\n\tt.Run(\"Successfully resolve symlink\", func(t *testing.T) {\n\t\tr, err := resolveSymbolicLinkRecursive(\"bar\", 2)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"foo\", r)\n\t})\n\tt.Run(\"Do not allow symlink at all\", func(t *testing.T) {\n\t\tr, err := resolveSymbolicLinkRecursive(\"bar\", 0)\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"\", r)\n\t})\n\tt.Run(\"Error because too nested symlink\", func(t *testing.T) {\n\t\tr, err := resolveSymbolicLinkRecursive(\"bam\", 2)\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"\", r)\n\t})\n\tt.Run(\"No such file or directory\", func(t *testing.T) {\n\t\tr, err := resolveSymbolicLinkRecursive(\"foobar\", 2)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"foobar\", r)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentOperationsClient) Get(ctx context.Context, resourceGroupName string, deploymentName string, operationID string) (result DeploymentOperation, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.DeploymentOperationsClient\", \"Get\", err.Error())\n\t}\n\n\treq, err := client.GetPreparer(ctx, resourceGroupName, deploymentName, operationID)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"Get\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.GetSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"Get\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.GetResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"Get\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "func Chmod(name string, mode os.FileMode) error {\n\treturn os.Chmod(name, mode)\n}", "is_vulnerable": 0}
{"code": "func (m *RepStdTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: RepStdTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: RepStdTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableTimestamps = append(m.NullableTimestamps, new(time.Time))\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(m.NullableTimestamps[len(m.NullableTimestamps)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDurations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDurations = append(m.NullableDurations, new(time.Duration))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(m.NullableDurations[len(m.NullableDurations)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Timestamps = append(m.Timestamps, time.Time{})\n\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&(m.Timestamps[len(m.Timestamps)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Durations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Durations = append(m.Durations, time.Duration(0))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(&(m.Durations[len(m.Durations)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDouble = append(m.NullableDouble, new(float64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(m.NullableDouble[len(m.NullableDouble)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullDouble = append(m.NonnullDouble, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(&(m.NonnullDouble[len(m.NonnullDouble)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableFloat = append(m.NullableFloat, new(float32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(m.NullableFloat[len(m.NullableFloat)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullFloat = append(m.NonnullFloat, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(&(m.NonnullFloat[len(m.NonnullFloat)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt64 = append(m.NullableInt64, new(int64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(m.NullableInt64[len(m.NullableInt64)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt64 = append(m.NonnullInt64, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(&(m.NonnullInt64[len(m.NonnullInt64)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt64 = append(m.NullableUInt64, new(uint64))\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(m.NullableUInt64[len(m.NullableUInt64)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt64 = append(m.NonnullUInt64, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(&(m.NonnullUInt64[len(m.NonnullUInt64)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt32 = append(m.NullableInt32, new(int32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(m.NullableInt32[len(m.NullableInt32)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt32 = append(m.NonnullInt32, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(&(m.NonnullInt32[len(m.NonnullInt32)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt32 = append(m.NullableUInt32, new(uint32))\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(m.NullableUInt32[len(m.NullableUInt32)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt32 = append(m.NonnullUInt32, 0)\n\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(&(m.NonnullUInt32[len(m.NonnullUInt32)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBool = append(m.NullableBool, new(bool))\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(m.NullableBool[len(m.NullableBool)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBool = append(m.NonnullBool, false)\n\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(&(m.NonnullBool[len(m.NonnullBool)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableString = append(m.NullableString, new(string))\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(m.NullableString[len(m.NullableString)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullString = append(m.NonnullString, \"\")\n\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(&(m.NonnullString[len(m.NonnullString)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBytes = append(m.NullableBytes, new([]byte))\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(m.NullableBytes[len(m.NullableBytes)-1], dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBytes = append(m.NonnullBytes, []byte{})\n\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(&(m.NonnullBytes[len(m.NonnullBytes)-1]), dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tfailpoint.Inject(\"MustMySQLPassword\", func(val failpoint.Value) {\n\t\tpwd := val.(string)\n\t\tif cfg.Passwd != pwd {\n\t\t\tfailpoint.Return(nil, &mysql.MySQLError{Number: tmysql.ErrAccessDenied, Message: \"access denied\"})\n\t\t}\n\t\tfailpoint.Return(nil, nil)\n\t})", "is_vulnerable": 0}
{"code": "\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tlog.Debug(\"%s %v\", r.Method, r.URL)\n\n\t\tif r.Method != method {\n\t\t\thttp.Error(w, \"This request must be \"+method, http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\n\t\tif method == http.MethodPost || method == http.MethodPut || method == http.MethodDelete {\n\t\t\tContext.controlLock.Lock()\n\t\t\tdefer Context.controlLock.Unlock()\n\t\t}\n\n\t\thandler(w, r)\n\t}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) MonitorDelConfig(ctx context.Context, in *clientpb.MonitoringProvider, opts ...grpc.CallOption) (*commonpb.Response, error) {\n\tout := new(commonpb.Response)\n\terr := c.cc.Invoke(ctx, SliverRPC_MonitorDelConfig_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func newServicePrincipalTokenFromMSI(msiEndpoint, resource string, userAssignedID *string, callbacks ...TokenRefreshCallback) (*ServicePrincipalToken, error) {\n\tif err := validateStringParam(msiEndpoint, \"msiEndpoint\"); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := validateStringParam(resource, \"resource\"); err != nil {\n\t\treturn nil, err\n\t}\n\tif userAssignedID != nil {\n\t\tif err := validateStringParam(*userAssignedID, \"userAssignedID\"); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\t// We set the oauth config token endpoint to be MSI's endpoint\n\tmsiEndpointURL, err := url.Parse(msiEndpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tv := url.Values{}\n\tv.Set(\"resource\", resource)\n\t// App Service MSI currently only supports token API version 2017-09-01\n\tif isAppService() {\n\t\tv.Set(\"api-version\", \"2017-09-01\")\n\t} else {\n\t\tv.Set(\"api-version\", \"2018-02-01\")\n\t}\n\tif userAssignedID != nil {\n\t\tv.Set(\"client_id\", *userAssignedID)\n\t}\n\tmsiEndpointURL.RawQuery = v.Encode()\n\n\tspt := &ServicePrincipalToken{\n\t\tinner: servicePrincipalToken{\n\t\t\tToken: newToken(),\n\t\t\tOauthConfig: OAuthConfig{\n\t\t\t\tTokenEndpoint: *msiEndpointURL,\n\t\t\t},\n\t\t\tSecret:        &ServicePrincipalMSISecret{},\n\t\t\tResource:      resource,\n\t\t\tAutoRefresh:   true,\n\t\t\tRefreshWithin: defaultRefresh,\n\t\t},\n\t\trefreshLock:           &sync.RWMutex{},\n\t\tsender:                sender(),\n\t\trefreshCallbacks:      callbacks,\n\t\tMaxMSIRefreshAttempts: defaultMaxMSIRefreshAttempts,\n\t}\n\n\tif userAssignedID != nil {\n\t\tspt.inner.ClientID = *userAssignedID\n\t}\n\n\treturn spt, nil\n}", "is_vulnerable": 0}
{"code": "func TestKVSEndpoint_GET_Raw(t *testing.T) {\n\tt.Parallel()\n\ta := NewTestAgent(t, \"\")\n\tdefer a.Shutdown()\n\n\tbuf := bytes.NewBuffer([]byte(\"test\"))\n\treq, _ := http.NewRequest(\"PUT\", \"/v1/kv/test\", buf)\n\tresp := httptest.NewRecorder()\n\tobj, err := a.srv.KVSEndpoint(resp, req)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif res := obj.(bool); !res {\n\t\tt.Fatalf(\"should work\")\n\t}\n\n\treq, _ = http.NewRequest(\"GET\", \"/v1/kv/test?raw\", nil)\n\tresp = httptest.NewRecorder()\n\t_, err = a.srv.KVSEndpoint(resp, req)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tassertIndex(t, resp)\n\n\t// Check the headers\n\tcontentTypeHdr := resp.Header().Values(\"Content-Type\")\n\tif len(contentTypeHdr) != 1 {\n\t\tt.Fatalf(\"expected 1 value for Content-Type header, got %d: %+v\", len(contentTypeHdr), contentTypeHdr)\n\t}\n\tif contentTypeHdr[0] != \"text/plain\" {\n\t\tt.Fatalf(\"expected Content-Type header to be \\\"text/plain\\\", got %q\", contentTypeHdr[0])\n\t}\n\n\toptionsHdr := resp.Header().Values(\"X-Content-Type-Options\")\n\tif len(optionsHdr) != 1 {\n\t\tt.Fatalf(\"expected 1 value for X-Content-Type-Options header, got %d: %+v\", len(optionsHdr), optionsHdr)\n\t}\n\tif optionsHdr[0] != \"nosniff\" {\n\t\tt.Fatalf(\"expected X-Content-Type-Options header to be \\\"nosniff\\\", got %q\", optionsHdr[0])\n\t}\n\n\tcspHeader := resp.Header().Values(\"Content-Security-Policy\")\n\tif len(cspHeader) != 1 {\n\t\tt.Fatalf(\"expected 1 value for Content-Security-Policy header, got %d: %+v\", len(optionsHdr), optionsHdr)\n\t}\n\tif cspHeader[0] != \"sandbox\" {\n\t\tt.Fatalf(\"expected X-Content-Type-Options header to be \\\"sandbox\\\", got %q\", optionsHdr[0])\n\t}\n\n\t// Check the body\n\tif !bytes.Equal(resp.Body.Bytes(), []byte(\"test\")) {\n\t\tt.Fatalf(\"bad: %s\", resp.Body.Bytes())\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn func(c *models.ReqContext) {\n\t\tif c.OrgRole == models.ROLE_ADMIN {\n\t\t\treturn\n\t\t}\n\n\t\tif c.OrgRole == models.ROLE_EDITOR && enabled {\n\t\t\treturn\n\t\t}\n\n\t\taccessForbidden(c)\n\t}", "is_vulnerable": 0}
{"code": "func (r *Reader) readBytes(op string) []byte {\n\tsize := int(r.ReadLong())\n\tif size < 0 {\n\t\tfnName := \"Read\" + strings.ToTitle(op)\n\t\tr.ReportError(fnName, \"invalid \"+op+\" length\")\n\t\treturn nil\n\t}\n\tif size == 0 {\n\t\treturn []byte{}\n\t}\n\tif max := r.cfg.getMaxByteSliceSize(); max > 0 && size > max {\n\t\tfnName := \"Read\" + strings.ToTitle(op)\n\t\tr.ReportError(fnName, \"size is greater than `Config.MaxByteSliceSize`\")\n\t\treturn nil\n\t}\n\n\t// The bytes are entirely in the buffer and of a reasonable size.\n\t// Use the byte slab.\n\tif r.head+size <= r.tail && size <= 1024 {\n\t\tif cap(r.slab) < size {\n\t\t\tr.slab = make([]byte, 1024)\n\t\t}\n\t\tdst := r.slab[:size]\n\t\tr.slab = r.slab[size:]\n\t\tcopy(dst, r.buf[r.head:r.head+size])\n\t\tr.head += size\n\t\treturn dst\n\t}\n\n\tbuf := make([]byte, size)\n\tr.Read(buf)\n\treturn buf\n}", "is_vulnerable": 0}
{"code": "func (Charset_utf32) DecodeRune(p []byte) (rune, int) {\n\tif len(p) < 4 {\n\t\treturn utf8.RuneError, len(p)\n\t}\n\treturn (rune(p[0]) << 24) | (rune(p[1]) << 16) | (rune(p[2]) << 8) | rune(p[3]), 4\n}", "is_vulnerable": 0}
{"code": "\t\treturn middleware.ResponderFunc(func(w http.ResponseWriter, p runtime.Producer) {\n\t\t\tcookie := restapi.NewSessionCookieForConsole(loginResponse.SessionID)\n\t\t\thttp.SetCookie(w, &cookie)\n\t\t\tuser_api.NewLoginCreated().WithPayload(loginResponse).WriteResponse(w, p)\n\t\t})", "is_vulnerable": 1}
{"code": "func EncryptCCA(rand io.Reader, public *PublicParams, policy *Policy, msg []byte) ([]byte, error) {\n\tseed := make([]byte, macKeySeedSize)\n\t_, err := io.ReadFull(rand, seed)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tid, macKey, err := expandSeed(seed)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tnumid := &pairing.Scalar{}\n\tnumid.SetBytes(id)\n\n\tencPolicy := policy.transformBK(numid)\n\n\theader, encPoint, err := encapsulate(rand, public, encPolicy)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Send the policy that was not enhanced. The receiver will recover with the ID.\n\t// This avoids a bug where we omit the check that the ID is correct\n\theader.p = policy\n\tC1, err := header.marshalBinary()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tenv := make([]byte, len(seed)+len(msg))\n\tcopy(env[0:len(seed)], seed)\n\tcopy(env[len(seed):], msg)\n\n\tencKey, err := encPoint.MarshalBinary()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\thashedEncKey := blake2b.Sum256(encKey)\n\n\tenv, err = blakeEncrypt(hashedEncKey[:], env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmacData := appendLenPrefixed(nil, C1)\n\tmacData = appendLenPrefixed(macData, env)\n\n\ttag, err := blakeMac(macKey, macData)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tret := appendLenPrefixed(nil, id)\n\tret = appendLenPrefixed(ret, macData)\n\tret = appendLenPrefixed(ret, tag)\n\n\treturn ret, nil\n}", "is_vulnerable": 0}
{"code": "func TestValidateRedisEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"host address must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"redis.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Redis)\n\n\tfor name, value := range eventSource.Spec.Redis {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tRedisEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (g *Genesis) ToBlock(db ethdb.Database) *types.Block {\n\tif db == nil {\n\t\tdb = rawdb.NewMemoryDatabase()\n\t}\n\tstatedb, _ := state.New(common.Hash{}, state.NewDatabase(db), nil)\n\tfor addr, account := range g.Alloc {\n\t\tstatedb.AddBalance(addr, account.Balance)\n\t\tstatedb.SetCode(addr, account.Code)\n\t\tstatedb.SetNonce(addr, account.Nonce)\n\t\tfor key, value := range account.Storage {\n\t\t\tstatedb.SetState(addr, key, value)\n\t\t}\n\t}\n\troot := statedb.IntermediateRoot(false)\n\thead := &types.Header{\n\t\tNumber:     new(big.Int).SetUint64(g.Number),\n\t\tNonce:      types.EncodeNonce(g.Nonce),\n\t\tTime:       g.Timestamp,\n\t\tParentHash: g.ParentHash,\n\t\tExtra:      g.ExtraData,\n\t\tGasLimit:   g.GasLimit,\n\t\tGasUsed:    g.GasUsed,\n\t\tDifficulty: g.Difficulty,\n\t\tMixDigest:  g.Mixhash,\n\t\tCoinbase:   g.Coinbase,\n\t\tRoot:       root,\n\t}\n\tif g.GasLimit == 0 {\n\t\thead.GasLimit = params.GenesisGasLimit\n\t}\n\tif g.Difficulty == nil {\n\t\thead.Difficulty = params.GenesisDifficulty\n\t}\n\tstatedb.Commit(false)\n\tstatedb.Database().TrieDB().Commit(root, true, nil)\n\n\treturn types.NewBlock(head, nil, nil, nil)\n}", "is_vulnerable": 1}
{"code": "func TestSearch_PrefixSearch_ACL(t *testing.T) {\n\tci.Parallel(t)\n\n\tjobID := \"aaaaaaaa-e8f7-fd38-c855-ab94ceb8970\"\n\n\ts, root, cleanupS := TestACLServer(t, func(c *Config) {\n\t\tc.NumSchedulers = 0\n\t})\n\tdefer cleanupS()\n\tcodec := rpcClient(t, s)\n\ttestutil.WaitForLeader(t, s.RPC)\n\tfsmState := s.fsm.State()\n\n\tjob := registerMockJob(s, t, jobID, 0)\n\trequire.NoError(t, fsmState.UpsertNode(structs.MsgTypeTestSetup, 1001, mock.Node()))\n\n\treq := &structs.SearchRequest{\n\t\tPrefix:  \"\",\n\t\tContext: structs.Jobs,\n\t\tQueryOptions: structs.QueryOptions{\n\t\t\tRegion:    \"global\",\n\t\t\tNamespace: job.Namespace,\n\t\t},\n\t}\n\n\t// Try without a token and expect failure\n\t{\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\trequire.EqualError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with an invalid token and expect failure\n\t{\n\t\tinvalidToken := mock.CreatePolicyAndToken(t, fsmState, 1003, \"test-invalid\",\n\t\t\tmock.NamespacePolicy(structs.DefaultNamespace, \"\", []string{acl.NamespaceCapabilityListJobs}))\n\t\treq.AuthToken = invalidToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\trequire.EqualError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with a node:read token and expect failure due to Jobs being the context\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, fsmState, 1005, \"test-invalid2\", mock.NodePolicy(acl.PolicyRead))\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\trequire.EqualError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with a node:read token and expect success due to All context\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, fsmState, 1007, \"test-valid\", mock.NodePolicy(acl.PolicyRead))\n\t\treq.Context = structs.All\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\trequire.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\t\trequire.Equal(t, uint64(1001), resp.Index)\n\t\trequire.Len(t, resp.Matches[structs.Nodes], 1)\n\n\t\t// Jobs filtered out since token only has access to node:read\n\t\trequire.Len(t, resp.Matches[structs.Jobs], 0)\n\t}\n\n\t// Try with a valid token for namespace:read-job\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, fsmState, 1009, \"test-valid2\",\n\t\t\tmock.NamespacePolicy(structs.DefaultNamespace, \"\", []string{acl.NamespaceCapabilityReadJob}))\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\trequire.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\t\trequire.Len(t, resp.Matches[structs.Jobs], 1)\n\t\trequire.Equal(t, job.ID, resp.Matches[structs.Jobs][0])\n\n\t\t// Index of job - not node - because node context is filtered out\n\t\trequire.Equal(t, uint64(1000), resp.Index)\n\n\t\t// Nodes filtered out since token only has access to namespace:read-job\n\t\trequire.Len(t, resp.Matches[structs.Nodes], 0)\n\t}\n\n\t// Try with a valid token for node:read and namespace:read-job\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, fsmState, 1011, \"test-valid3\", strings.Join([]string{\n\t\t\tmock.NamespacePolicy(structs.DefaultNamespace, \"\", []string{acl.NamespaceCapabilityReadJob}),\n\t\t\tmock.NodePolicy(acl.PolicyRead),\n\t\t}, \"\\n\"))\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\trequire.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\t\trequire.Len(t, resp.Matches[structs.Jobs], 1)\n\t\trequire.Equal(t, job.ID, resp.Matches[structs.Jobs][0])\n\t\trequire.Len(t, resp.Matches[structs.Nodes], 1)\n\t\trequire.Equal(t, uint64(1001), resp.Index)\n\t}\n\n\t// Try with a management token\n\t{\n\t\treq.AuthToken = root.SecretID\n\t\tvar resp structs.SearchResponse\n\t\trequire.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\t\trequire.Equal(t, uint64(1001), resp.Index)\n\t\trequire.Len(t, resp.Matches[structs.Jobs], 1)\n\t\trequire.Equal(t, job.ID, resp.Matches[structs.Jobs][0])\n\t\trequire.Len(t, resp.Matches[structs.Nodes], 1)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"topics can't be empty list\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"pulsar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Pulsar)\n\n\tfor name, value := range eventSource.Spec.Pulsar {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPulsarEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestStringList(t *testing.T) {\n\tcases := []struct {\n\t\tin     string\n\t\texpect model.StringList\n\t}{\n\t\t{`\"a,b,c\"`, []string{\"a\", \"b\", \"c\"}},\n\t\t{`\"a\"`, []string{\"a\"}},\n\t\t{`\"\"`, []string{}},\n\t\t{`\"123,@#$#,abcdef\"`, []string{\"123\", \"@#$#\", \"abcdef\"}},\n\t}\n\tfor _, tt := range cases {\n\t\tt.Run(tt.in, func(t *testing.T) {\n\t\t\tvar out model.StringList\n\t\t\tif err := json.Unmarshal([]byte(tt.in), &out); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(out, tt.expect) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.expect, out)\n\t\t\t}\n\t\t\tb, err := json.Marshal(out)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(string(b), tt.in) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.in, string(b))\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func Test_ParseFilters_InvalidFunction(t *testing.T) {\n\tfilterExpression := \"invalid_function(type,bar)\"\n\n\t_, err := ParseFilters(filterExpression, common.Task)\n\n\tassert.EqualError(t, err, \"unrecognized filter function: invalid_function\")\n}", "is_vulnerable": 0}
{"code": "func containsOne(target string, chars []rune) bool {\n\tcharMap := make(map[rune]bool, len(chars))\n\tfor _, c := range chars {\n\t\tcharMap[c] = true\n\t}\n\tfor _, s := range target {\n\t\tif charMap[s] {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (s *Shm) MarkDestroyed() {\n\ts.mu.Lock()\n\tdefer s.mu.Unlock()\n\t// Prevent the segment from being found in the registry.\n\ts.key = linux.IPC_PRIVATE\n\ts.pendingDestruction = true\n\ts.DecRef()\n}", "is_vulnerable": 1}
{"code": "func (s *TestServer) handleStartup(client *pgproto3.Backend) error {\n\tstartupMessageI, err := client.ReceiveStartupMessage()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tstartupMessage, ok := startupMessageI.(*pgproto3.StartupMessage)\n\tif !ok {\n\t\treturn trace.BadParameter(\"expected *pgproto3.StartupMessage, got: %#v\", startupMessage)\n\t}\n\ts.log.Debugf(\"Received %#v.\", startupMessage)\n\t// Push connect parameters into the channel so tests can consume them.\n\ts.parametersCh <- startupMessage.Parameters\n\t// If auth token is specified, used it for password authentication, this\n\t// simulates cloud provider IAM auth.\n\tif s.cfg.AuthToken != \"\" {\n\t\tif err := s.handlePasswordAuth(client); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\t// Accept auth and send ready for query.\n\tif err := client.Send(&pgproto3.AuthenticationOk{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := client.Send(&pgproto3.ReadyForQuery{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (page *ProviderListResultPage) Next() error {\n\treturn page.NextWithContext(context.Background())\n}", "is_vulnerable": 0}
{"code": "func (a affinity) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, sessionAffinityAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (p *Profile) write() (pth string, err error) {\n\trootDir, err := utils.GetTempDir()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tpth = filepath.Join(rootDir, p.Id)\n\n\tdata := \"\"\n\tfor _, line := range strings.Split(p.Data, \"\\n\") {\n\t\ttrimLine := strings.TrimSpace(line)\n\t\ttrimLine = strings.Trim(trimLine, \"#\")\n\t\ttrimLine = strings.Trim(trimLine, \"-\")\n\t\ttrimLine = strings.Trim(trimLine, \"_\")\n\t\ttrimLine = strings.Trim(trimLine, \":\")\n\t\ttrimLine = strings.Trim(trimLine, \";\")\n\t\ttrimLine = strings.Trim(trimLine, \"*\")\n\t\ttrimLine = strings.Trim(trimLine, \"%\")\n\t\ttrimLine = strings.Trim(trimLine, \"$\")\n\t\ttrimLine = strings.Trim(trimLine, \"+\")\n\t\ttrimLine = strings.Trim(trimLine, \"=\")\n\t\ttrimLine = strings.Trim(trimLine, \"~\")\n\t\ttrimLine = strings.Trim(trimLine, \"(\")\n\t\ttrimLine = strings.Trim(trimLine, \")\")\n\t\ttrimLine = strings.Trim(trimLine, \"[\")\n\t\ttrimLine = strings.Trim(trimLine, \"]\")\n\t\ttrimLine = strings.Trim(trimLine, \"{\")\n\t\ttrimLine = strings.Trim(trimLine, \"}\")\n\n\t\tif strings.Contains(trimLine, \"script-security\") ||\n\t\t\tstrings.HasPrefix(trimLine, \"log \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"up \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"down \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"route-pre-down \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"tls-verify \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"ipchange \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"route-up \") {\n\n\t\t\tcontinue\n\t\t}\n\t\tdata += line + \"\\n\"\n\t}\n\n\t_ = os.Remove(pth)\n\terr = ioutil.WriteFile(pth, []byte(data), os.FileMode(0600))\n\tif err != nil {\n\t\terr = &WriteError{\n\t\t\terrors.Wrap(err, \"profile: Failed to write profile\"),\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (v *Validator) AddManifest(pkifile *PKIFile, mft *librpki.RPKIManifest) (bool, []*PKIFile, *Resource, error) {\n\tpathCert, err := ExtractPathManifest(mft)\n\tif err != nil {\n\t\treturn false, nil, nil, fmt.Errorf(\"ExtractPathManifest failed: %v\", err)\n\t}\n\n\tvalid, _, res, err := v.AddCert(mft.Certificate, false)\n\tif res == nil {\n\t\treturn valid, pathCert, res, errors.New(fmt.Sprintf(\"Resource is empty: %v\", err))\n\t}\n\tres.File = pkifile\n\tres.Type = TYPE_MFTCER\n\n\tif !mft.InnerValid {\n\t\tvalid = false\n\t\terr = errors.New(fmt.Sprintf(\"Manifest inner validity error: %v\", mft.InnerValidityError))\n\t}\n\n\tres_mft := ObjectToResource(mft)\n\tres_mft.Type = TYPE_MFT\n\tres_mft.File = pkifile\n\tres.Childs = append(res.Childs, res_mft)\n\tres_mft.Parent = res\n\tkey := mft.Certificate.Certificate.SubjectKeyId\n\tif valid {\n\t\tv.ValidManifest[string(key)] = res_mft\n\t}\n\tv.Manifest[string(key)] = res_mft\n\n\tif err != nil {\n\t\terrRes := NewResourceErrorWrap(mft, err)\n\t\terrRes.InnerValidity = valid\n\t\terr = errRes\n\t}\n\n\treturn valid, pathCert, res_mft, err\n}", "is_vulnerable": 0}
{"code": "func pipe(p *[2]_C_int) (err error) {\n\t_, _, e1 := RawSyscall(SYS_PIPE, uintptr(unsafe.Pointer(p)), 0, 0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (f MigrateRepo) ParseRemoteAddr(user *db.User) (string, error) {\n\tremoteAddr := strings.TrimSpace(f.CloneAddr)\n\n\t// Remote address can be HTTP/HTTPS/Git URL or local path.\n\tif strings.HasPrefix(remoteAddr, \"http://\") ||\n\t\tstrings.HasPrefix(remoteAddr, \"https://\") ||\n\t\tstrings.HasPrefix(remoteAddr, \"git://\") {\n\t\tu, err := url.Parse(remoteAddr)\n\t\tif err != nil {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsURLError: true}\n\t\t}\n\n\t\tif netutil.IsLocalHostname(u.Hostname()) {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsURLError: true}\n\t\t}\n\n\t\tif len(f.AuthUsername)+len(f.AuthPassword) > 0 {\n\t\t\tu.User = url.UserPassword(f.AuthUsername, f.AuthPassword)\n\t\t}\n\t\t// To prevent CRLF injection in git protocol, see https://github.com/gogs/gogs/issues/6413\n\t\tif u.Scheme == \"git\" && (strings.Contains(remoteAddr, \"%0d\") || strings.Contains(remoteAddr, \"%0a\")) {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsURLError: true}\n\t\t}\n\t\tremoteAddr = u.String()\n\t} else if !user.CanImportLocal() {\n\t\treturn \"\", db.ErrInvalidCloneAddr{IsPermissionDenied: true}\n\t} else if !com.IsDir(remoteAddr) {\n\t\treturn \"\", db.ErrInvalidCloneAddr{IsInvalidPath: true}\n\t}\n\n\treturn remoteAddr, nil\n}", "is_vulnerable": 0}
{"code": "func removePullSecret(s []string) []string {\n\treturn strings.Split(strings.ReplaceAll(strings.Join(s, \" \"), config.GlobalConfig.PullSecretToken, \"<SECRET>\"), \" \")\n}", "is_vulnerable": 0}
{"code": "func (i *File) Delete() error {\n\tpath := filepath.Dir(i.Path)\n\n\tnspath := filepath.Join(path, \"ns\")\n\tif _, err := os.Stat(nspath); err == nil {\n\t\tif err := syscall.Unmount(nspath, syscall.MNT_DETACH); err != nil {\n\t\t\tsylog.Errorf(\"can't umount %s: %s\", nspath, err)\n\t\t}\n\t}\n\n\treturn os.RemoveAll(path)\n}", "is_vulnerable": 1}
{"code": "func (va ClawbackVestingAccount) GetUnvestedOnly(blockTime time.Time) sdk.Coins {\n\ttotalUnvested := va.OriginalVesting.Sub(va.GetVestedOnly(blockTime)...)\n\tif totalUnvested == nil {\n\t\ttotalUnvested = sdk.Coins{}\n\t}\n\treturn totalUnvested\n}", "is_vulnerable": 1}
{"code": "func (s *Server) Run(ctx context.Context) error {\n\n\tunaryServerInterceptors := []grpc.UnaryServerInterceptor{\n\t\tgrpc_validator.UnaryServerInterceptor(),\n\t}\n\tunaryServerInterceptors = append(unaryServerInterceptors, s.config.UnaryInterceptors...)\n\n\tstreamingInterceptors := []grpc.StreamServerInterceptor{\n\t\tgrpc_validator.StreamServerInterceptor(),\n\t}\n\tstreamingInterceptors = append(streamingInterceptors, s.config.StreamingInterceptors...)\n\n\topts := []grpc.ServerOption{\n\t\tgrpc.ChainUnaryInterceptor(unaryServerInterceptors...),\n\t\tgrpc.ChainStreamInterceptor(streamingInterceptors...),\n\t}\n\n\tif s.config.GRPCServer.TLSConfig != nil {\n\t\tcreds, err := credentials.NewServerTLSFromFile(s.config.GRPCServer.TLSConfig.CertPath, s.config.GRPCServer.TLSConfig.KeyPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\topts = append(opts, grpc.Creds(creds))\n\t}\n\t// nosemgrep: grpc-server-insecure-connection\n\tgrpcServer := grpc.NewServer(opts...)\n\topenfgapb.RegisterOpenFGAServiceServer(grpcServer, s)\n\thealthServer := &health.Checker{TargetService: s, TargetServiceName: openfgapb.OpenFGAService_ServiceDesc.ServiceName}\n\thealthv1pb.RegisterHealthServer(grpcServer, healthServer)\n\treflection.Register(grpcServer)\n\n\trpcAddr := s.config.GRPCServer.Addr\n\tlis, err := net.Listen(\"tcp\", rpcAddr.String())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tgo func() {\n\t\tif err := grpcServer.Serve(lis); err != nil {\n\t\t\ts.logger.Error(\"failed to start grpc server\", logger.Error(err))\n\t\t}\n\t}()\n\n\ts.logger.Info(fmt.Sprintf(\"grpc server listening on '%s'...\", rpcAddr))\n\n\tvar httpServer *http.Server\n\tif s.config.HTTPServer.Enabled {\n\t\t// Set a request timeout.\n\t\truntime.DefaultContextTimeout = s.config.HTTPServer.UpstreamTimeout\n\n\t\tdialOpts := []grpc.DialOption{\n\t\t\tgrpc.WithBlock(),\n\t\t\tgrpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()),\n\t\t}\n\t\tif s.config.GRPCServer.TLSConfig != nil {\n\t\t\tcreds, err := credentials.NewClientTLSFromFile(s.config.GRPCServer.TLSConfig.CertPath, \"\")\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(creds))\n\t\t} else {\n\t\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\t\t}\n\n\t\ttimeoutCtx, cancel := context.WithTimeout(ctx, 3*time.Second)\n\t\tdefer cancel()\n\n\t\tconn, err := grpc.DialContext(timeoutCtx, rpcAddr.String(), dialOpts...)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer conn.Close()\n\n\t\thealthClient := healthv1pb.NewHealthClient(conn)\n\n\t\tmuxOpts := []runtime.ServeMuxOption{\n\t\t\truntime.WithHealthzEndpoint(healthClient),\n\t\t}\n\t\tmuxOpts = append(muxOpts, s.defaultServeMuxOpts...) // register the defaults first\n\t\tmuxOpts = append(muxOpts, s.config.MuxOptions...)   // any provided options override defaults if they are duplicates\n\n\t\tmux := runtime.NewServeMux(muxOpts...)\n\n\t\tif err := openfgapb.RegisterOpenFGAServiceHandler(ctx, mux, conn); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thttpServer = &http.Server{\n\t\t\tAddr: s.config.HTTPServer.Addr.String(),\n\t\t\tHandler: cors.New(cors.Options{\n\t\t\t\tAllowedOrigins:   s.config.HTTPServer.CORSAllowedOrigins,\n\t\t\t\tAllowCredentials: true,\n\t\t\t\tAllowedHeaders:   s.config.HTTPServer.CORSAllowedHeaders,\n\t\t\t\tAllowedMethods: []string{http.MethodGet, http.MethodPost,\n\t\t\t\t\thttp.MethodHead, http.MethodPatch, http.MethodDelete, http.MethodPut},\n\t\t\t}).Handler(mux),\n\t\t}\n\n\t\tgo func() {\n\t\t\ts.logger.Info(fmt.Sprintf(\"HTTP server listening on '%s'...\", httpServer.Addr))\n\n\t\t\tvar err error\n\t\t\tif s.config.HTTPServer.TLSConfig != nil {\n\t\t\t\terr = httpServer.ListenAndServeTLS(s.config.HTTPServer.TLSConfig.CertPath, s.config.HTTPServer.TLSConfig.KeyPath)\n\t\t\t} else {\n\t\t\t\terr = httpServer.ListenAndServe()\n\t\t\t}\n\t\t\tif err != http.ErrServerClosed {\n\t\t\t\ts.logger.ErrorWithContext(ctx, \"HTTP server closed with unexpected error\", logger.Error(err))\n\t\t\t}\n\t\t}()\n\t}\n\n\t<-ctx.Done()\n\ts.logger.InfoWithContext(ctx, \"Termination signal received! Gracefully shutting down\")\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\n\tif httpServer != nil {\n\t\tif err := httpServer.Shutdown(ctx); err != nil {\n\t\t\ts.logger.ErrorWithContext(ctx, \"HTTP server shutdown failed\", logger.Error(err))\n\t\t\treturn err\n\t\t}\n\t}\n\n\tgrpcServer.GracefulStop()\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (b *BearerTokenAuth) Authenticate(ctx context.Context, headers map[string][]string) (context.Context, error) {\n\tauth, ok := headers[\"authorization\"]\n\tif !ok {\n\t\tauth, ok = headers[\"Authorization\"]\n\t}\n\tif !ok || len(auth) == 0 {\n\t\treturn ctx, errors.New(\"authentication didn't succeed\")\n\t}\n\ttoken := auth[0]\n\texpect := b.tokenString\n\tif len(b.scheme) != 0 {\n\t\texpect = fmt.Sprintf(\"%s %s\", b.scheme, expect)\n\t}\n\tif expect != token {\n\t\treturn ctx, fmt.Errorf(\"scheme or token does not match: %s\", token)\n\t}\n\treturn ctx, nil\n}", "is_vulnerable": 1}
{"code": "func Test_IsTrusted_shouldReturnFalseForDifferentFolder(t *testing.T) {\n\ttestutil.UnitTest(t)\n\tconfig.CurrentConfig().SetTrustedFolderFeatureEnabled(true)\n\tconfig.CurrentConfig().SetTrustedFolders([]string{\"/dummy\"})\n\tf := NewFolder(\"/UntrustedPath\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\tassert.False(t, f.IsTrusted())\n}", "is_vulnerable": 0}
{"code": "func (m *Object) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowObject\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Object: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Object: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field OptionalNumber\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowObject\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.OptionalNumber = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipObject(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthObject\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthObject\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (p Precompile) Run(evm *vm.EVM, contract *vm.Contract, readOnly bool) (bz []byte, err error) {\n\tctx, stateDB, method, initialGas, args, err := p.RunSetup(evm, contract, readOnly, p.IsTransaction)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// This handles any out of gas errors that may occur during the execution of a precompile tx or query.\n\t// It avoids panics and returns the out of gas error so the EVM can continue gracefully.\n\tdefer cmn.HandleGasError(ctx, contract, initialGas, &err)()\n\n\tif err := stateDB.Commit(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tswitch method.Name {\n\tcase SwapMethod:\n\t\tbz, err = p.Swap(ctx, evm.Origin, stateDB, contract, method, args)\n\tdefault:\n\t\treturn nil, fmt.Errorf(cmn.ErrUnknownMethod, method.Name)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcost := ctx.GasMeter().GasConsumed() - initialGas\n\n\tif !contract.UseGas(cost) {\n\t\treturn nil, vm.ErrOutOfGas\n\t}\n\n\treturn bz, nil\n}", "is_vulnerable": 0}
{"code": "func (c *linuxContainer) makeCriuRestoreMountpoints(m *configs.Mount) error {\n\tswitch m.Device {\n\tcase \"cgroup\":\n\t\t// No mount point(s) need to be created:\n\t\t//\n\t\t// * for v1, mount points are saved by CRIU because\n\t\t//   /sys/fs/cgroup is a tmpfs mount\n\t\t//\n\t\t// * for v2, /sys/fs/cgroup is a real mount, but\n\t\t//   the mountpoint appears as soon as /sys is mounted\n\t\treturn nil\n\tcase \"bind\":\n\t\t// The prepareBindMount() function checks if source\n\t\t// exists. So it cannot be used for other filesystem types.\n\t\tif err := prepareBindMount(m, c.config.Rootfs); err != nil {\n\t\t\treturn err\n\t\t}\n\tdefault:\n\t\t// for all other filesystems just create the mountpoints\n\t\tdest, err := securejoin.SecureJoin(c.config.Rootfs, m.Destination)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := checkProcMount(c.config.Rootfs, dest, \"\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\thandleErr := func(w http.ResponseWriter, errMsg string) {\n\t\thttp.Error(w, errMsg, http.StatusBadRequest)\n\t\tcompletionChan <- errMsg\n\t}", "is_vulnerable": 1}
{"code": "\tt.Run(\"should not allocate a new object when no hooks are passed\", func(t *testing.T) {\n\t\tevent := model.NewWebSocketEvent(model.WebsocketEventPosted, \"\", \"\", \"\", nil, \"\")\n\n\t\tresult := hub.runBroadcastHooks(event, webConn, nil, nil)\n\n\t\tassert.Same(t, event, result)\n\t})", "is_vulnerable": 0}
{"code": "func TestTCPHostnameParam(t *testing.T) {\n\tc := &config.Config{\n\t\tModules: map[string]config.Module{\n\t\t\t\"tls_connect\": {\n\t\t\t\tProber:  \"tcp\",\n\t\t\t\tTimeout: 10 * time.Second,\n\t\t\t\tTCP: config.TCPProbe{\n\t\t\t\t\tTLS:        true,\n\t\t\t\t\tIPProtocol: \"ip4\",\n\t\t\t\t\tTLSConfig:  pconfig.TLSConfig{InsecureSkipVerify: true},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\t// check that 'hostname' parameter make its way to server_name in the tls_config\n\thostname := \"foo.example.com\"\n\n\tts := httptest.NewTLSServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tif r.Host != hostname {\n\t\t\tt.Errorf(\"Unexpected Host: expected %q, got %q.\", hostname, r.Host)\n\t\t}\n\t\tw.WriteHeader(http.StatusOK)\n\t}))\n\tdefer ts.Close()\n\n\trequrl := fmt.Sprintf(\"?module=tls_connect&debug=true&hostname=%s&target=%s\", hostname, ts.Listener.Addr().(*net.TCPAddr).IP.String()+\":\"+strconv.Itoa(ts.Listener.Addr().(*net.TCPAddr).Port))\n\n\treq, err := http.NewRequest(\"GET\", requrl, nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\trr := httptest.NewRecorder()\n\n\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil)\n\t})\n\n\thandler.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tt.Errorf(\"probe request handler returned wrong status code: %v, want %v\", status, http.StatusOK)\n\t}\n\n\t// check debug output to confirm the server_name is set in tls_config and matches supplied hostname\n\tif !strings.Contains(rr.Body.String(), \"server_name: \"+hostname) {\n\t\tt.Errorf(\"probe failed, response body: %v\", rr.Body.String())\n\t}\n\n}", "is_vulnerable": 1}
{"code": "func (in *EVMInterpreter) Run(contract *Contract, input []byte, readOnly bool) (ret []byte, err error) {\n\n\t// Increment the call depth which is restricted to 1024\n\tin.evm.depth++\n\tdefer func() { in.evm.depth-- }()\n\n\t// Make sure the readOnly is only set if we aren't in readOnly yet.\n\t// This makes also sure that the readOnly flag isn't removed for child calls.\n\tif readOnly && !in.readOnly {\n\t\tin.readOnly = true\n\t\tdefer func() { in.readOnly = false }()\n\t}\n\n\t// Reset the previous call's return data. It's unimportant to preserve the old buffer\n\t// as every returning call will return new data anyway.\n\tin.returnData = nil\n\n\t// Don't bother with the execution if there's no code.\n\tif len(contract.Code) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tvar (\n\t\top          OpCode             // current opcode\n\t\tmem         = NewMemory()      // bound memory\n\t\tstack       = newstack()       // local stack\n\t\treturns     = newReturnStack() // local returns stack\n\t\tcallContext = &callCtx{\n\t\t\tmemory:   mem,\n\t\t\tstack:    stack,\n\t\t\trstack:   returns,\n\t\t\tcontract: contract,\n\t\t}\n\t\t// For optimisation reason we're using uint64 as the program counter.\n\t\t// It's theoretically possible to go above 2^64. The YP defines the PC\n\t\t// to be uint256. Practically much less so feasible.\n\t\tpc   = uint64(0) // program counter\n\t\tcost uint64\n\t\t// copies used by tracer\n\t\tpcCopy  uint64 // needed for the deferred Tracer\n\t\tgasCopy uint64 // for Tracer to log gas remaining before execution\n\t\tlogged  bool   // deferred Tracer should ignore already logged steps\n\t\tres     []byte // result of the opcode execution function\n\t)\n\t// Don't move this deferrred function, it's placed before the capturestate-deferred method,\n\t// so that it get's executed _after_: the capturestate needs the stacks before\n\t// they are returned to the pools\n\tdefer func() {\n\t\treturnStack(stack)\n\t\treturnRStack(returns)\n\t}()\n\tcontract.Input = input\n\n\tif in.cfg.Debug {\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\tif !logged {\n\t\t\t\t\tin.cfg.Tracer.CaptureState(in.evm, pcCopy, op, gasCopy, cost, mem, stack, returns, in.returnData, contract, in.evm.depth, err)\n\t\t\t\t} else {\n\t\t\t\t\tin.cfg.Tracer.CaptureFault(in.evm, pcCopy, op, gasCopy, cost, mem, stack, returns, contract, in.evm.depth, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\t// The Interpreter main run loop (contextual). This loop runs until either an\n\t// explicit STOP, RETURN or SELFDESTRUCT is executed, an error occurred during\n\t// the execution of one of the operations or until the done flag is set by the\n\t// parent context.\n\tsteps := 0\n\tfor {\n\t\tsteps++\n\t\tif steps%1000 == 0 && atomic.LoadInt32(&in.evm.abort) != 0 {\n\t\t\tbreak\n\t\t}\n\t\tif in.cfg.Debug {\n\t\t\t// Capture pre-execution values for tracing.\n\t\t\tlogged, pcCopy, gasCopy = false, pc, contract.Gas\n\t\t}\n\n\t\t// Get the operation from the jump table and validate the stack to ensure there are\n\t\t// enough stack items available to perform the operation.\n\t\top = contract.GetOp(pc)\n\t\toperation := in.cfg.JumpTable[op]\n\t\tif !operation.valid {\n\t\t\treturn nil, &ErrInvalidOpCode{opcode: op}\n\t\t}\n\t\t// Validate stack\n\t\tif sLen := stack.len(); sLen < operation.minStack {\n\t\t\treturn nil, &ErrStackUnderflow{stackLen: sLen, required: operation.minStack}\n\t\t} else if sLen > operation.maxStack {\n\t\t\treturn nil, &ErrStackOverflow{stackLen: sLen, limit: operation.maxStack}\n\t\t}\n\t\t// If the operation is valid, enforce and write restrictions\n\t\tif in.readOnly && in.evm.chainRules.IsByzantium {\n\t\t\t// If the interpreter is operating in readonly mode, make sure no\n\t\t\t// state-modifying operation is performed. The 3rd stack item\n\t\t\t// for a call operation is the value. Transferring value from one\n\t\t\t// account to the others means the state is modified and should also\n\t\t\t// return with an error.\n\t\t\tif operation.writes || (op == CALL && stack.Back(2).Sign() != 0) {\n\t\t\t\treturn nil, ErrWriteProtection\n\t\t\t}\n\t\t}\n\t\t// Static portion of gas\n\t\tcost = operation.constantGas // For tracing\n\t\tif !contract.UseGas(operation.constantGas) {\n\t\t\treturn nil, ErrOutOfGas\n\t\t}\n\n\t\tvar memorySize uint64\n\t\t// calculate the new memory size and expand the memory to fit\n\t\t// the operation\n\t\t// Memory check needs to be done prior to evaluating the dynamic gas portion,\n\t\t// to detect calculation overflows\n\t\tif operation.memorySize != nil {\n\t\t\tmemSize, overflow := operation.memorySize(stack)\n\t\t\tif overflow {\n\t\t\t\treturn nil, ErrGasUintOverflow\n\t\t\t}\n\t\t\t// memory is expanded in words of 32 bytes. Gas\n\t\t\t// is also calculated in words.\n\t\t\tif memorySize, overflow = math.SafeMul(toWordSize(memSize), 32); overflow {\n\t\t\t\treturn nil, ErrGasUintOverflow\n\t\t\t}\n\t\t}\n\t\t// Dynamic portion of gas\n\t\t// consume the gas and return an error if not enough gas is available.\n\t\t// cost is explicitly set so that the capture state defer method can get the proper cost\n\t\tif operation.dynamicGas != nil {\n\t\t\tvar dynamicCost uint64\n\t\t\tdynamicCost, err = operation.dynamicGas(in.evm, contract, stack, mem, memorySize)\n\t\t\tcost += dynamicCost // total cost, for debug tracing\n\t\t\tif err != nil || !contract.UseGas(dynamicCost) {\n\t\t\t\treturn nil, ErrOutOfGas\n\t\t\t}\n\t\t}\n\t\tif memorySize > 0 {\n\t\t\tmem.Resize(memorySize)\n\t\t}\n\n\t\tif in.cfg.Debug {\n\t\t\tin.cfg.Tracer.CaptureState(in.evm, pc, op, gasCopy, cost, mem, stack, returns, in.returnData, contract, in.evm.depth, err)\n\t\t\tlogged = true\n\t\t}\n\n\t\t// execute the operation\n\t\tres, err = operation.execute(&pc, in, callContext)\n\t\t// if the operation clears the return data (e.g. it has returning data)\n\t\t// set the last return to the result of the operation.\n\t\tif operation.returns {\n\t\t\tin.returnData = common.CopyBytes(res)\n\t\t}\n\n\t\tswitch {\n\t\tcase err != nil:\n\t\t\treturn nil, err\n\t\tcase operation.reverts:\n\t\t\treturn res, ErrExecutionReverted\n\t\tcase operation.halts:\n\t\t\treturn res, nil\n\t\tcase !operation.jumps:\n\t\t\tpc++\n\t\t}\n\t}\n\treturn nil, nil\n}", "is_vulnerable": 0}
{"code": "func setupTest(t *testing.T) *testData {\n\tproj := util.GetTestProject(t)\n\tcredsJson, creds := util.GetTestCredentials(t)\n\thttpC, err := gcputil.GetHttpClient(creds, iam.CloudPlatformScope)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tiamAdmin, err := iam.NewService(context.Background(), option.WithHTTPClient(httpC))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tb, reqStorage := getTestBackend(t)\n\ttestConfigUpdate(t, b, reqStorage, map[string]interface{}{\n\t\t\"credentials\": credsJson,\n\t})\n\n\treturn &testData{\n\t\tB:          b,\n\t\tS:          reqStorage,\n\t\tProject:    proj,\n\t\tHttpClient: httpC,\n\t\tIamAdmin:   iamAdmin,\n\t}\n}", "is_vulnerable": 1}
{"code": "\tmux.HandleFunc(\"/loop\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"X-Terraform-Get\", header)\n\t\tt.Logf(\"serving loop\")\n\t})", "is_vulnerable": 0}
{"code": "func TestIssue55ScriptTags(t *testing.T) {\n\tp1 := NewPolicy()\n\tp2 := UGCPolicy()\n\tp3 := UGCPolicy().AllowElements(\"script\")\n\n\tin := `<SCRIPT>document.write('<h1><header/h1>')</SCRIPT>`\n\texpected := ``\n\tout := p1.Sanitize(in)\n\tif out != expected {\n\t\tt.Errorf(\n\t\t\t\"test failed;\\ninput   : %s\\noutput  : %s\\nexpected: %s\",\n\t\t\tin,\n\t\t\tout,\n\t\t\texpected,\n\t\t)\n\t}\n\n\texpected = ``\n\tout = p2.Sanitize(in)\n\tif out != expected {\n\t\tt.Errorf(\n\t\t\t\"test failed;\\ninput   : %s\\noutput  : %s\\nexpected: %s\",\n\t\t\tin,\n\t\t\tout,\n\t\t\texpected,\n\t\t)\n\t}\n\n\texpected = `<script>document.write('<h1><header/h1>')</script>`\n\tout = p3.Sanitize(in)\n\tif out != expected {\n\t\tt.Errorf(\n\t\t\t\"test failed;\\ninput   : %s\\noutput  : %s\\nexpected: %s\",\n\t\t\tin,\n\t\t\tout,\n\t\t\texpected,\n\t\t)\n\t}\n}", "is_vulnerable": 1}
{"code": "\tgo func() {\n\t\tfor {\n\t\t\t// Wait for the given duration or until something gets added\n\t\t\tselect {\n\t\t\tcase dnsName := <-e.added:\n\t\t\t\tif err := e.dns.Add(dnsName); err != nil {\n\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t}\n\t\t\t\tif err := e.updateEntryForName(dnsName); err != nil {\n\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t}\n\t\t\tcase <-time.After(durationTillNextQuery):\n\t\t\t\tif len(dnsName) > 0 {\n\t\t\t\t\tif _, err := e.Update(dnsName); err != nil {\n\t\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t\t}\n\t\t\t\t\tif err := e.updateEntryForName(dnsName); err != nil {\n\t\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase <-e.stopChan:\n\t\t\t\treturn\n\t\t\tcase <-e.controllerStop:\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// before waiting on the signals get the next time this thread needs to wake up\n\t\t\tttl, dnsName, timeSet = e.dns.GetNextQueryTime()\n\t\t\tif time.Until(ttl) > defaultInterval || !timeSet {\n\t\t\t\tdurationTillNextQuery = defaultInterval\n\t\t\t} else {\n\t\t\t\tdurationTillNextQuery = time.Until(ttl)\n\t\t\t}\n\t\t}\n\t}()", "is_vulnerable": 1}
{"code": "func TestAccountURLResolverNoFetchOnReload(t *testing.T) {\n\tkp, _ := nkeys.FromSeed(oSeed)\n\takp, _ := nkeys.CreateAccount()\n\tapub, _ := akp.PublicKey()\n\tnac := jwt.NewAccountClaims(apub)\n\tajwt, err := nac.Encode(kp)\n\tif err != nil {\n\t\tt.Fatalf(\"Error generating account JWT: %v\", err)\n\t}\n\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(ajwt))\n\t}))\n\tdefer ts.Close()\n\n\tconfTemplate := `\n\t\toperator: %s\n\t\tlisten: -1\n\t\tresolver: URL(\"%s/ngs/v1/accounts/jwt/\")\n    `\n\tconf := createConfFile(t, []byte(fmt.Sprintf(confTemplate, ojwt, ts.URL)))\n\tdefer os.Remove(conf)\n\n\ts, _ := RunServerWithConfig(conf)\n\tdefer s.Shutdown()\n\n\tacc, _ := s.LookupAccount(apub)\n\tif acc == nil {\n\t\tt.Fatalf(\"Expected to receive an account\")\n\t}\n\n\t// Reload would produce a DATA race during the DeepEqual check for the account resolver,\n\t// so close the current one and we will create a new one that keeps track of fetch calls.\n\tts.Close()\n\n\tfetch := int32(0)\n\tts = httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tatomic.AddInt32(&fetch, 1)\n\t\tw.Write([]byte(ajwt))\n\t}))\n\tdefer ts.Close()\n\n\tchangeCurrentConfigContentWithNewContent(t, conf, []byte(fmt.Sprintf(confTemplate, ojwt, ts.URL)))\n\n\tif err := s.Reload(); err != nil {\n\t\tt.Fatalf(\"Error on reload: %v\", err)\n\t}\n\tif atomic.LoadInt32(&fetch) != 0 {\n\t\tt.Fatalf(\"Fetch invoked during reload\")\n\t}\n\n\t// Now stop the resolver and make sure that on startup, we report URL resolver failure\n\ts.Shutdown()\n\ts = nil\n\tts.Close()\n\n\topts := LoadConfig(conf)\n\tif s, err := NewServer(opts); err == nil || !strings.Contains(err.Error(), \"could not fetch\") {\n\t\tif s != nil {\n\t\t\ts.Shutdown()\n\t\t}\n\t\tt.Fatalf(\"Expected error regarding account resolver, got %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (upsert UserSettingUpsert) Validate() error {\n\tif upsert.Key == UserSettingLocaleKey {\n\t\tlocaleValue := \"en\"\n\t\terr := json.Unmarshal([]byte(upsert.Value), &localeValue)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to unmarshal user setting locale value\")\n\t\t}\n\n\t\tinvalid := true\n\t\tfor _, value := range UserSettingLocaleValue {\n\t\t\tif localeValue == value {\n\t\t\t\tinvalid = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif invalid {\n\t\t\treturn fmt.Errorf(\"invalid user setting locale value\")\n\t\t}\n\t} else if upsert.Key == UserSettingAppearanceKey {\n\t\tappearanceValue := \"light\"\n\t\terr := json.Unmarshal([]byte(upsert.Value), &appearanceValue)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to unmarshal user setting appearance value\")\n\t\t}\n\n\t\tinvalid := true\n\t\tfor _, value := range UserSettingAppearanceValue {\n\t\t\tif appearanceValue == value {\n\t\t\t\tinvalid = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif invalid {\n\t\t\treturn fmt.Errorf(\"invalid user setting appearance value\")\n\t\t}\n\t} else if upsert.Key == UserSettingMemoVisibilityKey {\n\t\tmemoVisibilityValue := Private\n\t\terr := json.Unmarshal([]byte(upsert.Value), &memoVisibilityValue)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to unmarshal user setting memo visibility value\")\n\t\t}\n\n\t\tinvalid := true\n\t\tfor _, value := range UserSettingMemoVisibilityValue {\n\t\t\tif memoVisibilityValue == value {\n\t\t\t\tinvalid = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif invalid {\n\t\t\treturn fmt.Errorf(\"invalid user setting memo visibility value\")\n\t\t}\n\t} else if upsert.Key == UserSettingMemoDisplayTsOptionKey {\n\t\tmemoDisplayTsOption := \"created_ts\"\n\t\terr := json.Unmarshal([]byte(upsert.Value), &memoDisplayTsOption)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to unmarshal user setting memo display ts option\")\n\t\t}\n\n\t\tinvalid := true\n\t\tfor _, value := range UserSettingMemoDisplayTsOptionKeyValue {\n\t\t\tif memoDisplayTsOption == value {\n\t\t\t\tinvalid = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif invalid {\n\t\t\treturn fmt.Errorf(\"invalid user setting memo display ts option value\")\n\t\t}\n\t} else {\n\t\treturn fmt.Errorf(\"invalid user setting key\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *ConsoleServer) Authenticate(ctx context.Context, in *console.AuthenticateRequest) (*console.ConsoleSession, error) {\n\tip, _ := extractClientAddressFromContext(s.logger, ctx)\n\tif !s.loginAttemptCache.Allow(in.Username, ip) {\n\t\treturn nil, status.Error(codes.ResourceExhausted, \"Try again later.\")\n\t}\n\n\trole := console.UserRole_USER_ROLE_UNKNOWN\n\tvar uname string\n\tvar email string\n\tvar id uuid.UUID\n\tswitch in.Username {\n\tcase s.config.GetConsole().Username:\n\t\tif in.Password == s.config.GetConsole().Password {\n\t\t\trole = console.UserRole_USER_ROLE_ADMIN\n\t\t\tuname = in.Username\n\t\t\tid = uuid.Nil\n\t\t} else {\n\t\t\tif lockout, until := s.loginAttemptCache.Add(s.config.GetConsole().Username, ip); lockout != LockoutTypeNone {\n\t\t\t\tswitch lockout {\n\t\t\t\tcase LockoutTypeAccount:\n\t\t\t\t\ts.logger.Info(fmt.Sprintf(\"Console admin account locked until %v.\", until))\n\t\t\t\tcase LockoutTypeIp:\n\t\t\t\t\ts.logger.Info(fmt.Sprintf(\"Console admin IP locked until %v.\", until))\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil, status.Error(codes.Unauthenticated, \"Invalid credentials.\")\n\t\t}\n\tdefault:\n\t\tvar err error\n\t\tid, uname, email, role, err = s.lookupConsoleUser(ctx, in.Username, in.Password, ip)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif role == console.UserRole_USER_ROLE_UNKNOWN {\n\t\treturn nil, status.Error(codes.Unauthenticated, \"Invalid credentials.\")\n\t}\n\n\ts.loginAttemptCache.Reset(uname)\n\n\texp := time.Now().UTC().Add(time.Duration(s.config.GetConsole().TokenExpirySec) * time.Second).Unix()\n\n\ttoken := jwt.NewWithClaims(jwt.SigningMethodHS256, &ConsoleTokenClaims{\n\t\tExpiresAt: exp,\n\t\tID:        id.String(),\n\t\tUsername:  uname,\n\t\tEmail:     email,\n\t\tRole:      role,\n\t\tCookie:    s.cookie,\n\t})\n\tkey := []byte(s.config.GetConsole().SigningKey)\n\tsignedToken, _ := token.SignedString(key)\n\n\ts.consoleSessionCache.Add(id, exp, signedToken, 0, \"\")\n\treturn &console.ConsoleSession{Token: signedToken}, nil\n}", "is_vulnerable": 0}
{"code": "func (s *GetSecurityGroupsForVpcInput) SetVpcId(v string) *GetSecurityGroupsForVpcInput {\n\ts.VpcId = &v\n\treturn s\n}", "is_vulnerable": 0}
{"code": "func (t *assetAction) checkERC20Deposit() error {\n\tasset, _ := t.asset.ERC20()\n\treturn t.bridgeView.FindDeposit(\n\t\tt.erc20D, t.blockHeight, t.logIndex, asset.Address(),\n\t)\n}", "is_vulnerable": 1}
{"code": "func NewAppStateManager(\n\tdb db.ArgoDB,\n\tappclientset appclientset.Interface,\n\trepoClientset apiclient.Clientset,\n\tnamespace string,\n\tkubectl kubeutil.Kubectl,\n\tsettingsMgr *settings.SettingsManager,\n\tliveStateCache statecache.LiveStateCache,\n\tprojInformer cache.SharedIndexInformer,\n\tmetricsServer *metrics.MetricsServer,\n\tcache *appstatecache.Cache,\n\tstatusRefreshTimeout time.Duration,\n\tresourceTracking argo.ResourceTracking,\n\tpersistResourceHealth bool,\n\tignoreNormalizerOpts normalizers.IgnoreNormalizerOpts,\n) AppStateManager {\n\treturn &appStateManager{\n\t\tliveStateCache:        liveStateCache,\n\t\tcache:                 cache,\n\t\tdb:                    db,\n\t\tappclientset:          appclientset,\n\t\tkubectl:               kubectl,\n\t\trepoClientset:         repoClientset,\n\t\tnamespace:             namespace,\n\t\tsettingsMgr:           settingsMgr,\n\t\tprojInformer:          projInformer,\n\t\tmetricsServer:         metricsServer,\n\t\tstatusRefreshTimeout:  statusRefreshTimeout,\n\t\tresourceTracking:      resourceTracking,\n\t\tpersistResourceHealth: persistResourceHealth,\n\t\tignoreNormalizerOpts:  ignoreNormalizerOpts,\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestBoundSplit(t *testing.T) {\n\tvar entries []*kv\n\tfor i := 0; i < 1024; i++ {\n\t\tvar val []byte\n\t\tif rand.Intn(3) == 0 {\n\t\t\tval = testrand.Bytes(3)\n\t\t} else {\n\t\t\tval = testrand.Bytes(32)\n\t\t}\n\t\tentries = append(entries, &kv{\n\t\t\tk: testrand.Bytes(32),\n\t\t\tv: val,\n\t\t})\n\t}\n\tslices.SortFunc(entries, (*kv).cmp)\n\n\tfor j := 0; j < 100; j++ {\n\t\tvar (\n\t\t\tnext int\n\t\t\tlast int\n\t\t\tdb   = rawdb.NewMemoryDatabase()\n\n\t\t\tlastRightRoot []byte\n\t\t)\n\t\tfor {\n\t\t\tif next == len(entries) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tlast = rand.Intn(len(entries)-next) + next\n\n\t\t\tr := buildPartial(common.Hash{}, db, db.NewBatch(), entries, next, last)\n\t\t\tset := r.modifies()\n\n\t\t\t// Skip if the chunk is zero-size\n\t\t\tif r.updates() == 0 {\n\t\t\t\tnext = last + 1\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Ensure the updates in two consecutive chunks are not overlapped.\n\t\t\t// The only overlapping part should be deletion.\n\t\t\tif lastRightRoot != nil && len(set) > 0 {\n\t\t\t\t// Derive the path of left-most node in this chunk\n\t\t\t\tvar leftRoot []byte\n\t\t\t\tfor path, hash := range r.modifies() {\n\t\t\t\t\tif hash == (common.Hash{}) {\n\t\t\t\t\t\tt.Fatalf(\"Unexpected deletion %v\", []byte(path))\n\t\t\t\t\t}\n\t\t\t\t\tif leftRoot == nil || bytes.Compare(leftRoot, []byte(path)) > 0 {\n\t\t\t\t\t\tleftRoot = []byte(path)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif bytes.HasPrefix(lastRightRoot, leftRoot) || bytes.HasPrefix(leftRoot, lastRightRoot) {\n\t\t\t\t\tt.Fatalf(\"Two chunks are not correctly separated, lastRight: %v, left: %v\", lastRightRoot, leftRoot)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Track the updates as the last chunk\n\t\t\tvar rightRoot []byte\n\t\t\tfor path := range set {\n\t\t\t\tif rightRoot == nil ||\n\t\t\t\t\t(bytes.Compare(rightRoot, []byte(path)) < 0) ||\n\t\t\t\t\t(bytes.Compare(rightRoot, []byte(path)) > 0 && bytes.HasPrefix(rightRoot, []byte(path))) {\n\t\t\t\t\trightRoot = []byte(path)\n\t\t\t\t}\n\t\t\t}\n\t\t\tlastRightRoot = rightRoot\n\t\t\tnext = last + 1\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *NinOptEnum) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptEnum: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptEnum: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v TheTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= TheTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v YetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field2 = &v\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v YetYetAnotherTestEnum\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= YetYetAnotherTestEnum(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field3 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m mockSecret) GetSecret(name string) (*api.Secret, error) {\n\tif name != \"default/demo-secret\" && name != \"otherns/demo-secret\" {\n\t\treturn nil, fmt.Errorf(\"there is no secret with name %v\", name)\n\t}\n\n\tns, _, err := cache.SplitMetaNamespaceKey(name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &api.Secret{\n\t\tObjectMeta: meta_v1.ObjectMeta{\n\t\t\tNamespace: ns,\n\t\t\tName:      \"demo-secret\",\n\t\t},\n\t\tData: map[string][]byte{\"auth\": []byte(\"foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\")},\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func processMessage(msg *beehiveModel.Message) {\n\tsource := msg.GetSource()\n\tif source != sourceType {\n\t\treturn\n\t}\n\tresource := msg.GetResource()\n\tswitch msg.GetOperation() {\n\tcase \"start\":\n\t\tif atomic.CompareAndSwapInt32(&inited, 0, 1) {\n\t\t\tdao.InsertUrls(resource)\n\t\t\tgo server(c)\n\t\t}\n\tcase \"stop\":\n\t\tdao.DeleteUrlsByKey(resource)\n\t\tif dao.IsTableEmpty() {\n\t\t\tc <- struct{}{}\n\t\t}\n\tdefault:\n\t\tr := strings.Split(resource, \":\")\n\t\tif len(r) != 2 {\n\t\t\tm := \"the format of resource \" + resource + \" is incorrect\"\n\t\t\tklog.Warningf(m)\n\t\t\tcode := http.StatusBadRequest\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tcontent, err := msg.GetContentData()\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"marshall message content failed %v\", err)\n\t\t\tm := \"error to marshal request msg content\"\n\t\t\tcode := http.StatusBadRequest\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tvar httpRequest commonType.HTTPRequest\n\t\tif err := json.Unmarshal(content, &httpRequest); err != nil {\n\t\t\tm := \"error to parse http request\"\n\t\t\tcode := http.StatusBadRequest\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t//send message with resource to the edge part\n\t\toperation := httpRequest.Method\n\t\ttargetURL := \"http://127.0.0.1:\" + r[0] + r[1]\n\t\tresp, err := uc.HTTPDo(operation, targetURL, httpRequest.Header, httpRequest.Body)\n\t\tif err != nil {\n\t\t\tm := \"error to call service\"\n\t\t\tcode := http.StatusNotFound\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tdefer resp.Body.Close()\n\t\tresBody, err := io.ReadAll(io.LimitReader(resp.Body, maxBodySize))\n\t\tif err != nil {\n\t\t\tif err.Error() == \"http: request body too large\" {\n\t\t\t\terr = fmt.Errorf(\"response body too large\")\n\t\t\t}\n\t\t\tm := \"error to receive response, err: \" + err.Error()\n\t\t\tcode := http.StatusInternalServerError\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tresponse := commonType.HTTPResponse{Header: resp.Header, StatusCode: resp.StatusCode, Body: resBody}\n\t\tresponseMsg := beehiveModel.NewMessage(msg.GetID()).SetRoute(modules.ServiceBusModuleName, modules.UserGroup).\n\t\t\tSetResourceOperation(\"\", beehiveModel.UploadOperation).FillBody(response)\n\t\tbeehiveContext.SendToGroup(modules.HubGroup, *responseMsg)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f *ConfigurationFile) parseIniFile(path string) error {\n\t// Ini package can't handle a non-existent file, so handle that automatically here\n\t// by creating it if not exists. Then, immediately close the file since we will use\n\t// other methods to write the new contents.\n\tfile, err := os.OpenFile(path, os.O_CREATE|os.O_RDWR, 0o644)\n\tif err != nil {\n\t\treturn err\n\t}\n\tfile.Close()\n\n\tcfg, err := ini.Load(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, replacement := range f.Replace {\n\t\tvar (\n\t\t\tpath         []string\n\t\t\tbracketDepth int\n\t\t\tv            []int32\n\t\t)\n\t\tfor _, c := range replacement.Match {\n\t\t\tswitch c {\n\t\t\tcase '[':\n\t\t\t\tbracketDepth++\n\t\t\tcase ']':\n\t\t\t\tbracketDepth--\n\t\t\tcase '.':\n\t\t\t\tif bracketDepth > 0 || len(path) == 1 {\n\t\t\t\t\tv = append(v, c)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tpath = append(path, string(v))\n\t\t\t\tv = v[:0]\n\t\t\tdefault:\n\t\t\t\tv = append(v, c)\n\t\t\t}\n\t\t}\n\t\tpath = append(path, string(v))\n\n\t\tvalue, err := f.LookupConfigurationValue(replacement)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tk := path[0]\n\t\ts := cfg.Section(\"\")\n\t\t// Passing a key of foo.bar will look for \"bar\" in the \"[foo]\" section of the file.\n\t\tif len(path) == 2 {\n\t\t\tk = path[1]\n\t\t\ts = cfg.Section(path[0])\n\t\t}\n\n\t\t// If no section was found, create that new section now and then set the\n\t\t// section value we're using to be the new one.\n\t\tif s == nil {\n\t\t\ts, err = cfg.NewSection(path[0])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// If the key exists in the file go ahead and set the value, otherwise try to\n\t\t// create it in the section.\n\t\tif s.HasKey(k) {\n\t\t\ts.Key(k).SetValue(value)\n\t\t} else {\n\t\t\tif _, err := s.NewKey(k, value); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn cfg.SaveTo(path)\n}", "is_vulnerable": 1}
{"code": "func SnapshotPublicModeOrSignedIn(cfg *setting.Cfg) macaron.Handler {\n\treturn func(c *models.ReqContext) {\n\t\tif cfg.SnapshotPublicMode {\n\t\t\treturn\n\t\t}\n\n\t\tif !c.IsSignedIn {\n\t\t\tnotAuthorized(c)\n\t\t\treturn\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client Client) Delete(ctx context.Context, resourceGroupName string, resourceProviderNamespace string, parentResourcePath string, resourceType string, resourceName string) (result autorest.Response, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"Delete\", err.Error())\n\t}\n\n\treq, err := client.DeletePreparer(ctx, resourceGroupName, resourceProviderNamespace, parentResourcePath, resourceType, resourceName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Delete\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.DeleteSender(req)\n\tif err != nil {\n\t\tresult.Response = resp\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Delete\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.DeleteResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Delete\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdb := NewMemoryDatabase()\n\n\t\t\ttx1 := types.NewTransaction(1, common.BytesToAddress([]byte{0x11}), big.NewInt(111), 1111, big.NewInt(11111), []byte{0x11, 0x11, 0x11})\n\t\t\ttx2 := types.NewTransaction(2, common.BytesToAddress([]byte{0x22}), big.NewInt(222), 2222, big.NewInt(22222), []byte{0x22, 0x22, 0x22})\n\t\t\ttx3 := types.NewTransaction(3, common.BytesToAddress([]byte{0x33}), big.NewInt(333), 3333, big.NewInt(33333), []byte{0x33, 0x33, 0x33})\n\t\t\ttxs := []*types.Transaction{tx1, tx2, tx3}\n\n\t\t\tblock := types.NewBlock(&types.Header{Number: big.NewInt(314)}, txs, nil, nil)\n\n\t\t\t// Check that no transactions entries are in a pristine database\n\t\t\tfor i, tx := range txs {\n\t\t\t\tif txn, _, _, _ := ReadTransaction(db, tx.Hash()); txn != nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: non existent transaction returned: %v\", i, tx.Hash(), txn)\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Insert all the transactions into the database, and verify contents\n\t\t\tWriteCanonicalHash(db, block.Hash(), block.NumberU64())\n\t\t\tWriteBlock(db, block)\n\t\t\ttc.writeTxLookupEntries(db, block)\n\n\t\t\tfor i, tx := range txs {\n\t\t\t\tif txn, hash, number, index := ReadTransaction(db, tx.Hash()); txn == nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: transaction not found\", i, tx.Hash())\n\t\t\t\t} else {\n\t\t\t\t\tif hash != block.Hash() || number != block.NumberU64() || index != uint64(i) {\n\t\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: positional metadata mismatch: have %x/%d/%d, want %x/%v/%v\", i, tx.Hash(), hash, number, index, block.Hash(), block.NumberU64(), i)\n\t\t\t\t\t}\n\t\t\t\t\tif tx.Hash() != txn.Hash() {\n\t\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: transaction mismatch: have %v, want %v\", i, tx.Hash(), txn, tx)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Delete the transactions and check purge\n\t\t\tfor i, tx := range txs {\n\t\t\t\tDeleteTxLookupEntry(db, tx.Hash())\n\t\t\t\tif txn, _, _, _ := ReadTransaction(db, tx.Hash()); txn != nil {\n\t\t\t\t\tt.Fatalf(\"tx #%d [%x]: deleted transaction returned: %v\", i, tx.Hash(), txn)\n\t\t\t\t}\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (fl fileLogger) shouldLogBody(header http.Header, body io.ReadCloser) bool {\n\tct := header.Get(\"Content-Type\")\n\treturn fl.logLevel >= LogDebug && body != nil && !strings.Contains(ct, \"application/octet-stream\")\n}", "is_vulnerable": 0}
{"code": "func New(ctx context.Context, next http.Handler, cfg dynamic.Headers, name string) (http.Handler, error) {\n\t// HeaderMiddleware -> SecureMiddleWare -> next\n\tmCtx := middlewares.GetLoggerCtx(ctx, name, typeName)\n\tlogger := log.FromContext(mCtx)\n\tlogger.Debug(\"Creating middleware\")\n\n\thandleDeprecation(mCtx, &cfg)\n\n\thasSecureHeaders := cfg.HasSecureHeadersDefined()\n\thasCustomHeaders := cfg.HasCustomHeadersDefined()\n\thasCorsHeaders := cfg.HasCorsHeadersDefined()\n\n\tif !hasSecureHeaders && !hasCustomHeaders && !hasCorsHeaders {\n\t\treturn nil, errors.New(\"headers configuration not valid\")\n\t}\n\n\tvar handler http.Handler\n\tnextHandler := next\n\n\tif hasSecureHeaders {\n\t\tlogger.Debugf(\"Setting up secureHeaders from %v\", cfg)\n\t\thandler = newSecure(next, cfg, name)\n\t\tnextHandler = handler\n\t}\n\n\tif hasCustomHeaders || hasCorsHeaders {\n\t\tlogger.Debugf(\"Setting up customHeaders/Cors from %v\", cfg)\n\t\th, err := NewHeader(nextHandler, cfg)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\thandler = connectionheader.Remover(h)\n\t}\n\n\treturn &headers{\n\t\thandler: handler,\n\t\tname:    name,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func authenticate(inner func(http.ResponseWriter, *http.Request, meta.User), h *Handler, requireAuthentication bool) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Return early if we are not authenticating\n\t\tif !requireAuthentication {\n\t\t\tinner(w, r, nil)\n\t\t\treturn\n\t\t}\n\t\tvar user meta.User\n\n\t\t// TODO corylanou: never allow this in the future without users\n\t\tif requireAuthentication && h.MetaClient.AdminUserExists() {\n\t\t\tcreds, err := parseCredentials(r)\n\t\t\tif err != nil {\n\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tswitch creds.Method {\n\t\t\tcase UserAuthentication:\n\t\t\t\tif creds.Username == \"\" {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"username required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tuser, err = h.MetaClient.Authenticate(creds.Username, creds.Password)\n\t\t\t\tif err != nil {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"authorization failed\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tcase BearerAuthentication:\n\t\t\t\tif h.Config.SharedSecret == \"\" {\n\t\t\t\t\tatomic.AddInt64(&h.stats.AuthenticationFailures, 1)\n\t\t\t\t\th.httpError(w, \"bearer auth disabled\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tkeyLookupFn := func(token *jwt.Token) (interface{}, error) {\n\t\t\t\t\t// Check for expected signing method.\n\t\t\t\t\tif _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"unexpected signing method: %v\", token.Header[\"alg\"])\n\t\t\t\t\t}\n\t\t\t\t\treturn []byte(h.Config.SharedSecret), nil\n\t\t\t\t}\n\n\t\t\t\t// Parse and validate the token.\n\t\t\t\ttoken, err := jwt.Parse(creds.Token, keyLookupFn)\n\t\t\t\tif err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if !token.Valid {\n\t\t\t\t\th.httpError(w, \"invalid token\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tclaims, ok := token.Claims.(jwt.MapClaims)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"problem authenticating token\", http.StatusInternalServerError)\n\t\t\t\t\th.Logger.Info(\"Could not assert JWT token claims as jwt.MapClaims\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Make sure an expiration was set on the token.\n\t\t\t\tif exp, ok := claims[\"exp\"].(float64); !ok || exp <= 0.0 {\n\t\t\t\t\th.httpError(w, \"token expiration required\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Get the username from the token.\n\t\t\t\tusername, ok := claims[\"username\"].(string)\n\t\t\t\tif !ok {\n\t\t\t\t\th.httpError(w, \"username in token must be a string\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if username == \"\" {\n\t\t\t\t\th.httpError(w, \"token must contain a username\", http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Lookup user in the metastore.\n\t\t\t\tif user, err = h.MetaClient.User(username); err != nil {\n\t\t\t\t\th.httpError(w, err.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t} else if user == nil {\n\t\t\t\t\th.httpError(w, meta.ErrUserNotFound.Error(), http.StatusUnauthorized)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\th.httpError(w, \"unsupported authentication\", http.StatusUnauthorized)\n\t\t\t}\n\n\t\t}\n\t\tinner(w, r, user)\n\t})\n}", "is_vulnerable": 0}
{"code": "func generateCallbackURI(httpC2ConfigName string) string {\n\thttpC2Config, err := db.LoadHTTPC2ConfigByName(httpC2ConfigName)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tsegments := httpC2Config.ImplantConfig.PathSegments\n\tStageFiles := []string{}\n\tStagePaths := []string{}\n\n\tfor _, segment := range segments {\n\t\tif segment.SegmentType == 3 {\n\t\t\tif segment.IsFile {\n\t\t\t\tStageFiles = append(StageFiles, segment.Value)\n\t\t\t} else {\n\t\t\t\tStagePaths = append(StagePaths, segment.Value)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn path.Join(randomPath(StagePaths, StageFiles)...)\n}", "is_vulnerable": 1}
{"code": "func Lessf(t TestingT, e1 interface{}, e2 interface{}, msg string, args ...interface{}) bool {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn Less(t, e1, e2, append([]interface{}{msg}, args...)...)\n}", "is_vulnerable": 0}
{"code": "func TestUTF16(t *testing.T) {\n\ttestCases := []struct {\n\t\tdesc    string\n\t\tsrc     string\n\t\tnotEOF  bool // the inverse of atEOF\n\t\tsizeDst int\n\t\twant    string\n\t\tnSrc    int\n\t\terr     error\n\t\tt       transform.Transformer\n\t}{{\n\t\tdesc: \"utf-16 IgnoreBOM dec: empty string\",\n\t\tt:    utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc: \"utf-16 UseBOM dec: empty string\",\n\t\tt:    utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc: \"utf-16 ExpectBOM dec: empty string\",\n\t\terr:  ErrMissingBOM,\n\t\tt:    utf16BEEB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: BOM determines encoding BE (RFC 2781:3.3)\",\n\t\tsrc:     \"\\xFE\\xFF\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\\x00\\x61\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=Ra\",\n\t\tnSrc:    12,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: BOM determines encoding LE (RFC 2781:3.3)\",\n\t\tsrc:     \"\\xFF\\xFE\\x08\\xD8\\x45\\xDF\\x3D\\x00\\x52\\x00\\x61\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=Ra\",\n\t\tnSrc:    12,\n\t\tt:       utf16LEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: BOM determines encoding LE, change default (RFC 2781:3.3)\",\n\t\tsrc:     \"\\xFF\\xFE\\x08\\xD8\\x45\\xDF\\x3D\\x00\\x52\\x00\\x61\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=Ra\",\n\t\tnSrc:    12,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: Fail on missing BOM when required\",\n\t\tsrc:     \"\\x08\\xD8\\x45\\xDF\\x3D\\x00\\xFF\\xFE\\xFE\\xFF\\x00\\x52\\x00\\x61\",\n\t\tsizeDst: 100,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\terr:     ErrMissingBOM,\n\t\tt:       utf16BEEB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: Fail on single byte missing BOM when required\",\n\t\tsrc:     \"\\x00\",\n\t\tsizeDst: 4,\n\t\tt:       utf16BEEB.NewDecoder(),\n\t\terr:     ErrMissingBOM,\n\t}, {\n\t\tdesc:    \"utf-16 dec: Fail on short src missing BOM when required\",\n\t\tsrc:     \"\\x00\",\n\t\tnotEOF:  true,\n\t\tsizeDst: 4,\n\t\tt:       utf16BEEB.NewDecoder(),\n\t\terr:     transform.ErrShortSrc,\n\t}, {\n\t\tdesc:    \"utf-16 dec: SHOULD interpret text as big-endian when BOM not present (RFC 2781:4.3)\",\n\t\tsrc:     \"\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\\x00\\x61\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=Ra\",\n\t\tnSrc:    10,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: incorrect UTF-16: odd bytes\",\n\t\tsrc:     \"\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFD\",\n\t\tnSrc:    1,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 dec: Fail on incorrect UTF-16: short source odd bytes\",\n\t\tsrc:     \"\\x00\",\n\t\tnotEOF:  true,\n\t\tsizeDst: 100,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t\terr:     transform.ErrShortSrc,\n\t}, {\n\t\t// This is an error according to RFC 2781. But errors in RFC 2781 are\n\t\t// open to interpretations, so I guess this is fine.\n\t\tdesc:    \"utf-16le dec: incorrect BOM is an error (RFC 2781:4.1)\",\n\t\tsrc:     \"\\xFE\\xFF\\x08\\xD8\\x45\\xDF\\x3D\\x00\\x52\\x00\\x61\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFE\\U00012345=Ra\",\n\t\tnSrc:    12,\n\t\tt:       utf16LEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16 enc: SHOULD write BOM (RFC 2781:3.3)\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\xFF\\xFE\\x08\\xD8\\x45\\xDF\\x3D\\x00\\x52\\x00\\x61\\x00\",\n\t\tnSrc:    7,\n\t\tt:       utf16LEUB.NewEncoder(),\n\t}, {\n\t\tdesc:    \"utf-16 enc: SHOULD write BOM (RFC 2781:3.3)\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\xFE\\xFF\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\\x00\\x61\",\n\t\tnSrc:    7,\n\t\tt:       utf16BEUB.NewEncoder(),\n\t}, {\n\t\tdesc:    \"utf-16le enc: MUST NOT write BOM (RFC 2781:3.3)\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\x08\\xD8\\x45\\xDF\\x3D\\x00\\x52\\x00\\x61\\x00\",\n\t\tnSrc:    7,\n\t\tt:       utf16LEIB.NewEncoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: incorrect UTF-16: odd bytes\",\n\t\tsrc:     \"\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFD\",\n\t\tnSrc:    1,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: unpaired surrogate, odd bytes\",\n\t\tsrc:     \"\\xD8\\x45\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFD\\uFFFD\",\n\t\tnSrc:    3,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: unpaired low surrogate + valid text\",\n\t\tsrc:     \"\\xD8\\x45\\x00a\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFDa\",\n\t\tnSrc:    4,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: unpaired low surrogate + valid text + single byte\",\n\t\tsrc:     \"\\xD8\\x45\\x00ab\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFDa\\uFFFD\",\n\t\tnSrc:    5,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16le dec: unpaired high surrogate\",\n\t\tsrc:     \"\\x00\\x00\\x00\\xDC\\x12\\xD8\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\x00\\uFFFD\\uFFFD\",\n\t\tnSrc:    6,\n\t\tt:       utf16LEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: two unpaired low surrogates\",\n\t\tsrc:     \"\\xD8\\x45\\xD8\\x12\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\uFFFD\\uFFFD\",\n\t\tnSrc:    4,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16be dec: short dst\",\n\t\tsrc:     \"\\x00a\",\n\t\tsizeDst: 0,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t\terr:     transform.ErrShortDst,\n\t}, {\n\t\tdesc:    \"utf-16be dec: short dst surrogate\",\n\t\tsrc:     \"\\xD8\\xF5\\xDC\\x12\",\n\t\tsizeDst: 3,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t\terr:     transform.ErrShortDst,\n\t}, {\n\t\tdesc:    \"utf-16be dec: short dst trailing byte\",\n\t\tsrc:     \"\\x00\",\n\t\tsizeDst: 2,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t\terr:     transform.ErrShortDst,\n\t}, {\n\t\tdesc:    \"utf-16be dec: short src\",\n\t\tsrc:     \"\\x00\",\n\t\tnotEOF:  true,\n\t\tsizeDst: 3,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\tt:       utf16BEIB.NewDecoder(),\n\t\terr:     transform.ErrShortSrc,\n\t}, {\n\t\tdesc:    \"utf-16 enc\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\xFE\\xFF\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\\x00\\x61\",\n\t\tnSrc:    7,\n\t\tt:       utf16BEUB.NewEncoder(),\n\t}, {\n\t\tdesc:    \"utf-16 enc: short dst normal\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 9,\n\t\twant:    \"\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\",\n\t\tnSrc:    6,\n\t\tt:       utf16BEIB.NewEncoder(),\n\t\terr:     transform.ErrShortDst,\n\t}, {\n\t\tdesc:    \"utf-16 enc: short dst surrogate\",\n\t\tsrc:     \"\\U00012345=Ra\",\n\t\tsizeDst: 3,\n\t\twant:    \"\",\n\t\tnSrc:    0,\n\t\tt:       utf16BEIB.NewEncoder(),\n\t\terr:     transform.ErrShortDst,\n\t}, {\n\t\tdesc:    \"utf-16 enc: short src\",\n\t\tsrc:     \"\\U00012345=Ra\\xC2\",\n\t\tnotEOF:  true,\n\t\tsizeDst: 100,\n\t\twant:    \"\\xD8\\x08\\xDF\\x45\\x00\\x3D\\x00\\x52\\x00\\x61\",\n\t\tnSrc:    7,\n\t\tt:       utf16BEIB.NewEncoder(),\n\t\terr:     transform.ErrShortSrc,\n\t}, {\n\t\tdesc:    \"utf-16be dec: don't change byte order mid-stream\",\n\t\tsrc:     \"\\xFE\\xFF\\xD8\\x08\\xDF\\x45\\x00\\x3D\\xFF\\xFE\\x00\\x52\\x00\\x61\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=\\ufffeRa\",\n\t\tnSrc:    14,\n\t\tt:       utf16BEUB.NewDecoder(),\n\t}, {\n\t\tdesc:    \"utf-16le dec: don't change byte order mid-stream\",\n\t\tsrc:     \"\\xFF\\xFE\\x08\\xD8\\x45\\xDF\\x3D\\x00\\xFF\\xFE\\xFE\\xFF\\x52\\x00\\x61\\x00\",\n\t\tsizeDst: 100,\n\t\twant:    \"\\U00012345=\\ufeff\\ufffeRa\",\n\t\tnSrc:    16,\n\t\tt:       utf16LEUB.NewDecoder(),\n\t}}\n\tfor i, tc := range testCases {\n\t\tfor j := 0; j < 2; j++ {\n\t\t\tb := make([]byte, tc.sizeDst)\n\t\t\tnDst, nSrc, err := tc.t.Transform(b, []byte(tc.src), !tc.notEOF)\n\t\t\tif err != tc.err {\n\t\t\t\tt.Errorf(\"%d:%s: error was %v; want %v\", i, tc.desc, err, tc.err)\n\t\t\t}\n\t\t\tif got := string(b[:nDst]); got != tc.want {\n\t\t\t\tt.Errorf(\"%d:%s: result was %q: want %q\", i, tc.desc, got, tc.want)\n\t\t\t}\n\t\t\tif nSrc != tc.nSrc {\n\t\t\t\tt.Errorf(\"%d:%s: nSrc was %d; want %d\", i, tc.desc, nSrc, tc.nSrc)\n\t\t\t}\n\t\t\t// Since Transform is stateful, run failures again\n\t\t\t// to ensure that the same error occurs a second time.\n\t\t\tif err == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockClient) GetID() string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetID\")\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func getTestTargetPath(t *testing.T, uid, vol string) string {\n\tdir := getTempTestDir(t)\n\tpath := filepath.Join(dir, \"pods\", uid, \"volumes\", \"kubernetes.io~csi\", vol, \"mount\")\n\tif err := os.MkdirAll(path, 0755); err != nil {\n\t\tt.Fatalf(\"expected err to be nil, got: %+v\", err)\n\t}\n\treturn path\n}", "is_vulnerable": 0}
{"code": "func (router *Router) HandleRoute(writer http.ResponseWriter, request *http.Request) {\n\troute := router.Route\n\n\tlogger := route.Logger.With(\n\t\tlogging.LabelEndpoint, route.Context.Endpoint,\n\t\tlogging.LabelPort, route.Context.Port,\n\t\tlogging.LabelHTTPMethod, route.Context.Method,\n\t)\n\n\tlogger.Info(\"request received from event source\")\n\n\tif !route.Active {\n\t\tlogger.Info(\"endpoint is not active, won't process the request\")\n\t\tcommon.SendErrorResponse(writer, \"inactive endpoint\")\n\t\treturn\n\t}\n\n\tdefer func(start time.Time) {\n\t\troute.Metrics.EventProcessingDuration(route.EventSourceName, route.EventName, float64(time.Since(start)/time.Millisecond))\n\t}(time.Now())\n\n\tbody, err := ioutil.ReadAll(request.Body)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to parse the request body\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tvar notification *httpNotification\n\terr = yaml.Unmarshal(body, &notification)\n\tif err != nil {\n\t\tlogger.Errorw(\"failed to convert request payload into sns notification\", zap.Error(err))\n\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\treturn\n\t}\n\n\tif notification == nil {\n\t\tcommon.SendErrorResponse(writer, \"bad request, not a valid SNS notification\")\n\t\treturn\n\t}\n\n\t// SNS Signature Verification\n\tif router.eventSource.ValidateSignature {\n\t\terr = notification.verify()\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to verify sns message\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t}\n\n\tswitch notification.Type {\n\tcase messageTypeSubscriptionConfirmation:\n\t\tawsSession := router.session\n\n\t\tresponse, err := awsSession.ConfirmSubscription(&snslib.ConfirmSubscriptionInput{\n\t\t\tTopicArn: &router.eventSource.TopicArn,\n\t\t\tToken:    &notification.Token,\n\t\t})\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to send confirmation response to aws sns\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\n\t\tlogger.Info(\"subscription successfully confirmed to aws sns\")\n\t\trouter.subscriptionArn = response.SubscriptionArn\n\n\tcase messageTypeNotification:\n\t\tlogger.Info(\"dispatching notification on route's data channel\")\n\n\t\teventData := &events.SNSEventData{\n\t\t\tHeader:   request.Header,\n\t\t\tBody:     (*json.RawMessage)(&body),\n\t\t\tMetadata: router.eventSource.Metadata,\n\t\t}\n\n\t\teventBytes, err := json.Marshal(eventData)\n\t\tif err != nil {\n\t\t\tlogger.Errorw(\"failed to marshal the event data\", zap.Error(err))\n\t\t\tcommon.SendErrorResponse(writer, err.Error())\n\t\t\troute.Metrics.EventProcessingFailed(route.EventSourceName, route.EventName)\n\t\t\treturn\n\t\t}\n\t\troute.DataCh <- eventBytes\n\t}\n\n\tlogger.Info(\"request has been successfully processed\")\n}", "is_vulnerable": 1}
{"code": "func (pk *PublicKey) EncapsulateTo(ct []byte, ss []byte, seed []byte) {\n\tif seed == nil {\n\t\tseed = make([]byte, EncapsulationSeedSize)\n\t\t_, _ = cryptoRand.Read(seed[:])\n\t}\n\tif len(seed) != EncapsulationSeedSize {\n\t\tpanic(\"seed must be of length EncapsulationSeedSize\")\n\t}\n\tif len(ct) != CiphertextSize {\n\t\tpanic(\"ct must be of length CiphertextSize\")\n\t}\n\tif len(ss) != SharedKeySize {\n\t\tpanic(\"ss must be of length SharedKeySize\")\n\t}\n\n\tvar G2out [2 * SharedKeySize]byte\n\n\tvar SpEpEpp [(paramN * paramNbar) + (paramN * paramNbar) + (paramNbar * paramNbar)]uint16\n\tvar byteSpEpEpp [2 * len(SpEpEpp)]byte\n\tSp := SpEpEpp[:paramN*paramNbar]\n\tEp := SpEpEpp[paramN*paramNbar : 2*paramN*paramNbar]\n\tEpp := SpEpEpp[2*paramN*paramNbar:]\n\n\tvar Bp nbarByNU16\n\n\tvar V nbarByNbarU16\n\tvar C nbarByNbarU16\n\n\tvar A nByNU16\n\n\tvar hpk [pkHashSize]byte\n\n\tvar mu [messageSize]byte\n\tcopy(mu[:], seed[:messageSize])\n\n\t// compute hpk = G_1(packed(pk))\n\tshake128 := sha3.NewShake128()\n\tvar ppk [PublicKeySize]byte\n\tpk.Pack(ppk[:])\n\t_, _ = shake128.Write(ppk[:])\n\t_, _ = shake128.Read(hpk[:])\n\n\t// compute (seedSE || k) = G_2(hpk || mu)\n\tshake128.Reset()\n\t_, _ = shake128.Write(hpk[:])\n\t_, _ = shake128.Write(mu[:])\n\t_, _ = shake128.Read(G2out[:])\n\n\t// Generate Sp, Ep, Epp, and A, and compute:\n\t// Bp = Sp*A + Ep\n\t// V = Sp*B + Epp\n\tshake128.Reset()\n\t_, _ = shake128.Write([]byte{0x96})\n\t_, _ = shake128.Write(G2out[:SharedKeySize])\n\t_, _ = shake128.Read(byteSpEpEpp[:])\n\tfor i := range SpEpEpp {\n\t\tSpEpEpp[i] = uint16(byteSpEpEpp[i*2]) | (uint16(byteSpEpEpp[(i*2)+1]) << 8)\n\t}\n\tsample(SpEpEpp[:])\n\n\texpandSeedIntoA(&A, &pk.seedA, &shake128)\n\tmulAddSAPlusE(&Bp, Sp, &A, Ep)\n\n\tmulAddSBPlusE(&V, Sp, &pk.matrixB, Epp)\n\n\t// Encode mu, and compute C = V + enc(mu) (mod q)\n\tencodeMessage(&C, &mu)\n\tadd(&C, &V, &C)\n\n\t// Prepare the ciphertext\n\tpack(ct[:matrixBpPackedSize], Bp[:])\n\tpack(ct[matrixBpPackedSize:], C[:])\n\n\t// Compute ss = F(ct||k)\n\tshake128.Reset()\n\t_, _ = shake128.Write(ct[:])\n\t_, _ = shake128.Write(G2out[SharedKeySize:])\n\t_, _ = shake128.Read(ss[:])\n}", "is_vulnerable": 1}
{"code": "func (q *Query) Sanitize(args ...interface{}) (string, error) {\n\targUse := make([]bool, len(args))\n\tbuf := &bytes.Buffer{}\n\n\tfor _, part := range q.Parts {\n\t\tvar str string\n\t\tswitch part := part.(type) {\n\t\tcase string:\n\t\t\tstr = part\n\t\tcase int:\n\t\t\targIdx := part - 1\n\t\t\tif argIdx >= len(args) {\n\t\t\t\treturn \"\", fmt.Errorf(\"insufficient arguments\")\n\t\t\t}\n\t\t\targ := args[argIdx]\n\t\t\tswitch arg := arg.(type) {\n\t\t\tcase nil:\n\t\t\t\tstr = \"null\"\n\t\t\tcase int64:\n\t\t\t\tstr = strconv.FormatInt(arg, 10)\n\t\t\tcase float64:\n\t\t\t\tstr = strconv.FormatFloat(arg, 'f', -1, 64)\n\t\t\tcase bool:\n\t\t\t\tstr = strconv.FormatBool(arg)\n\t\t\tcase []byte:\n\t\t\t\tstr = QuoteBytes(arg)\n\t\t\tcase string:\n\t\t\t\tstr = QuoteString(arg)\n\t\t\tcase time.Time:\n\t\t\t\tstr = arg.Truncate(time.Microsecond).Format(\"'2006-01-02 15:04:05.999999999Z07:00:00'\")\n\t\t\tdefault:\n\t\t\t\treturn \"\", fmt.Errorf(\"invalid arg type: %T\", arg)\n\t\t\t}\n\t\t\targUse[argIdx] = true\n\n\t\t\t// Prevent SQL injection via Line Comment Creation\n\t\t\t// https://github.com/jackc/pgx/security/advisories/GHSA-m7wr-2xf7-cm9p\n\t\t\tstr = \"(\" + str + \")\"\n\t\tdefault:\n\t\t\treturn \"\", fmt.Errorf(\"invalid Part type: %T\", part)\n\t\t}\n\t\tbuf.WriteString(str)\n\t}\n\n\tfor i, used := range argUse {\n\t\tif !used {\n\t\t\treturn \"\", fmt.Errorf(\"unused argument: %d\", i)\n\t\t}\n\t}\n\treturn buf.String(), nil\n}", "is_vulnerable": 0}
{"code": "\ttestApp := newTestApp(func(app *appsv1.Application) {\n\t\tapp.Name = \"test\"\n\t\tapp.Status.Resources = []appsv1.ResourceStatus{\n\t\t\t{\n\t\t\t\tGroup:     deployment.GroupVersionKind().Group,\n\t\t\t\tKind:      deployment.GroupVersionKind().Kind,\n\t\t\t\tVersion:   deployment.GroupVersionKind().Version,\n\t\t\t\tName:      deployment.Name,\n\t\t\t\tNamespace: deployment.Namespace,\n\t\t\t\tStatus:    \"Synced\",\n\t\t\t},\n\t\t}\n\t\tapp.Status.History = []appsv1.RevisionHistory{\n\t\t\t{\n\t\t\t\tID: 0,\n\t\t\t\tSource: appsv1.ApplicationSource{\n\t\t\t\t\tTargetRevision: \"something-old\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (c *Tun) Activate() error {\n\tvar err error\n\tc.Interface, err = water.New(water.Config{\n\t\tDeviceType: water.TUN,\n\t\tPlatformSpecificParams: water.PlatformSpecificParams{\n\t\t\tComponentID: \"tap0901\",\n\t\t\tNetwork:     c.Cidr.String(),\n\t\t},\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Activate failed: %v\", err)\n\t}\n\n\tc.Device = c.Interface.Name()\n\n\t// TODO use syscalls instead of exec.Command\n\terr = exec.Command(\n\t\t\"netsh\", \"interface\", \"ipv4\", \"set\", \"address\",\n\t\tfmt.Sprintf(\"name=%s\", c.Device),\n\t\t\"source=static\",\n\t\tfmt.Sprintf(\"addr=%s\", c.Cidr.IP),\n\t\tfmt.Sprintf(\"mask=%s\", net.IP(c.Cidr.Mask)),\n\t\t\"gateway=none\",\n\t).Run()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to run 'netsh' to set address: %s\", err)\n\t}\n\terr = exec.Command(\n\t\t\"netsh\", \"interface\", \"ipv4\", \"set\", \"interface\",\n\t\tc.Device,\n\t\tfmt.Sprintf(\"mtu=%d\", c.MTU),\n\t).Run()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to run 'netsh' to set MTU: %s\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func YAMLEqf(t TestingT, expected string, actual string, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.YAMLEqf(t, expected, actual, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func PostUserLogin(c *gin.Context) {\n\n\tif !limiter.Allow() {\n\t\tc.JSON(common_err.TOO_MANY_REQUEST,\n\t\t\tmodel.Result{\n\t\t\t\tSuccess: common_err.TOO_MANY_LOGIN_REQUESTS,\n\t\t\t\tMessage: common_err.GetMsg(common_err.TOO_MANY_LOGIN_REQUESTS),\n\t\t\t})\n\t\treturn\n\t}\n\n\tjson := make(map[string]string)\n\tc.ShouldBind(&json)\n\n\tusername := json[\"username\"]\n\n\tpassword := json[\"password\"]\n\t// check params is empty\n\tif len(username) == 0 || len(password) == 0 {\n\t\tc.JSON(common_err.CLIENT_ERROR,\n\t\t\tmodel.Result{\n\t\t\t\tSuccess: common_err.CLIENT_ERROR,\n\t\t\t\tMessage: common_err.GetMsg(common_err.INVALID_PARAMS),\n\t\t\t})\n\t\treturn\n\t}\n\tuser := service.MyService.User().GetUserAllInfoByName(username)\n\tif user.Id == 0 {\n\t\tc.JSON(common_err.CLIENT_ERROR,\n\t\t\tmodel.Result{Success: common_err.USER_NOT_EXIST, Message: common_err.GetMsg(common_err.USER_NOT_EXIST)})\n\t\treturn\n\t}\n\tif user.Password != encryption.GetMD5ByStr(password) {\n\t\tc.JSON(common_err.CLIENT_ERROR,\n\t\t\tmodel.Result{Success: common_err.USER_NOT_EXIST_OR_PWD_INVALID, Message: common_err.GetMsg(common_err.USER_NOT_EXIST_OR_PWD_INVALID)})\n\t\treturn\n\t}\n\n\t// clean limit\n\tlimiter = rate.NewLimiter(rate.Every(time.Minute), 5)\n\n\tprivateKey, _ := service.MyService.User().GetKeyPair()\n\n\ttoken := system_model.VerifyInformation{}\n\n\taccessToken, err := jwt.GetAccessToken(user.Username, privateKey, user.Id)\n\tif err != nil {\n\t\tc.JSON(http.StatusInternalServerError, model.Result{Success: common_err.SERVICE_ERROR, Message: err.Error()})\n\t}\n\ttoken.AccessToken = accessToken\n\n\trefreshToken, err := jwt.GetRefreshToken(user.Username, privateKey, user.Id)\n\tif err != nil {\n\t\tc.JSON(http.StatusInternalServerError, model.Result{Success: common_err.SERVICE_ERROR, Message: err.Error()})\n\t}\n\ttoken.RefreshToken = refreshToken\n\n\ttoken.ExpiresAt = time.Now().Add(3 * time.Hour * time.Duration(1)).Unix()\n\tdata := make(map[string]interface{}, 2)\n\tuser.Password = \"\"\n\tdata[\"token\"] = token\n\n\t// TODO:1 Database fields cannot be external\n\tdata[\"user\"] = user\n\n\tc.JSON(common_err.SUCCESS,\n\t\tmodel.Result{\n\t\t\tSuccess: common_err.SUCCESS,\n\t\t\tMessage: common_err.GetMsg(common_err.SUCCESS),\n\t\t\tData:    data,\n\t\t})\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) DeleteImplantProfile(ctx context.Context, in *clientpb.DeleteReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/DeleteImplantProfile\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestJobEndpointConnect_gatewayBindAddressesForBridge(t *testing.T) {\n\tt.Parallel()\n\n\tt.Run(\"nil\", func(t *testing.T) {\n\n\t\tresult := gatewayBindAddressesIngressForBridge(nil)\n\t\trequire.Empty(t, result)\n\t})\n\n\tt.Run(\"no listeners\", func(t *testing.T) {\n\t\tresult := gatewayBindAddressesIngressForBridge(&structs.ConsulIngressConfigEntry{Listeners: nil})\n\t\trequire.Empty(t, result)\n\t})\n\n\tt.Run(\"simple\", func(t *testing.T) {\n\t\tresult := gatewayBindAddressesIngressForBridge(&structs.ConsulIngressConfigEntry{\n\t\t\tListeners: []*structs.ConsulIngressListener{{\n\t\t\t\tPort:     3000,\n\t\t\t\tProtocol: \"tcp\",\n\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\tName: \"service1\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t})\n\t\trequire.Equal(t, map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\"service1\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    3000,\n\t\t\t},\n\t\t}, result)\n\t})\n\n\tt.Run(\"complex\", func(t *testing.T) {\n\t\tresult := gatewayBindAddressesIngressForBridge(&structs.ConsulIngressConfigEntry{\n\t\t\tListeners: []*structs.ConsulIngressListener{{\n\t\t\t\tPort:     3000,\n\t\t\t\tProtocol: \"tcp\",\n\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\tName: \"service1\",\n\t\t\t\t}, {\n\t\t\t\t\tName: \"service2\",\n\t\t\t\t}},\n\t\t\t}, {\n\t\t\t\tPort:     3001,\n\t\t\t\tProtocol: \"http\",\n\t\t\t\tServices: []*structs.ConsulIngressService{{\n\t\t\t\t\tName: \"service3\",\n\t\t\t\t}},\n\t\t\t}},\n\t\t})\n\t\trequire.Equal(t, map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\"service1\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    3000,\n\t\t\t},\n\t\t\t\"service2\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    3000,\n\t\t\t},\n\t\t\t\"service3\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    3001,\n\t\t\t},\n\t\t}, result)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (u *userSet) Get(value string) (resolutionTracer, bool) {\n\tu.m.Lock()\n\tdefer u.m.Unlock()\n\n\tvar found bool\n\tvar rt resolutionTracer\n\tif rt, found = u.u[value]; !found {\n\t\tif rt, found = u.u[Wildcard]; !found {\n\t\t\treturn nil, false\n\t\t}\n\t}\n\treturn rt, found\n}", "is_vulnerable": 0}
{"code": "func NewSeriesStatsAggregatorFactory(\n\treg prometheus.Registerer,\n\tdurationQuantiles []float64,\n\tsampleQuantiles []float64,\n\tseriesQuantiles []float64,\n) *seriesStatsAggregatorFactory {\n\treturn &seriesStatsAggregatorFactory{\n\t\tqueryDuration: promauto.With(reg).NewHistogramVec(prometheus.HistogramOpts{\n\t\t\tName:    \"thanos_store_api_query_duration_seconds\",\n\t\t\tHelp:    \"Duration of the Thanos Store API select phase for a query.\",\n\t\t\tBuckets: durationQuantiles,\n\t\t}, []string{\"series_le\", \"samples_le\", \"tenant\"}),\n\t\tseriesLeBuckets:  seriesQuantiles,\n\t\tsamplesLeBuckets: sampleQuantiles,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f *Formatter) AddValues(kvList []any) {\n\t// Three slice args forces a copy.\n\tn := len(f.values)\n\tf.values = append(f.values[:n:n], kvList...)\n\n\tvals := f.values\n\tif hook := f.opts.RenderValuesHook; hook != nil {\n\t\tvals = hook(f.sanitize(vals))\n\t}\n\n\t// Pre-render values, so we don't have to do it on each Info/Error call.\n\tbuf := bytes.NewBuffer(make([]byte, 0, 1024))\n\tf.flatten(buf, vals, false, true) // escape user-provided keys\n\tf.valuesStr = buf.String()\n}", "is_vulnerable": 0}
{"code": "func (svc Service) TeamScheduleQuery(ctx context.Context, teamID uint, q *fleet.ScheduledQuery) (*fleet.ScheduledQuery, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.Pack{TeamIDs: []uint{teamID}}, fleet.ActionWrite); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgp, err := svc.ds.EnsureTeamPack(ctx, teamID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tq.PackID = gp.ID\n\n\treturn svc.unauthorizedScheduleQuery(ctx, q)\n}", "is_vulnerable": 1}
{"code": "func readStatusUserNS(pid string) ([]string, error) {\n\tpath := fmt.Sprintf(\"/proc/%s/status\", pid)\n\targs := []string{\"nsenter\", \"-U\", \"-t\", pid, \"cat\", path}\n\n\tc := exec.Command(args[0], args[1:]...)\n\toutput, err := c.CombinedOutput()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error executing %q: %v\", strings.Join(args, \" \"), err)\n\t}\n\n\treturn strings.Split(string(output), \"\\n\"), nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockAccessRequester) GetRequestedAudience() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetRequestedAudience\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (p *Plugin) getSecurityLevelsForProject(client Client, projectKey string) ([]string, error) {\n\tcreateMeta, err := client.GetCreateMetaInfo(p.API, &jira.GetQueryOptions{\n\t\tExpand:      \"projects.issuetypes.fields\",\n\t\tProjectKeys: projectKey,\n\t})\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"error fetching user security levels\")\n\t}\n\n\tif len(createMeta.Projects) == 0 || len(createMeta.Projects[0].IssueTypes) == 0 {\n\t\treturn nil, errors.Wrapf(err, \"no project found for project key %s\", projectKey)\n\t}\n\n\tsecurityLevels1, err := createMeta.Projects[0].IssueTypes[0].Fields.MarshalMap(securityLevelField)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"error parsing user security levels\")\n\t}\n\n\tallowed, ok := securityLevels1[\"allowedValues\"].([]interface{})\n\tif !ok {\n\t\treturn nil, errors.New(\"error parsing user security levels: failed to type assertion on array\")\n\t}\n\n\tout := []string{}\n\tfor _, level := range allowed {\n\t\tvalue, ok := level.(tcontainer.MarshalMap)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"error parsing user security levels: failed to type assertion on map\")\n\t\t}\n\n\t\tid, ok := value[\"id\"].(string)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"error parsing user security levels: failed to type assertion on string\")\n\t\t}\n\n\t\tout = append(out, id)\n\t}\n\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "\tfor _, check := range []func(*processor, string) error{\n\t\t(*processor).checkProviderMetadata,\n\t\t(*processor).checkPGPKeys,\n\t\t(*processor).checkSecurity,\n\t\t(*processor).checkCSAFs,\n\t\t(*processor).checkMissing,\n\t\t(*processor).checkInvalid,\n\t\t(*processor).checkListing,\n\t\t(*processor).checkWellknownMetadataReporter,\n\t\t(*processor).checkDNSPathReporter,\n\t} {", "is_vulnerable": 0}
{"code": "func (fs *fileStat) Name() string       { return fs.name }", "is_vulnerable": 0}
{"code": "func HTTPBodyNotContainsf(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, str interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.HTTPBodyNotContainsf(t, handler, method, url, values, str, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (ts *Server) CreateKeyspace(ctx context.Context, keyspace string, value *topodatapb.Keyspace) error {\n\tif err := ValidateKeyspaceName(keyspace); err != nil {\n\t\treturn vterrors.Wrapf(err, \"CreateKeyspace: %s\", err)\n\t}\n\n\tdata, err := proto.Marshal(value)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tkeyspacePath := path.Join(KeyspacesPath, keyspace, KeyspaceFile)\n\tif _, err := ts.globalCell.Create(ctx, keyspacePath, data); err != nil {\n\t\treturn err\n\t}\n\n\tevent.Dispatch(&events.KeyspaceChange{\n\t\tKeyspaceName: keyspace,\n\t\tKeyspace:     value,\n\t\tStatus:       \"created\",\n\t})\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) RevToSelf(ctx context.Context, in *sliverpb.RevToSelfReq, opts ...grpc.CallOption) (*sliverpb.RevToSelf, error) {\n\tout := new(sliverpb.RevToSelf)\n\terr := c.cc.Invoke(ctx, SliverRPC_RevToSelf_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestPrometheusTimeoutHTTP(t *testing.T) {\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\ttime.Sleep(2 * time.Second)\n\t}))\n\tdefer ts.Close()\n\n\treq, err := http.NewRequest(\"GET\", \"?target=\"+ts.URL, nil)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\treq.Header.Set(\"X-Prometheus-Scrape-Timeout-Seconds\", \"1\")\n\n\trr := httptest.NewRecorder()\n\thandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tHandler(w, r, c, log.NewNopLogger(), &ResultHistory{}, 0.5, nil, nil, level.AllowNone())\n\t})\n\n\thandler.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tt.Errorf(\"probe request handler returned wrong status code: %v, want %v\", status, http.StatusOK)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerReallyEmptyFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\td := c.MkDir()\n\t// the snap dir is a 0700 directory with nothing in it\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(snapdir.New(d), info, discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n\n\terr = snap.ValidateComponentContainer(snapdir.New(d), \"empty-snap+comp.comp\", discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeResponder) AddFragment(arg0, arg1 string) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"AddFragment\", arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func (m *RepProtoTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: RepProtoTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: RepProtoTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableTimestamps = append(m.NullableTimestamps, &types.Timestamp{})\n\t\t\tif err := m.NullableTimestamps[len(m.NullableTimestamps)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDurations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDurations = append(m.NullableDurations, &types.Duration{})\n\t\t\tif err := m.NullableDurations[len(m.NullableDurations)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamps\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Timestamps = append(m.Timestamps, types.Timestamp{})\n\t\t\tif err := m.Timestamps[len(m.Timestamps)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Durations\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Durations = append(m.Durations, types.Duration{})\n\t\t\tif err := m.Durations[len(m.Durations)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableDouble = append(m.NullableDouble, &types.DoubleValue{})\n\t\t\tif err := m.NullableDouble[len(m.NullableDouble)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullDouble = append(m.NonnullDouble, types.DoubleValue{})\n\t\t\tif err := m.NonnullDouble[len(m.NonnullDouble)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableFloat = append(m.NullableFloat, &types.FloatValue{})\n\t\t\tif err := m.NullableFloat[len(m.NullableFloat)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullFloat = append(m.NonnullFloat, types.FloatValue{})\n\t\t\tif err := m.NonnullFloat[len(m.NonnullFloat)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt64 = append(m.NullableInt64, &types.Int64Value{})\n\t\t\tif err := m.NullableInt64[len(m.NullableInt64)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt64 = append(m.NonnullInt64, types.Int64Value{})\n\t\t\tif err := m.NonnullInt64[len(m.NonnullInt64)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt64 = append(m.NullableUInt64, &types.UInt64Value{})\n\t\t\tif err := m.NullableUInt64[len(m.NullableUInt64)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt64 = append(m.NonnullUInt64, types.UInt64Value{})\n\t\t\tif err := m.NonnullUInt64[len(m.NonnullUInt64)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableInt32 = append(m.NullableInt32, &types.Int32Value{})\n\t\t\tif err := m.NullableInt32[len(m.NullableInt32)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullInt32 = append(m.NonnullInt32, types.Int32Value{})\n\t\t\tif err := m.NonnullInt32[len(m.NonnullInt32)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableUInt32 = append(m.NullableUInt32, &types.UInt32Value{})\n\t\t\tif err := m.NullableUInt32[len(m.NullableUInt32)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullUInt32 = append(m.NonnullUInt32, types.UInt32Value{})\n\t\t\tif err := m.NonnullUInt32[len(m.NonnullUInt32)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBool = append(m.NullableBool, &types.BoolValue{})\n\t\t\tif err := m.NullableBool[len(m.NullableBool)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBool = append(m.NonnullBool, types.BoolValue{})\n\t\t\tif err := m.NonnullBool[len(m.NonnullBool)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableString = append(m.NullableString, &types.StringValue{})\n\t\t\tif err := m.NullableString[len(m.NullableString)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullString = append(m.NonnullString, types.StringValue{})\n\t\t\tif err := m.NonnullString[len(m.NonnullString)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NullableBytes = append(m.NullableBytes, &types.BytesValue{})\n\t\t\tif err := m.NullableBytes[len(m.NullableBytes)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NonnullBytes = append(m.NonnullBytes, types.BytesValue{})\n\t\t\tif err := m.NonnullBytes[len(m.NonnullBytes)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tfor _, u := range umounts {\n\t\t\t_ = utils.WithProcfd(c.config.Rootfs, u, func(procfd string) error {\n\t\t\t\tif e := unix.Unmount(procfd, unix.MNT_DETACH); e != nil {\n\t\t\t\t\tif e != unix.EINVAL {\n\t\t\t\t\t\t// Ignore EINVAL as it means 'target is not a mount point.'\n\t\t\t\t\t\t// It probably has already been unmounted.\n\t\t\t\t\t\tlogrus.Warnf(\"Error during cleanup unmounting of %s (%s): %v\", procfd, u, e)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn nil\n\t\t\t})\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func TestInvalidEvent(t *testing.T) {\n\thook := test.NewGlobal()\n\th := NewMockHandler(nil, []string{})\n\treq := httptest.NewRequest(http.MethodPost, \"/api/webhook\", nil)\n\treq.Header.Set(\"X-GitHub-Event\", \"push\")\n\tw := httptest.NewRecorder()\n\th.Handler(w, req)\n\tassert.Equal(t, w.Code, http.StatusBadRequest)\n\texpectedLogResult := \"Webhook processing failed: error parsing payload\"\n\tassert.Equal(t, expectedLogResult, hook.LastEntry().Message)\n\tassert.Equal(t, expectedLogResult+\"\\n\", w.Body.String())\n\thook.Reset()\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetRequestedScopes() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetRequestedScopes\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetRequestedScopes))\n}", "is_vulnerable": 0}
{"code": "func (g *GSSResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'p')\n\tdst = append(dst, g.Data...)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (c *managedIdentityClient) createAzureMLAuthRequest(ctx context.Context, id ManagedIDKind, scopes []string) (*policy.Request, error) {\n\trequest, err := azruntime.NewRequest(ctx, http.MethodGet, c.endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\trequest.Raw().Header.Set(\"secret\", os.Getenv(msiSecret))\n\tq := request.Raw().URL.Query()\n\tq.Add(\"api-version\", \"2017-09-01\")\n\tq.Add(\"resource\", strings.Join(scopes, \" \"))\n\tq.Add(\"clientid\", os.Getenv(defaultIdentityClientID))\n\tif id != nil {\n\t\tif id.idKind() == miResourceID {\n\t\t\tlog.Write(EventAuthentication, \"WARNING: Azure ML doesn't support specifying a managed identity by resource ID\")\n\t\t\tq.Set(\"clientid\", \"\")\n\t\t\tq.Set(miResID, id.String())\n\t\t} else {\n\t\t\tq.Set(\"clientid\", id.String())\n\t\t}\n\t}\n\trequest.Raw().URL.RawQuery = q.Encode()\n\treturn request, nil\n}", "is_vulnerable": 0}
{"code": "func (u *CronjobService) SearchWithPage(search dto.PageCronjob) (int64, interface{}, error) {", "is_vulnerable": 0}
{"code": "\t\treturn middleware.ResponderFunc(func(w http.ResponseWriter, p runtime.Producer) {\n\t\t\tcookie := NewSessionCookieForConsole(loginResponse.SessionID)\n\t\t\thttp.SetCookie(w, &cookie)\n\t\t\tuser_api.NewLoginCreated().WithPayload(loginResponse).WriteResponse(w, p)\n\t\t})", "is_vulnerable": 1}
{"code": "func TestConnectWithRedirects(t *testing.T) {\n\ttests := []struct {\n\t\tdesc              string\n\t\tredirects         []string\n\t\tmethod            string // initial request method, empty == GET\n\t\texpectError       bool\n\t\texpectedRedirects int\n\t\tnewPort           bool // special case different port test\n\t}{{\n\t\tdesc:              \"relative redirects allowed\",\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"redirects to the same host are allowed\",\n\t\tredirects:         []string{\"http://HOST/ok\"}, // HOST replaced with server address in test\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"POST redirects to GET\",\n\t\tmethod:            http.MethodPost,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"PUT redirects to GET\",\n\t\tmethod:            http.MethodPut,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"DELETE redirects to GET\",\n\t\tmethod:            http.MethodDelete,\n\t\tredirects:         []string{\"/ok\"},\n\t\texpectedRedirects: 1,\n\t}, {\n\t\tdesc:              \"9 redirects are allowed\",\n\t\tredirects:         []string{\"/1\", \"/2\", \"/3\", \"/4\", \"/5\", \"/6\", \"/7\", \"/8\", \"/9\"},\n\t\texpectedRedirects: 9,\n\t}, {\n\t\tdesc:        \"10 redirects are forbidden\",\n\t\tredirects:   []string{\"/1\", \"/2\", \"/3\", \"/4\", \"/5\", \"/6\", \"/7\", \"/8\", \"/9\", \"/10\"},\n\t\texpectError: true,\n\t}, {\n\t\tdesc:              \"redirect to different host are prevented\",\n\t\tredirects:         []string{\"http://example.com/foo\"},\n\t\texpectedRedirects: 0,\n\t}, {\n\t\tdesc:              \"multiple redirect to different host forbidden\",\n\t\tredirects:         []string{\"/1\", \"/2\", \"/3\", \"http://example.com/foo\"},\n\t\texpectedRedirects: 3,\n\t}, {\n\t\tdesc:              \"redirect to different port is allowed\",\n\t\tredirects:         []string{\"http://HOST/foo\"},\n\t\texpectedRedirects: 1,\n\t\tnewPort:           true,\n\t}}\n\n\tconst resultString = \"Test output\"\n\tfor _, test := range tests {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tredirectCount := 0\n\t\t\ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\t\t\t// Verify redirect request.\n\t\t\t\tif redirectCount > 0 {\n\t\t\t\t\texpectedURL, err := url.Parse(test.redirects[redirectCount-1])\n\t\t\t\t\trequire.NoError(t, err, \"test URL error\")\n\t\t\t\t\tassert.Equal(t, req.URL.Path, expectedURL.Path, \"unknown redirect path\")\n\t\t\t\t\tassert.Equal(t, http.MethodGet, req.Method, \"redirects must always be GET\")\n\t\t\t\t}\n\t\t\t\tif redirectCount < len(test.redirects) {\n\t\t\t\t\thttp.Redirect(w, req, test.redirects[redirectCount], http.StatusFound)\n\t\t\t\t\tredirectCount++\n\t\t\t\t} else if redirectCount == len(test.redirects) {\n\t\t\t\t\tw.Write([]byte(resultString))\n\t\t\t\t} else {\n\t\t\t\t\tt.Errorf(\"unexpected number of redirects %d to %s\", redirectCount, req.URL.String())\n\t\t\t\t}\n\t\t\t}))\n\t\t\tdefer s.Close()\n\n\t\t\tu, err := url.Parse(s.URL)\n\t\t\trequire.NoError(t, err, \"Error parsing server URL\")\n\t\t\thost := u.Host\n\n\t\t\t// Special case new-port test with a secondary server.\n\t\t\tif test.newPort {\n\t\t\t\ts2 := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\t\t\t\tw.Write([]byte(resultString))\n\t\t\t\t}))\n\t\t\t\tdefer s2.Close()\n\t\t\t\tu2, err := url.Parse(s2.URL)\n\t\t\t\trequire.NoError(t, err, \"Error parsing secondary server URL\")\n\n\t\t\t\t// Sanity check: secondary server uses same hostname, different port.\n\t\t\t\trequire.Equal(t, u.Hostname(), u2.Hostname(), \"sanity check: same hostname\")\n\t\t\t\trequire.NotEqual(t, u.Port(), u2.Port(), \"sanity check: different port\")\n\n\t\t\t\t// Redirect to the secondary server.\n\t\t\t\thost = u2.Host\n\n\t\t\t}\n\n\t\t\t// Update redirect URLs with actual host.\n\t\t\tfor i := range test.redirects {\n\t\t\t\ttest.redirects[i] = strings.Replace(test.redirects[i], \"HOST\", host, 1)\n\t\t\t}\n\n\t\t\tmethod := test.method\n\t\t\tif method == \"\" {\n\t\t\t\tmethod = http.MethodGet\n\t\t\t}\n\n\t\t\tnetdialer := &net.Dialer{\n\t\t\t\tTimeout:   wait.ForeverTestTimeout,\n\t\t\t\tKeepAlive: wait.ForeverTestTimeout,\n\t\t\t}\n\t\t\tdialer := DialerFunc(func(req *http.Request) (net.Conn, error) {\n\t\t\t\tconn, err := netdialer.Dial(\"tcp\", req.URL.Host)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn conn, err\n\t\t\t\t}\n\t\t\t\tif err = req.Write(conn); err != nil {\n\t\t\t\t\trequire.NoError(t, conn.Close())\n\t\t\t\t\treturn nil, fmt.Errorf(\"error sending request: %v\", err)\n\t\t\t\t}\n\t\t\t\treturn conn, err\n\t\t\t})\n\t\t\tconn, rawResponse, err := ConnectWithRedirects(method, u, http.Header{} /*body*/, nil, dialer, true)\n\t\t\tif test.expectError {\n\t\t\t\trequire.Error(t, err, \"expected request error\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trequire.NoError(t, err, \"unexpected request error\")\n\t\t\tassert.NoError(t, conn.Close(), \"error closing connection\")\n\n\t\t\tresp, err := http.ReadResponse(bufio.NewReader(bytes.NewReader(rawResponse)), nil)\n\t\t\trequire.NoError(t, err, \"unexpected request error\")\n\n\t\t\tresult, err := ioutil.ReadAll(resp.Body)\n\t\t\tassert.Nil(t, err)\n\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\tif test.expectedRedirects < len(test.redirects) {\n\t\t\t\t// Expect the last redirect to be returned.\n\t\t\t\tassert.Equal(t, http.StatusFound, resp.StatusCode, \"Final response is not a redirect\")\n\t\t\t\tassert.Equal(t, test.redirects[len(test.redirects)-1], resp.Header.Get(\"Location\"))\n\t\t\t\tassert.NotEqual(t, resultString, string(result), \"wrong content\")\n\t\t\t} else {\n\t\t\t\tassert.Equal(t, resultString, string(result), \"stream content does not match\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *Pack) isGlobalPack() bool {\n\treturn p.Type != nil && *p.Type == \"global\"\n}", "is_vulnerable": 0}
{"code": "func (fsys MkdirFsImpl) MkdirAll(path string, perm fs.FileMode) error {\n\treturn os.MkdirAll(fsys.dir+\"/\"+path, perm)\n}", "is_vulnerable": 1}
{"code": "func (fs *UnixFS) RemoveStat(name string) (FileInfo, error) {\n\tdirfd, name, closeFd, err := fs.safePath(name)\n\tdefer closeFd()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Lstat name, we use Lstat as Unlink doesn't care about symlinks.\n\ts, err := fs.Lstatat(dirfd, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif s.IsDir() {\n\t\terr = fs.unlinkat(dirfd, name, AT_REMOVEDIR) // Rmdir\n\t} else {\n\t\terr = fs.unlinkat(dirfd, name, 0)\n\t}\n\tif err != nil {\n\t\treturn s, convertErrorType(&PathError{Op: \"remove\", Path: name, Err: err})\n\t}\n\treturn s, nil\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) DefaultErrorHandler(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {\n\th.L.Warnln(\"A client requested the default error URL, environment variable OAUTH2_ERROR_URL is probably not set.\")\n\n\tfmt.Fprintf(w, `\n<html>\n<head>\n\t<title>An OAuth 2.0 Error Occurred</title>\n</head>\n<body>\n<h1>\n\tThe OAuth2 request resulted in an error.\n</h1>\n<ul>\n\t<li>Error: %s</li>\n\t<li>Description: %s</li>\n\t<li>Hint: %s</li>\n\t<li>Debug: %s</li>\n</ul>\n<p>\n\tYou are seeing this default error page because the administrator has not set a dedicated error URL (environment variable <code>OAUTH2_ERROR_URL</code> is not set). \n\tIf you are an administrator, please read <a href=\"https://www.ory.sh/docs\">the guide</a> to understand what you\n\tneed to do. If you are a user, please contact the administrator.\n</p>\n</body>\n</html>\n`, r.URL.Query().Get(\"error\"), r.URL.Query().Get(\"error_description\"), r.URL.Query().Get(\"error_hint\"), r.URL.Query().Get(\"error_debug\"))\n}", "is_vulnerable": 1}
{"code": "func inBodyIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase TextToken:\n\t\td := p.tok.Data\n\t\tswitch n := p.oe.top(); n.DataAtom {\n\t\tcase a.Pre, a.Listing:\n\t\t\tif n.FirstChild == nil {\n\t\t\t\t// Ignore a newline at the start of a <pre> block.\n\t\t\t\tif d != \"\" && d[0] == '\\r' {\n\t\t\t\t\td = d[1:]\n\t\t\t\t}\n\t\t\t\tif d != \"\" && d[0] == '\\n' {\n\t\t\t\t\td = d[1:]\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\td = strings.Replace(d, \"\\x00\", \"\", -1)\n\t\tif d == \"\" {\n\t\t\treturn true\n\t\t}\n\t\tp.reconstructActiveFormattingElements()\n\t\tp.addText(d)\n\t\tif p.framesetOK && strings.TrimLeft(d, whitespace) != \"\" {\n\t\t\t// There were non-whitespace characters inserted.\n\t\t\tp.framesetOK = false\n\t\t}\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\tif p.oe.contains(a.Template) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tcopyAttributes(p.oe[0], p.tok)\n\t\tcase a.Base, a.Basefont, a.Bgsound, a.Command, a.Link, a.Meta, a.Noframes, a.Script, a.Style, a.Template, a.Title:\n\t\t\treturn inHeadIM(p)\n\t\tcase a.Body:\n\t\t\tif p.oe.contains(a.Template) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tif len(p.oe) >= 2 {\n\t\t\t\tbody := p.oe[1]\n\t\t\t\tif body.Type == ElementNode && body.DataAtom == a.Body {\n\t\t\t\t\tp.framesetOK = false\n\t\t\t\t\tcopyAttributes(body, p.tok)\n\t\t\t\t}\n\t\t\t}\n\t\tcase a.Frameset:\n\t\t\tif !p.framesetOK || len(p.oe) < 2 || p.oe[1].DataAtom != a.Body {\n\t\t\t\t// Ignore the token.\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tbody := p.oe[1]\n\t\t\tif body.Parent != nil {\n\t\t\t\tbody.Parent.RemoveChild(body)\n\t\t\t}\n\t\t\tp.oe = p.oe[:1]\n\t\t\tp.addElement()\n\t\t\tp.im = inFramesetIM\n\t\t\treturn true\n\t\tcase a.Address, a.Article, a.Aside, a.Blockquote, a.Center, a.Details, a.Dir, a.Div, a.Dl, a.Fieldset, a.Figcaption, a.Figure, a.Footer, a.Header, a.Hgroup, a.Menu, a.Nav, a.Ol, a.P, a.Section, a.Summary, a.Ul:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\tcase a.H1, a.H2, a.H3, a.H4, a.H5, a.H6:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tswitch n := p.top(); n.DataAtom {\n\t\t\tcase a.H1, a.H2, a.H3, a.H4, a.H5, a.H6:\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Pre, a.Listing:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\t\t// The newline, if any, will be dealt with by the TextToken case.\n\t\t\tp.framesetOK = false\n\t\tcase a.Form:\n\t\t\tif p.oe.contains(a.Template) || p.form == nil {\n\t\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\t\tp.addElement()\n\t\t\t\tp.form = p.top()\n\t\t\t}\n\t\tcase a.Li:\n\t\t\tp.framesetOK = false\n\t\t\tfor i := len(p.oe) - 1; i >= 0; i-- {\n\t\t\t\tnode := p.oe[i]\n\t\t\t\tswitch node.DataAtom {\n\t\t\t\tcase a.Li:\n\t\t\t\t\tp.oe = p.oe[:i]\n\t\t\t\tcase a.Address, a.Div, a.P:\n\t\t\t\t\tcontinue\n\t\t\t\tdefault:\n\t\t\t\t\tif !isSpecialElement(node) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\tcase a.Dd, a.Dt:\n\t\t\tp.framesetOK = false\n\t\t\tfor i := len(p.oe) - 1; i >= 0; i-- {\n\t\t\t\tnode := p.oe[i]\n\t\t\t\tswitch node.DataAtom {\n\t\t\t\tcase a.Dd, a.Dt:\n\t\t\t\t\tp.oe = p.oe[:i]\n\t\t\t\tcase a.Address, a.Div, a.P:\n\t\t\t\t\tcontinue\n\t\t\t\tdefault:\n\t\t\t\t\tif !isSpecialElement(node) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\tcase a.Plaintext:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\tcase a.Button:\n\t\t\tp.popUntil(defaultScope, a.Button)\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\t\tp.framesetOK = false\n\t\tcase a.A:\n\t\t\tfor i := len(p.afe) - 1; i >= 0 && p.afe[i].Type != scopeMarkerNode; i-- {\n\t\t\t\tif n := p.afe[i]; n.Type == ElementNode && n.DataAtom == a.A {\n\t\t\t\t\tp.inBodyEndTagFormatting(a.A)\n\t\t\t\t\tp.oe.remove(n)\n\t\t\t\t\tp.afe.remove(n)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addFormattingElement()\n\t\tcase a.B, a.Big, a.Code, a.Em, a.Font, a.I, a.S, a.Small, a.Strike, a.Strong, a.Tt, a.U:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addFormattingElement()\n\t\tcase a.Nobr:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tif p.elementInScope(defaultScope, a.Nobr) {\n\t\t\t\tp.inBodyEndTagFormatting(a.Nobr)\n\t\t\t\tp.reconstructActiveFormattingElements()\n\t\t\t}\n\t\t\tp.addFormattingElement()\n\t\tcase a.Applet, a.Marquee, a.Object:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\t\tp.afe = append(p.afe, &scopeMarker)\n\t\t\tp.framesetOK = false\n\t\tcase a.Table:\n\t\t\tif !p.quirks {\n\t\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\t}\n\t\t\tp.addElement()\n\t\t\tp.framesetOK = false\n\t\t\tp.im = inTableIM\n\t\t\treturn true\n\t\tcase a.Area, a.Br, a.Embed, a.Img, a.Input, a.Keygen, a.Wbr:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\t\tp.oe.pop()\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\tif p.tok.DataAtom == a.Input {\n\t\t\t\tfor _, t := range p.tok.Attr {\n\t\t\t\t\tif t.Key == \"type\" {\n\t\t\t\t\t\tif strings.ToLower(t.Val) == \"hidden\" {\n\t\t\t\t\t\t\t// Skip setting framesetOK = false\n\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.framesetOK = false\n\t\tcase a.Param, a.Source, a.Track:\n\t\t\tp.addElement()\n\t\t\tp.oe.pop()\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\tcase a.Hr:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.addElement()\n\t\t\tp.oe.pop()\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\tp.framesetOK = false\n\t\tcase a.Image:\n\t\t\tp.tok.DataAtom = a.Img\n\t\t\tp.tok.Data = a.Img.String()\n\t\t\treturn false\n\t\tcase a.Isindex:\n\t\t\tif p.form != nil {\n\t\t\t\t// Ignore the token.\n\t\t\t\treturn true\n\t\t\t}\n\t\t\taction := \"\"\n\t\t\tprompt := \"This is a searchable index. Enter search keywords: \"\n\t\t\tattr := []Attribute{{Key: \"name\", Val: \"isindex\"}}\n\t\t\tfor _, t := range p.tok.Attr {\n\t\t\t\tswitch t.Key {\n\t\t\t\tcase \"action\":\n\t\t\t\t\taction = t.Val\n\t\t\t\tcase \"name\":\n\t\t\t\t\t// Ignore the attribute.\n\t\t\t\tcase \"prompt\":\n\t\t\t\t\tprompt = t.Val\n\t\t\t\tdefault:\n\t\t\t\t\tattr = append(attr, t)\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.parseImpliedToken(StartTagToken, a.Form, a.Form.String())\n\t\t\tif action != \"\" {\n\t\t\t\tp.form.Attr = []Attribute{{Key: \"action\", Val: action}}\n\t\t\t}\n\t\t\tp.parseImpliedToken(StartTagToken, a.Hr, a.Hr.String())\n\t\t\tp.parseImpliedToken(StartTagToken, a.Label, a.Label.String())\n\t\t\tp.addText(prompt)\n\t\t\tp.addChild(&Node{\n\t\t\t\tType:     ElementNode,\n\t\t\t\tDataAtom: a.Input,\n\t\t\t\tData:     a.Input.String(),\n\t\t\t\tAttr:     attr,\n\t\t\t})\n\t\t\tp.oe.pop()\n\t\t\tp.parseImpliedToken(EndTagToken, a.Label, a.Label.String())\n\t\t\tp.parseImpliedToken(StartTagToken, a.Hr, a.Hr.String())\n\t\t\tp.parseImpliedToken(EndTagToken, a.Form, a.Form.String())\n\t\tcase a.Textarea:\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.framesetOK = false\n\t\t\tp.im = textIM\n\t\tcase a.Xmp:\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.framesetOK = false\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.im = textIM\n\t\tcase a.Iframe:\n\t\t\tp.framesetOK = false\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.im = textIM\n\t\tcase a.Noembed, a.Noscript:\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.im = textIM\n\t\tcase a.Select:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\t\tp.framesetOK = false\n\t\t\tp.im = inSelectIM\n\t\t\treturn true\n\t\tcase a.Optgroup, a.Option:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\tcase a.Rp, a.Rt:\n\t\t\tif p.elementInScope(defaultScope, a.Ruby) {\n\t\t\t\tp.generateImpliedEndTags()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Math, a.Svg:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tif p.tok.DataAtom == a.Math {\n\t\t\t\tadjustAttributeNames(p.tok.Attr, mathMLAttributeAdjustments)\n\t\t\t} else {\n\t\t\t\tadjustAttributeNames(p.tok.Attr, svgAttributeAdjustments)\n\t\t\t}\n\t\t\tadjustForeignAttributes(p.tok.Attr)\n\t\t\tp.addElement()\n\t\t\tp.top().Namespace = p.tok.Data\n\t\t\tif p.hasSelfClosingToken {\n\t\t\t\tp.oe.pop()\n\t\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\t}\n\t\t\treturn true\n\t\tcase a.Frame:\n\t\t\t// TODO: remove this divergence from the HTML5 spec.\n\t\t\tif p.oe.contains(a.Template) {\n\t\t\t\tp.addElement()\n\t\t\t\treturn true\n\t\t\t}\n\t\tcase a.Caption, a.Col, a.Colgroup, a.Head, a.Tbody, a.Td, a.Tfoot, a.Th, a.Thead, a.Tr:\n\t\t\t// Ignore the token.\n\t\tdefault:\n\t\t\tp.reconstructActiveFormattingElements()\n\t\t\tp.addElement()\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Body:\n\t\t\tif p.elementInScope(defaultScope, a.Body) {\n\t\t\t\tp.im = afterBodyIM\n\t\t\t}\n\t\tcase a.Html:\n\t\t\tif p.elementInScope(defaultScope, a.Body) {\n\t\t\t\tp.parseImpliedToken(EndTagToken, a.Body, a.Body.String())\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn true\n\t\tcase a.Address, a.Article, a.Aside, a.Blockquote, a.Button, a.Center, a.Details, a.Dir, a.Div, a.Dl, a.Fieldset, a.Figcaption, a.Figure, a.Footer, a.Header, a.Hgroup, a.Listing, a.Menu, a.Nav, a.Ol, a.Pre, a.Section, a.Summary, a.Ul:\n\t\t\tp.popUntil(defaultScope, p.tok.DataAtom)\n\t\tcase a.Form:\n\t\t\tif p.oe.contains(a.Template) {\n\t\t\t\tif !p.oe.contains(a.Form) {\n\t\t\t\t\t// Ignore the token.\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tp.generateImpliedEndTags()\n\t\t\t\tif p.tok.DataAtom == a.Form {\n\t\t\t\t\t// Ignore the token.\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tp.popUntil(defaultScope, a.Form)\n\t\t\t} else {\n\t\t\t\tnode := p.form\n\t\t\t\tp.form = nil\n\t\t\t\ti := p.indexOfElementInScope(defaultScope, a.Form)\n\t\t\t\tif node == nil || i == -1 || p.oe[i] != node {\n\t\t\t\t\t// Ignore the token.\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tp.generateImpliedEndTags()\n\t\t\t\tp.oe.remove(node)\n\t\t\t}\n\t\tcase a.P:\n\t\t\tif !p.elementInScope(buttonScope, a.P) {\n\t\t\t\tp.parseImpliedToken(StartTagToken, a.P, a.P.String())\n\t\t\t}\n\t\t\tp.popUntil(buttonScope, a.P)\n\t\tcase a.Li:\n\t\t\tp.popUntil(listItemScope, a.Li)\n\t\tcase a.Dd, a.Dt:\n\t\t\tp.popUntil(defaultScope, p.tok.DataAtom)\n\t\tcase a.H1, a.H2, a.H3, a.H4, a.H5, a.H6:\n\t\t\tp.popUntil(defaultScope, a.H1, a.H2, a.H3, a.H4, a.H5, a.H6)\n\t\tcase a.A, a.B, a.Big, a.Code, a.Em, a.Font, a.I, a.Nobr, a.S, a.Small, a.Strike, a.Strong, a.Tt, a.U:\n\t\t\tp.inBodyEndTagFormatting(p.tok.DataAtom)\n\t\tcase a.Applet, a.Marquee, a.Object:\n\t\t\tif p.popUntil(defaultScope, p.tok.DataAtom) {\n\t\t\t\tp.clearActiveFormattingElements()\n\t\t\t}\n\t\tcase a.Br:\n\t\t\tp.tok.Type = StartTagToken\n\t\t\treturn false\n\t\tcase a.Template:\n\t\t\treturn inHeadIM(p)\n\t\tdefault:\n\t\t\tp.inBodyEndTagOther(p.tok.DataAtom)\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\tcase ErrorToken:\n\t\t// TODO: remove this divergence from the HTML5 spec.\n\t\tif len(p.templateStack) > 0 {\n\t\t\tp.im = inTemplateIM\n\t\t\treturn false\n\t\t} else {\n\t\t\tfor _, e := range p.oe {\n\t\t\t\t// TODO(namusyaka): rb and rtc elements should be added after updating atom.\n\t\t\t\tswitch e.DataAtom {\n\t\t\t\tcase a.Dd, a.Dt, a.Li, a.Optgroup, a.Option, a.P, a.Rp, a.Rt, a.Tbody, a.Td, a.Tfoot, a.Th,\n\t\t\t\t\ta.Thead, a.Tr, a.Body, a.Html:\n\t\t\t\tdefault:\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func testSBOMScanSingleRef(t *testing.T, sb integration.Sandbox) {\n\tintegration.CheckFeatureCompat(t, sb, integration.FeatureDirectPush, integration.FeatureSBOM)\n\trequiresLinux(t)\n\tc, err := New(sb.Context(), sb.Address())\n\trequire.NoError(t, err)\n\tdefer c.Close()\n\n\tregistry, err := sb.NewRegistry()\n\tif errors.Is(err, integration.ErrRequirements) {\n\t\tt.Skip(err.Error())\n\t}\n\trequire.NoError(t, err)\n\n\tp := platforms.DefaultSpec()\n\tpk := platforms.Format(p)\n\n\tscannerFrontend := func(ctx context.Context, c gateway.Client) (*gateway.Result, error) {\n\t\tres := gateway.NewResult()\n\n\t\tst := llb.Image(\"busybox\")\n\t\tdef, err := st.Marshal(sb.Context())\n\t\trequire.NoError(t, err)\n\n\t\tr, err := c.Solve(ctx, gateway.SolveRequest{\n\t\t\tDefinition: def.ToPB(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tref, err := r.SingleRef()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err = ref.ToState()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tres.AddRef(pk, ref)\n\n\t\texpPlatforms := &exptypes.Platforms{\n\t\t\tPlatforms: []exptypes.Platform{{ID: pk, Platform: p}},\n\t\t}\n\t\tdt, err := json.Marshal(expPlatforms)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tres.AddMeta(exptypes.ExporterPlatformsKey, dt)\n\n\t\tvar img ocispecs.Image\n\t\tcmd := `\ncat <<EOF > $BUILDKIT_SCAN_DESTINATION/spdx.json\n{\n  \"_type\": \"https://in-toto.io/Statement/v0.1\",\n  \"predicateType\": \"https://spdx.dev/Document\",\n  \"predicate\": {\"name\": \"fallback\"}\n}\nEOF\n`\n\t\timg.Config.Cmd = []string{\"/bin/sh\", \"-c\", cmd}\n\t\timg.Platform = p\n\t\tconfig, err := json.Marshal(img)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to marshal image config\")\n\t\t}\n\t\tres.AddMeta(fmt.Sprintf(\"%s/%s\", exptypes.ExporterImageConfigKey, pk), config)\n\n\t\treturn res, nil\n\t}\n\n\tscannerTarget := registry + \"/buildkit/testsbomscanner:latest\"\n\t_, err = c.Build(sb.Context(), SolveOpt{\n\t\tExports: []ExportEntry{\n\t\t\t{\n\t\t\t\tType: ExporterImage,\n\t\t\t\tAttrs: map[string]string{\n\t\t\t\t\t\"name\": scannerTarget,\n\t\t\t\t\t\"push\": \"true\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, \"\", scannerFrontend, nil)\n\trequire.NoError(t, err)\n\n\ttargetFrontend := func(ctx context.Context, c gateway.Client) (*gateway.Result, error) {\n\t\tres := gateway.NewResult()\n\n\t\t// build image\n\t\tst := llb.Scratch().File(\n\t\t\tllb.Mkfile(\"/greeting\", 0600, []byte(\"hello world!\")),\n\t\t)\n\t\tdef, err := st.Marshal(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tr, err := c.Solve(ctx, gateway.SolveRequest{\n\t\t\tDefinition: def.ToPB(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tref, err := r.SingleRef()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err = ref.ToState()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tres.SetRef(ref)\n\n\t\tvar img ocispecs.Image\n\t\timg.Config.Cmd = []string{\"/bin/sh\", \"-c\", \"cat /greeting\"}\n\t\timg.Platform = p\n\t\tconfig, err := json.Marshal(img)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"failed to marshal image config\")\n\t\t}\n\t\tres.AddMeta(exptypes.ExporterImageConfigKey, config)\n\n\t\texpPlatforms := &exptypes.Platforms{\n\t\t\tPlatforms: []exptypes.Platform{{ID: pk, Platform: p}},\n\t\t}\n\t\tdt, err := json.Marshal(expPlatforms)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tres.AddMeta(exptypes.ExporterPlatformsKey, dt)\n\n\t\treturn res, nil\n\t}\n\n\ttarget := registry + \"/buildkit/testsbomsingle:latest\"\n\t_, err = c.Build(sb.Context(), SolveOpt{\n\t\tFrontendAttrs: map[string]string{\n\t\t\t\"attest:sbom\": \"generator=\" + scannerTarget,\n\t\t},\n\t\tExports: []ExportEntry{\n\t\t\t{\n\t\t\t\tType: ExporterImage,\n\t\t\t\tAttrs: map[string]string{\n\t\t\t\t\t\"name\": target,\n\t\t\t\t\t\"push\": \"true\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, \"\", targetFrontend, nil)\n\trequire.NoError(t, err)\n\n\tdesc, provider, err := contentutil.ProviderFromRef(target)\n\trequire.NoError(t, err)\n\n\timgs, err := testutil.ReadImages(sb.Context(), provider, desc)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, len(imgs.Images))\n\n\timg := imgs.Find(pk)\n\trequire.NotNil(t, img)\n\trequire.Equal(t, []string{\"/bin/sh\", \"-c\", \"cat /greeting\"}, img.Img.Config.Cmd)\n\n\tatt := imgs.Find(\"unknown/unknown\")\n\trequire.NotNil(t, att)\n\tattest := intoto.Statement{}\n\trequire.NoError(t, json.Unmarshal(att.LayersRaw[0], &attest))\n\trequire.Equal(t, \"https://in-toto.io/Statement/v0.1\", attest.Type)\n\trequire.Equal(t, intoto.PredicateSPDX, attest.PredicateType)\n\trequire.Subset(t, attest.Predicate, map[string]interface{}{\"name\": \"fallback\"})\n}", "is_vulnerable": 0}
{"code": "func (m *MockAuthorizeRequester) DidHandleAllResponseTypes() bool {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"DidHandleAllResponseTypes\")\n\tret0, _ := ret[0].(bool)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tconf.App.Version = \"0.13.0\"\n}", "is_vulnerable": 0}
{"code": "func (p *Profile) writeConfWgQuick(data *WgConf) (pth string, err error) {\n\tallowedIps := []string{}\n\tif data.Routes != nil {\n\t\tfor _, route := range data.Routes {\n\t\t\tallowedIps = append(allowedIps, route.Network)\n\t\t}\n\t}\n\tif data.Routes6 != nil {\n\t\tfor _, route := range data.Routes6 {\n\t\t\tallowedIps = append(allowedIps, route.Network)\n\t\t}\n\t}\n\n\taddr := data.Address\n\tif data.Address6 != \"\" {\n\t\taddr += \",\" + data.Address6\n\t}\n\n\ttemplData := WgConfData{\n\t\tAddress:    addr,\n\t\tPrivateKey: p.PrivateKeyWg,\n\t\tPublicKey:  data.PublicKey,\n\t\tAllowedIps: strings.Join(allowedIps, \",\"),\n\t\tEndpoint:   fmt.Sprintf(\"%s:%d\", data.Hostname, data.Port),\n\t}\n\n\tif data.DnsServers != nil && len(data.DnsServers) > 0 {\n\t\ttemplData.HasDns = true\n\t\ttemplData.DnsServers = strings.Join(data.DnsServers, \",\")\n\t}\n\n\toutput := &bytes.Buffer{}\n\terr = WgConfTempl.Execute(output, templData)\n\tif err != nil {\n\t\terr = &errortypes.ParseError{\n\t\t\terrors.Wrap(err, \"profile: Failed to exec wg template\"),\n\t\t}\n\t\treturn\n\t}\n\n\trootDir := \"\"\n\tswitch runtime.GOOS {\n\tcase \"linux\":\n\t\trootDir = WgLinuxConfPath\n\n\t\terr = os.MkdirAll(WgLinuxConfPath, 0700)\n\t\tif err != nil {\n\t\t\terr = &errortypes.WriteError{\n\t\t\t\terrors.Wrap(\n\t\t\t\t\terr, \"profile: Failed to create wg conf directory\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\tcase \"darwin\":\n\t\trootDir = WgMacConfPath\n\n\t\terr = os.MkdirAll(WgMacConfPath, 0700)\n\t\tif err != nil {\n\t\t\terr = &errortypes.WriteError{\n\t\t\t\terrors.Wrap(\n\t\t\t\t\terr, \"profile: Failed to create wg conf directory\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\trootDir, err = utils.GetTempDir()\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tpth = filepath.Join(rootDir, p.Iface+\".conf\")\n\n\tos.Remove(pth)\n\terr = ioutil.WriteFile(\n\t\tpth,\n\t\t[]byte(output.String()),\n\t\tos.FileMode(0600),\n\t)\n\tif err != nil {\n\t\terr = &WriteError{\n\t\t\terrors.Wrap(err, \"profile: Failed to write wg conf\"),\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (s *store) Count(key string) (int64, error) {\n\tkey = path.Join(s.pathPrefix, key)\n\n\t// We need to make sure the key ended with \"/\" so that we only get children \"directories\".\n\t// e.g. if we have key \"/a\", \"/a/b\", \"/ab\", getting keys with prefix \"/a\" will return all three,\n\t// while with prefix \"/a/\" will return only \"/a/b\" which is the correct answer.\n\tif !strings.HasSuffix(key, \"/\") {\n\t\tkey += \"/\"\n\t}\n\n\tstartTime := time.Now()\n\tgetResp, err := s.client.KV.Get(context.Background(), key, clientv3.WithRange(clientv3.GetPrefixRangeEnd(key)), clientv3.WithCountOnly())\n\tmetrics.RecordEtcdRequestLatency(\"listWithCount\", key, startTime)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn getResp.Count, nil\n}", "is_vulnerable": 1}
{"code": "func TestBodyStorage(t *testing.T) {\n\tdb := NewMemoryDatabase()\n\n\t// Create a test body to move around the database and make sure it's really new\n\tbody := &types.Body{Uncles: []*types.Header{{Extra: []byte(\"test header\")}}}\n\n\thasher := sha3.NewLegacyKeccak256()\n\trlp.Encode(hasher, body)\n\thash := common.BytesToHash(hasher.Sum(nil))\n\n\tif entry := ReadBody(db, hash, 0); entry != nil {\n\t\tt.Fatalf(\"Non existent body returned: %v\", entry)\n\t}\n\t// Write and verify the body in the database\n\tWriteBody(db, hash, 0, body)\n\tif entry := ReadBody(db, hash, 0); entry == nil {\n\t\tt.Fatalf(\"Stored body not found\")\n\t} else if types.DeriveSha(types.Transactions(entry.Transactions), newHasher()) != types.DeriveSha(types.Transactions(body.Transactions), newHasher()) || types.CalcUncleHash(entry.Uncles) != types.CalcUncleHash(body.Uncles) {\n\t\tt.Fatalf(\"Retrieved body mismatch: have %v, want %v\", entry, body)\n\t}\n\tif entry := ReadBodyRLP(db, hash, 0); entry == nil {\n\t\tt.Fatalf(\"Stored body RLP not found\")\n\t} else {\n\t\thasher := sha3.NewLegacyKeccak256()\n\t\thasher.Write(entry)\n\n\t\tif calc := common.BytesToHash(hasher.Sum(nil)); calc != hash {\n\t\t\tt.Fatalf(\"Retrieved RLP body mismatch: have %v, want %v\", entry, body)\n\t\t}\n\t}\n\t// Delete the body and verify the execution\n\tDeleteBody(db, hash, 0)\n\tif entry := ReadBody(db, hash, 0); entry != nil {\n\t\tt.Fatalf(\"Deleted body returned: %v\", entry)\n\t}\n}", "is_vulnerable": 0}
{"code": "func main() {\n\thostPtr := flag.String(\"host\", \"localhost:9159\", \"the hostname that the server should listen on.\")\n\ttokenPtr := flag.String(\"token\", \"\", \"the Proxy Access Token used to restrict access to the server.\")\n\tallowedOriginsPtr := flag.String(\"allowed-origins\", \"*\", \"a comma separated list of allowed origins.\")\n\tbannedOutputsPtr := flag.String(\"banned-outputs\", \"\", \"a comma separated list of banned outputs.\")\n\tbannedDestsPtr := flag.String(\"banned-dests\", \"\", \"a comma separated list of banned proxy destinations.\")\n\n\tflag.Parse()\n\n\tfinished := make(chan bool)\n\tlibproxy.Initialize(*tokenPtr, *hostPtr, *allowedOriginsPtr, *bannedOutputsPtr, *bannedDestsPtr, onProxyStateChangeServer, false, finished)\n\n\t<-finished\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetSession() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetSession\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetSession))\n}", "is_vulnerable": 0}
{"code": "func TestContextClientIP(t *testing.T) {\n\tc, _ := CreateTestContext(httptest.NewRecorder())\n\tc.Request, _ = http.NewRequest(\"POST\", \"/\", nil)\n\tresetTrustedCIDRs(c)\n\tresetContextForClientIPTests(c)\n\n\t// Legacy tests (validating that the defaults don't break the\n\t// (insecure!) old behaviour)\n\tassert.Equal(t, \"20.20.20.20\", c.ClientIP())\n\n\tc.Request.Header.Del(\"X-Forwarded-For\")\n\tassert.Equal(t, \"10.10.10.10\", c.ClientIP())\n\n\tc.Request.Header.Set(\"X-Forwarded-For\", \"30.30.30.30  \")\n\tassert.Equal(t, \"30.30.30.30\", c.ClientIP())\n\n\tc.Request.Header.Del(\"X-Forwarded-For\")\n\tc.Request.Header.Del(\"X-Real-IP\")\n\tc.engine.AppEngine = true\n\tassert.Equal(t, \"50.50.50.50\", c.ClientIP())\n\n\tc.Request.Header.Del(\"X-Appengine-Remote-Addr\")\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// no port\n\tc.Request.RemoteAddr = \"50.50.50.50\"\n\tassert.Empty(t, c.ClientIP())\n\n\t// Tests exercising the TrustedProxies functionality\n\tresetContextForClientIPTests(c)\n\n\t// No trusted proxies\n\tc.engine.TrustedProxies = []string{}\n\tresetTrustedCIDRs(c)\n\tc.engine.RemoteIPHeaders = []string{\"X-Forwarded-For\"}\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// Last proxy is trusted, but the RemoteAddr is not\n\tc.engine.TrustedProxies = []string{\"30.30.30.30\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// Only trust RemoteAddr\n\tc.engine.TrustedProxies = []string{\"40.40.40.40\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"20.20.20.20\", c.ClientIP())\n\n\t// All steps are trusted\n\tc.engine.TrustedProxies = []string{\"40.40.40.40\", \"30.30.30.30\", \"20.20.20.20\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"20.20.20.20\", c.ClientIP())\n\n\t// Use CIDR\n\tc.engine.TrustedProxies = []string{\"40.40.25.25/16\", \"30.30.30.30\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"20.20.20.20\", c.ClientIP())\n\n\t// Use hostname that resolves to all the proxies\n\tc.engine.TrustedProxies = []string{\"foo\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// Use hostname that returns an error\n\tc.engine.TrustedProxies = []string{\"bar\"}\n\tresetTrustedCIDRs(c)\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// X-Forwarded-For has a non-IP element\n\tc.engine.TrustedProxies = []string{\"40.40.40.40\"}\n\tresetTrustedCIDRs(c)\n\tc.Request.Header.Set(\"X-Forwarded-For\", \" blah \")\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// Result from LookupHost has non-IP element. This should never\n\t// happen, but we should test it to make sure we handle it\n\t// gracefully.\n\tc.engine.TrustedProxies = []string{\"baz\"}\n\tresetTrustedCIDRs(c)\n\tc.Request.Header.Set(\"X-Forwarded-For\", \" 30.30.30.30 \")\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\tc.engine.TrustedProxies = []string{\"40.40.40.40\"}\n\tresetTrustedCIDRs(c)\n\tc.Request.Header.Del(\"X-Forwarded-For\")\n\tc.engine.RemoteIPHeaders = []string{\"X-Forwarded-For\", \"X-Real-IP\"}\n\tassert.Equal(t, \"10.10.10.10\", c.ClientIP())\n\n\tc.engine.RemoteIPHeaders = []string{}\n\tc.engine.AppEngine = true\n\tassert.Equal(t, \"50.50.50.50\", c.ClientIP())\n\n\tc.Request.Header.Del(\"X-Appengine-Remote-Addr\")\n\tassert.Equal(t, \"40.40.40.40\", c.ClientIP())\n\n\t// no port\n\tc.Request.RemoteAddr = \"50.50.50.50\"\n\tassert.Empty(t, c.ClientIP())\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tsyncOptionsFactory := func() *application.SyncOptions {\n\t\t\t\t\tsyncOptions := application.SyncOptions{}\n\t\t\t\t\titems := make([]string, 0)\n\t\t\t\t\tif replace {\n\t\t\t\t\t\titems = append(items, common.SyncOptionReplace)\n\t\t\t\t\t}\n\t\t\t\t\tif serverSideApply {\n\t\t\t\t\t\titems = append(items, common.SyncOptionServerSideApply)\n\t\t\t\t\t}\n\t\t\t\t\tif applyOutOfSyncOnly {\n\t\t\t\t\t\titems = append(items, common.SyncOptionApplyOutOfSyncOnly)\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(items) == 0 {\n\t\t\t\t\t\t// for prevent send even empty array if not need\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\t\t\t\t\tsyncOptions.Items = items\n\t\t\t\t\treturn &syncOptions\n\t\t\t\t}\n\n\t\t\t\tsyncReq := application.ApplicationSyncRequest{\n\t\t\t\t\tName:         &appName,\n\t\t\t\t\tAppNamespace: &appNs,\n\t\t\t\t\tDryRun:       &dryRun,\n\t\t\t\t\tRevision:     &revision,\n\t\t\t\t\tResources:    filteredResources,\n\t\t\t\t\tPrune:        &prune,\n\t\t\t\t\tManifests:    localObjsStrings,\n\t\t\t\t\tInfos:        getInfos(infos),\n\t\t\t\t\tSyncOptions:  syncOptionsFactory(),\n\t\t\t\t}\n\n\t\t\t\tswitch strategy {\n\t\t\t\tcase \"apply\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Apply: &argoappv1.SyncStrategyApply{}}\n\t\t\t\t\tsyncReq.Strategy.Apply.Force = force\n\t\t\t\tcase \"\", \"hook\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Hook: &argoappv1.SyncStrategyHook{}}\n\t\t\t\t\tsyncReq.Strategy.Hook.Force = force\n\t\t\t\tdefault:\n\t\t\t\t\tlog.Fatalf(\"Unknown sync strategy: '%s'\", strategy)\n\t\t\t\t}\n\t\t\t\tif retryLimit > 0 {\n\t\t\t\t\tsyncReq.RetryStrategy = &argoappv1.RetryStrategy{\n\t\t\t\t\t\tLimit: retryLimit,\n\t\t\t\t\t\tBackoff: &argoappv1.Backoff{\n\t\t\t\t\t\t\tDuration:    retryBackoffDuration.String(),\n\t\t\t\t\t\t\tMaxDuration: retryBackoffMaxDuration.String(),\n\t\t\t\t\t\t\tFactor:      pointer.Int64(retryBackoffFactor),\n\t\t\t\t\t\t},\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif diffChanges {\n\t\t\t\t\tresources, err := appIf.ManagedResources(ctx, &application.ResourcesQuery{\n\t\t\t\t\t\tApplicationName: &appName,\n\t\t\t\t\t\tAppNamespace:    &appNs,\n\t\t\t\t\t})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tconn, settingsIf := acdClient.NewSettingsClientOrDie()\n\t\t\t\t\tdefer argoio.Close(conn)\n\t\t\t\t\targoSettings, err := settingsIf.Get(ctx, &settings.SettingsQuery{})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tfoundDiffs := false\n\t\t\t\t\tfmt.Printf(\"====== Previewing differences between live and desired state of application %s ======\\n\", appQualifiedName)\n\n\t\t\t\t\tproj := getProject(c, clientOpts, ctx, app.Spec.Project)\n\t\t\t\t\tfoundDiffs = findandPrintDiff(ctx, app, proj.Project, resources, argoSettings, diffOption)\n\t\t\t\t\tif foundDiffs {\n\t\t\t\t\t\tif !diffChangesConfirm {\n\t\t\t\t\t\t\tyesno := cli.AskToProceed(fmt.Sprintf(\"Please review changes to application %s shown above. Do you want to continue the sync process? (y/n): \", appQualifiedName))\n\t\t\t\t\t\t\tif !yesno {\n\t\t\t\t\t\t\t\tos.Exit(0)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfmt.Printf(\"====== No Differences found ======\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_, err = appIf.Sync(ctx, &syncReq)\n\t\t\t\terrors.CheckError(err)\n\n\t\t\t\tif !async {\n\t\t\t\t\tapp, opState, err := waitOnApplicationStatus(ctx, acdClient, appQualifiedName, timeout, watchOpts{operation: true}, selectedResources, output)\n\t\t\t\t\terrors.CheckError(err)\n\n\t\t\t\t\tif !dryRun {\n\t\t\t\t\t\tif !opState.Phase.Successful() {\n\t\t\t\t\t\t\tlog.Fatalf(\"Operation has completed with phase: %s\", opState.Phase)\n\t\t\t\t\t\t} else if len(selectedResources) == 0 && app.Status.Sync.Status != argoappv1.SyncStatusCodeSynced {\n\t\t\t\t\t\t\t// Only get resources to be pruned if sync was application-wide and final status is not synced\n\t\t\t\t\t\t\tpruningRequired := opState.SyncResult.Resources.PruningRequired()\n\t\t\t\t\t\t\tif pruningRequired > 0 {\n\t\t\t\t\t\t\t\tlog.Fatalf(\"%d resources require pruning\", pruningRequired)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t},", "is_vulnerable": 1}
{"code": "func Panics(t TestingT, f assert.PanicTestFunc, msgAndArgs ...interface{}) {\n\tif assert.Panics(t, f, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (src *AuthenticationSASLContinue) Encode(dst []byte) []byte {\n\tdst = append(dst, 'R')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\tdst = pgio.AppendUint32(dst, AuthTypeSASLContinue)\n\n\tdst = append(dst, src.Data...)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (a *App) SendNotifications(c request.CTX, post *model.Post, team *model.Team, channel *model.Channel, sender *model.User, parentPostList *model.PostList, setOnline bool) ([]string, error) {\n\t// Do not send notifications in archived channels\n\tif channel.DeleteAt > 0 {\n\t\treturn []string{}, nil\n\t}\n\n\tisCRTAllowed := *a.Config().ServiceSettings.CollapsedThreads != model.CollapsedThreadsDisabled\n\n\tpchan := make(chan store.StoreResult, 1)\n\tgo func() {\n\t\tprops, err := a.Srv().Store().User().GetAllProfilesInChannel(context.Background(), channel.Id, true)\n\t\tpchan <- store.StoreResult{Data: props, NErr: err}\n\t\tclose(pchan)\n\t}()\n\n\tcmnchan := make(chan store.StoreResult, 1)\n\tgo func() {\n\t\tprops, err := a.Srv().Store().Channel().GetAllChannelMembersNotifyPropsForChannel(channel.Id, true)\n\t\tcmnchan <- store.StoreResult{Data: props, NErr: err}\n\t\tclose(cmnchan)\n\t}()\n\n\tvar gchan chan store.StoreResult\n\tif a.allowGroupMentions(c, post) {\n\t\tgchan = make(chan store.StoreResult, 1)\n\t\tgo func() {\n\t\t\tgroupsMap, err := a.getGroupsAllowedForReferenceInChannel(channel, team)\n\t\t\tgchan <- store.StoreResult{Data: groupsMap, NErr: err}\n\t\t\tclose(gchan)\n\t\t}()\n\t}\n\n\tvar fchan chan store.StoreResult\n\tif len(post.FileIds) != 0 {\n\t\tfchan = make(chan store.StoreResult, 1)\n\t\tgo func() {\n\t\t\tfileInfos, err := a.Srv().Store().FileInfo().GetForPost(post.Id, true, false, true)\n\t\t\tfchan <- store.StoreResult{Data: fileInfos, NErr: err}\n\t\t\tclose(fchan)\n\t\t}()\n\t}\n\n\tvar tchan chan store.StoreResult\n\tif isCRTAllowed && post.RootId != \"\" {\n\t\ttchan = make(chan store.StoreResult, 1)\n\t\tgo func() {\n\t\t\tfollowers, err := a.Srv().Store().Thread().GetThreadFollowers(post.RootId, true)\n\t\t\ttchan <- store.StoreResult{Data: followers, NErr: err}\n\t\t\tclose(tchan)\n\t\t}()\n\t}\n\n\tresult := <-pchan\n\tif result.NErr != nil {\n\t\treturn nil, result.NErr\n\t}\n\tprofileMap := result.Data.(map[string]*model.User)\n\n\tresult = <-cmnchan\n\tif result.NErr != nil {\n\t\treturn nil, result.NErr\n\t}\n\tchannelMemberNotifyPropsMap := result.Data.(map[string]model.StringMap)\n\n\tfollowers := make(model.StringSet, 0)\n\tif tchan != nil {\n\t\tresult = <-tchan\n\t\tif result.NErr != nil {\n\t\t\treturn nil, result.NErr\n\t\t}\n\t\tfor _, v := range result.Data.([]string) {\n\t\t\tfollowers.Add(v)\n\t\t}\n\t}\n\n\tgroups := make(map[string]*model.Group)\n\tif gchan != nil {\n\t\tresult = <-gchan\n\t\tif result.NErr != nil {\n\t\t\treturn nil, result.NErr\n\t\t}\n\t\tgroups = result.Data.(map[string]*model.Group)\n\t}\n\n\tmentions, keywords := a.getExplicitMentionsAndKeywords(c, post, channel, profileMap, groups, channelMemberNotifyPropsMap, parentPostList)\n\n\tvar allActivityPushUserIds []string\n\tif channel.Type != model.ChannelTypeDirect {\n\t\t// Iterate through all groups that were mentioned and insert group members into the list of mentions or potential mentions\n\t\tfor _, group := range mentions.GroupMentions {\n\t\t\tanyUsersMentionedByGroup, err := a.insertGroupMentions(group, channel, profileMap, mentions)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tif !anyUsersMentionedByGroup {\n\t\t\t\ta.sendNoUsersNotifiedByGroupInChannel(c, sender, post, channel, group)\n\t\t\t}\n\t\t}\n\n\t\tgo func() {\n\t\t\t_, err := a.sendOutOfChannelMentions(c, sender, post, channel, mentions.OtherPotentialMentions)\n\t\t\tif err != nil {\n\t\t\t\tmlog.Error(\"Failed to send warning for out of channel mentions\", mlog.String(\"user_id\", sender.Id), mlog.String(\"post_id\", post.Id), mlog.Err(err))\n\t\t\t}\n\t\t}()\n\n\t\t// find which users in the channel are set up to always receive mobile notifications\n\t\t// excludes CRT users since those should be added in notificationsForCRT\n\t\tfor _, profile := range profileMap {\n\t\t\tif (profile.NotifyProps[model.PushNotifyProp] == model.UserNotifyAll ||\n\t\t\t\tchannelMemberNotifyPropsMap[profile.Id][model.PushNotifyProp] == model.ChannelNotifyAll) &&\n\t\t\t\t(post.UserId != profile.Id || post.GetProp(\"from_webhook\") == \"true\") &&\n\t\t\t\t!post.IsSystemMessage() &&\n\t\t\t\t!(a.IsCRTEnabledForUser(c, profile.Id) && post.RootId != \"\") {\n\t\t\t\tallActivityPushUserIds = append(allActivityPushUserIds, profile.Id)\n\t\t\t}\n\t\t}\n\t}\n\n\tmentionedUsersList := make(model.StringArray, 0, len(mentions.Mentions))\n\tmentionAutofollowChans := []chan *model.AppError{}\n\tthreadParticipants := map[string]bool{post.UserId: true}\n\tnewParticipants := map[string]bool{}\n\tparticipantMemberships := map[string]*model.ThreadMembership{}\n\tmembershipsMutex := &sync.Mutex{}\n\tfollowersMutex := &sync.Mutex{}\n\tif *a.Config().ServiceSettings.ThreadAutoFollow && post.RootId != \"\" {\n\t\tvar rootMentions *ExplicitMentions\n\t\tif parentPostList != nil {\n\t\t\trootPost := parentPostList.Posts[parentPostList.Order[0]]\n\t\t\tif rootPost.GetProp(\"from_webhook\") != \"true\" {\n\t\t\t\tthreadParticipants[rootPost.UserId] = true\n\t\t\t}\n\t\t\tif channel.Type != model.ChannelTypeDirect {\n\t\t\t\trootMentions = getExplicitMentions(rootPost, keywords, groups)\n\t\t\t\tfor id := range rootMentions.Mentions {\n\t\t\t\t\tthreadParticipants[id] = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor id := range mentions.Mentions {\n\t\t\tthreadParticipants[id] = true\n\t\t}\n\n\t\tif channel.Type != model.ChannelTypeDirect {\n\t\t\tfor id, propsMap := range channelMemberNotifyPropsMap {\n\t\t\t\tif ok := followers.Has(id); !ok && propsMap[model.ChannelAutoFollowThreads] == model.ChannelAutoFollowThreadsOn {\n\t\t\t\t\tthreadParticipants[id] = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// sema is a counting semaphore to throttle the number of concurrent DB requests.\n\t\t// A concurrency of 8 should be sufficient.\n\t\t// We don't want to set a higher limit which can bring down the DB.\n\t\tsema := make(chan struct{}, 8)\n\t\t// for each mention, make sure to update thread autofollow (if enabled) and update increment mention count\n\t\tfor id := range threadParticipants {\n\t\t\tmac := make(chan *model.AppError, 1)\n\t\t\t// Get token.\n\t\t\tsema <- struct{}{}\n\t\t\tgo func(userID string) {\n\t\t\t\tdefer func() {\n\t\t\t\t\tclose(mac)\n\t\t\t\t\t// Release token.\n\t\t\t\t\t<-sema\n\t\t\t\t}()\n\t\t\t\tmentionType, incrementMentions := mentions.Mentions[userID]\n\t\t\t\t// if the user was not explicitly mentioned, check if they explicitly unfollowed the thread\n\t\t\t\tif !incrementMentions {\n\t\t\t\t\tmembership, err := a.Srv().Store().Thread().GetMembershipForUser(userID, post.RootId)\n\t\t\t\t\tvar nfErr *store.ErrNotFound\n\n\t\t\t\t\tif err != nil && !errors.As(err, &nfErr) {\n\t\t\t\t\t\tmac <- model.NewAppError(\"SendNotifications\", \"app.channel.autofollow.app_error\", nil, \"\", http.StatusInternalServerError).Wrap(err)\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\n\t\t\t\t\tif membership != nil && !membership.Following {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tupdateFollowing := *a.Config().ServiceSettings.ThreadAutoFollow\n\t\t\t\tif mentionType == ThreadMention || mentionType == CommentMention {\n\t\t\t\t\tincrementMentions = false\n\t\t\t\t\tupdateFollowing = false\n\t\t\t\t}\n\t\t\t\topts := store.ThreadMembershipOpts{\n\t\t\t\t\tFollowing:             true,\n\t\t\t\t\tIncrementMentions:     incrementMentions,\n\t\t\t\t\tUpdateFollowing:       updateFollowing,\n\t\t\t\t\tUpdateViewedTimestamp: false,\n\t\t\t\t\tUpdateParticipants:    userID == post.UserId,\n\t\t\t\t}\n\t\t\t\tthreadMembership, err := a.Srv().Store().Thread().MaintainMembership(userID, post.RootId, opts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tmac <- model.NewAppError(\"SendNotifications\", \"app.channel.autofollow.app_error\", nil, \"\", http.StatusInternalServerError).Wrap(err)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tfollowersMutex.Lock()\n\t\t\t\t// add new followers to existing followers\n\t\t\t\tif ok := followers.Has(userID); !ok && threadMembership.Following {\n\t\t\t\t\tfollowers.Add(userID)\n\t\t\t\t\tnewParticipants[userID] = true\n\t\t\t\t}\n\t\t\t\tfollowersMutex.Unlock()\n\n\t\t\t\tmembershipsMutex.Lock()\n\t\t\t\tparticipantMemberships[userID] = threadMembership\n\t\t\t\tmembershipsMutex.Unlock()\n\n\t\t\t\tmac <- nil\n\t\t\t}(id)\n\t\t\tmentionAutofollowChans = append(mentionAutofollowChans, mac)\n\t\t}\n\t}\n\tfor id := range mentions.Mentions {\n\t\tmentionedUsersList = append(mentionedUsersList, id)\n\t}\n\n\tnErr := a.Srv().Store().Channel().IncrementMentionCount(post.ChannelId, mentionedUsersList, post.RootId == \"\", post.IsUrgent())\n\n\tif nErr != nil {\n\t\tmlog.Warn(\n\t\t\t\"Failed to update mention count\",\n\t\t\tmlog.String(\"post_id\", post.Id),\n\t\t\tmlog.String(\"channel_id\", post.ChannelId),\n\t\t\tmlog.Err(nErr),\n\t\t)\n\t}\n\n\t// Log the problems that might have occurred while auto following the thread\n\tfor _, mac := range mentionAutofollowChans {\n\t\tif err := <-mac; err != nil {\n\t\t\tmlog.Warn(\n\t\t\t\t\"Failed to update thread autofollow from mention\",\n\t\t\t\tmlog.String(\"post_id\", post.Id),\n\t\t\t\tmlog.String(\"channel_id\", post.ChannelId),\n\t\t\t\tmlog.Err(err),\n\t\t\t)\n\t\t}\n\t}\n\n\tnotificationsForCRT := &CRTNotifiers{}\n\tif isCRTAllowed && post.RootId != \"\" {\n\t\tfor uid := range followers {\n\t\t\tprofile := profileMap[uid]\n\t\t\tif profile == nil || !a.IsCRTEnabledForUser(c, uid) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif post.GetProp(\"from_webhook\") != \"true\" && uid == post.UserId {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// add user id to notificationsForCRT depending on threads notify props\n\t\t\tnotificationsForCRT.addFollowerToNotify(profile, mentions, channelMemberNotifyPropsMap[profile.Id], channel)\n\t\t}\n\t}\n\n\tnotification := &PostNotification{\n\t\tPost:       post.Clone(),\n\t\tChannel:    channel,\n\t\tProfileMap: profileMap,\n\t\tSender:     sender,\n\t}\n\n\tif *a.Config().EmailSettings.SendEmailNotifications {\n\t\temailRecipients := append(mentionedUsersList, notificationsForCRT.Email...)\n\t\temailRecipients = model.RemoveDuplicateStrings(emailRecipients)\n\n\t\tfor _, id := range emailRecipients {\n\t\t\tif profileMap[id] == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t//If email verification is required and user email is not verified don't send email.\n\t\t\tif *a.Config().EmailSettings.RequireEmailVerification && !profileMap[id].EmailVerified {\n\t\t\t\tmlog.Debug(\"Skipped sending notification email, address not verified.\", mlog.String(\"user_email\", profileMap[id].Email), mlog.String(\"user_id\", id))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif a.userAllowsEmail(c, profileMap[id], channelMemberNotifyPropsMap[id], post) {\n\t\t\t\tsenderProfileImage, _, err := a.GetProfileImage(sender)\n\t\t\t\tif err != nil {\n\t\t\t\t\ta.Log().Warn(\"Unable to get the sender user profile image.\", mlog.String(\"user_id\", sender.Id), mlog.Err(err))\n\t\t\t\t}\n\t\t\t\tif err := a.sendNotificationEmail(c, notification, profileMap[id], team, senderProfileImage); err != nil {\n\t\t\t\t\tmlog.Warn(\"Unable to send notification email.\", mlog.Err(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check for channel-wide mentions in channels that have too many members for those to work\n\tif int64(len(profileMap)) > *a.Config().TeamSettings.MaxNotificationsPerChannel {\n\t\tT := i18n.GetUserTranslations(sender.Locale)\n\n\t\tif mentions.HereMentioned {\n\t\t\ta.SendEphemeralPost(\n\t\t\t\tc,\n\t\t\t\tpost.UserId,\n\t\t\t\t&model.Post{\n\t\t\t\t\tChannelId: post.ChannelId,\n\t\t\t\t\tMessage:   T(\"api.post.disabled_here\", map[string]any{\"Users\": *a.Config().TeamSettings.MaxNotificationsPerChannel}),\n\t\t\t\t\tCreateAt:  post.CreateAt + 1,\n\t\t\t\t},\n\t\t\t)\n\t\t}\n\n\t\tif mentions.ChannelMentioned {\n\t\t\ta.SendEphemeralPost(\n\t\t\t\tc,\n\t\t\t\tpost.UserId,\n\t\t\t\t&model.Post{\n\t\t\t\t\tChannelId: post.ChannelId,\n\t\t\t\t\tMessage:   T(\"api.post.disabled_channel\", map[string]any{\"Users\": *a.Config().TeamSettings.MaxNotificationsPerChannel}),\n\t\t\t\t\tCreateAt:  post.CreateAt + 1,\n\t\t\t\t},\n\t\t\t)\n\t\t}\n\n\t\tif mentions.AllMentioned {\n\t\t\ta.SendEphemeralPost(\n\t\t\t\tc,\n\t\t\t\tpost.UserId,\n\t\t\t\t&model.Post{\n\t\t\t\t\tChannelId: post.ChannelId,\n\t\t\t\t\tMessage:   T(\"api.post.disabled_all\", map[string]any{\"Users\": *a.Config().TeamSettings.MaxNotificationsPerChannel}),\n\t\t\t\t\tCreateAt:  post.CreateAt + 1,\n\t\t\t\t},\n\t\t\t)\n\t\t}\n\t}\n\n\tif a.canSendPushNotifications() {\n\t\tfor _, id := range mentionedUsersList {\n\t\t\tif profileMap[id] == nil || notificationsForCRT.Push.Contains(id) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tvar status *model.Status\n\t\t\tvar err *model.AppError\n\t\t\tif status, err = a.GetStatus(id); err != nil {\n\t\t\t\tstatus = &model.Status{UserId: id, Status: model.StatusOffline, Manual: false, LastActivityAt: 0, ActiveChannel: \"\"}\n\t\t\t}\n\n\t\t\tif ShouldSendPushNotification(profileMap[id], channelMemberNotifyPropsMap[id], true, status, post) {\n\t\t\t\tmentionType := mentions.Mentions[id]\n\n\t\t\t\treplyToThreadType := \"\"\n\t\t\t\tif mentionType == ThreadMention {\n\t\t\t\t\treplyToThreadType = model.CommentsNotifyAny\n\t\t\t\t} else if mentionType == CommentMention {\n\t\t\t\t\treplyToThreadType = model.CommentsNotifyRoot\n\t\t\t\t}\n\n\t\t\t\ta.sendPushNotification(\n\t\t\t\t\tnotification,\n\t\t\t\t\tprofileMap[id],\n\t\t\t\t\tmentionType == KeywordMention || mentionType == ChannelMention || mentionType == DMMention,\n\t\t\t\t\tmentionType == ChannelMention,\n\t\t\t\t\treplyToThreadType,\n\t\t\t\t)\n\t\t\t} else {\n\t\t\t\t// register that a notification was not sent\n\t\t\t\ta.NotificationsLog().Debug(\"Notification not sent\",\n\t\t\t\t\tmlog.String(\"ackId\", \"\"),\n\t\t\t\t\tmlog.String(\"type\", model.PushTypeMessage),\n\t\t\t\t\tmlog.String(\"userId\", id),\n\t\t\t\t\tmlog.String(\"postId\", post.Id),\n\t\t\t\t\tmlog.String(\"status\", model.PushNotSent),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\n\t\tfor _, id := range allActivityPushUserIds {\n\t\t\tif profileMap[id] == nil || notificationsForCRT.Push.Contains(id) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif _, ok := mentions.Mentions[id]; !ok {\n\t\t\t\tvar status *model.Status\n\t\t\t\tvar err *model.AppError\n\t\t\t\tif status, err = a.GetStatus(id); err != nil {\n\t\t\t\t\tstatus = &model.Status{UserId: id, Status: model.StatusOffline, Manual: false, LastActivityAt: 0, ActiveChannel: \"\"}\n\t\t\t\t}\n\n\t\t\t\tif ShouldSendPushNotification(profileMap[id], channelMemberNotifyPropsMap[id], false, status, post) {\n\t\t\t\t\ta.sendPushNotification(\n\t\t\t\t\t\tnotification,\n\t\t\t\t\t\tprofileMap[id],\n\t\t\t\t\t\tfalse,\n\t\t\t\t\t\tfalse,\n\t\t\t\t\t\t\"\",\n\t\t\t\t\t)\n\t\t\t\t} else {\n\t\t\t\t\t// register that a notification was not sent\n\t\t\t\t\ta.NotificationsLog().Debug(\"Notification not sent\",\n\t\t\t\t\t\tmlog.String(\"ackId\", \"\"),\n\t\t\t\t\t\tmlog.String(\"type\", model.PushTypeMessage),\n\t\t\t\t\t\tmlog.String(\"userId\", id),\n\t\t\t\t\t\tmlog.String(\"postId\", post.Id),\n\t\t\t\t\t\tmlog.String(\"status\", model.PushNotSent),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor _, id := range notificationsForCRT.Push {\n\t\t\tif profileMap[id] == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tvar status *model.Status\n\t\t\tvar err *model.AppError\n\t\t\tif status, err = a.GetStatus(id); err != nil {\n\t\t\t\tstatus = &model.Status{UserId: id, Status: model.StatusOffline, Manual: false, LastActivityAt: 0, ActiveChannel: \"\"}\n\t\t\t}\n\n\t\t\tif DoesStatusAllowPushNotification(profileMap[id].NotifyProps, status, post.ChannelId) {\n\t\t\t\ta.sendPushNotification(\n\t\t\t\t\tnotification,\n\t\t\t\t\tprofileMap[id],\n\t\t\t\t\tfalse,\n\t\t\t\t\tfalse,\n\t\t\t\t\tmodel.CommentsNotifyCRT,\n\t\t\t\t)\n\t\t\t} else {\n\t\t\t\t// register that a notification was not sent\n\t\t\t\ta.NotificationsLog().Debug(\"Notification not sent\",\n\t\t\t\t\tmlog.String(\"ackId\", \"\"),\n\t\t\t\t\tmlog.String(\"type\", model.PushTypeMessage),\n\t\t\t\t\tmlog.String(\"userId\", id),\n\t\t\t\t\tmlog.String(\"postId\", post.Id),\n\t\t\t\t\tmlog.String(\"status\", model.PushNotSent),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t}\n\n\tmessage := model.NewWebSocketEvent(model.WebsocketEventPosted, \"\", post.ChannelId, \"\", nil, \"\")\n\n\t// Note that PreparePostForClient should've already been called by this point\n\tpostJSON, jsonErr := post.ToJSON()\n\tif jsonErr != nil {\n\t\treturn nil, errors.Wrapf(jsonErr, \"failed to encode post to JSON\")\n\t}\n\tmessage.Add(\"post\", postJSON)\n\n\tmessage.Add(\"channel_type\", channel.Type)\n\tmessage.Add(\"channel_display_name\", notification.GetChannelName(model.ShowUsername, \"\"))\n\tmessage.Add(\"channel_name\", channel.Name)\n\tmessage.Add(\"sender_name\", notification.GetSenderName(model.ShowUsername, *a.Config().ServiceSettings.EnablePostUsernameOverride))\n\tmessage.Add(\"team_id\", team.Id)\n\tmessage.Add(\"set_online\", setOnline)\n\n\tif len(post.FileIds) != 0 && fchan != nil {\n\t\tmessage.Add(\"otherFile\", \"true\")\n\n\t\tvar infos []*model.FileInfo\n\t\tif result := <-fchan; result.NErr != nil {\n\t\t\tmlog.Warn(\"Unable to get fileInfo for push notifications.\", mlog.String(\"post_id\", post.Id), mlog.Err(result.NErr))\n\t\t} else {\n\t\t\tinfos = result.Data.([]*model.FileInfo)\n\t\t}\n\n\t\tfor _, info := range infos {\n\t\t\tif info.IsImage() {\n\t\t\t\tmessage.Add(\"image\", \"true\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(mentionedUsersList) > 0 {\n\t\tuseAddMentionsHook(message, mentionedUsersList)\n\t}\n\n\tif len(notificationsForCRT.Desktop) > 0 {\n\t\tuseAddFollowersHook(message, notificationsForCRT.Desktop)\n\t}\n\n\tpublished, err := a.publishWebsocketEventForPermalinkPost(c, post, message)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !published {\n\t\ta.Publish(message)\n\t}\n\n\t// If this is a reply in a thread, notify participants\n\tif isCRTAllowed && post.RootId != \"\" {\n\t\tfor uid := range followers {\n\t\t\t// A user following a thread but had left the channel won't get a notification\n\t\t\t// https://mattermost.atlassian.net/browse/MM-36769\n\t\t\tif profileMap[uid] == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif a.IsCRTEnabledForUser(c, uid) {\n\t\t\t\tmessage := model.NewWebSocketEvent(model.WebsocketEventThreadUpdated, team.Id, \"\", uid, nil, \"\")\n\t\t\t\tthreadMembership := participantMemberships[uid]\n\t\t\t\tif threadMembership == nil {\n\t\t\t\t\ttm, err := a.Srv().Store().Thread().GetMembershipForUser(uid, post.RootId)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, errors.Wrapf(err, \"Missing thread membership for participant in notifications. user_id=%q thread_id=%q\", uid, post.RootId)\n\t\t\t\t\t}\n\t\t\t\t\tif tm == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tthreadMembership = tm\n\t\t\t\t}\n\t\t\t\tuserThread, err := a.Srv().Store().Thread().GetThreadForUser(threadMembership, true, a.IsPostPriorityEnabled())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, errors.Wrapf(err, \"cannot get thread %q for user %q\", post.RootId, uid)\n\t\t\t\t}\n\t\t\t\tif userThread != nil {\n\t\t\t\t\tpreviousUnreadMentions := int64(0)\n\t\t\t\t\tpreviousUnreadReplies := int64(0)\n\n\t\t\t\t\t// if it's not a newly followed thread, calculate previous unread values.\n\t\t\t\t\tif !newParticipants[uid] {\n\t\t\t\t\t\tpreviousUnreadMentions = userThread.UnreadMentions\n\t\t\t\t\t\tpreviousUnreadReplies = max(userThread.UnreadReplies-1, 0)\n\n\t\t\t\t\t\tif mentions.isUserMentioned(uid) {\n\t\t\t\t\t\t\tpreviousUnreadMentions = max(userThread.UnreadMentions-1, 0)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// set LastViewed to now for commenter\n\t\t\t\t\tif uid == post.UserId {\n\t\t\t\t\t\topts := store.ThreadMembershipOpts{\n\t\t\t\t\t\t\tUpdateViewedTimestamp: true,\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// should set unread mentions, and unread replies to 0\n\t\t\t\t\t\t_, err = a.Srv().Store().Thread().MaintainMembership(uid, post.RootId, opts)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn nil, errors.Wrapf(err, \"cannot maintain thread membership %q for user %q\", post.RootId, uid)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tuserThread.UnreadMentions = 0\n\t\t\t\t\t\tuserThread.UnreadReplies = 0\n\t\t\t\t\t}\n\t\t\t\t\ta.sanitizeProfiles(userThread.Participants, false)\n\t\t\t\t\tuserThread.Post.SanitizeProps()\n\n\t\t\t\t\tsanitizedPost, err := a.SanitizePostMetadataForUser(c, userThread.Post, uid)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tuserThread.Post = sanitizedPost\n\n\t\t\t\t\tpayload, jsonErr := json.Marshal(userThread)\n\t\t\t\t\tif jsonErr != nil {\n\t\t\t\t\t\tmlog.Warn(\"Failed to encode thread to JSON\")\n\t\t\t\t\t}\n\t\t\t\t\tmessage.Add(\"thread\", string(payload))\n\t\t\t\t\tmessage.Add(\"previous_unread_mentions\", previousUnreadMentions)\n\t\t\t\t\tmessage.Add(\"previous_unread_replies\", previousUnreadReplies)\n\n\t\t\t\t\ta.Publish(message)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn mentionedUsersList, nil\n}", "is_vulnerable": 0}
{"code": "func (mr *MockRequesterMockRecorder) Merge(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Merge\", reflect.TypeOf((*MockRequester)(nil).Merge), arg0)\n}", "is_vulnerable": 0}
{"code": "func TestFragmentBuffer_Overflow(t *testing.T) {\n\tfragmentBuffer := newFragmentBuffer()\n\n\t// Push a buffer that doesn't exceed size limits\n\tif _, err := fragmentBuffer.push([]byte{0x16, 0xfe, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0F, 0x03, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0xfe, 0xff, 0x00}); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// Allocate a buffer that exceeds cache size\n\tlargeBuffer := make([]byte, fragmentBufferMaxSize)\n\tif _, err := fragmentBuffer.push(largeBuffer); !errors.Is(err, errFragmentBufferOverflow) {\n\t\tt.Fatalf(\"Pushing a large buffer returned (%s) expected(%s)\", err, errFragmentBufferOverflow)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestLoadPayloads(t *testing.T) {\n\ttempdir, err := os.MkdirTemp(\"\", \"templates-*\")\n\trequire.NoError(t, err, \"could not create temp dir\")\n\tdefer os.RemoveAll(tempdir)\n\n\tgenerator := &PayloadGenerator{catalog: disk.NewCatalog(tempdir)}\n\n\tfullpath := filepath.Join(tempdir, \"payloads.txt\")\n\terr = os.WriteFile(fullpath, []byte(\"test\\nanother\"), 0777)\n\trequire.NoError(t, err, \"could not write payload\")\n\n\t// Test sandbox\n\tt.Run(\"templates-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/test\", tempdir, false)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})\n\tt.Run(\"templates-path-relative\", func(t *testing.T) {\n\t\t_, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": \"../../../../../../../../../etc/passwd\",\n\t\t}, \".\", tempdir, false)\n\t\trequire.Error(t, err, \"could load payloads\")\n\t})\n\tt.Run(\"template-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, filepath.Join(tempdir, \"test.yaml\"), \"/test\", false)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})\n\tt.Run(\"no-sandbox-unix\", func(t *testing.T) {\n\t\tif osutils.IsWindows() {\n\t\t\treturn\n\t\t}\n\t\t_, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": \"/etc/passwd\",\n\t\t}, \"/random\", \"/test\", true)\n\t\trequire.NoError(t, err, \"could load payloads\")\n\t})\n\tt.Run(\"invalid\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": \"/etc/passwd\",\n\t\t}, \"/random\", \"/test\", false)\n\t\trequire.Error(t, err, \"could load payloads\")\n\t\trequire.Equal(t, 0, len(values), \"could get values\")\n\n\t\tvalues, err = generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/random\", \"/test\", false)\n\t\trequire.Error(t, err, \"could load payloads\")\n\t\trequire.Equal(t, 0, len(values), \"could get values\")\n\t})\n}", "is_vulnerable": 0}
{"code": "func CsrfFromHeader(param string) func(c *fiber.Ctx) (string, error) {\n\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.Get(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", errMissingHeader\n\t\t}\n\t\treturn token, nil\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestService_ListSoftware(t *testing.T) {\n\tds := new(mock.Store)\n\n\tvar calledWithTeamID *uint\n\tvar calledWithOpt fleet.SoftwareListOptions\n\tds.ListSoftwareFunc = func(ctx context.Context, opt fleet.SoftwareListOptions) ([]fleet.Software, error) {\n\t\tcalledWithTeamID = opt.TeamID\n\t\tcalledWithOpt = opt\n\t\treturn []fleet.Software{}, nil\n\t}\n\n\tuser := &fleet.User{ID: 3, Email: \"foo@bar.com\", GlobalRole: ptr.String(fleet.RoleObserver)}\n\n\tsvc := newTestService(t, ds, nil, nil)\n\tctx := context.Background()\n\tctx = viewer.NewContext(ctx, viewer.Viewer{User: user})\n\n\t_, err := svc.ListSoftware(ctx, fleet.SoftwareListOptions{TeamID: ptr.Uint(42), ListOptions: fleet.ListOptions{PerPage: 77, Page: 4}})\n\trequire.NoError(t, err)\n\n\tassert.True(t, ds.ListSoftwareFuncInvoked)\n\tassert.Equal(t, ptr.Uint(42), calledWithTeamID)\n\t// sort order defaults to hosts_count descending, automatically, if not explicitly provided\n\tassert.Equal(t, fleet.ListOptions{PerPage: 77, Page: 4, OrderKey: \"hosts_count\", OrderDirection: fleet.OrderDescending}, calledWithOpt.ListOptions)\n\tassert.True(t, calledWithOpt.WithHostCounts)\n\n\t// call again, this time with an explicit sort\n\tds.ListSoftwareFuncInvoked = false\n\t_, err = svc.ListSoftware(ctx, fleet.SoftwareListOptions{TeamID: nil, ListOptions: fleet.ListOptions{PerPage: 11, Page: 2, OrderKey: \"id\", OrderDirection: fleet.OrderAscending}})\n\trequire.NoError(t, err)\n\n\tassert.True(t, ds.ListSoftwareFuncInvoked)\n\tassert.Nil(t, calledWithTeamID)\n\tassert.Equal(t, fleet.ListOptions{PerPage: 11, Page: 2, OrderKey: \"id\", OrderDirection: fleet.OrderAscending}, calledWithOpt.ListOptions)\n\tassert.True(t, calledWithOpt.WithHostCounts)\n}", "is_vulnerable": 1}
{"code": "func (f *ScmpFilter) addRuleWrapper(call ScmpSyscall, action ScmpAction, exact bool, length C.uint, cond C.scmp_cast_t) error {\n\tif length != 0 && cond == nil {\n\t\treturn fmt.Errorf(\"null conditions list, but length is nonzero\")\n\t}\n\n\tvar retCode C.int\n\tif exact {\n\t\tretCode = C.seccomp_rule_add_exact_array(f.filterCtx, action.toNative(), C.int(call), length, cond)\n\t} else {\n\t\tretCode = C.seccomp_rule_add_array(f.filterCtx, action.toNative(), C.int(call), length, cond)\n\t}\n\n\tif syscall.Errno(-1*retCode) == syscall.EFAULT {\n\t\treturn fmt.Errorf(\"unrecognized syscall\")\n\t} else if syscall.Errno(-1*retCode) == syscall.EPERM {\n\t\treturn fmt.Errorf(\"requested action matches default action of filter\")\n\t} else if syscall.Errno(-1*retCode) == syscall.EINVAL {\n\t\treturn fmt.Errorf(\"two checks on same syscall argument\")\n\t} else if retCode != 0 {\n\t\treturn syscall.Errno(-1 * retCode)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *kubeGenericRuntimeManager) generateLinuxContainerConfig(container *v1.Container, pod *v1.Pod, uid *int64, username string, nsTarget *kubecontainer.ContainerID, enforceMemoryQoS bool) (*runtimeapi.LinuxContainerConfig, error) {\n\tsc, err := m.determineEffectiveSecurityContext(pod, container, uid, username)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlc := &runtimeapi.LinuxContainerConfig{\n\t\tResources:       &runtimeapi.LinuxContainerResources{},\n\t\tSecurityContext: sc,\n\t}\n\n\tif nsTarget != nil && lc.SecurityContext.NamespaceOptions.Pid == runtimeapi.NamespaceMode_CONTAINER {\n\t\tlc.SecurityContext.NamespaceOptions.Pid = runtimeapi.NamespaceMode_TARGET\n\t\tlc.SecurityContext.NamespaceOptions.TargetId = nsTarget.ID\n\t}\n\n\t// set linux container resources\n\tlc.Resources = m.calculateLinuxResources(container.Resources.Requests.Cpu(), container.Resources.Limits.Cpu(), container.Resources.Limits.Memory())\n\n\tlc.Resources.OomScoreAdj = int64(qos.GetContainerOOMScoreAdjust(pod, container,\n\t\tint64(m.machineInfo.MemoryCapacity)))\n\n\tlc.Resources.HugepageLimits = GetHugepageLimitsFromResources(container.Resources)\n\n\tif utilfeature.DefaultFeatureGate.Enabled(kubefeatures.NodeSwap) {\n\t\t// NOTE(ehashman): Behaviour is defined in the opencontainers runtime spec:\n\t\t// https://github.com/opencontainers/runtime-spec/blob/1c3f411f041711bbeecf35ff7e93461ea6789220/config-linux.md#memory\n\t\tswitch m.memorySwapBehavior {\n\t\tcase kubelettypes.UnlimitedSwap:\n\t\t\t// -1 = unlimited swap\n\t\t\tlc.Resources.MemorySwapLimitInBytes = -1\n\t\tcase kubelettypes.LimitedSwap:\n\t\t\tfallthrough\n\t\tdefault:\n\t\t\t// memorySwapLimit = total permitted memory+swap; if equal to memory limit, => 0 swap above memory limit\n\t\t\t// Some swapping is still possible.\n\t\t\t// Note that if memory limit is 0, memory swap limit is ignored.\n\t\t\tlc.Resources.MemorySwapLimitInBytes = lc.Resources.MemoryLimitInBytes\n\t\t}\n\t}\n\n\t// Set memory.min and memory.high to enforce MemoryQoS\n\tif enforceMemoryQoS {\n\t\tunified := map[string]string{}\n\t\tmemoryRequest := container.Resources.Requests.Memory().Value()\n\t\tmemoryLimit := container.Resources.Limits.Memory().Value()\n\t\tif memoryRequest != 0 {\n\t\t\tunified[cm.MemoryMin] = strconv.FormatInt(memoryRequest, 10)\n\t\t}\n\n\t\t// If container sets limits.memory, we set memory.high=pod.spec.containers[i].resources.limits[memory] * memory_throttling_factor\n\t\t// for container level cgroup if memory.high>memory.min.\n\t\t// If container doesn't set limits.memory, we set memory.high=node_allocatable_memory * memory_throttling_factor\n\t\t// for container level cgroup.\n\t\tmemoryHigh := int64(0)\n\t\tif memoryLimit != 0 {\n\t\t\tmemoryHigh = int64(float64(memoryLimit) * m.memoryThrottlingFactor)\n\t\t} else {\n\t\t\tallocatable := m.getNodeAllocatable()\n\t\t\tallocatableMemory, ok := allocatable[v1.ResourceMemory]\n\t\t\tif ok && allocatableMemory.Value() > 0 {\n\t\t\t\tmemoryHigh = int64(float64(allocatableMemory.Value()) * m.memoryThrottlingFactor)\n\t\t\t}\n\t\t}\n\t\tif memoryHigh > memoryRequest {\n\t\t\tunified[cm.MemoryHigh] = strconv.FormatInt(memoryHigh, 10)\n\t\t}\n\t\tif len(unified) > 0 {\n\t\t\tif lc.Resources.Unified == nil {\n\t\t\t\tlc.Resources.Unified = unified\n\t\t\t} else {\n\t\t\t\tfor k, v := range unified {\n\t\t\t\t\tlc.Resources.Unified[k] = v\n\t\t\t\t}\n\t\t\t}\n\t\t\tklog.V(4).InfoS(\"MemoryQoS config for container\", \"pod\", klog.KObj(pod), \"containerName\", container.Name, \"unified\", unified)\n\t\t}\n\t}\n\n\treturn lc, nil\n}", "is_vulnerable": 0}
{"code": "var _ = Describe(\"chain tests\", func() {\n\tvar testChain chain\n\tvar ipt *iptables.IPTables\n\tvar cleanup func()\n\n\tBeforeEach(func() {\n\n\t\t// Save a reference to the original namespace,\n\t\t// Add a new NS\n\t\tcurrNs, err := ns.GetCurrentNS()\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\ttestNs, err := ns.NewNS()\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\ttlChainName := fmt.Sprintf(\"cni-test-%d\", rand.Intn(10000000))\n\t\tchainName := fmt.Sprintf(\"cni-test-%d\", rand.Intn(10000000))\n\n\t\ttestChain = chain{\n\t\t\ttable:       TABLE,\n\t\t\tname:        chainName,\n\t\t\tentryChains: []string{tlChainName},\n\t\t\tentryRules:  [][]string{{\"-d\", \"203.0.113.1\"}},\n\t\t\trules: [][]string{\n\t\t\t\t{\"-m\", \"comment\", \"--comment\", \"test 1\", \"-j\", \"RETURN\"},\n\t\t\t\t{\"-m\", \"comment\", \"--comment\", \"test 2\", \"-j\", \"RETURN\"},\n\t\t\t},\n\t\t}\n\n\t\tipt, err = iptables.NewWithProtocol(iptables.ProtocolIPv4)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\truntime.LockOSThread()\n\t\terr = testNs.Set()\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\terr = ipt.ClearChain(TABLE, tlChainName) // This will create the chain\n\t\tif err != nil {\n\t\t\tcurrNs.Set()\n\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\t}\n\n\t\tcleanup = func() {\n\t\t\tif ipt == nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tipt.ClearChain(TABLE, testChain.name)\n\t\t\tipt.ClearChain(TABLE, tlChainName)\n\t\t\tipt.DeleteChain(TABLE, testChain.name)\n\t\t\tipt.DeleteChain(TABLE, tlChainName)\n\t\t\tcurrNs.Set()\n\t\t}\n\n\t})\n\n\tIt(\"creates and destroys a chain\", func() {\n\t\tdefer cleanup()\n\n\t\ttlChainName := testChain.entryChains[0]\n\n\t\t// add an extra rule to the test chain to make sure it's not touched\n\t\terr := ipt.Append(TABLE, tlChainName, \"-m\", \"comment\", \"--comment\",\n\t\t\t\"canary value\", \"-j\", \"ACCEPT\")\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// Create the chain\n\t\terr = testChain.setup(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// Verify the chain exists\n\t\tok := false\n\t\tchains, err := ipt.ListChains(TABLE)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tfor _, chain := range chains {\n\t\t\tif chain == testChain.name {\n\t\t\t\tok = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !ok {\n\t\t\tFail(\"Could not find created chain\")\n\t\t}\n\n\t\t// Check that the entry rule was created\n\t\thaveRules, err := ipt.List(TABLE, tlChainName)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tExpect(haveRules).To(Equal([]string{\n\t\t\t\"-N \" + tlChainName,\n\t\t\t\"-A \" + tlChainName + \" -d 203.0.113.1/32 -j \" + testChain.name,\n\t\t\t\"-A \" + tlChainName + ` -m comment --comment \"canary value\" -j ACCEPT`,\n\t\t}))\n\n\t\t// Check that the chain and rule was created\n\t\thaveRules, err = ipt.List(TABLE, testChain.name)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tExpect(haveRules).To(Equal([]string{\n\t\t\t\"-N \" + testChain.name,\n\t\t\t\"-A \" + testChain.name + ` -m comment --comment \"test 1\" -j RETURN`,\n\t\t\t\"-A \" + testChain.name + ` -m comment --comment \"test 2\" -j RETURN`,\n\t\t}))\n\n\t\terr = testChain.teardown(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\ttlRules, err := ipt.List(TABLE, tlChainName)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tExpect(tlRules).To(Equal([]string{\n\t\t\t\"-N \" + tlChainName,\n\t\t\t\"-A \" + tlChainName + ` -m comment --comment \"canary value\" -j ACCEPT`,\n\t\t}))\n\n\t\tchains, err = ipt.ListChains(TABLE)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tfor _, chain := range chains {\n\t\t\tif chain == testChain.name {\n\t\t\t\tFail(\"chain was not deleted\")\n\t\t\t}\n\t\t}\n\t})\n\n\tIt(\"creates chains idempotently\", func() {\n\t\tdefer cleanup()\n\n\t\terr := testChain.setup(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// Create it again!\n\t\terr = testChain.setup(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\t// Make sure there are only two rules\n\t\t// (the first rule is an -N because go-iptables\n\t\trules, err := ipt.List(TABLE, testChain.name)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tExpect(len(rules)).To(Equal(3))\n\n\t})\n\n\tIt(\"deletes chains idempotently\", func() {\n\t\tdefer cleanup()\n\n\t\terr := testChain.setup(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\terr = testChain.teardown(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\n\t\tchains, err := ipt.ListChains(TABLE)\n\t\tfor _, chain := range chains {\n\t\t\tif chain == testChain.name {\n\t\t\t\tFail(\"Chain was not deleted\")\n\t\t\t}\n\t\t}\n\n\t\terr = testChain.teardown(ipt)\n\t\tExpect(err).NotTo(HaveOccurred())\n\t\tchains, err = ipt.ListChains(TABLE)\n\t\tfor _, chain := range chains {\n\t\t\tif chain == testChain.name {\n\t\t\t\tFail(\"Chain was not deleted\")\n\t\t\t}\n\t\t}\n\t})\n})", "is_vulnerable": 1}
{"code": "func (db *Database) AddAPIKey(r *requests.Request) error {\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\tuser, err := db.validateUserIdentity(r.User.Username, r.User.Email)\n\tif err != nil {\n\t\treturn errors.ErrAddAPIKey.WithArgs(r.Key.Usage, err)\n\t}\n\ts := util.GetRandomStringFromRange(72, 96)\n\tfailCount := 0\n\tfor {\n\t\thk, err := NewPassword(s)\n\t\tif err != nil {\n\t\t\tif failCount > 10 {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfailCount++\n\t\t\tcontinue\n\t\t}\n\t\tkeyPrefix := string(s[:24])\n\t\tif _, exists := db.refAPIKey[keyPrefix]; exists {\n\t\t\tcontinue\n\t\t}\n\t\tr.Response.Payload = s\n\t\tr.Key.Payload = hk.Hash\n\t\tr.Key.Prefix = keyPrefix\n\t\tif err := user.AddAPIKey(r); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdb.refAPIKey[keyPrefix] = user\n\t\tbreak\n\t}\n\n\tif err := db.commit(); err != nil {\n\t\treturn errors.ErrAddAPIKey.WithArgs(r.Key.Usage, err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func NewListResultIterator(page ListResultPage) ListResultIterator {\n\treturn original.NewListResultIterator(page)\n}", "is_vulnerable": 0}
{"code": "func (o *LoginNoContent) WriteResponse(rw http.ResponseWriter, producer runtime.Producer) {\n\n\trw.Header().Del(runtime.HeaderContentType) //Remove Content-Type on empty responses\n\n\trw.WriteHeader(204)\n}", "is_vulnerable": 0}
{"code": "func (t *TestServerStream) SendAndClose(r *apiclient.ManifestResponse) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func unmarshal(yamlBytes []byte, obj interface{}, unmarshalFn func([]byte, interface{}) error, opts ...JSONOpt) error {\n\tjsonTarget := reflect.ValueOf(obj)\n\n\tjsonBytes, err := yamlToJSONTarget(yamlBytes, &jsonTarget, unmarshalFn)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error converting YAML to JSON: %w\", err)\n\t}\n\n\terr = jsonUnmarshal(bytes.NewReader(jsonBytes), obj, opts...)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error unmarshaling JSON: %w\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (sl scrapeLogger) Log(keyvals ...interface{}) error {\n\tsl.bufferLogger.Log(keyvals...)\n\tkvs := make([]interface{}, len(keyvals))\n\tcopy(kvs, keyvals)\n\t// Switch level to debug for application output.\n\tfor i := 0; i < len(kvs); i += 2 {\n\t\tif kvs[i] == level.Key() {\n\t\t\tkvs[i+1] = level.DebugValue()\n\t\t}\n\t}\n\treturn sl.next.Log(kvs...)\n}", "is_vulnerable": 1}
{"code": "func (c *ChartDownloader) ResolveChartVersion(ref, version string) (*url.URL, error) {\n\tu, err := url.Parse(ref)\n\tif err != nil {\n\t\treturn nil, errors.Errorf(\"invalid chart URL format: %s\", ref)\n\t}\n\tc.Options = append(c.Options, getter.WithURL(ref))\n\n\trf, err := loadRepoConfig(c.RepositoryConfig)\n\tif err != nil {\n\t\treturn u, err\n\t}\n\n\tif u.IsAbs() && len(u.Host) > 0 && len(u.Path) > 0 {\n\t\t// In this case, we have to find the parent repo that contains this chart\n\t\t// URL. And this is an unfortunate problem, as it requires actually going\n\t\t// through each repo cache file and finding a matching URL. But basically\n\t\t// we want to find the repo in case we have special SSL cert config\n\t\t// for that repo.\n\n\t\trc, err := c.scanReposForURL(ref, rf)\n\t\tif err != nil {\n\t\t\t// If there is no special config, return the default HTTP client and\n\t\t\t// swallow the error.\n\t\t\tif err == ErrNoOwnerRepo {\n\t\t\t\treturn u, nil\n\t\t\t}\n\t\t\treturn u, err\n\t\t}\n\n\t\t// If we get here, we don't need to go through the next phase of looking\n\t\t// up the URL. We have it already. So we just set the parameters and return.\n\t\tc.Options = append(\n\t\t\tc.Options,\n\t\t\tgetter.WithURL(rc.URL),\n\t\t)\n\t\tif rc.CertFile != \"\" || rc.KeyFile != \"\" || rc.CAFile != \"\" {\n\t\t\tc.Options = append(c.Options, getter.WithTLSClientConfig(rc.CertFile, rc.KeyFile, rc.CAFile))\n\t\t}\n\t\tif rc.Username != \"\" && rc.Password != \"\" {\n\t\t\tc.Options = append(\n\t\t\t\tc.Options,\n\t\t\t\tgetter.WithBasicAuth(rc.Username, rc.Password),\n\t\t\t\tgetter.WithPassCredentialsAll(rc.PassCredentialsAll),\n\t\t\t)\n\t\t}\n\t\treturn u, nil\n\t}\n\n\t// See if it's of the form: repo/path_to_chart\n\tp := strings.SplitN(u.Path, \"/\", 2)\n\tif len(p) < 2 {\n\t\treturn u, errors.Errorf(\"non-absolute URLs should be in form of repo_name/path_to_chart, got: %s\", u)\n\t}\n\n\trepoName := p[0]\n\tchartName := p[1]\n\trc, err := pickChartRepositoryConfigByName(repoName, rf.Repositories)\n\n\tif err != nil {\n\t\treturn u, err\n\t}\n\n\tr, err := repo.NewChartRepository(rc, c.Getters)\n\tif err != nil {\n\t\treturn u, err\n\t}\n\n\tif r != nil && r.Config != nil {\n\t\tif r.Config.CertFile != \"\" || r.Config.KeyFile != \"\" || r.Config.CAFile != \"\" {\n\t\t\tc.Options = append(c.Options, getter.WithTLSClientConfig(r.Config.CertFile, r.Config.KeyFile, r.Config.CAFile))\n\t\t}\n\t\tif r.Config.Username != \"\" && r.Config.Password != \"\" {\n\t\t\tc.Options = append(c.Options,\n\t\t\t\tgetter.WithBasicAuth(r.Config.Username, r.Config.Password),\n\t\t\t\tgetter.WithPassCredentialsAll(r.Config.PassCredentialsAll),\n\t\t\t)\n\t\t}\n\t}\n\n\t// Next, we need to load the index, and actually look up the chart.\n\tidxFile := filepath.Join(c.RepositoryCache, helmpath.CacheIndexFile(r.Config.Name))\n\ti, err := repo.LoadIndexFile(idxFile)\n\tif err != nil {\n\t\treturn u, errors.Wrap(err, \"no cached repo found. (try 'helm repo update')\")\n\t}\n\n\tcv, err := i.Get(chartName, version)\n\tif err != nil {\n\t\treturn u, errors.Wrapf(err, \"chart %q matching %s not found in %s index. (try 'helm repo update')\", chartName, version, r.Config.Name)\n\t}\n\n\tif len(cv.URLs) == 0 {\n\t\treturn u, errors.Errorf(\"chart %q has no downloadable URLs\", ref)\n\t}\n\n\t// TODO: Seems that picking first URL is not fully correct\n\tu, err = url.Parse(cv.URLs[0])\n\tif err != nil {\n\t\treturn u, errors.Errorf(\"invalid chart URL format: %s\", ref)\n\t}\n\n\t// If the URL is relative (no scheme), prepend the chart repo's base URL\n\tif !u.IsAbs() {\n\t\trepoURL, err := url.Parse(rc.URL)\n\t\tif err != nil {\n\t\t\treturn repoURL, err\n\t\t}\n\t\tq := repoURL.Query()\n\t\t// We need a trailing slash for ResolveReference to work, but make sure there isn't already one\n\t\trepoURL.Path = strings.TrimSuffix(repoURL.Path, \"/\") + \"/\"\n\t\tu = repoURL.ResolveReference(u)\n\t\tu.RawQuery = q.Encode()\n\t\t// TODO add user-agent\n\t\tif _, err := getter.NewHTTPGetter(getter.WithURL(rc.URL)); err != nil {\n\t\t\treturn repoURL, err\n\t\t}\n\t\treturn u, err\n\t}\n\n\t// TODO add user-agent\n\treturn u, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Container) shareFiles(m Mount, idx int, hostSharedDir, guestSharedDir string) (string, bool, error) {\n\trandBytes, err := utils.GenerateRandomBytes(8)\n\tif err != nil {\n\t\treturn \"\", false, err\n\t}\n\n\tfilename := fmt.Sprintf(\"%s-%s-%s\", c.id, hex.EncodeToString(randBytes), filepath.Base(m.Destination))\n\tguestDest := filepath.Join(guestSharedDir, filename)\n\n\t// copy file to contaier's rootfs if filesystem sharing is not supported, otherwise\n\t// bind mount it in the shared directory.\n\tcaps := c.sandbox.hypervisor.capabilities()\n\tif !caps.IsFsSharingSupported() {\n\t\tc.Logger().Debug(\"filesystem sharing is not supported, files will be copied\")\n\n\t\tfileInfo, err := os.Stat(m.Source)\n\t\tif err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\n\t\t// Ignore the mount if this is not a regular file (excludes\n\t\t// directory, socket, device, ...) as it cannot be handled by\n\t\t// a simple copy. But this should not be treated as an error,\n\t\t// only as a limitation.\n\t\tif !fileInfo.Mode().IsRegular() {\n\t\t\tc.Logger().WithField(\"ignored-file\", m.Source).Debug(\"Ignoring non-regular file as FS sharing not supported\")\n\t\t\treturn \"\", true, nil\n\t\t}\n\n\t\tif err := c.sandbox.agent.copyFile(m.Source, guestDest); err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\t} else {\n\t\t// These mounts are created in the shared dir\n\t\tmountDest := filepath.Join(hostSharedDir, filename)\n\t\tif err := bindMount(c.ctx, m.Source, mountDest, m.ReadOnly, \"private\"); err != nil {\n\t\t\treturn \"\", false, err\n\t\t}\n\t\t// Save HostPath mount value into the mount list of the container.\n\t\tc.mounts[idx].HostPath = mountDest\n\t}\n\n\treturn guestDest, false, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Ps(ctx context.Context, in *sliverpb.PsReq, opts ...grpc.CallOption) (*sliverpb.Ps, error) {\n\tout := new(sliverpb.Ps)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/Ps\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func TestDockerComposeGetConfigurations(t *testing.T) {\n\ttarget := NewConfigurations(platforms.DockerCompose, nil, \"testdata\")\n\tconfigurations := target.GetConfigurations(\"\")\n\tassert.Equal(t, 1, len(configurations), \"Should load test data configurations\")\n\tfor _, v := range configurations {\n\t\tassert.Equal(t, v.Kind, \"Configuration\", \"Should only load configuration files\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockStorage) ClientAssertionJWTValid(arg0 context.Context, arg1 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"ClientAssertionJWTValid\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func testSignerFromFile(t *testing.T, keyCert *keyCertPair, envelopeType, dir string) {\n\tkeyPath, certPath, err := prepareTestKeyCertFile(keyCert, envelopeType, dir)\n\tif err != nil {\n\t\tt.Fatalf(\"prepareTestKeyCertFile() failed: %v\", err)\n\t}\n\ts, err := NewFromFiles(keyPath, certPath)\n\tif err != nil {\n\t\tt.Fatalf(\"NewSignerFromFiles() failed: %v\", err)\n\t}\n\tdesc, opts := generateSigningContent()\n\topts.SignatureMediaType = envelopeType\n\tsig, _, err := s.Sign(context.Background(), desc, opts)\n\tif err != nil {\n\t\tt.Fatalf(\"Sign() failed: %v\", err)\n\t}\n\t// basic verification\n\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], nil)\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) Delete(ctx context.Context, resourceGroupName string) (result GroupsDeleteFuture, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupsClient.Delete\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response() != nil {\n\t\t\t\tsc = result.Response().StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.GroupsClient\", \"Delete\", err.Error())\n\t}\n\n\treq, err := client.DeletePreparer(ctx, resourceGroupName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"Delete\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresult, err = client.DeleteSender(req)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"Delete\", result.Response(), \"Failure sending request\")\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (r *queryResolver) PackageSearch(ctx context.Context, searchTerm *string, resultSize *int) ([]*models.Package, error) {\n\tvar gpackages []*models.Package\n\n\tlimit := 100\n\tif resultSize != nil {\n\t\tlimit = *resultSize\n\t}\n\n\tvar err error\n\tif strings.Contains(*searchTerm, \"*\") {\n\t\t// if the query contains wildcards\n\t\twildcardSearchTerm := strings.ReplaceAll(*searchTerm, \"*\", \"%\")\n\t\terr = database.DBCon.Model(&gpackages).\n\t\t\tWhereOr(\"atom LIKE ? \", wildcardSearchTerm).\n\t\t\tWhereOr(\"name LIKE ? \", wildcardSearchTerm).\n\t\t\tRelation(\"PkgCheckResults\").Relation(\"Bugs\").Relation(\"PullRequests\").Relation(\"ReverseDependencies\").Relation(\"Commits\").Relation(\"Versions\").Relation(\"Versions.Masks\").Relation(\"Versions.PkgCheckResults\").Relation(\"Versions.Dependencies\").Relation(\"PkgCheckResults\").Relation(\"Outdated\").\n\t\t\tOrderExpr(\"name <-> '\" + *searchTerm + \"'\").\n\t\t\tLimit(limit).\n\t\t\tSelect()\n\t} else {\n\t\t// if the query contains no wildcards do a fuzzy search\n\t\tsearchQuery := packages.BuildSearchQuery(*searchTerm)\n\t\terr = database.DBCon.Model(&gpackages).\n\t\t\tWhere(searchQuery).\n\t\t\tWhereOr(\"atom LIKE ? \", (\"%\" + *searchTerm + \"%\")).\n\t\t\tRelation(\"PkgCheckResults\").Relation(\"Bugs\").Relation(\"PullRequests\").Relation(\"ReverseDependencies\").Relation(\"Commits\").Relation(\"Versions\").Relation(\"Versions.Masks\").Relation(\"Versions.PkgCheckResults\").Relation(\"Versions.Dependencies\").Relation(\"PkgCheckResults\").Relation(\"Outdated\").\n\t\t\tOrderExpr(\"name <-> '\" + *searchTerm + \"'\").\n\t\t\tLimit(limit).\n\t\t\tSelect()\n\t}\n\n\tif len(gpackages) > 1 && (gpackages[0].Atom == *searchTerm || (gpackages[0].Name == *searchTerm && gpackages[1].Name != *searchTerm)) {\n\t\treturn gpackages[:1], nil\n\t}\n\n\tif err != nil {\n\t\treturn nil, errors.New(\"an error occurred while searching for the packages\")\n\t}\n\n\treturn gpackages, nil\n}", "is_vulnerable": 1}
{"code": "func (c Certificate) GetTLSConfigForServer() (*tls.Config, error) {\n\tcertificate, err := tls.LoadX509KeyPair(\n\t\tc.CertFile,\n\t\tc.KeyFile,\n\t)\n\n\tcertPool := x509.NewCertPool()\n\tbs, err := ioutil.ReadFile(c.CAFile)\n\tif err != nil {\n\t\treturn nil, errors.New(fmt.Sprintf(\"failed to read client ca cert: %s\", err))\n\t}\n\n\tok := certPool.AppendCertsFromPEM(bs)\n\tif !ok {\n\t\treturn nil, errors.New(\"failed to append client certs\")\n\t}\n\n\ttlsConfig := &tls.Config{\n\t\tClientAuth:   tls.RequireAndVerifyClientCert,\n\t\tCertificates: []tls.Certificate{certificate},\n\t\tClientCAs:    certPool,\n\t}\n\n\treturn tlsConfig, nil\n}", "is_vulnerable": 1}
{"code": "func NewExportProxyDeployment(namespace, repository, imagePrefix, version, productName, productVersion, productComponent, image string, pullPolicy corev1.PullPolicy, imagePullSecrets []corev1.LocalObjectReference, verbosity string, extraEnv map[string]string) (*appsv1.Deployment, error) {\n\tpodAntiAffinity := newPodAntiAffinity(kubevirtLabelKey, kubernetesHostnameTopologyKey, metav1.LabelSelectorOpIn, []string{VirtAPIName})\n\tdeploymentName := VirtExportProxyName\n\timageName := fmt.Sprintf(\"%s%s\", imagePrefix, deploymentName)\n\tenv := operatorutil.NewEnvVarMap(extraEnv)\n\tdeployment, err := newBaseDeployment(deploymentName, imageName, namespace, repository, version, productName, productVersion, productComponent, image, pullPolicy, imagePullSecrets, podAntiAffinity, env)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tattachCertificateSecret(&deployment.Spec.Template.Spec, VirtExportProxyCertSecretName, \"/etc/virt-exportproxy/certificates\")\n\tattachProfileVolume(&deployment.Spec.Template.Spec)\n\n\tpod := &deployment.Spec.Template.Spec\n\tpod.ServiceAccountName = ExportProxyServiceAccountName\n\tpod.SecurityContext = &corev1.PodSecurityContext{\n\t\tRunAsNonRoot: boolPtr(true),\n\t}\n\n\tconst shortName = \"exportproxy\"\n\tcontainer := &deployment.Spec.Template.Spec.Containers[0]\n\t// virt-exportproxy too long\n\tcontainer.Name = shortName\n\tcontainer.Command = []string{\n\t\tVirtExportProxyName,\n\t\tportName,\n\t\t\"8443\",\n\t\t\"-v\",\n\t\tverbosity,\n\t}\n\tcontainer.Ports = []corev1.ContainerPort{\n\t\t{\n\t\t\tName:          shortName,\n\t\t\tProtocol:      corev1.ProtocolTCP,\n\t\t\tContainerPort: 8443,\n\t\t},\n\t\t{\n\t\t\tName:          \"metrics\",\n\t\t\tProtocol:      corev1.ProtocolTCP,\n\t\t\tContainerPort: 8443,\n\t\t},\n\t}\n\n\tcontainer.ReadinessProbe = &corev1.Probe{\n\t\tProbeHandler: corev1.ProbeHandler{\n\t\t\tHTTPGet: &corev1.HTTPGetAction{\n\t\t\t\tScheme: corev1.URISchemeHTTPS,\n\t\t\t\tPort: intstr.IntOrString{\n\t\t\t\t\tType:   intstr.Int,\n\t\t\t\t\tIntVal: 8443,\n\t\t\t\t},\n\t\t\t\tPath: \"/healthz\",\n\t\t\t},\n\t\t},\n\t\tInitialDelaySeconds: 15,\n\t\tPeriodSeconds:       10,\n\t}\n\n\tcontainer.Resources = corev1.ResourceRequirements{\n\t\tRequests: corev1.ResourceList{\n\t\t\tcorev1.ResourceCPU:    resource.MustParse(\"5m\"),\n\t\t\tcorev1.ResourceMemory: resource.MustParse(\"150Mi\"),\n\t\t},\n\t}\n\n\treturn deployment, nil\n}", "is_vulnerable": 0}
{"code": "func main() {\n\tvar metricsAddr string\n\tvar enableLeaderElection bool\n\tvar probeAddr string\n\tflag.StringVar(&metricsAddr, \"metrics-bind-address\", \":8080\", \"The address the metric endpoint binds to.\")\n\tflag.StringVar(&probeAddr, \"health-probe-bind-address\", \":8081\", \"The address the probe endpoint binds to.\")\n\tflag.BoolVar(&enableLeaderElection, \"leader-elect\", false,\n\t\t\"Enable leader election for controller manager. \"+\n\t\t\t\"Enabling this will ensure there is only one active controller manager.\")\n\n\topts := zap.Options{\n\t\tDevelopment: true,\n\t}\n\topts.BindFlags(flag.CommandLine)\n\tflag.Parse()\n\n\tctrl.SetLogger(zap.New(zap.UseFlagOptions(&opts)))\n\n\tmgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{\n\t\tScheme:                 scheme,\n\t\tMetricsBindAddress:     metricsAddr,\n\t\tPort:                   9443,\n\t\tHealthProbeBindAddress: probeAddr,\n\t\tLeaderElection:         enableLeaderElection,\n\t\tLeaderElectionID:       \"785548a1.sealos.io\",\n\t\t// LeaderElectionReleaseOnCancel defines if the leader should step down voluntarily\n\t\t// when the Manager ends. This requires the binary to immediately end when the\n\t\t// Manager is stopped, otherwise, this setting is unsafe. Setting this significantly\n\t\t// speeds up voluntary leader transitions as the new leader don't have to wait\n\t\t// LeaseDuration time first.\n\t\t//\n\t\t// In the default scaffold provided, the program ends immediately after\n\t\t// the manager stops, so would be fine to enable this option. However,\n\t\t// if you are doing or is intended to do any operation such as perform cleanups\n\t\t// after the manager stops then its usage might be unsafe.\n\t\t// LeaderElectionReleaseOnCancel: true,\n\t})\n\tif err != nil {\n\t\tsetupLog.Error(err, \"unable to start manager\")\n\t\tos.Exit(1)\n\t}\n\tif err = (&controllers.UserReconciler{}).SetupWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"unable to create controller\", \"controller\", \"User\")\n\t\tos.Exit(1)\n\t}\n\tif err = (&controllers.UserGroupReconciler{}).SetupWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"unable to create controller\", \"controller\", \"UserGroup\")\n\t\tos.Exit(1)\n\t}\n\tif err = (&controllers.UserGroupBindingReconciler{\n\t\tClient: mgr.GetClient(),\n\t\tScheme: mgr.GetScheme(),\n\t}).SetupWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"unable to create controller\", \"controller\", \"UserGroupBinding\")\n\t\tos.Exit(1)\n\t}\n\n\tif err = (&controllers.NamespaceReconciler{\n\t\tClient: mgr.GetClient(),\n\t\tScheme: mgr.GetScheme(),\n\t}).SetupWithManager(mgr); err != nil {\n\t\tsetupLog.Error(err, \"unable to create controller\", \"controller\", \"Namespace\")\n\t\tos.Exit(1)\n\t}\n\n\t//if err = (&controllers.UserExpirationReconciler{\n\t//\tClient: mgr.GetClient(),\n\t//\tScheme: mgr.GetScheme(),\n\t//}).SetupWithManager(mgr); err != nil {\n\t//\tsetupLog.Error(err, \"unable to create controller\", \"controller\", \"Secret\")\n\t//\tos.Exit(1)\n\t//}\n\n\tif err = cache.SetupCache(mgr); err != nil {\n\t\tsetupLog.Error(err, \"unable to cache controller\")\n\t\tos.Exit(1)\n\t}\n\tif os.Getenv(\"DISABLE_WEBHOOKS\") == \"true\" {\n\t\tsetupLog.Info(\"disable all webhooks\")\n\t} else {\n\t\tif err = (&userv1.User{}).SetupWebhookWithManager(mgr); err != nil {\n\t\t\tsetupLog.Error(err, \"unable to create webhook\", \"webhook\", \"User\")\n\t\t\tos.Exit(1)\n\t\t}\n\t\tsetupLog.Info(\"add ug and ugb webhooks\")\n\t\tif err = (&userv1.UserGroup{}).SetupWebhookWithManager(mgr); err != nil {\n\t\t\tsetupLog.Error(err, \"unable to create webhook\", \"webhook\", \"UserGroup\")\n\t\t\tos.Exit(1)\n\t\t}\n\t\tif err = (&userv1.UserGroupBinding{}).SetupWebhookWithManager(mgr); err != nil {\n\t\t\tsetupLog.Error(err, \"unable to create webhook\", \"webhook\", \"UserGroupBinding\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\t//+kubebuilder:scaffold:builder\n\n\tif err := mgr.AddHealthzCheck(\"healthz\", healthz.Ping); err != nil {\n\t\tsetupLog.Error(err, \"unable to set up health check\")\n\t\tos.Exit(1)\n\t}\n\tif err := mgr.AddReadyzCheck(\"readyz\", healthz.Ping); err != nil {\n\t\tsetupLog.Error(err, \"unable to set up ready check\")\n\t\tos.Exit(1)\n\t}\n\tctx, cancel := context.WithCancel(context.TODO())\n\tdefer cancel()\n\tsetupLog.Info(\"starting manager\")\n\tif err = mgr.Start(ctx); err != nil {\n\t\tsetupLog.Error(err, \"failed to running manager\")\n\t\tos.Exit(1)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *client) CreateStep(ctx context.Context, ctn *pipeline.Container) error {\n\t// update engine logger with step metadata\n\t//\n\t// https://pkg.go.dev/github.com/sirupsen/logrus#Entry.WithField\n\tlogger := c.Logger.WithField(\"step\", ctn.Name)\n\n\t// TODO: remove hardcoded reference\n\tif ctn.Name == \"init\" {\n\t\treturn nil\n\t}\n\n\tlogger.Debug(\"setting up container\")\n\t// setup the runtime container\n\terr := c.Runtime.SetupContainer(ctx, ctn)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create a library step object to facilitate injecting environment as early as possible\n\t// (PlanStep is too late to inject environment vars for the kubernetes runtime).\n\t_step := library.StepFromBuildContainer(c.build, ctn)\n\n\t// update the step container environment\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/worker/internal/step#Environment\n\terr = step.Environment(ctn, c.build, c.repo, _step, c.Version)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlogger.Debug(\"injecting secrets\")\n\t// inject secrets for container\n\terr = injectSecrets(ctn, c.Secrets)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlogger.Debug(\"substituting container configuration\")\n\t// substitute container configuration\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/pipeline#Container.Substitute\n\terr = ctn.Substitute()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to substitute container configuration\")\n\t}\n\n\tlogger.Debug(\"injecting non-substituted secrets\")\n\t// inject no-substitution secrets for container\n\terr = injectSecrets(ctn, c.NoSubSecrets)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Setup) command(ctx context.Context, command string) error {\n\tif m.envPath != \"\" {\n\t\tbackupEnv := os.Environ()\n\t\tos.Clearenv()\n\t\tos.Setenv(\"PATH\", m.envPath)\n\t\tdefer env.SetFromList(backupEnv)\n\t}\n\n\tconfig := libcni.NewCNIConfig([]string{m.cniPath.Plugin}, nil)\n\n\t// set a timeout context for the execution of the CNI plugin\n\t// to interrupt its execution if it takes more than 5 seconds\n\tctx, cancel := context.WithTimeout(ctx, 5*time.Second)\n\tdefer cancel()\n\n\tif command == \"ADD\" {\n\t\tm.result = make([]types.Result, len(m.networkConfList))\n\t\tfor i := 0; i < len(m.networkConfList); i++ {\n\t\t\tvar err error\n\t\t\tif m.result[i], err = config.AddNetworkList(ctx, m.networkConfList[i], m.runtimeConf[i]); err != nil {\n\t\t\t\tfor j := i - 1; j >= 0; j-- {\n\t\t\t\t\tif err := config.DelNetworkList(ctx, m.networkConfList[j], m.runtimeConf[j]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t} else if command == \"DEL\" {\n\t\tfor i := 0; i < len(m.networkConfList); i++ {\n\t\t\tif err := config.DelNetworkList(ctx, m.networkConfList[i], m.runtimeConf[i]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func handleFileUpload(p string, s *server.Server, header *multipart.FileHeader) error {\n\tfile, err := header.Open()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\n\tif err := s.Filesystem().IsIgnored(p); err != nil {\n\t\treturn err\n\t}\n\tif err := s.Filesystem().Writefile(p, file); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (l Logger) Error(err error, msg string, keysAndValues ...interface{}) {\n\tif l.sink == nil {\n\t\treturn\n\t}\n\tif withHelper, ok := l.sink.(CallStackHelperLogSink); ok {\n\t\twithHelper.GetCallStackHelper()()\n\t}\n\tl.sink.Error(err, msg, keysAndValues...)\n}", "is_vulnerable": 1}
{"code": "func (v *commandAttrValidator) validateStartChildExecutionAttributes(\n\tnamespaceID namespace.ID,\n\ttargetNamespaceID namespace.ID,\n\ttargetNamespace namespace.Name,\n\tattributes *commandpb.StartChildWorkflowExecutionCommandAttributes,\n\tparentInfo *persistencespb.WorkflowExecutionInfo,\n\tdefaultWorkflowTaskTimeoutFn dynamicconfig.DurationPropertyFnWithNamespaceFilter,\n) (enumspb.WorkflowTaskFailedCause, error) {\n\n\tconst failedCause = enumspb.WORKFLOW_TASK_FAILED_CAUSE_BAD_START_CHILD_EXECUTION_ATTRIBUTES\n\tif err := v.validateCrossNamespaceCall(\n\t\tnamespaceID,\n\t\ttargetNamespaceID,\n\t); err != nil {\n\t\treturn failedCause, err\n\t}\n\n\tif attributes == nil {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"StartChildWorkflowExecutionCommandAttributes is not set on command.\")\n\t}\n\n\tif attributes.GetWorkflowId() == \"\" {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Required field WorkflowId is not set on command.\")\n\t}\n\n\tif attributes.WorkflowType == nil || attributes.WorkflowType.GetName() == \"\" {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Required field WorkflowType is not set on command.\")\n\t}\n\n\tif len(attributes.GetNamespace()) > v.maxIDLengthLimit {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Namespace exceeds length limit.\")\n\t}\n\n\tif len(attributes.GetWorkflowId()) > v.maxIDLengthLimit {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"WorkflowId exceeds length limit.\")\n\t}\n\n\tif len(attributes.WorkflowType.GetName()) > v.maxIDLengthLimit {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"WorkflowType exceeds length limit.\")\n\t}\n\n\tif err := common.ValidateUTF8String(\"WorkflowId\", attributes.GetWorkflowId()); err != nil {\n\t\treturn failedCause, err\n\t}\n\n\tif err := common.ValidateUTF8String(\"WorkflowType\", attributes.WorkflowType.GetName()); err != nil {\n\t\treturn failedCause, err\n\t}\n\n\tif timestamp.DurationValue(attributes.GetWorkflowExecutionTimeout()) < 0 {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Invalid WorkflowExecutionTimeout.\")\n\t}\n\n\tif timestamp.DurationValue(attributes.GetWorkflowRunTimeout()) < 0 {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Invalid WorkflowRunTimeout.\")\n\t}\n\n\tif timestamp.DurationValue(attributes.GetWorkflowTaskTimeout()) < 0 {\n\t\treturn failedCause, serviceerror.NewInvalidArgument(\"Invalid WorkflowTaskTimeout.\")\n\t}\n\n\tif err := v.validateWorkflowRetryPolicy(namespace.Name(attributes.GetNamespace()), attributes.RetryPolicy); err != nil {\n\t\treturn failedCause, err\n\t}\n\n\tif err := backoff.ValidateSchedule(attributes.GetCronSchedule()); err != nil {\n\t\treturn failedCause, err\n\t}\n\n\tif err := v.searchAttributesValidator.Validate(attributes.GetSearchAttributes(), targetNamespace.String()); err != nil {\n\t\treturn enumspb.WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES, err\n\t}\n\n\t// Inherit taskqueue from parent workflow execution if not provided on command\n\ttaskQueue, err := v.validateTaskQueue(attributes.TaskQueue, parentInfo.TaskQueue)\n\tif err != nil {\n\t\treturn failedCause, err\n\t}\n\tattributes.TaskQueue = taskQueue\n\n\t// workflow execution timeout is left as is\n\t//  if workflow execution timeout == 0 -> infinity\n\n\tattributes.WorkflowRunTimeout = timestamp.DurationPtr(\n\t\tcommon.OverrideWorkflowRunTimeout(\n\t\t\ttimestamp.DurationValue(attributes.GetWorkflowRunTimeout()),\n\t\t\ttimestamp.DurationValue(attributes.GetWorkflowExecutionTimeout()),\n\t\t),\n\t)\n\n\tattributes.WorkflowTaskTimeout = timestamp.DurationPtr(\n\t\tcommon.OverrideWorkflowTaskTimeout(\n\t\t\ttargetNamespace.String(),\n\t\t\ttimestamp.DurationValue(attributes.GetWorkflowTaskTimeout()),\n\t\t\ttimestamp.DurationValue(attributes.GetWorkflowRunTimeout()),\n\t\t\tdefaultWorkflowTaskTimeoutFn,\n\t\t),\n\t)\n\n\treturn enumspb.WORKFLOW_TASK_FAILED_CAUSE_UNSPECIFIED, nil\n}", "is_vulnerable": 0}
{"code": "func (autoApi *AutoCodeApi) GetColumn(c *gin.Context) {\n\tbusinessDB := c.Query(\"businessDB\")\n\tdbName := c.DefaultQuery(\"dbName\", global.GVA_CONFIG.Mysql.Dbname)\n\ttableName := c.Query(\"tableName\")\n\tcolumns, err := autoCodeService.Database(businessDB).GetColumn(businessDB, tableName, dbName)\n\tif err != nil {\n\t\tglobal.GVA_LOG.Error(\"\u83b7\u53d6\u5931\u8d25!\", zap.Error(err))\n\t\tresponse.FailWithMessage(\"\u83b7\u53d6\u5931\u8d25\", c)\n\t} else {\n\t\tresponse.OkWithDetailed(gin.H{\"columns\": columns}, \"\u83b7\u53d6\u6210\u529f\", c)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (evpool *Pool) removePendingEvidence(evidence types.Evidence) {\n\tkey := keyPending(evidence)\n\tif err := evpool.evidenceStore.Delete(key); err != nil {\n\t\tevpool.logger.Error(\"Unable to delete pending evidence\", \"err\", err)\n\t} else {\n\t\tatomic.AddUint32(&evpool.evidenceSize, ^uint32(0))\n\t\tevpool.logger.Info(\"Deleted pending evidence\", \"evidence\", evidence)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestWrongSignedPeerRecord(t *testing.T) {\n\th1 := blhost.NewBlankHost(swarmt.GenSwarm(t))\n\tdefer h1.Close()\n\tids, err := NewIDService(h1)\n\trequire.NoError(t, err)\n\tids.Start()\n\tdefer ids.Close()\n\n\th2 := blhost.NewBlankHost(swarmt.GenSwarm(t))\n\tdefer h2.Close()\n\tids2, err := NewIDService(h2)\n\trequire.NoError(t, err)\n\tids2.Start()\n\tdefer ids2.Close()\n\n\th3 := blhost.NewBlankHost(swarmt.GenSwarm(t))\n\tdefer h2.Close()\n\tids3, err := NewIDService(h3)\n\trequire.NoError(t, err)\n\tids3.Start()\n\tdefer ids3.Close()\n\n\th2.Connect(context.Background(), peer.AddrInfo{ID: h1.ID(), Addrs: h1.Addrs()})\n\ts, err := h2.NewStream(context.Background(), h1.ID(), IDPush)\n\trequire.NoError(t, err)\n\n\terr = ids3.sendIdentifyResp(s, true)\n\t// This should fail because the peer record is signed by h3, not h2\n\trequire.NoError(t, err)\n\ttime.Sleep(time.Second)\n\n\trequire.Empty(t, h1.Peerstore().Addrs(h3.ID()), \"h1 should not know about h3 since it was relayed over h2\")\n}", "is_vulnerable": 0}
{"code": "func InstrumentHandlerDuration(obs prometheus.ObserverVec, next http.Handler, opts ...Option) http.HandlerFunc {\n\tmwOpts := &option{}\n\tfor _, o := range opts {\n\t\to(mwOpts)\n\t}\n\n\tcode, method := checkLabels(obs)\n\n\tif code {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tnow := time.Now()\n\t\t\td := newDelegator(w, nil)\n\t\t\tnext.ServeHTTP(d, r)\n\n\t\t\tobs.With(labels(code, method, r.Method, d.Status(), mwOpts.extraMethods...)).Observe(time.Since(now).Seconds())\n\t\t})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnow := time.Now()\n\t\tnext.ServeHTTP(w, r)\n\t\tobs.With(labels(code, method, r.Method, 0, mwOpts.extraMethods...)).Observe(time.Since(now).Seconds())\n\t})\n}", "is_vulnerable": 0}
{"code": "\t\t\tSetConfigMap: func(ns string) *v1.ConfigMap {\n\t\t\t\treturn &v1.ConfigMap{\n\t\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\t\tName:     \"config\",\n\t\t\t\t\t\tSelfLink: fmt.Sprintf(\"/api/v1/namespaces/%s/configmaps/config\", ns),\n\t\t\t\t\t},\n\t\t\t\t\tData: map[string]string{\n\t\t\t\t\t\t\"enable-snippet-directives\": \"false\",\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\tnginxController := newDynamicNginxController(t, testCase.SetConfigMap)\n\t\tupstreams, servers := nginxController.getBackendServers(testCase.Ingresses)\n\t\ttestCase.Validate(testCase.Ingresses, upstreams, servers)\n\t}\n}", "is_vulnerable": 0}
{"code": "func UnitTest(t *testing.T) {\n\tt.Helper()\n\tc := config.New()\n\tc.SetManageBinariesAutomatically(false)\n\tc.SetToken(\"00000000-0000-0000-0000-000000000001\")\n\tc.SetTrustedFolderFeatureEnabled(false)\n\tconfig.SetCurrentConfig(c)\n\tCLIDownloadLockFileCleanUp(t)\n}", "is_vulnerable": 0}
{"code": "func TestArgsAllowList(t *testing.T) {\n\n\tpluginConfigAllowList := []string{\"-drive\", \"-net\", \"-snapshot\"}\n\n\tvalidArgs := [][]string{\n\t\t{\"-drive\", \"/path/to/wherever\", \"-snapshot\"},\n\t\t{\"-net\", \"tap,vlan=0,ifname=tap0\"},\n\t}\n\n\tinvalidArgs := [][]string{\n\t\t{\"-usbdevice\", \"mouse\"},\n\t\t{\"-singlestep\"},\n\t\t{\"--singlestep\"},\n\t\t{\" -singlestep\"},\n\t\t{\"\\t-singlestep\"},\n\t}\n\n\tfor _, args := range validArgs {\n\t\trequire.NoError(t, validateArgs(pluginConfigAllowList, args))\n\t\trequire.NoError(t, validateArgs([]string{}, args))\n\n\t}\n\tfor _, args := range invalidArgs {\n\t\trequire.Error(t, validateArgs(pluginConfigAllowList, args))\n\t\trequire.NoError(t, validateArgs([]string{}, args))\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) YAMLEq(expected string, actual string, msgAndArgs ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tYAMLEq(a.t, expected, actual, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func (s *SshExecutor) DeviceTeardown(host, device, vgid string) error {\n\n\t// Setup commands\n\tcommands := []string{\n\t\tfmt.Sprintf(\"vgremove %v\", s.vgName(vgid)),\n\t\tfmt.Sprintf(\"pvremove %v\", device),\n\t}\n\n\t// Execute command\n\t_, err := s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\tlogger.LogError(\"Error while deleting device %v on %v with id %v\",\n\t\t\tdevice, host, vgid)\n\t}\n\n\tcommands = []string{\n\t\tfmt.Sprintf(\"ls %v/%v\", rootMountPoint, s.vgName(vgid)),\n\t}\n\t_, err = s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\tcommands = []string{\n\t\tfmt.Sprintf(\"rmdir %v/%v\", rootMountPoint, s.vgName(vgid)),\n\t}\n\n\t_, err = s.RemoteExecutor.RemoteCommandExecute(host, commands, 5)\n\tif err != nil {\n\t\tlogger.LogError(\"Error while removing the VG directory\")\n\t\treturn nil\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestDockerComposeGetComponent(t *testing.T) {\n\tvar scenarios = []struct {\n\t\tname string\n\t\twant bool\n\t}{\n\t\t{\"cronjob\", true},\n\t\t{\"messagebus\", true},\n\t\t{\"does_not_exist\", false},\n\t}\n\n\ttarget := NewComponents(platforms.DockerCompose, nil, \"testdata\")\n\n\tfor _, scenario := range scenarios {\n\t\tt.Run(fmt.Sprintf(\"Should load valid component - %t\", scenario.want), func(t *testing.T) {\n\t\t\tcomponent := target.GetComponent(\"\", scenario.name)\n\t\t\tassert.NotNil(t, component, \"Should always return something\")\n\n\t\t\tif scenario.want {\n\t\t\t\tassert.Equal(t, \"Component\", component.Kind, \"Should only return components\")\n\t\t\t\tassert.Equal(t, scenario.name, component.Name, \"Name should be set\")\n\t\t\t\tassert.NotEmpty(t, component.Type, \"When component valid, type is set\")\n\t\t\t} else {\n\t\t\t\tassert.Empty(t, component.Kind, \"When component not valid, kind is not set\")\n\t\t\t\tassert.Empty(t, component.Type, \"When component not valid, type is not set\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn utils.WithProcfd(rootfs, m.Destination, func(procfd string) error {\n\t\treturn mount(m.Source, m.Destination, procfd, m.Device, uintptr(m.Flags|unix.MS_REMOUNT), \"\")\n\t})", "is_vulnerable": 1}
{"code": "func pendingFromCallExpr(ce *ast.CallExpr) bool {\n\n\tpending := false\n\tif len(ce.Args) < 2 {\n\t\treturn pending\n\t}\n\n\tfor _, arg := range ce.Args[1:] {\n\t\tswitch expr := arg.(type) {\n\t\tcase *ast.CallExpr:\n\t\t\tid, ok := expr.Fun.(*ast.Ident)\n\t\t\tif !ok {\n\t\t\t\t// to skip over cases where the expr.Fun. is actually *ast.SelectorExpr\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif id.Name == \"Pending\" {\n\t\t\t\tpending = true\n\t\t\t}\n\t\tcase *ast.Ident:\n\t\t\tif expr.Name == \"Pending\" {\n\t\t\t\tpending = true\n\t\t\t}\n\t\t}\n\t}\n\treturn pending\n}", "is_vulnerable": 0}
{"code": "func (q *ListObjectsQuery) Execute(\n\tctx context.Context,\n\treq *openfgav1.ListObjectsRequest,\n) (*ListObjectsResponse, error) {\n\n\tresultsChan := make(chan ListObjectsResult, 1)\n\tmaxResults := q.listObjectsMaxResults\n\tif maxResults > 0 {\n\t\tresultsChan = make(chan ListObjectsResult, maxResults)\n\t}\n\n\ttimeoutCtx := ctx\n\tif q.listObjectsDeadline != 0 {\n\t\tvar cancel context.CancelFunc\n\t\ttimeoutCtx, cancel = context.WithTimeout(ctx, q.listObjectsDeadline)\n\t\tdefer cancel()\n\t}\n\n\tresolutionMetadata := reverseexpand.NewResolutionMetadata()\n\n\terr := q.evaluate(timeoutCtx, req, resultsChan, maxResults, resolutionMetadata)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tobjects := make([]string, 0)\n\n\tfor {\n\t\tselect {\n\n\t\tcase <-timeoutCtx.Done():\n\t\t\tq.logger.WarnWithContext(\n\t\t\t\tctx, fmt.Sprintf(\"list objects timeout after %s\", q.listObjectsDeadline.String()),\n\t\t\t)\n\t\t\treturn &ListObjectsResponse{\n\t\t\t\tObjects:            objects,\n\t\t\t\tResolutionMetadata: *resolutionMetadata,\n\t\t\t}, nil\n\n\t\tcase result, channelOpen := <-resultsChan:\n\t\t\tif result.Err != nil {\n\t\t\t\tif errors.Is(result.Err, serverErrors.AuthorizationModelResolutionTooComplex) {\n\t\t\t\t\treturn nil, result.Err\n\t\t\t\t}\n\n\t\t\t\treturn nil, serverErrors.HandleError(\"\", result.Err)\n\t\t\t}\n\n\t\t\tif !channelOpen {\n\t\t\t\treturn &ListObjectsResponse{\n\t\t\t\t\tObjects:            objects,\n\t\t\t\t\tResolutionMetadata: *resolutionMetadata,\n\t\t\t\t}, nil\n\t\t\t}\n\t\t\tobjects = append(objects, result.ObjectID)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func newServiceWithCommitSHA(root, revision string) *Service {\n\tvar revisionErr error\n\n\tcommitSHARegex := regexp.MustCompile(\"^[0-9A-Fa-f]{40}$\")\n\tif !commitSHARegex.MatchString(revision) {\n\t\trevisionErr = errors.New(\"not a commit SHA\")\n\t}\n\n\tservice, gitClient := newServiceWithOpt(func(gitClient *gitmocks.Client) {\n\t\tgitClient.On(\"Init\").Return(nil)\n\t\tgitClient.On(\"Fetch\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"Checkout\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"LsRemote\", revision).Return(revision, revisionErr)\n\t\tgitClient.On(\"CommitSHA\").Return(\"632039659e542ed7de0c170a4fcc1c571b288fc0\", nil)\n\t\tgitClient.On(\"Root\").Return(root)\n\t})\n\n\tservice.newGitClient = func(rawRepoURL string, creds git.Creds, insecure bool, enableLfs bool, proxy string, opts ...git.ClientOpts) (client git.Client, e error) {\n\t\treturn gitClient, nil\n\t}\n\n\treturn service\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) LootRm(ctx context.Context, in *clientpb.Loot, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_LootRm_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (fp *FileProvider) SessionRead(sid string) (Store, error) {\n\tif strings.ContainsAny(sid, \"./\") {\n\t\treturn nil, nil\n\t}\n\tif len(sid) < 2 {\n\t\treturn nil, errors.New(\"length of the sid is less than 2\")\n\t}\n\tfilepder.lock.Lock()\n\tdefer filepder.lock.Unlock()\n\n\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0755)\n\tif err != nil {\n\t\tSLogger.Println(err.Error())\n\t}\n\t_, err = os.Stat(path.Join(fp.savePath, string(sid[0]), string(sid[1]), sid))\n\tvar f *os.File\n\tif err == nil {\n\t\tf, err = os.OpenFile(path.Join(fp.savePath, string(sid[0]), string(sid[1]), sid), os.O_RDWR, 0777)\n\t} else if os.IsNotExist(err) {\n\t\tf, err = os.Create(path.Join(fp.savePath, string(sid[0]), string(sid[1]), sid))\n\t} else {\n\t\treturn nil, err\n\t}\n\n\tdefer f.Close()\n\n\tos.Chtimes(path.Join(fp.savePath, string(sid[0]), string(sid[1]), sid), time.Now(), time.Now())\n\tvar kv map[interface{}]interface{}\n\tb, err := ioutil.ReadAll(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(b) == 0 {\n\t\tkv = make(map[interface{}]interface{})\n\t} else {\n\t\tkv, err = DecodeGob(b)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tss := &FileSessionStore{sid: sid, values: kv}\n\treturn ss, nil\n}", "is_vulnerable": 0}
{"code": "func (dag *DAG) EnsureService(meta types.NamespacedName, port intstr.IntOrString, cache *KubernetesCache) (*Service, error) {\n\tsvc, svcPort, err := cache.LookupService(meta, port)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif dagSvc := dag.GetService(k8s.NamespacedNameOf(svc), svcPort.Port); dagSvc != nil {\n\t\treturn dagSvc, nil\n\t}\n\n\tdagSvc := &Service{\n\t\tWeighted: WeightedService{\n\t\t\tServiceName:      svc.Name,\n\t\t\tServiceNamespace: svc.Namespace,\n\t\t\tServicePort:      svcPort,\n\t\t\tWeight:           1,\n\t\t},\n\t\tProtocol:           upstreamProtocol(svc, svcPort),\n\t\tMaxConnections:     annotation.MaxConnections(svc),\n\t\tMaxPendingRequests: annotation.MaxPendingRequests(svc),\n\t\tMaxRequests:        annotation.MaxRequests(svc),\n\t\tMaxRetries:         annotation.MaxRetries(svc),\n\t\tExternalName:       externalName(svc),\n\t}\n\treturn dagSvc, nil\n}", "is_vulnerable": 1}
{"code": "func TestAdd(t *testing.T) {\n\ttest.EnsurePrivilege(t)\n\n\tfor _, e := range instanceTests {\n\t\tvar err error\n\t\tvar file *File\n\n\t\tfile, err = Add(e.name, e.privileged, testSubDir)\n\t\tif err != nil && !e.expectFailure {\n\t\t\tt.Errorf(\"unexpected failure for name %s: %s\", e.name, err)\n\t\t} else if err == nil && e.expectFailure {\n\t\t\tt.Errorf(\"unexpected success for name %s\", e.name)\n\t\t}\n\t\tif file != nil {\n\t\t\tfile.User = \"root\"\n\t\t\tfile.Pid = os.Getpid()\n\t\t\tif err := file.Update(); err != nil {\n\t\t\t\tt.Errorf(\"error while creating instance %s: %s\", e.name, err)\n\t\t\t}\n\t\t\tif err := file.MountNamespaces(); err != nil {\n\t\t\t\tt.Errorf(\"error while mounting namespaces: %s\", err)\n\t\t\t}\n\t\t\terr := file.UpdateNamespacesPath([]specs.LinuxNamespace{})\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"unexpected success while updating namespace paths\")\n\t\t\t}\n\t\t\t// should always fail with 'no command line match found'\n\t\t\tfile.PPid = file.Pid\n\t\t\terr = file.UpdateNamespacesPath([]specs.LinuxNamespace{})\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"unexpected success while updating namespace paths\")\n\t\t\t}\n\t\t\tstdout, stderr, err := SetLogFile(e.name, 0, testSubDir)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"error while creating instance log file: %s\", err)\n\t\t\t}\n\t\t\tif err := os.Remove(stdout.Name()); err != nil {\n\t\t\t\tt.Errorf(\"error while delete instance log out file: %s\", err)\n\t\t\t}\n\t\t\tif err := os.Remove(stderr.Name()); err != nil {\n\t\t\t\tt.Errorf(\"error while deleting instance log err file: %s\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func ResetDefaultSanitizerForTesting() {\n\tdefaultSanitizer = nil\n\tdefaultSanitizerOnce = sync.Once{}\n}", "is_vulnerable": 0}
{"code": "func (r *CountedReader) BytesRead() int64 {\n\treturn r.counter.Load()\n}", "is_vulnerable": 0}
{"code": "func TestImportExtremelyLargeImageWorks(t *testing.T) {\n\tif runtime.GOARCH == \"arm64\" {\n\t\tt.Skip(\"effective test will be time out\")\n\t}\n\n\tclient := request.NewAPIClient(t)\n\n\t// Construct an empty tar archive with about 8GB of junk padding at the\n\t// end. This should not cause any crashes (the padding should be mostly\n\t// ignored).\n\tvar tarBuffer bytes.Buffer\n\n\ttw := tar.NewWriter(&tarBuffer)\n\tif err := tw.Close(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\timageRdr := io.MultiReader(&tarBuffer, io.LimitReader(testutil.DevZero, 8*1024*1024*1024))\n\n\t_, err := client.ImageImport(context.Background(),\n\t\ttypes.ImageImportSource{Source: imageRdr, SourceName: \"-\"},\n\t\t\"test1234:v42\",\n\t\ttypes.ImageImportOptions{})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *client) PlanBuild(ctx context.Context) error {\n\t// defer taking a snapshot of the build\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/worker/internal/build#Snapshot\n\tdefer func() { build.Snapshot(c.build, c.Vela, c.err, c.Logger, c.repo) }()\n\n\t// load the init step from the client\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/worker/internal/step#Load\n\t_init, err := step.Load(c.init, &c.steps)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// load the logs for the init step from the client\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/worker/internal/step#LoadLogs\n\t_log, err := step.LoadLogs(c.init, &c.stepLogs)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// put worker information into init logs\n\t_log.AppendData([]byte(fmt.Sprintf(\"> Worker Information:\\n Host: %s\\n Version: %s\\n Runtime: %s\\n\", c.Hostname, c.Version, c.Runtime.Driver())))\n\n\t// defer taking a snapshot of the init step\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/worker/internal/step#SnapshotInit\n\tdefer func() {\n\t\tif c.err != nil {\n\t\t\t_init.SetStatus(constants.StatusFailure)\n\t\t}\n\n\t\tstep.SnapshotInit(c.init, c.build, c.Vela, c.Logger, c.repo, _init, _log)\n\t}()\n\n\tc.Logger.Info(\"creating network\")\n\t// create the runtime network for the pipeline\n\tc.err = c.Runtime.CreateNetwork(ctx, c.pipeline)\n\tif c.err != nil {\n\t\treturn fmt.Errorf(\"unable to create network: %w\", c.err)\n\t}\n\n\t// update the init log with progress\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/library#Log.AppendData\n\t_log.AppendData([]byte(\"> Inspecting runtime network...\\n\"))\n\n\t// inspect the runtime network for the pipeline\n\tnetwork, err := c.Runtime.InspectNetwork(ctx, c.pipeline)\n\tif err != nil {\n\t\tc.err = err\n\t\treturn fmt.Errorf(\"unable to inspect network: %w\", err)\n\t}\n\n\t// update the init log with network information\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/library#Log.AppendData\n\t_log.AppendData(network)\n\n\tc.Logger.Info(\"creating volume\")\n\t// create the runtime volume for the pipeline\n\tc.err = c.Runtime.CreateVolume(ctx, c.pipeline)\n\tif c.err != nil {\n\t\treturn fmt.Errorf(\"unable to create volume: %w\", c.err)\n\t}\n\n\t// update the init log with progress\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/library#Log.AppendData\n\t_log.AppendData([]byte(\"> Inspecting runtime volume...\\n\"))\n\n\t// inspect the runtime volume for the pipeline\n\tvolume, err := c.Runtime.InspectVolume(ctx, c.pipeline)\n\tif err != nil {\n\t\tc.err = err\n\t\treturn fmt.Errorf(\"unable to inspect volume: %w\", err)\n\t}\n\n\t// update the init log with volume information\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/library#Log.AppendData\n\t_log.AppendData(volume)\n\n\t// update the init log with progress\n\t//\n\t// https://pkg.go.dev/github.com/go-vela/types/library#Log.AppendData\n\t_log.AppendData([]byte(\"> Preparing secrets...\\n\"))\n\n\t// iterate through each secret provided in the pipeline\n\tfor _, secret := range c.pipeline.Secrets {\n\t\t// ignore pulling secrets coming from plugins\n\t\tif !secret.Origin.Empty() {\n\t\t\tcontinue\n\t\t}\n\n\t\t// only pull in secrets that are set to be pulled in at the start\n\t\tif strings.EqualFold(secret.Pull, constants.SecretPullStep) {\n\t\t\t_log.AppendData([]byte(fmt.Sprintf(\"> Skipping pull: secret <%s> lazy loaded\\n\", secret.Name)))\n\n\t\t\tcontinue\n\t\t}\n\n\t\tc.Logger.Infof(\"pulling secret: %s\", secret.Name)\n\n\t\ts, err := c.secret.pull(secret)\n\t\tif err != nil {\n\t\t\tc.err = err\n\t\t\treturn fmt.Errorf(\"unable to pull secrets: %w\", err)\n\t\t}\n\n\t\t_log.AppendData([]byte(\n\t\t\tfmt.Sprintf(\"$ vela view secret --secret.engine %s --secret.type %s --org %s --repo %s --name %s \\n\",\n\t\t\t\tsecret.Engine, secret.Type, s.GetOrg(), s.GetRepo(), s.GetName())))\n\n\t\tsRaw, err := json.MarshalIndent(s.Sanitize(), \"\", \" \")\n\t\tif err != nil {\n\t\t\tc.err = err\n\t\t\treturn fmt.Errorf(\"unable to decode secret: %w\", err)\n\t\t}\n\n\t\t_log.AppendData(append(sRaw, \"\\n\"...))\n\n\t\t// add secret to the map\n\t\tc.Secrets[secret.Name] = s\n\t}\n\n\t// escape newlines in secrets loaded on build_start\n\tescapeNewlineSecrets(c.Secrets)\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (a servicePrincipalClientSecretAuth) getAuthorizationToken(oauthConfig *adal.OAuthConfig, endpoint string) (*autorest.BearerAuthorizer, error) {\n\tspt, err := adal.NewServicePrincipalToken(*oauthConfig, a.clientId, a.clientSecret, endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauth := autorest.NewBearerAuthorizer(spt)\n\treturn auth, nil\n}", "is_vulnerable": 1}
{"code": "func BenchmarkGetHubForUserId(b *testing.B) {\n\tth := Setup(b).InitBasic()\n\tdefer th.TearDown()\n\n\tth.Service.Start(nil)\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\thubSink = th.Service.GetHubForUserId(th.BasicUser.Id)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (sch *scheme) Encapsulate(pk kem.PublicKey) (ct []byte, ss []byte, err error) {\n\tvar seed [EncapsulationSeedSize]byte\n\tif _, err := cryptoRand.Read(seed[:]); err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn sch.EncapsulateDeterministically(pk, seed[:])\n}", "is_vulnerable": 0}
{"code": "func parseReferenceCrane(ctx context.Context, ref string, registryClient registryclient.Client) (*parsedReference, error) {\n\tnameRef, err := name.ParseReference(ref)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tauthenticator, err := getAuthenticator(ctx, ref, registryClient)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcraneOpts := crane.WithAuth(*authenticator)\n\tremoteOpts, err := getRemoteOpts(*authenticator)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdesc, err := crane.Head(ref, craneOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif !isDigestReference(ref) {\n\t\tnameRef, err = name.ParseReference(GetReferenceFromDescriptor(v1ToOciSpecDescriptor(*desc), nameRef))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\trepository := NewRepository(craneOpts, remoteOpts, nameRef)\n\terr = resolveDigestCrane(repository, craneOpts, remoteOpts, nameRef)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to resolve digest\")\n\t}\n\n\treturn &parsedReference{\n\t\tRepo:       repository,\n\t\tCraneOpts:  craneOpts,\n\t\tRemoteOpts: remoteOpts,\n\t\tRef:        nameRef,\n\t\tDesc:       v1ToOciSpecDescriptor(*desc),\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Client) blobAndFileSASURI(options SASOptions, uri, permissions, canonicalizedResource, signedResource string, headers OverrideHeaders) (string, error) {\n\tstart := \"\"\n\tif options.Start != (time.Time{}) {\n\t\tstart = options.Start.UTC().Format(time.RFC3339)\n\t}\n\n\texpiry := options.Expiry.UTC().Format(time.RFC3339)\n\n\t// We need to replace + with %2b first to avoid being treated as a space (which is correct for query strings, but not the path component).\n\tcanonicalizedResource = strings.Replace(canonicalizedResource, \"+\", \"%2b\", -1)\n\tcanonicalizedResource, err := url.QueryUnescape(canonicalizedResource)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tprotocols := \"\"\n\tif options.UseHTTPS {\n\t\tprotocols = \"https\"\n\t}\n\tstringToSign, err := blobSASStringToSign(permissions, start, expiry, canonicalizedResource, options.Identifier, options.IP, protocols, c.apiVersion, headers)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tsig := c.computeHmac256(stringToSign)\n\tsasParams := url.Values{\n\t\t\"sv\":  {c.apiVersion},\n\t\t\"se\":  {expiry},\n\t\t\"sr\":  {signedResource},\n\t\t\"sp\":  {permissions},\n\t\t\"sig\": {sig},\n\t}\n\n\tif start != \"\" {\n\t\tsasParams.Add(\"st\", start)\n\t}\n\n\tif c.apiVersion >= \"2015-04-05\" {\n\t\tif protocols != \"\" {\n\t\t\tsasParams.Add(\"spr\", protocols)\n\t\t}\n\t\tif options.IP != \"\" {\n\t\t\tsasParams.Add(\"sip\", options.IP)\n\t\t}\n\t}\n\n\t// Add override response hedaers\n\taddQueryParameter(sasParams, \"rscc\", headers.CacheControl)\n\taddQueryParameter(sasParams, \"rscd\", headers.ContentDisposition)\n\taddQueryParameter(sasParams, \"rsce\", headers.ContentEncoding)\n\taddQueryParameter(sasParams, \"rscl\", headers.ContentLanguage)\n\taddQueryParameter(sasParams, \"rsct\", headers.ContentType)\n\n\tsasURL, err := url.Parse(uri)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tsasURL.RawQuery = sasParams.Encode()\n\treturn sasURL.String(), nil\n}", "is_vulnerable": 1}
{"code": "func (e *EngineInfo) Protocol() Protocol {\n\treturn Protocol(e.info.protocol)\n}", "is_vulnerable": 1}
{"code": "\tt.Run(desc, func(t *testing.T) {\n\t\tctx := web.Context{Req: &http.Request{}}\n\t\torgID := int64(1)\n\t\trole := models.ROLE_ADMIN\n\t\tsqlStore := sqlstore.InitTestDB(t)\n\t\tservice := LibraryElementService{\n\t\t\tCfg:      setting.NewCfg(),\n\t\t\tSQLStore: sqlStore,\n\t\t}\n\n\t\tuser := models.SignedInUser{\n\t\t\tUserId:     1,\n\t\t\tName:       \"Signed In User\",\n\t\t\tLogin:      \"signed_in_user\",\n\t\t\tEmail:      \"signed.in.user@test.com\",\n\t\t\tOrgId:      orgID,\n\t\t\tOrgRole:    role,\n\t\t\tLastSeenAt: time.Now(),\n\t\t}\n\n\t\t// deliberate difference between signed in user and user in db to make it crystal clear\n\t\t// what to expect in the tests\n\t\t// In the real world these are identical\n\t\tcmd := models.CreateUserCommand{\n\t\t\tEmail: \"user.in.db@test.com\",\n\t\t\tName:  \"User In DB\",\n\t\t\tLogin: userInDbName,\n\t\t}\n\n\t\t_, err := sqlStore.CreateUser(context.Background(), cmd)\n\t\trequire.NoError(t, err)\n\n\t\tsc := scenarioContext{\n\t\t\tuser:     user,\n\t\t\tctx:      &ctx,\n\t\t\tservice:  &service,\n\t\t\tsqlStore: sqlStore,\n\t\t\treqContext: &models.ReqContext{\n\t\t\t\tContext:      &ctx,\n\t\t\t\tSignedInUser: &user,\n\t\t\t},\n\t\t}\n\n\t\tsc.folder = createFolderWithACL(t, sc.sqlStore, \"ScenarioFolder\", sc.user, []folderACLItem{})\n\n\t\tfn(t, sc)\n\t})", "is_vulnerable": 1}
{"code": "func NewBitfield(size int) Bitfield {\n\tif size%8 != 0 {\n\t\tpanic(\"Bitfield size must be a multiple of 8\")\n\t}\n\treturn make([]byte, size/8)\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetOperators(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.Operators, error) {\n\tout := new(clientpb.Operators)\n\terr := c.cc.Invoke(ctx, SliverRPC_GetOperators_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (d *driver) newNodeServer() *nodeServer {\n\treturn &nodeServer{\n\t\tnodeId:               d.nodeId,\n\t\tDefaultNodeServer:    csicommon.NewDefaultNodeServer(d.csiDriver),\n\t\tclient:               d.client,\n\t\tapiReader:            d.apiReader,\n\t\tnodeAuthorizedClient: d.nodeAuthorizedClient,\n\t}\n}", "is_vulnerable": 0}
{"code": "func introducerCast(e eval, col collations.ID) (*evalBytes, error) {\n\tif col == collations.CollationBinaryID {\n\t\treturn evalToBinary(e), nil\n\t}\n\n\tvar bytes []byte\n\tif b, ok := e.(*evalBytes); !ok {\n\t\tbytes = b.ToRawBytes()\n\t} else {\n\t\tcs := col.Get().Charset()\n\t\tbytes = b.bytes\n\t\t// We only need to pad here for encodings that have a minimum\n\t\t// character byte width larger than 1, which is all UTF-16\n\t\t// variations and UTF-32.\n\t\tswitch cs.(type) {\n\t\tcase charset.Charset_utf16, charset.Charset_utf16le, charset.Charset_ucs2:\n\t\t\tif len(bytes)%2 != 0 {\n\t\t\t\tbytes = append([]byte{0}, bytes...)\n\t\t\t}\n\t\tcase charset.Charset_utf32:\n\t\t\tif mod := len(bytes) % 4; mod != 0 {\n\t\t\t\tbytes = append(make([]byte, 4-mod), bytes...)\n\t\t\t}\n\t\t}\n\t}\n\ttypedcol := collations.TypedCollation{\n\t\tCollation:    col,\n\t\tCoercibility: collations.CoerceCoercible,\n\t\tRepertoire:   collations.RepertoireASCII,\n\t}\n\treturn newEvalText(bytes, typedcol), nil\n}", "is_vulnerable": 0}
{"code": "func TestHttpGetter__XTerraformGetLimit(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tln := testHttpServerWithXTerraformGetLoop(t)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/loop\"\n\n\tdst := testing_helper.TempDir(t)\n\tdefer os.RemoveAll(dst)\n\n\tg := new(HttpGetter)\n\tg.XTerraformGetLimit = 10\n\tg.Client = &http.Client{}\n\n\treq := Request{\n\t\tDst:     dst,\n\t\tu:       &u,\n\t\tGetMode: ModeDir,\n\t}\n\n\terr := g.Get(ctx, &req)\n\tif !strings.Contains(err.Error(), \"too many X-Terraform-Get redirects\") {\n\t\tt.Fatalf(\"too many X-Terraform-Get redirects, got: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) BuilderRegister(ctx context.Context, in *clientpb.Builder, opts ...grpc.CallOption) (SliverRPC_BuilderRegisterClient, error) {\n\tstream, err := c.cc.NewStream(ctx, &SliverRPC_ServiceDesc.Streams[1], SliverRPC_BuilderRegister_FullMethodName, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tx := &sliverRPCBuilderRegisterClient{stream}\n\tif err := x.ClientStream.SendMsg(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := x.ClientStream.CloseSend(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn x, nil\n}", "is_vulnerable": 1}
{"code": "func (f *Frontend) SendExecute(msg *Execute) {\n\tif f.encodeError != nil {\n\t\treturn\n\t}\n\n\tprevLen := len(f.wbuf)\n\tnewBuf, err := msg.Encode(f.wbuf)\n\tif err != nil {\n\t\tf.encodeError = err\n\t\treturn\n\t}\n\tf.wbuf = newBuf\n\n\tif f.tracer != nil {\n\t\tf.tracer.TraceQueryute('F', int32(len(f.wbuf)-prevLen), msg)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestMqttAdaptorConnectError(t *testing.T) {\n\ta := NewAdaptor(\"tcp://localhost:1884\", \"client\")\n\n\terr := a.Connect()\n\tgobottest.Assert(t, strings.Contains(err.Error(), \"connection refused\"), true)\n}", "is_vulnerable": 0}
{"code": "func TestAddDebug(t *testing.T) {\n\terr := ErrRevocationClientMismatch.WithDebug(\"debug\")\n\tassert.NotEqual(t, err, ErrRevocationClientMismatch)\n\tassert.Empty(t, ErrRevocationClientMismatch.Debug)\n\tassert.NotEmpty(t, err.Debug)\n}", "is_vulnerable": 1}
{"code": "func (ctx *Ctx) AuthZRequest(w http.ResponseWriter, r *http.Request) error {\n\tvar body []byte\n\tif sendBody(ctx.requestURI, r.Header) && r.ContentLength > 0 && r.ContentLength < maxBodySize {\n\t\tvar err error\n\t\tbody, r.Body, err = drainBody(r.Body)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tvar h bytes.Buffer\n\tif err := r.Header.Write(&h); err != nil {\n\t\treturn err\n\t}\n\n\tctx.authReq = &Request{\n\t\tUser:            ctx.user,\n\t\tUserAuthNMethod: ctx.userAuthNMethod,\n\t\tRequestMethod:   ctx.requestMethod,\n\t\tRequestURI:      ctx.requestURI,\n\t\tRequestBody:     body,\n\t\tRequestHeaders:  headers(r.Header),\n\t}\n\n\tif r.TLS != nil {\n\t\tfor _, c := range r.TLS.PeerCertificates {\n\t\t\tpc := PeerCertificate(*c)\n\t\t\tctx.authReq.RequestPeerCertificates = append(ctx.authReq.RequestPeerCertificates, &pc)\n\t\t}\n\t}\n\n\tfor _, plugin := range ctx.plugins {\n\t\tlogrus.Debugf(\"AuthZ request using plugin %s\", plugin.Name())\n\n\t\tauthRes, err := plugin.AuthZRequest(ctx.authReq)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"plugin %s failed with error: %s\", plugin.Name(), err)\n\t\t}\n\n\t\tif !authRes.Allow {\n\t\t\treturn newAuthorizationError(plugin.Name(), authRes.Msg)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_CommonTLSConfigPreferServerCipherSuites(t *testing.T) {\n\tc, err := NewConfigurator(Config{}, nil)\n\trequire.NoError(t, err)\n\ttlsConf := c.commonTLSConfig(false)\n\trequire.False(t, tlsConf.PreferServerCipherSuites)\n\n\trequire.NoError(t, c.Update(Config{PreferServerCipherSuites: false}))\n\ttlsConf = c.commonTLSConfig(false)\n\trequire.False(t, tlsConf.PreferServerCipherSuites)\n\n\trequire.NoError(t, c.Update(Config{PreferServerCipherSuites: true}))\n\ttlsConf = c.commonTLSConfig(false)\n\trequire.True(t, tlsConf.PreferServerCipherSuites)\n}", "is_vulnerable": 0}
{"code": "func (r *Runtime) setupRootlessPortMapping(ctr *Container, netnsPath string) (err error) {\n\tsyncR, syncW, err := os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open pipe\")\n\t}\n\tdefer errorhandling.CloseQuiet(syncR)\n\tdefer errorhandling.CloseQuiet(syncW)\n\n\tlogPath := filepath.Join(ctr.runtime.config.TmpDir, fmt.Sprintf(\"rootlessport-%s.log\", ctr.config.ID))\n\tlogFile, err := os.Create(logPath)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to open rootlessport log file %s\", logPath)\n\t}\n\tdefer logFile.Close()\n\t// Unlink immediately the file so we won't need to worry about cleaning it up later.\n\t// It is still accessible through the open fd logFile.\n\tif err := os.Remove(logPath); err != nil {\n\t\treturn errors.Wrapf(err, \"delete file %s\", logPath)\n\t}\n\n\tctr.rootlessPortSyncR, ctr.rootlessPortSyncW, err = os.Pipe()\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"failed to create rootless port sync pipe\")\n\t}\n\tcfg := rootlessport.Config{\n\t\tMappings:  ctr.config.PortMappings,\n\t\tNetNSPath: netnsPath,\n\t\tExitFD:    3,\n\t\tReadyFD:   4,\n\t}\n\tcfgJSON, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcfgR := bytes.NewReader(cfgJSON)\n\tvar stdout bytes.Buffer\n\tcmd := exec.Command(fmt.Sprintf(\"/proc/%d/exe\", os.Getpid()))\n\tcmd.Args = []string{rootlessport.ReexecKey}\n\t// Leak one end of the pipe in rootlessport process, the other will be sent to conmon\n\tcmd.ExtraFiles = append(cmd.ExtraFiles, ctr.rootlessPortSyncR, syncW)\n\tcmd.Stdin = cfgR\n\t// stdout is for human-readable error, stderr is for debug log\n\tcmd.Stdout = &stdout\n\tcmd.Stderr = io.MultiWriter(logFile, &logrusDebugWriter{\"rootlessport: \"})\n\tcmd.SysProcAttr = &syscall.SysProcAttr{\n\t\tSetpgid: true,\n\t}\n\tif err := cmd.Start(); err != nil {\n\t\treturn errors.Wrapf(err, \"failed to start rootlessport process\")\n\t}\n\tdefer func() {\n\t\tif err := cmd.Process.Release(); err != nil {\n\t\t\tlogrus.Errorf(\"unable to release rootlessport process: %q\", err)\n\t\t}\n\t}()\n\tif err := waitForSync(syncR, cmd, logFile, 3*time.Second); err != nil {\n\t\tstdoutStr := stdout.String()\n\t\tif stdoutStr != \"\" {\n\t\t\t// err contains full debug log and too verbose, so return stdoutStr\n\t\t\tlogrus.Debug(err)\n\t\t\treturn errors.Errorf(\"failed to expose ports via rootlessport: %q\", stdoutStr)\n\t\t}\n\t\treturn err\n\t}\n\tlogrus.Debug(\"rootlessport is ready\")\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func UnZip(zipFile string, destPath string) error {\n\tzipReader, err := zip.OpenReader(zipFile)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer zipReader.Close()\n\n\tfor _, f := range zipReader.File {\n\t\t//issue#62: fix ZipSlip bug\n\t\tpath, err := safeFilepathJoin(destPath, f.Name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif f.FileInfo().IsDir() {\n\t\t\tos.MkdirAll(path, os.ModePerm)\n\t\t} else {\n\t\t\tif err = os.MkdirAll(filepath.Dir(path), os.ModePerm); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tinFile, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer inFile.Close()\n\n\t\t\toutFile, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, f.Mode())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer outFile.Close()\n\n\t\t\t_, err = io.Copy(outFile, inFile)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (d *Decoder) Read() (Token, error) {\n\tconst scalar = Null | Bool | Number | String\n\n\tdefer func() { d.lastCall = readCall }()\n\tif d.lastCall == peekCall {\n\t\treturn d.lastToken, d.lastErr\n\t}\n\n\ttok, err := d.parseNext()\n\tif err != nil {\n\t\treturn Token{}, err\n\t}\n\n\tswitch tok.kind {\n\tcase EOF:\n\t\tif len(d.openStack) != 0 ||\n\t\t\td.lastToken.kind&scalar|ObjectClose|ArrayClose == 0 {\n\t\t\treturn Token{}, ErrUnexpectedEOF\n\t\t}\n\n\tcase Null:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\n\tcase Bool, Number:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\n\tcase String:\n\t\tif d.isValueNext() {\n\t\t\tbreak\n\t\t}\n\t\t// This string token should only be for a field name.\n\t\tif d.lastToken.kind&(ObjectOpen|comma) == 0 {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\tif len(d.in) == 0 {\n\t\t\treturn Token{}, ErrUnexpectedEOF\n\t\t}\n\t\tif c := d.in[0]; c != ':' {\n\t\t\treturn Token{}, d.newSyntaxError(d.currPos(), `unexpected character %s, missing \":\" after field name`, string(c))\n\t\t}\n\t\ttok.kind = Name\n\t\td.consume(1)\n\n\tcase ObjectOpen, ArrayOpen:\n\t\tif !d.isValueNext() {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = append(d.openStack, tok.kind)\n\n\tcase ObjectClose:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind == comma ||\n\t\t\td.openStack[len(d.openStack)-1] != ObjectOpen {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = d.openStack[:len(d.openStack)-1]\n\n\tcase ArrayClose:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind == comma ||\n\t\t\td.openStack[len(d.openStack)-1] != ArrayOpen {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t\td.openStack = d.openStack[:len(d.openStack)-1]\n\n\tcase comma:\n\t\tif len(d.openStack) == 0 ||\n\t\t\td.lastToken.kind&(scalar|ObjectClose|ArrayClose) == 0 {\n\t\t\treturn Token{}, d.newSyntaxError(tok.pos, unexpectedFmt, tok.RawString())\n\t\t}\n\t}\n\n\t// Update d.lastToken only after validating token to be in the right sequence.\n\td.lastToken = tok\n\n\tif d.lastToken.kind == comma {\n\t\treturn d.Read()\n\t}\n\treturn tok, nil\n}", "is_vulnerable": 1}
{"code": "\t\tgo func(id int) {\n\t\t\tdefer pend.Done()\n\n\t\t\t// Create a hasher to reuse between invocations\n\t\t\tkeccak512 := makeHasher(sha3.NewLegacyKeccak512())\n\n\t\t\t// Calculate the data segment this thread should generate\n\t\t\tbatch := uint32((size + hashBytes*uint64(threads) - 1) / (hashBytes * uint64(threads)))\n\t\t\tfirst := uint32(id) * batch\n\t\t\tlimit := first + batch\n\t\t\tif limit > uint32(size/hashBytes) {\n\t\t\t\tlimit = uint32(size / hashBytes)\n\t\t\t}\n\t\t\t// Calculate the dataset segment\n\t\t\tpercent := size / hashBytes / 100\n\t\t\tfor index := first; index < limit; index++ {\n\t\t\t\titem := generateDatasetItem(cache, index, keccak512)\n\t\t\t\tif swapped {\n\t\t\t\t\tswap(item)\n\t\t\t\t}\n\t\t\t\tcopy(dataset[index*hashBytes:], item)\n\n\t\t\t\tif status := atomic.AddUint64(&progress, 1); status%percent == 0 {\n\t\t\t\t\tlogger.Info(\"Generating DAG in progress\", \"percentage\", (status*100)/(size/hashBytes), \"elapsed\", common.PrettyDuration(time.Since(start)))\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)", "is_vulnerable": 1}
{"code": "func Implements(t TestingT, interfaceObject interface{}, object interface{}, msgAndArgs ...interface{}) {\n\tif assert.Implements(t, interfaceObject, object, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (a alias) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "\tmakeAny := func(m proto.Message) *anypb.Any {\n\t\tv, err := anypb.New(m)\n\t\trequire.NoError(t, err)\n\t\treturn v\n\t}\n\ttests := map[string]struct {\n\t\tfilter          *envoy_listener_v3.Filter\n\t\tisInboundFilter bool\n\t\texpectFilter    *envoy_listener_v3.Filter\n\t\texpectBool      bool\n\t\texpectErr       string\n\t}{\n\t\t\"invalid filter name is ignored\": {\n\t\t\tfilter:       &envoy_listener_v3.Filter{Name: \"something\"},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{Name: \"something\"},\n\t\t\texpectBool:   false,\n\t\t},\n\t\t\"error getting typed config\": {\n\t\t\tfilter:       &envoy_listener_v3.Filter{Name: \"envoy.filters.network.http_connection_manager\"},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{Name: \"envoy.filters.network.http_connection_manager\"},\n\t\t\texpectBool:   false,\n\t\t\texpectErr:    \"error getting typed config for http filter\",\n\t\t},\n\t\t\"error getting http connection manager\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: &anypb.Any{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: &anypb.Any{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: false,\n\t\t\texpectErr:  \"error unmarshalling filter\",\n\t\t},\n\t\t\"StripAnyHostPort is set\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tStripPortMode: &envoy_http_v3.HttpConnectionManager_StripAnyHostPort{\n\t\t\t\t\t\t\tStripAnyHostPort: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: true,\n\t\t},\n\t\t\"lambda filter injected correctly\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tStripPortMode: &envoy_http_v3.HttpConnectionManager_StripAnyHostPort{\n\t\t\t\t\t\t\tStripAnyHostPort: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName: \"envoy.filters.http.aws_lambda\",\n\t\t\t\t\t\t\t\tConfigType: &envoy_http_v3.HttpFilter_TypedConfig{TypedConfig: makeAny(\n\t\t\t\t\t\t\t\t\t&envoy_lambda_v3.Config{\n\t\t\t\t\t\t\t\t\t\tArn:                \"some-arn\",\n\t\t\t\t\t\t\t\t\t\tPayloadPassthrough: true,\n\t\t\t\t\t\t\t\t\t\tInvocationMode:     envoy_lambda_v3.Config_ASYNCHRONOUS,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t)},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectBool: true,\n\t\t},\n\t\t\"inbound filter ignored\": {\n\t\t\tfilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectFilter: &envoy_listener_v3.Filter{\n\t\t\t\tName: \"envoy.filters.network.http_connection_manager\",\n\t\t\t\tConfigType: &envoy_listener_v3.Filter_TypedConfig{\n\t\t\t\t\tTypedConfig: makeAny(&envoy_http_v3.HttpConnectionManager{\n\t\t\t\t\t\tHttpFilters: []*envoy_http_v3.HttpFilter{\n\t\t\t\t\t\t\t{Name: \"one\"},\n\t\t\t\t\t\t\t{Name: \"two\"},\n\t\t\t\t\t\t\t{Name: \"envoy.filters.http.router\"},\n\t\t\t\t\t\t\t{Name: \"three\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t\t},\n\t\t\t},\n\t\t\tisInboundFilter: true,\n\t\t\texpectBool:      false,\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tl := awsLambda{\n\t\t\t\tARN:                \"some-arn\",\n\t\t\t\tPayloadPassthrough: true,\n\t\t\t\tInvocationMode:     \"asynchronous\",\n\t\t\t}\n\t\t\tf, ok, err := l.PatchFilter(nil, tc.filter, tc.isInboundFilter)\n\t\t\trequire.Equal(t, tc.expectBool, ok)\n\t\t\tif tc.expectErr == \"\" {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t} else {\n\t\t\t\trequire.ErrorContains(t, err, tc.expectErr)\n\t\t\t}\n\t\t\tprototest.AssertDeepEqual(t, tc.expectFilter, f)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func newFalse() *bool {\n\tb := false\n\treturn &b\n}", "is_vulnerable": 1}
{"code": "func ToMalfeasancePB(nodeID types.NodeID, mp *wire.MalfeasanceProof, includeProof bool) *pb.MalfeasanceProof {\n\tif mp == nil {\n\t\treturn &pb.MalfeasanceProof{}\n\t}\n\tkind := pb.MalfeasanceProof_MALFEASANCE_UNSPECIFIED\n\tswitch mp.Proof.Type {\n\tcase wire.MultipleATXs:\n\t\tkind = pb.MalfeasanceProof_MALFEASANCE_ATX\n\tcase wire.MultipleBallots:\n\t\tkind = pb.MalfeasanceProof_MALFEASANCE_BALLOT\n\tcase wire.HareEquivocation:\n\t\tkind = pb.MalfeasanceProof_MALFEASANCE_HARE\n\tcase wire.InvalidPostIndex:\n\t\tkind = pb.MalfeasanceProof_MALFEASANCE_POST_INDEX\n\tcase wire.InvalidPrevATX:\n\t\tkind = pb.MalfeasanceProof_MALFEASANCE_INCORRECT_PREV_ATX\n\t}\n\tresult := &pb.MalfeasanceProof{\n\t\tSmesherId: &pb.SmesherId{Id: nodeID.Bytes()},\n\t\tLayer:     &pb.LayerNumber{Number: mp.Layer.Uint32()},\n\t\tKind:      kind,\n\t\tDebugInfo: wire.MalfeasanceInfo(nodeID, mp),\n\t}\n\tif includeProof {\n\t\tdata, _ := codec.Encode(mp)\n\t\tresult.Proof = data\n\t}\n\treturn result\n}", "is_vulnerable": 0}
{"code": "func TestIterativeRandomDelayedSync(t *testing.T) {\n\t// Create a random trie to copy\n\tsrcDb, srcTrie, srcData := makeTestTrie()\n\n\t// Create a destination trie and sync with the scheduler\n\tdiskdb := memorydb.New()\n\ttriedb := NewDatabase(diskdb)\n\tsched := NewSync(srcTrie.Hash(), diskdb, nil, NewSyncBloom(1, diskdb))\n\n\tqueue := make(map[common.Hash]struct{})\n\tfor _, hash := range sched.Missing(10000) {\n\t\tqueue[hash] = struct{}{}\n\t}\n\tfor len(queue) > 0 {\n\t\t// Sync only half of the scheduled nodes, even those in random order\n\t\tresults := make([]SyncResult, 0, len(queue)/2+1)\n\t\tfor hash := range queue {\n\t\t\tdata, err := srcDb.Node(hash)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to retrieve node data for %x: %v\", hash, err)\n\t\t\t}\n\t\t\tresults = append(results, SyncResult{hash, data})\n\n\t\t\tif len(results) >= cap(results) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// Feed the retrieved results back and queue new tasks\n\t\tif _, index, err := sched.Process(results); err != nil {\n\t\t\tt.Fatalf(\"failed to process result #%d: %v\", index, err)\n\t\t}\n\t\tbatch := diskdb.NewBatch()\n\t\tif err := sched.Commit(batch); err != nil {\n\t\t\tt.Fatalf(\"failed to commit data: %v\", err)\n\t\t}\n\t\tbatch.Write()\n\t\tfor _, result := range results {\n\t\t\tdelete(queue, result.Hash)\n\t\t}\n\t\tfor _, hash := range sched.Missing(10000) {\n\t\t\tqueue[hash] = struct{}{}\n\t\t}\n\t}\n\t// Cross check that the two tries are in sync\n\tcheckTrieContents(t, triedb, srcTrie.Hash().Bytes(), srcData)\n}", "is_vulnerable": 1}
{"code": "func NewConnectionPool(address *url.URL, poolSize int) (*ConnectionPool, error) {\n\tcache, err := lru.NewWithEvict(poolSize, func(_, value interface{}) {\n\t\tconnectionPoolSize.Dec()\n\n\t\t// We attempt to gracefully close the connection\n\t\tconn, ok := value.(gitpod.APIInterface)\n\t\tif !ok {\n\t\t\tlog.Errorf(\"Failed to cast cache value to gitpod API Interface\")\n\t\t\treturn\n\t\t}\n\n\t\tcloseErr := conn.Close()\n\t\tif closeErr != nil {\n\t\t\tlog.Log.WithError(closeErr).Warn(\"Failed to close connection to server.\")\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create LRU cache: %w\", err)\n\t}\n\n\treturn &ConnectionPool{\n\t\tcache: cache,\n\t\tconnConstructor: func(token auth.Token) (gitpod.APIInterface, error) {\n\t\t\topts := gitpod.ConnectToServerOpts{\n\t\t\t\t// We're using Background context as we want the connection to persist beyond the lifecycle of a single request\n\t\t\t\tContext: context.Background(),\n\t\t\t\tLog:     log.Log,\n\t\t\t\tCloseHandler: func(_ error) {\n\t\t\t\t\tcache.Remove(token)\n\t\t\t\t\tconnectionPoolSize.Dec()\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tswitch token.Type {\n\t\t\tcase auth.AccessTokenType:\n\t\t\t\topts.Token = token.Value\n\t\t\tcase auth.CookieTokenType:\n\t\t\t\topts.Cookie = token.Value\n\t\t\t\topts.Origin = token.OriginHeader\n\t\t\tdefault:\n\t\t\t\treturn nil, errors.New(\"unknown token type\")\n\t\t\t}\n\n\t\t\tendpoint, err := getEndpointBasedOnToken(token, address)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to construct endpoint: %w\", err)\n\t\t\t}\n\n\t\t\tconn, err := gitpod.ConnectToServer(endpoint, opts)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to create new connection to server: %w\", err)\n\t\t\t}\n\n\t\t\treturn conn, nil\n\t\t},\n\t}, nil\n\n}", "is_vulnerable": 1}
{"code": "func (EmptyEvidencePool) Update(State, types.EvidenceList)              {}", "is_vulnerable": 1}
{"code": "func (m *NinRepNonByteCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNonByteCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepNonByteCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field1 = append(m.Field1, T{})\n\t\t\tif err := m.Field1[len(m.Field1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestEntryFormatter_Process(t *testing.T) {\n\ttests := map[string]struct {\n\t\tIsErrorExpected      bool\n\t\tExpectedErrorMessage string\n\t\tSubtype              subtype\n\t\tRequiredFormat       format\n\t\tData                 *logical.LogInput\n\t\tRootNamespace        bool\n\t}{\n\t\t\"json-request-no-data\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: cannot audit event (AuditRequest) with no data: invalid parameter\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 nil,\n\t\t},\n\t\t\"json-response-no-data\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: cannot audit event (AuditResponse) with no data: invalid parameter\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 nil,\n\t\t},\n\t\t\"json-request-basic-input\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse request from audit event: request to request-audit a nil request\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 &logical.LogInput{Type: \"magic\"},\n\t\t},\n\t\t\"json-response-basic-input\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse response from audit event: request to response-audit a nil request\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 &logical.LogInput{Type: \"magic\"},\n\t\t},\n\t\t\"json-request-basic-input-and-request-no-ns\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse request from audit event: no namespace\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t},\n\t\t\"json-response-basic-input-and-request-no-ns\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse response from audit event: no namespace\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONFormat,\n\t\t\tData:                 &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t},\n\t\t\"json-request-basic-input-and-request-with-ns\": {\n\t\t\tIsErrorExpected: false,\n\t\t\tSubtype:         RequestType,\n\t\t\tRequiredFormat:  JSONFormat,\n\t\t\tData:            &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t\tRootNamespace:   true,\n\t\t},\n\t\t\"json-response-basic-input-and-request-with-ns\": {\n\t\t\tIsErrorExpected: false,\n\t\t\tSubtype:         ResponseType,\n\t\t\tRequiredFormat:  JSONFormat,\n\t\t\tData:            &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t\tRootNamespace:   true,\n\t\t},\n\t\t\"jsonx-request-no-data\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: cannot audit event (AuditRequest) with no data: invalid parameter\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 nil,\n\t\t},\n\t\t\"jsonx-response-no-data\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: cannot audit event (AuditResponse) with no data: invalid parameter\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 nil,\n\t\t},\n\t\t\"jsonx-request-basic-input\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse request from audit event: request to request-audit a nil request\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 &logical.LogInput{Type: \"magic\"},\n\t\t},\n\t\t\"jsonx-response-basic-input\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse response from audit event: request to response-audit a nil request\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 &logical.LogInput{Type: \"magic\"},\n\t\t},\n\t\t\"jsonx-request-basic-input-and-request-no-ns\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse request from audit event: no namespace\",\n\t\t\tSubtype:              RequestType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t},\n\t\t\"jsonx-response-basic-input-and-request-no-ns\": {\n\t\t\tIsErrorExpected:      true,\n\t\t\tExpectedErrorMessage: \"audit.(EntryFormatter).Process: unable to parse response from audit event: no namespace\",\n\t\t\tSubtype:              ResponseType,\n\t\t\tRequiredFormat:       JSONxFormat,\n\t\t\tData:                 &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t},\n\t\t\"jsonx-request-basic-input-and-request-with-ns\": {\n\t\t\tIsErrorExpected: false,\n\t\t\tSubtype:         RequestType,\n\t\t\tRequiredFormat:  JSONxFormat,\n\t\t\tData:            &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t\tRootNamespace:   true,\n\t\t},\n\t\t\"jsonx-response-basic-input-and-request-with-ns\": {\n\t\t\tIsErrorExpected: false,\n\t\t\tSubtype:         ResponseType,\n\t\t\tRequiredFormat:  JSONxFormat,\n\t\t\tData:            &logical.LogInput{Request: &logical.Request{ID: \"123\"}},\n\t\t\tRootNamespace:   true,\n\t\t},\n\t}\n\n\tfor name, tc := range tests {\n\t\tname := name\n\t\ttc := tc\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\te := fakeEvent(t, tc.Subtype, tc.Data)\n\t\t\trequire.NotNil(t, e)\n\n\t\t\tss := newStaticSalt(t)\n\t\t\tcfg, err := NewFormatterConfig(WithFormat(tc.RequiredFormat.String()))\n\t\t\trequire.NoError(t, err)\n\n\t\t\tf, err := NewEntryFormatter(cfg, ss)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NotNil(t, f)\n\n\t\t\tvar ctx context.Context\n\t\t\tswitch {\n\t\t\tcase tc.RootNamespace:\n\t\t\t\tctx = namespace.RootContext(context.Background())\n\t\t\tdefault:\n\t\t\t\tctx = context.Background()\n\t\t\t}\n\n\t\t\tprocessed, err := f.Process(ctx, e)\n\n\t\t\tswitch {\n\t\t\tcase tc.IsErrorExpected:\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.EqualError(t, err, tc.ExpectedErrorMessage)\n\t\t\t\trequire.Nil(t, processed)\n\t\t\tdefault:\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NotNil(t, processed)\n\t\t\t\tb, found := processed.Format(string(tc.RequiredFormat))\n\t\t\t\trequire.True(t, found)\n\t\t\t\trequire.NotNil(t, b)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\treturn sockjs.NewHandler(\"/api/v1/kolide/results\", opt, func(session sockjs.Session) {\n\t\tconn := &websocket.Conn{Session: session}\n\t\tdefer func() {\n\t\t\tif p := recover(); p != nil {\n\t\t\t\tlogger.Log(\"err\", p, \"msg\", \"panic in result handler\")\n\t\t\t\tconn.WriteJSONError(\"panic in result handler\")\n\t\t\t}\n\t\t\tsession.Close(0, \"none\")\n\t\t}()\n\n\t\t// Receive the auth bearer token\n\t\ttoken, err := conn.ReadAuthToken()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"failed to read auth token\")\n\t\t\treturn\n\t\t}\n\n\t\t// Authenticate with the token\n\t\tvc, err := authViewer(context.Background(), jwtKey, token, svc)\n\t\tif err != nil || !vc.CanPerformActions() {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unauthorized viewer\")\n\t\t\tconn.WriteJSONError(\"unauthorized\")\n\t\t\treturn\n\t\t}\n\n\t\tctx := viewer.NewContext(context.Background(), *vc)\n\n\t\tmsg, err := conn.ReadJSONMessage()\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"reading select_campaign JSON\")\n\t\t\tconn.WriteJSONError(\"error reading select_campaign\")\n\t\t\treturn\n\t\t}\n\t\tif msg.Type != \"select_campaign\" {\n\t\t\tlogger.Log(\"err\", \"unexpected msg type, expected select_campaign\", \"msg-type\", msg.Type)\n\t\t\tconn.WriteJSONError(\"expected select_campaign\")\n\t\t\treturn\n\t\t}\n\n\t\tvar info struct {\n\t\t\tCampaignID uint `json:\"campaign_id\"`\n\t\t}\n\t\terr = json.Unmarshal(*(msg.Data.(*json.RawMessage)), &info)\n\t\tif err != nil {\n\t\t\tlogger.Log(\"err\", err, \"msg\", \"unmarshaling select_campaign data\")\n\t\t\tconn.WriteJSONError(\"error unmarshaling select_campaign data\")\n\t\t\treturn\n\t\t}\n\t\tif info.CampaignID == 0 {\n\t\t\tlogger.Log(\"err\", \"campaign ID not set\")\n\t\t\tconn.WriteJSONError(\"0 is not a valid campaign ID\")\n\t\t\treturn\n\t\t}\n\n\t\tsvc.StreamCampaignResults(ctx, conn, info.CampaignID)\n\n\t})", "is_vulnerable": 0}
{"code": "func CookieNameFromDomain(domain string) string {\n\t// replace all non-word characters with underscores\n\tderived := regexp.MustCompile(`[\\W_]+`).ReplaceAllString(domain, \"_\")\n\treturn \"_\" + derived + \"_jwt2_\"\n}", "is_vulnerable": 1}
{"code": "func doesPolicySignatureMatch(formValues http.Header) APIErrorCode {\n\t// For SignV2 - Signature field will be valid\n\tif _, ok := formValues[\"Signature\"]; ok {\n\t\treturn doesPolicySignatureV2Match(formValues)\n\t}\n\treturn doesPolicySignatureV4Match(formValues)\n}", "is_vulnerable": 1}
{"code": "\tg.POST(\"/memo\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing user in session\")\n\t\t}\n\n\t\tmemoCreate := &api.MemoCreate{\n\t\t\tCreatorID: userID,\n\t\t}\n\t\tif err := json.NewDecoder(c.Request().Body).Decode(memoCreate); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Malformatted post memo request\").SetInternal(err)\n\t\t}\n\t\tif memoCreate.Content == \"\" {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Memo content shouldn't be empty\")\n\t\t}\n\n\t\tif memoCreate.Visibility == \"\" {\n\t\t\tuserSettingMemoVisibilityKey := api.UserSettingMemoVisibilityKey\n\t\t\tuserMemoVisibilitySetting, err := s.Store.FindUserSetting(ctx, &api.UserSettingFind{\n\t\t\t\tUserID: userID,\n\t\t\t\tKey:    &userSettingMemoVisibilityKey,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to find user setting\").SetInternal(err)\n\t\t\t}\n\n\t\t\tif userMemoVisibilitySetting != nil {\n\t\t\t\tmemoVisibility := api.Private\n\t\t\t\terr := json.Unmarshal([]byte(userMemoVisibilitySetting.Value), &memoVisibility)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to unmarshal user setting value\").SetInternal(err)\n\t\t\t\t}\n\t\t\t\tmemoCreate.Visibility = memoVisibility\n\t\t\t} else {\n\t\t\t\t// Private is the default memo visibility.\n\t\t\t\tmemoCreate.Visibility = api.Private\n\t\t\t}\n\t\t}\n\n\t\tmemo, err := s.Store.CreateMemo(ctx, memoCreate)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to create memo\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"memo created\",\n\t\t})\n\n\t\tfor _, resourceID := range memoCreate.ResourceIDList {\n\t\t\tif _, err := s.Store.UpsertMemoResource(ctx, &api.MemoResourceUpsert{\n\t\t\t\tMemoID:     memo.ID,\n\t\t\t\tResourceID: resourceID,\n\t\t\t}); err != nil {\n\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to upsert memo resource\").SetInternal(err)\n\t\t\t}\n\t\t}\n\n\t\tmemo, err = s.Store.ComposeMemo(ctx, memo)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to compose memo\").SetInternal(err)\n\t\t}\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(memo)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode memo response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 1}
{"code": "\t\t\texpectedRule: func() *Rule {\n\t\t\t\tr := MustParseRule(`p { concat(\"/\", input) with concat as data.test.mock_concat }`)\n\t\t\t\tr.Body[0].With[0].Target.Value = Ref([]*Term{VarTerm(\"concat\")})\n\t\t\t\treturn r\n\t\t\t}(),\n\t\t},\n\t}\n\n\tfor _, tc := range tests {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tc := NewCompiler()\n\t\t\tif tc.opts != nil {\n\t\t\t\tc = tc.opts(c)\n\t\t\t}\n\t\t\tmodule := fixture + tc.input\n\t\t\tc.Modules[\"test\"] = MustParseModule(module)\n\t\t\tcompileStages(c, c.rewriteWithModifiers)\n\t\t\tif tc.wantErr == nil {\n\t\t\t\tassertNotFailed(t, c)\n\t\t\t\texpected := tc.expectedRule\n\t\t\t\tif expected == nil {\n\t\t\t\t\texpected = MustParseRule(tc.expected)\n\t\t\t\t}\n\t\t\t\tresult := c.Modules[\"test\"].Rules[1]\n\t\t\t\tif result.Compare(expected) != 0 {\n\t\t\t\t\tt.Fatalf(\"\\nExp: %v\\nGot: %v\", expected, result)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tassertCompilerErrorStrings(t, c, []string{tc.wantErr.Error()})\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func CreateSessionManager(sessionLifetime time.Duration, sessionIdleTimeout time.Duration, sessionPresentCallback func(), noSessionsPresentCallback func(), metric prometheus.Gauge) *scs.SessionManager {\n\tstore := session.New()\n\tstore.RegisterListener(&sessionCountingListener{\n\t\tsessionPresent:    sessionPresentCallback,\n\t\tnoSessionsPresent: noSessionsPresentCallback,\n\t\tmetric:            metric,\n\t})\n\n\tsessionManager := scs.New()\n\n\tsessionManager.Lifetime = sessionLifetime\n\tsessionManager.IdleTimeout = sessionIdleTimeout\n\tsessionManager.Cookie.HttpOnly = true\n\tsessionManager.Cookie.Persist = false\n\tsessionManager.Cookie.Secure = true\n\tsessionManager.Cookie.SameSite = http.SameSiteStrictMode\n\tsessionManager.Store = store\n\treturn sessionManager\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleCopyMove(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\thdr := r.Header.Get(\"Destination\")\n\tif hdr == \"\" {\n\t\treturn http.StatusBadRequest, errInvalidDestination\n\t}\n\tu, err := url.Parse(hdr)\n\tif err != nil {\n\t\treturn http.StatusBadRequest, errInvalidDestination\n\t}\n\tif u.Host != \"\" && u.Host != r.Host {\n\t\treturn http.StatusBadGateway, errInvalidDestination\n\t}\n\n\tsrc, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\n\tdst, status, err := h.stripPrefix(u.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\n\tif dst == \"\" {\n\t\treturn http.StatusBadGateway, errInvalidDestination\n\t}\n\tif dst == src {\n\t\treturn http.StatusForbidden, errDestinationEqualsSource\n\t}\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\tsrc = path.Join(user.BasePath, src)\n\tdst = path.Join(user.BasePath, dst)\n\n\tif r.Method == \"COPY\" {\n\t\t// Section 7.5.1 says that a COPY only needs to lock the destination,\n\t\t// not both destination and source. Strictly speaking, this is racy,\n\t\t// even though a COPY doesn't modify the source, if a concurrent\n\t\t// operation modifies the source. However, the litmus test explicitly\n\t\t// checks that COPYing a locked-by-another source is OK.\n\t\trelease, status, err := h.confirmLocks(r, \"\", dst)\n\t\tif err != nil {\n\t\t\treturn status, err\n\t\t}\n\t\tdefer release()\n\n\t\t// Section 9.8.3 says that \"The COPY method on a collection without a Depth\n\t\t// header must act as if a Depth header with value \"infinity\" was included\".\n\t\tdepth := infiniteDepth\n\t\tif hdr := r.Header.Get(\"Depth\"); hdr != \"\" {\n\t\t\tdepth = parseDepth(hdr)\n\t\t\tif depth != 0 && depth != infiniteDepth {\n\t\t\t\t// Section 9.8.3 says that \"A client may submit a Depth header on a\n\t\t\t\t// COPY on a collection with a value of \"0\" or \"infinity\".\"\n\t\t\t\treturn http.StatusBadRequest, errInvalidDepth\n\t\t\t}\n\t\t}\n\t\treturn copyFiles(ctx, src, dst, r.Header.Get(\"Overwrite\") != \"F\")\n\t}\n\n\trelease, status, err := h.confirmLocks(r, src, dst)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\t// Section 9.9.2 says that \"The MOVE method on a collection must act as if\n\t// a \"Depth: infinity\" header was used on it. A client must not submit a\n\t// Depth header on a MOVE on a collection with any value but \"infinity\".\"\n\tif hdr := r.Header.Get(\"Depth\"); hdr != \"\" {\n\t\tif parseDepth(hdr) != infiniteDepth {\n\t\t\treturn http.StatusBadRequest, errInvalidDepth\n\t\t}\n\t}\n\treturn moveFiles(ctx, src, dst, r.Header.Get(\"Overwrite\") == \"T\")\n}", "is_vulnerable": 1}
{"code": "func isIgnoreUserInvalidPasswordError(err error, request *domain.AuthRequest) bool {\n\treturn request != nil && request.LoginPolicy != nil && request.LoginPolicy.IgnoreUnknownUsernames && zerrors.IsErrorInvalidArgument(err) && zerrors.Contains(err, \"Errors.User.Password.Invalid\")\n}", "is_vulnerable": 1}
{"code": "func TestPodDisruptionBudgetStore(t *testing.T) {\n\t// Fixed metadata on type and help text. We prepend this to every expected\n\t// output so we only have to modify a single place when doing adjustments.\n\tconst metadata = `\n\t# HELP kube_poddisruptionbudget_created Unix creation timestamp\n\t# TYPE kube_poddisruptionbudget_created gauge\n\t# HELP kube_poddisruptionbudget_status_current_healthy Current number of healthy pods\n\t# TYPE kube_poddisruptionbudget_status_current_healthy gauge\n\t# HELP kube_poddisruptionbudget_status_desired_healthy Minimum desired number of healthy pods\n\t# TYPE kube_poddisruptionbudget_status_desired_healthy gauge\n\t# HELP kube_poddisruptionbudget_status_pod_disruptions_allowed Number of pod disruptions that are currently allowed\n\t# TYPE kube_poddisruptionbudget_status_pod_disruptions_allowed gauge\n\t# HELP kube_poddisruptionbudget_status_expected_pods Total number of pods counted by this disruption budget\n\t# TYPE kube_poddisruptionbudget_status_expected_pods gauge\n\t# HELP kube_poddisruptionbudget_status_observed_generation Most recent generation observed when updating this PDB status\n\t# TYPE kube_poddisruptionbudget_status_observed_generation gauge\n\t# HELP kube_poddisruptionbudget_annotations Kubernetes annotations converted to Prometheus labels.\n\t# TYPE kube_poddisruptionbudget_annotations gauge\n\t`\n\tcases := []generateMetricsTestCase{\n\t\t{\n\t\t\tObj: &v1beta1.PodDisruptionBudget{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:              \"pdb1\",\n\t\t\t\t\tCreationTimestamp: metav1.Time{Time: time.Unix(1500000000, 0)},\n\t\t\t\t\tNamespace:         \"ns1\",\n\t\t\t\t\tGeneration:        21,\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"pdb1\": \"pdb1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: v1beta1.PodDisruptionBudgetStatus{\n\t\t\t\t\tCurrentHealthy:        12,\n\t\t\t\t\tDesiredHealthy:        10,\n\t\t\t\t\tPodDisruptionsAllowed: 2,\n\t\t\t\t\tExpectedPods:          15,\n\t\t\t\t\tObservedGeneration:    111,\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\tkube_poddisruptionbudget_created{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 1.5e+09\n\t\t\tkube_poddisruptionbudget_status_current_healthy{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 12\n\t\t\tkube_poddisruptionbudget_status_desired_healthy{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 10\n\t\t\tkube_poddisruptionbudget_status_pod_disruptions_allowed{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 2\n\t\t\tkube_poddisruptionbudget_status_expected_pods{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 15\n\t\t\tkube_poddisruptionbudget_status_observed_generation{namespace=\"ns1\",poddisruptionbudget=\"pdb1\"} 111\n\t\t\tkube_poddisruptionbudget_annotations{namespace=\"ns1\",poddisruptionbudget=\"pdb1\",annotation_pdb1=\"pdb1\"} 1\n\t\t\t`,\n\t\t},\n\t\t{\n\t\t\tObj: &v1beta1.PodDisruptionBudget{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:       \"pdb2\",\n\t\t\t\t\tNamespace:  \"ns2\",\n\t\t\t\t\tGeneration: 14,\n\t\t\t\t},\n\t\t\t\tStatus: v1beta1.PodDisruptionBudgetStatus{\n\t\t\t\t\tCurrentHealthy:        8,\n\t\t\t\t\tDesiredHealthy:        9,\n\t\t\t\t\tPodDisruptionsAllowed: 0,\n\t\t\t\t\tExpectedPods:          10,\n\t\t\t\t\tObservedGeneration:    1111,\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\t\tkube_poddisruptionbudget_status_current_healthy{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 8\n\t\t\t\tkube_poddisruptionbudget_status_desired_healthy{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 9\n\t\t\t\tkube_poddisruptionbudget_status_pod_disruptions_allowed{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 0\n\t\t\t\tkube_poddisruptionbudget_status_expected_pods{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 10\n\t\t\t\tkube_poddisruptionbudget_status_observed_generation{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 1111\n\t\t\t\tkube_poddisruptionbudget_annotations{namespace=\"ns2\",poddisruptionbudget=\"pdb2\"} 1\n\t\t\t`,\n\t\t},\n\t}\n\tfor i, c := range cases {\n\t\tc.Func = metric.ComposeMetricGenFuncs(podDisruptionBudgetMetricFamilies)\n\t\tif err := c.run(); err != nil {\n\t\t\tt.Errorf(\"unexpected collecting result in %vth run:\\n%s\", i, err)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func NVReadValueAuth(rw io.ReadWriter, index, offset, len uint32, auth []byte) ([]byte, error) {\n\tif auth == nil {\n\t\treturn nil, fmt.Errorf(\"no auth value given but mandatory\")\n\t}\n\tsharedSecret, osapr, err := newOSAPSession(rw, etOwner, khOwner, auth[:])\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to start new auth session: %v\", err)\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\tauthIn := []interface{}{ordNVReadValueAuth, index, offset, len}\n\tca, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, nil, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to construct auth fields: %v\", err)\n\t}\n\tdata, ra, ret, err := nvReadValue(rw, index, offset, len, ca)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read from NVRAM: %v\", err)\n\t}\n\traIn := []interface{}{ret, ordNVReadValueAuth, tpmutil.U32Bytes(data)}\n\tif err := ra.verify(ca.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to verify authenticity of response: %v\", err)\n\t}\n\n\treturn data, nil\n}", "is_vulnerable": 0}
{"code": "func (srv *Server) serveTCP(l net.Listener) error {\n\tdefer l.Close()\n\n\tif srv.NotifyStartedFunc != nil {\n\t\tsrv.NotifyStartedFunc()\n\t}\n\n\treader := Reader(&defaultReader{srv})\n\tif srv.DecorateReader != nil {\n\t\treader = srv.DecorateReader(reader)\n\t}\n\n\thandler := srv.Handler\n\tif handler == nil {\n\t\thandler = DefaultServeMux\n\t}\n\trtimeout := srv.getReadTimeout()\n\t// deadline is not used here\n\tfor {\n\t\trw, err := l.Accept()\n\t\tsrv.lock.RLock()\n\t\tif !srv.started {\n\t\t\tsrv.lock.RUnlock()\n\t\t\treturn nil\n\t\t}\n\t\tsrv.lock.RUnlock()\n\t\tif err != nil {\n\t\t\tif neterr, ok := err.(net.Error); ok && neterr.Temporary() {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tgo func() {\n\t\t\tm, err := reader.ReadTCP(rw, rtimeout)\n\t\t\tif err != nil {\n\t\t\t\trw.Close()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n\t\t}()\n\t}\n}", "is_vulnerable": 0}
{"code": "func (b *Backend) Send(msg BackendMessage) error {\n\t_, err := b.w.Write(msg.Encode(nil))\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func createAccountForOperatorKey(t *testing.T, s *server.Server, seed []byte) nkeys.KeyPair {\n\tt.Helper()\n\tokp, _ := nkeys.FromSeed(seed)\n\takp, _ := nkeys.CreateAccount()\n\tpub, _ := akp.PublicKey()\n\tnac := jwt.NewAccountClaims(pub)\n\tjwt, _ := nac.Encode(okp)\n\tif err := s.AccountResolver().Store(pub, jwt); err != nil {\n\t\tt.Fatalf(\"Account Resolver returned an error: %v\", err)\n\t}\n\treturn akp\n}", "is_vulnerable": 0}
{"code": "func (r *replayer) modifies() map[string]common.Hash {\n\tset := make(map[string]common.Hash)\n\tfor i, path := range r.paths {\n\t\tset[path] = r.hashes[i]\n\t}\n\treturn set\n}", "is_vulnerable": 0}
{"code": "func uploads(router *httprouter.Router, fsys MkdirFS) {\n\trouter.POST(\"/_apis/pipelines/workflows/:runId/artifacts\", func(w http.ResponseWriter, req *http.Request, params httprouter.Params) {\n\t\trunID := params.ByName(\"runId\")\n\n\t\tjson, err := json.Marshal(FileContainerResourceURL{\n\t\t\tFileContainerResourceURL: fmt.Sprintf(\"http://%s/upload/%s\", req.Host, runID),\n\t\t})\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\t_, err = w.Write(json)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t})\n\n\trouter.PUT(\"/upload/:runId\", func(w http.ResponseWriter, req *http.Request, params httprouter.Params) {\n\t\titemPath := req.URL.Query().Get(\"itemPath\")\n\t\trunID := params.ByName(\"runId\")\n\n\t\tif req.Header.Get(\"Content-Encoding\") == \"gzip\" {\n\t\t\titemPath += gzipExtension\n\t\t}\n\n\t\tfilePath := fmt.Sprintf(\"%s/%s\", runID, itemPath)\n\n\t\terr := fsys.MkdirAll(path.Dir(filePath), os.ModePerm)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tfile, err := func() (fs.File, error) {\n\t\t\tcontentRange := req.Header.Get(\"Content-Range\")\n\t\t\tif contentRange != \"\" && !strings.HasPrefix(contentRange, \"bytes 0-\") {\n\t\t\t\treturn fsys.OpenAtEnd(filePath)\n\t\t\t}\n\t\t\treturn fsys.Open(filePath)\n\t\t}()\n\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tdefer file.Close()\n\n\t\twriter, ok := file.(io.Writer)\n\t\tif !ok {\n\t\t\tpanic(errors.New(\"File is not writable\"))\n\t\t}\n\n\t\tif req.Body == nil {\n\t\t\tpanic(errors.New(\"No body given\"))\n\t\t}\n\n\t\t_, err = io.Copy(writer, req.Body)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tjson, err := json.Marshal(ResponseMessage{\n\t\t\tMessage: \"success\",\n\t\t})\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\t_, err = w.Write(json)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t})\n\n\trouter.PATCH(\"/_apis/pipelines/workflows/:runId/artifacts\", func(w http.ResponseWriter, req *http.Request, params httprouter.Params) {\n\t\tjson, err := json.Marshal(ResponseMessage{\n\t\t\tMessage: \"success\",\n\t\t})\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\t_, err = w.Write(json)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func (m *Meta) install(dstdir string) error {\n\tif err := os.MkdirAll(m.Path, 0755); err != nil {\n\t\treturn err\n\t}\n\n\tif err := m.installImage(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := m.installBinary(); err != nil {\n\t\treturn err\n\t}\n\n\tif err := m.installMeta(dstdir); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (g *rfc4122Generator) getHardwareAddr() ([]byte, error) {\n\tvar err error\n\tg.hardwareAddrOnce.Do(func() {\n\t\tif hwAddr, err := g.hwAddrFunc(); err == nil {\n\t\t\tcopy(g.hardwareAddr[:], hwAddr)\n\t\t\treturn\n\t\t}\n\n\t\t// Initialize hardwareAddr randomly in case\n\t\t// of real network interfaces absence.\n\t\tif _, err = io.ReadFull(g.rand, g.hardwareAddr[:]); err != nil {\n\t\t\treturn\n\t\t}\n\t\t// Set multicast bit as recommended by RFC 4122\n\t\tg.hardwareAddr[0] |= 0x01\n\t})\n\tif err != nil {\n\t\treturn []byte{}, err\n\t}\n\treturn g.hardwareAddr[:], nil\n}", "is_vulnerable": 0}
{"code": "func (s *DiscoveryServer) generateRawClusters(node *model.Proxy, push *model.PushContext) []*xdsapi.Cluster {\n\trawClusters := s.ConfigGenerator.BuildClusters(s.Env, node, push)\n\n\tfor _, c := range rawClusters {\n\t\tif err := c.Validate(); err != nil {\n\t\t\tretErr := fmt.Errorf(\"CDS: Generated invalid cluster for node %v: %v\", node, err)\n\t\t\tadsLog.Errorf(\"CDS: Generated invalid cluster for node:%s: %v, %v\", node.ID, err, c)\n\t\t\tcdsBuildErrPushes.Increment()\n\t\t\ttotalXDSInternalErrors.Increment()\n\t\t\t// Generating invalid clusters is a bug.\n\t\t\t// Panic instead of trying to recover from that, since we can't\n\t\t\t// assume anything about the state.\n\t\t\tpanic(retErr.Error())\n\t\t}\n\t}\n\treturn rawClusters\n}", "is_vulnerable": 1}
{"code": "func (client Client) Get(ctx context.Context, resourceGroupName string, resourceProviderNamespace string, parentResourcePath string, resourceType string, resourceName string) (result GenericResource, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/Client.Get\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"Get\", err.Error())\n\t}\n\n\treq, err := client.GetPreparer(ctx, resourceGroupName, resourceProviderNamespace, parentResourcePath, resourceType, resourceName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Get\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.GetSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Get\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.GetResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Get\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func Add(name string, privileged bool, subDir string) (*File, error) {\n\tif err := CheckName(name); err != nil {\n\t\treturn nil, err\n\t}\n\t_, err := Get(name, subDir)\n\tif err == nil {\n\t\treturn nil, fmt.Errorf(\"instance %s already exists\", name)\n\t}\n\ti := &File{Name: name, Privileged: privileged}\n\ti.Path, err = getPath(privileged, \"\", subDir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tjsonFile := name + \".json\"\n\ti.Path = filepath.Join(i.Path, name, jsonFile)\n\treturn i, nil\n}", "is_vulnerable": 1}
{"code": "\t\tpatchResponse func(t *testing.T, srv *Server, resp *pbautoconf.AutoConfigResponse)\n\t\terr           string\n\t}\n\n\tdefaultEntMeta := structs.DefaultEnterpriseMetaInDefaultPartition()\n\n\tcases := map[string]testCase{\n\t\t\"wrong-datacenter\": {\n\t\t\trequest: pbautoconf.AutoConfigRequest{\n\t\t\t\tDatacenter: \"no-such-dc\",\n\t\t\t},\n\t\t\terr: `invalid datacenter \"no-such-dc\" - agent auto configuration cannot target a remote datacenter`,\n\t\t},\n\t\t\"unverifiable\": {\n\t\t\trequest: pbautoconf.AutoConfigRequest{\n\t\t\t\tNode: \"test-node\",\n\t\t\t\t// this is signed using an incorrect private key\n\t\t\t\tJWT: signJWTWithStandardClaims(t, altpriv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t},\n\t\t\terr: \"Permission denied: Failed JWT authorization: no known key successfully validated the token signature\",\n\t\t},\n\t\t\"bad-req-node\": {\n\t\t\trequest: &pbautoconf.AutoConfigRequest{\n\t\t\t\tNode: \"bad node\",\n\t\t\t\tJWT:  signJWTWithStandardClaims(t, priv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t},\n\t\t\terr: \"Invalid request field. node =\",\n\t\t},\n\t\t\"bad-req-segment\": {\n\t\t\trequest: &pbautoconf.AutoConfigRequest{\n\t\t\t\tNode:    \"test-node\",\n\t\t\t\tSegment: \"bad segment\",\n\t\t\t\tJWT:     signJWTWithStandardClaims(t, priv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t},\n\t\t\terr: \"Invalid request field. segment =\",\n\t\t},\n\t\t\"bad-req-partition\": {\n\t\t\trequest: &pbautoconf.AutoConfigRequest{\n\t\t\t\tNode:      \"test-node\",\n\t\t\t\tPartition: \"bad partition\",\n\t\t\t\tJWT:       signJWTWithStandardClaims(t, priv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t},\n\t\t\terr: \"Invalid request field. partition =\",\n\t\t},\n\t\t\"claim-assertion-failed\": {\n\t\t\trequest: pbautoconf.AutoConfigRequest{\n\t\t\t\tNode: \"test-node\",\n\t\t\t\tJWT:  signJWTWithStandardClaims(t, priv, map[string]interface{}{\"wrong_claim\": \"test-node\"}),\n\t\t\t},\n\t\t\terr: \"Permission denied: Failed JWT claim assertion\",\n\t\t},\n\t\t\"bad-csr-id\": {\n\t\t\trequest: pbautoconf.AutoConfigRequest{\n\t\t\t\tNode: \"test-node\",\n\t\t\t\tJWT:  signJWTWithStandardClaims(t, priv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t\tCSR:  altCSR,\n\t\t\t},\n\t\t\terr: \"Spiffe ID agent name (alt) of the certificate signing request is not for the correct node (test-node)\",\n\t\t},\n\t\t\"good\": {\n\t\t\trequest: pbautoconf.AutoConfigRequest{\n\t\t\t\tNode: \"test-node\",\n\t\t\t\tJWT:  signJWTWithStandardClaims(t, priv, map[string]interface{}{\"consul_node_name\": \"test-node\"}),\n\t\t\t\tCSR:  csr,\n\t\t\t},\n\t\t\texpected: pbautoconf.AutoConfigResponse{\n\t\t\t\tCARoots:             pbroots,\n\t\t\t\tExtraCACertificates: []string{cacert},\n\t\t\t\tConfig: &pbconfig.Config{\n\t\t\t\t\tDatacenter:        \"dc1\",\n\t\t\t\t\tPrimaryDatacenter: \"dc1\",\n\t\t\t\t\tNodeName:          \"test-node\",\n\t\t\t\t\tACL: &pbconfig.ACL{\n\t\t\t\t\t\tEnabled:       true,\n\t\t\t\t\t\tPolicyTTL:     \"30s\",\n\t\t\t\t\t\tTokenTTL:      \"30s\",\n\t\t\t\t\t\tRoleTTL:       \"30s\",\n\t\t\t\t\t\tDownPolicy:    \"extend-cache\",\n\t\t\t\t\t\tDefaultPolicy: \"deny\",\n\t\t\t\t\t\tTokens: &pbconfig.ACLTokens{\n\t\t\t\t\t\t\tAgent: \"patched-secret\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tGossip: &pbconfig.Gossip{\n\t\t\t\t\t\tEncryption: &pbconfig.GossipEncryption{\n\t\t\t\t\t\t\tKey:            gossipKeyEncoded,\n\t\t\t\t\t\t\tVerifyIncoming: true,\n\t\t\t\t\t\t\tVerifyOutgoing: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tRetryJoinLAN: []string{joinAddr.String()},\n\t\t\t\t\t},\n\t\t\t\t\tTLS: &pbconfig.TLS{\n\t\t\t\t\t\tVerifyOutgoing:           true,\n\t\t\t\t\t\tVerifyServerHostname:     true,\n\t\t\t\t\t\tMinVersion:               \"tls12\",\n\t\t\t\t\t\tPreferServerCipherSuites: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tpatchResponse: func(t *testing.T, _ *Server, resp *pbautoconf.AutoConfigResponse) {\n\t\t\t\t// we are expecting an ACL token but cannot check anything for equality\n\t\t\t\t// so here we check that it was set and overwrite it\n\t\t\t\trequire.NotNil(t, resp.Config)\n\t\t\t\trequire.NotNil(t, resp.Config.ACL)\n\t\t\t\trequire.NotNil(t, resp.Config.ACL.Tokens)\n\t\t\t\trequire.NotEmpty(t, resp.Config.ACL.Tokens.Agent)\n\t\t\t\tresp.Config.ACL.Tokens.Agent = \"patched-secret\"\n\n\t\t\t\trequire.NotNil(t, resp.Certificate)\n\t\t\t\trequire.NotEmpty(t, resp.Certificate.SerialNumber)\n\t\t\t\trequire.NotEmpty(t, resp.Certificate.CertPEM)\n\t\t\t\trequire.Empty(t, resp.Certificate.Service)\n\t\t\t\trequire.Empty(t, resp.Certificate.ServiceURI)\n\t\t\t\trequire.Equal(t, \"test-node\", resp.Certificate.Agent)\n\n\t\t\t\texpectedID := connect.SpiffeIDAgent{\n\t\t\t\t\tHost:       roots.TrustDomain,\n\t\t\t\t\tAgent:      \"test-node\",\n\t\t\t\t\tPartition:  defaultEntMeta.PartitionOrDefault(),\n\t\t\t\t\tDatacenter: \"dc1\",\n\t\t\t\t}\n\n\t\t\t\trequire.Equal(t, expectedID.URI().String(), resp.Certificate.AgentURI)\n\n\t\t\t\t// nil this out so we don't check it for equality\n\t\t\t\tresp.Certificate = nil\n\t\t\t},\n\t\t},\n\t}\n\n\tfor testName, tcase := range cases {\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tvar reply pbautoconf.AutoConfigResponse\n\t\t\terr := msgpackrpc.CallWithCodec(codec, \"AutoConfig.InitialConfiguration\", &tcase.request, &reply)\n\t\t\tif tcase.err != \"\" {\n\t\t\t\ttestutil.RequireErrorContains(t, err, tcase.err)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif tcase.patchResponse != nil {\n\t\t\t\t\ttcase.patchResponse(t, s, &reply)\n\t\t\t\t}\n\t\t\t\trequire.Equal(t, tcase.expected, reply)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *ConnectionPool) Get(ctx context.Context, token auth.Token) (gitpod.APIInterface, error) {\n\tcached, found := p.cache.Get(token)\n\treportCacheOutcome(found)\n\tif found {\n\t\tconn, ok := cached.(*gitpod.APIoverJSONRPC)\n\t\tif ok {\n\t\t\treturn conn, nil\n\t\t}\n\t}\n\n\tconn, err := p.connConstructor(token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create new connection to server: %w\", err)\n\t}\n\n\tp.cache.Add(token, conn)\n\tconnectionPoolSize.Inc()\n\n\treturn conn, nil\n}", "is_vulnerable": 1}
{"code": "\trouteString := func(typ, name string, protected bool) string {\n\t\tstr := `{\n\t\t\t\t\"name\": \"pomerium-` + typ + `-` + name + `\",\n\t\t\t\t\"match\": {\n\t\t\t\t\t\"` + typ + `\": \"` + name + `\"\n\t\t\t\t},\n\t\t\t\t\"responseHeadersToAdd\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"appendAction\": \"OVERWRITE_IF_EXISTS_OR_ADD\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t  \"key\": \"X-Frame-Options\",\n\t\t\t\t\t\t  \"value\": \"SAMEORIGIN\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"appendAction\": \"OVERWRITE_IF_EXISTS_OR_ADD\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t  \"key\": \"X-XSS-Protection\",\n\t\t\t\t\t\t  \"value\": \"1; mode=block\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"route\": {\n\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t}\n\t\t\t`\n\t\tif !protected {\n\t\t\tstr += `,\n\t\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\t\"disabled\": true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t`\n\t\t}\n\t\tstr += \"}\"\n\t\treturn str\n\t}\n\tt.Run(\"authenticate\", func(t *testing.T) {\n\t\toptions := &config.Options{\n\t\t\tServices:                 \"all\",\n\t\t\tAuthenticateURLString:    \"https://authenticate.example.com\",\n\t\t\tAuthenticateCallbackPath: \"/oauth2/callback\",\n\t\t}\n\t\troutes, err := b.buildPomeriumHTTPRoutes(options, \"authenticate.example.com\", false)\n\t\trequire.NoError(t, err)\n\n\t\ttestutil.AssertProtoJSONEqual(t, `[\n\t\t\t`+routeString(\"path\", \"/.pomerium/jwt\", true)+`,\n\t\t\t`+routeString(\"path\", urlutil.WebAuthnURLPath, true)+`,\n\t\t\t`+routeString(\"path\", \"/ping\", false)+`,\n\t\t\t`+routeString(\"path\", \"/healthz\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.well-known/pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.well-known/pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/robots.txt\", false)+`,\n\t\t\t`+routeString(\"path\", \"/oauth2/callback\", false)+`,\n\t\t\t`+routeString(\"path\", \"/\", false)+`\n\t\t]`, routes)\n\t})\n\tt.Run(\"proxy fronting authenticate\", func(t *testing.T) {\n\t\toptions := &config.Options{\n\t\t\tServices:                 \"proxy\",\n\t\t\tAuthenticateURLString:    \"https://authenticate.example.com\",\n\t\t\tAuthenticateCallbackPath: \"/oauth2/callback\",\n\t\t}\n\t\troutes, err := b.buildPomeriumHTTPRoutes(options, \"authenticate.example.com\", false)\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, \"null\", routes)\n\t})\n\n\tt.Run(\"with robots\", func(t *testing.T) {\n\t\toptions := &config.Options{\n\t\t\tServices:                 \"all\",\n\t\t\tAuthenticateURLString:    \"https://authenticate.example.com\",\n\t\t\tAuthenticateCallbackPath: \"/oauth2/callback\",\n\t\t\tPolicies: []config.Policy{{\n\t\t\t\tFrom: \"https://from.example.com\",\n\t\t\t\tTo:   mustParseWeightedURLs(t, \"https://to.example.com\"),\n\t\t\t}},\n\t\t}\n\t\t_ = options.Policies[0].Validate()\n\t\troutes, err := b.buildPomeriumHTTPRoutes(options, \"from.example.com\", false)\n\t\trequire.NoError(t, err)\n\n\t\ttestutil.AssertProtoJSONEqual(t, `[\n\t\t\t`+routeString(\"path\", \"/.pomerium/jwt\", true)+`,\n\t\t\t`+routeString(\"path\", urlutil.WebAuthnURLPath, true)+`,\n\t\t\t`+routeString(\"path\", \"/ping\", false)+`,\n\t\t\t`+routeString(\"path\", \"/healthz\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.well-known/pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.well-known/pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/robots.txt\", false)+`\n\t\t]`, routes)\n\t})\n\n\tt.Run(\"without robots\", func(t *testing.T) {\n\t\toptions := &config.Options{\n\t\t\tServices:                 \"all\",\n\t\t\tAuthenticateURLString:    \"https://authenticate.example.com\",\n\t\t\tAuthenticateCallbackPath: \"/oauth2/callback\",\n\t\t\tPolicies: []config.Policy{{\n\t\t\t\tFrom:                             \"https://from.example.com\",\n\t\t\t\tTo:                               mustParseWeightedURLs(t, \"https://to.example.com\"),\n\t\t\t\tAllowPublicUnauthenticatedAccess: true,\n\t\t\t}},\n\t\t}\n\t\t_ = options.Policies[0].Validate()\n\t\troutes, err := b.buildPomeriumHTTPRoutes(options, \"from.example.com\", false)\n\t\trequire.NoError(t, err)\n\n\t\ttestutil.AssertProtoJSONEqual(t, `[\n\t\t\t`+routeString(\"path\", \"/.pomerium/jwt\", true)+`,\n\t\t\t`+routeString(\"path\", urlutil.WebAuthnURLPath, true)+`,\n\t\t\t`+routeString(\"path\", \"/ping\", false)+`,\n\t\t\t`+routeString(\"path\", \"/healthz\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.pomerium/\", false)+`,\n\t\t\t`+routeString(\"path\", \"/.well-known/pomerium\", false)+`,\n\t\t\t`+routeString(\"prefix\", \"/.well-known/pomerium/\", false)+`\n\t\t]`, routes)\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestEventListener_ValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"server url can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"generic.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Generic)\n\n\tfor name, value := range eventSource.Spec.Generic {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGenericEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) StageImplantBuild(ctx context.Context, in *clientpb.ImplantStageReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/StageImplantBuild\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func pathHasPrefixFold(s, prefix string) bool {\n\tif len(s) < len(prefix) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(prefix); i++ {\n\t\tif isSlash(prefix[i]) {\n\t\t\tif !isSlash(s[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else if toUpper(prefix[i]) != toUpper(s[i]) {\n\t\t\treturn false\n\t\t}\n\t}\n\tif len(s) > len(prefix) && !isSlash(s[len(prefix)]) {\n\t\treturn false\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (client AccountsClient) ListByResourceGroup(ctx context.Context, resourceGroupName string) (result AccountListResult, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/AccountsClient.ListByResourceGroup\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\treq, err := client.ListByResourceGroupPreparer(ctx, resourceGroupName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListByResourceGroup\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.ListByResourceGroupSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListByResourceGroup\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.ListByResourceGroupResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListByResourceGroup\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (a *ClientApp) generateAppState(returnURL string, w http.ResponseWriter) (string, error) {\n\trandStr := rand.RandString(10)\n\tif returnURL == \"\" {\n\t\treturnURL = a.baseHRef\n\t}\n\tcookieValue := fmt.Sprintf(\"%s:%s\", randStr, returnURL)\n\tif encrypted, err := crypto.Encrypt([]byte(cookieValue), a.encryptionKey); err != nil {\n\t\treturn \"\", err\n\t} else {\n\t\tcookieValue = hex.EncodeToString(encrypted)\n\t}\n\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     common.StateCookieName,\n\t\tValue:    cookieValue,\n\t\tExpires:  time.Now().Add(common.StateCookieMaxAge),\n\t\tHttpOnly: true,\n\t\tSameSite: http.SameSiteLaxMode,\n\t\tSecure:   a.secureCookie,\n\t})\n\treturn randStr, nil\n}", "is_vulnerable": 1}
{"code": "func (iter *TagsListResultIterator) NextWithContext(ctx context.Context) (err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/TagsListResultIterator.NextWithContext\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif iter.Response().Response.Response != nil {\n\t\t\t\tsc = iter.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\titer.i++\n\tif iter.i < len(iter.page.Values()) {\n\t\treturn nil\n\t}\n\terr = iter.page.NextWithContext(ctx)\n\tif err != nil {\n\t\titer.i--\n\t\treturn err\n\t}\n\titer.i = 0\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func setUids(ruid, euid, suid int) error {\n\tlog.Printf(\"Setting ruid=%d euid=%d suid=%d\", ruid, euid, suid)\n\t// We elevate the all the privs before setting them. This prevents\n\t// issues with (ruid=1000,euid=1000,suid=0), where just a single call\n\t// to setresuid might fail with permission denied.\n\tif res, err := C.setresuid(0, 0, 0); res < 0 {\n\t\treturn errors.Wrapf(err.(syscall.Errno), \"setting uids\")\n\t}\n\tif res, err := C.setresuid(C.uid_t(ruid), C.uid_t(euid), C.uid_t(suid)); res < 0 {\n\t\treturn errors.Wrapf(err.(syscall.Errno), \"setting uids\")\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tgo func() {\n\t\t\tdefer GinkgoRecover()\n\t\t\t<-finishHandshake\n\t\t\tcryptoSetup.EXPECT().StartHandshake()\n\t\t\tcryptoSetup.EXPECT().NextEvent().Return(handshake.Event{Kind: handshake.EventHandshakeComplete})\n\t\t\tcryptoSetup.EXPECT().NextEvent().Return(handshake.Event{Kind: handshake.EventNoEvent})\n\t\t\tcryptoSetup.EXPECT().SetHandshakeConfirmed()\n\t\t\tcryptoSetup.EXPECT().GetSessionTicket()\n\t\t\tconn.run()\n\t\t}()", "is_vulnerable": 1}
{"code": "func (mr *MockOpenIDConnectRequestStorageMockRecorder) CreateOpenIDConnectSession(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"CreateOpenIDConnectSession\", reflect.TypeOf((*MockOpenIDConnectRequestStorage)(nil).CreateOpenIDConnectSession), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func (s *Server) getApplicationEnforceRBACClient(ctx context.Context, action, project, namespace, name, resourceVersion string) (*appv1.Application, error) {\n\tnamespaceOrDefault := s.appNamespaceOrDefault(namespace)\n\treturn s.getAppEnforceRBAC(ctx, action, project, namespaceOrDefault, name, func() (*appv1.Application, error) {\n\t\tif !s.isNamespaceEnabled(namespaceOrDefault) {\n\t\t\treturn nil, security.NamespaceNotPermittedError(namespaceOrDefault)\n\t\t}\n\t\treturn s.appclientset.ArgoprojV1alpha1().Applications(namespaceOrDefault).Get(ctx, name, metav1.GetOptions{\n\t\t\tResourceVersion: resourceVersion,\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func (c *CycleDetectionCheckResolver) ResolveCheck(\n\tctx context.Context,\n\treq *ResolveCheckRequest,\n) (*ResolveCheckResponse, error) {\n\tctx, span := tracer.Start(ctx, \"ResolveCheck\")\n\tdefer span.End()\n\tspan.SetAttributes(attribute.String(\"resolver_type\", \"CycleDetectionCheckResolver\"))\n\tspan.SetAttributes(attribute.String(\"tuple_key\", req.GetTupleKey().String()))\n\n\tkey := tuple.TupleKeyToString(req.GetTupleKey())\n\n\tif req.VisitedPaths == nil {\n\t\treq.VisitedPaths = map[string]struct{}{}\n\t}\n\n\t_, cycleDetected := req.VisitedPaths[key]\n\tspan.SetAttributes(attribute.Bool(\"cycle_detected\", cycleDetected))\n\tif cycleDetected {\n\t\treturn nil, ErrCycleDetected\n\t}\n\n\treq.VisitedPaths[key] = struct{}{}\n\n\treturn c.delegate.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\tStoreID:              req.GetStoreID(),\n\t\tAuthorizationModelID: req.GetAuthorizationModelID(),\n\t\tTupleKey:             req.GetTupleKey(),\n\t\tContextualTuples:     req.GetContextualTuples(),\n\t\tRequestMetadata:      req.GetRequestMetadata(),\n\t\tVisitedPaths:         req.VisitedPaths,\n\t\tContext:              req.GetContext(),\n\t})\n}", "is_vulnerable": 1}
{"code": "func (i *instances) Supported() bool {\n\treturn i.platform == \"kubernetes\" || i.platform == \"standalone\"\n}", "is_vulnerable": 1}
{"code": "func (ctx *Ctx) AuthZResponse(rm ResponseModifier, r *http.Request) error {\n\tctx.authReq.ResponseStatusCode = rm.StatusCode()\n\tctx.authReq.ResponseHeaders = headers(rm.Header())\n\n\tif sendBody(ctx.requestURI, rm.Header()) {\n\t\tctx.authReq.ResponseBody = rm.RawBody()\n\t}\n\n\tfor _, plugin := range ctx.plugins {\n\t\tlogrus.Debugf(\"AuthZ response using plugin %s\", plugin.Name())\n\n\t\tauthRes, err := plugin.AuthZResponse(ctx.authReq)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"plugin %s failed with error: %s\", plugin.Name(), err)\n\t\t}\n\n\t\tif !authRes.Allow {\n\t\t\treturn newAuthorizationError(plugin.Name(), authRes.Msg)\n\t\t}\n\t}\n\n\trm.FlushAll()\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *DecryptionClient) GetObject(input *s3.GetObjectInput) (*s3.GetObjectOutput, error) {\n\treturn getObject(c.getClientOptions(), input)\n}", "is_vulnerable": 0}
{"code": "func (a mirror) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, mirrorAnnotation.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (s *codeMonitorStore) UpdateEmailAction(ctx context.Context, id int64, args *EmailActionArgs) (*EmailAction, error) {\n\ta := actor.FromContext(ctx)\n\tq := sqlf.Sprintf(\n\t\tupdateActionEmailFmtStr,\n\t\targs.Enabled,\n\t\targs.IncludeResults,\n\t\targs.Priority,\n\t\targs.Header,\n\t\ta.UID,\n\t\ts.Now(),\n\t\tid,\n\t\ta.UID,\n\t\tsqlf.Join(emailsColumns, \", \"),\n\t)\n\n\trow := s.QueryRow(ctx, q)\n\treturn scanEmail(row)\n}", "is_vulnerable": 0}
{"code": "func init() {\n\trootCmd.AddCommand(serverCmd)\n\n\tserverCmd.Flags().StringVarP(&options.ServerAddr, \"address\", \"a\", \"localhost:7171\", \"server listening address\")\n\tserverCmd.Flags().BoolVarP(&options.AllowInsecureURIs, \"allow-insecure-uri\", \"A\", false, \"allow uris that dont start with http(s)\")\n}", "is_vulnerable": 0}
{"code": "func (c *Config) SetTrustedFolderFeatureEnabled(enabled bool) {\n\tc.m.Lock()\n\tdefer c.m.Unlock()\n\tc.trustedFoldersFeatureEnabled = enabled\n}", "is_vulnerable": 0}
{"code": "func (kp *kmsKeyHandler) GenerateCipherDataWithContext(ctx aws.Context, keySize, ivSize int) (CipherData, error) {\n\treturn kp.GenerateCipherDataWithCEKAlgWithContext(ctx, keySize, ivSize, \"\")\n}", "is_vulnerable": 0}
{"code": "func (db backend) GetDocumentation() parser.AnnotationFields {\n\treturn db.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func TestApplyDestinationRuleOSCACert(t *testing.T) {\n\tdefer func() {\n\t\tfeatures.VerifyCertAtClient = false\n\t}()\n\tservicePort := model.PortList{\n\t\t&model.Port{\n\t\t\tName:     \"default\",\n\t\t\tPort:     8080,\n\t\t\tProtocol: protocol.HTTP,\n\t\t},\n\t\t&model.Port{\n\t\t\tName:     \"auto\",\n\t\t\tPort:     9090,\n\t\t\tProtocol: protocol.Unsupported,\n\t\t},\n\t}\n\tservice := &model.Service{\n\t\tHostname:   host.Name(\"foo.default.svc.cluster.local\"),\n\t\tPorts:      servicePort,\n\t\tResolution: model.ClientSideLB,\n\t\tAttributes: model.ServiceAttributes{\n\t\t\tNamespace: TestServiceNamespace,\n\t\t},\n\t}\n\n\tcases := []struct {\n\t\tname                      string\n\t\tcluster                   *cluster.Cluster\n\t\tclusterMode               ClusterMode\n\t\tservice                   *model.Service\n\t\tport                      *model.Port\n\t\tnetworkView               map[network.ID]bool\n\t\tdestRule                  *networking.DestinationRule\n\t\texpectedCaCertificateName string\n\t\tenableVerifyCertAtClient  bool\n\t}{\n\t\t{\n\t\t\tname:        \"VerifyCertAtClient set and destination rule with empty string CaCertificates\",\n\t\t\tcluster:     &cluster.Cluster{Name: \"foo\", ClusterDiscoveryType: &cluster.Cluster_Type{Type: cluster.Cluster_EDS}},\n\t\t\tclusterMode: DefaultClusterMode,\n\t\t\tservice:     service,\n\t\t\tport:        servicePort[0],\n\t\t\tnetworkView: map[network.ID]bool{},\n\t\t\tdestRule: &networking.DestinationRule{\n\t\t\t\tHost: \"foo.default.svc.cluster.local\",\n\t\t\t\tTrafficPolicy: &networking.TrafficPolicy{\n\t\t\t\t\tConnectionPool: &networking.ConnectionPoolSettings{\n\t\t\t\t\t\tHttp: &networking.ConnectionPoolSettings_HTTPSettings{\n\t\t\t\t\t\t\tMaxRetries:        10,\n\t\t\t\t\t\t\tUseClientProtocol: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTls: &networking.ClientTLSSettings{\n\t\t\t\t\t\tCaCertificates: \"\",\n\t\t\t\t\t\tMode:           networking.ClientTLSSettings_SIMPLE,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedCaCertificateName: \"system\",\n\t\t\tenableVerifyCertAtClient:  true,\n\t\t},\n\t\t{\n\t\t\tname:        \"VerifyCertAtClient set and destination rule with CaCertificates\",\n\t\t\tcluster:     &cluster.Cluster{Name: \"foo\", ClusterDiscoveryType: &cluster.Cluster_Type{Type: cluster.Cluster_EDS}},\n\t\t\tclusterMode: DefaultClusterMode,\n\t\t\tservice:     service,\n\t\t\tport:        servicePort[0],\n\t\t\tnetworkView: map[network.ID]bool{},\n\t\t\tdestRule: &networking.DestinationRule{\n\t\t\t\tHost: \"foo.default.svc.cluster.local\",\n\t\t\t\tTrafficPolicy: &networking.TrafficPolicy{\n\t\t\t\t\tConnectionPool: &networking.ConnectionPoolSettings{\n\t\t\t\t\t\tHttp: &networking.ConnectionPoolSettings_HTTPSettings{\n\t\t\t\t\t\t\tMaxRetries:        10,\n\t\t\t\t\t\t\tUseClientProtocol: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTls: &networking.ClientTLSSettings{\n\t\t\t\t\t\tCaCertificates: constants.DefaultRootCert,\n\t\t\t\t\t\tMode:           networking.ClientTLSSettings_SIMPLE,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedCaCertificateName: constants.DefaultRootCert,\n\t\t\tenableVerifyCertAtClient:  true,\n\t\t},\n\t\t{\n\t\t\tname:        \"VerifyCertAtClient set and destination rule without CaCertificates\",\n\t\t\tcluster:     &cluster.Cluster{Name: \"foo\", ClusterDiscoveryType: &cluster.Cluster_Type{Type: cluster.Cluster_EDS}},\n\t\t\tclusterMode: DefaultClusterMode,\n\t\t\tservice:     service,\n\t\t\tport:        servicePort[0],\n\t\t\tnetworkView: map[network.ID]bool{},\n\t\t\tdestRule: &networking.DestinationRule{\n\t\t\t\tHost: \"foo.default.svc.cluster.local\",\n\t\t\t\tTrafficPolicy: &networking.TrafficPolicy{\n\t\t\t\t\tConnectionPool: &networking.ConnectionPoolSettings{\n\t\t\t\t\t\tHttp: &networking.ConnectionPoolSettings_HTTPSettings{\n\t\t\t\t\t\t\tMaxRetries:        10,\n\t\t\t\t\t\t\tUseClientProtocol: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTls: &networking.ClientTLSSettings{\n\t\t\t\t\t\tMode: networking.ClientTLSSettings_SIMPLE,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedCaCertificateName: \"system\",\n\t\t\tenableVerifyCertAtClient:  true,\n\t\t},\n\t\t{\n\t\t\tname:        \"VerifyCertAtClient false and destination rule without CaCertificates\",\n\t\t\tcluster:     &cluster.Cluster{Name: \"foo\", ClusterDiscoveryType: &cluster.Cluster_Type{Type: cluster.Cluster_EDS}},\n\t\t\tclusterMode: DefaultClusterMode,\n\t\t\tservice:     service,\n\t\t\tport:        servicePort[0],\n\t\t\tnetworkView: map[network.ID]bool{},\n\t\t\tdestRule: &networking.DestinationRule{\n\t\t\t\tHost: \"foo.default.svc.cluster.local\",\n\t\t\t\tTrafficPolicy: &networking.TrafficPolicy{\n\t\t\t\t\tConnectionPool: &networking.ConnectionPoolSettings{\n\t\t\t\t\t\tHttp: &networking.ConnectionPoolSettings_HTTPSettings{\n\t\t\t\t\t\t\tMaxRetries:        10,\n\t\t\t\t\t\t\tUseClientProtocol: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTls: &networking.ClientTLSSettings{\n\t\t\t\t\t\tMode: networking.ClientTLSSettings_SIMPLE,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedCaCertificateName: \"\",\n\t\t\tenableVerifyCertAtClient:  false,\n\t\t},\n\t\t{\n\t\t\tname:        \"VerifyCertAtClient false and destination rule with CaCertificates\",\n\t\t\tcluster:     &cluster.Cluster{Name: \"foo\", ClusterDiscoveryType: &cluster.Cluster_Type{Type: cluster.Cluster_EDS}},\n\t\t\tclusterMode: DefaultClusterMode,\n\t\t\tservice:     service,\n\t\t\tport:        servicePort[0],\n\t\t\tnetworkView: map[network.ID]bool{},\n\t\t\tdestRule: &networking.DestinationRule{\n\t\t\t\tHost: \"foo.default.svc.cluster.local\",\n\t\t\t\tTrafficPolicy: &networking.TrafficPolicy{\n\t\t\t\t\tConnectionPool: &networking.ConnectionPoolSettings{\n\t\t\t\t\t\tHttp: &networking.ConnectionPoolSettings_HTTPSettings{\n\t\t\t\t\t\t\tMaxRetries:        10,\n\t\t\t\t\t\t\tUseClientProtocol: true,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tTls: &networking.ClientTLSSettings{\n\t\t\t\t\t\tCaCertificates: constants.DefaultRootCert,\n\t\t\t\t\t\tMode:           networking.ClientTLSSettings_SIMPLE,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedCaCertificateName: constants.DefaultRootCert,\n\t\t\tenableVerifyCertAtClient:  false,\n\t\t},\n\t}\n\n\tfor _, tt := range cases {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tfeatures.VerifyCertAtClient = tt.enableVerifyCertAtClient\n\t\t\tinstances := []*model.ServiceInstance{\n\t\t\t\t{\n\t\t\t\t\tService:     tt.service,\n\t\t\t\t\tServicePort: tt.port,\n\t\t\t\t\tEndpoint: &model.IstioEndpoint{\n\t\t\t\t\t\tAddress:      \"192.168.1.1\",\n\t\t\t\t\t\tEndpointPort: 10001,\n\t\t\t\t\t\tLocality: model.Locality{\n\t\t\t\t\t\t\tClusterID: \"\",\n\t\t\t\t\t\t\tLabel:     \"region1/zone1/subzone1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\tTLSMode: model.IstioMutualTLSModeLabel,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tvar cfg *config.Config\n\t\t\tif tt.destRule != nil {\n\t\t\t\tcfg = &config.Config{\n\t\t\t\t\tMeta: config.Meta{\n\t\t\t\t\t\tGroupVersionKind: gvk.DestinationRule,\n\t\t\t\t\t\tName:             \"acme\",\n\t\t\t\t\t\tNamespace:        \"default\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec: tt.destRule,\n\t\t\t\t}\n\t\t\t}\n\t\t\tcg := NewConfigGenTest(t, TestOptions{\n\t\t\t\tConfigPointers: []*config.Config{cfg},\n\t\t\t\tServices:       []*model.Service{tt.service},\n\t\t\t})\n\t\t\tcg.MemRegistry.WantGetProxyServiceInstances = instances\n\t\t\tproxy := cg.SetupProxy(nil)\n\t\t\tcb := NewClusterBuilder(proxy, &model.PushRequest{Push: cg.PushContext()}, nil)\n\n\t\t\tec := NewMutableCluster(tt.cluster)\n\t\t\tdestRule := cb.req.Push.DestinationRule(proxy, tt.service)\n\n\t\t\t// ACT\n\t\t\t_ = cb.applyDestinationRule(ec, tt.clusterMode, tt.service, tt.port, tt.networkView, destRule, nil)\n\n\t\t\tbyteArray, err := config.ToJSON(destRule.Spec)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Could not parse destination rule: %v\", err)\n\t\t\t}\n\t\t\tdr := &networking.DestinationRule{}\n\t\t\terr = json.Unmarshal(byteArray, &dr)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Could not unmarshal destination rule: %v\", err)\n\t\t\t}\n\t\t\tca := dr.TrafficPolicy.Tls.CaCertificates\n\t\t\tif ca != tt.expectedCaCertificateName {\n\t\t\t\tt.Errorf(\"%v: got unexpected caCertitifcates field. Expected (%v), received (%v)\", tt.name, tt.expectedCaCertificateName, ca)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (db *Database) AddAPIKey(r *requests.Request) error {\n\tdb.mu.Lock()\n\tdefer db.mu.Unlock()\n\tuser, err := db.validateUserIdentity(r.User.Username, r.User.Email)\n\tif err != nil {\n\t\treturn errors.ErrAddAPIKey.WithArgs(r.Key.Usage, err)\n\t}\n\ts := GetRandomStringFromRange(72, 96)\n\tfailCount := 0\n\tfor {\n\t\thk, err := NewPassword(s)\n\t\tif err != nil {\n\t\t\tif failCount > 10 {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfailCount++\n\t\t\tcontinue\n\t\t}\n\t\tkeyPrefix := string(s[:24])\n\t\tif _, exists := db.refAPIKey[keyPrefix]; exists {\n\t\t\tcontinue\n\t\t}\n\t\tr.Response.Payload = s\n\t\tr.Key.Payload = hk.Hash\n\t\tr.Key.Prefix = keyPrefix\n\t\tif err := user.AddAPIKey(r); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdb.refAPIKey[keyPrefix] = user\n\t\tbreak\n\t}\n\n\tif err := db.commit(); err != nil {\n\t\treturn errors.ErrAddAPIKey.WithArgs(r.Key.Usage, err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func loadBalancerServiceChanged(current, expected *corev1.Service, platform *configv1.PlatformStatus) (bool, *corev1.Service, bool) {\n\tscopeChanged := loadBalancerServiceScopeChanged(current, expected, platform)\n\n\tserviceCmpOpts := []cmp.Option{\n\t\t// Ignore fields that the API, other controllers, or user may\n\t\t// have modified.\n\t\tcmpopts.IgnoreFields(corev1.ServicePort{}, \"NodePort\"),\n\t\tcmpopts.IgnoreFields(corev1.ServiceSpec{}, \"ClusterIP\", \"ExternalIPs\", \"HealthCheckNodePort\"),\n\t\tcmp.Comparer(cmpServiceAffinity),\n\t\tcmpopts.EquateEmpty(),\n\t}\n\tif !scopeChanged && cmp.Equal(current.Spec, expected.Spec, serviceCmpOpts...) {\n\t\treturn false, nil, false\n\t}\n\n\tupdated := current.DeepCopy()\n\tif updated.Annotations == nil {\n\t\tupdated.Annotations = map[string]string{}\n\t}\n\tfor name := range InternalLBAnnotations[platform.Type] {\n\t\tif v, ok := expected.Annotations[name]; ok {\n\t\t\tupdated.Annotations[name] = v\n\t\t} else {\n\t\t\tdelete(updated.Annotations, name)\n\t\t}\n\t}\n\n\tupdated.Spec = expected.Spec\n\n\t// Preserve fields that the API, other controllers, or user may have\n\t// modified.\n\tupdated.Spec.ClusterIP = current.Spec.ClusterIP\n\tupdated.Spec.ExternalIPs = current.Spec.ExternalIPs\n\tupdated.Spec.HealthCheckNodePort = current.Spec.HealthCheckNodePort\n\tfor i, updatedPort := range updated.Spec.Ports {\n\t\tfor _, currentPort := range current.Spec.Ports {\n\t\t\tif currentPort.Name == updatedPort.Name {\n\t\t\t\tupdated.Spec.Ports[i].NodePort = currentPort.NodePort\n\t\t\t}\n\t\t}\n\t}\n\n\t// When switching between internal scope and external scope, it may be\n\t// necessary to delete and recreate the service, depending on the cloud\n\t// provider implementation:\n\t//\n\t// * Azure and GCE can handle changing scope, so updating the annotation\n\t//   on the service suffices.\n\t//\n\t// * AWS cannot handle changing scope, so the service needs to be\n\t//   recreated.\n\t//\n\t// * IBM Cloud may or may not handle scope change, so recreate the\n\t//   service to be safe.\n\tneedsRecreate := false\n\tif scopeChanged {\n\t\tswitch platform.Type {\n\t\tcase configv1.AWSPlatformType, configv1.IBMCloudPlatformType:\n\t\t\tneedsRecreate = true\n\t\t}\n\t}\n\n\treturn true, updated, needsRecreate\n}", "is_vulnerable": 0}
{"code": "func main() {\n\tif len(os.Args) < 3 {\n\t\tfatal(usage)\n\t}\n\n\tcmd, filename := os.Args[1], os.Args[2]\n\n\tff := archiver.MatchingFormat(filename)\n\tif ff == nil {\n\t\tfatalf(\"%s: Unsupported file extension\", filename)\n\t}\n\n\tvar err error\n\tswitch cmd {\n\tcase \"make\":\n\t\tif len(os.Args) < 4 {\n\t\t\tfatal(usage)\n\t\t}\n\t\terr = ff.Make(filename, os.Args[3:])\n\tcase \"open\":\n\t\tdest := \"\"\n\t\tif len(os.Args) == 4 {\n\t\t\tdest = os.Args[3]\n\t\t} else if len(os.Args) > 4 {\n\t\t\tfatal(usage)\n\t\t}\n\t\terr = ff.Open(filename, dest)\n\tdefault:\n\t\tfatal(usage)\n\t}\n\tif err != nil {\n\t\tfatal(err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *reconciler) finalizeLoadBalancerService(ci *operatorv1.IngressController) (bool, error) {\n\thaveLBS, service, err := r.currentLoadBalancerService(ci)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tif !haveLBS {\n\t\treturn false, nil\n\t}\n\t_, err = r.deleteLoadBalancerServiceFinalizer(service)\n\treturn true, err\n}", "is_vulnerable": 0}
{"code": "func (m *NidRepNonByteCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepNonByteCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepNonByteCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field1 = append(m.Field1, T{})\n\t\t\tif err := m.Field1[len(m.Field1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func Nil(t TestingT, object interface{}, msgAndArgs ...interface{}) {\n\tif assert.Nil(t, object, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (k *Key) Disabled() bool {\n\tres := C.key_disabled(k.k) != 0\n\truntime.KeepAlive(k)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) GreaterOrEqual(e1 interface{}, e2 interface{}, msgAndArgs ...interface{}) bool {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn GreaterOrEqual(a.t, e1, e2, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func NewTenantInstrumentationMiddleware(tenantHeaderName string, defaultTenant string, reg prometheus.Registerer, buckets []float64) InstrumentationMiddleware {\n\treturn &tenantInstrumentationMiddleware{\n\t\ttenantHeaderName: tenantHeaderName,\n\t\tdefaultTenant:    defaultTenant,\n\t\tmetrics:          newDefaultMetrics(reg, buckets, []string{\"tenant\"}),\n\t}\n}", "is_vulnerable": 0}
{"code": "func matchType(sig oci.Signature, expectedType string) (bool, string, error) {\n\tif expectedType != \"\" {\n\t\tstatement, _, err := decodeStatement(sig)\n\t\tif err != nil {\n\t\t\treturn false, \"\", fmt.Errorf(\"failed to decode type: %w\", err)\n\t\t}\n\n\t\tif pType, ok := statement[\"type\"]; ok {\n\t\t\tif pType.(string) == expectedType {\n\t\t\t\treturn true, pType.(string), nil\n\t\t\t}\n\t\t}\n\t}\n\treturn false, \"\", nil\n}", "is_vulnerable": 0}
{"code": "func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descriptor, cc *encconfig.CryptoConfig, lf LayerFilter, cryptoOp cryptoOp) (ocispec.Descriptor, bool, error) {\n\t// read the index; if any layer is encrypted and any manifests change we will need to rewrite it\n\tb, err := content.ReadBlob(ctx, cs, desc)\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, false, err\n\t}\n\n\tvar index ocispec.Index\n\tif err := json.Unmarshal(b, &index); err != nil {\n\t\treturn ocispec.Descriptor{}, false, err\n\t}\n\n\tvar newManifests []ocispec.Descriptor\n\tmodified := false\n\tfor _, manifest := range index.Manifests {\n\t\tif cryptoOp == cryptoOpUnwrapOnly && !isLocalPlatform(manifest.Platform) {\n\t\t\tcontinue\n\t\t}\n\t\tnewManifest, m, err := cryptChildren(ctx, cs, manifest, cc, lf, cryptoOp, manifest.Platform)\n\t\tif err != nil || cryptoOp == cryptoOpUnwrapOnly {\n\t\t\treturn ocispec.Descriptor{}, false, err\n\t\t}\n\t\tif m {\n\t\t\tmodified = true\n\t\t}\n\t\tnewManifests = append(newManifests, newManifest)\n\t}\n\tif cryptoOp == cryptoOpUnwrapOnly {\n\t\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"No manifest found for local platform\")\n\t}\n\n\tif modified {\n\t\t// we need to update the index\n\t\tnewIndex := ocispec.Index{\n\t\t\tVersioned: index.Versioned,\n\t\t\tManifests: newManifests,\n\t\t}\n\n\t\tmb, err := json.MarshalIndent(newIndex, \"\", \"   \")\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"failed to marshal index: %w\", err)\n\t\t}\n\n\t\tnewDesc := ocispec.Descriptor{\n\t\t\tMediaType: ocispec.MediaTypeImageIndex,\n\t\t\tSize:      int64(len(mb)),\n\t\t\tDigest:    digest.Canonical.FromBytes(mb),\n\t\t}\n\n\t\tlabels := map[string]string{}\n\t\tfor i, m := range newIndex.Manifests {\n\t\t\tlabels[fmt.Sprintf(\"containerd.io/gc.ref.content.%d\", i)] = m.Digest.String()\n\t\t}\n\n\t\tref := fmt.Sprintf(\"index-%s\", newDesc.Digest.String())\n\n\t\tif err = content.WriteBlob(ctx, cs, ref, bytes.NewReader(mb), newDesc, content.WithLabels(labels)); err != nil {\n\t\t\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"failed to write index: %w\", err)\n\t\t}\n\t\treturn newDesc, true, nil\n\t}\n\n\treturn desc, false, nil\n}", "is_vulnerable": 0}
{"code": "func (w *RemoteClusterTunnelManager) realNewAgentPool(ctx context.Context, cluster, addr string) (*AgentPool, error) {\n\tpool, err := NewAgentPool(ctx, AgentPoolConfig{\n\t\t// Configs for our cluster.\n\t\tClient:              w.cfg.AuthClient,\n\t\tAccessPoint:         w.cfg.AccessPoint,\n\t\tHostSigner:          w.cfg.HostSigner,\n\t\tHostUUID:            w.cfg.HostUUID,\n\t\tLocalCluster:        w.cfg.LocalCluster,\n\t\tClock:               w.cfg.Clock,\n\t\tKubeDialAddr:        w.cfg.KubeDialAddr,\n\t\tReverseTunnelServer: w.cfg.ReverseTunnelServer,\n\t\tFIPS:                w.cfg.FIPS,\n\t\t// RemoteClusterManager only runs on proxies.\n\t\tComponent: teleport.ComponentProxy,\n\n\t\t// Configs for remote cluster.\n\t\tCluster:   cluster,\n\t\tProxyAddr: addr,\n\t})\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err, \"failed creating reverse tunnel pool for remote cluster %q at address %q: %v\", cluster, addr, err)\n\t}\n\tgo pool.Start()\n\n\treturn pool, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Configurator) CAPems() []string {\n\tc.RLock()\n\tdefer c.RUnlock()\n\treturn append(c.manual.caPems, c.autoTLS.caPems()...)\n}", "is_vulnerable": 1}
{"code": "func (r *userRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\tusr := loggedUser(r.ctx)\n\tif !usr.IsAdmin {\n\t\treturn 0, rest.ErrPermissionDenied\n\t}\n\treturn r.CountAll(r.parseRestOptions(r.ctx, options...))\n}", "is_vulnerable": 0}
{"code": "func (p Precompile) Run(evm *vm.EVM, contract *vm.Contract, readOnly bool) (bz []byte, err error) {\n\tctx, _, method, initialGas, args, err := p.RunSetup(evm, contract, readOnly, p.IsTransaction)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// This handles any out of gas errors that may occur during the execution of a precompile query.\n\t// It avoids panics and returns the out of gas error so the EVM can continue gracefully.\n\tdefer cmn.HandleGasError(ctx, contract, initialGas, &err)()\n\n\tswitch method.Name {\n\t// Bank queries\n\tcase BalancesMethod:\n\t\tbz, err = p.Balances(ctx, contract, method, args)\n\tcase TotalSupplyMethod:\n\t\tbz, err = p.TotalSupply(ctx, contract, method, args)\n\tcase SupplyOfMethod:\n\t\tbz, err = p.SupplyOf(ctx, contract, method, args)\n\tdefault:\n\t\treturn nil, fmt.Errorf(cmn.ErrUnknownMethod, method.Name)\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcost := ctx.GasMeter().GasConsumed() - initialGas\n\n\tif !contract.UseGas(cost) {\n\t\treturn nil, vm.ErrOutOfGas\n\t}\n\n\treturn bz, nil\n}", "is_vulnerable": 1}
{"code": "func assertUnmarshalsTo(t *testing.T, expected any, actual any) {\n\tt.Helper()\n\n\tval, err := json.Marshal(expected)\n\trequire.NoError(t, err)\n\n\tassert.JSONEq(t, string(val), actual.(string))\n}", "is_vulnerable": 0}
{"code": "func (m *Node) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Node: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Node: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Label\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Label = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Children\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Children = append(m.Children, &Node{})\n\t\t\tif err := m.Children[len(m.Children)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (mt *MultiTenantServicePrincipalToken) AuxiliaryOAuthTokens() []string {\n\ttokens := make([]string, len(mt.AuxiliaryTokens))\n\tfor i := range mt.AuxiliaryTokens {\n\t\ttokens[i] = mt.AuxiliaryTokens[i].OAuthToken()\n\t}\n\treturn tokens\n}", "is_vulnerable": 0}
{"code": "func (client ProvidersClient) GetSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func TestHasCycle(t *testing.T) {\n\n\ttests := []struct {\n\t\tname       string\n\t\tmodel      string\n\t\tobjectType string\n\t\trelation   string\n\t\texpected   bool\n\t}{\n\t\t{\n\t\t\tname: \"test_1\",\n\t\t\tmodel: `\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define x as y\n\t\t\t    define y as x\n\t\t\t`,\n\t\t\tobjectType: \"resource\",\n\t\t\trelation:   \"x\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_2\",\n\t\t\tmodel: `\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define x as y\n\t\t\t    define y as z\n\t\t\t\tdefine z as x\n\t\t\t`,\n\t\t\tobjectType: \"resource\",\n\t\t\trelation:   \"y\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_3\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define x: [user] as self or y\n\t\t\t    define y: [user] as self or z\n\t\t\t\tdefine z: [user] as self or x\n\t\t\t`,\n\t\t\tobjectType: \"resource\",\n\t\t\trelation:   \"z\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_4\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t    define x: [user] as self or y\n\t\t\t    define y: [user] as self or z\n\t\t\t\tdefine z: [user] as self or x\n\t\t\t`,\n\t\t\tobjectType: \"resource\",\n\t\t\trelation:   \"z\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_5\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype resource\n\t\t\t  relations\n\t\t\t\tdefine x: [user] as self but not y\n\t\t\t\tdefine y: [user] as self but not z\n\t\t\t\tdefine z: [user] as self or x\n\t\t\t`,\n\t\t\tobjectType: \"resource\",\n\t\t\trelation:   \"x\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_6\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype group\n\t\t\t  relations\n\t\t\t\tdefine member: [user] as self or memberA or memberB or memberC\n\t\t\t\tdefine memberA: [user] as self or member or memberB or memberC\n\t\t\t\tdefine memberB: [user] as self or member or memberA or memberC\n\t\t\t\tdefine memberC: [user] as self or member or memberA or memberB\n\t\t\t`,\n\t\t\tobjectType: \"group\",\n\t\t\trelation:   \"member\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_7\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype account\n\t\t\trelations\n\t\t\t\tdefine admin: [user] as self or member or super_admin or owner\n\t\t\t\tdefine member: [user] as self or owner or admin or super_admin\n\t\t\t\tdefine super_admin: [user] as self or admin or member or owner\n\t\t\t\tdefine owner: [user] as self\n\t\t\t`,\n\t\t\tobjectType: \"account\",\n\t\t\trelation:   \"member\",\n\t\t\texpected:   true,\n\t\t},\n\t\t{\n\t\t\tname: \"test_8\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype account\n\t\t\trelations\n\t\t\t\tdefine admin: [user] as self or member or super_admin or owner\n\t\t\t\tdefine member: [user] as self or owner or admin or super_admin\n\t\t\t\tdefine super_admin: [user] as self or admin or member or owner\n\t\t\t\tdefine owner: [user] as self\n\t\t\t`,\n\t\t\tobjectType: \"account\",\n\t\t\trelation:   \"owner\",\n\t\t\texpected:   false,\n\t\t},\n\t\t{\n\t\t\tname: \"test_9\",\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t\tdefine editor: [user] as self\n\t\t\t\tdefine viewer: [document#viewer] as self or editor\n\t\t\t`,\n\t\t\tobjectType: \"document\",\n\t\t\trelation:   \"viewer\",\n\t\t\texpected:   false,\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\n\t\t\ttypesys := New(&openfgav1.AuthorizationModel{\n\t\t\t\tSchemaVersion:   SchemaVersion1_1,\n\t\t\t\tTypeDefinitions: parser.MustParse(test.model),\n\t\t\t})\n\n\t\t\thasCycle, err := typesys.HasCycle(test.objectType, test.relation)\n\t\t\trequire.Equal(t, test.expected, hasCycle)\n\t\t\trequire.NoError(t, err)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *DeleteOpsItemInput) Validate() error {\n\tinvalidParams := request.ErrInvalidParams{Context: \"DeleteOpsItemInput\"}\n\tif s.OpsItemId == nil {\n\t\tinvalidParams.Add(request.NewErrParamRequired(\"OpsItemId\"))\n\t}\n\n\tif invalidParams.Len() > 0 {\n\t\treturn invalidParams\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestServer_DeltaAggregatedResources_v3_NackLoop(t *testing.T) {\n\taclResolve := func(id string) (acl.Authorizer, error) {\n\t\t// Allow all\n\t\treturn acl.RootAuthorizer(\"manage\"), nil\n\t}\n\tscenario := newTestServerDeltaScenario(t, aclResolve, \"web-sidecar-proxy\", \"\", 0)\n\tmgr, errCh, envoy := scenario.mgr, scenario.errCh, scenario.envoy\n\n\tsid := structs.NewServiceID(\"web-sidecar-proxy\", nil)\n\n\t// Register the proxy to create state needed to Watch() on\n\tmgr.RegisterProxy(t, sid)\n\n\tvar snap *proxycfg.ConfigSnapshot\n\n\ttestutil.RunStep(t, \"initial setup\", func(t *testing.T) {\n\t\tsnap = newTestSnapshot(t, nil, \"\", nil)\n\n\t\t// Plug in a bad port for the public listener\n\t\tsnap.Port = 1\n\n\t\t// Send initial cluster discover.\n\t\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, &envoy_discovery_v3.DeltaDiscoveryRequest{})\n\n\t\t// Check no response sent yet\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\trequireProtocolVersionGauge(t, scenario, \"v3\", 1)\n\n\t\t// Deliver a new snapshot (tcp with one tcp upstream)\n\t\tmgr.DeliverConfig(t, sid, snap)\n\t})\n\n\ttestutil.RunStep(t, \"simulate Envoy NACKing initial listener\", func(t *testing.T) {\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ClusterType,\n\t\t\tNonce:   hexString(1),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:local_app\"),\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:db\"),\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// Envoy then tries to discover endpoints for those clusters.\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t\t\"geo-cache.default.dc1.query.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t},\n\t\t})\n\n\t\t// We should get a response immediately since the config is already present in\n\t\t// the server for endpoints. Note that this should not be racy if the server\n\t\t// is behaving well since the Cluster send above should be blocked until we\n\t\t// deliver a new config version.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.EndpointType,\n\t\t\tNonce:   hexString(2),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:db\"),\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// After receiving the endpoints Envoy sends an ACK for the clusters\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ClusterType, 1)\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// Envoy now sends listener request\n\t\tenvoy.SendDeltaReq(t, xdscommon.ListenerType, nil)\n\n\t\t// It also (in parallel) issues the endpoint ACK\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 2)\n\n\t\t// And should get a response immediately.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ListenerType,\n\t\t\tNonce:   hexString(3),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\t// Response contains public_listener with port that Envoy can't bind to\n\t\t\t\tmakeTestListener(t, snap, \"tcp:bad_public_listener\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:db\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// Envoy NACKs the listener update due to the bad public listener\n\t\tenvoy.SendDeltaReqNACK(t, xdscommon.ListenerType, 3, &rpcstatus.Status{})\n\n\t\t// Consul should not respond until a new snapshot is delivered\n\t\t// because the current snapshot is known to be bad.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\ttestutil.RunStep(t, \"simulate envoy NACKing a listener update\", func(t *testing.T) {\n\t\t// Correct the port and deliver a new snapshot\n\t\tsnap.Port = 9999\n\t\tmgr.DeliverConfig(t, sid, snap)\n\n\t\t// And should send a response immediately.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ListenerType,\n\t\t\tNonce:   hexString(4),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\t// Send a public listener that Envoy will accept\n\t\t\t\tmakeTestListener(t, snap, \"tcp:public_listener\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:db\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// New listener is acked now\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 4)\n\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\tenvoy.Close()\n\tselect {\n\tcase err := <-errCh:\n\t\trequire.NoError(t, err)\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatalf(\"timed out waiting for handler to finish\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *Timestamp) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTimestamp\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Timestamp: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Timestamp: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Seconds\", wireType)\n\t\t\t}\n\t\t\tm.Seconds = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTimestamp\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Seconds |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Nanos\", wireType)\n\t\t\t}\n\t\t\tm.Nanos = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTimestamp\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Nanos |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTimestamp(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTimestamp\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (t *DictController) GetSysDictByCode(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tcode := utils.SanitizeInput(ctx.Param(\"code\"))\n\tdata, err := t.sysDictService.GetSysDictByCode(code)\n\tif err != nil {\n\t\te := &response.AdminError{\n\t\t\tErrorCode:    http.StatusBadRequest,\n\t\t\tErrorMessage: err.Error(),\n\t\t}\n\t\t_ = ctx.Error(e)\n\t\treturn\n\t}\n\tresp.SetData(data)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (mp *MalfeasanceProof) MarshalLogObject(encoder log.ObjectEncoder) error {\n\tencoder.AddUint32(\"generated_layer\", mp.Layer.Uint32())\n\tswitch mp.Proof.Type {\n\tcase MultipleATXs:\n\t\tencoder.AddString(\"type\", \"multiple atxs\")\n\t\tp, ok := mp.Proof.Data.(*AtxProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase MultipleBallots:\n\t\tencoder.AddString(\"type\", \"multiple ballots\")\n\t\tp, ok := mp.Proof.Data.(*BallotProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase HareEquivocation:\n\t\tencoder.AddString(\"type\", \"hare equivocation\")\n\t\tp, ok := mp.Proof.Data.(*HareProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase InvalidPostIndex:\n\t\tencoder.AddString(\"type\", \"invalid post index\")\n\t\tp, ok := mp.Proof.Data.(*InvalidPostIndexProof)\n\t\tif ok {\n\t\t\tencoder.AddString(\"atx_id\", p.Atx.ID().String())\n\t\t\tencoder.AddString(\"smesher\", p.Atx.SmesherID.String())\n\t\t\tencoder.AddUint32(\"invalid index\", p.InvalidIdx)\n\t\t}\n\tcase InvalidPrevATX:\n\t\tencoder.AddString(\"type\", \"invalid prev atx\")\n\t\tp, ok := mp.Proof.Data.(*InvalidPrevATXProof)\n\t\tif ok {\n\t\t\tencoder.AddString(\"atx1_id\", p.Atx2.ID().String())\n\t\t\tencoder.AddString(\"atx2_id\", p.Atx2.ID().String())\n\t\t\tencoder.AddString(\"smesher\", p.Atx1.SmesherID.String())\n\t\t\tencoder.AddString(\"prev_atx\", p.Atx1.PrevATXID.String())\n\t\t}\n\tdefault:\n\t\tencoder.AddString(\"type\", \"unknown\")\n\t}\n\tencoder.AddTime(\"received\", mp.received)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func isOriginAllowed(allows []string, origin string) bool {\n\torigin = strings.ToLower(origin)\n\tfor _, allow := range allows {\n\t\tif allow == allOrigins {\n\t\t\treturn true\n\t\t}\n\n\t\tallow = strings.ToLower(allow)\n\t\tif origin == allow {\n\t\t\treturn true\n\t\t}\n\n\t\tif strings.HasSuffix(origin, \".\"+allow) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func NewComponents(platform string, daprClient scheme.Interface) Components {\n\tc := components{}\n\tc.platform = platform\n\n\tif platform == \"kubernetes\" {\n\t\tc.getComponentsFn = c.getKubernetesComponents\n\t\tc.daprClient = daprClient\n\t} else if platform == \"standalone\" {\n\t\tc.getComponentsFn = c.getStandaloneComponents\n\t}\n\treturn &c\n}", "is_vulnerable": 1}
{"code": "func (l *Login) handleDeviceAuthAction(w http.ResponseWriter, r *http.Request) {\n\tauthReq, err := l.ensureAuthRequest(r)\n\tif err != nil {\n\t\tl.redirectDeviceAuthStart(w, r, err.Error())\n\t\treturn\n\t}\n\tif !authReq.Done() {\n\t\tl.redirectDeviceAuthStart(w, r, \"authentication not completed\")\n\t\treturn\n\t}\n\tauthDev, ok := authReq.Request.(*domain.AuthRequestDevice)\n\tif !ok {\n\t\tl.redirectDeviceAuthStart(w, r, fmt.Sprintf(\"wrong auth request type: %T\", authReq.Request))\n\t\treturn\n\t}\n\n\taction := mux.Vars(r)[\"action\"]\n\tswitch action {\n\tcase deviceAuthAllowed:\n\t\t_, err = l.command.ApproveDeviceAuth(r.Context(), authDev.DeviceCode, authReq.UserID, authReq.UserOrgID, authReq.UserAuthMethodTypes(), authReq.AuthTime, authReq.PreferredLanguage, authReq.ToUserAgent())\n\tcase deviceAuthDenied:\n\t\t_, err = l.command.CancelDeviceAuth(r.Context(), authDev.DeviceCode, domain.DeviceAuthCanceledDenied)\n\tdefault:\n\t\tl.renderDeviceAuthAction(w, r, authReq, authDev.Scopes)\n\t\treturn\n\t}\n\tif err != nil {\n\t\tl.redirectDeviceAuthStart(w, r, err.Error())\n\t\treturn\n\t}\n\n\tl.renderDeviceAuthDone(w, r, authReq, action)\n}", "is_vulnerable": 0}
{"code": "func TestValidateIP(t *testing.T) {\n\tt.Parallel()\n\t// This allows the testing of the validateIP function\n\tnetInterfaceAddrs = func() ([]net.Addr, error) {\n\t\tvar ips []net.Addr\n\t\tvar err error\n\t\t//var ip net.IP\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"127.0.0.1\"), Mask: net.CIDRMask(8, 32)})\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"10.50.100.101\"), Mask: net.CIDRMask(24, 32)})\n\t\tips = append(ips, &net.IPNet{IP: net.ParseIP(\"::1\"), Mask: net.CIDRMask(128, 128)})\n\n\t\treturn ips, err\n\t}\n\tvar testIP string\n\tvar testCIDR string\n\tvar err error\n\n\ttestIP = \"10.50.100.101\"\n\ttestCIDR = \"\"\n\terr = validateIP(testIP, testCIDR)\n\t// Pass if err == nil\n\tif err != nil {\n\t\tt.Fatalf(\"Actual IP Match: expected nill, actual: %s\", err)\n\t}\n\n\ttestIP = \"10.50.100.102\"\n\ttestCIDR = \"10.50.100.0/24\"\n\terr = validateIP(testIP, testCIDR)\n\t// Pass if err == nil\n\tif err != nil {\n\t\tt.Fatalf(\"IP in CIDR: expected nill, actual: %s\", err)\n\t}\n\n\ttestIP = \"10.50.100.102\"\n\ttestCIDR = \"\"\n\terr = validateIP(testIP, testCIDR)\n\t// Fail if err == nil\n\tif err == nil {\n\t\tt.Fatalf(\"IP Does Not Match: expected error, actual: nil\")\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func (s *Sync) Process(results []SyncResult) (bool, int, error) {\n\tcommitted := false\n\n\tfor i, item := range results {\n\t\t// If the item was not requested, bail out\n\t\trequest := s.requests[item.Hash]\n\t\tif request == nil {\n\t\t\treturn committed, i, ErrNotRequested\n\t\t}\n\t\tif request.data != nil {\n\t\t\treturn committed, i, ErrAlreadyProcessed\n\t\t}\n\t\t// If the item is a raw entry request, commit directly\n\t\tif request.raw {\n\t\t\trequest.data = item.Data\n\t\t\ts.commit(request)\n\t\t\tcommitted = true\n\t\t\tcontinue\n\t\t}\n\t\t// Decode the node data content and update the request\n\t\tnode, err := decodeNode(item.Hash[:], item.Data)\n\t\tif err != nil {\n\t\t\treturn committed, i, err\n\t\t}\n\t\trequest.data = item.Data\n\n\t\t// Create and schedule a request for all the children nodes\n\t\trequests, err := s.children(request, node)\n\t\tif err != nil {\n\t\t\treturn committed, i, err\n\t\t}\n\t\tif len(requests) == 0 && request.deps == 0 {\n\t\t\ts.commit(request)\n\t\t\tcommitted = true\n\t\t\tcontinue\n\t\t}\n\t\trequest.deps += len(requests)\n\t\tfor _, child := range requests {\n\t\t\ts.schedule(child)\n\t\t}\n\t}\n\treturn committed, 0, nil\n}", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) handleWalkerError(err error, f ufs.FileInfo) error {\n\tif !IsErrorCode(err, ErrCodePathResolution) {\n\t\treturn err\n\t}\n\tif f != nil && f.IsDir() {\n\t\treturn filepath.SkipDir\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *TestSuiteIAM) TestLDAPSTSServiceAccounts(c *check) {\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\n\tbucket := getRandomBucketName()\n\terr := s.client.MakeBucket(ctx, bucket, minio.MakeBucketOptions{})\n\tif err != nil {\n\t\tc.Fatalf(\"bucket create error: %v\", err)\n\t}\n\n\t// Create policy\n\tpolicy := \"mypolicy\"\n\tpolicyBytes := []byte(fmt.Sprintf(`{\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n  {\n   \"Effect\": \"Allow\",\n   \"Action\": [\n    \"s3:PutObject\",\n    \"s3:GetObject\",\n    \"s3:ListBucket\"\n   ],\n   \"Resource\": [\n    \"arn:aws:s3:::%s/*\"\n   ]\n  }\n ]\n}`, bucket))\n\terr = s.adm.AddCannedPolicy(ctx, policy, policyBytes)\n\tif err != nil {\n\t\tc.Fatalf(\"policy add error: %v\", err)\n\t}\n\n\tuserDN := \"uid=dillon,ou=people,ou=swengg,dc=min,dc=io\"\n\terr = s.adm.SetPolicy(ctx, policy, userDN, false)\n\tif err != nil {\n\t\tc.Fatalf(\"Unable to set policy: %v\", err)\n\t}\n\n\tldapID := cr.LDAPIdentity{\n\t\tClient:       s.TestSuiteCommon.client,\n\t\tSTSEndpoint:  s.endPoint,\n\t\tLDAPUsername: \"dillon\",\n\t\tLDAPPassword: \"dillon\",\n\t}\n\n\tvalue, err := ldapID.Retrieve()\n\tif err != nil {\n\t\tc.Fatalf(\"Expected to generate STS creds, got err: %#v\", err)\n\t}\n\n\t// Check that the LDAP sts cred is actually working.\n\tminioClient, err := minio.New(s.endpoint, &minio.Options{\n\t\tCreds:     cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure:    s.secure,\n\t\tTransport: s.TestSuiteCommon.client.Transport,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Error initializing client: %v\", err)\n\t}\n\n\t// Validate that the client from sts creds can access the bucket.\n\tc.mustListObjects(ctx, minioClient, bucket)\n\n\t// Create an madmin client with user creds\n\tuserAdmClient, err := madmin.NewWithOptions(s.endpoint, &madmin.Options{\n\t\tCreds:  cr.NewStaticV4(value.AccessKeyID, value.SecretAccessKey, value.SessionToken),\n\t\tSecure: s.secure,\n\t})\n\tif err != nil {\n\t\tc.Fatalf(\"Err creating user admin client: %v\", err)\n\t}\n\tuserAdmClient.SetCustomTransport(s.TestSuiteCommon.client.Transport)\n\n\t// Create svc acc\n\tcr := c.mustCreateSvcAccount(ctx, value.AccessKeyID, userAdmClient)\n\n\t// 1. Check that svc account appears in listing\n\tc.assertSvcAccAppearsInListing(ctx, userAdmClient, value.AccessKeyID, cr.AccessKey)\n\n\t// 2. Check that svc account info can be queried\n\tc.assertSvcAccInfoQueryable(ctx, userAdmClient, value.AccessKeyID, cr.AccessKey, true)\n\n\t// 3. Check S3 access\n\tc.assertSvcAccS3Access(ctx, s, cr, bucket)\n\n\t// 4. Check that svc account can restrict the policy, and that the\n\t// session policy can be updated.\n\tc.assertSvcAccSessionPolicyUpdate(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 4. Check that service account's secret key and account status can be\n\t// updated.\n\tc.assertSvcAccSecretKeyAndStatusUpdate(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 5. Check that service account can be deleted.\n\tc.assertSvcAccDeletion(ctx, s, userAdmClient, value.AccessKeyID, bucket)\n\n\t// 6. Check that service account cannot be created for some other user.\n\tc.mustNotCreateSvcAccount(ctx, globalActiveCred.AccessKey, userAdmClient)\n}", "is_vulnerable": 0}
{"code": "func testSignerFromFile(t *testing.T, keyCert *keyCertPair, envelopeType, dir string) {\n\tkeyPath, certPath, err := prepareTestKeyCertFile(keyCert, envelopeType, dir)\n\tif err != nil {\n\t\tt.Fatalf(\"prepareTestKeyCertFile() failed: %v\", err)\n\t}\n\ts, err := NewFromFiles(keyPath, certPath)\n\tif err != nil {\n\t\tt.Fatalf(\"NewSignerFromFiles() failed: %v\", err)\n\t}\n\tdesc, opts := generateSigningContent(nil)\n\topts.SignatureMediaType = envelopeType\n\tsig, _, err := s.Sign(context.Background(), desc, opts)\n\tif err != nil {\n\t\tt.Fatalf(\"Sign() failed: %v\", err)\n\t}\n\t// basic verification\n\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], nil)\n}", "is_vulnerable": 1}
{"code": "\treturn func(ctx context.Context, req admission.Request) *admission.Response {\n\t\toldNs := &corev1.Namespace{}\n\t\tif err := decoder.DecodeRaw(req.OldObject, oldNs); err != nil {\n\t\t\treturn utils.ErroredResponse(err)\n\t\t}\n\n\t\ttntList := &capsulev1beta2.TenantList{}\n\t\tif err := c.List(ctx, tntList, client.MatchingFieldsSelector{\n\t\t\tSelector: fields.OneTermEqualSelector(\".status.namespaces\", oldNs.Name),\n\t\t}); err != nil {\n\t\t\treturn utils.ErroredResponse(err)\n\t\t}\n\n\t\tif !h.namespaceIsOwned(oldNs, tntList, req) {\n\t\t\trecorder.Eventf(oldNs, corev1.EventTypeWarning, \"OfflimitNamespace\", \"Namespace %s can not be patched\", oldNs.GetName())\n\n\t\t\tresponse := admission.Denied(\"Denied patch request for this namespace\")\n\n\t\t\treturn &response\n\t\t}\n\n\t\tnewNs := &corev1.Namespace{}\n\t\tif err := decoder.Decode(req, newNs); err != nil {\n\t\t\treturn utils.ErroredResponse(err)\n\t\t}\n\n\t\to, err := json.Marshal(newNs.DeepCopy())\n\t\tif err != nil {\n\t\t\tresponse := admission.Errored(http.StatusInternalServerError, err)\n\n\t\t\treturn &response\n\t\t}\n\n\t\tvar refs []metav1.OwnerReference\n\n\t\tfor _, ref := range oldNs.OwnerReferences {\n\t\t\tif capsuleutils.IsTenantOwnerReference(ref) {\n\t\t\t\trefs = append(refs, ref)\n\t\t\t}\n\t\t}\n\n\t\tfor _, ref := range newNs.OwnerReferences {\n\t\t\tif !capsuleutils.IsTenantOwnerReference(ref) {\n\t\t\t\trefs = append(refs, ref)\n\t\t\t}\n\t\t}\n\n\t\tnewNs.OwnerReferences = refs\n\n\t\tc, err := json.Marshal(newNs)\n\t\tif err != nil {\n\t\t\tresponse := admission.Errored(http.StatusInternalServerError, err)\n\n\t\t\treturn &response\n\t\t}\n\n\t\tresponse := admission.PatchResponseFromRaw(o, c)\n\n\t\treturn &response\n\t}\n}", "is_vulnerable": 0}
{"code": "func isCpusetListAvailable(provided, available string) (bool, error) {\n\tparsedAvailable, err := parsers.ParseUintList(available)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\t// 8192 is the normal maximum number of CPUs in Linux, so accept numbers up to this\n\t// or more if we actually have more CPUs.\n\tmax := 8192\n\tfor m := range parsedAvailable {\n\t\tif m > max {\n\t\t\tmax = m\n\t\t}\n\t}\n\tparsedProvided, err := parsers.ParseUintListMaximum(provided, max)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tfor k := range parsedProvided {\n\t\tif !parsedAvailable[k] {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}", "is_vulnerable": 0}
{"code": "func NewDataSession(ctx context.Context, opts DataSessionOptions) (*DataSession, error) {\n\t// create temp directory\n\ttempDir, err := os.MkdirTemp(\"\", \"wolfictl-advisory-data-session-*\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating temp dir: %w\", err)\n\t}\n\tds := &DataSession{\n\t\ttempDir: tempDir,\n\t\tdistro:  opts.Distro,\n\t}\n\n\tds.githubClient = opts.GitHubClient\n\n\t// clone advisories repo\n\trepo, err := git.PlainCloneContext(ctx, tempDir, false, &git.CloneOptions{\n\t\tURL:  opts.Distro.Absolute.AdvisoriesHTTPSCloneURL(),\n\t\tAuth: wgit.GetGitAuth(),\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cloning advisories repo: %w\", err)\n\t}\n\tds.repo = repo\n\n\t// checkout a new branch\n\tu := uuid.New()\n\tbranchName := fmt.Sprintf(\"wolfictl-data-session-%s\", u)\n\tds.workingBranch = branchName\n\twt, err := repo.Worktree()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"getting worktree: %w\", err)\n\t}\n\terr = wt.Checkout(&git.CheckoutOptions{\n\t\tBranch: plumbing.NewBranchReferenceName(branchName),\n\t\tCreate: true,\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"checking out new branch: %w\", err)\n\t}\n\n\t// index advisory documents\n\tindex, err := v2.NewIndex(ctx, rwos.DirFS(tempDir))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"indexing advisory documents: %w\", err)\n\t}\n\tds.index = index\n\n\treturn ds, nil\n}", "is_vulnerable": 1}
{"code": "func (self *InventoryGetFunction) Call(ctx context.Context,\n\tscope vfilter.Scope,\n\targs *ordereddict.Dict) vfilter.Any {\n\n\targ := &InventoryGetFunctionArgs{}\n\terr := arg_parser.ExtractArgsWithContext(ctx, scope, args, arg)\n\tif err != nil {\n\t\tscope.Log(\"inventory_get: %s\", err.Error())\n\t\treturn vfilter.Null{}\n\t}\n\n\terr = vql_subsystem.CheckAccess(scope, acls.SERVER_ADMIN)\n\tif err != nil {\n\t\tscope.Log(\"inventory_get: %s\", err)\n\t\treturn vfilter.Null{}\n\t}\n\n\tconfig_obj, ok := vql_subsystem.GetServerConfig(scope)\n\tif !ok {\n\t\tscope.Log(\"Command can only run on the server\")\n\t\treturn vfilter.Null{}\n\t}\n\n\tinventory, err := services.GetInventory(config_obj)\n\tif err != nil {\n\t\tscope.Log(\"inventory_get: %s\", err.Error())\n\t\treturn vfilter.Null{}\n\t}\n\n\ttool, err := inventory.GetToolInfo(ctx, config_obj, arg.Tool, arg.Version)\n\tif err != nil {\n\t\tscope.Log(\"inventory_get: %s\", err.Error())\n\t\treturn vfilter.Null{}\n\t}\n\n\turl := tool.ServeUrl\n\tif url == \"\" {\n\t\turl = tool.Url\n\t}\n\n\tresult := ordereddict.NewDict().\n\t\tSet(\"Tool_\"+arg.Tool+\"_HASH\", tool.Hash).\n\t\tSet(\"Tool_\"+arg.Tool+\"_FILENAME\", tool.Filename).\n\t\tSet(\"Tool_\"+arg.Tool+\"_URL\", url).\n\t\tSet(\"Definition\", tool)\n\treturn result\n}", "is_vulnerable": 1}
{"code": "func userKeyringIDLookup(uid int) (int, error) {\n\tcacheLock.Lock()\n\tdefer cacheLock.Unlock()\n\tif keyringID, ok := keyringIDCache[uid]; ok {\n\t\treturn keyringID, nil\n\t}\n\n\truid, euid := os.Getuid(), os.Geteuid()\n\t// If all the ids do not agree, we will have to change them\n\tneedSetUids := uid != ruid || uid != euid\n\n\t// The value of KEY_SPEC_USER_KEYRING is determined by the real uid, so\n\t// we must set the ruid appropriately. Note that this will also trigger\n\t// the creation of the uid keyring if it does not yet exist.\n\tif needSetUids {\n\t\tdefer setUids(ruid, euid) // Always reset privileges\n\t\tif err := setUids(uid, 0); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tkeyringID, err := unix.KeyctlGetKeyringID(unix.KEY_SPEC_USER_KEYRING, true)\n\tlog.Printf(\"keyringID(_uid.%d) = %d, %v\", uid, keyringID, err)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// We still want to use this key after our privileges are reset. If we\n\t// link the key into the process keyring, we will possess it and still\n\t// be able to use it. However, the permissions to link are based on the\n\t// effective uid, so we must set the euid appropriately.\n\tif needSetUids {\n\t\tif err := setUids(0, uid); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif err := keyringLink(keyringID, unix.KEY_SPEC_PROCESS_KEYRING); err != nil {\n\t\treturn 0, err\n\t}\n\n\tkeyringIDCache[uid] = keyringID\n\treturn keyringID, nil\n}", "is_vulnerable": 1}
{"code": "\tgetHash := func(num uint64) common.Hash {\n\t\tif pre.Env.BlockHashes == nil {\n\t\t\thashError = fmt.Errorf(\"getHash(%d) invoked, no blockhashes provided\", num)\n\t\t\treturn common.Hash{}\n\t\t}\n\t\th, ok := pre.Env.BlockHashes[math.HexOrDecimal64(num)]\n\t\tif !ok {\n\t\t\thashError = fmt.Errorf(\"getHash(%d) invoked, blockhash for that block not provided\", num)\n\t\t}\n\t\treturn h\n\t}\n\tvar (\n\t\tstatedb     = MakePreState(rawdb.NewMemoryDatabase(), pre.Pre)\n\t\tsigner      = types.MakeSigner(chainConfig, new(big.Int).SetUint64(pre.Env.Number))\n\t\tgaspool     = new(core.GasPool)\n\t\tblockHash   = common.Hash{0x13, 0x37}\n\t\trejectedTxs []int\n\t\tincludedTxs types.Transactions\n\t\tgasUsed     = uint64(0)\n\t\treceipts    = make(types.Receipts, 0)\n\t\ttxIndex     = 0\n\t)\n\tgaspool.AddGas(pre.Env.GasLimit)\n\tvmContext := vm.Context{\n\t\tCanTransfer: core.CanTransfer,\n\t\tTransfer:    core.Transfer,\n\t\tCoinbase:    pre.Env.Coinbase,\n\t\tBlockNumber: new(big.Int).SetUint64(pre.Env.Number),\n\t\tTime:        new(big.Int).SetUint64(pre.Env.Timestamp),\n\t\tDifficulty:  pre.Env.Difficulty,\n\t\tGasLimit:    pre.Env.GasLimit,\n\t\tGetHash:     getHash,\n\t\t// GasPrice and Origin needs to be set per transaction\n\t}\n\t// If DAO is supported/enabled, we need to handle it here. In geth 'proper', it's\n\t// done in StateProcessor.Process(block, ...), right before transactions are applied.\n\tif chainConfig.DAOForkSupport &&\n\t\tchainConfig.DAOForkBlock != nil &&\n\t\tchainConfig.DAOForkBlock.Cmp(new(big.Int).SetUint64(pre.Env.Number)) == 0 {\n\t\tmisc.ApplyDAOHardFork(statedb)\n\t}\n\n\tfor i, tx := range txs {\n\t\tmsg, err := tx.AsMessage(signer)\n\t\tif err != nil {\n\t\t\tlog.Info(\"rejected tx\", \"index\", i, \"hash\", tx.Hash(), \"error\", err)\n\t\t\trejectedTxs = append(rejectedTxs, i)\n\t\t\tcontinue\n\t\t}\n\t\ttracer, err := getTracerFn(txIndex, tx.Hash())\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tvmConfig.Tracer = tracer\n\t\tvmConfig.Debug = (tracer != nil)\n\t\tstatedb.Prepare(tx.Hash(), blockHash, txIndex)\n\t\tvmContext.GasPrice = msg.GasPrice()\n\t\tvmContext.Origin = msg.From()\n\n\t\tevm := vm.NewEVM(vmContext, statedb, chainConfig, vmConfig)\n\t\tsnapshot := statedb.Snapshot()\n\t\t// (ret []byte, usedGas uint64, failed bool, err error)\n\t\tmsgResult, err := core.ApplyMessage(evm, msg, gaspool)\n\t\tif err != nil {\n\t\t\tstatedb.RevertToSnapshot(snapshot)\n\t\t\tlog.Info(\"rejected tx\", \"index\", i, \"hash\", tx.Hash(), \"from\", msg.From(), \"error\", err)\n\t\t\trejectedTxs = append(rejectedTxs, i)\n\t\t\tcontinue\n\t\t}\n\t\tincludedTxs = append(includedTxs, tx)\n\t\tif hashError != nil {\n\t\t\treturn nil, nil, NewError(ErrorMissingBlockhash, hashError)\n\t\t}\n\t\tgasUsed += msgResult.UsedGas\n\t\t// Create a new receipt for the transaction, storing the intermediate root and gas used by the tx\n\t\t{\n\t\t\tvar root []byte\n\t\t\tif chainConfig.IsByzantium(vmContext.BlockNumber) {\n\t\t\t\tstatedb.Finalise(true)\n\t\t\t} else {\n\t\t\t\troot = statedb.IntermediateRoot(chainConfig.IsEIP158(vmContext.BlockNumber)).Bytes()\n\t\t\t}\n\n\t\t\treceipt := types.NewReceipt(root, msgResult.Failed(), gasUsed)\n\t\t\treceipt.TxHash = tx.Hash()\n\t\t\treceipt.GasUsed = msgResult.UsedGas\n\t\t\t// if the transaction created a contract, store the creation address in the receipt.\n\t\t\tif msg.To() == nil {\n\t\t\t\treceipt.ContractAddress = crypto.CreateAddress(evm.Context.Origin, tx.Nonce())\n\t\t\t}\n\t\t\t// Set the receipt logs and create a bloom for filtering\n\t\t\treceipt.Logs = statedb.GetLogs(tx.Hash())\n\t\t\treceipt.Bloom = types.CreateBloom(types.Receipts{receipt})\n\t\t\t// These three are non-consensus fields\n\t\t\t//receipt.BlockHash\n\t\t\t//receipt.BlockNumber =\n\t\t\treceipt.TransactionIndex = uint(txIndex)\n\t\t\treceipts = append(receipts, receipt)\n\t\t}\n\t\ttxIndex++\n\t}\n\tstatedb.IntermediateRoot(chainConfig.IsEIP158(vmContext.BlockNumber))\n\t// Add mining reward?\n\tif miningReward > 0 {\n\t\t// Add mining reward. The mining reward may be `0`, which only makes a difference in the cases\n\t\t// where\n\t\t// - the coinbase suicided, or\n\t\t// - there are only 'bad' transactions, which aren't executed. In those cases,\n\t\t//   the coinbase gets no txfee, so isn't created, and thus needs to be touched\n\t\tvar (\n\t\t\tblockReward = big.NewInt(miningReward)\n\t\t\tminerReward = new(big.Int).Set(blockReward)\n\t\t\tperOmmer    = new(big.Int).Div(blockReward, big.NewInt(32))\n\t\t)\n\t\tfor _, ommer := range pre.Env.Ommers {\n\t\t\t// Add 1/32th for each ommer included\n\t\t\tminerReward.Add(minerReward, perOmmer)\n\t\t\t// Add (8-delta)/8\n\t\t\treward := big.NewInt(8)\n\t\t\treward.Sub(reward, big.NewInt(0).SetUint64(ommer.Delta))\n\t\t\treward.Mul(reward, blockReward)\n\t\t\treward.Div(reward, big.NewInt(8))\n\t\t\tstatedb.AddBalance(ommer.Address, reward)\n\t\t}\n\t\tstatedb.AddBalance(pre.Env.Coinbase, minerReward)\n\t}\n\t// Commit block\n\troot, err := statedb.Commit(chainConfig.IsEIP158(vmContext.BlockNumber))\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Could not commit state: %v\", err)\n\t\treturn nil, nil, NewError(ErrorEVM, fmt.Errorf(\"could not commit state: %v\", err))\n\t}\n\texecRs := &ExecutionResult{\n\t\tStateRoot:   root,\n\t\tTxRoot:      types.DeriveSha(includedTxs, new(trie.Trie)),\n\t\tReceiptRoot: types.DeriveSha(receipts, new(trie.Trie)),\n\t\tBloom:       types.CreateBloom(receipts),\n\t\tLogsHash:    rlpHash(statedb.Logs()),\n\t\tReceipts:    receipts,\n\t\tRejected:    rejectedTxs,\n\t}\n\treturn statedb, execRs, nil\n}", "is_vulnerable": 0}
{"code": "func opCreate(pc *uint64, interpreter *EVMInterpreter, callContext *callCtx) ([]byte, error) {\n\tvar (\n\t\tvalue        = callContext.stack.pop()\n\t\toffset, size = callContext.stack.pop(), callContext.stack.pop()\n\t\tinput        = callContext.memory.GetCopy(int64(offset.Uint64()), int64(size.Uint64()))\n\t\tgas          = callContext.contract.Gas\n\t)\n\tif interpreter.evm.chainRules.IsEIP150 {\n\t\tgas -= gas / 64\n\t}\n\t// reuse size int for stackvalue\n\tstackvalue := size\n\n\tcallContext.contract.UseGas(gas)\n\tres, addr, returnGas, suberr := interpreter.evm.Create(callContext.contract, input, gas, value.ToBig())\n\t// Push item on the stack based on the returned error. If the ruleset is\n\t// homestead we must check for CodeStoreOutOfGasError (homestead only\n\t// rule) and treat as an error, if the ruleset is frontier we must\n\t// ignore this error and pretend the operation was successful.\n\tif interpreter.evm.chainRules.IsHomestead && suberr == ErrCodeStoreOutOfGas {\n\t\tstackvalue.Clear()\n\t} else if suberr != nil && suberr != ErrCodeStoreOutOfGas {\n\t\tstackvalue.Clear()\n\t} else {\n\t\tstackvalue.SetBytes(addr.Bytes())\n\t}\n\tcallContext.stack.push(&stackvalue)\n\tcallContext.contract.Gas += returnGas\n\n\tif suberr == ErrExecutionReverted {\n\t\treturn res, nil\n\t}\n\treturn nil, nil\n}", "is_vulnerable": 1}
{"code": "func (self *Compress) Call(ctx context.Context,\n\tscope vfilter.Scope,\n\targs *ordereddict.Dict) vfilter.Any {\n\n\terr := vql_subsystem.CheckAccess(scope, acls.FILESYSTEM_WRITE, acls.FILESYSTEM_READ)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\n\targ := &CompressArgs{}\n\terr = arg_parser.ExtractArgsWithContext(ctx, scope, args, arg)\n\tif err != nil {\n\t\tscope.Log(\"compress: %s\", err.Error())\n\t\treturn vfilter.Null{}\n\t}\n\n\tfd, err := os.Open(arg.Path)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\tdefer fd.Close()\n\n\tout_fd, err := os.OpenFile(arg.Output,\n\t\tos.O_RDWR|os.O_CREATE|os.O_TRUNC, 0660)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\treturn vfilter.Null{}\n\t}\n\tdefer out_fd.Close()\n\n\tzw := gzip.NewWriter(out_fd)\n\tdefer zw.Close()\n\n\tzw.Name = strings.TrimPrefix(arg.Path, \"/\")\n\n\t_, err = utils.Copy(ctx, zw, fd)\n\tif err != nil {\n\t\tscope.Log(\"compress: %v\", err)\n\t\terr2 := os.Remove(arg.Output)\n\t\tif err2 != nil {\n\t\t\tscope.Log(\"compress: cleaning up %v (%v)\", err2, err)\n\t\t}\n\t\treturn vfilter.Null{}\n\t}\n\n\treturn arg.Output\n}", "is_vulnerable": 0}
{"code": "func (e *GrantExec) Next(ctx context.Context, req *chunk.Chunk) error {\n\tif e.done {\n\t\treturn nil\n\t}\n\te.done = true\n\n\tdbName := e.Level.DBName\n\tif len(dbName) == 0 {\n\t\tdbName = e.ctx.GetSessionVars().CurrentDB\n\t}\n\n\t// For table & column level, check whether table exists and privilege is valid\n\tif e.Level.Level == ast.GrantLevelTable {\n\t\t// Return if privilege is invalid, to fail before not existing table, see issue #29302\n\t\tfor _, p := range e.Privs {\n\t\t\tif len(p.Cols) == 0 {\n\t\t\t\tif !mysql.AllTablePrivs.Has(p.Priv) && p.Priv != mysql.AllPriv && p.Priv != mysql.UsagePriv && p.Priv != mysql.GrantPriv && p.Priv != mysql.ExtendedPriv {\n\t\t\t\t\treturn ErrIllegalGrantForTable\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif !mysql.AllColumnPrivs.Has(p.Priv) && p.Priv != mysql.AllPriv && p.Priv != mysql.UsagePriv {\n\t\t\t\t\treturn ErrWrongUsage.GenWithStackByArgs(\"COLUMN GRANT\", \"NON-COLUMN PRIVILEGES\")\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tdbNameStr := model.NewCIStr(dbName)\n\t\tschema := e.ctx.GetInfoSchema().(infoschema.InfoSchema)\n\t\ttbl, err := schema.TableByName(dbNameStr, model.NewCIStr(e.Level.TableName))\n\t\t// Allow GRANT on non-existent table with at least create privilege, see issue #28533 #29268\n\t\tif err != nil {\n\t\t\tallowed := false\n\t\t\tif terror.ErrorEqual(err, infoschema.ErrTableNotExists) {\n\t\t\t\tfor _, p := range e.Privs {\n\t\t\t\t\tif p.Priv == mysql.AllPriv || p.Priv&mysql.CreatePriv > 0 {\n\t\t\t\t\t\tallowed = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !allowed {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\t// Note the table name compare is case sensitive here.\n\t\tif tbl != nil && tbl.Meta().Name.String() != e.Level.TableName {\n\t\t\treturn infoschema.ErrTableNotExists.GenWithStackByArgs(dbName, e.Level.TableName)\n\t\t}\n\t\tif len(e.Level.DBName) > 0 {\n\t\t\t// The database name should also match.\n\t\t\tdb, succ := schema.SchemaByName(dbNameStr)\n\t\t\tif !succ || db.Name.L != dbNameStr.L {\n\t\t\t\treturn infoschema.ErrTableNotExists.GenWithStackByArgs(dbName, e.Level.TableName)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Commit the old transaction, like DDL.\n\tif err := sessiontxn.NewTxnInStmt(ctx, e.ctx); err != nil {\n\t\treturn err\n\t}\n\tdefer func() { e.ctx.GetSessionVars().SetInTxn(false) }()\n\n\t// Create internal session to start internal transaction.\n\tisCommit := false\n\tinternalSession, err := e.getSysSession()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\tif !isCommit {\n\t\t\t_, err := internalSession.(sqlexec.SQLExecutor).ExecuteInternal(context.Background(), \"rollback\")\n\t\t\tif err != nil {\n\t\t\t\tlogutil.BgLogger().Error(\"rollback error occur at grant privilege\", zap.Error(err))\n\t\t\t}\n\t\t}\n\t\te.releaseSysSession(internalSession)\n\t}()\n\n\t_, err = internalSession.(sqlexec.SQLExecutor).ExecuteInternal(context.Background(), \"begin\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Check which user is not exist.\n\tfor _, user := range e.Users {\n\t\texists, err := userExists(ctx, e.ctx, user.User.Username, user.User.Hostname)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !exists && e.ctx.GetSessionVars().SQLMode.HasNoAutoCreateUserMode() {\n\t\t\treturn ErrCantCreateUserWithGrant\n\t\t} else if !exists {\n\t\t\t// This code path only applies if mode NO_AUTO_CREATE_USER is unset.\n\t\t\t// It is required for compatibility with 5.7 but removed from 8.0\n\t\t\t// since it results in a massive security issue:\n\t\t\t// spelling errors will create users with no passwords.\n\t\t\tpwd, ok := user.EncodedPassword()\n\t\t\tif !ok {\n\t\t\t\treturn errors.Trace(ErrPasswordFormat)\n\t\t\t}\n\t\t\tauthPlugin := mysql.AuthNativePassword\n\t\t\tif user.AuthOpt != nil && user.AuthOpt.AuthPlugin != \"\" {\n\t\t\t\tauthPlugin = user.AuthOpt.AuthPlugin\n\t\t\t}\n\t\t\t_, err := internalSession.(sqlexec.SQLExecutor).ExecuteInternal(ctx,\n\t\t\t\t`INSERT INTO %n.%n (Host, User, authentication_string, plugin) VALUES (%?, %?, %?, %?);`,\n\t\t\t\tmysql.SystemDB, mysql.UserTable, user.User.Hostname, user.User.Username, pwd, authPlugin)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// Grant for each user\n\tfor _, user := range e.Users {\n\t\t// If there is no privilege entry in corresponding table, insert a new one.\n\t\t// Global scope:\t\tmysql.global_priv\n\t\t// DB scope:\t\t\tmysql.DB\n\t\t// Table scope:\t\t\tmysql.Tables_priv\n\t\t// Column scope:\t\tmysql.Columns_priv\n\t\tif e.TLSOptions != nil {\n\t\t\terr = checkAndInitGlobalPriv(internalSession, user.User.Username, user.User.Hostname)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tswitch e.Level.Level {\n\t\tcase ast.GrantLevelDB:\n\t\t\terr := checkAndInitDBPriv(internalSession, dbName, e.is, user.User.Username, user.User.Hostname)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tcase ast.GrantLevelTable:\n\t\t\terr := checkAndInitTablePriv(internalSession, dbName, e.Level.TableName, e.is, user.User.Username, user.User.Hostname)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// Previously \"WITH GRANT OPTION\" implied setting the Grant_Priv in mysql.user.\n\t\t// However, with DYNAMIC privileges the GRANT OPTION is individually grantable, and not a global\n\t\t// property of the user. The logic observed in MySQL 8.0 is as follows:\n\t\t// - The GRANT OPTION applies to all PrivElems in e.Privs.\n\t\t// - Thus, if PrivElems contains any non-DYNAMIC privileges, the user GRANT option needs to be set.\n\t\t// - If it contains ONLY dynamic privileges, don't set the GRANT option, as it is individually set in the handling of dynamic options.\n\t\tprivs := e.Privs\n\t\tif e.WithGrant && containsNonDynamicPriv(privs) {\n\t\t\tprivs = append(privs, &ast.PrivElem{Priv: mysql.GrantPriv})\n\t\t}\n\n\t\t// Grant TLS privs to use in global table\n\t\terr = e.grantGlobalPriv(internalSession, user)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Grant each priv to the user.\n\t\tfor _, priv := range privs {\n\t\t\tif len(priv.Cols) > 0 {\n\t\t\t\t// Check column scope privilege entry.\n\t\t\t\t// TODO: Check validity before insert new entry.\n\t\t\t\terr := e.checkAndInitColumnPriv(user.User.Username, user.User.Hostname, priv.Cols, internalSession)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\terr := e.grantLevelPriv(priv, user, internalSession)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t_, err = internalSession.(sqlexec.SQLExecutor).ExecuteInternal(context.Background(), \"commit\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tisCommit = true\n\treturn domain.GetDomain(e.ctx).NotifyUpdatePrivilege()\n}", "is_vulnerable": 0}
{"code": "func TestMultiResolver(t *testing.T) {\n\tr := NewMultiResolver()\n\tfor _, tc := range append(commonResolverTestCases, []resolverTestCase{\n\t\t{\n\t\t\tname:        \"multi-tenant\",\n\t\t\theaderValue: strptr(\"tenant-a|tenant-b\"),\n\t\t\terrTenantID: user.ErrTooManyOrgIDs,\n\t\t\ttenantIDs:   []string{\"tenant-a\", \"tenant-b\"},\n\t\t},\n\t\t{\n\t\t\tname:        \"multi-tenant-wrong-order\",\n\t\t\theaderValue: strptr(\"tenant-b|tenant-a\"),\n\t\t\terrTenantID: user.ErrTooManyOrgIDs,\n\t\t\ttenantIDs:   []string{\"tenant-a\", \"tenant-b\"},\n\t\t},\n\t\t{\n\t\t\tname:        \"multi-tenant-duplicate-order\",\n\t\t\theaderValue: strptr(\"tenant-b|tenant-b|tenant-a\"),\n\t\t\terrTenantID: user.ErrTooManyOrgIDs,\n\t\t\ttenantIDs:   []string{\"tenant-a\", \"tenant-b\"},\n\t\t},\n\t\t{\n\t\t\tname:         \"multi-tenant-with-relative-path\",\n\t\t\theaderValue:  strptr(\"tenant-a|tenant-b|..\"),\n\t\t\terrTenantID:  errInvalidTenantID,\n\t\t\terrTenantIDs: errInvalidTenantID,\n\t\t},\n\t\t{\n\t\t\tname:         \"containing-forward-slash\",\n\t\t\theaderValue:  strptr(\"forward/slash\"),\n\t\t\terrTenantID:  &errTenantIDUnsupportedCharacter{pos: 7, tenantID: \"forward/slash\"},\n\t\t\terrTenantIDs: &errTenantIDUnsupportedCharacter{pos: 7, tenantID: \"forward/slash\"},\n\t\t},\n\t\t{\n\t\t\tname:         \"containing-backward-slash\",\n\t\t\theaderValue:  strptr(`backward\\slash`),\n\t\t\terrTenantID:  &errTenantIDUnsupportedCharacter{pos: 8, tenantID: \"backward\\\\slash\"},\n\t\t\terrTenantIDs: &errTenantIDUnsupportedCharacter{pos: 8, tenantID: \"backward\\\\slash\"},\n\t\t},\n\t}...) {\n\t\tt.Run(tc.name, tc.test(r))\n\t}\n}", "is_vulnerable": 0}
{"code": "func (context *DatabaseContext) QueryRoleAccess(username string) (sgbucket.QueryResultIterator, error) {\n\n\t// View Query\n\tif context.Options.UseViews {\n\t\topts := map[string]interface{}{\"stale\": false, \"key\": username}\n\t\treturn context.ViewQueryWithStats(DesignDocSyncGateway(), ViewRoleAccess, opts)\n\t}\n\n\t// N1QL Query\n\tif username == \"\" {\n\t\tbase.Warnf(base.KeyAll, \"QueryRoleAccess called with empty username\")\n\t\treturn &EmptyResultIterator{}, nil\n\t}\n\n\taccessQueryStatement := context.buildRoleAccessQuery(username)\n\t// Can't use prepared query because username is in select clause\n\treturn context.N1QLQueryWithStats(QueryTypeRoleAccess, accessQueryStatement, nil, gocb.RequestPlus, true)\n}", "is_vulnerable": 1}
{"code": "func Init(options *types.Options) error {\n\tif Dialer != nil {\n\t\treturn nil\n\t}\n\topts := fastdialer.DefaultOptions\n\n\tswitch {\n\tcase options.SourceIP != \"\" && options.Interface != \"\":\n\t\tisAssociated, err := isIpAssociatedWithInterface(options.SourceIP, options.Interface)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif isAssociated {\n\t\t\topts.Dialer = &net.Dialer{\n\t\t\t\tLocalAddr: &net.TCPAddr{\n\t\t\t\t\tIP: net.ParseIP(options.SourceIP),\n\t\t\t\t},\n\t\t\t}\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"source ip (%s) is not associated with the interface (%s)\", options.SourceIP, options.Interface)\n\t\t}\n\tcase options.SourceIP != \"\":\n\t\tisAssociated, err := isIpAssociatedWithInterface(options.SourceIP, \"any\")\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif isAssociated {\n\t\t\topts.Dialer = &net.Dialer{\n\t\t\t\tLocalAddr: &net.TCPAddr{\n\t\t\t\t\tIP: net.ParseIP(options.SourceIP),\n\t\t\t\t},\n\t\t\t}\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"source ip (%s) is not associated with any network interface\", options.SourceIP)\n\t\t}\n\tcase options.Interface != \"\":\n\t\tifadrr, err := interfaceAddress(options.Interface)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\topts.Dialer = &net.Dialer{\n\t\t\tLocalAddr: &net.TCPAddr{\n\t\t\t\tIP: ifadrr,\n\t\t\t},\n\t\t}\n\t}\n\tif types.ProxySocksURL != \"\" {\n\t\tproxyURL, err := url.Parse(types.ProxySocksURL)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvar forward *net.Dialer\n\t\tif opts.Dialer != nil {\n\t\t\tforward = opts.Dialer\n\t\t} else {\n\t\t\tforward = &net.Dialer{\n\t\t\t\tTimeout:   opts.DialerTimeout,\n\t\t\t\tKeepAlive: opts.DialerKeepAlive,\n\t\t\t\tDualStack: true,\n\t\t\t}\n\t\t}\n\t\tdialer, err := proxy.FromURL(proxyURL, forward)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\topts.ProxyDialer = &dialer\n\t}\n\n\tif options.SystemResolvers {\n\t\topts.EnableFallback = true\n\t}\n\tif options.ResolversFile != \"\" {\n\t\topts.BaseResolvers = options.InternalResolversList\n\t}\n\tif options.Sandbox {\n\t\topts.Deny = append(networkpolicy.DefaultIPv4DenylistRanges, networkpolicy.DefaultIPv6DenylistRanges...)\n\t}\n\topts.WithDialerHistory = true\n\topts.SNIName = options.SNI\n\t// fastdialer now by default fallbacks to ztls when there are tls related errors\n\tdialer, err := fastdialer.NewDialer(opts)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"could not create dialer\")\n\t}\n\tDialer = dialer\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tgqlServer.AroundResponses(func(ctx context.Context, next graphql.ResponseHandler) *graphql.Response {\n\t\tloggedOnUser := \"<unknown>\"\n\t\tstart := time.Now()\n\t\tresult := next(ctx)\n\t\tloggedOnUser = server.UpdateAccessControllerState(ctx, loggedOnUser, sessionManager)\n\t\trctx := graphql.GetOperationContext(ctx)\n\t\tif rctx != nil {\n\t\t\tsince := time.Since(start)\n\t\t\tlog.Printf(\"[%s] Query execution - op: %s %s\\n\", loggedOnUser, rctx.OperationName, since)\n\t\t\tqueryTimeMetric.WithLabelValues(rctx.OperationName).Observe(since.Seconds())\n\t\t}\n\t\treturn result\n\t})\n\n\tif *developmentMode {\n\t\tqueryServer.Handle(queryEndpoint, server.DevelopmentHandler(gqlServer, sessionManager, config.BearerToken))\n\t} else {\n\t\tqueryServer.Handle(queryEndpoint, server.AuthHandler(gqlServer, sessionManager, impersonationConfig))\n\t}\n\n\tgo func() {\n\t\terr = http.ListenAndServe(\"127.0.0.1:\"+port, sessionManager.LoadAndSave(queryServer))\n\t\tif err != nil {\n\t\t\tpanic(err.Error())\n\t\t}\n\t}()\n\n\tmetricsServer := http.NewServeMux()\n\n\tmetricsServer.Handle(\"/metrics\", promhttp.Handler())\n\terr = http.ListenAndServe(\":\"+metricsPort, metricsServer)\n\tif err != nil {\n\t\tpanic(err.Error())\n\t}\n\n}", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateContainerReallyEmptyFails(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\n`\n\tcontainer := s.container()\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(container, info, discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n\n\terr = snap.ValidateComponentContainer(container, \"empty-snap+comp.comp\", discard)\n\tc.Check(err, Equals, snap.ErrMissingPaths)\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_OutgoingTLS_TLSMinVersion(t *testing.T) {\n\ttlsVersions := []string{\"tls10\", \"tls11\", \"tls12\"}\n\tfor _, version := range tlsVersions {\n\t\tconf := &Config{\n\t\t\tVerifyOutgoing: true,\n\t\t\tCAFile:         \"../test/ca/root.cer\",\n\t\t\tTLSMinVersion:  version,\n\t\t}\n\t\tc := NewConfigurator(conf)\n\t\ttlsConf, err := c.OutgoingRPCConfig()\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, tlsConf)\n\t\trequire.Equal(t, tlsConf.MinVersion, TLSLookup[version])\n\t}\n}", "is_vulnerable": 1}
{"code": "func (i *instances) getKubernetesInstances(scope string) []Instance {\n\tctx := context.Background()\n\tlist := []Instance{}\n\tresp, err := i.kubeClient.AppsV1().Deployments(scope).List(ctx, (meta_v1.ListOptions{}))\n\trespSts, errSts := i.kubeClient.AppsV1().StatefulSets(scope).List(ctx, (meta_v1.ListOptions{}))\n\tif err != nil {\n\t\tlog.Println(err)\n\t\treturn list\n\t}\n\n\tif errSts != nil {\n\t\tlog.Println(errSts)\n\t\treturn list\n\t}\n\n\tfor _, d := range resp.Items {\n\t\tif d.Spec.Template.Annotations[daprEnabledAnnotation] != \"\" {\n\t\t\tid := d.Spec.Template.Annotations[daprIDAnnotation]\n\t\t\ti := Instance{\n\t\t\t\tAppID:            id,\n\t\t\t\tHTTPPort:         3500,\n\t\t\t\tGRPCPort:         50001,\n\t\t\t\tCommand:          \"\",\n\t\t\t\tAge:              age.GetAge(d.CreationTimestamp.Time),\n\t\t\t\tCreated:          d.GetCreationTimestamp().String(),\n\t\t\t\tPID:              -1,\n\t\t\t\tReplicas:         int(*d.Spec.Replicas),\n\t\t\t\tSupportsDeletion: false,\n\t\t\t\tSupportsLogs:     true,\n\t\t\t\tAddress:          fmt.Sprintf(\"%s-dapr:80\", id),\n\t\t\t\tStatus:           fmt.Sprintf(\"%d/%d\", d.Status.ReadyReplicas, d.Status.Replicas),\n\t\t\t\tLabels:           getAppLabelValue(d.Labels[\"app\"]),\n\t\t\t\tSelector:         getAppLabelValue(d.Spec.Selector.MatchLabels[\"app\"]),\n\t\t\t\tConfig:           d.Spec.Template.Annotations[\"dapr.io/config\"],\n\t\t\t}\n\n\t\t\tif val, ok := d.Spec.Template.Annotations[daprPortAnnotation]; ok {\n\t\t\t\tappPort, err := strconv.Atoi(val)\n\t\t\t\tif err == nil {\n\t\t\t\t\ti.AppPort = appPort\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ts := json_serializer.NewYAMLSerializer(json_serializer.DefaultMetaFactory, nil, nil)\n\t\t\tbuf := new(bytes.Buffer)\n\t\t\terr := s.Encode(&d, buf)\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(err)\n\t\t\t\treturn list\n\t\t\t}\n\n\t\t\ti.Manifest = buf.String()\n\n\t\t\tlist = append(list, i)\n\t\t}\n\t}\n\tfor _, d := range respSts.Items {\n\t\tif d.Spec.Template.Annotations[daprIDAnnotation] != \"\" {\n\t\t\tid := d.Spec.Template.Annotations[daprIDAnnotation]\n\t\t\ti := Instance{\n\t\t\t\tAppID:            id,\n\t\t\t\tHTTPPort:         3500,\n\t\t\t\tGRPCPort:         50001,\n\t\t\t\tCommand:          \"\",\n\t\t\t\tAge:              age.GetAge(d.CreationTimestamp.Time),\n\t\t\t\tCreated:          d.GetCreationTimestamp().String(),\n\t\t\t\tPID:              -1,\n\t\t\t\tReplicas:         int(*d.Spec.Replicas),\n\t\t\t\tSupportsDeletion: false,\n\t\t\t\tSupportsLogs:     true,\n\t\t\t\tAddress:          fmt.Sprintf(\"%s-dapr:80\", id),\n\t\t\t\tStatus:           fmt.Sprintf(\"%d/%d\", d.Status.ReadyReplicas, d.Status.Replicas),\n\t\t\t\tLabels:           getAppLabelValue(d.Labels[\"app\"]),\n\t\t\t\tSelector:         getAppLabelValue(d.Spec.Selector.MatchLabels[\"app\"]),\n\t\t\t\tConfig:           d.Spec.Template.Annotations[\"dapr.io/config\"],\n\t\t\t}\n\t\t\tif val, ok := d.Spec.Template.Annotations[daprPortAnnotation]; ok {\n\t\t\t\tappPort, err := strconv.Atoi(val)\n\t\t\t\tif err == nil {\n\t\t\t\t\ti.AppPort = appPort\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ts := json_serializer.NewYAMLSerializer(json_serializer.DefaultMetaFactory, nil, nil)\n\t\t\tbuf := new(bytes.Buffer)\n\t\t\terr := s.Encode(&d, buf)\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(err)\n\t\t\t\treturn list\n\t\t\t}\n\n\t\t\ti.Manifest = buf.String()\n\n\t\t\tlist = append(list, i)\n\t\t}\n\t}\n\n\treturn list\n}", "is_vulnerable": 0}
{"code": "func (mr *MockCoreStorageMockRecorder) CreateRefreshTokenSession(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"CreateRefreshTokenSession\", reflect.TypeOf((*MockCoreStorage)(nil).CreateRefreshTokenSession), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func (k *Key) CanCertify() bool {\n\treturn C.key_can_certify(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "func (k *Key) Revoked() bool {\n\treturn C.key_revoked(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tctx := c.Context()\n\n\t\t\t// get rid of logging error handler\n\t\t\truntime.ErrorHandlers = runtime.ErrorHandlers[1:]\n\n\t\t\tif len(args) != 1 {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\toutputPath := args[0]\n\n\t\t\terrors.CheckError(os.Setenv(v1alpha1.EnvVarFakeInClusterConfig, \"true\"))\n\t\t\tcfg, err := clientConfig.ClientConfig()\n\t\t\terrors.CheckError(err)\n\t\t\tnamespace, _, err := clientConfig.Namespace()\n\t\t\terrors.CheckError(err)\n\n\t\t\tvar result []appReconcileResult\n\t\t\tif refresh {\n\t\t\t\tif repoServerAddress == \"\" {\n\t\t\t\t\tprintLine(\"Repo server is not provided, trying to port-forward to argocd-repo-server pod.\")\n\t\t\t\t\toverrides := clientcmd.ConfigOverrides{}\n\t\t\t\t\trepoServerPort, err := kubeutil.PortForward(8081, namespace, &overrides, \"app.kubernetes.io/name=argocd-repo-server\")\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\trepoServerAddress = fmt.Sprintf(\"localhost:%d\", repoServerPort)\n\t\t\t\t}\n\t\t\t\trepoServerClient := argocdclient.NewRepoServerClientset(repoServerAddress, 60, argocdclient.TLSConfiguration{DisableTLS: false, StrictValidation: false})\n\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tkubeClientset := kubernetes.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = reconcileApplications(ctx, kubeClientset, appClientset, namespace, repoServerClient, selector, newLiveStateCache, ignoreNormalizerOpts)\n\t\t\t\terrors.CheckError(err)\n\t\t\t} else {\n\t\t\t\tappClientset := appclientset.NewForConfigOrDie(cfg)\n\t\t\t\tresult, err = getReconcileResults(ctx, appClientset, namespace, selector)\n\t\t\t}\n\n\t\t\terrors.CheckError(saveToFile(err, outputFormat, reconcileResults{Applications: result}, outputPath))\n\t\t},", "is_vulnerable": 0}
{"code": "func (s *StateDB) createObject(addr common.Address) (newobj, prev *stateObject) {\n\tprev = s.getDeletedStateObject(addr) // Note, prev might have been deleted, we need that!\n\n\tvar prevdestruct bool\n\tif s.snap != nil && prev != nil {\n\t\t_, prevdestruct = s.snapDestructs[prev.addrHash]\n\t\tif !prevdestruct {\n\t\t\ts.snapDestructs[prev.addrHash] = struct{}{}\n\t\t}\n\t}\n\tnewobj = newObject(s, addr, Account{})\n\tnewobj.setNonce(0) // sets the object to dirty\n\tif prev == nil {\n\t\ts.journal.append(createObjectChange{account: &addr})\n\t} else {\n\t\ts.journal.append(resetObjectChange{prev: prev, prevdestruct: prevdestruct})\n\t}\n\ts.setStateObject(newobj)\n\tif prev != nil && !prev.deleted {\n\t\treturn newobj, prev\n\t}\n\treturn newobj, nil\n}", "is_vulnerable": 0}
{"code": "func Validate(s *types.Schema, doc *types.ExecutableDefinition, variables map[string]interface{}, maxDepth int) []*errors.QueryError {\n\tc := newContext(s, doc, maxDepth)\n\n\topNames := make(nameSet)\n\tfragUsedBy := make(map[*types.FragmentDefinition][]*types.OperationDefinition)\n\tfor _, op := range doc.Operations {\n\t\tc.usedVars[op] = make(varSet)\n\t\topc := &opContext{c, []*types.OperationDefinition{op}}\n\n\t\t// Check if max depth is exceeded, if it's set. If max depth is exceeded,\n\t\t// don't continue to validate the document and exit early.\n\t\tif validateMaxDepth(opc, op.Selections, 1) {\n\t\t\treturn c.errs\n\t\t}\n\n\t\tif op.Name.Name == \"\" && len(doc.Operations) != 1 {\n\t\t\tc.addErr(op.Loc, \"LoneAnonymousOperation\", \"This anonymous operation must be the only defined operation.\")\n\t\t}\n\t\tif op.Name.Name != \"\" {\n\t\t\tvalidateName(c, opNames, op.Name, \"UniqueOperationNames\", \"operation\")\n\t\t}\n\n\t\tvalidateDirectives(opc, string(op.Type), op.Directives)\n\n\t\tvarNames := make(nameSet)\n\t\tfor _, v := range op.Vars {\n\t\t\tvalidateName(c, varNames, v.Name, \"UniqueVariableNames\", \"variable\")\n\n\t\t\tt := resolveType(c, v.Type)\n\t\t\tif !canBeInput(t) {\n\t\t\t\tc.addErr(v.TypeLoc, \"VariablesAreInputTypes\", \"Variable %q cannot be non-input type %q.\", \"$\"+v.Name.Name, t)\n\t\t\t}\n\t\t\tvalidateValue(opc, v, variables[v.Name.Name], t)\n\n\t\t\tif v.Default != nil {\n\t\t\t\tvalidateLiteral(opc, v.Default)\n\n\t\t\t\tif t != nil {\n\t\t\t\t\tif nn, ok := t.(*types.NonNull); ok {\n\t\t\t\t\t\tc.addErr(v.Default.Location(), \"DefaultValuesOfCorrectType\", \"Variable %q of type %q is required and will not use the default value. Perhaps you meant to use type %q.\", \"$\"+v.Name.Name, t, nn.OfType)\n\t\t\t\t\t}\n\n\t\t\t\t\tif ok, reason := validateValueType(opc, v.Default, t); !ok {\n\t\t\t\t\t\tc.addErr(v.Default.Location(), \"DefaultValuesOfCorrectType\", \"Variable %q of type %q has invalid default value %s.\\n%s\", \"$\"+v.Name.Name, t, v.Default, reason)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tvar entryPoint types.NamedType\n\t\tswitch op.Type {\n\t\tcase query.Query:\n\t\t\tentryPoint = s.EntryPoints[\"query\"]\n\t\tcase query.Mutation:\n\t\t\tentryPoint = s.EntryPoints[\"mutation\"]\n\t\tcase query.Subscription:\n\t\t\tentryPoint = s.EntryPoints[\"subscription\"]\n\t\tdefault:\n\t\t\tpanic(\"unreachable\")\n\t\t}\n\n\t\tvalidateSelectionSet(opc, op.Selections, entryPoint)\n\n\t\tfragUsed := make(map[*types.FragmentDefinition]struct{})\n\t\tmarkUsedFragments(c, op.Selections, fragUsed)\n\t\tfor frag := range fragUsed {\n\t\t\tfragUsedBy[frag] = append(fragUsedBy[frag], op)\n\t\t}\n\t}\n\n\tfragNames := make(nameSet)\n\tfragVisited := make(map[*types.FragmentDefinition]struct{})\n\tfor _, frag := range doc.Fragments {\n\t\topc := &opContext{c, fragUsedBy[frag]}\n\n\t\tvalidateName(c, fragNames, frag.Name, \"UniqueFragmentNames\", \"fragment\")\n\t\tvalidateDirectives(opc, \"FRAGMENT_DEFINITION\", frag.Directives)\n\n\t\tt := unwrapType(resolveType(c, &frag.On))\n\t\t// continue even if t is nil\n\t\tif t != nil && !canBeFragment(t) {\n\t\t\tc.addErr(frag.On.Loc, \"FragmentsOnCompositeTypes\", \"Fragment %q cannot condition on non composite type %q.\", frag.Name.Name, t)\n\t\t\tcontinue\n\t\t}\n\n\t\tvalidateSelectionSet(opc, frag.Selections, t)\n\n\t\tif _, ok := fragVisited[frag]; !ok {\n\t\t\tdetectFragmentCycle(c, frag.Selections, fragVisited, nil, map[string]int{frag.Name.Name: 0})\n\t\t}\n\t}\n\n\tfor _, frag := range doc.Fragments {\n\t\tif len(fragUsedBy[frag]) == 0 {\n\t\t\tc.addErr(frag.Loc, \"NoUnusedFragments\", \"Fragment %q is never used.\", frag.Name.Name)\n\t\t}\n\t}\n\n\tfor _, op := range doc.Operations {\n\t\tc.errs = append(c.errs, c.opErrs[op]...)\n\n\t\topUsedVars := c.usedVars[op]\n\t\tfor _, v := range op.Vars {\n\t\t\tif _, ok := opUsedVars[v]; !ok {\n\t\t\t\topSuffix := \"\"\n\t\t\t\tif op.Name.Name != \"\" {\n\t\t\t\t\topSuffix = fmt.Sprintf(\" in operation %q\", op.Name.Name)\n\t\t\t\t}\n\t\t\t\tc.addErr(v.Loc, \"NoUnusedVariables\", \"Variable %q is never used%s.\", \"$\"+v.Name.Name, opSuffix)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn c.errs\n}", "is_vulnerable": 1}
{"code": "func YAMLEq(t TestingT, expected string, actual string, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.YAMLEq(t, expected, actual, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func DecodeBytes(na ipld.NodeAssembler, src []byte) error {\n\tremaining := src\n\n\tma, err := na.BeginMap(2)\n\tif err != nil {\n\t\treturn err\n\t}\n\tvar links ipld.ListAssembler\n\n\thaveData := false\n\thaveLinks := false\n\tfor {\n\t\tif len(remaining) == 0 {\n\t\t\tbreak\n\t\t}\n\n\t\tfieldNum, wireType, n := protowire.ConsumeTag(remaining)\n\t\tif n < 0 {\n\t\t\treturn protowire.ParseError(n)\n\t\t}\n\t\tremaining = remaining[n:]\n\n\t\tif wireType != 2 {\n\t\t\treturn fmt.Errorf(\"protobuf: (PBNode) invalid wireType, expected 2, got %d\", wireType)\n\t\t}\n\n\t\t// Note that we allow Data and Links to come in either order,\n\t\t// since the spec defines that decoding \"should\" accept either form.\n\t\t// This is for backwards compatibility with older IPFS data.\n\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif haveData {\n\t\t\t\treturn fmt.Errorf(\"protobuf: (PBNode) duplicate Data section\")\n\t\t\t}\n\n\t\t\tchunk, n := protowire.ConsumeBytes(remaining)\n\t\t\tif n < 0 {\n\t\t\t\treturn protowire.ParseError(n)\n\t\t\t}\n\t\t\tremaining = remaining[n:]\n\n\t\t\tif links != nil {\n\t\t\t\t// Links came before Data.\n\t\t\t\t// Finish them before we start Data.\n\t\t\t\tif err := links.Finish(); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tlinks = nil\n\t\t\t}\n\n\t\t\tif err := ma.AssembleKey().AssignString(\"Data\"); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := ma.AssembleValue().AssignBytes(chunk); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\thaveData = true\n\n\t\tcase 2:\n\t\t\tchunk, n := protowire.ConsumeBytes(remaining)\n\t\t\tif n < 0 {\n\t\t\t\treturn protowire.ParseError(n)\n\t\t\t}\n\t\t\tremaining = remaining[n:]\n\n\t\t\tif links == nil {\n\t\t\t\tif haveLinks {\n\t\t\t\t\treturn fmt.Errorf(\"protobuf: (PBNode) duplicate Links section\")\n\t\t\t\t}\n\n\t\t\t\t// The repeated \"Links\" part begins.\n\t\t\t\tif err := ma.AssembleKey().AssignString(\"Links\"); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tlinks, err = ma.AssembleValue().BeginList(0)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcurLink, err := links.AssembleValue().BeginMap(3)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := unmarshalLink(chunk, curLink); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := curLink.Finish(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\thaveLinks = true\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"protobuf: (PBNode) invalid fieldNumber, expected 1 or 2, got %d\", fieldNum)\n\t\t}\n\t}\n\n\tif links != nil {\n\t\t// We had some links at the end, so finish them.\n\t\tif err := links.Finish(); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t} else if !haveLinks {\n\t\t// We didn't have any links.\n\t\t// Since we always want a Links field, add one here.\n\t\tif err := ma.AssembleKey().AssignString(\"Links\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlinks, err := ma.AssembleValue().BeginList(0)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := links.Finish(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn ma.Finish()\n}", "is_vulnerable": 0}
{"code": "func (m *mockOCISignatures) Get() ([]oci.Signature, error) {\n\treturn m.signatures, nil\n}", "is_vulnerable": 0}
{"code": "func processMessage(msg *beehiveModel.Message) {\n\tsource := msg.GetSource()\n\tif source != sourceType {\n\t\treturn\n\t}\n\tresource := msg.GetResource()\n\tswitch msg.GetOperation() {\n\tcase \"start\":\n\t\tif atomic.CompareAndSwapInt32(&inited, 0, 1) {\n\t\t\tdao.InsertUrls(resource)\n\t\t\tgo server(c)\n\t\t}\n\tcase \"stop\":\n\t\tdao.DeleteUrlsByKey(resource)\n\t\tif dao.IsTableEmpty() {\n\t\t\tc <- struct{}{}\n\t\t}\n\tdefault:\n\t\tr := strings.Split(resource, \":\")\n\t\tif len(r) != 2 {\n\t\t\tm := \"the format of resource \" + resource + \" is incorrect\"\n\t\t\tklog.Warningf(m)\n\t\t\tcode := http.StatusBadRequest\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tcontent, err := msg.GetContentData()\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"marshall message content failed %v\", err)\n\t\t\tm := \"error to marshal request msg content\"\n\t\t\tcode := http.StatusBadRequest\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tvar httpRequest commonType.HTTPRequest\n\t\tif err := json.Unmarshal(content, &httpRequest); err != nil {\n\t\t\tm := \"error to parse http request\"\n\t\t\tcode := http.StatusBadRequest\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t//send message with resource to the edge part\n\t\toperation := httpRequest.Method\n\t\ttargetURL := \"http://127.0.0.1:\" + r[0] + r[1]\n\t\tresp, err := uc.HTTPDo(operation, targetURL, httpRequest.Header, httpRequest.Body)\n\t\tif err != nil {\n\t\t\tm := \"error to call service\"\n\t\t\tcode := http.StatusNotFound\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tdefer resp.Body.Close()\n\t\tresp.Body = http.MaxBytesReader(nil, resp.Body, maxBodySize)\n\t\tresBody, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tif err.Error() == \"http: request body too large\" {\n\t\t\t\terr = fmt.Errorf(\"response body too large\")\n\t\t\t}\n\t\t\tm := \"error to receive response, err: \" + err.Error()\n\t\t\tcode := http.StatusInternalServerError\n\t\t\tklog.Errorf(m, err)\n\t\t\tif response, err := buildErrorResponse(msg.GetID(), m, code); err == nil {\n\t\t\t\tbeehiveContext.SendToGroup(modules.HubGroup, response)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tresponse := commonType.HTTPResponse{Header: resp.Header, StatusCode: resp.StatusCode, Body: resBody}\n\t\tresponseMsg := beehiveModel.NewMessage(msg.GetID()).SetRoute(modules.ServiceBusModuleName, modules.UserGroup).\n\t\t\tSetResourceOperation(\"\", beehiveModel.UploadOperation).FillBody(response)\n\t\tbeehiveContext.SendToGroup(modules.HubGroup, *responseMsg)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (u *SSHService) GenerateSSH(req dto.GenerateSSH) error {\n\tif cmd.CheckIllegal(req.EncryptionMode, req.Password) {\n\t\treturn buserr.New(constant.ErrCmdIllegal)\n\t}\n\tcurrentUser, err := user.Current()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"load current user failed, err: %v\", err)\n\t}\n\tsecretFile := fmt.Sprintf(\"%s/.ssh/id_item_%s\", currentUser.HomeDir, req.EncryptionMode)\n\tsecretPubFile := fmt.Sprintf(\"%s/.ssh/id_item_%s.pub\", currentUser.HomeDir, req.EncryptionMode)\n\tauthFile := currentUser.HomeDir + \"/.ssh/authorized_keys\"\n\n\tcommand := fmt.Sprintf(\"ssh-keygen -t %s -f %s/.ssh/id_item_%s | echo y\", req.EncryptionMode, currentUser.HomeDir, req.EncryptionMode)\n\tif len(req.Password) != 0 {\n\t\tcommand = fmt.Sprintf(\"ssh-keygen -t %s -P %s -f %s/.ssh/id_item_%s | echo y\", req.EncryptionMode, req.Password, currentUser.HomeDir, req.EncryptionMode)\n\t}\n\tstdout, err := cmd.Exec(command)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"generate failed, err: %v, message: %s\", err, stdout)\n\t}\n\tdefer func() {\n\t\t_ = os.Remove(secretFile)\n\t}()\n\tdefer func() {\n\t\t_ = os.Remove(secretPubFile)\n\t}()\n\n\tif _, err := os.Stat(authFile); err != nil {\n\t\t_, _ = os.Create(authFile)\n\t}\n\tstdout1, err := cmd.Execf(\"cat %s >> %s/.ssh/authorized_keys\", secretPubFile, currentUser.HomeDir)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"generate failed, err: %v, message: %s\", err, stdout1)\n\t}\n\n\tfileOp := files.NewFileOp()\n\tif err := fileOp.Rename(secretFile, fmt.Sprintf(\"%s/.ssh/id_%s\", currentUser.HomeDir, req.EncryptionMode)); err != nil {\n\t\treturn err\n\t}\n\tif err := fileOp.Rename(secretPubFile, fmt.Sprintf(\"%s/.ssh/id_%s.pub\", currentUser.HomeDir, req.EncryptionMode)); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func rawFileHandler(w http.ResponseWriter, r *http.Request, file *files.FileInfo) (int, error) {\n\tfd, err := file.Fs.Open(file.Path)\n\tif err != nil {\n\t\treturn http.StatusInternalServerError, err\n\t}\n\tdefer fd.Close()\n\n\tsetContentDisposition(w, r, file)\n\tw.Header().Add(\"Content-Security-Policy\", `script-src 'none';`)\n\tw.Header().Set(\"Cache-Control\", \"private\")\n\thttp.ServeContent(w, r, file.Name, file.ModTime, fd)\n\treturn 0, nil\n}", "is_vulnerable": 0}
{"code": "\treturn func(c *models.ReqContext) {\n\t\tif cfg.SnapshotPublicMode {\n\t\t\treturn\n\t\t}\n\n\t\t_, err := c.Invoke(ReqSignedIn)\n\t\tif err != nil {\n\t\t\tc.JsonApiErr(500, \"Failed to invoke required signed in middleware\", err)\n\t\t}\n\t}", "is_vulnerable": 1}
{"code": "\tdir1, s1 := testServerWithConfig(t, func(c *Config) {\n\t\tc.Datacenter = \"dc1\"\n\t\tc.Bootstrap = true\n\t\tc.SerfFloodInterval = 100 * time.Millisecond\n\t\tc.SerfLANConfig.ReconnectTimeout = 250 * time.Millisecond\n\t\tc.SerfLANConfig.ReapInterval = 500 * time.Millisecond\n\t})", "is_vulnerable": 1}
{"code": "func (hs *HTTPServer) getPluginAssets(c *models.ReqContext) {\n\tpluginID := web.Params(c.Req)[\":pluginId\"]\n\tplugin, exists := hs.pluginStore.Plugin(c.Req.Context(), pluginID)\n\tif !exists {\n\t\tc.JsonApiErr(404, \"Plugin not found\", nil)\n\t\treturn\n\t}\n\n\trequestedFile := filepath.Clean(web.Params(c.Req)[\"*\"])\n\tpluginFilePath := filepath.Join(plugin.PluginDir, requestedFile)\n\n\tif !plugin.IncludedInSignature(requestedFile) {\n\t\ths.log.Warn(\"Access to requested plugin file will be forbidden in upcoming Grafana versions as the file \"+\n\t\t\t\"is not included in the plugin signature\", \"file\", requestedFile)\n\t}\n\n\t// It's safe to ignore gosec warning G304 since we already clean the requested file path and subsequently\n\t// use this with a prefix of the plugin's directory, which is set during plugin loading\n\t// nolint:gosec\n\tf, err := os.Open(pluginFilePath)\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\tc.JsonApiErr(404, \"Plugin file not found\", err)\n\t\t\treturn\n\t\t}\n\t\tc.JsonApiErr(500, \"Could not open plugin file\", err)\n\t\treturn\n\t}\n\tdefer func() {\n\t\tif err := f.Close(); err != nil {\n\t\t\ths.log.Error(\"Failed to close file\", \"err\", err)\n\t\t}\n\t}()\n\n\tfi, err := f.Stat()\n\tif err != nil {\n\t\tc.JsonApiErr(500, \"Plugin file exists but could not open\", err)\n\t\treturn\n\t}\n\n\tif hs.Cfg.Env == setting.Dev {\n\t\tc.Resp.Header().Set(\"Cache-Control\", \"max-age=0, must-revalidate, no-cache\")\n\t} else {\n\t\tc.Resp.Header().Set(\"Cache-Control\", \"public, max-age=3600\")\n\t}\n\n\thttp.ServeContent(c.Resp, c.Req, pluginFilePath, fi.ModTime(), f)\n}", "is_vulnerable": 1}
{"code": "func (m *MockERC20BridgeView) FindBridgeStopped(arg0 *types.ERC20EventBridgeStopped, arg1, arg2 uint64, arg3 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"FindBridgeStopped\", arg0, arg1, arg2, arg3)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func TestGenerateYamlManifestInDir(t *testing.T) {\n\tservice := newService(\"../..\")\n\n\tsrc := argoappv1.ApplicationSource{Path: \"manifests/base\"}\n\tq := apiclient.ManifestRequest{Repo: &argoappv1.Repository{}, ApplicationSource: &src}\n\n\t// update this value if we add/remove manifests\n\tconst countOfManifests = 34\n\n\tres1, err := service.GenerateManifest(context.Background(), &q)\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, countOfManifests, len(res1.Manifests))\n\n\t// this will test concatenated manifests to verify we split YAMLs correctly\n\tres2, err := GenerateManifests(\"./testdata/concatenated\", \"/\", \"\", &q, false)\n\tassert.NoError(t, err)\n\tassert.Equal(t, 3, len(res2.Manifests))\n}", "is_vulnerable": 1}
{"code": "func NewQUICServer(addr, password, domain string, tcpTimeout, udpTimeout int, blockDomainList, blockCIDR4List, blockCIDR6List string, updateListInterval int64, blockGeoIP []string, withoutbrook bool) (*QUICServer, error) {\n\tif err := limits.Raise(); err != nil {\n\t\tLog(&Error{\"when\": \"try to raise system limits\", \"warning\": err.Error()})\n\t}\n\tif runtime.GOOS == \"linux\" {\n\t\tc := exec.Command(\"sysctl\", \"-w\", \"net.core.rmem_max=2500000\")\n\t\tb, err := c.CombinedOutput()\n\t\tif err != nil {\n\t\t\tLog(&Error{\"when\": \"try to raise UDP Receive Buffer Size\", \"warning\": string(b)})\n\t\t}\n\t}\n\tif runtime.GOOS == \"darwin\" {\n\t\tc := exec.Command(\"sysctl\", \"-w\", \"kern.ipc.maxsockbuf=3014656\")\n\t\tb, err := c.CombinedOutput()\n\t\tif err != nil {\n\t\t\tLog(&Error{\"when\": \"try to raise UDP Receive Buffer Size\", \"warning\": string(b)})\n\t\t}\n\t}\n\tvar p []byte\n\tvar f UDPServerConnFactory\n\tif !withoutbrook {\n\t\tp = []byte(password)\n\t\tf = NewPacketServerConnFactory()\n\t}\n\tif withoutbrook {\n\t\tvar err error\n\t\tp, err = crypto1.SHA256Bytes([]byte(password))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tf = NewSimplePacketServerConnFactory()\n\t}\n\ts := &QUICServer{\n\t\tPassword:             p,\n\t\tDomain:               domain,\n\t\tAddr:                 addr,\n\t\tTCPTimeout:           tcpTimeout,\n\t\tUDPTimeout:           udpTimeout,\n\t\tUDPServerConnFactory: f,\n\t\tRunnerGroup:          runnergroup.New(),\n\t\tWithoutBrook:         withoutbrook,\n\t}\n\treturn s, nil\n}", "is_vulnerable": 1}
{"code": "func YAMLToJSON(y []byte) ([]byte, error) {\n\treturn yamlToJSON(y, nil, yaml.Unmarshal)\n}", "is_vulnerable": 1}
{"code": "func (s *PrecompileTestSuite) setupRedelegations(redelAmt *big.Int) error {\n\tmsg := stakingtypes.MsgBeginRedelegate{\n\t\tDelegatorAddress:    sdk.AccAddress(s.address.Bytes()).String(),\n\t\tValidatorSrcAddress: s.validators[0].OperatorAddress,\n\t\tValidatorDstAddress: s.validators[1].OperatorAddress,\n\t\tAmount:              sdk.NewCoin(s.bondDenom, math.NewIntFromBigInt(redelAmt)),\n\t}\n\n\tmsgSrv := stakingkeeper.NewMsgServerImpl(&s.app.StakingKeeper)\n\t// create 2 entries for same redelegation\n\tfor i := 0; i < 2; i++ {\n\t\tif _, err := msgSrv.BeginRedelegate(s.ctx, &msg); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// create a validator with s.address and s.privKey\n\t// then create a redelegation from validator[0] to this new validator\n\ttestutil.CreateValidator(s.ctx, s.T(), s.privKey.PubKey(), *s.app.StakingKeeper.Keeper, math.NewInt(100))\n\tmsg.ValidatorDstAddress = sdk.ValAddress(s.address.Bytes()).String()\n\t_, err := msgSrv.BeginRedelegate(s.ctx, &msg)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "\tf.Fuzz(func(t *testing.T, vector string) {\n\t\tcvss20, err := ParseVector(vector)\n\n\t\tif err != nil {\n\t\t\tif cvss20 != nil {\n\t\t\t\tt.Fatal(\"not supposed to get a CVSS20 when an error is returned\")\n\t\t\t}\n\t\t} else {\n\t\t\t// This check works because CVSS v2.0 has a predetermined order.\n\t\t\tcvss20vector := cvss20.Vector()\n\t\t\tif vector != cvss20vector {\n\t\t\t\tt.Fatalf(\"vector differs at export: input is %s but output is %s\", vector, cvss20vector)\n\t\t\t}\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) CalculateTemplateHashSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func (dl *Download) isExternalNetwork(ctx context.Context) error {\n\tdialer := &net.Dialer{\n\t\tLocalAddr: nil,\n\t}\n\n\thost := dl.req.URL.Host\n\n\t// This cluster-fuck of math and integer shit converts an integer IP into a proper IPv4.\n\t// For example: 16843009 would become 1.1.1.1\n\t//if i, err := strconv.ParseInt(host, 10, 64); err == nil {\n\t//\thost = strconv.FormatInt((i>>24)&0xFF, 10) + \".\" + strconv.FormatInt((i>>16)&0xFF, 10) + \".\" + strconv.FormatInt((i>>8)&0xFF, 10) + \".\" + strconv.FormatInt(i&0xFF, 10)\n\t//}\n\n\tif _, _, err := net.SplitHostPort(host); err != nil {\n\t\tif !strings.Contains(err.Error(), \"missing port in address\") {\n\t\t\treturn errors.WithStack(err)\n\t\t}\n\t\tswitch dl.req.URL.Scheme {\n\t\tcase \"http\":\n\t\t\thost += \":80\"\n\t\tcase \"https\":\n\t\t\thost += \":443\"\n\t\t}\n\t}\n\n\tc, err := dialer.DialContext(ctx, \"tcp\", host)\n\tif err != nil {\n\t\treturn errors.WithStack(err)\n\t}\n\t_ = c.Close()\n\n\tipStr, _, err := net.SplitHostPort(c.RemoteAddr().String())\n\tif err != nil {\n\t\treturn errors.WithStack(err)\n\t}\n\tip := net.ParseIP(ipStr)\n\tif ip == nil {\n\t\treturn errors.WithStack(ErrInvalidIPAddress)\n\t}\n\tif ip.IsLoopback() || ip.IsLinkLocalUnicast() || ip.IsLinkLocalMulticast() || ip.IsInterfaceLocalMulticast() {\n\t\treturn errors.WithStack(ErrInternalResolution)\n\t}\n\tfor _, block := range internalRanges {\n\t\tif block.Contains(ip) {\n\t\t\treturn errors.WithStack(ErrInternalResolution)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"InvalidTemplate\", func(t *testing.T) {\n\t\t_, err := Replace(toJsonString(\"{{\"), nil, false)\n\t\tassert.Error(t, err)\n\t})", "is_vulnerable": 0}
{"code": "func (svc *Service) RefetchHost(ctx context.Context, id uint) error {\n\tif !svc.authz.IsAuthenticatedWith(ctx, authz.AuthnDeviceToken) {\n\t\tif err := svc.authz.Authorize(ctx, &fleet.Host{}, fleet.ActionList); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\thost, err := svc.ds.HostLite(ctx, id)\n\t\tif err != nil {\n\t\t\treturn ctxerr.Wrap(ctx, err, \"find host for refetch\")\n\t\t}\n\n\t\t// We verify fleet.ActionRead instead of fleet.ActionWrite because we want to allow\n\t\t// observers to be able to refetch hosts.\n\t\tif err := svc.authz.Authorize(ctx, host, fleet.ActionRead); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := svc.ds.UpdateHostRefetchRequested(ctx, id, true); err != nil {\n\t\treturn ctxerr.Wrap(ctx, err, \"save host\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func mapRequest(ctx *context, requestContext stdlibcontext.Context, removeHopHeaders bool) (*http.Request, *routing.LBEndpoint, error) {\n\tvar endpoint *routing.LBEndpoint\n\tr := ctx.request\n\trt := ctx.route\n\thost := ctx.outgoingHost\n\tstateBag := ctx.StateBag()\n\tu := r.URL\n\n\tswitch rt.BackendType {\n\tcase eskip.DynamicBackend:\n\t\tsetRequestURLFromRequest(u, r)\n\t\tsetRequestURLForDynamicBackend(u, stateBag)\n\tcase eskip.LBBackend:\n\t\tendpoint = setRequestURLForLoadBalancedBackend(u, rt, &routing.LBContext{Request: r, Route: rt, Params: stateBag})\n\tdefault:\n\t\tu.Scheme = rt.Scheme\n\t\tu.Host = rt.Host\n\t}\n\n\tbody := r.Body\n\tif r.ContentLength == 0 {\n\t\tbody = nil\n\t}\n\n\trr, err := http.NewRequestWithContext(requestContext, r.Method, u.String(), body)\n\tif err != nil {\n\t\treturn nil, endpoint, err\n\t}\n\n\trr.ContentLength = r.ContentLength\n\tif removeHopHeaders {\n\t\trr.Header = cloneHeaderExcluding(r.Header, hopHeaders)\n\t} else {\n\t\trr.Header = cloneHeader(r.Header)\n\t}\n\t// Disable default net/http user agent when user agent is not specified\n\tif _, ok := rr.Header[\"User-Agent\"]; !ok {\n\t\trr.Header[\"User-Agent\"] = []string{\"\"}\n\t}\n\trr.Host = host\n\n\t// If there is basic auth configured in the URL we add them as headers\n\tif u.User != nil {\n\t\tup := u.User.String()\n\t\tupBase64 := base64.StdEncoding.EncodeToString([]byte(up))\n\t\trr.Header.Add(\"Authorization\", fmt.Sprintf(\"Basic %s\", upBase64))\n\t}\n\n\tctxspan := ot.SpanFromContext(r.Context())\n\tif ctxspan != nil {\n\t\trr = rr.WithContext(ot.ContextWithSpan(rr.Context(), ctxspan))\n\t}\n\n\tif _, ok := stateBag[filters.BackendIsProxyKey]; ok {\n\t\trr = forwardToProxy(r, rr)\n\t}\n\n\treturn rr, endpoint, nil\n}", "is_vulnerable": 0}
{"code": "func NewHandler(appLister applisters.ApplicationLister, namespace string, enabledNamespaces []string, db db.ArgoDB, enf *rbac.Enforcer, cache *servercache.Cache,\n\tappResourceTree AppResourceTreeFn, allowedShells []string) *terminalHandler {\n\treturn &terminalHandler{\n\t\tappLister:         appLister,\n\t\tdb:                db,\n\t\tenf:               enf,\n\t\tcache:             cache,\n\t\tappResourceTreeFn: appResourceTree,\n\t\tallowedShells:     allowedShells,\n\t\tnamespace:         namespace,\n\t\tenabledNamespaces: enabledNamespaces,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (k *Key) KeyListMode() KeyListMode {\n\tres := KeyListMode(k.k.keylist_mode)\n\truntime.KeepAlive(k)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func TestPathRoleSet_RotateKeyRoleSet(t *testing.T) {\n\trsName := \"test-rotatekeyrs\"\n\troles := util.StringSet{\n\t\t\"roles/viewer\": struct{}{},\n\t}\n\n\t// Initial test set up - backend, initial config, test resources in project\n\ttd := setupTest(t, \"0s\", \"2h\")\n\tdefer cleanup(t, td, rsName, roles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// Create role set\n\texpectedBinds := ResourceBindings{projRes: roles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":     td.Project,\n\t\t\t\"secret_type\": SecretTypeKey,\n\t\t\t\"bindings\":    bindsRaw,\n\t\t})\n\n\t// Verify initial role set.\n\trespData := testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\tinitSa := getServiceAccount(t, td.IamAdmin, respData)\n\tverifyProjectBinding(t, td, initSa.Email, roles)\n\n\t// Rotate account and verify is new account.\n\ttestRoleSetRotate(t, td, rsName)\n\tnewSa := getServiceAccount(t, td.IamAdmin, testRoleSetRead(t, td, rsName))\n\tif newSa.Name == initSa.Name {\n\t\tt.Fatalf(\"expected role set to have new service account after rotation (update)\")\n\t}\n\tverifyProjectBinding(t, td, newSa.Email, roles)\n\n\t// Verify old account/bindings deleted.\n\tverifyServiceAccountDeleted(t, td.IamAdmin, initSa.Name)\n\tverifyProjectBindingsRemoved(t, td, initSa.Email, roles)\n\n\t// Get RoleSet object for confirming key rotation:\n\trs, err := getRoleSet(rsName, context.Background(), td.S)\n\tif rs.TokenGen != nil {\n\t\tt.Fatalf(\"expected no token gen to have been created for key role set\")\n\t}\n\n\t// 4. Delete role set\n\ttestRoleSetDelete(t, td, rsName, newSa.Name)\n\tverifyProjectBindingsRemoved(t, td, newSa.Email, roles)\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tsuite.Register(new(remotereceivernotoken))\n}", "is_vulnerable": 0}
{"code": "func (m *MockRequester) SetID(arg0 string) {\n\tm.ctrl.T.Helper()\n\tm.ctrl.Call(m, \"SetID\", arg0)\n}", "is_vulnerable": 0}
{"code": "func StripSensitiveValue(req fmt.Stringer, key string) fmt.Stringer {\n\treturn &stripSensitiveValue{\n\t\tkey: key,\n\t\treq: req,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *CustomNameCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldA\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v Uuid\n\t\t\tm.FieldA = &v\n\t\t\tif err := m.FieldA.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldB\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.FieldB = &v\n\t\t\tif err := m.FieldB.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldC\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v Uuid\n\t\t\tm.FieldC = append(m.FieldC, v)\n\t\t\tif err := m.FieldC[len(m.FieldC)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldD\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.FieldD = append(m.FieldD, v)\n\t\t\tif err := m.FieldD[len(m.FieldD)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func PidfdOpen(pid int, flags int) (fd int, err error) {\n\tr0, _, e1 := Syscall(SYS_PIDFD_OPEN, uintptr(pid), uintptr(flags), 0)\n\tfd = int(r0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "\tparser.Inspect(expr, func(node parser.Node, nodes []parser.Node) error {\n\t\tswitch n := node.(type) {\n\t\tcase *parser.Call:\n\t\t\tif n.Func != nil {\n\t\t\t\tif n.Func.Name == \"label_join\" || n.Func.Name == \"label_replace\" {\n\t\t\t\t\tdstLabel := stringFromArg(n.Args[1])\n\t\t\t\t\tdynamicLabels = append(dynamicLabels, dstLabel)\n\t\t\t\t} else if n.Func.Name == \"absent_over_time\" || n.Func.Name == \"absent\" || n.Func.Name == \"scalar\" {\n\t\t\t\t\tisShardable = false\n\t\t\t\t\treturn notShardableErr\n\t\t\t\t} else if n.Func.Name == \"histogram_quantile\" {\n\t\t\t\t\tanalysis = analysis.scopeToLabels([]string{\"le\"}, false)\n\t\t\t\t}\n\t\t\t}\n\t\tcase *parser.BinaryExpr:\n\t\t\tif n.VectorMatching != nil {\n\t\t\t\tshardingLabels := n.VectorMatching.MatchingLabels\n\t\t\t\tif !n.VectorMatching.On {\n\t\t\t\t\tshardingLabels = append(shardingLabels, model.MetricNameLabel)\n\t\t\t\t}\n\t\t\t\tanalysis = analysis.scopeToLabels(shardingLabels, n.VectorMatching.On)\n\t\t\t}\n\t\tcase *parser.AggregateExpr:\n\t\t\tshardingLabels := make([]string, 0)\n\t\t\tif len(n.Grouping) > 0 {\n\t\t\t\tshardingLabels = n.Grouping\n\t\t\t}\n\t\t\tanalysis = analysis.scopeToLabels(shardingLabels, !n.Without)\n\t\t}\n\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func TestInspectCommand_SecretsFromEnv(t *testing.T) {\n\tt.Setenv(defaultUsernameEnv, \"user\")\n\tt.Setenv(defaultPasswordEnv, \"password\")\n\topts := &inspectOpts{}\n\texpected := &inspectOpts{\n\t\treference: \"ref\",\n\t\tSecureFlagOpts: SecureFlagOpts{\n\t\t\tPassword: \"password\",\n\t\t\tUsername: \"user\",\n\t\t},\n\t\toutputFormat:  cmd.OutputJSON,\n\t\tmaxSignatures: 100,\n\t}\n\tcommand := inspectCommand(opts)\n\tif err := command.ParseFlags([]string{\n\t\texpected.reference,\n\t\t\"--output\", \"json\"}); err != nil {\n\t\tt.Fatalf(\"Parse Flag failed: %v\", err)\n\t}\n\tif err := command.Args(command, command.Flags().Args()); err != nil {\n\t\tt.Fatalf(\"Parse Args failed: %v\", err)\n\t}\n\tif *opts != *expected {\n\t\tt.Fatalf(\"Expect inspect opts: %v, got: %v\", expected, opts)\n\t}\n}", "is_vulnerable": 0}
{"code": "func ValidateKeyspaceName(name string) error {\n\tif strings.ContainsAny(name, invalidKeyspaceNameChars) {\n\t\treturn vterrors.Errorf(vtrpcpb.Code_INVALID_ARGUMENT, \"keyspace name %s contains invalid characters; may not contain any of the following: %+v\", name, strings.Split(invalidKeyspaceNameChars, \"\"))\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Timer) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Timer: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Timer: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Time1\", wireType)\n\t\t\t}\n\t\t\tm.Time1 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Time1 = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 2:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Time2\", wireType)\n\t\t\t}\n\t\t\tm.Time2 = 0\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Time2 = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Data\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Data = append(m.Data[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Data == nil {\n\t\t\t\tm.Data = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func MakeHookedWebSocketEvent(event *model.WebSocketEvent) *HookedWebSocketEvent {\n\treturn &HookedWebSocketEvent{\n\t\toriginal: event,\n\t}\n}", "is_vulnerable": 0}
{"code": "func local_request_API_GetToolInfo_0(ctx context.Context, marshaler runtime.Marshaler, server APIServer, req *http.Request, pathParams map[string]string) (proto.Message, runtime.ServerMetadata, error) {\n\tvar protoReq proto_6.Tool\n\tvar metadata runtime.ServerMetadata\n\n\tif err := req.ParseForm(); err != nil {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", err)\n\t}\n\tif err := runtime.PopulateQueryParameters(&protoReq, req.Form, filter_API_GetToolInfo_0); err != nil {\n\t\treturn nil, metadata, status.Errorf(codes.InvalidArgument, \"%v\", err)\n\t}\n\n\tmsg, err := server.GetToolInfo(ctx, &protoReq)\n\treturn msg, metadata, err\n\n}", "is_vulnerable": 0}
{"code": "\tDescribe(\"Decrypt\", func() {\n\t\tvar (\n\t\t\tplainText  = []byte(\"this is a secret message!\")\n\t\t\tcipherText []byte\n\t\t\tnonce      []byte\n\t\t)\n\n\t\tBeforeEach(func() {\n\t\t\tvar err error\n\t\t\tcipherText, nonce, err = aesGcm.Encrypt(plainText)\n\t\t\tExpect(err).ToNot(HaveOccurred())\n\t\t\tExpect(cipherText).ToNot(Equal(plainText))\n\t\t\tExpect(nonce).ToNot(BeNil())\n\t\t})\n\n\t\tContext(\"when using correct key and nonce\", func() {\n\t\t\tIt(\"decrypts the cipher text\", func() {\n\t\t\t\tdecryptedText, err := aesGcm.Decrypt(cipherText, nonce)\n\t\t\t\tExpect(err).ToNot(HaveOccurred())\n\t\t\t\tExpect(decryptedText).To(Equal(plainText))\n\t\t\t})\n\t\t})\n\n\t\tContext(\"when using an invalid key\", func() {\n\t\t\tIt(\"returns an error\", func() {\n\t\t\t\totherKey := []byte(\"0123456789ABCDEF\")\n\n\t\t\t\totherAesGcm, err := secure.NewAesGCM(otherKey)\n\t\t\t\tExpect(err).ToNot(HaveOccurred())\n\n\t\t\t\tdecryptedText, err := otherAesGcm.Decrypt(cipherText, nonce)\n\t\t\t\tExpect(err).To(HaveOccurred())\n\t\t\t\tExpect(err.Error()).Should(ContainSubstring(\"authentication failed\"))\n\t\t\t\tExpect(decryptedText).ToNot(Equal(plainText))\n\t\t\t})\n\t\t})\n\n\t\tContext(\"when using an invalid nonce\", func() {\n\t\t\tIt(\"returns an error\", func() {\n\t\t\t\totherNonce := []byte(\"0123456789AB\")\n\t\t\t\tdecryptedText, err := aesGcm.Decrypt(cipherText, otherNonce)\n\t\t\t\tExpect(err).To(HaveOccurred())\n\t\t\t\tExpect(err.Error()).Should(ContainSubstring(\"authentication failed\"))\n\t\t\t\tExpect(decryptedText).ToNot(Equal(plainText))\n\t\t\t})\n\t\t})\n\n\t\tContext(\"when the nonce is an invalid length\", func() {\n\t\t\tIt(\"does not panic and returns an error\", func() {\n\t\t\t\totherNonce := []byte(\"0123\")\n\t\t\t\tdecryptedText, err := aesGcm.Decrypt(cipherText, otherNonce)\n\t\t\t\tExpect(err).To(HaveOccurred())\n\t\t\t\tExpect(err.Error()).Should(ContainSubstring(\"incorrect nonce length\"))\n\t\t\t\tExpect(decryptedText).ToNot(Equal(plainText))\n\t\t\t})\n\t\t})\n\t})", "is_vulnerable": 0}
{"code": "func TestListNodeExecutions_Order(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(nodeExecutions)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\t_, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}", "is_vulnerable": 1}
{"code": "func TestBuilder_BuildBootstrapAdmin(t *testing.T) {\n\tb := New(\"local-grpc\", \"local-http\", filemgr.NewManager(), nil)\n\tt.Run(\"valid\", func(t *testing.T) {\n\t\tadminCfg, err := b.BuildBootstrapAdmin(&config.Config{\n\t\t\tOptions: &config.Options{\n\t\t\t\tEnvoyAdminAddress: \"localhost:9901\",\n\t\t\t},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"address\": {\n\t\t\t\t\t\"socketAddress\": {\n\t\t\t\t\t\t\"address\": \"127.0.0.1\",\n\t\t\t\t\t\t\"portValue\": 9901\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t`, adminCfg)\n\t})\n\tt.Run(\"bad address\", func(t *testing.T) {\n\t\t_, err := b.BuildBootstrapAdmin(&config.Config{\n\t\t\tOptions: &config.Options{\n\t\t\t\tEnvoyAdminAddress: \"xyz1234:zyx4321\",\n\t\t\t},\n\t\t})\n\t\tassert.Error(t, err)\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestHttpGetter__XTerraformGetDisabled(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tln := testHttpServerWithXTerraformGetLoop(t)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/loop\"\n\tdst := testing_helper.TempDir(t)\n\n\tg := new(HttpGetter)\n\tg.XTerraformGetDisabled = true\n\tg.Client = &http.Client{}\n\n\treq := Request{\n\t\tDst:     dst,\n\t\tu:       &u,\n\t\tGetMode: ModeDir,\n\t}\n\n\terr := g.Get(ctx, &req)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TempClone(gitURL, hash string, useAuth bool) (repoDir string, err error) {\n\tdir, err := os.MkdirTemp(\"\", \"wolfictl-git-clone-*\")\n\tif err != nil {\n\t\treturn dir, fmt.Errorf(\"unable to create temp directory for git clone: %w\", err)\n\t}\n\n\tvar auth transport.AuthMethod\n\tif useAuth {\n\t\tauth, err = GetGitAuth(gitURL)\n\t\tif err != nil {\n\t\t\treturn dir, fmt.Errorf(\"unable to get git auth: %w\", err)\n\t\t}\n\t}\n\n\trepo, err := git.PlainClone(dir, false, &git.CloneOptions{\n\t\tAuth: auth,\n\t\tURL:  gitURL,\n\t})\n\tif err != nil {\n\t\treturn dir, fmt.Errorf(\"unable to clone repo %q to temp directory: %w\", gitURL, err)\n\t}\n\n\tif hash != \"\" {\n\t\tw, err := repo.Worktree()\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"unable to get worktree for repo %q: %w\", gitURL, err)\n\t\t}\n\t\terr = w.Checkout(&git.CheckoutOptions{\n\t\t\tHash: plumbing.NewHash(hash),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"unable to checkout hash %q for repo %q: %w\", hash, gitURL, err)\n\t\t}\n\t}\n\n\treturn dir, nil\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_CommonTLSConfigValidateVerifyOutgoingCA(t *testing.T) {\n\tc := NewConfigurator(&Config{VerifyOutgoing: true})\n\t_, err := c.commonTLSConfig(false)\n\trequire.Error(t, err)\n}", "is_vulnerable": 1}
{"code": "func hasBadPathComponent(path string) bool {\n\tpath = strings.TrimSpace(path)\n\tfor _, p := range strings.Split(path, SlashSeparator) {\n\t\tswitch strings.TrimSpace(p) {\n\t\tcase dotdotComponent:\n\t\t\treturn true\n\t\tcase dotComponent:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func TestProxyUpgradeErrorResponseTerminates(t *testing.T) {\n\tfor _, intercept := range []bool{true, false} {\n\t\tfor _, code := range []int{200, 400, 500} {\n\t\t\tt.Run(fmt.Sprintf(\"intercept=%v,code=%v\", intercept, code), func(t *testing.T) {\n\t\t\t\t// Set up a backend server\n\t\t\t\tbackend := http.NewServeMux()\n\t\t\t\tbackend.Handle(\"/hello\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\t\tw.WriteHeader(code)\n\t\t\t\t\tw.Write([]byte(`some data`))\n\t\t\t\t}))\n\t\t\t\tbackend.Handle(\"/there\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\t\tt.Error(\"request to /there\")\n\t\t\t\t}))\n\t\t\t\tbackendServer := httptest.NewServer(backend)\n\t\t\t\tdefer backendServer.Close()\n\t\t\t\tbackendServerURL, _ := url.Parse(backendServer.URL)\n\t\t\t\tbackendServerURL.Path = \"/hello\"\n\n\t\t\t\t// Set up a proxy pointing to a specific path on the backend\n\t\t\t\tproxyHandler := NewUpgradeAwareHandler(backendServerURL, nil, false, false, &noErrorsAllowed{t: t})\n\t\t\t\tproxyHandler.InterceptRedirects = intercept\n\t\t\t\tproxy := httptest.NewServer(proxyHandler)\n\t\t\t\tdefer proxy.Close()\n\t\t\t\tproxyURL, _ := url.Parse(proxy.URL)\n\n\t\t\t\tconn, err := net.Dial(\"tcp\", proxyURL.Host)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tbufferedReader := bufio.NewReader(conn)\n\n\t\t\t\t// Send upgrade request resulting in a non-101 response from the backend\n\t\t\t\treq, _ := http.NewRequest(\"GET\", \"/\", nil)\n\t\t\t\treq.Header.Set(httpstream.HeaderConnection, httpstream.HeaderUpgrade)\n\t\t\t\trequire.NoError(t, req.Write(conn))\n\t\t\t\t// Verify we get the correct response and full message body content\n\t\t\t\tresp, err := http.ReadResponse(bufferedReader, nil)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tdata, err := ioutil.ReadAll(resp.Body)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, resp.StatusCode, code)\n\t\t\t\trequire.Equal(t, data, []byte(`some data`))\n\t\t\t\tresp.Body.Close()\n\n\t\t\t\t// try to read from the connection to verify it was closed\n\t\t\t\tb := make([]byte, 1)\n\t\t\t\tconn.SetReadDeadline(time.Now().Add(time.Second))\n\t\t\t\tif _, err := conn.Read(b); err != io.EOF {\n\t\t\t\t\tt.Errorf(\"expected EOF, got %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// Send another request to another endpoint to verify it is not received\n\t\t\t\treq, _ = http.NewRequest(\"GET\", \"/there\", nil)\n\t\t\t\treq.Write(conn)\n\t\t\t\t// wait to ensure the handler does not receive the request\n\t\t\t\ttime.Sleep(time.Second)\n\n\t\t\t\t// clean up\n\t\t\t\tconn.Close()\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (h *backupHandler) ServeHTTP(resp http.ResponseWriter, req *http.Request) {\n\t// Validate before authenticate because the authentication is dependent\n\t// on the state connection that is determined during the validation.\n\tst, err := h.ctxt.stateForRequestAuthenticatedUser(req)\n\tif err != nil {\n\t\th.sendError(resp, err)\n\t\treturn\n\t}\n\tdefer st.Release()\n\n\tif !st.IsController() {\n\t\th.sendError(resp, errors.New(\"requested model is not the controller model\"))\n\t\treturn\n\t}\n\n\tswitch req.Method {\n\tcase \"GET\":\n\t\tlogger.Infof(\"handling backups download request\")\n\t\tid, err := h.download(newBackups(), resp, req)\n\t\tif err != nil {\n\t\t\th.sendError(resp, err)\n\t\t\treturn\n\t\t}\n\t\tlogger.Infof(\"backups download request successful for %q\", id)\n\tdefault:\n\t\th.sendError(resp, errors.MethodNotAllowedf(\"unsupported method: %q\", req.Method))\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\t\t\t\t\tgo func(absPath string) {\n\t\t\t\t\t\t\tdefer waitGroup.Done()\n\t\t\t\t\t\t\tfs.BeforeFileOpen()\n\t\t\t\t\t\t\tdefer fs.AfterFileClose()\n\t\t\t\t\t\t\tos.Remove(absPath)\n\t\t\t\t\t\t}(absPath)", "is_vulnerable": 0}
{"code": "func (ng *AlertNG) init() error {\n\tvar err error\n\n\t// AlertNG should be initialized before the cancellation deadline of initCtx\n\tinitCtx, cancelFunc := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer cancelFunc()\n\n\tstore := &store.DBstore{\n\t\tCfg:              ng.Cfg.UnifiedAlerting,\n\t\tFeatureToggles:   ng.FeatureToggles,\n\t\tSQLStore:         ng.SQLStore,\n\t\tLogger:           ng.Log,\n\t\tFolderService:    ng.folderService,\n\t\tAccessControl:    ng.accesscontrol,\n\t\tDashboardService: ng.dashboardService,\n\t}\n\tng.store = store\n\n\tdecryptFn := ng.SecretsService.GetDecryptedValue\n\tmultiOrgMetrics := ng.Metrics.GetMultiOrgAlertmanagerMetrics()\n\tng.MultiOrgAlertmanager, err = notifier.NewMultiOrgAlertmanager(ng.Cfg, store, store, ng.KVStore, store, decryptFn, multiOrgMetrics, ng.NotificationService, log.New(\"ngalert.multiorg.alertmanager\"), ng.SecretsService)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\timageService, err := image.NewScreenshotImageServiceFromCfg(ng.Cfg, store, ng.dashboardService, ng.renderService, ng.Metrics.Registerer)\n\tif err != nil {\n\t\treturn err\n\t}\n\tng.imageService = imageService\n\n\t// Let's make sure we're able to complete an initial sync of Alertmanagers before we start the alerting components.\n\tif err := ng.MultiOrgAlertmanager.LoadAndSyncAlertmanagersForOrgs(initCtx); err != nil {\n\t\treturn fmt.Errorf(\"failed to initialize alerting because multiorg alertmanager manager failed to warm up: %w\", err)\n\t}\n\n\tappUrl, err := url.Parse(ng.Cfg.AppURL)\n\tif err != nil {\n\t\tng.Log.Error(\"Failed to parse application URL. Continue without it.\", \"error\", err)\n\t\tappUrl = nil\n\t}\n\n\tclk := clock.New()\n\n\talertsRouter := sender.NewAlertsRouter(ng.MultiOrgAlertmanager, store, clk, appUrl, ng.Cfg.UnifiedAlerting.DisabledOrgs,\n\t\tng.Cfg.UnifiedAlerting.AdminConfigPollInterval, ng.DataSourceService, ng.SecretsService)\n\n\t// Make sure we sync at least once as Grafana starts to get the router up and running before we start sending any alerts.\n\tif err := alertsRouter.SyncAndApplyConfigFromDatabase(); err != nil {\n\t\treturn fmt.Errorf(\"failed to initialize alerting because alert notifications router failed to warm up: %w\", err)\n\t}\n\n\tng.AlertsRouter = alertsRouter\n\n\tevalFactory := eval.NewEvaluatorFactory(ng.Cfg.UnifiedAlerting, ng.DataSourceCache, ng.ExpressionService, ng.pluginsStore)\n\tschedCfg := schedule.SchedulerCfg{\n\t\tMaxAttempts:          ng.Cfg.UnifiedAlerting.MaxAttempts,\n\t\tC:                    clk,\n\t\tBaseInterval:         ng.Cfg.UnifiedAlerting.BaseInterval,\n\t\tMinRuleInterval:      ng.Cfg.UnifiedAlerting.MinInterval,\n\t\tDisableGrafanaFolder: ng.Cfg.UnifiedAlerting.ReservedLabels.IsReservedLabelDisabled(models.FolderTitleLabel),\n\t\tAppURL:               appUrl,\n\t\tEvaluatorFactory:     evalFactory,\n\t\tRuleStore:            store,\n\t\tMetrics:              ng.Metrics.GetSchedulerMetrics(),\n\t\tAlertSender:          alertsRouter,\n\t\tTracer:               ng.tracer,\n\t}\n\n\thistory, err := configureHistorianBackend(initCtx, ng.Cfg.UnifiedAlerting.StateHistory, ng.annotationsRepo, ng.dashboardService, ng.store, ng.Metrics.GetHistorianMetrics(), ng.Log)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcfg := state.ManagerCfg{\n\t\tMetrics:              ng.Metrics.GetStateMetrics(),\n\t\tExternalURL:          appUrl,\n\t\tInstanceStore:        store,\n\t\tImages:               ng.imageService,\n\t\tClock:                clk,\n\t\tHistorian:            history,\n\t\tDoNotSaveNormalState: ng.FeatureToggles.IsEnabled(featuremgmt.FlagAlertingNoNormalState),\n\t}\n\tstateManager := state.NewManager(cfg)\n\tscheduler := schedule.NewScheduler(schedCfg, stateManager)\n\n\t// if it is required to include folder title to the alerts, we need to subscribe to changes of alert title\n\tif !ng.Cfg.UnifiedAlerting.ReservedLabels.IsReservedLabelDisabled(models.FolderTitleLabel) {\n\t\tsubscribeToFolderChanges(context.Background(), ng.Log, ng.bus, store, scheduler)\n\t}\n\n\tng.stateManager = stateManager\n\tng.schedule = scheduler\n\n\t// Provisioning\n\tpolicyService := provisioning.NewNotificationPolicyService(store, store, store, ng.Cfg.UnifiedAlerting, ng.Log)\n\tcontactPointService := provisioning.NewContactPointService(store, ng.SecretsService, store, store, ng.Log)\n\ttemplateService := provisioning.NewTemplateService(store, store, store, ng.Log)\n\tmuteTimingService := provisioning.NewMuteTimingService(store, store, store, ng.Log)\n\talertRuleService := provisioning.NewAlertRuleService(store, store, ng.dashboardService, ng.QuotaService, store,\n\t\tint64(ng.Cfg.UnifiedAlerting.DefaultRuleEvaluationInterval.Seconds()),\n\t\tint64(ng.Cfg.UnifiedAlerting.BaseInterval.Seconds()), ng.Log)\n\n\tapi := api.API{\n\t\tCfg:                  ng.Cfg,\n\t\tDatasourceCache:      ng.DataSourceCache,\n\t\tDatasourceService:    ng.DataSourceService,\n\t\tRouteRegister:        ng.RouteRegister,\n\t\tSchedule:             ng.schedule,\n\t\tDataProxy:            ng.DataProxy,\n\t\tQuotaService:         ng.QuotaService,\n\t\tTransactionManager:   store,\n\t\tRuleStore:            store,\n\t\tAlertingStore:        store,\n\t\tAdminConfigStore:     store,\n\t\tProvenanceStore:      store,\n\t\tMultiOrgAlertmanager: ng.MultiOrgAlertmanager,\n\t\tStateManager:         ng.stateManager,\n\t\tAccessControl:        ng.accesscontrol,\n\t\tPolicies:             policyService,\n\t\tContactPointService:  contactPointService,\n\t\tTemplates:            templateService,\n\t\tMuteTimings:          muteTimingService,\n\t\tAlertRules:           alertRuleService,\n\t\tAlertsRouter:         alertsRouter,\n\t\tEvaluatorFactory:     evalFactory,\n\t\tFeatureManager:       ng.FeatureToggles,\n\t\tAppUrl:               appUrl,\n\t\tHistorian:            history,\n\t}\n\tapi.RegisterAPIEndpoints(ng.Metrics.GetAPIMetrics())\n\n\tdefaultLimits, err := readQuotaConfig(ng.Cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := ng.QuotaService.RegisterQuotaReporter(&quota.NewUsageReporter{\n\t\tTargetSrv:     models.QuotaTargetSrv,\n\t\tDefaultLimits: defaultLimits,\n\t\tReporter:      api.Usage,\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\tlog.RegisterContextualLogProvider(func(ctx context.Context) ([]interface{}, bool) {\n\t\tkey, ok := models.RuleKeyFromContext(ctx)\n\t\tif !ok {\n\t\t\treturn nil, false\n\t\t}\n\t\treturn key.LogContext(), true\n\t})\n\n\treturn DeclareFixedRoles(ng.accesscontrolService)\n}", "is_vulnerable": 0}
{"code": "func (f *writableMapFile) Close() error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *CustomMap) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomMap: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomMap: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Nullable128S\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Nullable128S == nil {\n\t\t\t\tm.Nullable128S = make(map[string]*github_com_gogo_protobuf_test_custom.Uint128)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Nullable128S[mapkey] = ((*github_com_gogo_protobuf_test_custom.Uint128)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Uint128S\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Uint128S == nil {\n\t\t\t\tm.Uint128S = make(map[string]github_com_gogo_protobuf_test_custom.Uint128)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Uint128S[mapkey] = ((github_com_gogo_protobuf_test_custom.Uint128)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableIds\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableIds == nil {\n\t\t\t\tm.NullableIds = make(map[string]*github_com_gogo_protobuf_test.Uuid)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test.Uuid\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableIds[mapkey] = ((*github_com_gogo_protobuf_test.Uuid)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Ids\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Ids == nil {\n\t\t\t\tm.Ids = make(map[string]github_com_gogo_protobuf_test.Uuid)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue1 github_com_gogo_protobuf_test.Uuid\n\t\t\tvar mapvalue = &mapvalue1\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapbyteLen uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowMapsproto2\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapbyteLen |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintMapbyteLen := int(mapbyteLen)\n\t\t\t\t\tif intMapbyteLen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tpostbytesIndex := iNdEx + intMapbyteLen\n\t\t\t\t\tif postbytesIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif postbytesIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postbytesIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postbytesIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Ids[mapkey] = ((github_com_gogo_protobuf_test.Uuid)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipMapsproto2(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthMapsproto2\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestPingEmail(t *testing.T) {\n\tfmt.Println(\"Testing ping email server\")\n\tassert := assert.New(t)\n\tapiTest := newHarborAPI()\n\n\t//case 1: ping email server without admin role\n\tcode, _, err := apiTest.PingEmail(*testUser, nil)\n\tif err != nil {\n\t\tt.Errorf(\"failed to test ping email server: %v\", err)\n\t\treturn\n\t}\n\n\tassert.Equal(401, code, \"the status code of ping email server with non-admin user should be 401\")\n\n\t//case 2: empty email host\n\tsettings := `{\n\t\t\"email_host\":     \"\"\n\t}`\n\n\tcode, _, err = apiTest.PingEmail(*admin, []byte(settings))\n\tif err != nil {\n\t\tt.Errorf(\"failed to test ping email server: %v\", err)\n\t\treturn\n\t}\n\n\tassert.Equal(400, code)\n\n\t//case 3: secure connection with admin role\n\tsettings = `{\n\t\t\"email_host\":     \"smtp.gmail.com\",\n\t\t\"email_port\":     465,\n\t\t\"email_identity\": \"\",\n\t\t\"email_username\": \"wrong_username\",\n\t\t\"email_ssl\":      true\n\t}`\n\n\tcode, _, err = apiTest.PingEmail(*admin, []byte(settings))\n\tif err != nil {\n\t\tt.Errorf(\"failed to test ping email server: %v\", err)\n\t\treturn\n\t}\n\n\tassert.Equal(400, code)\n\n\t//case 4: ping email server whose settings are read from config\n\tcode, _, err = apiTest.PingEmail(*admin, nil)\n\tif err != nil {\n\t\tt.Errorf(\"failed to test ping email server: %v\", err)\n\t\treturn\n\t}\n\n\tassert.Equal(400, code)\n}", "is_vulnerable": 0}
{"code": "func (client AccountsClient) CreateSender(req *http.Request) (future AccountsCreateFuture, err error) {\n\tvar resp *http.Response\n\tresp, err = autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n\tif err != nil {\n\t\treturn\n\t}\n\terr = autorest.Respond(resp, azure.WithErrorUnlessStatusCode(http.StatusOK, http.StatusAccepted))\n\tif err != nil {\n\t\treturn\n\t}\n\tfuture.Future, err = azure.NewFutureFromResponse(resp)\n\treturn\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(\"server-generated linear advance proof\", func(t *testing.T) {\n\t\t\tfor i := uint64(1); i <= txCount; i++ {\n\t\t\t\tfor j := i; j <= txCount; j++ {\n\t\t\t\t\tssm.state = ssm.stateHistory[i]\n\n\t\t\t\t\t_, err = cl.VerifiedTxByID(context.Background(), j)\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.EqualValues(t, j, ssm.state.TxId)\n\t\t\t\t}\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func (s *validateSuite) TestValidateContainerSymlinksFails(c *C) {\n\tc.Skip(\"checking symlink targets not implemented yet\")\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: foo\n`\n\td := emptyContainer(c)\n\tfn := filepath.Join(d.Path(), \"foo\")\n\tc.Assert(os.WriteFile(fn+\".real\", nil, 0444), IsNil)\n\tc.Assert(os.Symlink(fn+\".real\", fn), IsNil)\n\n\t// snapdir contains a command that's a symlink to a file that's not world-rx\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(d, info, discard)\n\tc.Check(err, Equals, snap.ErrBadModes)\n}", "is_vulnerable": 1}
{"code": "func TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tdirEntries, err := os.ReadDir(dir)\n\trequire.NoError(t, err)\n\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tt.Run(\n\t\t\tfmt.Sprintf(\"test example load: %s/%s\", dir, entry.Name()),\n\t\t\tfunc(t *testing.T) {\n\t\t\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\tvar sensor *v1alpha1.Sensor\n\t\t\t\teventBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\t\t\t\terr = yaml.Unmarshal(content, &sensor)\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\terr = ValidateSensor(sensor, eventBus)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CloseSession(ctx context.Context, in *sliverpb.CloseSession, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CloseSession_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(fmt.Sprintf(\"%s %s\", desc, url), func(t *testing.T) {\n\t\tdefer bus.ClearBusHandlers()\n\n\t\tsc := setupScenarioContext(t, url)\n\t\tsc.defaultHandler = routing.Wrap(func(c *models.ReqContext) response.Response {\n\t\t\tc.Req.Body = mockRequestBody(cmd)\n\t\t\tc.Req.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tsc.context = c\n\t\t\tsc.context.UserId = testUserID\n\t\t\tsc.context.OrgId = testOrgID\n\t\t\tsc.context.OrgRole = role\n\n\t\t\treturn hs.PauseAlert(c)\n\t\t})\n\n\t\tsc.m.Post(routePattern, sc.defaultHandler)\n\n\t\tfn(sc)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (us *UserService) UserVerifyEmailSend(ctx context.Context, userID string) error {\n\tuserInfo, has, err := us.userRepo.GetByUserID(ctx, userID)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !has {\n\t\treturn errors.BadRequest(reason.UserNotFound)\n\t}\n\n\tdata := &schema.EmailCodeContent{\n\t\tEmail:  userInfo.EMail,\n\t\tUserID: userInfo.ID,\n\t}\n\tcode := uuid.NewString()\n\tverifyEmailURL := fmt.Sprintf(\"%s/users/account-activation?code=%s\", us.getSiteUrl(ctx), code)\n\ttitle, body, err := us.emailService.RegisterTemplate(ctx, verifyEmailURL)\n\tif err != nil {\n\t\treturn err\n\t}\n\tgo us.emailService.SendAndSaveCode(ctx, userInfo.ID, userInfo.EMail, title, body, code, data.ToJSONString())\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func InDeltaMapValues(t TestingT, expected interface{}, actual interface{}, delta float64, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.InDeltaMapValues(t, expected, actual, delta, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "\tTimeNow = func() time.Time {\n\t\trv, _ := time.Parse(\"Mon Jan 2 15:04:05 MST 2006\", \"Mon Dec 1 01:57:09 UTC 2015\")\n\t\treturn rv\n\t}\n\tClock = dsig.NewFakeClockAt(TimeNow())\n\n\ts.IDPMetadata.EntityID = \"http://snakeoil.com\"\n\treq.PostForm.Set(\"SAMLResponse\", base64.StdEncoding.EncodeToString(test.SamlResponse))\n\t_, err = s.ParseResponse(&req, []string{\"id-9e61753d64e928af5a7a341a97f420c9\"})\n\tassert.Check(t, is.Error(err.(*InvalidResponseError).PrivateErr,\n\t\t\"response Issuer does not match the IDP metadata (expected \\\"http://snakeoil.com\\\")\"))\n\ts.IDPMetadata.EntityID = \"https://idp.testshib.org/idp/shibboleth\"\n\n\toldSpStatusSuccess := StatusSuccess\n\tStatusSuccess = \"not:the:success:value\"\n\treq.PostForm.Set(\"SAMLResponse\", base64.StdEncoding.EncodeToString(test.SamlResponse))\n\t_, err = s.ParseResponse(&req, []string{\"id-9e61753d64e928af5a7a341a97f420c9\"})\n\tassert.Check(t, is.Error(err.(*InvalidResponseError).PrivateErr,\n\t\t\"urn:oasis:names:tc:SAML:2.0:status:Success\"))\n\tStatusSuccess = oldSpStatusSuccess\n\n\ts.IDPMetadata.IDPSSODescriptors[0].KeyDescriptors[0].KeyInfo.X509Data.X509Certificates[0].Data = \"invalid\"\n\treq.PostForm.Set(\"SAMLResponse\", base64.StdEncoding.EncodeToString(test.SamlResponse))\n\t_, err = s.ParseResponse(&req, []string{\"id-9e61753d64e928af5a7a341a97f420c9\"})\n\tassert.Check(t, is.Error(err.(*InvalidResponseError).PrivateErr,\n\t\t\"cannot validate signature on Response: cannot parse certificate: illegal base64 data at input byte 4\"))\n\n\ts.IDPMetadata.IDPSSODescriptors[0].KeyDescriptors[0].KeyInfo.X509Data.X509Certificates[0].Data = \"aW52YWxpZA==\"\n\treq.PostForm.Set(\"SAMLResponse\", base64.StdEncoding.EncodeToString(test.SamlResponse))\n\t_, err = s.ParseResponse(&req, []string{\"id-9e61753d64e928af5a7a341a97f420c9\"})\n\n\tassert.Check(t, is.Error(err.(*InvalidResponseError).PrivateErr,\n\t\t\"cannot validate signature on Response: x509: malformed certificate\"))\n}", "is_vulnerable": 1}
{"code": "func EpollCreate(size int) (fd int, err error) {\n\tif size <= 0 {\n\t\treturn -1, EINVAL\n\t}\n\treturn EpollCreate1(0)\n}", "is_vulnerable": 1}
{"code": "func (autoApi *AutoCodeApi) GetDB(c *gin.Context) {\n\tbusinessDB := c.Query(\"businessDB\")\n\tdbs, err := autoCodeService.Database(businessDB).GetDB(businessDB)\n\tvar dbList []map[string]interface{}\n\tfor _, db := range global.GVA_CONFIG.DBList {\n\t\tvar item = make(map[string]interface{})\n\t\titem[\"aliasName\"] = db.AliasName\n\t\titem[\"dbName\"] = db.Dbname\n\t\titem[\"disable\"] = db.Disable\n\t\titem[\"dbtype\"] = db.Type\n\t\tdbList = append(dbList, item)\n\t}\n\tif err != nil {\n\t\tglobal.GVA_LOG.Error(\"\u83b7\u53d6\u5931\u8d25!\", zap.Error(err))\n\t\tresponse.FailWithMessage(\"\u83b7\u53d6\u5931\u8d25\", c)\n\t} else {\n\t\tresponse.OkWithDetailed(gin.H{\"dbs\": dbs, \"dbList\": dbList}, \"\u83b7\u53d6\u6210\u529f\", c)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *Server) Create(ctx context.Context, q *session.SessionCreateRequest) (*session.SessionResponse, error) {\n\tif q.Token != \"\" {\n\t\treturn nil, status.Errorf(codes.Unauthenticated, \"token-based session creation no longer supported. please upgrade argocd cli to v0.7+\")\n\t}\n\tif q.Username == \"\" || q.Password == \"\" {\n\t\treturn nil, status.Errorf(codes.Unauthenticated, \"no credentials supplied\")\n\t}\n\terr := s.mgr.VerifyUsernamePassword(q.Username, q.Password)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tjwtToken, err := s.mgr.Create(q.Username, 0, \"\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &session.SessionResponse{Token: jwtToken}, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Leaf) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Leaf: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Leaf: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tm.Value = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Value |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field StrValue\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.StrValue = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (p *Profile) write() (pth string, err error) {\n\trootDir, err := utils.GetTempDir()\n\tif err != nil {\n\t\treturn\n\t}\n\n\tpth = filepath.Join(rootDir, p.Id)\n\n\tdata := \"\"\n\tfor _, line := range strings.Split(p.Data, \"\\n\") {\n\t\ttrimLine := strings.TrimSpace(line)\n\t\ttrimLine = strings.Trim(trimLine, \"#\")\n\t\ttrimLine = strings.Trim(trimLine, \"-\")\n\t\ttrimLine = strings.Trim(trimLine, \"_\")\n\t\ttrimLine = strings.Trim(trimLine, \":\")\n\t\ttrimLine = strings.Trim(trimLine, \";\")\n\t\ttrimLine = strings.Trim(trimLine, \"*\")\n\t\ttrimLine = strings.Trim(trimLine, \"%\")\n\t\ttrimLine = strings.Trim(trimLine, \"$\")\n\t\ttrimLine = strings.Trim(trimLine, \"+\")\n\t\ttrimLine = strings.Trim(trimLine, \"=\")\n\t\ttrimLine = strings.Trim(trimLine, \"~\")\n\t\ttrimLine = strings.Trim(trimLine, \"(\")\n\t\ttrimLine = strings.Trim(trimLine, \")\")\n\t\ttrimLine = strings.Trim(trimLine, \"[\")\n\t\ttrimLine = strings.Trim(trimLine, \"]\")\n\t\ttrimLine = strings.Trim(trimLine, \"{\")\n\t\ttrimLine = strings.Trim(trimLine, \"}\")\n\n\t\tif strings.Contains(trimLine, \"script-security\") ||\n\t\t\tstrings.HasPrefix(trimLine, \"log \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"log-append \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"syslog \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"management \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"plugin \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"up \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"down \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"route-pre-down \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"tls-verify \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"ipchange \") ||\n\t\t\tstrings.HasPrefix(trimLine, \"route-up \") {\n\n\t\t\tcontinue\n\t\t}\n\t\tdata += line + \"\\n\"\n\t}\n\n\t_ = os.Remove(pth)\n\terr = ioutil.WriteFile(pth, []byte(data), os.FileMode(0600))\n\tif err != nil {\n\t\terr = &WriteError{\n\t\t\terrors.Wrap(err, \"profile: Failed to write profile\"),\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func TestSimTPM20QuoteAndVerifyAll(t *testing.T) {\n\tsim, tpm := setupSimulatedTPM(t)\n\tdefer sim.Close()\n\n\tak, err := tpm.NewAK(nil)\n\tif err != nil {\n\t\tt.Fatalf(\"NewAK() failed: %v\", err)\n\t}\n\tdefer ak.Close(tpm)\n\n\tnonce := []byte{1, 2, 3, 4, 5, 6, 7, 8}\n\tquote256, err := ak.Quote(tpm, nonce, HashSHA256)\n\tif err != nil {\n\t\tt.Fatalf(\"ak.Quote(SHA256) failed: %v\", err)\n\t}\n\tquote1, err := ak.Quote(tpm, nonce, HashSHA1)\n\tif err != nil {\n\t\tt.Fatalf(\"ak.Quote(SHA1) failed: %v\", err)\n\t}\n\n\t// Providing both PCR banks to AKPublic.Verify() ensures we can handle\n\t// the case where extra PCRs of a different digest algorithm are provided.\n\tvar pcrs []PCR\n\tfor _, alg := range []HashAlg{HashSHA256, HashSHA1} {\n\t\tp, err := tpm.PCRs(alg)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"tpm.PCRs(%v) failed: %v\", alg, err)\n\t\t}\n\t\tpcrs = append(pcrs, p...)\n\t}\n\n\tpub, err := ParseAKPublic(tpm.Version(), ak.AttestationParameters().Public)\n\tif err != nil {\n\t\tt.Fatalf(\"ParseAKPublic() failed: %v\", err)\n\t}\n\n\t// Ensure VerifyAll fails if a quote is missing and hence not all PCR\n\t// banks are covered.\n\tif err := pub.VerifyAll([]Quote{*quote256}, pcrs, nonce); err == nil {\n\t\tt.Error(\"VerifyAll().err returned nil, expected failure\")\n\t}\n\n\tif err := pub.VerifyAll([]Quote{*quote256, *quote1}, pcrs, nonce); err != nil {\n\t\tt.Errorf(\"quote verification failed: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (svc *Service) User(ctx context.Context, id uint) (*fleet.User, error) {\n\tuser, err := svc.ds.UserByID(ctx, id)\n\tif err != nil {\n\t\tsetAuthCheckedOnPreAuthErr(ctx)\n\t\treturn nil, ctxerr.Wrap(ctx, err)\n\t}\n\n\tif err := svc.authz.Authorize(ctx, user, fleet.ActionRead); err != nil {\n\t\treturn nil, err\n\t}\n\treturn user, nil\n}", "is_vulnerable": 0}
{"code": "func (mp *MalfeasanceProof) MarshalLogObject(encoder log.ObjectEncoder) error {\n\tencoder.AddUint32(\"generated_layer\", mp.Layer.Uint32())\n\tswitch mp.Proof.Type {\n\tcase MultipleATXs:\n\t\tencoder.AddString(\"type\", \"multiple atxs\")\n\t\tp, ok := mp.Proof.Data.(*AtxProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase MultipleBallots:\n\t\tencoder.AddString(\"type\", \"multiple ballots\")\n\t\tp, ok := mp.Proof.Data.(*BallotProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase HareEquivocation:\n\t\tencoder.AddString(\"type\", \"hare equivocation\")\n\t\tp, ok := mp.Proof.Data.(*HareProof)\n\t\tif !ok {\n\t\t\tencoder.AddString(\"msgs\", \"n/a\")\n\t\t} else {\n\t\t\tencoder.AddObject(\"msgs\", p)\n\t\t}\n\tcase InvalidPostIndex:\n\t\tencoder.AddString(\"type\", \"invalid post index\")\n\t\tp, ok := mp.Proof.Data.(*InvalidPostIndexProof)\n\t\tif ok {\n\t\t\tatx := wire.ActivationTxFromWireV1(&p.Atx)\n\t\t\tencoder.AddString(\"atx_id\", atx.ID().String())\n\t\t\tencoder.AddString(\"smesher\", p.Atx.SmesherID.String())\n\t\t\tencoder.AddUint32(\"invalid index\", p.InvalidIdx)\n\t\t}\n\tdefault:\n\t\tencoder.AddString(\"type\", \"unknown\")\n\t}\n\tencoder.AddTime(\"received\", mp.received)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func Test_buildMetricsHTTPConnectionManagerFilter(t *testing.T) {\n\tcacheDir, _ := os.UserCacheDir()\n\tcertFileName := filepath.Join(cacheDir, \"pomerium\", \"envoy\", \"files\", \"tls-crt-354e49305a5a39414a545530374e58454e48334148524c4e324258463837364355564c4e4532464b54355139495547514a38.pem\")\n\tkeyFileName := filepath.Join(cacheDir, \"pomerium\", \"envoy\", \"files\", \"tls-key-3350415a38414e4e4a4655424e55393430474147324651433949384e485341334b5157364f424b4c5856365a545937383735.pem\")\n\n\tb := New(\"local-grpc\", \"local-http\", filemgr.NewManager(), nil)\n\tli, err := b.buildMetricsListener(&config.Config{\n\t\tOptions: &config.Options{\n\t\t\tMetricsAddr:           \"127.0.0.1:9902\",\n\t\t\tMetricsCertificate:    aExampleComCert,\n\t\t\tMetricsCertificateKey: aExampleComKey,\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\ttestutil.AssertProtoJSONEqual(t, `\n{\n\t\"name\": \"metrics-ingress-1566242852377945326\",\n\t\"perConnectionBufferLimitBytes\": 32768,\n\t\"address\": {\n\t\t\"socketAddress\": {\n\t\t\t\"address\": \"127.0.0.1\",\n\t\t\t\"ipv4Compat\": true,\n\t\t\t\"portValue\": 9902\n\t\t}\n\t},\n\t\"filterChains\": [{\n\t\t\"filters\": [{\n\t\t\t\"name\": \"envoy.filters.network.http_connection_manager\",\n\t\t\t\"typedConfig\": {\n\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\",\n\t\t\t\t\"httpFilters\": [{\n\t\t\t\t\t\"name\": \"envoy.filters.http.router\"\n\t\t\t\t}],\n\t\t\t\t\"routeConfig\": {\n\t\t\t\t\t\"name\": \"metrics\",\n\t\t\t\t\t\"validateClusters\": false,\n\t\t\t\t\t\"virtualHosts\": [{\n\t\t\t\t\t\t\"name\": \"metrics\",\n\t\t\t\t\t\t\"domains\": [\"*\"],\n\t\t\t\t\t\t\"routes\": [{\n\t\t\t\t\t\t\t\"name\": \"metrics\",\n\t\t\t\t\t\t\t\"match\": {\n\t\t\t\t\t\t\t\t\"prefix\": \"/\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"route\": {\n\t\t\t\t\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}]\n\t\t\t\t\t}]\n\t\t\t\t},\n\t\t\t\t\"statPrefix\": \"metrics\"\n\t\t\t}\n\t\t}],\n\t\t\"transportSocket\": {\n\t\t\t\"name\": \"tls\",\n\t\t\t\"typedConfig\": {\n\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext\",\n\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\"cipherSuites\": [\n\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\"ECDHE-RSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\"ECDHE-RSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n\t\t\t\t\t\t\t\"ECDHE-RSA-CHACHA20-POLY1305\"\n\t\t\t\t\t\t],\n\t\t\t\t\t\t\"tlsMinimumProtocolVersion\": \"TLSv1_2\"\n\t\t\t\t\t},\n\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\"tlsCertificates\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"certificateChain\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+certFileName+`\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"privateKey\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+keyFileName+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}]\n}`, li)\n}", "is_vulnerable": 1}
{"code": "func (f *fragmentBuffer) size() int {\n\tsize := 0\n\tfor i := range f.cache {\n\t\tfor j := range f.cache[i] {\n\t\t\tsize += len(f.cache[i][j].data)\n\t\t}\n\t}\n\treturn size\n}", "is_vulnerable": 0}
{"code": "func (o *Options) WithDisableIdentityCheck(disableIdentityCheck bool) *Options {\n\to.DisableIdentityCheck = disableIdentityCheck\n\treturn o\n}", "is_vulnerable": 0}
{"code": "func queryMatches(rp *arrayPathResult, value Result) bool {\n\trpv := rp.query.value\n\tif len(rpv) > 0 && rpv[0] == '~' {\n\t\t// convert to bool\n\t\trpv = rpv[1:]\n\t\tif value.Bool() {\n\t\t\tvalue = Result{Type: True}\n\t\t} else {\n\t\t\tvalue = Result{Type: False}\n\t\t}\n\t}\n\tif !value.Exists() {\n\t\treturn false\n\t}\n\tif rp.query.op == \"\" {\n\t\t// the query is only looking for existence, such as:\n\t\t//   friends.#(name)\n\t\t// which makes sure that the array \"friends\" has an element of\n\t\t// \"name\" that exists\n\t\treturn true\n\t}\n\tswitch value.Type {\n\tcase String:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn value.Str == rpv\n\t\tcase \"!=\":\n\t\t\treturn value.Str != rpv\n\t\tcase \"<\":\n\t\t\treturn value.Str < rpv\n\t\tcase \"<=\":\n\t\t\treturn value.Str <= rpv\n\t\tcase \">\":\n\t\t\treturn value.Str > rpv\n\t\tcase \">=\":\n\t\t\treturn value.Str >= rpv\n\t\tcase \"%\":\n\t\t\treturn matchLimit(value.Str, rpv)\n\t\tcase \"!%\":\n\t\t\treturn !matchLimit(value.Str, rpv)\n\t\t}\n\tcase Number:\n\t\trpvn, _ := strconv.ParseFloat(rpv, 64)\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn value.Num == rpvn\n\t\tcase \"!=\":\n\t\t\treturn value.Num != rpvn\n\t\tcase \"<\":\n\t\t\treturn value.Num < rpvn\n\t\tcase \"<=\":\n\t\t\treturn value.Num <= rpvn\n\t\tcase \">\":\n\t\t\treturn value.Num > rpvn\n\t\tcase \">=\":\n\t\t\treturn value.Num >= rpvn\n\t\t}\n\tcase True:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn rpv == \"true\"\n\t\tcase \"!=\":\n\t\t\treturn rpv != \"true\"\n\t\tcase \">\":\n\t\t\treturn rpv == \"false\"\n\t\tcase \">=\":\n\t\t\treturn true\n\t\t}\n\tcase False:\n\t\tswitch rp.query.op {\n\t\tcase \"=\":\n\t\t\treturn rpv == \"false\"\n\t\tcase \"!=\":\n\t\t\treturn rpv != \"false\"\n\t\tcase \"<\":\n\t\t\treturn rpv == \"true\"\n\t\tcase \"<=\":\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (c *mockConn) Close() error {\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func RemoveSignatureFromData(data []byte) []byte {\n\treturn bytes.Trim(ReDigest.ReplaceAll(data, []byte(\"\")), \"\\n\")\n}", "is_vulnerable": 1}
{"code": "func generateECDSATokenWithMalformedIss(t *testing.T, serviceAccount *v1.ServiceAccount, ecdsaSecret *v1.Secret) string {\n\tt.Helper()\n\n\tecdsaToken := generateECDSAToken(t, \"panda\", serviceAccount, ecdsaSecret)\n\n\tecdsaTokenJWS, err := jose.ParseSigned(ecdsaToken)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdataFullSerialize := map[string]any{}\n\tif err := json.Unmarshal([]byte(ecdsaTokenJWS.FullSerialize()), &dataFullSerialize); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdataFullSerialize[\"malformed_iss\"] = \".\" + base64.RawURLEncoding.EncodeToString([]byte(`{\"iss\":\"bar\"}`)) + \".\"\n\n\tout, err := json.Marshal(dataFullSerialize)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\treturn string(out)\n}", "is_vulnerable": 0}
{"code": "func Clean(p string) string {\n\treturn strings.Trim(path.Clean(\"/\"+p), \"/\")\n}", "is_vulnerable": 0}
{"code": "func (sc *scenarioContext) fakeReqNoAssertionsWithCookie(method, url string, cookie http.Cookie) *scenarioContext {\n\tsc.resp = httptest.NewRecorder()\n\thttp.SetCookie(sc.resp, &cookie)\n\n\treq, _ := http.NewRequest(method, url, nil)\n\treq.Header = http.Header{\"Cookie\": sc.resp.Header()[\"Set-Cookie\"]}\n\n\tsc.req = req\n\n\treturn sc\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn ipallowlist{\n\t\tr:                r,\n\t\tannotationConfig: allowlistAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m multiTenantOAuthConfig) PrimaryTenant() *OAuthConfig {\n\treturn m.cfgs[0]\n}", "is_vulnerable": 0}
{"code": "func BenchmarkListObjectsWithReverseExpand(b *testing.B, ds storage.OpenFGADatastore) {\n\n\tctx := context.Background()\n\tstore := ulid.Make().String()\n\n\tmodel := &openfgapb.AuthorizationModel{\n\t\tId:            ulid.Make().String(),\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"document\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t},\n\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\ttypesystem.DirectRelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\terr := ds.WriteAuthorizationModel(ctx, store, model)\n\trequire.NoError(b, err)\n\n\tn := 0\n\tfor i := 0; i < 100; i++ {\n\t\tvar tuples []*openfgapb.TupleKey\n\n\t\tfor j := 0; j < ds.MaxTuplesPerWrite(); j++ {\n\t\t\tobj := fmt.Sprintf(\"document:%s\", strconv.Itoa(n))\n\t\t\tuser := fmt.Sprintf(\"user:%s\", strconv.Itoa(n))\n\n\t\t\ttuples = append(tuples, tuple.NewTupleKey(obj, \"viewer\", user))\n\n\t\t\tn += 1\n\t\t}\n\n\t\terr = ds.Write(ctx, store, nil, tuples)\n\t\trequire.NoError(b, err)\n\t}\n\n\tlistObjectsQuery := commands.ListObjectsQuery{\n\t\tDatastore:        ds,\n\t\tLogger:           logger.NewNoopLogger(),\n\t\tResolveNodeLimit: defaultResolveNodeLimit,\n\t}\n\n\tvar r *openfgapb.ListObjectsResponse\n\n\tctx = typesystem.ContextWithTypesystem(ctx, typesystem.New(model))\n\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\tr, _ = listObjectsQuery.Execute(ctx, &openfgapb.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: model.Id,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:999\",\n\t\t})\n\t}\n\n\tlistObjectsResponse = r\n}", "is_vulnerable": 1}
{"code": "func TestAPI_AgentServices(t *testing.T) {\n\tt.Parallel()\n\tc, s := makeClient(t)\n\tdefer s.Stop()\n\n\tagent := c.Agent()\n\n\treg := &AgentServiceRegistration{\n\t\tName: \"foo\",\n\t\tID:   \"foo\",\n\t\tTags: []string{\"bar\", \"baz\"},\n\t\tPort: 8000,\n\t\tCheck: &AgentServiceCheck{\n\t\t\tTTL: \"15s\",\n\t\t},\n\t}\n\tif err := agent.ServiceRegister(reg); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\tservices, err := agent.Services()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif _, ok := services[\"foo\"]; !ok {\n\t\tt.Fatalf(\"missing service: %#v\", services)\n\t}\n\tchecks, err := agent.Checks()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tchk, ok := checks[\"service:foo\"]\n\tif !ok {\n\t\tt.Fatalf(\"missing check: %v\", checks)\n\t}\n\n\t// Checks should default to critical\n\tif chk.Status != HealthCritical {\n\t\tt.Fatalf(\"Bad: %#v\", chk)\n\t}\n\n\tstate, out, err := agent.AgentHealthServiceByID(\"foo2\")\n\trequire.Nil(t, err)\n\trequire.Nil(t, out)\n\trequire.Equal(t, HealthCritical, state)\n\n\tstate, out, err = agent.AgentHealthServiceByID(\"foo\")\n\trequire.Nil(t, err)\n\trequire.NotNil(t, out)\n\trequire.Equal(t, HealthCritical, state)\n\trequire.Equal(t, 8000, out.Service.Port)\n\n\tstate, outs, err := agent.AgentHealthServiceByName(\"foo\")\n\trequire.Nil(t, err)\n\trequire.NotNil(t, outs)\n\trequire.Equal(t, HealthCritical, state)\n\trequire.Equal(t, 8000, out.Service.Port)\n\n\tif err := agent.ServiceDeregister(\"foo\"); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (o *LoginOperatorCreated) WriteResponse(rw http.ResponseWriter, producer runtime.Producer) {\n\n\trw.WriteHeader(201)\n\tif o.Payload != nil {\n\t\tpayload := o.Payload\n\t\tif err := producer.Produce(rw, payload); err != nil {\n\t\t\tpanic(err) // let the recovery middleware deal with this\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *nodeStack) contains(a atom.Atom) bool {\n\tfor _, n := range *s {\n\t\tif n.DataAtom == a && n.Namespace == \"\" {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (p *provider) ApplyComponent(ctx wfContext.Context, v *value.Value, act wfTypes.Action) error {\n\treturn p.applyComponent(ctx, v, act, nil)\n}", "is_vulnerable": 1}
{"code": "func (fs *fileStat) ModTime() time.Time { return fs.modTime }", "is_vulnerable": 0}
{"code": "func TestConfigurator_CommonTLSConfigTLSMinVersion(t *testing.T) {\n\tc, err := NewConfigurator(Config{TLSMinVersion: \"\"}, nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, c.commonTLSConfig(false).MinVersion, TLSLookup[\"tls10\"])\n\n\ttlsVersions := []string{\"tls10\", \"tls11\", \"tls12\"}\n\tfor _, version := range tlsVersions {\n\t\trequire.NoError(t, c.Update(Config{TLSMinVersion: version}))\n\t\trequire.Equal(t, c.commonTLSConfig(false).MinVersion,\n\t\t\tTLSLookup[version])\n\t}\n\n\trequire.Error(t, c.Update(Config{TLSMinVersion: \"tlsBOGUS\"}))\n}", "is_vulnerable": 0}
{"code": "func (d *DNSFilter) handleFilteringSetRules(w http.ResponseWriter, r *http.Request) {\n\tif aghhttp.WriteTextPlainDeprecated(w, r) {\n\t\treturn\n\t}\n\n\treq := &filteringRulesReq{}\n\terr := json.NewDecoder(r.Body).Decode(req)\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusBadRequest, \"reading req: %s\", err)\n\n\t\treturn\n\t}\n\n\td.UserRules = req.Rules\n\td.ConfigModified()\n\td.EnableFilters(true)\n}", "is_vulnerable": 0}
{"code": "func (crs *checkingResourceStream) queue(result *v1.DispatchReachableResourcesResponse) bool {\n\tcurrentResource := possibleResource{\n\t\treachableResult: result,\n\t\tlookupResult:    nil,\n\t\torderingIndex:   crs.reachableResourcesCount,\n\t}\n\n\t// If the resource found already has permission (i.e. a check is not required), simply set\n\t// the lookup result on the resource now.\n\tif result.Resource.ResultStatus == v1.ReachableResource_HAS_PERMISSION {\n\t\tcurrentResource.lookupResult = &v1.DispatchLookupResourcesResponse{\n\t\t\tResolvedResource: &v1.ResolvedResource{\n\t\t\t\tResourceId:     result.Resource.ResourceId,\n\t\t\t\tPermissionship: v1.ResolvedResource_HAS_PERMISSION,\n\t\t\t},\n\t\t\tMetadata:            addCallToResponseMetadata(result.Metadata),\n\t\t\tAfterResponseCursor: result.AfterResponseCursor,\n\t\t}\n\t}\n\n\tcrs.rq.addPossibleResource(currentResource)\n\tcrs.reachableResourcesCount++\n\tcrs.lastResourceCursor = result.AfterResponseCursor\n\n\t// If the resource found already has permission (i.e. a check is not required), immediately\n\t// publish it, rather than going through a processing worker. This saves a step for better\n\t// performance.\n\tif result.Resource.ResultStatus == v1.ReachableResource_HAS_PERMISSION {\n\t\tselect {\n\t\tcase crs.availableForPublishing <- true:\n\t\t\treturn true\n\n\t\tcase <-crs.reachableContext.Done():\n\t\t\treturn false\n\n\t\tcase <-crs.ctx.Done():\n\t\t\tcrs.setError(crs.ctx.Err())\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tselect {\n\t\tcase crs.reachableResourceAvailable <- struct{}{}:\n\t\t\treturn true\n\n\t\tcase <-crs.reachableContext.Done():\n\t\t\treturn false\n\n\t\tcase <-crs.ctx.Done():\n\t\t\tcrs.setError(crs.ctx.Err())\n\t\t\treturn false\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestInvalidCSV(t *testing.T) {\n\ttestCases := []struct {\n\t\tinput string\n\t\terr   string\n\t}{\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = ''\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` must not be empty\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = 'hello'\n\t\t\t\tdelimiter = 'hel'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = 'hel'\n\t\t\t\tdelimiter = 'hello'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\'\n\t\t\t\tbackslash-escape = false\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\uff0c'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = ''\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = 'hello'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = '\\'\n\t\t\t\tbackslash-escape = false\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\s'\n\t\t\t\tdelimiter = '\\d'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '|'\n\t\t\t\tdelimiter = '|'\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.csv.separator` and `mydumper.csv.delimiter` must not be prefix of each other\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tseparator = '\\'\n\t\t\t\tbackslash-escape = true\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]cannot use '\\\\' as CSV separator when `mydumper.csv.backslash-escape` is true\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper.csv]\n\t\t\t\tdelimiter = '\\'\n\t\t\t\tbackslash-escape = true\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]cannot use '\\\\' as CSV delimiter when `mydumper.csv.backslash-escape` is true\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[tidb]\n\t\t\t\tsql-mode = \"invalid-sql-mode\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]`mydumper.tidb.sql_mode` must be a valid SQL_MODE: ERROR 1231 (42000): Variable 'sql_mode' can't be set to the value of 'invalid-sql-mode'\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[[routes]]\n\t\t\t\tschema-pattern = \"\"\n\t\t\t\ttable-pattern = \"shard_table_*\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]file route rule is invalid: schema pattern of table route rule should not be empty\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[[routes]]\n\t\t\t\tschema-pattern = \"schema_*\"\n\t\t\t\ttable-pattern = \"\"\n\t\t\t`,\n\t\t\terr: \"[Lightning:Config:ErrInvalidConfig]file route rule is invalid: target schema of table route rule should not be empty\",\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tcomment := fmt.Sprintf(\"input = %s\", tc.input)\n\t\tcfg := config.NewConfig()\n\t\tcfg.Mydumper.SourceDir = \"file://.\"\n\t\tcfg.TiDB.Port = 4000\n\t\tcfg.TiDB.PdAddr = \"test.invalid:2379\"\n\t\tcfg.TikvImporter.Backend = config.BackendLocal\n\t\tcfg.TikvImporter.SortedKVDir = \".\"\n\t\tcfg.TiDB.DistSQLScanConcurrency = 1\n\t\terr := cfg.LoadFromTOML([]byte(tc.input))\n\t\trequire.NoError(t, err)\n\n\t\terr = cfg.Adjust(context.Background())\n\t\tif tc.err != \"\" {\n\t\t\trequire.EqualError(t, err, tc.err, comment)\n\t\t} else {\n\t\t\trequire.NoError(t, err)\n\t\t}\n\t}\n}\n\nfunc TestInvalidTOML(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\tinvalid[mydumper.csv]\n\t\tdelimiter = '\\'\n\t\tbackslash-escape = true\n\t`))\n\trequire.EqualError(t, err, \"toml: line 2: expected '.' or '=', but got '[' instead\")\n}\n\nfunc TestTOMLUnusedKeys(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\t[lightning]\n\t\ttypo = 123\n\t`))\n\trequire.EqualError(t, err, \"config file contained unknown configuration options: lightning.typo\")\n}\n\nfunc TestDurationUnmarshal(t *testing.T) {\n\tduration := config.Duration{}\n\terr := duration.UnmarshalText([]byte(\"13m20s\"))\n\trequire.NoError(t, err)\n\trequire.Equal(t, 13*60+20.0, duration.Duration.Seconds())\n\terr = duration.UnmarshalText([]byte(\"13x20s\"))\n\trequire.Error(t, err)\n\trequire.Regexp(t, \"time: unknown unit .?x.? in duration .?13x20s.?\", err.Error())\n}\n\nfunc TestDurationMarshalJSON(t *testing.T) {\n\tduration := config.Duration{}\n\terr := duration.UnmarshalText([]byte(\"13m20s\"))\n\trequire.NoError(t, err)\n\trequire.Equal(t, 13*60+20.0, duration.Duration.Seconds())\n\tresult, err := duration.MarshalJSON()\n\trequire.NoError(t, err)\n\trequire.Equal(t, `\"13m20s\"`, string(result))\n}\n\nfunc TestDuplicateResolutionAlgorithm(t *testing.T) {\n\tvar dra config.DuplicateResolutionAlgorithm\n\trequire.NoError(t, dra.FromStringValue(\"record\"))\n\trequire.Equal(t, config.DupeResAlgRecord, dra)\n\trequire.NoError(t, dra.FromStringValue(\"none\"))\n\trequire.Equal(t, config.DupeResAlgNone, dra)\n\trequire.NoError(t, dra.FromStringValue(\"remove\"))\n\trequire.Equal(t, config.DupeResAlgRemove, dra)\n\n\trequire.Equal(t, \"record\", config.DupeResAlgRecord.String())\n\trequire.Equal(t, \"none\", config.DupeResAlgNone.String())\n\trequire.Equal(t, \"remove\", config.DupeResAlgRemove.String())\n}\n\nfunc TestLoadConfig(t *testing.T) {\n\tcfg, err := config.LoadGlobalConfig([]string{\"-tidb-port\", \"sss\"}, nil)\n\trequire.EqualError(t, err, `[Lightning:Common:ErrInvalidArgument]invalid argument: invalid value \"sss\" for flag -tidb-port: parse error`)\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"-V\"}, nil)\n\trequire.Equal(t, flag.ErrHelp, err)\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"-config\", \"not-exists\"}, nil)\n\trequire.Error(t, err)\n\trequire.Regexp(t, \".*(no such file or directory|The system cannot find the file specified).*\", err.Error())\n\trequire.Nil(t, cfg)\n\n\tcfg, err = config.LoadGlobalConfig([]string{\"--server-mode\"}, nil)\n\trequire.EqualError(t, err, \"[Lightning:Config:ErrInvalidConfig]If server-mode is enabled, the status-addr must be a valid listen address\")\n\trequire.Nil(t, cfg)\n\n\tpath, _ := filepath.Abs(\".\")\n\tcfg, err = config.LoadGlobalConfig([]string{\n\t\t\"-L\", \"debug\",\n\t\t\"-log-file\", \"/path/to/file.log\",\n\t\t\"-tidb-host\", \"172.16.30.11\",\n\t\t\"-tidb-port\", \"4001\",\n\t\t\"-tidb-user\", \"guest\",\n\t\t\"-tidb-password\", \"12345\",\n\t\t\"-pd-urls\", \"172.16.30.11:2379,172.16.30.12:2379\",\n\t\t\"-d\", path,\n\t\t\"-backend\", config.BackendLocal,\n\t\t\"-sorted-kv-dir\", \".\",\n\t\t\"-checksum=false\",\n\t}, nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"debug\", cfg.App.Config.Level)\n\trequire.Equal(t, \"/path/to/file.log\", cfg.App.Config.File)\n\trequire.Equal(t, \"172.16.30.11\", cfg.TiDB.Host)\n\trequire.Equal(t, 4001, cfg.TiDB.Port)\n\trequire.Equal(t, \"guest\", cfg.TiDB.User)\n\trequire.Equal(t, \"12345\", cfg.TiDB.Psw)\n\trequire.Equal(t, \"172.16.30.11:2379,172.16.30.12:2379\", cfg.TiDB.PdAddr)\n\trequire.Equal(t, path, cfg.Mydumper.SourceDir)\n\trequire.Equal(t, config.BackendLocal, cfg.TikvImporter.Backend)\n\trequire.Equal(t, \".\", cfg.TikvImporter.SortedKVDir)\n\trequire.Equal(t, config.OpLevelOff, cfg.PostRestore.Checksum)\n\trequire.Equal(t, config.OpLevelOptional, cfg.PostRestore.Analyze)\n\n\ttaskCfg := config.NewConfig()\n\terr = taskCfg.LoadFromGlobal(cfg)\n\trequire.NoError(t, err)\n\trequire.Equal(t, config.OpLevelOff, taskCfg.PostRestore.Checksum)\n\trequire.Equal(t, config.OpLevelOptional, taskCfg.PostRestore.Analyze)\n\n\ttaskCfg.Checkpoint.DSN = \"\"\n\ttaskCfg.Checkpoint.Driver = config.CheckpointDriverMySQL\n\ttaskCfg.TiDB.DistSQLScanConcurrency = 1\n\terr = taskCfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"guest:12345@tcp(172.16.30.11:4001)/?charset=utf8mb4&sql_mode='\"+mysql.DefaultSQLMode+\"'&maxAllowedPacket=67108864&tls=false\", taskCfg.Checkpoint.DSN)\n\n\tresult := taskCfg.String()\n\trequire.Regexp(t, `.*\"pd-addr\":\"172.16.30.11:2379,172.16.30.12:2379\".*`, result)\n\n\tcfg, err = config.LoadGlobalConfig([]string{}, nil)\n\trequire.NoError(t, err)\n\trequire.Regexp(t, \".*lightning.log.*\", cfg.App.Config.File)\n\tcfg, err = config.LoadGlobalConfig([]string{\"--log-file\", \"-\"}, nil)\n\trequire.NoError(t, err)\n\trequire.Equal(t, \"-\", cfg.App.Config.File)\n}\n\nfunc TestDefaultImporterBackendValue(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"local\"\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 2, cfg.App.IndexConcurrency)\n\trequire.Equal(t, 6, cfg.App.TableConcurrency)\n}\n\nfunc TestDefaultTidbBackendValue(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"tidb\"\n\tcfg.App.RegionConcurrency = 123\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 123, cfg.App.TableConcurrency)\n}\n\nfunc TestDefaultCouldBeOverwritten(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\tcfg.TikvImporter.Backend = \"local\"\n\tcfg.App.IndexConcurrency = 20\n\tcfg.App.TableConcurrency = 60\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\terr := cfg.Adjust(context.Background())\n\trequire.NoError(t, err)\n\trequire.Equal(t, 20, cfg.App.IndexConcurrency)\n\trequire.Equal(t, 60, cfg.App.TableConcurrency)\n}\n\nfunc TestLoadFromInvalidConfig(t *testing.T) {\n\ttaskCfg := config.NewConfig()\n\terr := taskCfg.LoadFromGlobal(&config.GlobalConfig{\n\t\tConfigFileContent: []byte(\"invalid toml\"),\n\t})\n\trequire.Error(t, err)\n\trequire.Regexp(t, \"line 1.*\", err.Error())\n}\n\nfunc TestTomlPostRestore(t *testing.T) {\n\tcfg := &config.Config{}\n\terr := cfg.LoadFromTOML([]byte(`\n\t\t[post-restore]\n\t\tchecksum = \"req\"\n\t`))\n\trequire.EqualError(t, err, \"invalid op level 'req', please choose valid option between ['off', 'optional', 'required']\")\n\n\terr = cfg.LoadFromTOML([]byte(`\n\t\t[post-restore]\n\t\tanalyze = 123\n\t`))\n\trequire.EqualError(t, err, \"invalid op level '123', please choose valid option between ['off', 'optional', 'required']\")\n\n\tkvMap := map[string]config.PostOpLevel{\n\t\t`\"off\"`:      config.OpLevelOff,\n\t\t`\"required\"`: config.OpLevelRequired,\n\t\t`\"optional\"`: config.OpLevelOptional,\n\t\t\"true\":       config.OpLevelRequired,\n\t\t\"false\":      config.OpLevelOff,\n\t}\n\n\tvar b bytes.Buffer\n\tenc := toml.NewEncoder(&b)\n\n\tfor k, v := range kvMap {\n\t\tcfg := &config.Config{}\n\t\tconfStr := fmt.Sprintf(\"[post-restore]\\r\\nchecksum= %s\\r\\n\", k)\n\t\terr := cfg.LoadFromTOML([]byte(confStr))\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, v, cfg.PostRestore.Checksum)\n\n\t\tb.Reset()\n\t\trequire.NoError(t, enc.Encode(cfg.PostRestore))\n\t\trequire.Regexp(t, fmt.Sprintf(`(?s).*checksum = \"\\Q%s\\E\".*`, v), &b)\n\t}\n\n\tfor k, v := range kvMap {\n\t\tcfg := &config.Config{}\n\t\tconfStr := fmt.Sprintf(\"[post-restore]\\r\\nanalyze= %s\\r\\n\", k)\n\t\terr := cfg.LoadFromTOML([]byte(confStr))\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, v, cfg.PostRestore.Analyze)\n\n\t\tb.Reset()\n\t\trequire.NoError(t, enc.Encode(cfg.PostRestore))\n\t\trequire.Regexp(t, fmt.Sprintf(`(?s).*analyze = \"\\Q%s\\E\".*`, v), &b)\n\t}\n}\n\nfunc TestCronEncodeDecode(t *testing.T) {\n\tcfg := &config.Config{}\n\tcfg.Cron.SwitchMode.Duration = 1 * time.Minute\n\tcfg.Cron.LogProgress.Duration = 2 * time.Minute\n\tcfg.Cron.CheckDiskQuota.Duration = 3 * time.Second\n\tvar b bytes.Buffer\n\trequire.NoError(t, toml.NewEncoder(&b).Encode(cfg.Cron))\n\trequire.Equal(t, \"switch-mode = \\\"1m0s\\\"\\nlog-progress = \\\"2m0s\\\"\\ncheck-disk-quota = \\\"3s\\\"\\n\", b.String())\n\n\tconfStr := \"[cron]\\r\\n\" + b.String()\n\tcfg2 := &config.Config{}\n\trequire.NoError(t, cfg2.LoadFromTOML([]byte(confStr)))\n\trequire.Equal(t, cfg.Cron, cfg2.Cron)\n}\n\nfunc TestAdjustWithLegacyBlackWhiteList(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\trequire.Equal(t, config.GetDefaultFilter(), cfg.Mydumper.Filter)\n\trequire.False(t, cfg.HasLegacyBlackWhiteList())\n\n\tctx := context.Background()\n\tcfg.Mydumper.Filter = []string{\"test.*\"}\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.False(t, cfg.HasLegacyBlackWhiteList())\n\n\tcfg.BWList.DoDBs = []string{\"test\"}\n\trequire.EqualError(t, cfg.Adjust(ctx), \"[Lightning:Config:ErrInvalidConfig]`mydumper.filter` and `black-white-list` cannot be simultaneously defined\")\n\n\tcfg.Mydumper.Filter = config.GetDefaultFilter()\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.True(t, cfg.HasLegacyBlackWhiteList())\n}\n\nfunc TestAdjustDiskQuota(t *testing.T) {\n\tcfg := config.NewConfig()\n\tassignMinimalLegalValue(cfg)\n\n\tbase := t.TempDir()\n\tctx := context.Background()\n\tcfg.TikvImporter.Backend = config.BackendLocal\n\tcfg.TikvImporter.DiskQuota = 0\n\tcfg.TikvImporter.SortedKVDir = base\n\tcfg.TiDB.DistSQLScanConcurrency = 1\n\trequire.NoError(t, cfg.Adjust(ctx))\n\trequire.Equal(t, int64(0), int64(cfg.TikvImporter.DiskQuota))\n}\n\nfunc TestDataCharacterSet(t *testing.T) {\n\ttestCases := []struct {\n\t\tinput string\n\t\terr   string\n\t}{\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'binary'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'utf8mb4'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-character-set = 'gb18030'\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\\u2323\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"a\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"INV\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\ud83d\ude0a\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t\t{\n\t\t\tinput: `\n\t\t\t\t[mydumper]\n\t\t\t\tdata-invalid-char-replace = \"\ud83d\ude0a\ud83d\ude2d\ud83d\ude05\ud83d\ude04\"\n\t\t\t`,\n\t\t\terr: \"\",\n\t\t},\n\t}", "is_vulnerable": 1}
{"code": "func checkAllowlist(r *library.Repo, allowlist []string) bool {\n\t// if the allowlist is not set or empty allow any repo to be enabled\n\tif len(allowlist) == 0 {\n\t\treturn true\n\t}\n\n\tfor _, repo := range allowlist {\n\t\t// allow all repos in org\n\t\tif strings.Contains(repo, \"/*\") {\n\t\t\tif strings.HasPrefix(repo, r.GetOrg()) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\n\t\t// allow specific repo within org\n\t\tif repo == r.GetFullName() {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (r *reconciler) ensureLoadBalancerService(ci *operatorv1.IngressController, deploymentRef metav1.OwnerReference, infraConfig *configv1.Infrastructure) (bool, *corev1.Service, error) {\n\tplatform, err := oputil.GetPlatformStatus(r.client, infraConfig)\n\tif err != nil {\n\t\treturn false, nil, fmt.Errorf(\"failed to determine infrastructure platform status for ingresscontroller %s/%s: %v\", ci.Namespace, ci.Name, err)\n\t}\n\tproxyNeeded, err := IsProxyProtocolNeeded(ci, platform)\n\tif err != nil {\n\t\treturn false, nil, fmt.Errorf(\"failed to determine if proxy protocol is proxyNeeded for ingresscontroller %q: %v\", ci.Name, err)\n\t}\n\twantLBS, desiredLBService, err := desiredLoadBalancerService(ci, deploymentRef, platform, proxyNeeded)\n\tif err != nil {\n\t\treturn false, nil, err\n\t}\n\n\thaveLBS, currentLBService, err := r.currentLoadBalancerService(ci)\n\tif err != nil {\n\t\treturn false, nil, err\n\t}\n\tif wantLBS && !haveLBS {\n\t\tif err := r.client.Create(context.TODO(), desiredLBService); err != nil {\n\t\t\treturn false, nil, fmt.Errorf(\"failed to create load balancer service %s/%s: %v\", desiredLBService.Namespace, desiredLBService.Name, err)\n\t\t}\n\t\tlog.Info(\"created load balancer service\", \"namespace\", desiredLBService.Namespace, \"name\", desiredLBService.Name)\n\t\treturn true, desiredLBService, nil\n\t}\n\t// return haveLBS instead of forcing true here since\n\t// there is no guarantee that currentLBService != nil\n\treturn haveLBS, currentLBService, nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.Name, func(t *testing.T) {\n\t\t\tactual := HostMatcher(tc.K, tc.V)\n\t\t\tif re := actual.GetSafeRegexMatch().GetRegex(); re != \"\" {\n\t\t\t\t_, err := regexp.Compile(re)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"failed to compile regex %s: %v\", re, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !cmp.Equal(tc.Expect, actual, protocmp.Transform()) {\n\t\t\t\tt.Errorf(\"expecting %v, but got %v\", tc.Expect, actual)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "\t\t\t\t\tAllow: func(raw interface{}) (bool, error) {\n\t\t\t\t\t\tsv := raw.(*structs.VariableEncrypted)\n\t\t\t\t\t\treturn strings.HasPrefix(sv.Path, args.Prefix) &&\n\t\t\t\t\t\t\t(aclObj == nil || aclObj.AllowVariableOperation(sv.Namespace, sv.Path, acl.PolicyList)), nil\n\t\t\t\t\t},", "is_vulnerable": 1}
{"code": "func TestIterativeRandomDelayedStateSync(t *testing.T) {\n\t// Create a random state to copy\n\tsrcDb, srcRoot, srcAccounts := makeTestState()\n\n\t// Create a destination state and sync with the scheduler\n\tdstDb := rawdb.NewMemoryDatabase()\n\tsched := NewStateSync(srcRoot, dstDb, trie.NewSyncBloom(1, dstDb))\n\n\tqueue := make(map[common.Hash]struct{})\n\tfor _, hash := range sched.Missing(0) {\n\t\tqueue[hash] = struct{}{}\n\t}\n\tfor len(queue) > 0 {\n\t\t// Sync only half of the scheduled nodes, even those in random order\n\t\tresults := make([]trie.SyncResult, 0, len(queue)/2+1)\n\t\tfor hash := range queue {\n\t\t\tdelete(queue, hash)\n\n\t\t\tdata, err := srcDb.TrieDB().Node(hash)\n\t\t\tif err != nil {\n\t\t\t\tdata, err = srcDb.ContractCode(common.Hash{}, hash)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to retrieve node data for %x\", hash)\n\t\t\t}\n\t\t\tresults = append(results, trie.SyncResult{Hash: hash, Data: data})\n\n\t\t\tif len(results) >= cap(results) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// Feed the retrieved results back and queue new tasks\n\t\tfor _, result := range results {\n\t\t\tif err := sched.Process(result); err != nil {\n\t\t\t\tt.Fatalf(\"failed to process result %v\", err)\n\t\t\t}\n\t\t}\n\t\tbatch := dstDb.NewBatch()\n\t\tif err := sched.Commit(batch); err != nil {\n\t\t\tt.Fatalf(\"failed to commit data: %v\", err)\n\t\t}\n\t\tbatch.Write()\n\t\tfor _, hash := range sched.Missing(0) {\n\t\t\tqueue[hash] = struct{}{}\n\t\t}\n\t}\n\t// Cross check that the two states are in sync\n\tcheckStateAccounts(t, dstDb, srcRoot, srcAccounts)\n}", "is_vulnerable": 0}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"broker url must be specified\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"emitter.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Emitter)\n\n\tfor _, value := range eventSource.Spec.Emitter {\n\t\tl := &EventListener{\n\t\t\tEmitterEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func init() {\n\tcobra.OnInitialize(initConfig)\n\n\trootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.rekor-server.yaml)\")\n\trootCmd.PersistentFlags().StringVar(&logType, \"log_type\", \"dev\", \"logger type to use (dev/prod)\")\n\trootCmd.PersistentFlags().BoolVar(&enablePprof, \"enable_pprof\", false, \"enable pprof for profiling on port 6060\")\n\trootCmd.PersistentFlags().Bool(\"enable_killswitch\", false, \"enable killswitch for TESTING ONLY on port 2345\")\n\t_ = rootCmd.PersistentFlags().MarkHidden(\"enable_killswitch\")\n\n\trootCmd.PersistentFlags().String(\"trillian_log_server.address\", \"127.0.0.1\", \"Trillian log server address\")\n\trootCmd.PersistentFlags().Uint16(\"trillian_log_server.port\", 8090, \"Trillian log server port\")\n\trootCmd.PersistentFlags().Uint(\"trillian_log_server.tlog_id\", 0, \"Trillian tree id\")\n\trootCmd.PersistentFlags().String(\"trillian_log_server.sharding_config\", \"\", \"path to config file for inactive shards, in JSON or YAML\")\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"localhost\"\n\t}\n\trootCmd.PersistentFlags().String(\"rekor_server.hostname\", hostname, \"public hostname of instance\")\n\trootCmd.PersistentFlags().String(\"rekor_server.address\", \"127.0.0.1\", \"Address to bind to\")\n\n\trootCmd.PersistentFlags().String(\"rekor_server.signer\", \"memory\",\n\t\t`Rekor signer to use. Valid options are: [gcpkms, memory, filename containing PEM encoded private key].\nMemory and file-based signers should only be used for testing.`)\n\trootCmd.PersistentFlags().String(\"rekor_server.signer-passwd\", \"\", \"Password to decrypt signer private key\")\n\n\trootCmd.PersistentFlags().Uint16(\"port\", 3000, \"Port to bind to\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_retrieve_api\", true, \"enables Redis-based index API endpoint\")\n\t_ = rootCmd.PersistentFlags().MarkDeprecated(\"enable_retrieve_api\", \"this flag is deprecated in favor of enabled_api_endpoints (searchIndex)\")\n\trootCmd.PersistentFlags().String(\"redis_server.address\", \"127.0.0.1\", \"Redis server address\")\n\trootCmd.PersistentFlags().Uint16(\"redis_server.port\", 6379, \"Redis server port\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_attestation_storage\", false, \"enables rich attestation storage\")\n\trootCmd.PersistentFlags().String(\"attestation_storage_bucket\", \"\", \"url for attestation storage bucket\")\n\trootCmd.PersistentFlags().Int(\"max_attestation_size\", 100*1024, \"max size for attestation storage, in bytes\")\n\n\trootCmd.PersistentFlags().StringSlice(\"enabled_api_endpoints\", operationIds, \"list of API endpoints to enable using operationId from openapi.yaml\")\n\n\trootCmd.PersistentFlags().Uint64(\"max_request_body_size\", 0, \"maximum size for HTTP request body, in bytes; set to 0 for unlimited\")\n\trootCmd.PersistentFlags().Uint64(\"max_jar_metadata_size\", 1048576, \"maximum permitted size for jar META-INF/ files, in bytes; set to 0 for unlimited\")\n\trootCmd.PersistentFlags().Uint64(\"max_apk_metadata_size\", 1048576, \"maximum permitted size for apk .SIGN and .PKGINFO files, in bytes; set to 0 for unlimited\")\n\n\tif err := viper.BindPFlags(rootCmd.PersistentFlags()); err != nil {\n\t\tlog.Logger.Fatal(err)\n\t}\n\n\trootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n\n\tlog.Logger.Debugf(\"pprof enabled %v\", enablePprof)\n\t// Enable pprof\n\tif enablePprof {\n\t\tgo func() {\n\t\t\tmux := http.NewServeMux()\n\n\t\t\tmux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/{action}\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n\n\t\t\tsrv := &http.Server{\n\t\t\t\tAddr:         \":6060\",\n\t\t\t\tReadTimeout:  10 * time.Second,\n\t\t\t\tWriteTimeout: 10 * time.Second,\n\t\t\t\tHandler:      mux,\n\t\t\t}\n\n\t\t\tif err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n\t\t\t\tlog.Logger.Fatalf(\"Error when starting or running http server: %v\", err)\n\t\t\t}\n\t\t}()\n\t}\n}", "is_vulnerable": 0}
{"code": "func (fs *UnixFS) Open(name string) (File, error) {\n\treturn fs.OpenFile(name, O_RDONLY, 0)\n}", "is_vulnerable": 0}
{"code": "func (t *TypeSystem) GetAllTupleToUsersetsDefinitions() map[string]map[string][]*openfgapb.TupleToUserset {\n\tresponse := make(map[string]map[string][]*openfgapb.TupleToUserset, 0)\n\tfor typeName, typeDef := range t.GetTypeDefinitions() {\n\t\tresponse[typeName] = make(map[string][]*openfgapb.TupleToUserset, 0)\n\t\tfor relationName, relationDef := range typeDef.GetRelations() {\n\t\t\tttus := make([]*openfgapb.TupleToUserset, 0)\n\t\t\tresponse[typeName][relationName] = t.getAllTupleToUsersetsDefinitions(relationDef, &ttus)\n\t\t}\n\t}\n\treturn response\n}", "is_vulnerable": 0}
{"code": "func (mock *clientProxyRemovingLinearAdvanceProof) VerifiableTxById(\n\tctx context.Context, in *schema.VerifiableTxRequest, opts ...grpc.CallOption,\n) (\n\t*schema.VerifiableTx, error,\n) {\n\tret, err := mock.ImmuServiceClient.VerifiableTxById(ctx, in)\n\tif ret != nil && ret.DualProof != nil {\n\t\t// Cleanup the linear advance proof so that it gets regenerated\n\t\tret.DualProof.LinearAdvanceProof = nil\n\t}\n\treturn ret, err\n}", "is_vulnerable": 0}
{"code": "func XMLToText(r io.Reader, breaks []string, skip []string, strict bool) (string, error) {\n\tvar result string\n\n\tdec := xml.NewDecoder(io.LimitReader(r, maxBytes))\n\tdec.Strict = strict\n\tfor {\n\t\tt, err := dec.Token()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tswitch v := t.(type) {\n\t\tcase xml.CharData:\n\t\t\tresult += string(v)\n\t\tcase xml.StartElement:\n\t\t\tfor _, breakElement := range breaks {\n\t\t\t\tif v.Name.Local == breakElement {\n\t\t\t\t\tresult += \"\\n\"\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, skipElement := range skip {\n\t\t\t\tif v.Name.Local == skipElement {\n\t\t\t\t\tdepth := 1\n\t\t\t\t\tfor {\n\t\t\t\t\t\tt, err := dec.Token()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t// An io.EOF here is actually an error.\n\t\t\t\t\t\t\treturn \"\", err\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tswitch t.(type) {\n\t\t\t\t\t\tcase xml.StartElement:\n\t\t\t\t\t\t\tdepth++\n\t\t\t\t\t\tcase xml.EndElement:\n\t\t\t\t\t\t\tdepth--\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif depth == 0 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result, nil\n}", "is_vulnerable": 0}
{"code": "func Render(tmpl string, s *types.Step) (types.StepSlice, error) {\n\tbuffer := new(bytes.Buffer)\n\tconfig := new(types.Build)\n\n\tvelaFuncs := funcHandler{envs: convertPlatformVars(s.Environment)}\n\ttemplateFuncMap := map[string]interface{}{\n\t\t\"vela\": velaFuncs.returnPlatformVar,\n\t}\n\n\t// parse the template with Masterminds/sprig functions\n\t//\n\t// https://pkg.go.dev/github.com/Masterminds/sprig?tab=doc#TxtFuncMap\n\tt, err := template.New(s.Name).Funcs(sprig.TxtFuncMap()).Funcs(templateFuncMap).Parse(tmpl)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to parse template %s: %v\", s.Template.Name, err)\n\t}\n\n\t// apply the variables to the parsed template\n\terr = t.Execute(buffer, s.Template.Variables)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to execute template %s: %v\", s.Template.Name, err)\n\t}\n\n\t// unmarshal the template to the pipeline\n\terr = yaml.Unmarshal(buffer.Bytes(), config)\n\tif err != nil {\n\t\treturn types.StepSlice{}, fmt.Errorf(\"unable to unmarshal yaml: %v\", err)\n\t}\n\n\t// ensure all templated steps have template prefix\n\tfor index, newStep := range config.Steps {\n\t\tconfig.Steps[index].Name = fmt.Sprintf(\"%s_%s\", s.Name, newStep.Name)\n\t}\n\n\treturn config.Steps, nil\n}", "is_vulnerable": 1}
{"code": "func dumprecord(w http.ResponseWriter, r *http.Request, parray []string) {\n\n\tdatabase := parray[0]\n\ttable := parray[1]\n\trec, err := strconv.Atoi(parray[2])\n\tcheckY(err)\n\n\tuser, pw := getCredentials(r)\n\tconn, err := sql.Open(\"mysql\", dsn(user, pw, database))\n\tcheckY(err)\n\tdefer conn.Close()\n\n\tstatement, err := conn.Prepare(\"select * from ?\")\n\tcheckY(err)\n\n\trows, err := statement.Query(table)\n\tcheckY(err)\n\tdefer rows.Close()\n\n\tcolumns, err := rows.Columns()\n\tcheckY(err)\n\n\traw := make([]interface{}, len(columns))\n\tval := make([]interface{}, len(columns))\n\n\tfor i := range val {\n\t\traw[i] = &val[i]\n\t}\n\n\tvar n int = 1\n\nrowLoop:\n\tfor rows.Next() {\n\n\t\t// unfortunately we have to iterate up to row of interest\n\t\tif n == rec {\n\t\t\terr = rows.Scan(raw...)\n\t\t\tcheckY(err)\n\n\t\t\tfmt.Fprintln(w, \"<p>\")\n\t\t\tfor i, col := range val {\n\t\t\t\tif col != nil {\n\t\t\t\t\tfmt.Fprintln(w, columns[i], \":\", string(col.([]byte)), \"<br>\")\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Fprintln(w, \"</p>\")\n\t\t\tbreak rowLoop\n\t\t}\n\t\tn = n + 1\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *Catalog) Register(args *structs.RegisterRequest, reply *struct{}) error {\n\tif done, err := c.srv.ForwardRPC(\"Catalog.Register\", args, args, reply); done {\n\t\treturn err\n\t}\n\tdefer metrics.MeasureSince([]string{\"catalog\", \"register\"}, time.Now())\n\n\t// Fetch the ACL token, if any.\n\tauthz, err := c.srv.ResolveTokenAndDefaultMeta(args.Token, &args.EnterpriseMeta, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.srv.validateEnterpriseRequest(args.GetEnterpriseMeta(), true); err != nil {\n\t\treturn err\n\t}\n\n\t// This needs to happen before the other preapply checks as it will fixup some of the\n\t// internal enterprise metas on the services and checks\n\tstate := c.srv.fsm.State()\n\tentMeta, err := state.ValidateRegisterRequest(args)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify the args.\n\tif err := nodePreApply(args.Node, string(args.ID)); err != nil {\n\t\treturn err\n\t}\n\tif args.Address == \"\" && !args.SkipNodeUpdate {\n\t\treturn fmt.Errorf(\"Must provide address if SkipNodeUpdate is not set\")\n\t}\n\n\t// Handle a service registration.\n\tif args.Service != nil {\n\t\tif err := servicePreApply(args.Service, authz); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Move the old format single check into the slice, and fixup IDs.\n\tif args.Check != nil {\n\t\targs.Checks = append(args.Checks, args.Check)\n\t\targs.Check = nil\n\t}\n\tfor _, check := range args.Checks {\n\t\tif check.Node == \"\" {\n\t\t\tcheck.Node = args.Node\n\t\t}\n\t\tcheckPreApply(check)\n\n\t\t// Populate check type for cases when a check is registered in the catalog directly\n\t\t// and not via anti-entropy\n\t\tif check.Type == \"\" {\n\t\t\tchkType := check.CheckType()\n\t\t\tcheck.Type = chkType.Type()\n\t\t}\n\t}\n\n\t// Check the complete register request against the given ACL policy.\n\tif authz != nil {\n\t\tstate := c.srv.fsm.State()\n\t\t_, ns, err := state.NodeServices(nil, args.Node, entMeta)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Node lookup failed: %v\", err)\n\t\t}\n\t\tif err := vetRegisterWithACL(authz, args, ns); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tresp, err := c.srv.raftApply(structs.RegisterRequestType, args)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif respErr, ok := resp.(error); ok {\n\t\treturn respErr\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func CreateWrapKey(rw io.ReadWriter, srkAuth []byte, usageAuth Digest, migrationAuth Digest, pcrs []int) ([]byte, error) {\n\tk, err := createWrapKeyHelper(rw, srkAuth, 0, usageAuth, migrationAuth, pcrs)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkeyblob, err := tpmutil.Pack(k)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn keyblob, nil\n}", "is_vulnerable": 0}
{"code": "func TestTLSServerWithLocalhostCertWithClientCertificateEnforcementUsingClientCA1(t *testing.T) {\n\tcerts := setupCertificates(t)\n\n\tcfg := server.Config{}\n\t(&cfg).RegisterFlags(flag.NewFlagSet(\"fake\", flag.ContinueOnError))\n\n\tunavailableDescErr := errorContainsString(\"rpc error: code = Unavailable desc =\")\n\n\t// Test a TLS server with localhost cert with client certificate enforcement through client CA 1\n\tcfg.HTTPTLSConfig.TLSCertPath = certs.serverCertFile\n\tcfg.HTTPTLSConfig.TLSKeyPath = certs.serverKeyFile\n\tcfg.HTTPTLSConfig.ClientCAs = certs.clientCA1CertFile\n\tcfg.HTTPTLSConfig.ClientAuth = \"RequireAndVerifyClientCert\"\n\tcfg.GRPCTLSConfig.TLSCertPath = certs.serverCertFile\n\tcfg.GRPCTLSConfig.TLSKeyPath = certs.serverKeyFile\n\tcfg.GRPCTLSConfig.ClientCAs = certs.clientCA1CertFile\n\tcfg.GRPCTLSConfig.ClientAuth = \"RequireAndVerifyClientCert\"\n\n\t// TODO: Investigate why we don't really receive the error about the\n\t// certificate required from the server side and just see connection\n\t// closed/reset instead\n\t// In Go 1.21, TLS 1.3 would return certificate required error instead\n\t// of bad certificate error\n\tcertRequiredErr := errorContainsString(\"remote error: tls: certificate required\")\n\tnewIntegrationClientServer(\n\t\tt,\n\t\tcfg,\n\t\t[]tcIntegrationClientServer{\n\t\t\t{\n\t\t\t\tname:           \"tls-skip-verify\",\n\t\t\t\ttlsGrpcEnabled: true,\n\t\t\t\ttlsConfig: tls.ClientConfig{\n\t\t\t\t\tInsecureSkipVerify: true,\n\t\t\t\t},\n\t\t\t\thttpExpectError: certRequiredErr,\n\t\t\t\tgrpcExpectError: unavailableDescErr,\n\t\t\t},\n\t\t\t{\n\t\t\t\tname:           \"ca-path\",\n\t\t\t\ttlsGrpcEnabled: true,\n\t\t\t\ttlsConfig: tls.ClientConfig{\n\t\t\t\t\tCAPath: certs.caCertFile,\n\t\t\t\t},\n\t\t\t\thttpExpectError: certRequiredErr,\n\t\t\t\tgrpcExpectError: unavailableDescErr,\n\t\t\t},\n\t\t\t{\n\t\t\t\tname:           \"ca-path-and-client-cert-ca1\",\n\t\t\t\ttlsGrpcEnabled: true,\n\t\t\t\ttlsConfig: tls.ClientConfig{\n\t\t\t\t\tCAPath:   certs.caCertFile,\n\t\t\t\t\tCertPath: certs.client1CertFile,\n\t\t\t\t\tKeyPath:  certs.client1KeyFile,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tname:           \"tls-skip-verify-and-client-cert-ca1\",\n\t\t\t\ttlsGrpcEnabled: true,\n\t\t\t\ttlsConfig: tls.ClientConfig{\n\t\t\t\t\tInsecureSkipVerify: true,\n\t\t\t\t\tCertPath:           certs.client1CertFile,\n\t\t\t\t\tKeyPath:            certs.client1KeyFile,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tname:           \"ca-cert-and-client-cert-ca2\",\n\t\t\t\ttlsGrpcEnabled: true,\n\t\t\t\ttlsConfig: tls.ClientConfig{\n\t\t\t\t\tCAPath:   certs.caCertFile,\n\t\t\t\t\tCertPath: certs.client2CertFile,\n\t\t\t\t\tKeyPath:  certs.client2KeyFile,\n\t\t\t\t},\n\t\t\t\thttpExpectError: certRequiredErr,\n\t\t\t\tgrpcExpectError: unavailableDescErr,\n\t\t\t},\n\t\t},\n\t)\n}", "is_vulnerable": 0}
{"code": "func (n *IntegrationNetwork) configureAndInitChain() error {\n\t// Create funded accounts based on the config and\n\t// create genesis accounts\n\tgenAccounts, fundedAccountBalances := getGenAccountsAndBalances(n.cfg)\n\n\t// Create validator set with the amount of validators specified in the config\n\t// with the default power of 1.\n\tvalSet, valSigners := createValidatorSetAndSigners(n.cfg.amountOfValidators)\n\ttotalBonded := bondedAmt.Mul(sdktypes.NewInt(int64(n.cfg.amountOfValidators)))\n\n\t// Build staking type validators and delegations\n\tvalidators, err := createStakingValidators(valSet.Validators, bondedAmt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfundedAccountBalances = addBondedModuleAccountToFundedBalances(fundedAccountBalances, sdktypes.NewCoin(n.cfg.denom, totalBonded))\n\n\tdelegations := createDelegations(valSet.Validators, genAccounts[0].GetAddress())\n\n\t// Create a new EvmosApp with the following params\n\tevmosApp := createEvmosApp(n.cfg.chainID)\n\n\t// Configure Genesis state\n\tgenesisState := app.NewDefaultGenesisState()\n\n\tgenesisState = setAuthGenesisState(evmosApp, genesisState, genAccounts)\n\n\tstakingParams := StakingCustomGenesisState{\n\t\tdenom:       n.cfg.denom,\n\t\tvalidators:  validators,\n\t\tdelegations: delegations,\n\t}\n\tgenesisState = setStakingGenesisState(evmosApp, genesisState, stakingParams)\n\n\tgenesisState = setInflationGenesisState(evmosApp, genesisState)\n\n\ttotalSupply := calculateTotalSupply(fundedAccountBalances)\n\tbankParams := BankCustomGenesisState{\n\t\ttotalSupply: totalSupply,\n\t\tbalances:    fundedAccountBalances,\n\t}\n\tgenesisState = setBankGenesisState(evmosApp, genesisState, bankParams)\n\n\t// Init chain\n\tstateBytes, err := json.MarshalIndent(genesisState, \"\", \" \")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnow := time.Now()\n\tevmosApp.InitChain(\n\t\tabcitypes.RequestInitChain{\n\t\t\tTime:            now,\n\t\t\tChainId:         n.cfg.chainID,\n\t\t\tValidators:      []abcitypes.ValidatorUpdate{},\n\t\t\tConsensusParams: app.DefaultConsensusParams,\n\t\t\tAppStateBytes:   stateBytes,\n\t\t},\n\t)\n\t// Commit genesis changes\n\tevmosApp.Commit()\n\n\theader := tmproto.Header{\n\t\tChainID:            n.cfg.chainID,\n\t\tHeight:             evmosApp.LastBlockHeight() + 1,\n\t\tTime:               now,\n\t\tAppHash:            evmosApp.LastCommitID().Hash,\n\t\tValidatorsHash:     valSet.Hash(),\n\t\tNextValidatorsHash: valSet.Hash(),\n\t\tProposerAddress:    valSet.Proposer.Address,\n\t}\n\tevmosApp.BeginBlock(abcitypes.RequestBeginBlock{Header: header})\n\n\t// Set networks global parameters\n\tn.app = evmosApp\n\t// TODO - this might not be the best way to initilize the context\n\tn.ctx = evmosApp.BaseApp.NewContext(false, header)\n\tn.validators = validators\n\tn.valSet = valSet\n\tn.valSigners = valSigners\n\n\t// Register EVMOS in denom metadata\n\tevmosMetadata := banktypes.Metadata{\n\t\tDescription: \"The native token of Evmos\",\n\t\tBase:        n.cfg.denom,\n\t\t// NOTE: Denom units MUST be increasing\n\t\tDenomUnits: []*banktypes.DenomUnit{\n\t\t\t{\n\t\t\t\tDenom:    n.cfg.denom,\n\t\t\t\tExponent: 0,\n\t\t\t\tAliases:  []string{n.cfg.denom},\n\t\t\t},\n\t\t\t{\n\t\t\t\tDenom:    n.cfg.denom,\n\t\t\t\tExponent: 18,\n\t\t\t},\n\t\t},\n\t\tName:    \"Evmos\",\n\t\tSymbol:  \"EVMOS\",\n\t\tDisplay: n.cfg.denom,\n\t}\n\tevmosApp.BankKeeper.SetDenomMetaData(n.ctx, evmosMetadata)\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func chaCha20_ctr32_vmx(out, inp *byte, len int, key *[8]uint32, counter *uint32)\n\nfunc (c *Cipher) xorKeyStreamAsm(dst, src []byte) {\n\tif len(src) >= bufSize {\n\t\tchaCha20_ctr32_vmx(&dst[0], &src[0], len(src)-len(src)%bufSize, &c.key, &c.counter)\n\t}\n\tif len(src)%bufSize != 0 {\n\t\tchaCha20_ctr32_vmx(&c.buf[0], &c.buf[0], bufSize, &c.key, &c.counter)\n\t\tstart := len(src) - len(src)%bufSize\n\t\tts, td, tb := src[start:], dst[start:], c.buf[:]\n\t\t// Unroll loop to XOR 32 bytes per iteration.\n\t\tfor i := 0; i < len(ts)-32; i += 32 {\n\t\t\ttd, tb = td[:len(ts)], tb[:len(ts)] // bounds check elimination\n\t\t\ts0 := binary.LittleEndian.Uint64(ts[0:8])\n\t\t\ts1 := binary.LittleEndian.Uint64(ts[8:16])\n\t\t\ts2 := binary.LittleEndian.Uint64(ts[16:24])\n\t\t\ts3 := binary.LittleEndian.Uint64(ts[24:32])\n\t\t\tb0 := binary.LittleEndian.Uint64(tb[0:8])\n\t\t\tb1 := binary.LittleEndian.Uint64(tb[8:16])\n\t\t\tb2 := binary.LittleEndian.Uint64(tb[16:24])\n\t\t\tb3 := binary.LittleEndian.Uint64(tb[24:32])\n\t\t\tbinary.LittleEndian.PutUint64(td[0:8], s0^b0)\n\t\t\tbinary.LittleEndian.PutUint64(td[8:16], s1^b1)\n\t\t\tbinary.LittleEndian.PutUint64(td[16:24], s2^b2)\n\t\t\tbinary.LittleEndian.PutUint64(td[24:32], s3^b3)\n\t\t\tts, td, tb = ts[32:], td[32:], tb[32:]\n\t\t}\n\t\ttd, tb = td[:len(ts)], tb[:len(ts)] // bounds check elimination\n\t\tfor i, v := range ts {\n\t\t\ttd[i] = tb[i] ^ v\n\t\t}\n\t\tc.len = bufSize - (len(src) % bufSize)\n\n\t}\n\n}", "is_vulnerable": 1}
{"code": "func (mr *MockTokenRevocationStorageMockRecorder) RevokeAccessToken(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"RevokeAccessToken\", reflect.TypeOf((*MockTokenRevocationStorage)(nil).RevokeAccessToken), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func TestGenerateManifests_MissingSymlinkDestination(t *testing.T) {\n\trepoDir := t.TempDir()\n\terr := os.Symlink(\"/obviously/does/not/exist\", path.Join(repoDir, \"test.yaml\"))\n\trequire.NoError(t, err)\n\n\tq := apiclient.ManifestRequest{Repo: &argoappv1.Repository{}, ApplicationSource: &argoappv1.ApplicationSource{}}\n\t_, err = GenerateManifests(repoDir, \"\", \"\", &q, false)\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func NewPbse2HmacAesKWAlg(keySize int, maxIters int64, minIters int64) JwaAlgorithm {\n\tswitch keySize {\n\tcase 128:\n\t\treturn &Pbse2HmacAesKW{keySizeBits: 128, maxIterations: maxIters, minIterations: minIters, aesKW: &AesKW{keySizeBits: 128}}\n\tcase 192:\n\t\treturn &Pbse2HmacAesKW{keySizeBits: 192, maxIterations: maxIters, minIterations: minIters, aesKW: &AesKW{keySizeBits: 192}}\n\tdefault:\n\t\treturn &Pbse2HmacAesKW{keySizeBits: 256, maxIterations: maxIters, minIterations: minIters, aesKW: &AesKW{keySizeBits: 256}}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestListArtifactContainer(t *testing.T) {\n\tassert := assert.New(t)\n\n\tvar memfs = fstest.MapFS(map[string]*fstest.MapFile{\n\t\t\"1/some/file\": {\n\t\t\tData: []byte(\"\"),\n\t\t},\n\t})\n\n\trouter := httprouter.New()\n\tdownloads(router, memfs)\n\n\treq, _ := http.NewRequest(\"GET\", \"http://localhost/download/1?itemPath=some/file\", nil)\n\trr := httptest.NewRecorder()\n\n\trouter.ServeHTTP(rr, req)\n\n\tif status := rr.Code; status != http.StatusOK {\n\t\tassert.FailNow(fmt.Sprintf(\"Wrong status: %d\", status))\n\t}\n\n\tresponse := ContainerItemResponse{}\n\terr := json.Unmarshal(rr.Body.Bytes(), &response)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tassert.Equal(1, len(response.Value))\n\tassert.Equal(\"some/file/.\", response.Value[0].Path)\n\tassert.Equal(\"file\", response.Value[0].ItemType)\n\tassert.Equal(\"http://localhost/artifact/1/some/file/.\", response.Value[0].ContentLocation)\n}", "is_vulnerable": 1}
{"code": "func registerModelWhiteList(instance any) fieldWhiteListedFunc {\n\tname := reflect.TypeOf(instance).String()\n\tregisterFieldWhiteList(name, instance)\n\treturn getFieldWhiteListedFunc(name)\n}", "is_vulnerable": 0}
{"code": "func (r *Router) AddRouteTLS(rule string, priority int, target tcp.Handler, config *tls.Config) error {\n\t// TLS PassThrough\n\tif config == nil {\n\t\treturn r.muxerTCPTLS.AddRoute(rule, priority, target)\n\t}\n\n\treturn r.muxerTCPTLS.AddRoute(rule, priority, &tcp.TLSHandler{\n\t\tNext:   target,\n\t\tConfig: config,\n\t})\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn serviceUpstream{\n\t\tr:                r,\n\t\tannotationConfig: serviceUpstreamAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(testname, func(t *testing.T) {\n\t\t\tassert := assert.New(t)\n\n\t\t\tcvss20, err := gocvss20.ParseVector(tt.Vector)\n\n\t\t\tassert.Equal(tt.ExpectedCVSS20, cvss20)\n\t\t\tassert.Equal(tt.ExpectedErr, err)\n\t\t})", "is_vulnerable": 1}
{"code": "\tt.Run(\"with annotation in namespace/name format\", func(t *testing.T) {\n\t\ting := ingTpl.DeepCopy()\n\t\ting.ObjectMeta.SetAnnotations(map[string]string{\n\t\t\tparser.GetAnnotationWithPrefix(\"auth-secret\"): \"testns/auth\",\n\t\t})\n\t\tif err := s.listers.Ingress.Update(ing); err != nil {\n\t\t\tt.Errorf(\"error updating the Ingress: %v\", err)\n\t\t}\n\t\ts.updateSecretIngressMap(ing)\n\n\t\tif l := s.secretIngressMap.Len(); !(l == 1 && s.secretIngressMap.Has(\"testns/auth\")) {\n\t\t\tt.Errorf(\"Expected \\\"otherns/auth\\\" to be the only referenced Secret (got %d)\", l)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (de dirent) Type() FileMode {\n\treturn de.modeType\n}", "is_vulnerable": 0}
{"code": "func (handler *Handler) deployComposeStack(config *composeStackDeploymentConfig) error {\n\tsettings, err := handler.SettingsService.Settings()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tisAdminOrEndpointAdmin, err := handler.userIsAdminOrEndpointAdmin(config.user, config.endpoint.ID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif (!settings.AllowBindMountsForRegularUsers ||\n\t\t!settings.AllowPrivilegedModeForRegularUsers ||\n\t\t!settings.AllowHostNamespaceForRegularUsers ||\n\t\t!settings.AllowDeviceMappingForRegularUsers) && !isAdminOrEndpointAdmin {\n\n\t\tcomposeFilePath := path.Join(config.stack.ProjectPath, config.stack.EntryPoint)\n\n\t\tstackContent, err := handler.FileService.GetFileContent(composeFilePath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = handler.isValidStackFile(stackContent, settings)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\thandler.stackCreationMutex.Lock()\n\tdefer handler.stackCreationMutex.Unlock()\n\n\thandler.SwarmStackManager.Login(config.dockerhub, config.registries, config.endpoint)\n\n\terr = handler.ComposeStackManager.Up(config.stack, config.endpoint)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn handler.SwarmStackManager.Logout(config.endpoint)\n}", "is_vulnerable": 1}
{"code": "func (d *decoder) decodeRecord(rec *walpb.Record) error {\n\tif len(d.brs) == 0 {\n\t\treturn io.EOF\n\t}\n\n\tl, err := readInt64(d.brs[0])\n\tif err == io.EOF || (err == nil && l == 0) {\n\t\t// hit end of file or preallocated space\n\t\td.brs = d.brs[1:]\n\t\tif len(d.brs) == 0 {\n\t\t\treturn io.EOF\n\t\t}\n\t\td.lastValidOff = 0\n\t\treturn d.decodeRecord(rec)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trecBytes, padBytes := decodeFrameSize(l)\n\tif recBytes >= maxWALEntrySizeLimit-padBytes {\n\t\treturn ErrMaxWALEntrySizeLimitExceeded\n\t}\n\n\tdata := make([]byte, recBytes+padBytes)\n\tif _, err = io.ReadFull(d.brs[0], data); err != nil {\n\t\t// ReadFull returns io.EOF only if no bytes were read\n\t\t// the decoder should treat this as an ErrUnexpectedEOF instead.\n\t\tif err == io.EOF {\n\t\t\terr = io.ErrUnexpectedEOF\n\t\t}\n\t\treturn err\n\t}\n\tif err := rec.Unmarshal(data[:recBytes]); err != nil {\n\t\tif d.isTornEntry(data) {\n\t\t\treturn io.ErrUnexpectedEOF\n\t\t}\n\t\treturn err\n\t}\n\n\t// skip crc checking if the record type is crcType\n\tif rec.Type != crcType {\n\t\td.crc.Write(rec.Data)\n\t\tif err := rec.Validate(d.crc.Sum32()); err != nil {\n\t\t\tif d.isTornEntry(data) {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t}\n\t// record decoded as valid; point last valid offset to end of record\n\td.lastValidOff += frameSizeBytes + recBytes + padBytes\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (client TagsClient) DeleteSender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func validate(bearerToken string) (UserInfo, error) {\n\n\tsigningKey := config.Get().LoginToken.SigningKey\n\n\tauth := false\n\tvar claims JWTClaimsJSON // special struct for decoding the json\n\tu := UserInfo{           // user we'll return, initially in error state\n\t\tAPIVersion: \"authentication.k8s.io/v1beta1\",\n\t\tKind:       \"TokenReview\",\n\t\tStatus: &Status{\n\t\t\tAuthenticated: &auth,\n\t\t\tUser:          nil,\n\t\t},\n\t}\n\n\ttoken, err := jwt.ParseWithClaims(bearerToken, &claims, func(token *jwt.Token) (interface{}, error) {\n\t\tif !strings.HasPrefix(token.Method.Alg(), \"HS\") { // HMAC are the only allowed signing methods\n\t\t\tlog.Errorf(\"Unexpected signing method: %s\", token.Method.Alg())\n\t\t\treturn nil, fmt.Errorf(\"Unexpected signing method: %s\", token.Method.Alg())\n\t\t}\n\t\treturn []byte(signingKey), nil\n\t})\n\n\tif token == nil || !token.Valid {\n\t\tlog.Debugf(\"Token not valid: %v\", err)\n\t\treturn u, err\n\t}\n\n\t// Token is valid so fill in the rest of u with happy state and return it\n\tauth = true\n\tu.Status.Authenticated = &auth\n\tu.Status.User = &User{Username: claims.Username, UID: claims.UID, Groups: claims.Groups}\n\n\treturn u, nil\n}", "is_vulnerable": 1}
{"code": "func TestUnixFS_Remove(t *testing.T) {\n\tt.Parallel()\n\tfs, err := newTestUnixFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t\treturn\n\t}\n\tdefer fs.Cleanup()\n\n\tt.Run(\"base directory\", func(t *testing.T) {\n\t\t// Try to remove the base directory.\n\t\tif err := fs.Remove(\"\"); !errors.Is(err, ufs.ErrBadPathResolution) {\n\t\t\tt.Errorf(\"expected an a bad path resolution error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n\n\tt.Run(\"path traversal\", func(t *testing.T) {\n\t\t// Try to remove the base directory.\n\t\tif err := fs.RemoveAll(\"../root\"); !errors.Is(err, ufs.ErrBadPathResolution) {\n\t\t\tt.Errorf(\"expected an a bad path resolution error, but got: %v\", err)\n\t\t\treturn\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestKeeperIntegrationTestSuite(t *testing.T) {\n\t// Run Ginkgo integration tests\n\tRegisterFailHandler(Fail)\n\tRunSpecs(t, \"Keeper Suite\")\n}", "is_vulnerable": 0}
{"code": "func (m *UnrecognizedWithInner_Inner) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Inner: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Inner: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestToSupi(t *testing.T) {\n\tsuciProfiles := []SuciProfile{\n\t\t{\n\t\t\tProtectionScheme: \"1\", // Protect Scheme: Profile A\n\t\t\tPrivateKey:       \"c53c22208b61860b06c62e5406a7b330c2b577aa5558981510d128247d38bd1d\",\n\t\t\tPublicKey:        \"5a8d38864820197c3394b92613b20b91633cbd897119273bf8e4a6f4eec0a650\",\n\t\t},\n\t\t{\n\t\t\tProtectionScheme: \"2\", // Protect Scheme: Profile B\n\t\t\tPrivateKey:       \"F1AB1074477EBCC7F554EA1C5FC368B1616730155E0041AC447D6301975FECDA\",\n\t\t\tPublicKey: \"0472DA71976234CE833A6907425867B82E074D44EF907DFB4B3E21C1C2256EBCD\" +\n\t\t\t\t\"15A7DED52FCBB097A4ED250E036C7B9C8C7004C4EEDC4F068CD7BF8D3F900E3B4\",\n\t\t},\n\t}\n\ttestCases := []struct {\n\t\tsuci         string\n\t\texpectedSupi string\n\t\texpectedErr  error\n\t}{\n\t\t{\n\t\t\tsuci:         \"suci-0-208-93-0-0-0-00007487\",\n\t\t\texpectedSupi: \"imsi-2089300007487\",\n\t\t\texpectedErr:  nil,\n\t\t},\n\t\t{\n\t\t\tsuci: \"suci-0-208-93-0-1-1-b2e92f836055a255837debf850b528997ce0201cb82a\" +\n\t\t\t\t\"dfe4be1f587d07d8457dcb02352410cddd9e730ef3fa87\",\n\t\t\texpectedSupi: \"imsi-20893001002086\",\n\t\t\texpectedErr:  nil,\n\t\t},\n\t\t{\n\t\t\tsuci: \"suci-0-208-93-0-2-2-039aab8376597021e855679a9778ea0b67396e68c66d\" +\n\t\t\t\t\"f32c0f41e9acca2da9b9d146a33fc2716ac7dae96aa30a4d\",\n\t\t\texpectedSupi: \"imsi-20893001002086\",\n\t\t\texpectedErr:  nil,\n\t\t},\n\t\t{\n\t\t\tsuci: \"suci-0-208-93-0-2-2-0434a66778799d52fedd9326db4b690d092e05c9ba0ace5b413da\" +\n\t\t\t\t\"fc0a40aa28ee00a79f790fa4da6a2ece892423adb130dc1b30e270b7d0088bdd716b93894891d5221a74c810d6b9350cc067c76\",\n\t\t\texpectedSupi: \"\",\n\t\t\texpectedErr:  fmt.Errorf(\"crypto/elliptic: attempted operation on invalid point\"),\n\t\t},\n\t}\n\tfor i, tc := range testCases {\n\t\tsupi, err := ToSupi(tc.suci, suciProfiles)\n\t\tif err != nil {\n\t\t\tif err.Error() != tc.expectedErr.Error() {\n\t\t\t\tt.Errorf(\"TC%d fail: err[%s], expected[%s]\\n\", i, err, tc.expectedErr)\n\t\t\t}\n\t\t} else if supi != tc.expectedSupi {\n\t\t\tt.Errorf(\"TC%d fail: supi[%s], expected[%s]\\n\", i, supi, tc.expectedSupi)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Container) IsPlugin() bool {\n\treturn len(c.Commands) == 0 &&\n\t\tlen(c.Entrypoint) == 0 &&\n\t\tlen(c.Environment) == 0\n}", "is_vulnerable": 0}
{"code": "func OwnerRoleBindingsIndexFunc(obj interface{}) (result []string, err error) {\n\trb := obj.(*rbacv1.RoleBinding)\n\n\tfor _, subject := range rb.Subjects {\n\t\tparts := []string{subject.Kind}\n\n\t\tif len(subject.Namespace) > 0 {\n\t\t\tparts = append(parts, subject.Namespace)\n\t\t}\n\n\t\tparts = append(parts, subject.Name)\n\n\t\tresult = append(result, strings.Join(parts, \"-\"))\n\t}\n\n\treturn result, nil\n}", "is_vulnerable": 0}
{"code": "\tpolicyWithName := func(name string) *extensions.PodSecurityPolicy {\n\t\tp := restrictivePSP()\n\t\tp.Name = name\n\t\treturn p\n\t}\n\n\ttests := map[string]struct {\n\t\tuser               user.Info\n\t\tsa                 user.Info\n\t\texpectedPolicies   sets.String\n\t\tinPolicies         []*extensions.PodSecurityPolicy\n\t\tdisallowedPolicies map[string][]string\n\t}{\n\t\t\"policy allowed by user\": {\n\t\t\tuser: &user.DefaultInfo{Name: \"user\"},\n\t\t\tsa:   &user.DefaultInfo{Name: \"sa\"},\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"sa\": {\"policy\"},\n\t\t\t},\n\t\t\tinPolicies:       []*extensions.PodSecurityPolicy{policyWithName(\"policy\")},\n\t\t\texpectedPolicies: sets.NewString(\"policy\"),\n\t\t},\n\t\t\"policy allowed by sa\": {\n\t\t\tuser: &user.DefaultInfo{Name: \"user\"},\n\t\t\tsa:   &user.DefaultInfo{Name: \"sa\"},\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"user\": {\"policy\"},\n\t\t\t},\n\t\t\tinPolicies:       []*extensions.PodSecurityPolicy{policyWithName(\"policy\")},\n\t\t\texpectedPolicies: sets.NewString(\"policy\"),\n\t\t},\n\t\t\"no policies allowed\": {\n\t\t\tuser: &user.DefaultInfo{Name: \"user\"},\n\t\t\tsa:   &user.DefaultInfo{Name: \"sa\"},\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"user\": {\"policy\"},\n\t\t\t\t\"sa\":   {\"policy\"},\n\t\t\t},\n\t\t\tinPolicies:       []*extensions.PodSecurityPolicy{policyWithName(\"policy\")},\n\t\t\texpectedPolicies: sets.NewString(),\n\t\t},\n\t\t\"multiple policies allowed\": {\n\t\t\tuser: &user.DefaultInfo{Name: \"user\"},\n\t\t\tsa:   &user.DefaultInfo{Name: \"sa\"},\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"user\": {\"policy1\", \"policy3\"},\n\t\t\t\t\"sa\":   {\"policy2\", \"policy3\"},\n\t\t\t},\n\t\t\tinPolicies: []*extensions.PodSecurityPolicy{\n\t\t\t\tpolicyWithName(\"policy1\"), // allowed by sa\n\t\t\t\tpolicyWithName(\"policy2\"), // allowed by user\n\t\t\t\tpolicyWithName(\"policy3\"), // not allowed\n\t\t\t},\n\t\t\texpectedPolicies: sets.NewString(\"policy1\", \"policy2\"),\n\t\t},\n\t\t\"policies are allowed for nil user info\": {\n\t\t\tuser: nil,\n\t\t\tsa:   &user.DefaultInfo{Name: \"sa\"},\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"user\": {\"policy1\", \"policy3\"},\n\t\t\t\t\"sa\":   {\"policy2\", \"policy3\"},\n\t\t\t},\n\t\t\tinPolicies: []*extensions.PodSecurityPolicy{\n\t\t\t\tpolicyWithName(\"policy1\"),\n\t\t\t\tpolicyWithName(\"policy2\"),\n\t\t\t\tpolicyWithName(\"policy3\"),\n\t\t\t},\n\t\t\t// all policies are allowed regardless of the permissions when user info is nil\n\t\t\t// (ie. a request hitting the unsecure port)\n\t\t\texpectedPolicies: sets.NewString(\"policy1\", \"policy2\", \"policy3\"),\n\t\t},\n\t\t\"policies are allowed for nil sa info\": {\n\t\t\tuser: &user.DefaultInfo{Name: \"user\"},\n\t\t\tsa:   nil,\n\t\t\tdisallowedPolicies: map[string][]string{\n\t\t\t\t\"user\": {\"policy1\", \"policy3\"},\n\t\t\t\t\"sa\":   {\"policy2\", \"policy3\"},\n\t\t\t},\n\t\t\tinPolicies: []*extensions.PodSecurityPolicy{\n\t\t\t\tpolicyWithName(\"policy1\"),\n\t\t\t\tpolicyWithName(\"policy2\"),\n\t\t\t\tpolicyWithName(\"policy3\"),\n\t\t\t},\n\t\t\t// all policies are allowed regardless of the permissions when sa info is nil\n\t\t\t// (ie. a request hitting the unsecure port)\n\t\t\texpectedPolicies: sets.NewString(\"policy1\", \"policy2\", \"policy3\"),\n\t\t},\n\t}\n\tfor k, v := range tests {\n\t\tstore := cache.NewStore(cache.MetaNamespaceKeyFunc)\n\t\tfor _, psp := range v.inPolicies {\n\t\t\tstore.Add(psp)\n\t\t}\n\n\t\tauthz := &TestAuthorizer{disallowed: v.disallowedPolicies}\n\t\tallowedPolicies, err := getMatchingPolicies(store, v.user, v.sa, authz)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"%s got unexpected error %#v\", k, err)\n\t\t\tcontinue\n\t\t}\n\t\tallowedPolicyNames := sets.NewString()\n\t\tfor _, p := range allowedPolicies {\n\t\t\tallowedPolicyNames.Insert(p.Name)\n\t\t}\n\t\tif !v.expectedPolicies.Equal(allowedPolicyNames) {\n\t\t\tt.Errorf(\"%s received unexpected policies.  Expected %#v but got %#v\", k, v.expectedPolicies.List(), allowedPolicyNames.List())\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "\tassert.Eventually(t, func() bool { return checkTrustMessageRequest() }, time.Second, time.Millisecond)", "is_vulnerable": 0}
{"code": "func TestAccountURLResolverNoFetchOnReload(t *testing.T) {\n\tkp, _ := nkeys.FromSeed(oSeed)\n\takp, _ := nkeys.CreateAccount()\n\tapub, _ := akp.PublicKey()\n\tnac := jwt.NewAccountClaims(apub)\n\tajwt, err := nac.Encode(kp)\n\tif err != nil {\n\t\tt.Fatalf(\"Error generating account JWT: %v\", err)\n\t}\n\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(ajwt))\n\t}))\n\tdefer ts.Close()\n\n\tconfTemplate := `\n\t\tlisten: -1\n\t\tresolver: URL(\"%s/ngs/v1/accounts/jwt/\")\n    `\n\tconf := createConfFile(t, []byte(fmt.Sprintf(confTemplate, ts.URL)))\n\tdefer os.Remove(conf)\n\n\ts, _ := RunServerWithConfig(conf)\n\tdefer s.Shutdown()\n\n\tacc, _ := s.LookupAccount(apub)\n\tif acc == nil {\n\t\tt.Fatalf(\"Expected to receive an account\")\n\t}\n\n\t// Reload would produce a DATA race during the DeepEqual check for the account resolver,\n\t// so close the current one and we will create a new one that keeps track of fetch calls.\n\tts.Close()\n\n\tfetch := int32(0)\n\tts = httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tatomic.AddInt32(&fetch, 1)\n\t\tw.Write([]byte(ajwt))\n\t}))\n\tdefer ts.Close()\n\n\tchangeCurrentConfigContentWithNewContent(t, conf, []byte(fmt.Sprintf(confTemplate, ts.URL)))\n\n\tif err := s.Reload(); err != nil {\n\t\tt.Fatalf(\"Error on reload: %v\", err)\n\t}\n\tif atomic.LoadInt32(&fetch) != 0 {\n\t\tt.Fatalf(\"Fetch invoked during reload\")\n\t}\n\n\t// Now stop the resolver and make sure that on startup, we report URL resolver failure\n\ts.Shutdown()\n\ts = nil\n\tts.Close()\n\n\topts := LoadConfig(conf)\n\tif s, err := NewServer(opts); err == nil || !strings.Contains(err.Error(), \"could not fetch\") {\n\t\tif s != nil {\n\t\t\ts.Shutdown()\n\t\t}\n\t\tt.Fatalf(\"Expected error regarding account resolver, got %v\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tProcessor: func(result *v1.DispatchReachableResourcesResponse) (*v1.DispatchReachableResourcesResponse, bool, error) {\n\t\t\t\t\t// If the context has been closed, nothing more to do.\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\treturn nil, false, ctx.Err()\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t}\n\n\t\t\t\t\t// If we've exhausted the limit of resources to be returned, nothing more to do.\n\t\t\t\t\tif ci.limits.hasExhaustedLimit() {\n\t\t\t\t\t\treturn nil, false, nil\n\t\t\t\t\t}\n\n\t\t\t\t\t// Map the found resources via the subject+resources used for dispatching, to determine\n\t\t\t\t\t// if any need to be made conditional due to caveats.\n\t\t\t\t\tmappedResource, err := foundResources.mapFoundResource(result.Resource, entrypoint.IsDirectResult())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, false, err\n\t\t\t\t\t}\n\n\t\t\t\t\tokay, done := ci.limits.prepareForPublishing()\n\t\t\t\t\tdefer done()\n\n\t\t\t\t\tif !okay {\n\t\t\t\t\t\treturn nil, false, nil\n\t\t\t\t\t}\n\n\t\t\t\t\t// The cursor for the response is that of the parent response + the cursor from the result itself.\n\t\t\t\t\tafterResponseCursor, err := combineCursors(\n\t\t\t\t\t\tci.responsePartialCursor(),\n\t\t\t\t\t\tresult.AfterResponseCursor,\n\t\t\t\t\t)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, false, err\n\t\t\t\t\t}\n\n\t\t\t\t\tresp := &v1.DispatchReachableResourcesResponse{\n\t\t\t\t\t\tResource:            mappedResource,\n\t\t\t\t\t\tMetadata:            addCallToResponseMetadata(result.Metadata),\n\t\t\t\t\t\tAfterResponseCursor: afterResponseCursor,\n\t\t\t\t\t}\n\t\t\t\t\treturn resp, true, nil\n\t\t\t\t},", "is_vulnerable": 1}
{"code": "func TestSearch_PrefixSearch_Namespace_ACL(t *testing.T) {\n\tci.Parallel(t)\n\n\ts, root, cleanup := TestACLServer(t, func(c *Config) {\n\t\tc.NumSchedulers = 0\n\t})\n\tdefer cleanup()\n\n\tcodec := rpcClient(t, s)\n\ttestutil.WaitForLeader(t, s.RPC)\n\tstore := s.fsm.State()\n\n\tns := mock.Namespace()\n\tmust.NoError(t, store.UpsertNamespaces(500, []*structs.Namespace{ns}))\n\n\tjob1 := mock.Job()\n\tmust.NoError(t, store.UpsertJob(structs.MsgTypeTestSetup, 502, nil, job1))\n\n\tjob2 := mock.Job()\n\tjob2.Namespace = ns.Name\n\tmust.NoError(t, store.UpsertJob(structs.MsgTypeTestSetup, 504, nil, job2))\n\n\tnode := mock.Node()\n\tmust.NoError(t, store.UpsertNode(structs.MsgTypeTestSetup, 1001, node))\n\n\treq := &structs.SearchRequest{\n\t\tPrefix:  \"\",\n\t\tContext: structs.Jobs,\n\t\tQueryOptions: structs.QueryOptions{\n\t\t\tRegion:    \"global\",\n\t\t\tNamespace: job1.Namespace,\n\t\t},\n\t}\n\n\t// Try without a token and expect failure\n\t{\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with an invalid token and expect failure\n\t{\n\t\tinvalidToken := mock.CreatePolicyAndToken(t, store, 1003, \"test-invalid\",\n\t\t\tmock.NamespacePolicy(structs.DefaultNamespace, \"\", []string{acl.NamespaceCapabilityListJobs}))\n\t\treq.AuthToken = invalidToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with a node:read token and expect failure due to Namespaces being the context\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, store, 1005, \"test-invalid2\", mock.NodePolicy(acl.PolicyRead))\n\t\treq.Context = structs.Namespaces\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\terr := msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp)\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t}\n\n\t// Try with a node:read token and expect success due to All context\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, store, 1007, \"test-valid\", mock.NodePolicy(acl.PolicyRead))\n\t\treq.Context = structs.All\n\t\treq.AuthToken = validToken.SecretID\n\t\tvar resp structs.SearchResponse\n\t\tmust.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\t\tmust.Eq(t, uint64(1001), resp.Index)\n\t\tmust.Eq(t, []string{node.ID}, resp.Matches[structs.Nodes])\n\n\t\t// Jobs filtered out since token only has access to node:read\n\t\tmust.SliceEmpty(t, resp.Matches[structs.Jobs])\n\t}\n\n\t// Try with a valid token for non-default namespace:read-job\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, store, 1009, \"test-valid2\",\n\t\t\tmock.NamespacePolicy(job2.Namespace, \"\", []string{acl.NamespaceCapabilityReadJob}))\n\t\treq.Context = structs.All\n\t\treq.AuthToken = validToken.SecretID\n\t\treq.Namespace = job2.Namespace\n\t\tvar resp structs.SearchResponse\n\t\tmust.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\n\t\tmust.Eq(t, []string{job2.ID}, resp.Matches[structs.Jobs])\n\t\tmust.Eq(t, []string{ns.Name}, resp.Matches[structs.Namespaces])\n\n\t\t// Index of job - not node - because node context is filtered out\n\t\tmust.Eq(t, uint64(504), resp.Index)\n\n\t\t// Nodes filtered out since token only has access to namespace:read-job\n\t\tmust.SliceEmpty(t, resp.Matches[structs.Nodes])\n\t}\n\n\t// Try with a valid token for node:read and default namespace:read-job\n\t{\n\t\tvalidToken := mock.CreatePolicyAndToken(t, store, 1011, \"test-valid3\", strings.Join([]string{\n\t\t\tmock.NamespacePolicy(structs.DefaultNamespace, \"\", []string{acl.NamespaceCapabilityReadJob}),\n\t\t\tmock.NodePolicy(acl.PolicyRead),\n\t\t}, \"\\n\"))\n\t\treq.Context = structs.All\n\t\treq.AuthToken = validToken.SecretID\n\t\treq.Namespace = structs.DefaultNamespace\n\t\tvar resp structs.SearchResponse\n\t\tmust.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\n\t\tmust.Eq(t, []string{job1.ID}, resp.Matches[structs.Jobs])\n\t\tmust.Eq(t, []string{node.ID}, resp.Matches[structs.Nodes])\n\t\tmust.Eq(t, []string{\"default\"}, resp.Matches[structs.Namespaces])\n\n\t\tmust.Eq(t, uint64(1001), resp.Index)\n\n\t}\n\n\t// Try with a management token\n\t{\n\t\treq.Context = structs.All\n\t\treq.AuthToken = root.SecretID\n\t\treq.Namespace = structs.DefaultNamespace\n\t\tvar resp structs.SearchResponse\n\t\tmust.NoError(t, msgpackrpc.CallWithCodec(codec, \"Search.PrefixSearch\", req, &resp))\n\n\t\tmust.Eq(t, []string{job1.ID}, resp.Matches[structs.Jobs])\n\t\tmust.Eq(t, []string{node.ID}, resp.Matches[structs.Nodes])\n\t\tmust.Eq(t, []string{\"default\", ns.Name}, resp.Matches[structs.Namespaces])\n\n\t\tmust.Eq(t, uint64(1001), resp.Index)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockAuthorizeRequester) GetSession() fosite.Session {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetSession\")\n\tret0, _ := ret[0].(fosite.Session)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func GenerateLeafCertWithExpiration(subject string, oidcIssuer string, expiration time.Time,\n\tpriv *ecdsa.PrivateKey,\n\tparentTemplate *x509.Certificate, parentPriv crypto.Signer) (*x509.Certificate, error) {\n\tcertTemplate := &x509.Certificate{\n\t\tSerialNumber:   big.NewInt(1),\n\t\tEmailAddresses: []string{subject},\n\t\tNotBefore:      expiration,\n\t\tNotAfter:       expiration.Add(10 * time.Minute),\n\t\tKeyUsage:       x509.KeyUsageDigitalSignature,\n\t\tExtKeyUsage:    []x509.ExtKeyUsage{x509.ExtKeyUsageCodeSigning},\n\t\tIsCA:           false,\n\t\tExtraExtensions: []pkix.Extension{{\n\t\t\t// OID for OIDC Issuer extension\n\t\t\tId:       asn1.ObjectIdentifier{1, 3, 6, 1, 4, 1, 57264, 1, 1},\n\t\t\tCritical: false,\n\t\t\tValue:    []byte(oidcIssuer),\n\t\t},\n\t\t},\n\t}\n\n\tcert, err := createCertificate(certTemplate, parentTemplate, &priv.PublicKey, parentPriv)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn cert, nil\n}", "is_vulnerable": 0}
{"code": "\tgo func() {\n\t\terr := metrics.ListenAndServe()\n\t\tif err != http.ErrServerClosed {\n\t\t\tfmt.Fprintf(os.Stderr, \"could not start healthz/metrics http server: %s\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func (s *CipherState) Decrypt(out, ad, ciphertext []byte) ([]byte, error) {\n\tif s.invalid {\n\t\treturn nil, ErrCipherSuiteCopied\n\t}\n\tif s.n > MaxNonce {\n\t\treturn nil, ErrMaxNonce\n\t}\n\tout, err := s.c.Decrypt(out, s.n, ad, ciphertext)\n\ts.n++\n\treturn out, err\n}", "is_vulnerable": 1}
{"code": "func NewErrorTranslateSampleAndChunkQueryable(q storage.SampleAndChunkQueryable) storage.SampleAndChunkQueryable {\n\treturn NewErrorTranslateSampleAndChunkQueryableWithFn(q, TranslateToPromqlAPIError)\n}", "is_vulnerable": 0}
{"code": "func TestGitGetter_GitHubDetector(t *testing.T) {\n\tcases := []struct {\n\t\tInput  string\n\t\tOutput string\n\t}{\n\t\t// HTTP\n\t\t{\"github.com/hashicorp/foo\", \"https://github.com/hashicorp/foo.git\"},\n\t\t{\"github.com/hashicorp/foo.git\", \"https://github.com/hashicorp/foo.git\"},\n\t\t{\n\t\t\t\"github.com/hashicorp/foo/bar\",\n\t\t\t\"https://github.com/hashicorp/foo.git//bar\",\n\t\t},\n\t\t{\n\t\t\t\"github.com/hashicorp/foo?foo=bar\",\n\t\t\t\"https://github.com/hashicorp/foo.git?foo=bar\",\n\t\t},\n\t\t{\n\t\t\t\"github.com/hashicorp/foo.git?foo=bar\",\n\t\t\t\"https://github.com/hashicorp/foo.git?foo=bar\",\n\t\t},\n\t}\n\n\tpwd := \"/pwd\"\n\tf := &GitGetter{[]Detector{\n\t\tnew(GitDetector),\n\t\tnew(BitBucketDetector),\n\t\tnew(GitHubDetector),\n\t},\n\t}\n\tfor i, tc := range cases {\n\t\treq := &Request{\n\t\t\tSrc: tc.Input,\n\t\t\tPwd: pwd,\n\t\t}\n\t\tok, err := Detect(req, f)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"err: %s\", err)\n\t\t}\n\t\tif !ok {\n\t\t\tt.Fatal(\"not ok\")\n\t\t}\n\n\t\tif req.Src != tc.Output {\n\t\t\tt.Fatalf(\"%d: bad: %#v\", i, req.Src)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func newTestUnixFS() (*testUnixFS, error) {\n\ttmpDir, err := os.MkdirTemp(os.TempDir(), \"ufs\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\troot := filepath.Join(tmpDir, \"root\")\n\tif err := os.Mkdir(root, 0o755); err != nil {\n\t\treturn nil, err\n\t}\n\t// TODO: test both disabled and enabled.\n\tfs, err := ufs.NewUnixFS(root, false)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttfs := &testUnixFS{\n\t\tUnixFS: fs,\n\t\tTmpDir: tmpDir,\n\t\tRoot:   root,\n\t}\n\treturn tfs, nil\n}", "is_vulnerable": 0}
{"code": "func (c *CommonController) checkAdminWriteRequest(group string) bool {\n\tif group != \"administrator\" && c.checkWriteRequest(c.Ctx.Request.RequestURI) {\n\t\tc.SetJsonData(ResultDataStruct{Status: -1, Msg: \"user group : [ \" + group + \" ] no authority\", Data: nil})\n\t\tc.StopServeJSON()\n\t\treturn false\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (rfs *rootFs) CreateServerFile(p string, c []byte) error {\n\tf, err := os.Create(filepath.Join(rfs.root, \"/server\", p))\n\n\tif err == nil {\n\t\tf.Write(c)\n\t\tf.Close()\n\t}\n\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (u userService) UpdatePassword(input UpdateUserPasswordInput) error {\n\tuser, err := u.repository.FindByUsername(input.Username)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !utils.PasswordsMatch(user.Password, input.OldPassword) {\n\t\treturn ErrInvalidPassword\n\t}\n\n\tpasswordHash, err := utils.HashAndSalt(input.NewPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\tuser.Password = passwordHash\n\treturn u.repository.Update(user)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) KillJob(ctx context.Context, in *clientpb.KillJobReq, opts ...grpc.CallOption) (*clientpb.KillJob, error) {\n\tout := new(clientpb.KillJob)\n\terr := c.cc.Invoke(ctx, SliverRPC_KillJob_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func NewMetaSyncer(logger log.Logger, reg prometheus.Registerer, bkt objstore.Bucket, fetcher block.MetadataFetcher, duplicateBlocksFilter block.DeduplicateFilter, ignoreDeletionMarkFilter *block.IgnoreDeletionMarkFilter, blocksMarkedForDeletion, garbageCollectedBlocks prometheus.Counter) (*Syncer, error) {\n\treturn NewMetaSyncerWithMetrics(logger, NewSyncerMetrics(reg, blocksMarkedForDeletion, garbageCollectedBlocks), bkt, fetcher, duplicateBlocksFilter, ignoreDeletionMarkFilter)\n}", "is_vulnerable": 0}
{"code": "func (p Precompile) Validator(\n\tctx sdk.Context,\n\tmethod *abi.Method,\n\t_ *vm.Contract,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewValidatorRequest(args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: p.stakingKeeper.Keeper}\n\n\tres, err := queryServer.Validator(sdk.WrapSDKContext(ctx), req)\n\tif err != nil {\n\t\t// return empty validator info if the validator is not found\n\t\texpError := fmt.Sprintf(\"validator %s not found\", req.ValidatorAddr)\n\t\tif strings.Contains(err.Error(), expError) {\n\t\t\treturn method.Outputs.Pack(DefaultValidatorOutput().Validator)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tout := new(ValidatorOutput).FromResponse(res)\n\n\treturn method.Outputs.Pack(out.Validator)\n}", "is_vulnerable": 0}
{"code": "func TestTokenGenerateAndValidate(t *testing.T) {\n\texpectedUserName := \"system:serviceaccount:test:my-service-account\"\n\texpectedUserUID := \"12345\"\n\n\t// Related API objects\n\tserviceAccount := &v1.ServiceAccount{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-service-account\",\n\t\t\tUID:       \"12345\",\n\t\t\tNamespace: \"test\",\n\t\t},\n\t}\n\trsaSecret := &v1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-rsa-secret\",\n\t\t\tNamespace: \"test\",\n\t\t},\n\t}\n\tinvalidAutoSecret := &v1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-rsa-secret\",\n\t\t\tNamespace: \"test\",\n\t\t\tLabels: map[string]string{\n\t\t\t\t\"kubernetes.io/legacy-token-invalid-since\": \"2022-12-20\",\n\t\t\t},\n\t\t},\n\t}\n\tecdsaSecret := &v1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      \"my-ecdsa-secret\",\n\t\t\tNamespace: \"test\",\n\t\t},\n\t}\n\n\t// Generate the RSA token\n\trsaGenerator, err := serviceaccount.JWTTokenGenerator(serviceaccount.LegacyIssuer, getPrivateKey(rsaPrivateKey))\n\tif err != nil {\n\t\tt.Fatalf(\"error making generator: %v\", err)\n\t}\n\trsaToken, err := rsaGenerator.GenerateToken(serviceaccount.LegacyClaims(*serviceAccount, *rsaSecret))\n\tif err != nil {\n\t\tt.Fatalf(\"error generating token: %v\", err)\n\t}\n\tif len(rsaToken) == 0 {\n\t\tt.Fatalf(\"no token generated\")\n\t}\n\trsaSecret.Data = map[string][]byte{\n\t\t\"token\": []byte(rsaToken),\n\t}\n\n\tcheckJSONWebSignatureHasKeyID(t, rsaToken, rsaKeyID)\n\n\t// Generate RSA token with invalidAutoSecret\n\tinvalidAutoSecretToken, err := rsaGenerator.GenerateToken(serviceaccount.LegacyClaims(*serviceAccount, *invalidAutoSecret))\n\tif err != nil {\n\t\tt.Fatalf(\"error generating token: %v\", err)\n\t}\n\tif len(invalidAutoSecretToken) == 0 {\n\t\tt.Fatalf(\"no token generated\")\n\t}\n\tinvalidAutoSecret.Data = map[string][]byte{\n\t\t\"token\": []byte(invalidAutoSecretToken),\n\t}\n\n\tcheckJSONWebSignatureHasKeyID(t, invalidAutoSecretToken, rsaKeyID)\n\n\t// Generate the ECDSA token\n\tecdsaToken := generateECDSAToken(t, serviceaccount.LegacyIssuer, serviceAccount, ecdsaSecret)\n\n\tecdsaSecret.Data = map[string][]byte{\n\t\t\"token\": []byte(ecdsaToken),\n\t}\n\n\tcheckJSONWebSignatureHasKeyID(t, ecdsaToken, ecdsaKeyID)\n\n\tecdsaTokenMalformedIss := generateECDSATokenWithMalformedIss(t, serviceAccount, ecdsaSecret)\n\n\t// Generate signer with same keys as RSA signer but different unrecognized issuer\n\tbadIssuerGenerator, err := serviceaccount.JWTTokenGenerator(\"foo\", getPrivateKey(rsaPrivateKey))\n\tif err != nil {\n\t\tt.Fatalf(\"error making generator: %v\", err)\n\t}\n\tbadIssuerToken, err := badIssuerGenerator.GenerateToken(serviceaccount.LegacyClaims(*serviceAccount, *rsaSecret))\n\tif err != nil {\n\t\tt.Fatalf(\"error generating token: %v\", err)\n\t}\n\n\t// Generate signer with same keys as RSA signer but different recognized issuer\n\tdifferentIssuerGenerator, err := serviceaccount.JWTTokenGenerator(\"bar\", getPrivateKey(rsaPrivateKey))\n\tif err != nil {\n\t\tt.Fatalf(\"error making generator: %v\", err)\n\t}\n\tdifferentIssuerToken, err := differentIssuerGenerator.GenerateToken(serviceaccount.LegacyClaims(*serviceAccount, *rsaSecret))\n\tif err != nil {\n\t\tt.Fatalf(\"error generating token: %v\", err)\n\t}\n\n\ttestCases := map[string]struct {\n\t\tClient clientset.Interface\n\t\tKeys   []interface{}\n\t\tToken  string\n\n\t\tExpectedErr      bool\n\t\tExpectedOK       bool\n\t\tExpectedUserName string\n\t\tExpectedUserUID  string\n\t\tExpectedGroups   []string\n\t}{\n\t\t\"no keys\": {\n\t\t\tToken:       rsaToken,\n\t\t\tClient:      nil,\n\t\t\tKeys:        []interface{}{},\n\t\t\tExpectedErr: false,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"invalid keys (rsa)\": {\n\t\t\tToken:       rsaToken,\n\t\t\tClient:      nil,\n\t\t\tKeys:        []interface{}{getPublicKey(otherPublicKey), getPublicKey(ecdsaPublicKey)},\n\t\t\tExpectedErr: true,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"invalid keys (ecdsa)\": {\n\t\t\tToken:       ecdsaToken,\n\t\t\tClient:      nil,\n\t\t\tKeys:        []interface{}{getPublicKey(otherPublicKey), getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr: true,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"valid key (rsa)\": {\n\t\t\tToken:            rsaToken,\n\t\t\tClient:           nil,\n\t\t\tKeys:             []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"valid key, invalid issuer (rsa)\": {\n\t\t\tToken:       badIssuerToken,\n\t\t\tClient:      nil,\n\t\t\tKeys:        []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr: false,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"valid key, different issuer (rsa)\": {\n\t\t\tToken:            differentIssuerToken,\n\t\t\tClient:           nil,\n\t\t\tKeys:             []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"valid key (ecdsa)\": {\n\t\t\tToken:            ecdsaToken,\n\t\t\tClient:           nil,\n\t\t\tKeys:             []interface{}{getPublicKey(ecdsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"rotated keys (rsa)\": {\n\t\t\tToken:            rsaToken,\n\t\t\tClient:           nil,\n\t\t\tKeys:             []interface{}{getPublicKey(otherPublicKey), getPublicKey(ecdsaPublicKey), getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"rotated keys (ecdsa)\": {\n\t\t\tToken:            ecdsaToken,\n\t\t\tClient:           nil,\n\t\t\tKeys:             []interface{}{getPublicKey(otherPublicKey), getPublicKey(rsaPublicKey), getPublicKey(ecdsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"valid lookup\": {\n\t\t\tToken:            rsaToken,\n\t\t\tClient:           fake.NewSimpleClientset(serviceAccount, rsaSecret, ecdsaSecret),\n\t\t\tKeys:             []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr:      false,\n\t\t\tExpectedOK:       true,\n\t\t\tExpectedUserName: expectedUserName,\n\t\t\tExpectedUserUID:  expectedUserUID,\n\t\t\tExpectedGroups:   []string{\"system:serviceaccounts\", \"system:serviceaccounts:test\"},\n\t\t},\n\t\t\"invalid secret lookup\": {\n\t\t\tToken:       rsaToken,\n\t\t\tClient:      fake.NewSimpleClientset(serviceAccount),\n\t\t\tKeys:        []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr: true,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"invalid serviceaccount lookup\": {\n\t\t\tToken:       rsaToken,\n\t\t\tClient:      fake.NewSimpleClientset(rsaSecret, ecdsaSecret),\n\t\t\tKeys:        []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr: true,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t\t\"secret is marked as invalid\": {\n\t\t\tToken:       invalidAutoSecretToken,\n\t\t\tClient:      fake.NewSimpleClientset(serviceAccount, invalidAutoSecret),\n\t\t\tKeys:        []interface{}{getPublicKey(rsaPublicKey)},\n\t\t\tExpectedErr: true,\n\t\t},\n\t\t\"malformed iss\": {\n\t\t\tToken:       ecdsaTokenMalformedIss,\n\t\t\tClient:      nil,\n\t\t\tKeys:        []interface{}{getPublicKey(ecdsaPublicKey)},\n\t\t\tExpectedErr: false,\n\t\t\tExpectedOK:  false,\n\t\t},\n\t}\n\n\tfor k, tc := range testCases {\n\t\tauds := authenticator.Audiences{\"api\"}\n\t\tgetter := serviceaccountcontroller.NewGetterFromClient(\n\t\t\ttc.Client,\n\t\t\tv1listers.NewSecretLister(newIndexer(func(namespace, name string) (interface{}, error) {\n\t\t\t\treturn tc.Client.CoreV1().Secrets(namespace).Get(context.TODO(), name, metav1.GetOptions{})\n\t\t\t})),\n\t\t\tv1listers.NewServiceAccountLister(newIndexer(func(namespace, name string) (interface{}, error) {\n\t\t\t\treturn tc.Client.CoreV1().ServiceAccounts(namespace).Get(context.TODO(), name, metav1.GetOptions{})\n\t\t\t})),\n\t\t\tv1listers.NewPodLister(newIndexer(func(namespace, name string) (interface{}, error) {\n\t\t\t\treturn tc.Client.CoreV1().Pods(namespace).Get(context.TODO(), name, metav1.GetOptions{})\n\t\t\t})),\n\t\t\tv1listers.NewNodeLister(newIndexer(func(_, name string) (interface{}, error) {\n\t\t\t\treturn tc.Client.CoreV1().Nodes().Get(context.TODO(), name, metav1.GetOptions{})\n\t\t\t})),\n\t\t)\n\t\tvar secretsWriter typedv1core.SecretsGetter\n\t\tif tc.Client != nil {\n\t\t\tsecretsWriter = tc.Client.CoreV1()\n\t\t}\n\t\tvalidator, err := serviceaccount.NewLegacyValidator(tc.Client != nil, getter, secretsWriter)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"While creating legacy validator, err: %v\", err)\n\t\t}\n\t\tauthn := serviceaccount.JWTTokenAuthenticator([]string{serviceaccount.LegacyIssuer, \"bar\"}, tc.Keys, auds, validator)\n\n\t\t// An invalid, non-JWT token should always fail\n\t\tctx := authenticator.WithAudiences(context.Background(), auds)\n\t\tif _, ok, err := authn.AuthenticateToken(ctx, \"invalid token\"); err != nil || ok {\n\t\t\tt.Errorf(\"%s: Expected err=nil, ok=false for non-JWT token\", k)\n\t\t\tcontinue\n\t\t}\n\n\t\tresp, ok, err := authn.AuthenticateToken(ctx, tc.Token)\n\t\tif (err != nil) != tc.ExpectedErr {\n\t\t\tt.Errorf(\"%s: Expected error=%v, got %v\", k, tc.ExpectedErr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif ok != tc.ExpectedOK {\n\t\t\tt.Errorf(\"%s: Expected ok=%v, got %v\", k, tc.ExpectedOK, ok)\n\t\t\tcontinue\n\t\t}\n\n\t\tif err != nil || !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\tif resp.User.GetName() != tc.ExpectedUserName {\n\t\t\tt.Errorf(\"%s: Expected username=%v, got %v\", k, tc.ExpectedUserName, resp.User.GetName())\n\t\t\tcontinue\n\t\t}\n\t\tif resp.User.GetUID() != tc.ExpectedUserUID {\n\t\t\tt.Errorf(\"%s: Expected userUID=%v, got %v\", k, tc.ExpectedUserUID, resp.User.GetUID())\n\t\t\tcontinue\n\t\t}\n\t\tif !reflect.DeepEqual(resp.User.GetGroups(), tc.ExpectedGroups) {\n\t\t\tt.Errorf(\"%s: Expected groups=%v, got %v\", k, tc.ExpectedGroups, resp.User.GetGroups())\n\t\t\tcontinue\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "\tRun: func(command *cobra.Command, args []string) {\n\t\tcmd.CheckArgs(0, 1, command, args)\n\t\tif rcflags.Opt.Enabled {\n\t\t\tlog.Fatalf(\"Don't supply --rc flag when using rcd\")\n\t\t}\n\n\t\t// Start the rc\n\t\trcflags.Opt.Enabled = true\n\t\tif len(args) > 0 {\n\t\t\trcflags.Opt.Files = args[0]\n\t\t}\n\n\t\tif rcflags.Opt.WebUI {\n\t\t\tif err := checkRelease(rcflags.Opt.WebGUIUpdate); err != nil {\n\t\t\t\tlog.Fatalf(\"Error while fetching the latest release of rclone-webui-react %v\", err)\n\t\t\t}\n\t\t\tif rcflags.Opt.NoAuth {\n\t\t\t\trcflags.Opt.NoAuth = false\n\t\t\t\tfs.Infof(nil, \"Cannot run web-gui without authentication, using default auth\")\n\t\t\t}\n\t\t\tif rcflags.Opt.HTTPOptions.BasicUser == \"\" {\n\t\t\t\trcflags.Opt.HTTPOptions.BasicUser = \"gui\"\n\t\t\t\tfs.Infof(\"Using default username: %s \\n\", rcflags.Opt.HTTPOptions.BasicUser)\n\t\t\t}\n\t\t\tif rcflags.Opt.HTTPOptions.BasicPass == \"\" {\n\t\t\t\trandomPass := random.String(16)\n\t\t\t\trcflags.Opt.HTTPOptions.BasicPass = randomPass\n\t\t\t\tfs.Infof(\"No password specified. Using random password: %s \\n\", randomPass)\n\t\t\t}\n\t\t\trcflags.Opt.Serve = true\n\t\t}\n\n\t\ts, err := rcserver.Start(&rcflags.Opt)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Failed to start remote control: %v\", err)\n\t\t}\n\t\tif s == nil {\n\t\t\tlog.Fatal(\"rc server not configured\")\n\t\t}\n\n\t\ts.Wait()\n\t},", "is_vulnerable": 1}
{"code": "func (a *awsLambda) PatchCluster(_ *extensioncommon.RuntimeConfig, c *envoy_cluster_v3.Cluster) (*envoy_cluster_v3.Cluster, bool, error) {\n\t// Only patch outbound clusters.\n\tif extensioncommon.IsLocalAppCluster(c) {\n\t\treturn c, false, nil\n\t}\n\n\ttransportSocket, err := extensioncommon.MakeUpstreamTLSTransportSocket(&envoy_tls_v3.UpstreamTlsContext{\n\t\tSni: \"*.amazonaws.com\",\n\t})\n\n\tif err != nil {\n\t\treturn c, false, fmt.Errorf(\"failed to make transport socket: %w\", err)\n\t}\n\n\t// Use the aws SDK to parse the ARN so that we can later extract the region\n\tparsedARN, err := arn_sdk.Parse(a.ARN)\n\tif err != nil {\n\t\treturn c, false, err\n\t}\n\n\tcluster := &envoy_cluster_v3.Cluster{\n\t\tName:                 c.Name,\n\t\tConnectTimeout:       c.ConnectTimeout,\n\t\tClusterDiscoveryType: &envoy_cluster_v3.Cluster_Type{Type: envoy_cluster_v3.Cluster_LOGICAL_DNS},\n\t\tDnsLookupFamily:      envoy_cluster_v3.Cluster_V4_ONLY,\n\t\tLbPolicy:             envoy_cluster_v3.Cluster_ROUND_ROBIN,\n\t\tMetadata: &envoy_core_v3.Metadata{\n\t\t\tFilterMetadata: map[string]*pstruct.Struct{\n\t\t\t\t\"com.amazonaws.lambda\": {\n\t\t\t\t\tFields: map[string]*pstruct.Value{\n\t\t\t\t\t\t\"egress_gateway\": {Kind: &pstruct.Value_BoolValue{BoolValue: true}},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tLoadAssignment: &envoy_endpoint_v3.ClusterLoadAssignment{\n\t\t\tClusterName: c.Name,\n\t\t\tEndpoints: []*envoy_endpoint_v3.LocalityLbEndpoints{\n\t\t\t\t{\n\t\t\t\t\tLbEndpoints: []*envoy_endpoint_v3.LbEndpoint{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tHostIdentifier: &envoy_endpoint_v3.LbEndpoint_Endpoint{\n\t\t\t\t\t\t\t\tEndpoint: &envoy_endpoint_v3.Endpoint{\n\t\t\t\t\t\t\t\t\tAddress: &envoy_core_v3.Address{\n\t\t\t\t\t\t\t\t\t\tAddress: &envoy_core_v3.Address_SocketAddress{\n\t\t\t\t\t\t\t\t\t\t\tSocketAddress: &envoy_core_v3.SocketAddress{\n\t\t\t\t\t\t\t\t\t\t\t\tAddress: fmt.Sprintf(\"lambda.%s.amazonaws.com\", parsedARN.Region),\n\t\t\t\t\t\t\t\t\t\t\t\tPortSpecifier: &envoy_core_v3.SocketAddress_PortValue{\n\t\t\t\t\t\t\t\t\t\t\t\t\tPortValue: 443,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tTransportSocket: transportSocket,\n\t}\n\treturn cluster, true, nil\n}", "is_vulnerable": 0}
{"code": "func Exactly(t TestingT, expected interface{}, actual interface{}, msgAndArgs ...interface{}) {\n\tif assert.Exactly(t, expected, actual, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (client DeploymentsClient) CheckExistence(ctx context.Context, resourceGroupName string, deploymentName string) (result autorest.Response, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.DeploymentsClient\", \"CheckExistence\", err.Error())\n\t}\n\n\treq, err := client.CheckExistencePreparer(ctx, resourceGroupName, deploymentName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.CheckExistenceSender(req)\n\tif err != nil {\n\t\tresult.Response = resp\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.CheckExistenceResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentsClient\", \"CheckExistence\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "\t\treturn middleware.ResponderFunc(func(w http.ResponseWriter, p runtime.Producer) {\n\t\t\tcookie := restapi.NewSessionCookieForConsole(loginResponse.SessionID)\n\t\t\thttp.SetCookie(w, &cookie)\n\t\t\tuser_api.NewLoginOperatorNoContent().WriteResponse(w, p)\n\t\t})", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tif err := os.RemoveAll(buildDir); err != nil {\n\t\t\tt.Fatalf(\"failed to clean up temp dir: %v\", err)\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func main() {\n\t// command line arguments\n\tport := flag.Int(\"port\", 8080, \"Port number to serve default backend 404 page.\")\n\thealthPort := flag.Int(\"svc-port\", 10254, \"Port number to serve /healthz and /metrics.\")\n\n\ttimeout := flag.Duration(\"timeout\", 5*time.Second, \"Time in seconds to wait before forcefully terminating the server.\")\n\n\tflag.Parse()\n\n\tnotFound := newHTTPServer(fmt.Sprintf(\":%d\", *port), notFound())\n\tmetrics := newHTTPServer(fmt.Sprintf(\":%d\", *healthPort), metrics())\n\n\t// start the the healthz and metrics http server\n\tgo func() {\n\t\terr := metrics.ListenAndServe()\n\t\tif err != http.ErrServerClosed {\n\t\t\tfmt.Fprintf(os.Stderr, \"could not start healthz/metrics http server: %s\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}()\n\n\t// start the main http server\n\tgo func() {\n\t\terr := notFound.ListenAndServe()\n\t\tif err != http.ErrServerClosed {\n\t\t\tfmt.Fprintf(os.Stderr, \"could not start http server: %s\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}()\n\n\twaitShutdown(notFound, *timeout)\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) GreaterOrEqual(e1 interface{}, e2 interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tGreaterOrEqual(a.t, e1, e2, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func (k *Key) IsQualified() bool {\n\treturn C.key_is_qualified(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Generate(ctx context.Context, in *clientpb.GenerateReq, opts ...grpc.CallOption) (*clientpb.Generate, error) {\n\tout := new(clientpb.Generate)\n\terr := c.cc.Invoke(ctx, SliverRPC_Generate_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "\t\tsc.defaultHandler = routing.Wrap(func(c *models.ReqContext) response.Response {\n\t\t\tc.Req.Body = mockRequestBody(cmd)\n\t\t\tc.Req.Header.Add(\"Content-Type\", \"application/json\")\n\t\t\tsc.context = c\n\t\t\tsc.context.UserId = testUserID\n\t\t\tsc.context.OrgId = testOrgID\n\t\t\tsc.context.OrgRole = role\n\n\t\t\treturn hs.AdminUpdateUserPermissions(c)\n\t\t})\n\n\t\tsc.m.Put(routePattern, sc.defaultHandler)\n\n\t\tfn(sc)\n\t})", "is_vulnerable": 0}
{"code": "\tr.NoRoute(func(c *gin.Context) {\n\t\tcommon.Log.Infof(\"A 404 error occurred, but the specific URL path is not logged to prevent log injection.\")\n\t\tc.Redirect(http.StatusMovedPermanently, \"/\")\n\t})", "is_vulnerable": 0}
{"code": "func Test_UpdateSettings(t *testing.T) {\n\ttestutil.UnitTest(t)\n\tdi.TestInit(t)\n\n\tt.Run(\"all settings\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tsettings := lsp.Settings{\n\t\t\tActivateSnykOpenSource:      \"false\",\n\t\t\tActivateSnykCode:            \"false\",\n\t\t\tActivateSnykIac:             \"false\",\n\t\t\tInsecure:                    \"true\",\n\t\t\tEndpoint:                    \"https://snyk.io/api\",\n\t\t\tAdditionalParams:            \"--all-projects -d\",\n\t\t\tAdditionalEnv:               \"a=b;c=d\",\n\t\t\tPath:                        \"addPath\",\n\t\t\tSendErrorReports:            \"true\",\n\t\t\tOrganization:                \"org\",\n\t\t\tEnableTelemetry:             \"false\",\n\t\t\tManageBinariesAutomatically: \"false\",\n\t\t\tCliPath:                     \"C:\\\\Users\\\\CliPath\\\\snyk-ls.exe\",\n\t\t\tToken:                       \"a fancy token\",\n\t\t\tTrustedFolders:              []string{\"trustedPath1\", \"trustedPath2\"},\n\t\t}\n\n\t\tUpdateSettings(context.Background(), settings)\n\n\t\tc := config.CurrentConfig()\n\t\tassert.Equal(t, false, c.IsSnykCodeEnabled())\n\t\tassert.Equal(t, false, c.IsSnykOssEnabled())\n\t\tassert.Equal(t, false, c.IsSnykIacEnabled())\n\t\tassert.Equal(t, true, c.CliSettings().Insecure)\n\t\tassert.Equal(t, []string{\"--all-projects\", \"-d\"}, c.CliSettings().AdditionalParameters)\n\t\tassert.Equal(t, \"https://snyk.io/api\", c.SnykApi())\n\t\tassert.Equal(t, \"b\", os.Getenv(\"a\"))\n\t\tassert.Equal(t, \"d\", os.Getenv(\"c\"))\n\t\tassert.True(t, strings.Contains(os.Getenv(\"PATH\"), \"addPath\"))\n\t\tassert.True(t, c.IsErrorReportingEnabled())\n\t\tassert.Equal(t, \"org\", c.GetOrganization())\n\t\tassert.False(t, c.IsTelemetryEnabled())\n\t\tassert.False(t, c.ManageBinariesAutomatically())\n\t\tassert.Equal(t, \"C:\\\\Users\\\\CliPath\\\\snyk-ls.exe\", c.CliSettings().Path())\n\t\tassert.Equal(t, \"a fancy token\", c.Token())\n\t\tassert.Contains(t, c.TrustedFolders(), \"trustedPath1\")\n\t\tassert.Contains(t, c.TrustedFolders(), \"trustedPath2\")\n\t})\n\n\tt.Run(\"blank organisation is ignored\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tUpdateSettings(context.Background(), lsp.Settings{Organization: \" \"})\n\n\t\tc := config.CurrentConfig()\n\t\tassert.Equal(t, \"\", c.GetOrganization())\n\t})\n\n\tt.Run(\"incomplete env vars\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tUpdateSettings(context.Background(), lsp.Settings{AdditionalEnv: \"a=\"})\n\n\t\tassert.Empty(t, os.Getenv(\"a\"))\n\t})\n\n\tt.Run(\"empty env vars\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tUpdateSettings(context.Background(), lsp.Settings{AdditionalEnv: \" \"})\n\n\t\tassert.Empty(t, os.Getenv(\"a\"))\n\t})\n\n\tt.Run(\"broken env variables\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tUpdateSettings(context.Background(), lsp.Settings{AdditionalEnv: \"a=; b\"})\n\n\t\tc := config.CurrentConfig()\n\t\tassert.Equal(t, \"\", c.GetOrganization())\n\t\tassert.Empty(t, os.Getenv(\"a\"))\n\t\tassert.Empty(t, os.Getenv(\"b\"))\n\t\tassert.Empty(t, os.Getenv(\";\"))\n\t})\n\tt.Run(\"trusted folders\", func(t *testing.T) {\n\t\tconfig.SetCurrentConfig(config.New())\n\n\t\tUpdateSettings(context.Background(), lsp.Settings{TrustedFolders: []string{\"/a/b\", \"/b/c\"}})\n\n\t\tc := config.CurrentConfig()\n\t\tassert.Contains(t, c.TrustedFolders(), \"/a/b\")\n\t\tassert.Contains(t, c.TrustedFolders(), \"/b/c\")\n\t})\n\n\tt.Run(\"manage binaries automatically\", func(t *testing.T) {\n\t\tt.Run(\"true\", func(t *testing.T) {\n\t\t\tUpdateSettings(context.Background(), lsp.Settings{\n\t\t\t\tManageBinariesAutomatically: \"true\",\n\t\t\t})\n\n\t\t\tassert.True(t, config.CurrentConfig().ManageBinariesAutomatically())\n\t\t})\n\t\tt.Run(\"false\", func(t *testing.T) {\n\t\t\tUpdateSettings(context.Background(), lsp.Settings{\n\t\t\t\tManageBinariesAutomatically: \"false\",\n\t\t\t})\n\n\t\t\tassert.False(t, config.CurrentConfig().ManageBinariesAutomatically())\n\t\t})\n\t\tt.Run(\"invalid value does not update\", func(t *testing.T) {\n\t\t\tUpdateSettings(context.Background(), lsp.Settings{\n\t\t\t\tManageBinariesAutomatically: \"true\",\n\t\t\t})\n\n\t\t\tUpdateSettings(context.Background(), lsp.Settings{\n\t\t\t\tManageBinariesAutomatically: \"dog\",\n\t\t\t})\n\n\t\t\tassert.True(t, config.CurrentConfig().ManageBinariesAutomatically())\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (iv *imageVerifier) verifyAttestors(\n\tattestors []kyvernov1.AttestorSet,\n\timageVerify kyvernov1.ImageVerification,\n\timageInfo apiutils.ImageInfo,\n\tpredicateType string,\n) (*response.RuleResponse, *cosign.Response) {\n\tvar cosignResponse *cosign.Response\n\timage := imageInfo.String()\n\n\tfor i, attestorSet := range attestors {\n\t\tvar err error\n\t\tpath := fmt.Sprintf(\".attestors[%d]\", i)\n\t\tiv.logger.V(4).Info(\"verifying attestors\", \"path\", path)\n\t\tcosignResponse, err = iv.verifyAttestorSet(attestorSet, imageVerify, imageInfo, path, predicateType)\n\t\tif err != nil {\n\t\t\tiv.logger.Error(err, \"failed to verify image\")\n\t\t\treturn iv.handleRegistryErrors(image, err), nil\n\t\t}\n\t}\n\n\tif cosignResponse == nil {\n\t\treturn ruleError(iv.rule, response.ImageVerify, \"invalid response\", fmt.Errorf(\"nil\")), nil\n\t}\n\n\tmsg := fmt.Sprintf(\"verified image signatures for %s\", image)\n\treturn ruleResponse(*iv.rule, response.ImageVerify, msg, response.RuleStatusPass, nil), cosignResponse\n}", "is_vulnerable": 1}
{"code": "func (m *CustomNameNinEmbeddedStructUnion) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNinEmbeddedStructUnion: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameNinEmbeddedStructUnion: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NidOptNative\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NidOptNative == nil {\n\t\t\t\tm.NidOptNative = &NidOptNative{}\n\t\t\t}\n\t\t\tif err := m.NidOptNative.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 200:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldA\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.FieldA == nil {\n\t\t\t\tm.FieldA = &NinOptNative{}\n\t\t\t}\n\t\t\tif err := m.FieldA.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 210:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldB\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.FieldB = &b\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (r *Router) ServeHTTP(rw http.ResponseWriter, req *http.Request) {\n\tif t, ok := r.routers[req.Method]; ok {\n\t\t// Fast match for static routes\n\t\tleaf := r.getLeaf(req.Method, req.URL.Path)\n\t\tif leaf != nil {\n\t\t\tleaf.handle(rw, req, nil)\n\t\t\treturn\n\t\t}\n\n\t\th, p, ok := t.Match(req.URL.EscapedPath())\n\t\tif ok {\n\t\t\tif splat, ok := p[\"*0\"]; ok {\n\t\t\t\tp[\"*\"] = splat // Easy name.\n\t\t\t}\n\t\t\th(rw, req, p)\n\t\t\treturn\n\t\t}\n\t}\n\n\tr.notFound(rw, req)\n}", "is_vulnerable": 1}
{"code": "func FuzzFromBytes(f *testing.F) {\n\tf.Fuzz(func(_ *testing.T, size int, bytes []byte) {\n\t\tif size > 1<<20 { // We relly on consumers for limit checks, hopefully they understand that a New... factory allocates memory.\n\t\t\treturn\n\t\t}\n\t\tFromBytes(size, bytes)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (mr *MockRequesterMockRecorder) AppendRequestedScope(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AppendRequestedScope\", reflect.TypeOf((*MockRequester)(nil).AppendRequestedScope), arg0)\n}", "is_vulnerable": 0}
{"code": "func (config *DirectClientConfig) getUserIdentificationPartialConfig(configAuthInfo clientcmdapi.AuthInfo, fallbackReader io.Reader, persistAuthConfig restclient.AuthProviderConfigPersister) (*restclient.Config, error) {\n\tmergedConfig := &restclient.Config{}\n\n\t// blindly overwrite existing values based on precedence\n\tif len(configAuthInfo.Token) > 0 {\n\t\tmergedConfig.BearerToken = configAuthInfo.Token\n\t} else if len(configAuthInfo.TokenFile) > 0 {\n\t\tts := restclient.NewCachedFileTokenSource(configAuthInfo.TokenFile)\n\t\tif _, err := ts.Token(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tmergedConfig.WrapTransport = restclient.TokenSourceWrapTransport(ts)\n\t}\n\tif len(configAuthInfo.Impersonate) > 0 {\n\t\tmergedConfig.Impersonate = restclient.ImpersonationConfig{\n\t\t\tUserName: configAuthInfo.Impersonate,\n\t\t\tGroups:   configAuthInfo.ImpersonateGroups,\n\t\t\tExtra:    configAuthInfo.ImpersonateUserExtra,\n\t\t}\n\t}\n\tif len(configAuthInfo.ClientCertificate) > 0 || len(configAuthInfo.ClientCertificateData) > 0 {\n\t\tmergedConfig.CertFile = configAuthInfo.ClientCertificate\n\t\tmergedConfig.CertData = configAuthInfo.ClientCertificateData\n\t\tmergedConfig.KeyFile = configAuthInfo.ClientKey\n\t\tmergedConfig.KeyData = configAuthInfo.ClientKeyData\n\t}\n\tif len(configAuthInfo.Username) > 0 || len(configAuthInfo.Password) > 0 {\n\t\tmergedConfig.Username = configAuthInfo.Username\n\t\tmergedConfig.Password = configAuthInfo.Password\n\t}\n\tif configAuthInfo.AuthProvider != nil {\n\t\tmergedConfig.AuthProvider = configAuthInfo.AuthProvider\n\t\tmergedConfig.AuthConfigPersister = persistAuthConfig\n\t}\n\tif configAuthInfo.Exec != nil {\n\t\tmergedConfig.ExecProvider = configAuthInfo.Exec\n\t}\n\n\t// if there still isn't enough information to authenticate the user, try prompting\n\tif !canIdentifyUser(*mergedConfig) && (fallbackReader != nil) {\n\t\tif len(config.promptedCredentials.username) > 0 && len(config.promptedCredentials.password) > 0 {\n\t\t\tmergedConfig.Username = config.promptedCredentials.username\n\t\t\tmergedConfig.Password = config.promptedCredentials.password\n\t\t\treturn mergedConfig, nil\n\t\t}\n\t\tprompter := NewPromptingAuthLoader(fallbackReader)\n\t\tpromptedAuthInfo, err := prompter.Prompt()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tpromptedConfig := makeUserIdentificationConfig(*promptedAuthInfo)\n\t\tpreviouslyMergedConfig := mergedConfig\n\t\tmergedConfig = &restclient.Config{}\n\t\tmergo.MergeWithOverwrite(mergedConfig, promptedConfig)\n\t\tmergo.MergeWithOverwrite(mergedConfig, previouslyMergedConfig)\n\t\tconfig.promptedCredentials.username = mergedConfig.Username\n\t\tconfig.promptedCredentials.password = mergedConfig.Password\n\t}\n\n\treturn mergedConfig, nil\n}", "is_vulnerable": 1}
{"code": "\t\tGetHostCheckers: func() ([]ssh.PublicKey, error) {\n\t\t\treturn trustedKeys, nil\n\t\t},", "is_vulnerable": 0}
{"code": "\thttp.HandleFunc(path.Join(*routePrefix, \"/probe\"), func(w http.ResponseWriter, r *http.Request) {\n\t\tsc.Lock()\n\t\tconf := sc.C\n\t\tsc.Unlock()\n\t\tprober.Handler(w, r, conf, logger, rh, *timeoutOffset, nil, moduleUnknownCounter, logLevelProber)\n\t})", "is_vulnerable": 0}
{"code": "func (cr *chunkedReader) beginChunk() {\n\t// chunk-size CRLF\n\tvar line []byte\n\tline, cr.err = readChunkLine(cr.r)\n\tif cr.err != nil {\n\t\treturn\n\t}\n\tcr.excess += int64(len(line)) + 2 // header, plus \\r\\n after the chunk data\n\tline = trimTrailingWhitespace(line)\n\tline, cr.err = removeChunkExtension(line)\n\tif cr.err != nil {\n\t\treturn\n\t}\n\tcr.n, cr.err = parseHexUint(line)\n\tif cr.err != nil {\n\t\treturn\n\t}\n\t// A sender who sends one byte per chunk will send 5 bytes of overhead\n\t// for every byte of data. (\"1\\r\\nX\\r\\n\" to send \"X\".)\n\t// We want to allow this, since streaming a byte at a time can be legitimate.\n\t//\n\t// A sender can use chunk extensions to add arbitrary amounts of additional\n\t// data per byte read. (\"1;very long extension\\r\\nX\\r\\n\" to send \"X\".)\n\t// We don't want to disallow extensions (although we discard them),\n\t// but we also don't want to allow a sender to reduce the signal/noise ratio\n\t// arbitrarily.\n\t//\n\t// We track the amount of excess overhead read,\n\t// and produce an error if it grows too large.\n\t//\n\t// Currently, we say that we're willing to accept 16 bytes of overhead per chunk,\n\t// plus twice the amount of real data in the chunk.\n\tcr.excess -= 16 + (2 * int64(cr.n))\n\tif cr.excess < 0 {\n\t\tcr.excess = 0\n\t}\n\tif cr.excess > 16*1024 {\n\t\tcr.err = errors.New(\"chunked encoding contains too much non-data\")\n\t}\n\tif cr.n == 0 {\n\t\tcr.err = io.EOF\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t *SingleResolver) TenantID(ctx context.Context) (string, error) {\n\t//lint:ignore faillint wrapper around upstream method\n\treturn user.ExtractOrgID(ctx)\n}", "is_vulnerable": 1}
{"code": "func (e *Engine) getConnectConfig(ctx context.Context, sessionCtx *common.Session) (*pgconn.Config, error) {\n\t// The driver requires the config to be built by parsing the connection\n\t// string so parse the basic template and then fill in the rest of\n\t// parameters such as TLS configuration.\n\tconfig, err := pgconn.ParseConfig(fmt.Sprintf(\"postgres://%s\", sessionCtx.Server.GetURI()))\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tconfig.User = sessionCtx.DatabaseUser\n\tconfig.Database = sessionCtx.DatabaseName\n\t// Pgconn adds fallbacks to retry connection without TLS if the TLS\n\t// attempt fails. Reset the fallbacks to avoid retries, otherwise\n\t// it's impossible to debug TLS connection errors.\n\tconfig.Fallbacks = nil\n\t// Set startup parameters that the client sent us.\n\tconfig.RuntimeParams = sessionCtx.StartupParameters\n\t// AWS RDS/Aurora and GCP Cloud SQL use IAM authentication so request an\n\t// auth token and use it as a password.\n\tswitch sessionCtx.Server.GetType() {\n\tcase types.DatabaseTypeRDS:\n\t\tconfig.Password, err = e.Auth.GetRDSAuthToken(sessionCtx)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\tcase types.DatabaseTypeRedshift:\n\t\tconfig.User, config.Password, err = e.Auth.GetRedshiftAuthToken(sessionCtx)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\tcase types.DatabaseTypeCloudSQL:\n\t\tconfig.Password, err = e.Auth.GetCloudSQLAuthToken(ctx, sessionCtx)\n\t\tif err != nil {\n\t\t\treturn nil, trace.Wrap(err)\n\t\t}\n\t}\n\t// TLS config will use client certificate for an onprem database or\n\t// will contain RDS root certificate for RDS/Aurora.\n\tconfig.TLSConfig, err = e.Auth.GetTLSConfig(ctx, sessionCtx)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\treturn config, nil\n}", "is_vulnerable": 0}
{"code": "func TestListObjects_Unoptimized_UnhappyPaths(t *testing.T) {\n\tctx := context.Background()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgav1.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: parser.MustParse(`\n\t\ttype user\n\n\t\ttype repo\n\t\t  relations\n\t\t    define allowed: [user] as self\n\t\t    define viewer: [user] as self and allowed\n\t\t`),\n\t}, nil)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, gomock.Any()).AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := MustNewServerWithOpts(\n\t\tWithDatastore(mockDatastore),\n\t)\n\n\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\tres, err := s.ListObjects(ctx, &openfgav1.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"repo\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t})\n\n\t\trequire.Nil(t, res)\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgav1.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"repo\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t}, NewMockStreamServer())\n\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeCodeStrategy) ValidateAuthorizeCode(arg0 context.Context, arg1 fosite.Requester, arg2 string) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"ValidateAuthorizeCode\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (t *Teler) checkCommonWebAttack(r *http.Request) error {\n\t// Decode the URL-encoded and unescape HTML entities in the\n\t// request URI of the URL then remove all special characters\n\turi := removeSpecialChars(stringDeUnescape(r.URL.RequestURI()))\n\n\t// Declare byte slice for request body.\n\tvar body string\n\n\t// Initialize buffer to hold request body.\n\tbuf := &bytes.Buffer{}\n\n\t// Use io.Copy to copy the request body to the buffer.\n\t_, err := io.Copy(buf, r.Body)\n\tif err == nil {\n\t\t// If the read not fails, replace the request body\n\t\t// with a new io.ReadCloser that reads from the buffer.\n\t\tr.Body = io.NopCloser(buf)\n\n\t\t// Convert the buffer to a string.\n\t\tbody = buf.String()\n\t}\n\n\t// Decode the URL-encoded and unescape HTML entities in the\n\t// body of request then remove all special characters\n\tbody = removeSpecialChars(stringDeUnescape(body))\n\n\t// Check if the request is in cache\n\tkey := uri + body\n\tif err, ok := t.getCache(key); ok {\n\t\treturn err\n\t}\n\n\t// Iterate over the filters in the CommonWebAttack data stored in the t.threat.cwa.Filters field\n\tfor _, filter := range t.threat.cwa.Filters {\n\t\t// Initialize a variable to track whether a match is found\n\t\tvar match bool\n\n\t\t// Check the type of the filter's pattern\n\t\tswitch pattern := filter.pattern.(type) {\n\t\tcase *regexp.Regexp: // If the pattern is a regex\n\t\t\tmatch = pattern.MatchString(uri) || pattern.MatchString(body)\n\t\tcase *pcre.Matcher: // If the pattern is a PCRE expr\n\t\t\tmatch = pattern.MatchString(uri, 0) || pattern.MatchString(body, 0)\n\t\tdefault: // If the pattern is of an unknown type, skip to the next iteration\n\t\t\tcontinue\n\t\t}\n\n\t\t// If the pattern matches the request URI or body, cache the request\n\t\t// and return an error indicating a common web attack has been detected\n\t\tif match {\n\t\t\tt.setCache(key, filter.Description)\n\t\t\treturn errors.New(filter.Description)\n\t\t}\n\t}\n\n\t// Cache the request\n\tt.setCache(key, \"\")\n\n\t// Return nil if no match is found\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (v RSAVerifier) Blind(random io.Reader, message []byte) ([]byte, blindsign.VerifierState, error) {\n\tif random == nil {\n\t\treturn nil, nil, ErrInvalidRandomness\n\t}\n\n\tsalt := make([]byte, v.hash.Size())\n\t_, err := io.ReadFull(random, salt)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tr, rInv, err := generateBlindingFactor(random, v.pk)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn fixedBlind(message, salt, r, rInv, v.pk, v.hash)\n}", "is_vulnerable": 0}
{"code": "func (t *TeamGuardianMock) CanAdmin(ctx context.Context, orgId int64, teamId int64, user *models.SignedInUser) error {\n\treturn t.result\n}", "is_vulnerable": 0}
{"code": "func (engine *EngineOperations) CleanupContainer(fatal error, status syscall.WaitStatus) error {\n\tsylog.Debugf(\"Cleanup container\")\n\n\tif engine.EngineConfig.GetDeleteImage() {\n\t\timage := engine.EngineConfig.GetImage()\n\t\tsylog.Verbosef(\"Removing image %s\", image)\n\t\tsylog.Infof(\"Cleaning up image...\")\n\t\tif err := os.RemoveAll(image); err != nil {\n\t\t\tsylog.Errorf(\"failed to delete container image %s: %s\", image, err)\n\t\t}\n\t}\n\n\tif engine.EngineConfig.Network != nil {\n\t\tif err := engine.EngineConfig.Network.DelNetworks(); err != nil {\n\t\t\tsylog.Errorf(\"%s\", err)\n\t\t}\n\t}\n\n\tif engine.EngineConfig.Cgroups != nil {\n\t\tif err := engine.EngineConfig.Cgroups.Remove(); err != nil {\n\t\t\tsylog.Errorf(\"%s\", err)\n\t\t}\n\t}\n\n\tif engine.EngineConfig.GetInstance() {\n\t\tuid := os.Getuid()\n\n\t\tfile, err := instance.Get(engine.CommonConfig.ContainerID, instance.SingSubDir)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif file.PPid != os.Getpid() {\n\t\t\treturn nil\n\t\t}\n\n\t\tif file.Privileged {\n\t\t\tvar err error\n\n\t\t\tmainthread.Execute(func() {\n\t\t\t\tif err = syscall.Setresuid(0, 0, uid); err != nil {\n\t\t\t\t\terr = fmt.Errorf(\"failed to escalate privileges\")\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tdefer syscall.Setresuid(uid, uid, 0)\n\n\t\t\t\tif err = file.Delete(); err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t})\n\t\t\treturn err\n\t\t}\n\t\treturn file.Delete()\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func NewGrant(a Authorization, expiration time.Time) (Grant, error) {\n\tg := Grant{\n\t\tExpiration: expiration,\n\t}\n\tmsg, ok := a.(proto.Message)\n\tif !ok {\n\t\treturn Grant{}, sdkerrors.Wrapf(sdkerrors.ErrPackAny, \"cannot proto marshal %T\", a)\n\t}\n\n\tany, err := cdctypes.NewAnyWithValue(msg)\n\tif err != nil {\n\t\treturn Grant{}, err\n\t}\n\tg.Authorization = any\n\n\treturn g, nil\n}", "is_vulnerable": 1}
{"code": "func TestInteractionHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an interaction event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an interaction action message\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tactionString := `{\"type\":\"block_actions\",\"team\":{\"id\":\"T9TK3CUKW\",\"domain\":\"example\"},\"user\":{\"id\":\"UA8RXUSPL\",\"username\":\"jtorrance\",\"team_id\":\"T9TK3CUKW\"},\"api_app_id\":\"AABA1ABCD\",\"token\":\"9s8d9as89d8as9d8as989\",\"container\":{\"type\":\"message_attachment\",\"message_ts\":\"1548261231.000200\",\"attachment_id\":1,\"channel_id\":\"CBR2V3XEX\",\"is_ephemeral\":false,\"is_app_unfurl\":false},\"trigger_id\":\"12321423423.333649436676.d8c1bb837935619ccad0f624c448ffb3\",\"channel\":{\"id\":\"CBR2V3XEX\",\"name\":\"review-updates\"},\"message\":{\"bot_id\":\"BAH5CA16Z\",\"type\":\"message\",\"text\":\"This content can't be displayed.\",\"user\":\"UAJ2RU415\",\"ts\":\"1548261231.000200\"},\"response_url\":\"https://hooks.slack.com/actions/AABA1ABCD/1232321423432/D09sSasdasdAS9091209\",\"actions\":[{\"action_id\":\"WaXA\",\"block_id\":\"=qXel\",\"text\":{\"type\":\"plain_text\",\"text\":\"View\",\"emoji\":true},\"value\":\"click_me_123\",\"type\":\"button\",\"action_ts\":\"1548426417.840180\"}]}`\n\t\t\tpayload := []byte(`payload=` + actionString)\n\t\t\tout := make(chan []byte)\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\tout <- <-router.route.DataCh\n\t\t\t}()\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tbuf.Write(payload)\n\n\t\t\theaders := make(map[string][]string)\n\t\t\theaders[\"Content-Type\"] = append(headers[\"Content-Type\"], \"application/x-www-form-urlencoded\")\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tMethod: http.MethodPost,\n\t\t\t\tHeader: headers,\n\t\t\t\tBody:   io.NopCloser(strings.NewReader(buf.String())),\n\t\t\t})\n\t\t\tresult := <-out\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusOK)\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"type\\\":\\\"block_actions\\\"\")\n\t\t\tconvey.So(string(result), convey.ShouldContainSubstring, \"\\\"token\\\":\\\"9s8d9as89d8as9d8as989\\\"\")\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (e *Engine) NotifyNewBlocks(blks []blocks.Block) {\n\tif len(blks) == 0 {\n\t\treturn\n\t}\n\n\t// Get the size of each block\n\tblockSizes := make(map[cid.Cid]int, len(blks))\n\tfor _, blk := range blks {\n\t\tblockSizes[blk.Cid()] = len(blk.RawData())\n\t}\n\n\t// Check each peer to see if it wants one of the blocks we received\n\tvar work bool\n\tmissingWants := make(map[peer.ID][]cid.Cid)\n\tfor _, b := range blks {\n\t\tk := b.Cid()\n\n\t\te.lock.RLock()\n\t\tpeers := e.peerLedger.Peers(k)\n\t\te.lock.RUnlock()\n\n\t\tfor _, p := range peers {\n\t\t\te.lock.RLock()\n\t\t\tledger, ok := e.ledgerMap[p]\n\t\t\te.lock.RUnlock()\n\n\t\t\tif !ok {\n\t\t\t\t// This can happen if the peer has disconnected while we're processing this list.\n\t\t\t\tlog.Debugw(\"failed to find peer in ledger\", \"peer\", p)\n\t\t\t\tmissingWants[p] = append(missingWants[p], k)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tledger.lk.RLock()\n\t\t\tentry, ok := ledger.WantListContains(k)\n\t\t\tledger.lk.RUnlock()\n\t\t\tif !ok {\n\t\t\t\t// This can happen if the peer has canceled their want while we're processing this message.\n\t\t\t\tlog.Debugw(\"wantlist index doesn't match peer's wantlist\", \"peer\", p)\n\t\t\t\tmissingWants[p] = append(missingWants[p], k)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\twork = true\n\n\t\t\tblockSize := blockSizes[k]\n\t\t\tisWantBlock := e.sendAsBlock(entry.WantType, blockSize)\n\n\t\t\tentrySize := blockSize\n\t\t\tif !isWantBlock {\n\t\t\t\tentrySize = bsmsg.BlockPresenceSize(k)\n\t\t\t}\n\n\t\t\te.peerRequestQueue.PushTasks(p, peertask.Task{\n\t\t\t\tTopic:    entry.Cid,\n\t\t\t\tPriority: int(entry.Priority),\n\t\t\t\tWork:     entrySize,\n\t\t\t\tData: &taskData{\n\t\t\t\t\tBlockSize:    blockSize,\n\t\t\t\t\tHaveBlock:    true,\n\t\t\t\t\tIsWantBlock:  isWantBlock,\n\t\t\t\t\tSendDontHave: false,\n\t\t\t\t},\n\t\t\t})\n\t\t\te.updateMetrics()\n\t\t}\n\t}\n\n\t// If we found missing wants (e.g., because the peer disconnected, we have some races here)\n\t// remove them from the list. Unfortunately, we still have to re-check because the user\n\t// could have re-connected in the meantime.\n\tif len(missingWants) > 0 {\n\t\te.lock.Lock()\n\t\tfor p, wl := range missingWants {\n\t\t\tif ledger, ok := e.ledgerMap[p]; ok {\n\t\t\t\tledger.lk.RLock()\n\t\t\t\tfor _, k := range wl {\n\t\t\t\t\tif _, has := ledger.WantListContains(k); has {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\te.peerLedger.CancelWant(p, k)\n\t\t\t\t}\n\t\t\t\tledger.lk.RUnlock()\n\t\t\t} else {\n\t\t\t\tfor _, k := range wl {\n\t\t\t\t\te.peerLedger.CancelWant(p, k)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\te.lock.Unlock()\n\t}\n\n\tif work {\n\t\te.signalNewWork()\n\t}\n}", "is_vulnerable": 1}
{"code": "func (rt *bearerAuthRoundTripper) RoundTrip(req *http.Request) (*http.Response, error) {\n\tif len(req.Header.Get(\"Authorization\")) != 0 {\n\t\treturn rt.rt.RoundTrip(req)\n\t}\n\n\treq = utilnet.CloneRequest(req)\n\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", rt.bearer))\n\treturn rt.rt.RoundTrip(req)\n}", "is_vulnerable": 1}
{"code": "func TestGetDynamic(t *testing.T) {\n\tsavedServices := services\n\tsavedGetVCSDirFn := getVCSDirFn\n\tdefer func() {\n\t\tservices = savedServices\n\t\tgetVCSDirFn = savedGetVCSDirFn\n\t}()\n\tservices = []*service{{pattern: regexp.MustCompile(\".*\"), get: testGet}}\n\tgetVCSDirFn = testGet\n\tclient := &http.Client{Transport: testTransport(testWeb)}\n\n\tfor _, tt := range getDynamicTests {\n\t\tdir, err := getDynamic(context.Background(), client, tt.importPath, \"\")\n\n\t\tif tt.dir == nil {\n\t\t\tif err == nil {\n\t\t\t\tt.Errorf(\"getDynamic(ctx, client, %q, etag) did not return expected error\", tt.importPath)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif err != nil {\n\t\t\tt.Errorf(\"getDynamic(ctx, client, %q, etag) return unexpected error: %v\", tt.importPath, err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !cmp.Equal(dir, tt.dir) {\n\t\t\tt.Errorf(\"getDynamic(client, %q, etag) =\\n     %+v,\\nwant %+v\", tt.importPath, dir, tt.dir)\n\t\t\tfor i, f := range dir.Files {\n\t\t\t\tvar want *File\n\t\t\t\tif i < len(tt.dir.Files) {\n\t\t\t\t\twant = tt.dir.Files[i]\n\t\t\t\t}\n\t\t\t\tt.Errorf(\"file %d = %+v, want %+v\", i, f, want)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (odr *testOdr) Retrieve(ctx context.Context, req OdrRequest) error {\n\tif odr.disable {\n\t\treturn ErrOdrDisabled\n\t}\n\tswitch req := req.(type) {\n\tcase *BlockRequest:\n\t\tnumber := rawdb.ReadHeaderNumber(odr.sdb, req.Hash)\n\t\tif number != nil {\n\t\t\treq.Rlp = rawdb.ReadBodyRLP(odr.sdb, req.Hash, *number)\n\t\t}\n\tcase *ReceiptsRequest:\n\t\tnumber := rawdb.ReadHeaderNumber(odr.sdb, req.Hash)\n\t\tif number != nil {\n\t\t\treq.Receipts = rawdb.ReadRawReceipts(odr.sdb, req.Hash, *number)\n\t\t}\n\tcase *TrieRequest:\n\t\tt, _ := trie.New(req.Id.Root, trie.NewDatabase(odr.sdb))\n\t\tnodes := NewNodeSet()\n\t\tt.Prove(req.Key, 0, nodes)\n\t\treq.Proof = nodes\n\tcase *CodeRequest:\n\t\treq.Data = rawdb.ReadCode(odr.sdb, req.Hash)\n\t}\n\treq.StoreResult(odr.ldb)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (clients *clientsContainer) handleGetClients(w http.ResponseWriter, r *http.Request) {\n\tdata := clientListJSON{}\n\n\tclients.lock.Lock()\n\tdefer clients.lock.Unlock()\n\n\tfor _, c := range clients.list {\n\t\tcj := clientToJSON(c)\n\t\tdata.Clients = append(data.Clients, cj)\n\t}\n\n\tclients.ipToRC.Range(func(ip net.IP, v any) (cont bool) {\n\t\trc, ok := v.(*RuntimeClient)\n\t\tif !ok {\n\t\t\tlog.Error(\"dns: bad type %T in ipToRC for %s\", v, ip)\n\n\t\t\treturn true\n\t\t}\n\n\t\tcj := runtimeClientJSON{\n\t\t\tWHOISInfo: rc.WHOISInfo,\n\n\t\t\tName:   rc.Host,\n\t\t\tSource: rc.Source,\n\t\t\tIP:     ip,\n\t\t}\n\n\t\tdata.RuntimeClients = append(data.RuntimeClients, cj)\n\n\t\treturn true\n\t})\n\n\tdata.Tags = clientTags\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\te := json.NewEncoder(w).Encode(data)\n\tif e != nil {\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"failed to encode to json: %v\", e)\n\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *CachedCheckResolver) ResolveCheck(\n\tctx context.Context,\n\treq *ResolveCheckRequest,\n) (*ResolveCheckResponse, error) {\n\tctx, span := tracer.Start(ctx, \"ResolveCheck\")\n\tdefer span.End()\n\tspan.SetAttributes(attribute.String(\"resolver_type\", \"CachedCheckResolver\"))\n\tspan.SetAttributes(attribute.String(\"tuple_key\", req.GetTupleKey().String()))\n\n\tcheckCacheTotalCounter.Inc()\n\n\tcacheKey, err := CheckRequestCacheKey(req)\n\tif err != nil {\n\t\tc.logger.Error(\"cache key computation failed with error\", zap.Error(err))\n\t\ttelemetry.TraceError(span, err)\n\t\treturn nil, err\n\t}\n\n\tcachedResp := c.cache.Get(cacheKey)\n\tif cachedResp != nil && !cachedResp.Expired() {\n\t\tcheckCacheHitCounter.Inc()\n\t\tspan.SetAttributes(attribute.Bool(\"is_cached\", true))\n\n\t\treturn cachedResp.Value(), nil\n\t}\n\tspan.SetAttributes(attribute.Bool(\"is_cached\", false))\n\n\tresp, err := c.delegate.ResolveCheck(ctx, req)\n\tif err != nil {\n\t\ttelemetry.TraceError(span, err)\n\t\treturn nil, err\n\t}\n\n\t// the cached subproblem's resolution metadata doesn't necessarily reflect\n\t// the actual number of database reads for the inflight request, so set it\n\t// to 0 so it doesn't bias the resolution metadata negatively\n\tclonedResp := CloneResolveCheckResponse(resp)\n\tclonedResp.ResolutionMetadata.DatastoreQueryCount = 0\n\n\tc.cache.Set(cacheKey, clonedResp, c.cacheTTL)\n\treturn resp, nil\n}", "is_vulnerable": 0}
{"code": "\t\tbackendServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tw.WriteHeader(200)\n\t\t\t_, _ = w.Write([]byte(\"I am the backend\"))\n\t\t\trequestHandled = true\n\t\t}))", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) LootAll(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.AllLoot, error) {\n\tout := new(clientpb.AllLoot)\n\terr := c.cc.Invoke(ctx, SliverRPC_LootAll_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (s *DiscoveryServer) generateRawClusters(node *model.Proxy, push *model.PushContext) []*xdsapi.Cluster {\n\trawClusters := s.ConfigGenerator.BuildClusters(s.Env, node, push)\n\n\tfor _, c := range rawClusters {\n\t\tif err := c.Validate(); err != nil {\n\t\t\tadsLog.Errorf(\"CDS: Generated invalid cluster for node:%s: %v, %v\", node.ID, err, c)\n\t\t\tcdsBuildErrPushes.Increment()\n\t\t\ttotalXDSInternalErrors.Increment()\n\t\t\t// Generating invalid clusters is a bug.\n\t\t\t// Instead of panic, which will break down the whole cluster. Just ignore it here, let envoy process it.\n\t\t}\n\t}\n\treturn rawClusters\n}", "is_vulnerable": 0}
{"code": "func (m *NidRepPackedNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepPackedNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepPackedNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (p *Plugin) validateSubscription(instanceID types.ID, subscription *ChannelSubscription, client Client) error {\n\tif len(subscription.Name) == 0 {\n\t\treturn errors.New(\"please provide a name for the subscription\")\n\t}\n\n\tif len(subscription.Name) > MaxSubscriptionNameLength {\n\t\treturn errors.Errorf(\"please provide a name less than %d characters\", MaxSubscriptionNameLength)\n\t}\n\n\tif len(subscription.Filters.Events) == 0 {\n\t\treturn errors.New(\"please provide at least one event type\")\n\t}\n\n\tif len(subscription.Filters.IssueTypes) == 0 {\n\t\treturn errors.New(\"please provide at least one issue type\")\n\t}\n\n\tif (len(subscription.Filters.Projects)) == 0 {\n\t\treturn errors.New(\"please provide a project identifier\")\n\t}\n\n\tchannelID := subscription.ChannelID\n\tsubs, err := p.getSubscriptionsForChannel(instanceID, channelID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor subID := range subs {\n\t\tif subs[subID].Name == subscription.Name && subs[subID].ID != subscription.ID {\n\t\t\treturn errors.Errorf(\"Subscription name, '%s', already exists. Please choose another name.\", subs[subID].Name)\n\t\t}\n\t}\n\n\tprojectKey := subscription.Filters.Projects.Elems()[0]\n\t_, err = client.GetProject(projectKey)\n\tif err != nil {\n\t\treturn errors.WithMessagef(err, \"failed to get project %q\", projectKey)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (cf *clientsFactory) UpdateNamespaces(ctx context.Context) error {\n\tclients, err := clientsForClusters(cf.clusters.Get())\n\tif err != nil {\n\t\tcf.log.Error(err, \"failed to create clients for\", \"clusters\", cf.clusters.Get())\n\t\treturn err\n\t}\n\n\tcf.syncCaches()\n\n\twg := sync.WaitGroup{}\n\n\tfor clusterName, c := range clients {\n\t\twg.Add(1)\n\n\t\tgo func(clusterName string, c client.Client) {\n\t\t\tdefer wg.Done()\n\n\t\t\tnsList := &v1.NamespaceList{}\n\n\t\t\tif err := c.List(ctx, nsList); err != nil {\n\t\t\t\tcf.log.Error(err, \"failed listing namespaces\", \"cluster\", clusterName)\n\t\t\t}\n\n\t\t\tcf.clustersNamespaces.Set(clusterName, nsList.Items)\n\t\t}(clusterName, c)\n\t}\n\n\twg.Wait()\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func fullTextFilter(_ string, value any) Sqlizer {\n\treturn fullTextExpr(value.(string))\n}", "is_vulnerable": 0}
{"code": "func (client GroupsClient) ListResourcesComplete(ctx context.Context, resourceGroupName string, filter string, expand string, top *int32) (result ListResultIterator, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupsClient.ListResources\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response().Response.Response != nil {\n\t\t\t\tsc = result.page.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tresult.page, err = client.ListResources(ctx, resourceGroupName, filter, expand, top)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (iter *TagsListResultIterator) Next() error {\n\treturn iter.NextWithContext(context.Background())\n}", "is_vulnerable": 0}
{"code": "func TestgetForcedGetter(t *testing.T) {\n\ttype args struct {\n\t\tsrc string\n\t}\n\ttests := []struct {\n\t\tname  string\n\t\targs  args\n\t\twant  string\n\t\twant1 string\n\t}{\n\t\t{\"s3 AWSv1234\",\n\t\t\targs{src: \"s3::https://s3-eu-west-1.amazonaws.com/bucket/foo/bar.baz?version=1234\"},\n\t\t\t\"s3\", \"https://s3-eu-west-1.amazonaws.com/bucket/foo/bar.baz?version=1234\",\n\t\t},\n\t\t{\"s3 localhost-1\",\n\t\t\targs{src: \"s3::http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret&region=us-east-2&version=1\"},\n\t\t\t\"s3\", \"http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret&region=us-east-2&version=1\",\n\t\t},\n\t\t{\"s3 localhost-2\",\n\t\t\targs{src: \"s3::http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret&version=1\"},\n\t\t\t\"s3\", \"http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret&version=1\",\n\t\t},\n\t\t{\"s3 localhost-3\",\n\t\t\targs{src: \"s3::http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret\"},\n\t\t\t\"s3\", \"http://127.0.0.1:9000/test-bucket/hello.txt?aws_access_key_id=TESTID&aws_access_key_secret=TestSecret\",\n\t\t},\n\n\t\t{\n\t\t\t\"gcs test1\",\n\t\t\targs{\"gcs::https://www.googleapis.com/storage/v1/go-getter-test/go-getter/foo/null.zip\"},\n\t\t\t\"gcs\", \"https://www.googleapis.com/storage/v1/go-getter-test/go-getter/foo/null.zip\",\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot, got1 := getForcedGetter(tt.args.src)\n\t\t\tif got != tt.want {\n\t\t\t\tt.Errorf(\"getForcedGetter() got = %v, want %v\", got, tt.want)\n\t\t\t}\n\t\t\tif got1 != tt.want1 {\n\t\t\t\tt.Errorf(\"getForcedGetter() got1 = %v, want %v\", got1, tt.want1)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *Core) handleLoginRequest(ctx context.Context, req *logical.Request) (retResp *logical.Response, retAuth *logical.Auth, retErr error) {\n\tdefer metrics.MeasureSince([]string{\"core\", \"handle_login_request\"}, time.Now())\n\n\treq.Unauthenticated = true\n\n\tvar nonHMACReqDataKeys []string\n\tentry := c.router.MatchingMountEntry(ctx, req.Path)\n\tif entry != nil {\n\t\t// Get and set ignored HMAC'd value.\n\t\tif rawVals, ok := entry.synthesizedConfigCache.Load(\"audit_non_hmac_request_keys\"); ok {\n\t\t\tnonHMACReqDataKeys = rawVals.([]string)\n\t\t}\n\t}\n\n\t// Do an unauth check. This will cause EGP policies to be checked\n\tvar auth *logical.Auth\n\tvar ctErr error\n\tauth, _, ctErr = c.checkToken(ctx, req, true)\n\tif ctErr == logical.ErrPerfStandbyPleaseForward {\n\t\treturn nil, nil, ctErr\n\t}\n\tif ctErr != nil {\n\t\t// If it is an internal error we return that, otherwise we\n\t\t// return invalid request so that the status codes can be correct\n\t\tvar errType error\n\t\tswitch ctErr {\n\t\tcase ErrInternalError, logical.ErrPermissionDenied:\n\t\t\terrType = ctErr\n\t\tdefault:\n\t\t\terrType = logical.ErrInvalidRequest\n\t\t}\n\n\t\tlogInput := &logical.LogInput{\n\t\t\tAuth:               auth,\n\t\t\tRequest:            req,\n\t\t\tOuterErr:           ctErr,\n\t\t\tNonHMACReqDataKeys: nonHMACReqDataKeys,\n\t\t}\n\t\tif err := c.auditBroker.LogRequest(ctx, logInput, c.auditedHeaders); err != nil {\n\t\t\tc.logger.Error(\"failed to audit request\", \"path\", req.Path, \"error\", err)\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\tif errType != nil {\n\t\t\tretErr = multierror.Append(retErr, errType)\n\t\t}\n\t\tif ctErr == ErrInternalError {\n\t\t\treturn nil, auth, retErr\n\t\t}\n\t\treturn logical.ErrorResponse(ctErr.Error()), auth, retErr\n\t}\n\n\t// Create an audit trail of the request. Attach auth if it was returned,\n\t// e.g. if a token was provided.\n\tlogInput := &logical.LogInput{\n\t\tAuth:               auth,\n\t\tRequest:            req,\n\t\tNonHMACReqDataKeys: nonHMACReqDataKeys,\n\t}\n\tif err := c.auditBroker.LogRequest(ctx, logInput, c.auditedHeaders); err != nil {\n\t\tc.logger.Error(\"failed to audit request\", \"path\", req.Path, \"error\", err)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// The token store uses authentication even when creating a new token,\n\t// so it's handled in handleRequest. It should not be reached here.\n\tif strings.HasPrefix(req.Path, \"auth/token/\") {\n\t\tc.logger.Error(\"unexpected login request for token backend\", \"request_path\", req.Path)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// Route the request\n\tresp, routeErr := c.doRouting(ctx, req)\n\tif resp != nil {\n\t\t// If wrapping is used, use the shortest between the request and response\n\t\tvar wrapTTL time.Duration\n\t\tvar wrapFormat, creationPath string\n\t\tvar sealWrap bool\n\n\t\t// Ensure no wrap info information is set other than, possibly, the TTL\n\t\tif resp.WrapInfo != nil {\n\t\t\tif resp.WrapInfo.TTL > 0 {\n\t\t\t\twrapTTL = resp.WrapInfo.TTL\n\t\t\t}\n\t\t\twrapFormat = resp.WrapInfo.Format\n\t\t\tcreationPath = resp.WrapInfo.CreationPath\n\t\t\tsealWrap = resp.WrapInfo.SealWrap\n\t\t\tresp.WrapInfo = nil\n\t\t}\n\n\t\tif req.WrapInfo != nil {\n\t\t\tif req.WrapInfo.TTL > 0 {\n\t\t\t\tswitch {\n\t\t\t\tcase wrapTTL == 0:\n\t\t\t\t\twrapTTL = req.WrapInfo.TTL\n\t\t\t\tcase req.WrapInfo.TTL < wrapTTL:\n\t\t\t\t\twrapTTL = req.WrapInfo.TTL\n\t\t\t\t}\n\t\t\t}\n\t\t\tif req.WrapInfo.Format != \"\" && wrapFormat == \"\" {\n\t\t\t\twrapFormat = req.WrapInfo.Format\n\t\t\t}\n\t\t}\n\n\t\tif wrapTTL > 0 {\n\t\t\tresp.WrapInfo = &wrapping.ResponseWrapInfo{\n\t\t\t\tTTL:          wrapTTL,\n\t\t\t\tFormat:       wrapFormat,\n\t\t\t\tCreationPath: creationPath,\n\t\t\t\tSealWrap:     sealWrap,\n\t\t\t}\n\t\t}\n\t}\n\n\t// A login request should never return a secret!\n\tif resp != nil && resp.Secret != nil {\n\t\tc.logger.Error(\"unexpected Secret response for login path\", \"request_path\", req.Path)\n\t\treturn nil, nil, ErrInternalError\n\t}\n\n\t// If the response generated an authentication, then generate the token\n\tif resp != nil && resp.Auth != nil {\n\n\t\tvar entity *identity.Entity\n\t\tauth = resp.Auth\n\n\t\tmEntry := c.router.MatchingMountEntry(ctx, req.Path)\n\n\t\tif auth.Alias != nil &&\n\t\t\tmEntry != nil &&\n\t\t\t!mEntry.Local &&\n\t\t\tc.identityStore != nil {\n\t\t\t// Overwrite the mount type and mount path in the alias\n\t\t\t// information\n\t\t\tauth.Alias.MountType = req.MountType\n\t\t\tauth.Alias.MountAccessor = req.MountAccessor\n\n\t\t\tif auth.Alias.Name == \"\" {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"missing name in alias\")\n\t\t\t}\n\n\t\t\tvar err error\n\n\t\t\t// Fetch the entity for the alias, or create an entity if one\n\t\t\t// doesn't exist.\n\t\t\tentity, err = c.identityStore.CreateOrFetchEntity(ctx, auth.Alias)\n\t\t\tif err != nil {\n\t\t\t\tentity, err = possiblyForwardAliasCreation(ctx, c, err, auth, entity)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tif entity == nil {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to create an entity for the authenticated alias\")\n\t\t\t}\n\n\t\t\tif entity.Disabled {\n\t\t\t\treturn nil, nil, logical.ErrPermissionDenied\n\t\t\t}\n\n\t\t\tauth.EntityID = entity.ID\n\t\t\tvalidAliases, err := c.identityStore.refreshExternalGroupMembershipsByEntityID(ctx, auth.EntityID, auth.GroupAliases)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tauth.GroupAliases = validAliases\n\t\t}\n\n\t\t// Determine the source of the login\n\t\tsource := c.router.MatchingMount(ctx, req.Path)\n\t\tsource = strings.TrimPrefix(source, credentialRoutePrefix)\n\t\tsource = strings.Replace(source, \"/\", \"-\", -1)\n\n\t\t// Prepend the source to the display name\n\t\tauth.DisplayName = strings.TrimSuffix(source+auth.DisplayName, \"-\")\n\n\t\tsysView := c.router.MatchingSystemView(ctx, req.Path)\n\t\tif sysView == nil {\n\t\t\tc.logger.Error(\"unable to look up sys view for login path\", \"request_path\", req.Path)\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\ttokenTTL, warnings, err := framework.CalculateTTL(sysView, 0, auth.TTL, auth.Period, auth.MaxTTL, auth.ExplicitMaxTTL, time.Time{})\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tfor _, warning := range warnings {\n\t\t\tresp.AddWarning(warning)\n\t\t}\n\n\t\tns, err := namespace.FromContext(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\t_, identityPolicies, err := c.fetchEntityAndDerivedPolicies(ctx, ns, auth.EntityID)\n\t\tif err != nil {\n\t\t\treturn nil, nil, ErrInternalError\n\t\t}\n\n\t\tauth.TokenPolicies = policyutil.SanitizePolicies(auth.Policies, !auth.NoDefaultPolicy)\n\t\tallPolicies := policyutil.SanitizePolicies(append(auth.TokenPolicies, identityPolicies[ns.ID]...), policyutil.DoNotAddDefaultPolicy)\n\n\t\t// Prevent internal policies from being assigned to tokens. We check\n\t\t// this on auth.Policies including derived ones from Identity before\n\t\t// actually making the token.\n\t\tfor _, policy := range allPolicies {\n\t\t\tif policy == \"root\" {\n\t\t\t\treturn logical.ErrorResponse(\"auth methods cannot create root tokens\"), nil, logical.ErrInvalidRequest\n\t\t\t}\n\t\t\tif strutil.StrListContains(nonAssignablePolicies, policy) {\n\t\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"cannot assign policy %q\", policy)), nil, logical.ErrInvalidRequest\n\t\t\t}\n\t\t}\n\n\t\tvar registerFunc RegisterAuthFunc\n\t\tvar funcGetErr error\n\t\t// Batch tokens should not be forwarded to perf standby\n\t\tif auth.TokenType == logical.TokenTypeBatch {\n\t\t\tregisterFunc = c.RegisterAuth\n\t\t} else {\n\t\t\tregisterFunc, funcGetErr = getAuthRegisterFunc(c)\n\t\t}\n\t\tif funcGetErr != nil {\n\t\t\tretErr = multierror.Append(retErr, funcGetErr)\n\t\t\treturn nil, auth, retErr\n\t\t}\n\n\t\terr = registerFunc(ctx, tokenTTL, req.Path, auth)\n\t\tswitch {\n\t\tcase err == nil:\n\t\tcase err == ErrInternalError:\n\t\t\treturn nil, auth, err\n\t\tdefault:\n\t\t\treturn logical.ErrorResponse(err.Error()), auth, logical.ErrInvalidRequest\n\t\t}\n\n\t\tauth.IdentityPolicies = policyutil.SanitizePolicies(identityPolicies[ns.ID], policyutil.DoNotAddDefaultPolicy)\n\t\tdelete(identityPolicies, ns.ID)\n\t\tauth.ExternalNamespacePolicies = identityPolicies\n\t\tauth.Policies = allPolicies\n\n\t\t// Attach the display name, might be used by audit backends\n\t\treq.DisplayName = auth.DisplayName\n\n\t}\n\n\treturn resp, auth, routeErr\n}", "is_vulnerable": 0}
{"code": "func (m *CustomNameCustomType) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameCustomType: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomNameCustomType: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldA\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v Uuid\n\t\t\tm.FieldA = &v\n\t\t\tif err := m.FieldA.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldB\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.FieldB = &v\n\t\t\tif err := m.FieldB.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldC\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v Uuid\n\t\t\tm.FieldC = append(m.FieldC, v)\n\t\t\tif err := m.FieldC[len(m.FieldC)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field FieldD\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.FieldD = append(m.FieldD, v)\n\t\t\tif err := m.FieldD[len(m.FieldD)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *MockCoreStorage) GetAuthorizeCodeSession(arg0 context.Context, arg1 string, arg2 fosite.Session) (fosite.Requester, error) {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetAuthorizeCodeSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(fosite.Requester)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "is_vulnerable": 0}
{"code": "func (t *TestPodLogsServer) SetTrailer(metadata.MD) {\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (s *DiscoveryServer) generateRawListeners(con *XdsConnection, push *model.PushContext) []*xdsapi.Listener {\n\trawListeners := s.ConfigGenerator.BuildListeners(s.Env, con.modelNode, push)\n\n\tfor _, l := range rawListeners {\n\t\tif err := l.Validate(); err != nil {\n\t\t\tretErr := fmt.Errorf(\"LDS: Generated invalid listener for node %v: %v\", con.modelNode, err)\n\t\t\tadsLog.Errorf(\"LDS: Generated invalid listener for node:%s: %v, %v\", con.modelNode.ID, err, l)\n\t\t\tldsBuildErrPushes.Increment()\n\t\t\t// Generating invalid listeners is a bug.\n\t\t\t// Panic instead of trying to recover from that, since we can't\n\t\t\t// assume anything about the state.\n\t\t\tpanic(retErr.Error())\n\t\t}\n\t}\n\treturn rawListeners\n}", "is_vulnerable": 1}
{"code": "func ShouldRejectRequest(url string) bool {\n\tfor _, protectedResource := range protectedResources {\n\t\tif strings.Contains(url, protectedResource.ResourceName) && strings.Contains(url, protectedResource.ResourceNamespace) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (he *HookedWebSocketEvent) Event() *model.WebSocketEvent {\n\tif he.copy == nil {\n\t\treturn he.original\n\t}\n\n\treturn he.copy\n}", "is_vulnerable": 0}
{"code": "func (sp *ServiceProvider) ParseResponse(req *http.Request, possibleRequestIDs []string) (*Assertion, error) {\n\tif artifactID := req.Form.Get(\"SAMLart\"); artifactID != \"\" {\n\t\treturn sp.handleArtifactRequest(req.Context(), artifactID, possibleRequestIDs)\n\t}\n\treturn sp.parseResponseHTTP(req, possibleRequestIDs)\n}", "is_vulnerable": 0}
{"code": "func bindUnmountAllRootfs(ctx context.Context, sharedDir string, sandbox *Sandbox) error {\n\tspan, _ := trace(ctx, \"bindUnmountAllRootfs\")\n\tdefer span.Finish()\n\n\tvar errors *merr.Error\n\tfor _, c := range sandbox.containers {\n\t\tif isSymlink(filepath.Join(sharedDir, c.id)) {\n\t\t\tlogrus.Warnf(\"container dir %s is a symlink, malicious guest?\", c.id)\n\t\t\tcontinue\n\t\t}\n\t\tc.unmountHostMounts()\n\t\tif c.state.Fstype == \"\" {\n\t\t\t// even if error found, don't break out of loop until all mounts attempted\n\t\t\t// to be unmounted, and collect all errors\n\t\t\terrors = merr.Append(errors, bindUnmountContainerRootfs(c.ctx, sharedDir, c.id))\n\t\t}\n\t}\n\treturn errors.ErrorOrNil()\n}", "is_vulnerable": 0}
{"code": "func (c *Context) PinEntryMode() PinEntryMode {\n\treturn PinEntryMode(C.gpgme_get_pinentry_mode(c.ctx))\n}", "is_vulnerable": 1}
{"code": "func newApiServerAuthDelegatorClusterRoleBinding(namespace string) *rbacv1.ClusterRoleBinding {\n\treturn &rbacv1.ClusterRoleBinding{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"ClusterRoleBinding\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: \"kubevirt-apiserver-auth-delegator\",\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: VersionName,\n\t\t\tKind:     \"ClusterRole\",\n\t\t\tName:     \"system:auth-delegator\",\n\t\t},\n\t\tSubjects: []rbacv1.Subject{\n\t\t\t{\n\t\t\t\tKind:      \"ServiceAccount\",\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      ApiServiceAccountName,\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func storeErrorsToRevocationError(err1, err2 error) error {\n\t// both errors are 404 or nil <=> the token is revoked\n\tif (errors.Is(err1, fosite.ErrNotFound) || err1 == nil) && (errors.Is(err2, fosite.ErrNotFound) || err2 == nil) {\n\t\treturn nil\n\t}\n\n\t// there was an unexpected error => the token may still exist and the client should retry later\n\treturn errors.WithStack(fosite.ErrTemporarilyUnavailable)\n}", "is_vulnerable": 0}
{"code": "func (h *ContextHandler) initContextWithBasicAuth(reqContext *models.ReqContext, orgID int64) bool {\n\tif !h.Cfg.BasicAuthEnabled {\n\t\treturn false\n\t}\n\n\theader := reqContext.Req.Header.Get(\"Authorization\")\n\tif header == \"\" {\n\t\treturn false\n\t}\n\n\tctx, span := h.tracer.Start(reqContext.Req.Context(), \"initContextWithBasicAuth\")\n\tdefer span.End()\n\n\tusername, password, err := util.DecodeBasicAuthHeader(header)\n\tif err != nil {\n\t\treqContext.JsonApiErr(401, \"Invalid Basic Auth Header\", err)\n\t\treturn true\n\t}\n\n\tauthQuery := models.LoginUserQuery{\n\t\tUsername: username,\n\t\tPassword: password,\n\t\tCfg:      h.Cfg,\n\t}\n\tif err := h.authenticator.AuthenticateUser(reqContext.Req.Context(), &authQuery); err != nil {\n\t\treqContext.Logger.Debug(\n\t\t\t\"Failed to authorize the user\",\n\t\t\t\"username\", username,\n\t\t\t\"err\", err,\n\t\t)\n\n\t\tif errors.Is(err, user.ErrUserNotFound) {\n\t\t\terr = login.ErrInvalidCredentials\n\t\t}\n\t\treqContext.JsonApiErr(401, InvalidUsernamePassword, err)\n\t\treturn true\n\t}\n\n\tuser := authQuery.User\n\n\tquery := models.GetSignedInUserQuery{UserId: user.ID, OrgId: orgID}\n\tif err := h.SQLStore.GetSignedInUserWithCacheCtx(ctx, &query); err != nil {\n\t\treqContext.Logger.Error(\n\t\t\t\"Failed at user signed in\",\n\t\t\t\"id\", user.ID,\n\t\t\t\"org\", orgID,\n\t\t)\n\t\treqContext.JsonApiErr(401, InvalidUsernamePassword, err)\n\t\treturn true\n\t}\n\n\treqContext.SignedInUser = query.Result\n\treqContext.IsSignedIn = true\n\treturn true\n}", "is_vulnerable": 1}
{"code": "func (iter *GroupListResultIterator) NextWithContext(ctx context.Context) (err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupListResultIterator.NextWithContext\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif iter.Response().Response.Response != nil {\n\t\t\t\tsc = iter.Response().Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\titer.i++\n\tif iter.i < len(iter.page.Values()) {\n\t\treturn nil\n\t}\n\terr = iter.page.NextWithContext(ctx)\n\tif err != nil {\n\t\titer.i--\n\t\treturn err\n\t}\n\titer.i = 0\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (t *TestServerStream) SetTrailer(metadata.MD) {\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (t *Trashcan) Archive(filePath string) error {\n\t_, err := osutil.Lstat(filePath)\n\tif os.IsNotExist(err) {\n\t\tl.Debugln(\"not archiving nonexistent file\", filePath)\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tversionsDir := filepath.Join(t.folderPath, \".stversions\")\n\tif _, err := os.Stat(versionsDir); err != nil {\n\t\tif !os.IsNotExist(err) {\n\t\t\treturn err\n\t\t}\n\n\t\tl.Debugln(\"creating versions dir\", versionsDir)\n\t\tif err := osutil.MkdirAll(versionsDir, 0777); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tosutil.HideFile(versionsDir)\n\t}\n\n\tl.Debugln(\"archiving\", filePath)\n\n\trelativePath, err := filepath.Rel(t.folderPath, filePath)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tarchivedPath := filepath.Join(versionsDir, relativePath)\n\tif err := osutil.MkdirAll(filepath.Dir(archivedPath), 0777); err != nil && !os.IsExist(err) {\n\t\treturn err\n\t}\n\n\tl.Debugln(\"moving to\", archivedPath)\n\n\tif err := osutil.Rename(filePath, archivedPath); err != nil {\n\t\treturn err\n\t}\n\n\t// Set the mtime to the time the file was deleted. This is used by the\n\t// cleanout routine. If this fails things won't work optimally but there's\n\t// not much we can do about it so we ignore the error.\n\tos.Chtimes(archivedPath, time.Now(), time.Now())\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (client GroupsClient) ExportTemplate(ctx context.Context, resourceGroupName string, parameters ExportTemplateRequest) (result GroupExportResult, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.GroupsClient\", \"ExportTemplate\", err.Error())\n\t}\n\n\treq, err := client.ExportTemplatePreparer(ctx, resourceGroupName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.ExportTemplateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.ExportTemplateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (cr *configReader) parseDatasourceConfig(path string, file os.FileInfo) (*DatasourcesAsConfig, error) {\n\tfilename, _ := filepath.Abs(filepath.Join(path, file.Name()))\n\tyamlFile, err := ioutil.ReadFile(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar apiVersion *ConfigVersion\n\terr = yaml.Unmarshal(yamlFile, &apiVersion)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif apiVersion == nil {\n\t\tapiVersion = &ConfigVersion{ApiVersion: 0}\n\t}\n\n\tif apiVersion.ApiVersion > 0 {\n\t\tvar v1 *DatasourcesAsConfigV1\n\t\terr = yaml.Unmarshal(yamlFile, &v1)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn v1.mapToDatasourceFromConfig(apiVersion.ApiVersion), nil\n\t}\n\n\tvar v0 *DatasourcesAsConfigV0\n\terr = yaml.Unmarshal(yamlFile, &v0)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcr.log.Warn(\"[Deprecated] the datasource provisioning config is outdated. please upgrade\", \"filename\", filename)\n\n\treturn v0.mapToDatasourceFromConfig(apiVersion.ApiVersion), nil\n}", "is_vulnerable": 1}
{"code": "func (p *Profile) writeConfWgQuick(data *WgConf) (pth string, err error) {\n\tallowedIps := []string{}\n\tif data.Routes != nil {\n\t\tfor _, route := range data.Routes {\n\t\t\tallowedIps = append(allowedIps, route.Network)\n\t\t}\n\t}\n\tif data.Routes6 != nil {\n\t\tfor _, route := range data.Routes6 {\n\t\t\tallowedIps = append(allowedIps, route.Network)\n\t\t}\n\t}\n\n\taddr := data.Address\n\tif data.Address6 != \"\" {\n\t\taddr += \",\" + data.Address6\n\t}\n\n\ttemplData := WgConfData{\n\t\tAddress:    addr,\n\t\tPrivateKey: p.PrivateKeyWg,\n\t\tPublicKey:  data.PublicKey,\n\t\tAllowedIps: strings.Join(allowedIps, \",\"),\n\t\tEndpoint:   fmt.Sprintf(\"%s:%d\", data.Hostname, data.Port),\n\t}\n\n\tif data.DnsServers != nil && len(data.DnsServers) > 0 {\n\t\ttemplData.HasDns = true\n\t\ttemplData.DnsServers = strings.Join(data.DnsServers, \",\")\n\t}\n\n\toutput := &bytes.Buffer{}\n\terr = WgConfTempl.Execute(output, templData)\n\tif err != nil {\n\t\terr = &errortypes.ParseError{\n\t\t\terrors.Wrap(err, \"profile: Failed to exec wg template\"),\n\t\t}\n\t\treturn\n\t}\n\n\trootDir := \"\"\n\tswitch runtime.GOOS {\n\tcase \"linux\":\n\t\trootDir = WgLinuxConfPath\n\n\t\terr = os.MkdirAll(WgLinuxConfPath, 0700)\n\t\tif err != nil {\n\t\t\terr = &errortypes.WriteError{\n\t\t\t\terrors.Wrap(\n\t\t\t\t\terr, \"profile: Failed to create wg conf directory\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\tcase \"darwin\":\n\t\trootDir = WgMacConfPath\n\n\t\terr = os.MkdirAll(WgMacConfPath, 0700)\n\t\tif err != nil {\n\t\t\terr = &errortypes.WriteError{\n\t\t\t\terrors.Wrap(\n\t\t\t\t\terr, \"profile: Failed to create wg conf directory\"),\n\t\t\t}\n\t\t\treturn\n\t\t}\n\tdefault:\n\t\trootDir, err = utils.GetTempDir()\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tpth = filepath.Join(rootDir, p.Iface+\".conf\")\n\n\t_ = os.Remove(pth)\n\terr = ioutil.WriteFile(\n\t\tpth,\n\t\t[]byte(output.String()),\n\t\tos.FileMode(0600),\n\t)\n\tif err != nil {\n\t\terr = &WriteError{\n\t\t\terrors.Wrap(err, \"profile: Failed to write wg conf\"),\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (s *TagScanner) Scan(ctx context.Context, lastModifiedSince time.Time, progress chan uint32) (int64, error) {\n\tctx = s.withAdminUser(ctx)\n\tstart := time.Now()\n\n\t// Special case: if lastModifiedSince is zero, re-import all files\n\tfullScan := lastModifiedSince.IsZero()\n\n\tallDBDirs, err := s.getDBDirTree(ctx)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tallFSDirs := dirMap{}\n\tvar changedDirs []string\n\ts.cnt = &counters{}\n\tgenres := newCachedGenreRepository(ctx, s.ds.Genre(ctx))\n\ts.mapper = newMediaFileMapper(s.rootFolder, genres)\n\n\tfoldersFound, walkerError := s.getRootFolderWalker(ctx)\n\tfor {\n\t\tfolderStats, more := <-foldersFound\n\t\tif !more {\n\t\t\tbreak\n\t\t}\n\t\tprogress <- folderStats.AudioFilesCount\n\t\tallFSDirs[folderStats.Path] = folderStats\n\n\t\tif s.folderHasChanged(ctx, folderStats, allDBDirs, lastModifiedSince) {\n\t\t\tchangedDirs = append(changedDirs, folderStats.Path)\n\t\t\tlog.Debug(\"Processing changed folder\", \"dir\", folderStats.Path)\n\t\t\terr := s.processChangedDir(ctx, folderStats.Path, fullScan)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(\"Error updating folder in the DB\", \"dir\", folderStats.Path, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tif err := <-walkerError; err != nil {\n\t\tlog.Error(\"Scan was interrupted by error. See errors above\", err)\n\t\treturn 0, err\n\t}\n\n\t// If the media folder is empty, abort to avoid deleting all data\n\tif len(allFSDirs) <= 1 {\n\t\tlog.Error(ctx, \"Media Folder is empty. Aborting scan.\", \"folder\", s.rootFolder)\n\t\treturn 0, nil\n\t}\n\n\tdeletedDirs := s.getDeletedDirs(ctx, allFSDirs, allDBDirs)\n\tif len(deletedDirs)+len(changedDirs) == 0 {\n\t\tlog.Debug(ctx, \"No changes found in Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start))\n\t\treturn 0, nil\n\t}\n\n\tfor _, dir := range deletedDirs {\n\t\terr := s.processDeletedDir(ctx, dir)\n\t\tif err != nil {\n\t\t\tlog.Error(\"Error removing deleted folder from DB\", \"dir\", dir, err)\n\t\t}\n\t}\n\n\ts.cnt.playlists = 0\n\tif conf.Server.AutoImportPlaylists {\n\t\t// Now that all mediafiles are imported/updated, search for and import/update playlists\n\t\tu, _ := request.UserFrom(ctx)\n\t\tfor _, dir := range changedDirs {\n\t\t\tinfo := allFSDirs[dir]\n\t\t\tif info.HasPlaylist {\n\t\t\t\tif !u.IsAdmin {\n\t\t\t\t\tlog.Warn(\"Playlists will not be imported, as there are no admin users yet, \"+\n\t\t\t\t\t\t\"Please create an admin user first, and then update the playlists for them to be imported\", \"dir\", dir)\n\t\t\t\t} else {\n\t\t\t\t\ts.cnt.playlists = s.plsSync.processPlaylists(ctx, dir)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlog.Debug(\"Playlist auto-import is disabled\")\n\t}\n\n\terr = s.ds.GC(log.NewContext(ctx), s.rootFolder)\n\tlog.Info(\"Finished processing Music Folder\", \"folder\", s.rootFolder, \"elapsed\", time.Since(start),\n\t\t\"added\", s.cnt.added, \"updated\", s.cnt.updated, \"deleted\", s.cnt.deleted, \"playlistsImported\", s.cnt.playlists)\n\n\treturn s.cnt.total(), err\n}", "is_vulnerable": 0}
{"code": "func (p *HTTPClient) Flush() error {\n\t// Close any previous response body to avoid leaking connections.\n\tp.closeResponse()\n\n\treq, err := http.NewRequest(\"POST\", p.url.String(), p.requestBuffer)\n\tif err != nil {\n\t\treturn NewTransportExceptionFromError(err)\n\t}\n\tp.header.Add(\"Content-Type\", \"application/x-thrift\")\n\treq.Header = p.header\n\tresponse, err := p.client.Do(req)\n\tif err != nil {\n\t\treturn NewTransportExceptionFromError(err)\n\t}\n\n\tdefer response.Body.Close()\n\n\tif response.StatusCode != http.StatusOK {\n\t\t// Close the response to avoid leaking file descriptors. closeResponse does\n\t\t// more than just call Close(), so temporarily assign it and reuse the logic.\n\t\tp.response = response\n\t\tp.closeResponse()\n\n\t\t// TODO(pomack) log bad response\n\t\treturn NewTransportException(UNKNOWN_TRANSPORT_EXCEPTION, \"HTTP Response code: \"+strconv.Itoa(response.StatusCode))\n\t}\n\n\t_, err = io.Copy(&p.responseBuffer, response.Body)\n\tif err != nil {\n\t\treturn NewTransportExceptionFromError(err)\n\t}\n\n\tp.response = response\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *Server) postHandler(w http.ResponseWriter, r *http.Request) {\n\tif err := r.ParseMultipartForm(_24K); nil != err {\n\t\tlog.Printf(\"%s\", err.Error())\n\t\thttp.Error(w, \"Error occurred copying to output stream\", 500)\n\t\treturn\n\t}\n\n\ttoken := Encode(INIT_SEED, s.randomTokenLength)\n\n\tw.Header().Set(\"Content-Type\", \"text/plain\")\n\n\tfor _, fheaders := range r.MultipartForm.File {\n\t\tfor _, fheader := range fheaders {\n\t\t\tfilename := sanitize(fheader.Filename)\n\t\t\tcontentType := mime.TypeByExtension(filepath.Ext(fheader.Filename))\n\n\t\t\tvar f io.Reader\n\t\t\tvar err error\n\n\t\t\tif f, err = fheader.Open(); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar b bytes.Buffer\n\n\t\t\tn, err := io.CopyN(&b, f, _24K+1)\n\t\t\tif err != nil && err != io.EOF {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar file *os.File\n\t\t\tvar reader io.Reader\n\n\t\t\tif n > _24K {\n\t\t\t\tfile, err = ioutil.TempFile(s.tempPath, \"transfer-\")\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tn, err = io.Copy(file, io.MultiReader(&b, f))\n\t\t\t\tif err != nil {\n\t\t\t\t\tcleanTmpFile(file)\n\n\t\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\treader, err = os.Open(file.Name())\n\t\t\t} else {\n\t\t\t\treader = bytes.NewReader(b.Bytes())\n\t\t\t}\n\n\t\t\tcontentLength := n\n\n\t\t\tif s.maxUploadSize > 0 && contentLength > s.maxUploadSize {\n\t\t\t\tlog.Print(\"Entity too large\")\n\t\t\t\thttp.Error(w, http.StatusText(http.StatusRequestEntityTooLarge), http.StatusRequestEntityTooLarge)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmetadata := MetadataForRequest(contentType, s.randomTokenLength, r)\n\n\t\t\tbuffer := &bytes.Buffer{}\n\t\t\tif err := json.NewEncoder(buffer).Encode(metadata); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not encode metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t} else if err := s.storage.Put(token, fmt.Sprintf(\"%s.metadata\", filename), buffer, \"text/json\", uint64(buffer.Len())); err != nil {\n\t\t\t\tlog.Printf(\"%s\", err.Error())\n\t\t\t\thttp.Error(w, errors.New(\"Could not save metadata\").Error(), 500)\n\n\t\t\t\tcleanTmpFile(file)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tlog.Printf(\"Uploading %s %s %d %s\", token, filename, contentLength, contentType)\n\n\t\t\tif err = s.storage.Put(token, filename, reader, contentType, uint64(contentLength)); err != nil {\n\t\t\t\tlog.Printf(\"Backend storage error: %s\", err.Error())\n\t\t\t\thttp.Error(w, err.Error(), 500)\n\t\t\t\treturn\n\n\t\t\t}\n\n\t\t\tfilename = url.PathEscape(filename)\n\t\t\trelativeURL, _ := url.Parse(path.Join(s.proxyPath, token, filename))\n\t\t\tfmt.Fprintln(w, getURL(r, s.proxyPort).ResolveReference(relativeURL).String())\n\n\t\t\tcleanTmpFile(file)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestListNodeExecutionsWithParent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\tparentID := uint(12)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.NodeExecutionResource) (execution models.NodeExecution, e error) {\n\t\tassert.Equal(t, \"parent_1\", input.NodeExecutionIdentifier.NodeId)\n\t\treturn models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: parentID,\n\t\t\t},\n\t\t}, nil\n\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 4)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.NodeExecution, input.InlineFilters[3].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[3].GetGormQueryExpr()\n\t\t\tassert.Equal(t, parentID, queryExpr.Args)\n\t\t\tassert.Equal(t, \"parent_id = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t\tUniqueParentId: \"parent_1\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}", "is_vulnerable": 1}
{"code": "func (client DeploymentOperationsClient) listNextResults(ctx context.Context, lastResults DeploymentOperationsListResult) (result DeploymentOperationsListResult, err error) {\n\treq, err := lastResults.deploymentOperationsListResultPreparer(ctx)\n\tif err != nil {\n\t\treturn result, autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"listNextResults\", nil, \"Failure preparing next results request\")\n\t}\n\tif req == nil {\n\t\treturn\n\t}\n\tresp, err := client.ListSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\treturn result, autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"listNextResults\", resp, \"Failure sending next results request\")\n\t}\n\tresult, err = client.ListResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.DeploymentOperationsClient\", \"listNextResults\", resp, \"Failure responding to next results request\")\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (m Map) Transform(transformer func(key string, value interface{}) (string, interface{})) Map {\n\tnewMap := Map{}\n\tfor k, v := range m {\n\t\tmodifiedKey, modifiedVal := transformer(k, v)\n\t\tnewMap[modifiedKey] = modifiedVal\n\t}\n\treturn newMap\n}", "is_vulnerable": 0}
{"code": "func (m *MapStdTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: MapStdTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: MapStdTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableTimestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableTimestamp == nil {\n\t\t\t\tm.NullableTimestamp = make(map[int32]*time.Time)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Time)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableTimestamp[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Timestamp == nil {\n\t\t\t\tm.Timestamp = make(map[int32]time.Time)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Time)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdTimeUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Timestamp[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDuration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDuration == nil {\n\t\t\t\tm.NullableDuration = make(map[int32]*time.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Duration)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDuration[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Duration == nil {\n\t\t\t\tm.Duration = make(map[int32]time.Duration)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(time.Duration)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDurationUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Duration[mapkey] = *mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableDouble == nil {\n\t\t\t\tm.NullableDouble = make(map[int32]*float64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableDouble[mapkey] = ((*float64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullDouble == nil {\n\t\t\t\tm.NonnullDouble = make(map[int32]float64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdDoubleUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullDouble[mapkey] = ((float64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableFloat == nil {\n\t\t\t\tm.NullableFloat = make(map[int32]*float32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableFloat[mapkey] = ((*float32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullFloat == nil {\n\t\t\t\tm.NonnullFloat = make(map[int32]float32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(float32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdFloatUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullFloat[mapkey] = ((float32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt64 == nil {\n\t\t\t\tm.NullableInt64 = make(map[int32]*int64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt64[mapkey] = ((*int64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt64 == nil {\n\t\t\t\tm.NonnullInt64 = make(map[int32]int64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt64[mapkey] = ((int64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt64 == nil {\n\t\t\t\tm.NullableUInt64 = make(map[int32]*uint64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt64[mapkey] = ((*uint64)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt64 == nil {\n\t\t\t\tm.NonnullUInt64 = make(map[int32]uint64)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint64)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt64Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt64[mapkey] = ((uint64)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableInt32 == nil {\n\t\t\t\tm.NullableInt32 = make(map[int32]*int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableInt32[mapkey] = ((*int32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullInt32 == nil {\n\t\t\t\tm.NonnullInt32 = make(map[int32]int32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(int32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullInt32[mapkey] = ((int32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableUInt32 == nil {\n\t\t\t\tm.NullableUInt32 = make(map[int32]*uint32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableUInt32[mapkey] = ((*uint32)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullUInt32 == nil {\n\t\t\t\tm.NonnullUInt32 = make(map[int32]uint32)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(uint32)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdUInt32Unmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullUInt32[mapkey] = ((uint32)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 17:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBool == nil {\n\t\t\t\tm.NullableBool = make(map[int32]*bool)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(bool)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBool[mapkey] = ((*bool)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 18:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBool == nil {\n\t\t\t\tm.NonnullBool = make(map[int32]bool)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(bool)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBoolUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBool[mapkey] = ((bool)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 19:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableString == nil {\n\t\t\t\tm.NullableString = make(map[int32]*string)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(string)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableString[mapkey] = ((*string)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 20:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullString == nil {\n\t\t\t\tm.NonnullString = make(map[int32]string)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new(string)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdStringUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullString[mapkey] = ((string)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 21:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NullableBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NullableBytes == nil {\n\t\t\t\tm.NullableBytes = make(map[int32]*[]byte)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new([]byte)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NullableBytes[mapkey] = ((*[]byte)(mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tcase 22:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NonnullBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NonnullBytes == nil {\n\t\t\t\tm.NonnullBytes = make(map[int32][]byte)\n\t\t\t}\n\t\t\tvar mapkey int32\n\t\t\tmapvalue := new([]byte)\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapkey |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tif err := github_com_gogo_protobuf_types.StdBytesUnmarshal(mapvalue, dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NonnullBytes[mapkey] = (([]byte)(*mapvalue))\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestHTTPGetter(t *testing.T) {\n\tg, err := NewHTTPGetter(WithURL(\"http://example.com\"))\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif _, ok := g.(*HTTPGetter); !ok {\n\t\tt.Fatal(\"Expected NewHTTPGetter to produce an *HTTPGetter\")\n\t}\n\n\tcd := \"../../testdata\"\n\tjoin := filepath.Join\n\tca, pub, priv := join(cd, \"rootca.crt\"), join(cd, \"crt.pem\"), join(cd, \"key.pem\")\n\tinsecure := false\n\ttimeout := time.Second * 5\n\n\t// Test with options\n\tg, err = NewHTTPGetter(\n\t\tWithBasicAuth(\"I\", \"Am\"),\n\t\tWithPassCredentialsAll(false),\n\t\tWithUserAgent(\"Groot\"),\n\t\tWithTLSClientConfig(pub, priv, ca),\n\t\tWithInsecureSkipVerifyTLS(insecure),\n\t\tWithTimeout(timeout),\n\t)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\thg, ok := g.(*HTTPGetter)\n\tif !ok {\n\t\tt.Fatal(\"expected NewHTTPGetter to produce an *HTTPGetter\")\n\t}\n\n\tif hg.opts.username != \"I\" {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the username, got %q\", \"I\", hg.opts.username)\n\t}\n\n\tif hg.opts.password != \"Am\" {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the password, got %q\", \"Am\", hg.opts.password)\n\t}\n\n\tif hg.opts.passCredentialsAll != false {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %t as PassCredentialsAll, got %t\", false, hg.opts.passCredentialsAll)\n\t}\n\n\tif hg.opts.userAgent != \"Groot\" {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the user agent, got %q\", \"Groot\", hg.opts.userAgent)\n\t}\n\n\tif hg.opts.certFile != pub {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the public key file, got %q\", pub, hg.opts.certFile)\n\t}\n\n\tif hg.opts.keyFile != priv {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the private key file, got %q\", priv, hg.opts.keyFile)\n\t}\n\n\tif hg.opts.caFile != ca {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %q as the CA file, got %q\", ca, hg.opts.caFile)\n\t}\n\n\tif hg.opts.insecureSkipVerifyTLS != insecure {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %t as InsecureSkipVerifyTLs flag, got %t\", false, hg.opts.insecureSkipVerifyTLS)\n\t}\n\n\tif hg.opts.timeout != timeout {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %s as Timeout flag, got %s\", timeout, hg.opts.timeout)\n\t}\n\n\t// Test if setting insecureSkipVerifyTLS is being passed to the ops\n\tinsecure = true\n\n\tg, err = NewHTTPGetter(\n\t\tWithInsecureSkipVerifyTLS(insecure),\n\t)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\thg, ok = g.(*HTTPGetter)\n\tif !ok {\n\t\tt.Fatal(\"expected NewHTTPGetter to produce an *HTTPGetter\")\n\t}\n\n\tif hg.opts.insecureSkipVerifyTLS != insecure {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %t as InsecureSkipVerifyTLs flag, got %t\", insecure, hg.opts.insecureSkipVerifyTLS)\n\t}\n\n\t// Checking false by default\n\tif hg.opts.passCredentialsAll != false {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %t as PassCredentialsAll, got %t\", false, hg.opts.passCredentialsAll)\n\t}\n\n\t// Test setting PassCredentialsAll\n\tg, err = NewHTTPGetter(\n\t\tWithBasicAuth(\"I\", \"Am\"),\n\t\tWithPassCredentialsAll(true),\n\t)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\thg, ok = g.(*HTTPGetter)\n\tif !ok {\n\t\tt.Fatal(\"expected NewHTTPGetter to produce an *HTTPGetter\")\n\t}\n\tif hg.opts.passCredentialsAll != true {\n\t\tt.Errorf(\"Expected NewHTTPGetter to contain %t as PassCredentialsAll, got %t\", true, hg.opts.passCredentialsAll)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockTokenRevocationStorageMockRecorder) CreateRefreshTokenSession(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"CreateRefreshTokenSession\", reflect.TypeOf((*MockTokenRevocationStorage)(nil).CreateRefreshTokenSession), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func access(current, selector, value interface{}, isSet bool) interface{} {", "is_vulnerable": 0}
{"code": "func (cn *clusterNode) resurrect() {\n\tgRPCServer, err := comm_utils.NewGRPCServer(cn.bindAddress, cn.serverConfig)\n\tif err != nil {\n\t\tpanic(fmt.Errorf(\"failed starting gRPC server: %v\", err))\n\t}\n\tcn.srv = gRPCServer\n\torderer.RegisterClusterServer(gRPCServer.Server(), cn.dispatcher)\n\tgo cn.srv.Start()\n}", "is_vulnerable": 0}
{"code": "func authenticationHandler(w http.ResponseWriter, r *http.Request) bool {\n\tvar userID int\n\n\tauthHeader := strings.ToLower(r.Header.Get(\"authorization\"))\n\n\tif len(authHeader) > 0 && strings.Contains(authHeader, \"bearer\") {\n\t\ttoken, err := helpers.Store(r).GetAPIToken(strings.Replace(authHeader, \"bearer \", \"\", 1))\n\n\t\tif err != nil {\n\t\t\tif err != db.ErrNotFound {\n\t\t\t\tlog.Error(err)\n\t\t\t}\n\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tuserID = token.UserID\n\t} else {\n\t\t// fetch session from cookie\n\t\tcookie, err := r.Cookie(\"semaphore\")\n\t\tif err != nil {\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tvalue := make(map[string]interface{})\n\t\tif err = util.Cookie.Decode(\"semaphore\", cookie.Value, &value); err != nil {\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tuser, ok := value[\"user\"]\n\t\tsessionVal, okSession := value[\"session\"]\n\t\tif !ok || !okSession {\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tuserID = user.(int)\n\t\tsessionID := sessionVal.(int)\n\n\t\t// fetch session\n\t\tsession, err := helpers.Store(r).GetSession(userID, sessionID)\n\n\t\tif err != nil {\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tif time.Since(session.LastActive).Hours() > 7*24 {\n\t\t\t// more than week old unused session\n\t\t\t// destroy.\n\t\t\tif err := helpers.Store(r).ExpireSession(userID, sessionID); err != nil {\n\t\t\t\t// it is internal error, it doesn't concern the user\n\t\t\t\tlog.Error(err)\n\t\t\t}\n\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\n\t\tif err := helpers.Store(r).TouchSession(userID, sessionID); err != nil {\n\t\t\tlog.Error(err)\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\t}\n\n\tuser, err := helpers.Store(r).GetUser(userID)\n\tif err != nil {\n\t\tif err != db.ErrNotFound {\n\t\t\t// internal error\n\t\t\tlog.Error(err)\n\t\t}\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\treturn false\n\t}\n\n\tif util.Config.DemoMode {\n\t\tif !user.Admin && r.Method != \"GET\" &&\n\t\t\t!strings.HasSuffix(r.URL.Path, \"/tasks\") &&\n\t\t\t!strings.HasSuffix(r.URL.Path, \"/stop\") {\n\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\treturn false\n\t\t}\n\t}\n\n\tcontext.Set(r, \"user\", &user)\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (c *liveStateCache) IterateHierarchy(server string, key kube.ResourceKey, action func(child appv1.ResourceNode, appName string)) error {\n\tclusterInfo, err := c.getSyncedCluster(server)\n\tif err != nil {\n\t\treturn err\n\t}\n\tclusterInfo.IterateHierarchy(key, func(resource *clustercache.Resource, namespaceResources map[kube.ResourceKey]*clustercache.Resource) {\n\t\taction(asResourceNode(resource), getApp(resource, namespaceResources))\n\t})\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func RunPrecompiledContract(p PrecompiledContract, input []byte, contract *Contract) (ret []byte, err error) {\n\tgas := p.RequiredGas(input)\n\tif contract.UseGas(gas) {\n\t\treturn p.Run(input)\n\t}\n\treturn nil, ErrOutOfGas\n}", "is_vulnerable": 1}
{"code": "func (m *Sub) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Sub: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Sub: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field SubNumber\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnmarshalmerge\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.SubNumber = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnmarshalmerge(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthUnmarshalmerge\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnmarshalmerge\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (r *sqlRepository) registerModel(instance any, filters map[string]filterFunc) {\n\tif r.tableName == \"\" {\n\t\tr.tableName = strings.TrimPrefix(reflect.TypeOf(instance).String(), \"*model.\")\n\t\tr.tableName = toSnakeCase(r.tableName)\n\t}\n\tr.tableName = strings.ToLower(r.tableName)\n\tr.isFieldWhiteListed = registerModelWhiteList(instance)\n\tr.filterMappings = filters\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) Stat(p string) (Stat, error) {\n\tf, err := fs.unixFS.Open(p)\n\tif err != nil {\n\t\treturn Stat{}, err\n\t}\n\tdefer f.Close()\n\tst, err := statFromFile(f)\n\tif err != nil {\n\t\treturn Stat{}, err\n\t}\n\treturn st, nil\n}", "is_vulnerable": 0}
{"code": "func (db *Database) commit(hash common.Hash, batch ethdb.Batch, uncacher *cleaner, callback func(common.Hash)) error {\n\t// If the node does not exist, it's a previously committed node\n\tnode, ok := db.dirties[hash]\n\tif !ok {\n\t\treturn nil\n\t}\n\tvar err error\n\tnode.forChilds(func(child common.Hash) {\n\t\tif err == nil {\n\t\t\terr = db.commit(child, batch, uncacher, callback)\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := batch.Put(hash[:], node.rlp()); err != nil {\n\t\treturn err\n\t}\n\tif callback != nil {\n\t\tcallback(hash)\n\t}\n\t// If we've reached an optimal batch size, commit and start over\n\tif batch.ValueSize() >= ethdb.IdealBatchSize {\n\t\tif err := batch.Write(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdb.lock.Lock()\n\t\tbatch.Replay(uncacher)\n\t\tbatch.Reset()\n\t\tdb.lock.Unlock()\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tassert.Equal(t, test.wantVal, isRepositoryGitPath(test.path))\n\t\t})", "is_vulnerable": 1}
{"code": "func (sa *SockaddrVM) sockaddr() (unsafe.Pointer, _Socklen, error) {\n\tsa.raw.Len = SizeofSockaddrVM\n\tsa.raw.Family = AF_VSOCK\n\tsa.raw.Port = sa.Port\n\tsa.raw.Cid = sa.CID\n\n\treturn unsafe.Pointer(&sa.raw), SizeofSockaddrVM, nil\n}", "is_vulnerable": 0}
{"code": "func (s *stateSync) processNodeData(blob []byte) (bool, common.Hash, error) {\n\tres := trie.SyncResult{Data: blob}\n\ts.keccak.Reset()\n\ts.keccak.Write(blob)\n\ts.keccak.Sum(res.Hash[:0])\n\tcommitted, _, err := s.sched.Process([]trie.SyncResult{res})\n\treturn committed, res.Hash, err\n}", "is_vulnerable": 1}
{"code": "func shmdt(addr uintptr) (err error) {\n\t_, _, e1 := syscall_syscall(libc_shmdt_trampoline_addr, uintptr(addr), 0, 0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (c *CommonController) Prepare()  {\n\tif c.Ctx.Request.Header.Get(\"Authorization\") != \"\"{\n\t\tc.basicAuthor()\n\t}else{\n\t\tc.normalAuthor()\n\t\tc.Data[\"Version\"] = config.VERSION\n\t}\n}", "is_vulnerable": 1}
{"code": "func (d mp4Generator) GetOriginDimensions(b []byte, contentType string, ctx rcontext.RequestContext) (bool, int, int, error) {\n\treturn false, 0, 0, nil\n}", "is_vulnerable": 0}
{"code": "func (f MigrateRepo) ParseRemoteAddr(user *db.User) (string, error) {\n\tremoteAddr := strings.TrimSpace(f.CloneAddr)\n\n\t// Remote address can be HTTP/HTTPS/Git URL or local path.\n\tif strings.HasPrefix(remoteAddr, \"http://\") ||\n\t\tstrings.HasPrefix(remoteAddr, \"https://\") ||\n\t\tstrings.HasPrefix(remoteAddr, \"git://\") {\n\t\tu, err := url.Parse(remoteAddr)\n\t\tif err != nil {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsURLError: true}\n\t\t}\n\n\t\tif netutil.IsBlockedLocalHostname(u.Hostname(), conf.Security.LocalNetworkAllowlist) {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsBlockedLocalAddress: true}\n\t\t}\n\n\t\tif len(f.AuthUsername)+len(f.AuthPassword) > 0 {\n\t\t\tu.User = url.UserPassword(f.AuthUsername, f.AuthPassword)\n\t\t}\n\t\t// To prevent CRLF injection in git protocol, see https://github.com/gogs/gogs/issues/6413\n\t\tif u.Scheme == \"git\" && (strings.Contains(remoteAddr, \"%0d\") || strings.Contains(remoteAddr, \"%0a\")) {\n\t\t\treturn \"\", db.ErrInvalidCloneAddr{IsURLError: true}\n\t\t}\n\t\tremoteAddr = u.String()\n\t} else if !user.CanImportLocal() {\n\t\treturn \"\", db.ErrInvalidCloneAddr{IsPermissionDenied: true}\n\t} else if !com.IsDir(remoteAddr) {\n\t\treturn \"\", db.ErrInvalidCloneAddr{IsInvalidPath: true}\n\t}\n\n\treturn remoteAddr, nil\n}", "is_vulnerable": 0}
{"code": "func (r *playerRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\treturn r.count(r.newRestSelect(), r.parseRestOptions(options...))\n}", "is_vulnerable": 1}
{"code": "\t\t\tdecoderInput: func() (dst NestedSlices, src map[string][]string) {\n\t\t\t\treturn dst, map[string][]string{\n\t\t\t\t\t\"Values.1.Val\":                 {\"132\"},\n\t\t\t\t\t\"Values.1.NestedValues.1.NVal\": {\"1\"},\n\t\t\t\t\t\"Values.1.NestedValues.2.NVal\": {\"2\"},\n\t\t\t\t\t\"Values.1.NestedValues.3.NVal\": {\"3\"},\n\t\t\t\t}\n\t\t\t},", "is_vulnerable": 0}
{"code": "func TestPlainSplit_NoUser_MultiPass(t *testing.T) {\n\ta := Auth{\n\t\tpasswd: []module.PlainAuth{\n\t\t\tmockAuth{\n\t\t\t\tdb: map[string]bool{\n\t\t\t\t\t\"user2\": true,\n\t\t\t\t},\n\t\t\t},\n\t\t\tmockAuth{\n\t\t\t\tdb: map[string]bool{\n\t\t\t\t\t\"user1\": true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\terr := a.AuthPlain(\"user1\", \"aaa\")\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected error:\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func validateWebhook(l macaron.Locale, w *db.Webhook) (field, msg string, ok bool) {\n\t// \ud83d\udea8 SECURITY: Local addresses must not be allowed by non-admins to prevent SSRF,\n\t// see https://github.com/gogs/gogs/issues/5366 for details.\n\tpayloadURL, err := url.Parse(w.URL)\n\tif err != nil {\n\t\treturn \"PayloadURL\", l.Tr(\"repo.settings.webhook.err_cannot_parse_payload_url\", err), false\n\t}\n\n\tif netutil.IsBlockedLocalHostname(payloadURL.Hostname(), conf.Security.LocalNetworkAllowlist) {\n\t\treturn \"PayloadURL\", l.Tr(\"repo.settings.webhook.url_resolved_to_blocked_local_address\"), false\n\t}\n\treturn \"\", \"\", true\n}", "is_vulnerable": 0}
{"code": "func (g *HttpGetter) GetFile(ctx context.Context, req *Request) error {\n\tif g.Netrc {\n\t\t// Add auth from netrc if we can\n\t\tif err := addAuthFromNetrc(req.u); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t// Create all the parent directories if needed\n\tif err := os.MkdirAll(filepath.Dir(req.Dst), req.Mode(0755)); err != nil {\n\t\treturn err\n\t}\n\n\tf, err := os.OpenFile(req.Dst, os.O_RDWR|os.O_CREATE, req.Mode(0666))\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer f.Close()\n\n\tif g.Client == nil {\n\t\tg.Client = httpClient\n\t}\n\n\tvar currentFileSize int64\n\n\t// We first make a HEAD request so we can check\n\t// if the server supports range queries. If the server/URL doesn't\n\t// support HEAD requests, we just fall back to GET.\n\thttpReq, err := http.NewRequestWithContext(ctx, \"HEAD\", req.u.String(), nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif g.Header != nil {\n\t\thttpReq.Header = g.Header.Clone()\n\t}\n\theadResp, err := g.Client.Do(httpReq)\n\tif err == nil {\n\t\theadResp.Body.Close()\n\t\tif headResp.StatusCode == 200 {\n\t\t\t// If the HEAD request succeeded, then attempt to set the range\n\t\t\t// query if we can.\n\t\t\tif headResp.Header.Get(\"Accept-Ranges\") == \"bytes\" && headResp.ContentLength >= 0 {\n\t\t\t\tif fi, err := f.Stat(); err == nil {\n\t\t\t\t\tif _, err = f.Seek(0, io.SeekEnd); err == nil {\n\t\t\t\t\t\tcurrentFileSize = fi.Size()\n\t\t\t\t\t\thttpReq.Header.Set(\"Range\", fmt.Sprintf(\"bytes=%d-\", currentFileSize))\n\t\t\t\t\t\tif currentFileSize >= headResp.ContentLength {\n\t\t\t\t\t\t\t// file already present\n\t\t\t\t\t\t\treturn nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\thttpReq.Method = \"GET\"\n\n\tresp, err := g.Client.Do(httpReq)\n\tif err != nil {\n\t\treturn err\n\t}\n\tswitch resp.StatusCode {\n\tcase http.StatusOK, http.StatusPartialContent:\n\t\t// all good\n\tdefault:\n\t\tresp.Body.Close()\n\t\treturn fmt.Errorf(\"bad response code: %d\", resp.StatusCode)\n\t}\n\n\tbody := resp.Body\n\n\tif req.ProgressListener != nil {\n\t\t// track download\n\t\tfn := filepath.Base(req.u.EscapedPath())\n\t\tbody = req.ProgressListener.TrackProgress(fn, currentFileSize, currentFileSize+resp.ContentLength, resp.Body)\n\t}\n\tdefer body.Close()\n\n\tn, err := Copy(ctx, f, body)\n\tif err == nil && n < resp.ContentLength {\n\t\terr = io.ErrShortWrite\n\t}\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func TestSignWithoutExpiry(t *testing.T) {\n\t// sign with key\n\tfor _, envelopeType := range signature.RegisteredEnvelopeTypes() {\n\t\tfor _, keyCert := range keyCertPairCollections {\n\t\t\tt.Run(fmt.Sprintf(\"envelopeType=%v_keySpec=%v\", envelopeType, keyCert.keySpecName), func(t *testing.T) {\n\t\t\t\ts, err := New(keyCert.key, keyCert.certs)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"NewSigner() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\tctx := context.Background()\n\t\t\t\tdesc, sOpts := generateSigningContent()\n\t\t\t\tsOpts.ExpiryDuration = 0 // reset expiry\n\t\t\t\tsOpts.SignatureMediaType = envelopeType\n\t\t\t\tsig, _, err := s.Sign(ctx, desc, sOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Sign() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// basic verification\n\t\t\t\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], nil)\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *OneofProtoTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: OneofProtoTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: OneofProtoTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Timestamp{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_Timestamp{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Duration{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_Duration{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.DoubleValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepDouble{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.FloatValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepFloat{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Int64Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepInt64{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.UInt64Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepUInt64{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Int32Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepInt32{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.UInt32Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepUInt32{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.BoolValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepBool{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.StringValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepString{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.BytesValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepBytes{v}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *Stat) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(struct {\n\t\tName      string `json:\"name\"`\n\t\tCreated   string `json:\"created\"`\n\t\tModified  string `json:\"modified\"`\n\t\tMode      string `json:\"mode\"`\n\t\tModeBits  string `json:\"mode_bits\"`\n\t\tSize      int64  `json:\"size\"`\n\t\tDirectory bool   `json:\"directory\"`\n\t\tFile      bool   `json:\"file\"`\n\t\tSymlink   bool   `json:\"symlink\"`\n\t\tMime      string `json:\"mime\"`\n\t}{\n\t\tName:     s.Name(),\n\t\tCreated:  s.CTime().Format(time.RFC3339),\n\t\tModified: s.ModTime().Format(time.RFC3339),\n\t\tMode:     s.Mode().String(),\n\t\t// Using `&ModePerm` on the file's mode will cause the mode to only have the permission values, and nothing else.\n\t\tModeBits:  strconv.FormatUint(uint64(s.Mode()&ufs.ModePerm), 8),\n\t\tSize:      s.Size(),\n\t\tDirectory: s.IsDir(),\n\t\tFile:      !s.IsDir(),\n\t\tSymlink:   s.Mode().Perm()&ufs.ModeSymlink != 0,\n\t\tMime:      s.Mimetype,\n\t})\n}", "is_vulnerable": 0}
{"code": "func (m *MineOwner) GetPoolManage(keyid int64) (bool, error) {\r\n\t\treturn false, err1\r\n\t}\r", "is_vulnerable": 0}
{"code": "func FileExistsf(t TestingT, path string, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.FileExistsf(t, path, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func UtimesNano(path string, ts []Timespec) error {\n\treturn UtimesNanoAt(AT_FDCWD, path, ts, 0)\n}", "is_vulnerable": 0}
{"code": "func inTemplateIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase TextToken, CommentToken, DoctypeToken:\n\t\treturn inBodyIM(p)\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Base, a.Basefont, a.Bgsound, a.Link, a.Meta, a.Noframes, a.Script, a.Style, a.Template, a.Title:\n\t\t\treturn inHeadIM(p)\n\t\tcase a.Caption, a.Colgroup, a.Tbody, a.Tfoot, a.Thead:\n\t\t\tp.templateStack.pop()\n\t\t\tp.templateStack = append(p.templateStack, inTableIM)\n\t\t\tp.im = inTableIM\n\t\t\treturn false\n\t\tcase a.Col:\n\t\t\tp.templateStack.pop()\n\t\t\tp.templateStack = append(p.templateStack, inColumnGroupIM)\n\t\t\tp.im = inColumnGroupIM\n\t\t\treturn false\n\t\tcase a.Tr:\n\t\t\tp.templateStack.pop()\n\t\t\tp.templateStack = append(p.templateStack, inTableBodyIM)\n\t\t\tp.im = inTableBodyIM\n\t\t\treturn false\n\t\tcase a.Td, a.Th:\n\t\t\tp.templateStack.pop()\n\t\t\tp.templateStack = append(p.templateStack, inRowIM)\n\t\t\tp.im = inRowIM\n\t\t\treturn false\n\t\tdefault:\n\t\t\tp.templateStack.pop()\n\t\t\tp.templateStack = append(p.templateStack, inBodyIM)\n\t\t\tp.im = inBodyIM\n\t\t\treturn false\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Template:\n\t\t\treturn inHeadIM(p)\n\t\tdefault:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\t}\n\tif !p.oe.contains(a.Template) {\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\tp.popUntil(defaultScope, a.Template)\n\tp.clearActiveFormattingElements()\n\tp.templateStack.pop()\n\tp.resetInsertionMode()\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func WithPrepareDecorators(ctx context.Context, prepareDecorator []PrepareDecorator) context.Context {\n\tif len(prepareDecorator) == 0 {\n\t\treturn ctx\n\t}\n\treturn context.WithValue(ctx, ctxPrepareDecorators{}, prepareDecorator)\n}", "is_vulnerable": 0}
{"code": "func IsInboundPublicListener(l *envoy_listener_v3.Listener) bool {\n\treturn GetListenerEnvoyID(l) == xdscommon.PublicListenerName\n}", "is_vulnerable": 0}
{"code": "func TestRouterPathPrefix(t *testing.T) {\n\ttests := []struct {\n\t\tname               string\n\t\turl                string\n\t\texpectedStatusCode int\n\t\texpectedBody       string\n\t}{\n\t\t{\n\t\t\tname:               \"token request\",\n\t\t\turl:                \"/metadata/identity/oauth2/token/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"token_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"token request without / suffix\",\n\t\t\turl:                \"/metadata/identity/oauth2/token\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"token_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"token request with upper case metadata\",\n\t\t\turl:                \"/Metadata/identity/oauth2/token/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"token_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"token request with upper case identity\",\n\t\t\turl:                \"/metadata/Identity/oauth2/token/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"default_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"host token request\",\n\t\t\turl:                \"/host/token/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"host_token_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"host token request without / suffix\",\n\t\t\turl:                \"/host/token\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"host_token_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"instance metadata request\",\n\t\t\turl:                \"/metadata/instance\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"instance_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"instance metadata request with upper case metadata\",\n\t\t\turl:                \"/Metadata/instance\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"instance_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"instance metadata request / suffix\",\n\t\t\turl:                \"/Metadata/instance/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"instance_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"default metadata request\",\n\t\t\turl:                \"/metadata/\",\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"default_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"invalid token request with \\\\oauth2\",\n\t\t\turl:                `/metadata/identity\\oauth2/token/`,\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"invalid_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"invalid token request with \\\\token\",\n\t\t\turl:                `/metadata/identity/oauth2\\token/`,\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"invalid_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"invalid token request with \\\\oauth2\\\\token\",\n\t\t\turl:                `/metadata/identity\\oauth2\\token/`,\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"invalid_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"invalid token request with mix of / and \\\\\",\n\t\t\turl:                `/metadata/identity/\\oauth2\\token/`,\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"invalid_request_handler\",\n\t\t},\n\t\t{\n\t\t\tname:               \"invalid token request with multiple \\\\\",\n\t\t\turl:                `/metadata/identity\\\\\\oauth2\\\\token/`,\n\t\t\texpectedStatusCode: http.StatusOK,\n\t\t\texpectedBody:       \"invalid_request_handler\",\n\t\t},\n\t}\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tsetup()\n\t\t\tdefer teardown()\n\n\t\t\trtr.PathPrefix(tokenPathPrefix).HandlerFunc(testTokenHandler)\n\t\t\trtr.MatcherFunc(invalidTokenPathMatcher).HandlerFunc(testInvalidRequestHandler)\n\t\t\trtr.PathPrefix(hostTokenPathPrefix).HandlerFunc(testHostTokenHandler)\n\t\t\trtr.PathPrefix(instancePathPrefix).HandlerFunc(testInstanceHandler)\n\t\t\trtr.PathPrefix(\"/\").HandlerFunc(testDefaultHandler)\n\n\t\t\treq, err := http.NewRequest(http.MethodGet, test.url, nil)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\trecorder := httptest.NewRecorder()\n\t\t\trtr.ServeHTTP(recorder, req)\n\n\t\t\tif recorder.Code != test.expectedStatusCode {\n\t\t\t\tt.Errorf(\"unexpected status code %d\", recorder.Code)\n\t\t\t}\n\n\t\t\tif test.expectedBody != strings.TrimSpace(recorder.Body.String()) {\n\t\t\t\tt.Errorf(\"unexpected response body %s\", recorder.Body.String())\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func testIterativeRandomStateSync(t *testing.T, count int) {\n\t// Create a random state to copy\n\tsrcDb, srcRoot, srcAccounts := makeTestState()\n\n\t// Create a destination state and sync with the scheduler\n\tdstDb := rawdb.NewMemoryDatabase()\n\tsched := NewStateSync(srcRoot, dstDb, trie.NewSyncBloom(1, dstDb))\n\n\tqueue := make(map[common.Hash]struct{})\n\tfor _, hash := range sched.Missing(count) {\n\t\tqueue[hash] = struct{}{}\n\t}\n\tfor len(queue) > 0 {\n\t\t// Fetch all the queued nodes in a random order\n\t\tresults := make([]trie.SyncResult, 0, len(queue))\n\t\tfor hash := range queue {\n\t\t\tdata, err := srcDb.TrieDB().Node(hash)\n\t\t\tif err != nil {\n\t\t\t\tdata, err = srcDb.ContractCode(common.Hash{}, hash)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to retrieve node data for %x\", hash)\n\t\t\t}\n\t\t\tresults = append(results, trie.SyncResult{Hash: hash, Data: data})\n\t\t}\n\t\t// Feed the retrieved results back and queue new tasks\n\t\tfor _, result := range results {\n\t\t\tif err := sched.Process(result); err != nil {\n\t\t\t\tt.Fatalf(\"failed to process result %v\", err)\n\t\t\t}\n\t\t}\n\t\tbatch := dstDb.NewBatch()\n\t\tif err := sched.Commit(batch); err != nil {\n\t\t\tt.Fatalf(\"failed to commit data: %v\", err)\n\t\t}\n\t\tbatch.Write()\n\t\tqueue = make(map[common.Hash]struct{})\n\t\tfor _, hash := range sched.Missing(count) {\n\t\t\tqueue[hash] = struct{}{}\n\t\t}\n\t}\n\t// Cross check that the two states are in sync\n\tcheckStateAccounts(t, dstDb, srcRoot, srcAccounts)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) GetCredByID(ctx context.Context, in *clientpb.Credential, opts ...grpc.CallOption) (*clientpb.Credential, error) {\n\tout := new(clientpb.Credential)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetCredByID\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func NewDeploymentOperationsListResultIterator(page DeploymentOperationsListResultPage) DeploymentOperationsListResultIterator {\n\treturn DeploymentOperationsListResultIterator{page: page}\n}", "is_vulnerable": 0}
{"code": "\t\trouter.Use(func(next http.Handler) http.Handler {\n\t\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\t\troute := mux.CurrentRoute(r)\n\n\t\t\t\t// Returns a 404 if the client is not authorized to access the metrics endpoint.\n\t\t\t\tif route.GetName() == \"metrics\" && !isAllowedToAccessMetricsEndpoint(r) {\n\t\t\t\t\tlogger.Error(`[Metrics] Client not allowed: %s`, request.ClientIP(r))\n\t\t\t\t\thttp.NotFound(w, r)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tnext.ServeHTTP(w, r)\n\t\t\t})\n\t\t})\n\t}\n\n\treturn router\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{\n\t\tCalendarEventSource: v1alpha1.CalendarEventSource{\n\t\t\t// Schedule: \"* * * * *\"\n\t\t},\n\t}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must have either schedule or interval\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"calendar.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Calendar)\n\n\tfor _, value := range eventSource.Spec.Calendar {\n\t\tl := &EventListener{\n\t\t\tCalendarEventSource: value,\n\t\t}\n\t\terr = l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "\tsetup := func(t *testing.T, ignores []v1alpha1.ResourceIgnoreDifferences) *fixture {\n\t\tt.Helper()\n\t\tdc, err := diff.NewDiffConfigBuilder().\n\t\t\tWithDiffSettings(ignores, nil, true).\n\t\t\tWithNoCache().\n\t\t\tBuild()\n\t\trequire.NoError(t, err)\n\t\tlive := test.YamlToUnstructured(testdata.LiveDeploymentWithManagedReplicaYaml)\n\t\ttarget := test.YamlToUnstructured(testdata.DesiredDeploymentYaml)\n\t\treturn &fixture{\n\t\t\tdiffConfig: dc,\n\t\t\tlives:      []*unstructured.Unstructured{live},\n\t\t\ttargets:    []*unstructured.Unstructured{target},\n\t\t}\n\t}\n\tt.Run(\"will normalize resources removing the fields owned by managers\", func(t *testing.T) {\n\t\t// given\n\t\tignore := v1alpha1.ResourceIgnoreDifferences{\n\t\t\tGroup:                 \"*\",\n\t\t\tKind:                  \"*\",\n\t\t\tManagedFieldsManagers: []string{\"revision-history-manager\"},\n\t\t}\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{ignore}\n\t\tf := setup(t, ignores)\n\n\t\t// when\n\t\tresult, err := diff.Normalize(f.lives, f.targets, f.diffConfig)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(result.Targets))\n\t\t_, ok, err := unstructured.NestedFloat64(result.Targets[0].Object, \"spec\", \"revisionHistoryLimit\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t\t_, ok, err = unstructured.NestedFloat64(result.Lives[0].Object, \"spec\", \"revisionHistoryLimit\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t})\n\tt.Run(\"will correctly normalize with multiple ignore configurations\", func(t *testing.T) {\n\t\t// given\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{\n\t\t\t{\n\t\t\t\tGroup:        \"apps\",\n\t\t\t\tKind:         \"Deployment\",\n\t\t\t\tJSONPointers: []string{\"/spec/replicas\"},\n\t\t\t},\n\t\t\t{\n\t\t\t\tGroup:                 \"*\",\n\t\t\t\tKind:                  \"*\",\n\t\t\t\tManagedFieldsManagers: []string{\"revision-history-manager\"},\n\t\t\t},\n\t\t}\n\t\tf := setup(t, ignores)\n\n\t\t// when\n\t\tnormalized, err := diff.Normalize(f.lives, f.targets, f.diffConfig)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(normalized.Targets))\n\t\t_, ok, err := unstructured.NestedFloat64(normalized.Targets[0].Object, \"spec\", \"revisionHistoryLimit\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t\t_, ok, err = unstructured.NestedFloat64(normalized.Lives[0].Object, \"spec\", \"revisionHistoryLimit\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t\t_, ok, err = unstructured.NestedInt64(normalized.Targets[0].Object, \"spec\", \"replicas\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t\t_, ok, err = unstructured.NestedInt64(normalized.Lives[0].Object, \"spec\", \"replicas\")\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, ok)\n\t})\n\tt.Run(\"will not modify resources if ignore difference is not configured\", func(t *testing.T) {\n\t\t// given\n\t\tignores := []v1alpha1.ResourceIgnoreDifferences{}\n\t\tf := setup(t, ignores)\n\n\t\t// when\n\t\tresult, err := diff.Normalize(f.lives, f.targets, f.diffConfig)\n\n\t\t// then\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, 1, len(result.Targets))\n\t\tassert.Equal(t, f.lives[0], result.Lives[0])\n\t\tassert.Equal(t, f.targets[0], result.Targets[0])\n\t})\n}", "is_vulnerable": 1}
{"code": "func (m *OneofProtoTypes) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: OneofProtoTypes: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: OneofProtoTypes: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Timestamp\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Timestamp{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_Timestamp{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Duration\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Duration{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_Duration{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepDouble\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.DoubleValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepDouble{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepFloat\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.FloatValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepFloat{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Int64Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepInt64{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepUInt64\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.UInt64Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepUInt64{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.Int32Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepInt32{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepUInt32\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.UInt32Value{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepUInt32{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepBool\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.BoolValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepBool{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepString\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.StringValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepString{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field RepBytes\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTypes\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &types.BytesValue{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.OneOfProtoTimes = &OneofProtoTypes_RepBytes{v}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTypes(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTypes\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tfindClosestCommands := func(command string) []string {\n\t\tvar closestCommands []string\n\t\tclosestCommands = append(closestCommands, commandsTree.PrefixMatch(command)...)\n\n\t\tsort.Strings(closestCommands)\n\t\t// Suggest other close commands - allow missed, wrongly added and\n\t\t// even transposed characters\n\t\tfor _, value := range commandsTree.Walk(commandsTree.Root()) {\n\t\t\tif sort.SearchStrings(closestCommands, value) < len(closestCommands) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// 2 is arbitrary and represents the max\n\t\t\t// allowed number of typed errors\n\t\t\tif words.DamerauLevenshteinDistance(command, value) < 2 {\n\t\t\t\tclosestCommands = append(closestCommands, value)\n\t\t\t}\n\t\t}\n\n\t\treturn closestCommands\n\t}\n\n\t// Register all commands.\n\tregisterCommand(serverCmd)\n\tregisterCommand(gatewayCmd)\n\n\t// Set up app.\n\tcli.HelpFlag = cli.BoolFlag{\n\t\tName:  \"help, h\",\n\t\tUsage: \"show help\",\n\t}\n\n\tapp := cli.NewApp()\n\tapp.Name = name\n\tapp.Author = \"MinIO, Inc.\"\n\tapp.Version = ReleaseTag\n\tapp.Usage = \"High Performance Object Storage\"\n\tapp.Description = `Build high performance data infrastructure for machine learning, analytics and application data workloads with MinIO`\n\tapp.Flags = GlobalFlags\n\tapp.HideHelpCommand = true // Hide `help, h` command, we already have `minio --help`.\n\tapp.Commands = commands\n\tapp.CustomAppHelpTemplate = minioHelpTemplate\n\tapp.CommandNotFound = func(ctx *cli.Context, command string) {\n\t\tconsole.Printf(\"\u2018%s\u2019 is not a minio sub-command. See \u2018minio --help\u2019.\\n\", command)\n\t\tclosestCommands := findClosestCommands(command)\n\t\tif len(closestCommands) > 0 {\n\t\t\tconsole.Println()\n\t\t\tconsole.Println(\"Did you mean one of these?\")\n\t\t\tfor _, cmd := range closestCommands {\n\t\t\t\tconsole.Printf(\"\\t\u2018%s\u2019\\n\", cmd)\n\t\t\t}\n\t\t}\n\n\t\tos.Exit(1)\n\t}\n\n\treturn app\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) RegistryDeleteKey(ctx context.Context, in *sliverpb.RegistryDeleteKeyReq, opts ...grpc.CallOption) (*sliverpb.RegistryDeleteKey, error) {\n\tout := new(sliverpb.RegistryDeleteKey)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/RegistryDeleteKey\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Conn) NextReader() (messageType int, r io.Reader, err error) {\n\t// Close previous reader, only relevant for decompression.\n\tif c.reader != nil {\n\t\tc.reader.Close()\n\t\tc.reader = nil\n\t}\n\n\tc.messageReader = nil\n\tc.readLength = 0\n\n\tfor c.readErr == nil {\n\t\tframeType, err := c.advanceFrame()\n\t\tif err != nil {\n\t\t\tc.readErr = hideTempErr(err)\n\t\t\tbreak\n\t\t}\n\n\t\tif frameType == TextMessage || frameType == BinaryMessage {\n\t\t\tc.messageReader = &messageReader{c}\n\t\t\tc.reader = c.messageReader\n\t\t\tif c.readDecompress {\n\t\t\t\tc.reader = c.newDecompressionReader(c.reader)\n\t\t\t}\n\t\t\treturn frameType, c.reader, nil\n\t\t}\n\t}\n\n\t// Applications that do handle the error returned from this method spin in\n\t// tight loop on connection failure. To help application developers detect\n\t// this error, panic on repeated reads to the failed connection.\n\tc.readErrCount++\n\tif c.readErrCount >= 1000 {\n\t\tpanic(\"repeated read on failed websocket connection\")\n\t}\n\n\treturn noFrame, nil, c.readErr\n}", "is_vulnerable": 0}
{"code": "func TestConfig_ParseCiphers(t *testing.T) {\n\ttestOk := strings.Join([]string{\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_RC4_128_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_RC4_128_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_RC4_128_SHA\",\n\t}, \",\")\n\tciphers := []uint16{\n\t\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_RSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_RSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_RSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_3DES_EDE_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_RC4_128_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_RC4_128_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_RC4_128_SHA,\n\t}\n\tv, err := ParseCiphers(testOk)\n\trequire.NoError(t, err)\n\tif got, want := v, ciphers; !reflect.DeepEqual(got, want) {\n\t\tt.Fatalf(\"got ciphers %#v want %#v\", got, want)\n\t}\n\n\t_, err = ParseCiphers(\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,cipherX\")\n\trequire.Error(t, err)\n\n\tv, err = ParseCiphers(\"\")\n\trequire.NoError(t, err)\n\trequire.Equal(t, []uint16{}, v)\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) LessOrEqualf(e1 interface{}, e2 interface{}, msg string, args ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tLessOrEqualf(a.t, e1, e2, msg, args...)\n}", "is_vulnerable": 0}
{"code": "func XMLToMap(r io.Reader) (map[string]string, error) {\n\tm := make(map[string]string)\n\tdec := xml.NewDecoder(io.LimitReader(r, maxBytes))\n\tvar tagName string\n\tfor {\n\t\tt, err := dec.Token()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\n\t\tswitch v := t.(type) {\n\t\tcase xml.StartElement:\n\t\t\ttagName = string(v.Name.Local)\n\t\tcase xml.CharData:\n\t\t\tm[tagName] = string(v)\n\t\t}\n\t}\n\treturn m, nil\n}", "is_vulnerable": 0}
{"code": "func (s *TestServer) handleStartup(client *pgproto3.Backend) error {\n\tstartupMessage, err := client.ReceiveStartupMessage()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif _, ok := startupMessage.(*pgproto3.StartupMessage); !ok {\n\t\treturn trace.BadParameter(\"expected *pgproto3.StartupMessage, got: %#v\", startupMessage)\n\t}\n\ts.log.Debugf(\"Received %#v.\", startupMessage)\n\t// If auth token is specified, used it for password authentication, this\n\t// simulates cloud provider IAM auth.\n\tif s.cfg.AuthToken != \"\" {\n\t\tif err := s.handlePasswordAuth(client); err != nil {\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\t// Accept auth and send ready for query.\n\tif err := client.Send(&pgproto3.AuthenticationOk{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := client.Send(&pgproto3.ReadyForQuery{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func List(username string, name string, subDir string) ([]*File, error) {\n\tlist := make([]*File, 0)\n\n\tpath, err := getPath(username, subDir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tpattern := filepath.Join(path, name, name+\".json\")\n\tfiles, err := filepath.Glob(pattern)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor _, file := range files {\n\t\tr, err := os.Open(file)\n\t\tif os.IsNotExist(err) {\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tb, err := ioutil.ReadAll(r)\n\t\tr.Close()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tf := &File{Path: file}\n\t\tif err := json.Unmarshal(b, f); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlist = append(list, f)\n\t}\n\n\treturn list, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) RunSSHCommand(ctx context.Context, in *sliverpb.SSHCommandReq, opts ...grpc.CallOption) (*sliverpb.SSHCommand, error) {\n\tout := new(sliverpb.SSHCommand)\n\terr := c.cc.Invoke(ctx, SliverRPC_RunSSHCommand_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func initLocales(opt Options) language.Matcher {\n\ttags := make([]language.Tag, len(opt.Langs))\n\tfor i, lang := range opt.Langs {\n\t\ttags[i] = language.Raw.Make(lang)\n\t\tfname := fmt.Sprintf(opt.Format, lang)\n\t\t// Append custom locale file.\n\t\tcustom := []interface{}{}\n\t\tcustomPath := path.Join(opt.CustomDirectory, fname)\n\t\tif com.IsFile(customPath) {\n\t\t\tcustom = append(custom, customPath)\n\t\t}\n\n\t\tvar locale interface{}\n\t\tif data, ok := opt.Files[fname]; ok {\n\t\t\tlocale = data\n\t\t} else {\n\t\t\tlocale = path.Join(opt.Directory, fname)\n\t\t}\n\n\t\terr := i18n.SetMessageWithDesc(lang, opt.Names[i], locale, custom...)\n\t\tif err != nil && err != i18n.ErrLangAlreadyExist {\n\t\t\tpanic(fmt.Errorf(\"fail to set message file(%s): %v\", lang, err))\n\t\t}\n\t}\n\treturn language.NewMatcher(tags)\n}", "is_vulnerable": 1}
{"code": "func (a *Archive) Name() string {\n\treturn unarrc.EntryGetName(a.archive)\n}", "is_vulnerable": 1}
{"code": "func RunPrecompiledContract(p PrecompiledContract, input []byte, suppliedGas uint64) (ret []byte, remainingGas uint64, err error) {\n\tgasCost := p.RequiredGas(input)\n\tif suppliedGas < gasCost {\n\t\treturn nil, 0, ErrOutOfGas\n\t}\n\tsuppliedGas -= gasCost\n\toutput, err := p.Run(input)\n\treturn output, suppliedGas, err\n}", "is_vulnerable": 0}
{"code": "\t\tAddFunc:    func(obj interface{}) { a(obj.(T)) },", "is_vulnerable": 1}
{"code": "func cloneServer(src *server, next http.Handler) *server {\n\tclone := &server{}\n\t*clone = *src\n\tclone.next = next\n\treturn clone\n}", "is_vulnerable": 0}
{"code": "func NewPublicKey(key interface{}) (PublicKey, error) {\n\tswitch key := key.(type) {\n\tcase *rsa.PublicKey:\n\t\treturn (*rsaPublicKey)(key), nil\n\tcase *ecdsa.PublicKey:\n\t\tif !supportedEllipticCurve(key.Curve) {\n\t\t\treturn nil, errors.New(\"ssh: only P-256, P-384 and P-521 EC keys are supported\")\n\t\t}\n\t\treturn (*ecdsaPublicKey)(key), nil\n\tcase *dsa.PublicKey:\n\t\treturn (*dsaPublicKey)(key), nil\n\tcase ed25519.PublicKey:\n\t\treturn (ed25519PublicKey)(key), nil\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"ssh: unsupported key type %T\", key)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) ListKeys(ctx context.Context, resourceGroupName string, accountName string) (result AccountListKeysResult, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/AccountsClient.ListKeys\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: accountName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"accountName\", Name: validation.MaxLength, Rule: 24, Chain: nil},\n\t\t\t\t{Target: \"accountName\", Name: validation.MinLength, Rule: 3, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"storage.AccountsClient\", \"ListKeys\", err.Error())\n\t}\n\n\treq, err := client.ListKeysPreparer(ctx, resourceGroupName, accountName)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListKeys\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.ListKeysSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListKeys\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.ListKeysResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"storage.AccountsClient\", \"ListKeys\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (va *ClawbackVestingAccount) TrackDelegation(_ time.Time, balance, amount sdk.Coins) {\n\t// Can only delegate vested (free) coins\n\tfor _, coin := range amount {\n\t\tbaseAmt := balance.AmountOf(coin.Denom)\n\t\t// Panic if the delegation amount is zero or if the base coins does not\n\t\t// exceed the desired delegation amount.\n\t\tif coin.Amount.IsZero() || baseAmt.LT(coin.Amount) {\n\t\t\tpanic(\"delegation attempt with zero coins or insufficient funds\")\n\t\t}\n\t\tva.DelegatedFree = va.DelegatedFree.Add(coin)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CrackstationRegister(ctx context.Context, in *clientpb.Crackstation, opts ...grpc.CallOption) (SliverRPC_CrackstationRegisterClient, error) {\n\tstream, err := c.cc.NewStream(ctx, &SliverRPC_ServiceDesc.Streams[2], SliverRPC_CrackstationRegister_FullMethodName, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tx := &sliverRPCCrackstationRegisterClient{stream}\n\tif err := x.ClientStream.SendMsg(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := x.ClientStream.CloseSend(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn x, nil\n}", "is_vulnerable": 1}
{"code": "func cleanHost(in string) string {\n\tif i := strings.IndexAny(in, \" /\"); i != -1 {\n\t\tin = in[:i]\n\t}\n\thost, port, err := net.SplitHostPort(in)\n\tif err != nil { // input was just a host\n\t\ta, err := idnaASCII(in)\n\t\tif err != nil {\n\t\t\treturn in // garbage in, garbage out\n\t\t}\n\t\treturn a\n\t}\n\ta, err := idnaASCII(host)\n\tif err != nil {\n\t\treturn in // garbage in, garbage out\n\t}\n\treturn net.JoinHostPort(a, port)\n}", "is_vulnerable": 1}
{"code": "func CsrfFromParam(param string) func(c *fiber.Ctx) (string, error) {\n\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.Params(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", ErrMissingParam\n\t\t}\n\t\treturn token, nil\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Compiler) Compile(conf *yaml_types.Workflow) (*backend_types.Config, error) {\n\tconfig := new(backend_types.Config)\n\n\tif match, err := conf.When.Match(c.metadata, true, c.env); !match && err == nil {\n\t\t// This pipeline does not match the configured filter so return an empty config and stop further compilation.\n\t\t// An empty pipeline will just be skipped completely.\n\t\treturn config, nil\n\t} else if err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create a default volume\n\tconfig.Volumes = append(config.Volumes, &backend_types.Volume{\n\t\tName: fmt.Sprintf(\"%s_default\", c.prefix),\n\t})\n\n\t// create a default network\n\tconfig.Networks = append(config.Networks, &backend_types.Network{\n\t\tName: fmt.Sprintf(\"%s_default\", c.prefix),\n\t})\n\n\t// create secrets for mask\n\tfor _, sec := range c.secrets {\n\t\tconfig.Secrets = append(config.Secrets, &backend_types.Secret{\n\t\t\tName:  sec.Name,\n\t\t\tValue: sec.Value,\n\t\t})\n\t}\n\n\t// overrides the default workspace paths when specified\n\t// in the YAML file.\n\tif len(conf.Workspace.Base) != 0 {\n\t\tc.base = conf.Workspace.Base\n\t}\n\tif len(conf.Workspace.Path) != 0 {\n\t\tc.path = conf.Workspace.Path\n\t}\n\n\tcloneImage := constant.DefaultCloneImage\n\tif len(c.defaultCloneImage) > 0 {\n\t\tcloneImage = c.defaultCloneImage\n\t}\n\n\t// add default clone step\n\tif !c.local && len(conf.Clone.ContainerList) == 0 && !conf.SkipClone {\n\t\tcloneSettings := map[string]any{\"depth\": \"0\"}\n\t\tif c.metadata.Curr.Event == metadata.EventTag {\n\t\t\tcloneSettings[\"tags\"] = \"true\"\n\t\t}\n\t\tcontainer := &yaml_types.Container{\n\t\t\tName:        defaultCloneName,\n\t\t\tImage:       cloneImage,\n\t\t\tSettings:    cloneSettings,\n\t\t\tEnvironment: make(map[string]any),\n\t\t}\n\t\tfor k, v := range c.cloneEnv {\n\t\t\tcontainer.Environment[k] = v\n\t\t}\n\t\tstep, err := c.createProcess(container, backend_types.StepTypeClone)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstage := new(backend_types.Stage)\n\t\tstage.Steps = append(stage.Steps, step)\n\n\t\tconfig.Stages = append(config.Stages, stage)\n\t} else if !c.local && !conf.SkipClone {\n\t\tfor _, container := range conf.Clone.ContainerList {\n\t\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstage := new(backend_types.Stage)\n\n\t\t\tstep, err := c.createProcess(container, backend_types.StepTypeClone)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// only inject netrc if it's a trusted repo or a trusted plugin\n\t\t\tif !c.netrcOnlyTrusted || c.trustedPipeline || (container.IsPlugin() && container.IsTrustedCloneImage()) {\n\t\t\t\tfor k, v := range c.cloneEnv {\n\t\t\t\t\tstep.Environment[k] = v\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tstage.Steps = append(stage.Steps, step)\n\n\t\t\tconfig.Stages = append(config.Stages, stage)\n\t\t}\n\t}\n\n\t// add services steps\n\tif len(conf.Services.ContainerList) != 0 {\n\t\tstage := new(backend_types.Stage)\n\n\t\tfor _, container := range conf.Services.ContainerList {\n\t\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstep, err := c.createProcess(container, backend_types.StepTypeService)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstage.Steps = append(stage.Steps, step)\n\t\t}\n\t\tconfig.Stages = append(config.Stages, stage)\n\t}\n\n\t// add pipeline steps\n\tsteps := make([]*dagCompilerStep, 0, len(conf.Steps.ContainerList))\n\tfor pos, container := range conf.Steps.ContainerList {\n\t\t// Skip if local and should not run local\n\t\tif c.local && !container.When.IsLocal() {\n\t\t\tcontinue\n\t\t}\n\n\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstepType := backend_types.StepTypeCommands\n\t\tif container.IsPlugin() {\n\t\t\tstepType = backend_types.StepTypePlugin\n\t\t}\n\t\tstep, err := c.createProcess(container, stepType)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// inject netrc if it's a trusted repo or a trusted clone-plugin\n\t\tif c.trustedPipeline || (container.IsPlugin() && container.IsTrustedCloneImage()) {\n\t\t\tfor k, v := range c.cloneEnv {\n\t\t\t\tstep.Environment[k] = v\n\t\t\t}\n\t\t}\n\n\t\tsteps = append(steps, &dagCompilerStep{\n\t\t\tstep:      step,\n\t\t\tposition:  pos,\n\t\t\tname:      container.Name,\n\t\t\tgroup:     container.Group,\n\t\t\tdependsOn: container.DependsOn,\n\t\t})\n\t}\n\n\t// generate stages out of steps\n\tstepStages, err := newDAGCompiler(steps).compile()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tconfig.Stages = append(config.Stages, stepStages...)\n\n\treturn config, nil\n}", "is_vulnerable": 1}
{"code": "func isAllowedToAccessMetricsEndpoint(r *http.Request) bool {\n\tif config.Opts.MetricsUsername() != \"\" && config.Opts.MetricsPassword() != \"\" {\n\t\tclientIP := request.ClientIP(r)\n\t\tusername, password, authOK := r.BasicAuth()\n\t\tif !authOK {\n\t\t\tlogger.Info(\"[Metrics] [ClientIP=%s] No authentication header sent\", clientIP)\n\t\t\treturn false\n\t\t}\n\n\t\tif username == \"\" || password == \"\" {\n\t\t\tlogger.Info(\"[Metrics] [ClientIP=%s] Empty username or password\", clientIP)\n\t\t\treturn false\n\t\t}\n\n\t\tif username != config.Opts.MetricsUsername() || password != config.Opts.MetricsPassword() {\n\t\t\tlogger.Error(\"[Metrics] [ClientIP=%s] Invalid username or password\", clientIP)\n\t\t\treturn false\n\t\t}\n\t}\n\n\tfor _, cidr := range config.Opts.MetricsAllowedNetworks() {\n\t\t_, network, err := net.ParseCIDR(cidr)\n\t\tif err != nil {\n\t\t\tlogger.Fatal(`[Metrics] Unable to parse CIDR %v`, err)\n\t\t}\n\n\t\t// We use r.RemoteAddr in this case because HTTP headers like X-Forwarded-For can be easily spoofed.\n\t\t// The recommendation is to use HTTP Basic authentication.\n\t\tif network.Contains(net.ParseIP(request.FindRemoteIP(r))) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func ConsumeEnvelope(data []byte, domain string) (envelope *Envelope, rec Record, err error) {\n\te, err := UnmarshalEnvelope(data)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed when unmarshalling the envelope: %w\", err)\n\t}\n\n\terr = e.validate(domain)\n\tif err != nil {\n\t\treturn e, nil, fmt.Errorf(\"failed to validate envelope: %w\", err)\n\t}\n\n\trec, err = e.Record()\n\tif err != nil {\n\t\treturn e, nil, fmt.Errorf(\"failed to unmarshal envelope payload: %w\", err)\n\t}\n\treturn e, rec, nil\n}", "is_vulnerable": 1}
{"code": "func TestPathRoleSet_Basic(t *testing.T) {\n\trsName := \"test-basicrs\"\n\troles := util.StringSet{\n\t\t\"roles/viewer\": struct{}{},\n\t}\n\n\ttd := setupTest(t, \"0s\", \"2h\")\n\tdefer cleanup(t, td, rsName, roles)\n\n\tprojRes := fmt.Sprintf(testProjectResourceTemplate, td.Project)\n\n\t// 1. Read should return nothing\n\trespData := testRoleSetRead(t, td, rsName)\n\tif respData != nil {\n\t\tt.Fatalf(\"expected role set to not exist initially\")\n\t}\n\n\t// 2. Create new role set\n\texpectedBinds := ResourceBindings{projRes: roles}\n\tbindsRaw, err := util.BindingsHCL(expectedBinds)\n\tif err != nil {\n\t\tt.Fatalf(\"unable to convert resource bindings to HCL string: %v\", err)\n\t}\n\ttestRoleSetCreate(t, td, rsName,\n\t\tmap[string]interface{}{\n\t\t\t\"project\":      td.Project,\n\t\t\t\"bindings\":     bindsRaw,\n\t\t\t\"token_scopes\": []string{iam.CloudPlatformScope},\n\t\t})\n\n\t// 3. Read role set\n\trespData = testRoleSetRead(t, td, rsName)\n\tif respData == nil {\n\t\tt.Fatalf(\"expected role set to have been created\")\n\t}\n\n\tverifyReadData(t, respData, map[string]interface{}{\n\t\t\"secret_type\": SecretTypeAccessToken, // default\n\t\t\"project\":     td.Project,\n\t\t\"bindings\":    expectedBinds,\n\t})\n\n\t// Verify service account exists and has given role on project\n\tsa := getServiceAccount(t, td.IamAdmin, respData)\n\tverifyProjectBinding(t, td, sa.Email, roles)\n\n\t// 4. Delete role set\n\ttestRoleSetDelete(t, td, rsName, sa.Name)\n\tverifyProjectBindingsRemoved(t, td, sa.Email, roles)\n}", "is_vulnerable": 0}
{"code": "\t\t\tt.Run(fmt.Sprintf(\"envelopeType=%v_keySpec=%v\", envelopeType, keyCert.keySpecName), func(t *testing.T) {\n\t\t\t\ts, err := New(keyCert.key, keyCert.certs)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"NewSigner() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\tctx := context.Background()\n\t\t\t\tdesc, sOpts := generateSigningContent()\n\t\t\t\tsOpts.ExpiryDuration = 0 // reset expiry\n\t\t\t\tsOpts.SignatureMediaType = envelopeType\n\t\t\t\tsig, _, err := s.Sign(ctx, desc, sOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Sign() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// basic verification\n\t\t\t\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], nil)\n\t\t\t})", "is_vulnerable": 0}
{"code": "\t\treturn true, func() {}", "is_vulnerable": 1}
{"code": "func (r *streamReader) readTail() error {\n\tindex, n, err := readIndexBody(r.xz)\n\tif err != nil {\n\t\tif err == io.EOF {\n\t\t\terr = io.ErrUnexpectedEOF\n\t\t}\n\t\treturn err\n\t}\n\tif len(index) != len(r.index) {\n\t\treturn fmt.Errorf(\"xz: index length is %d; want %d\",\n\t\t\tlen(index), len(r.index))\n\t}\n\tfor i, rec := range r.index {\n\t\tif rec != index[i] {\n\t\t\treturn fmt.Errorf(\"xz: record %d is %v; want %v\",\n\t\t\t\ti, rec, index[i])\n\t\t}\n\t}\n\n\tp := make([]byte, footerLen)\n\tif _, err = io.ReadFull(r.xz, p); err != nil {\n\t\tif err == io.EOF {\n\t\t\terr = io.ErrUnexpectedEOF\n\t\t}\n\t\treturn err\n\t}\n\tvar f footer\n\tif err = f.UnmarshalBinary(p); err != nil {\n\t\treturn err\n\t}\n\txlog.Debugf(\"xz footer %s\", f)\n\tif f.flags != r.h.flags {\n\t\treturn errors.New(\"xz: footer flags incorrect\")\n\t}\n\tif f.indexSize != int64(n)+1 {\n\t\treturn errors.New(\"xz: index size in footer wrong\")\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestPlainSplit_NoUser(t *testing.T) {\n\ta := Auth{\n\t\tpasswd: []module.PlainAuth{\n\t\t\tmockAuth{\n\t\t\t\tdb: map[string]bool{\n\t\t\t\t\t\"user1\": true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\terr := a.AuthPlain(\"user1\", \"aaa\")\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected error:\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (b *BasicEnvoyExtender) Extend(resources *xdscommon.IndexedResources, config *RuntimeConfig) (*xdscommon.IndexedResources, error) {\n\tvar resultErr error\n\n\t// We don't support patching the local proxy with an upstream's config except in special\n\t// cases supported by UpstreamEnvoyExtender.\n\tif config.IsSourcedFromUpstream {\n\t\treturn nil, fmt.Errorf(\"%q extension applied as local config but is sourced from an upstream of the local service\", config.EnvoyExtension.Name)\n\t}\n\n\tswitch config.Kind {\n\tcase api.ServiceKindTerminatingGateway, api.ServiceKindConnectProxy:\n\tdefault:\n\t\treturn resources, nil\n\t}\n\n\tif !b.Extension.CanApply(config) {\n\t\treturn resources, nil\n\t}\n\n\tfor _, indexType := range []string{\n\t\txdscommon.ListenerType,\n\t\txdscommon.RouteType,\n\t\txdscommon.ClusterType,\n\t} {\n\t\tfor nameOrSNI, msg := range resources.Index[indexType] {\n\t\t\tswitch resource := msg.(type) {\n\t\t\tcase *envoy_cluster_v3.Cluster:\n\t\t\t\tnewCluster, patched, err := b.Extension.PatchCluster(config, resource)\n\t\t\t\tif err != nil {\n\t\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching cluster: %w\", err))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif patched {\n\t\t\t\t\tresources.Index[xdscommon.ClusterType][nameOrSNI] = newCluster\n\t\t\t\t}\n\n\t\t\tcase *envoy_listener_v3.Listener:\n\t\t\t\tnewListener, patched, err := b.patchListener(config, resource)\n\t\t\t\tif err != nil {\n\t\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching listener: %w\", err))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif patched {\n\t\t\t\t\tresources.Index[xdscommon.ListenerType][nameOrSNI] = newListener\n\t\t\t\t}\n\n\t\t\tcase *envoy_route_v3.RouteConfiguration:\n\t\t\t\tnewRoute, patched, err := b.Extension.PatchRoute(config, resource)\n\t\t\t\tif err != nil {\n\t\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching route: %w\", err))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif patched {\n\t\t\t\t\tresources.Index[xdscommon.RouteType][nameOrSNI] = newRoute\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"unsupported type was skipped: %T\", resource))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn resources, resultErr\n}", "is_vulnerable": 0}
{"code": "func TestAddEndpoints(t *testing.T) {\n\trouter := newFakeTemplateRouter()\n\tsuKey := \"test\"\n\trouter.CreateServiceUnit(suKey)\n\n\tif _, ok := router.FindServiceUnit(suKey); !ok {\n\t\tt.Errorf(\"Unable to find serivce unit %s after creation\", suKey)\n\t}\n\n\tendpoint := Endpoint{\n\t\tID:     \"ep1\",\n\t\tIP:     \"ip\",\n\t\tPort:   \"port\",\n\t\tIdHash: fmt.Sprintf(\"%x\", md5.Sum([]byte(\"ep1ipport\"))),\n\t}\n\n\trouter.AddEndpoints(suKey, []Endpoint{endpoint})\n\n\tsu, ok := router.FindServiceUnit(suKey)\n\n\tif !ok {\n\t\tt.Errorf(\"Unable to find created service unit %s\", suKey)\n\t} else {\n\t\tif len(su.EndpointTable) != 1 {\n\t\t\tt.Errorf(\"Expected endpoint table to contain 1 entry\")\n\t\t} else {\n\t\t\tactualEp := su.EndpointTable[0]\n\t\t\tif endpoint.IP != actualEp.IP || endpoint.Port != actualEp.Port || endpoint.IdHash != actualEp.IdHash {\n\t\t\t\tt.Errorf(\"Expected endpoint %v did not match actual endpoint %v\", endpoint, actualEp)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *MSPMessageCryptoService) VerifyBlock(chainID common.ChannelID, seqNum uint64, block *pcommon.Block) error {\n\tif block.Header == nil {\n\t\treturn fmt.Errorf(\"Invalid Block on channel [%s]. Header must be different from nil.\", chainID)\n\t}\n\n\tblockSeqNum := block.Header.Number\n\tif seqNum != blockSeqNum {\n\t\treturn fmt.Errorf(\"Claimed seqNum is [%d] but actual seqNum inside block is [%d]\", seqNum, blockSeqNum)\n\t}\n\n\t// - Extract channelID and compare with chainID\n\tchannelID, err := protoutil.GetChannelIDFromBlock(block)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed getting channel id from block with id [%d] on channel [%s]: [%s]\", block.Header.Number, chainID, err)\n\t}\n\n\tif channelID != string(chainID) {\n\t\treturn fmt.Errorf(\"Invalid block's channel id. Expected [%s]. Given [%s]\", chainID, channelID)\n\t}\n\n\t// - Unmarshal medatada\n\tif block.Metadata == nil || len(block.Metadata.Metadata) == 0 {\n\t\treturn fmt.Errorf(\"Block with id [%d] on channel [%s] does not have metadata. Block not valid.\", block.Header.Number, chainID)\n\t}\n\n\tmetadata, err := protoutil.GetMetadataFromBlock(block, pcommon.BlockMetadataIndex_SIGNATURES)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed unmarshalling medatata for signatures [%s]\", err)\n\t}\n\n\tif err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {\n\t\treturn fmt.Errorf(\"block has malformed transactions: %v\", err)\n\t}\n\n\t// - Verify that Header.DataHash is equal to the hash of block.Data\n\t// This is to ensure that the header is consistent with the data carried by this block\n\tif !bytes.Equal(protoutil.BlockDataHash(block.Data), block.Header.DataHash) {\n\t\treturn fmt.Errorf(\"Header.DataHash is different from Hash(block.Data) for block with id [%d] on channel [%s]\", block.Header.Number, chainID)\n\t}\n\n\t// - Get Policy for block validation\n\n\t// Get the policy manager for channelID\n\tcpm := s.channelPolicyManagerGetter.Manager(channelID)\n\tif cpm == nil {\n\t\treturn fmt.Errorf(\"Could not acquire policy manager for channel %s\", channelID)\n\t}\n\tmcsLogger.Debugf(\"Got policy manager for channel [%s]\", channelID)\n\n\t// Get block validation policy\n\tpolicy, ok := cpm.GetPolicy(policies.BlockValidation)\n\t// ok is true if it was the policy requested, or false if it is the default policy\n\tmcsLogger.Debugf(\"Got block validation policy for channel [%s] with flag [%t]\", channelID, ok)\n\n\t// - Prepare SignedData\n\tsignatureSet := []*protoutil.SignedData{}\n\tfor _, metadataSignature := range metadata.Signatures {\n\t\tshdr, err := protoutil.UnmarshalSignatureHeader(metadataSignature.SignatureHeader)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Failed unmarshalling signature header for block with id [%d] on channel [%s]: [%s]\", block.Header.Number, chainID, err)\n\t\t}\n\t\tsignatureSet = append(\n\t\t\tsignatureSet,\n\t\t\t&protoutil.SignedData{\n\t\t\t\tIdentity:  shdr.Creator,\n\t\t\t\tData:      util.ConcatenateBytes(metadata.Value, metadataSignature.SignatureHeader, protoutil.BlockHeaderBytes(block.Header)),\n\t\t\t\tSignature: metadataSignature.Signature,\n\t\t\t},\n\t\t)\n\t}\n\n\t// - Evaluate policy\n\treturn policy.EvaluateSignedData(signatureSet)\n}", "is_vulnerable": 0}
{"code": "func benchmarkPrecompiled(addr string, test precompiledTest, bench *testing.B) {\n\tif test.NoBenchmark {\n\t\treturn\n\t}\n\tp := allPrecompiles[common.HexToAddress(addr)]\n\tin := common.Hex2Bytes(test.Input)\n\treqGas := p.RequiredGas(in)\n\tcontract := NewContract(AccountRef(common.HexToAddress(\"1337\")),\n\t\tnil, new(big.Int), reqGas)\n\n\tvar (\n\t\tres  []byte\n\t\terr  error\n\t\tdata = make([]byte, len(in))\n\t)\n\n\tbench.Run(fmt.Sprintf(\"%s-Gas=%d\", test.Name, contract.Gas), func(bench *testing.B) {\n\t\tbench.ReportAllocs()\n\t\tstart := time.Now().Nanosecond()\n\t\tbench.ResetTimer()\n\t\tfor i := 0; i < bench.N; i++ {\n\t\t\tcontract.Gas = reqGas\n\t\t\tcopy(data, in)\n\t\t\tres, err = RunPrecompiledContract(p, data, contract)\n\t\t}\n\t\tbench.StopTimer()\n\t\telapsed := float64(time.Now().Nanosecond() - start)\n\t\tif elapsed < 1 {\n\t\t\telapsed = 1\n\t\t}\n\t\tgasUsed := reqGas * uint64(bench.N)\n\t\tbench.ReportMetric(float64(reqGas), \"gas/op\")\n\t\tbench.ReportMetric(float64(gasUsed*1000)/elapsed, \"mgas/s\")\n\t\t//Check if it is correct\n\t\tif err != nil {\n\t\t\tbench.Error(err)\n\t\t\treturn\n\t\t}\n\t\tif common.Bytes2Hex(res) != test.Expected {\n\t\t\tbench.Error(fmt.Sprintf(\"Expected %v, got %v\", test.Expected, common.Bytes2Hex(res)))\n\t\t\treturn\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func (hs *HTTPServer) pluginMarkdown(ctx context.Context, pluginId string, name string) ([]byte, error) {\n\tplugin, exists := hs.pluginStore.Plugin(ctx, pluginId)\n\tif !exists {\n\t\treturn nil, plugins.NotFoundError{PluginID: pluginId}\n\t}\n\n\t// nolint:gosec\n\t// We can ignore the gosec G304 warning on this one because `plugin.PluginDir` is based\n\t// on plugin the folder structure on disk and not user input.\n\tpath := filepath.Join(plugin.PluginDir, fmt.Sprintf(\"%s.md\", strings.ToUpper(name)))\n\texists, err := fs.Exists(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !exists {\n\t\tpath = filepath.Join(plugin.PluginDir, fmt.Sprintf(\"%s.md\", strings.ToLower(name)))\n\t}\n\n\texists, err = fs.Exists(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !exists {\n\t\treturn make([]byte, 0), nil\n\t}\n\n\t// nolint:gosec\n\t// We can ignore the gosec G304 warning on this one because `plugin.PluginDir` is based\n\t// on plugin the folder structure on disk and not user input.\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn data, nil\n}", "is_vulnerable": 1}
{"code": "func (nvd NonceVerificationDecorator) AnteHandle(ctx sdk.Context, tx sdk.Tx, simulate bool, next sdk.AnteHandler) (newCtx sdk.Context, err error) {\n\tmsgEthTx, ok := tx.(evmtypes.MsgEthereumTx)\n\tif !ok {\n\t\treturn ctx, sdkerrors.Wrapf(sdkerrors.ErrUnknownRequest, \"invalid transaction type: %T\", tx)\n\t}\n\n\t// sender address should be in the tx cache from the previous AnteHandle call\n\taddress := msgEthTx.From()\n\tif address.Empty() {\n\t\tpanic(\"sender address cannot be empty\")\n\t}\n\n\tacc := nvd.ak.GetAccount(ctx, address)\n\tif acc == nil {\n\t\treturn ctx, sdkerrors.Wrapf(\n\t\t\tsdkerrors.ErrUnknownAddress,\n\t\t\t\"account %s (%s) is nil\", common.BytesToAddress(address.Bytes()), address,\n\t\t)\n\t}\n\n\tseq := acc.GetSequence()\n\t// if multiple transactions are submitted in succession with increasing nonces,\n\t// all will be rejected except the first, since the first needs to be included in a block\n\t// before the sequence increments\n\tif msgEthTx.Data.AccountNonce != seq {\n\t\treturn ctx, sdkerrors.Wrapf(\n\t\t\tsdkerrors.ErrInvalidSequence,\n\t\t\t\"invalid nonce; got %d, expected %d\", msgEthTx.Data.AccountNonce, seq,\n\t\t)\n\t}\n\n\treturn next(ctx, tx, simulate)\n}", "is_vulnerable": 0}
{"code": "func Syscall9(trap, a1, a2, a3, a4, a5, a6, a7, a8, a9 uintptr) (r1, r2 uintptr, err syscall.Errno)\n\n//sys\tdup2(oldfd int, newfd int) (err error)\n//sysnb\tEpollCreate(size int) (fd int, err error)\n//sys\tEpollWait(epfd int, events []EpollEvent, msec int) (n int, err error)\n//sys\tFadvise(fd int, offset int64, length int64, advice int) (err error) = SYS_FADVISE64\n//sys\tFchown(fd int, uid int, gid int) (err error)\n//sys\tFtruncate(fd int, length int64) (err error) = SYS_FTRUNCATE64\n//sysnb\tGetegid() (egid int)\n//sysnb\tGeteuid() (euid int)\n//sysnb\tGetgid() (gid int)\n//sysnb\tGetuid() (uid int)\n//sys\tLchown(path string, uid int, gid int) (err error)\n//sys\tListen(s int, n int) (err error)\n//sys\tPread(fd int, p []byte, offset int64) (n int, err error) = SYS_PREAD64\n//sys\tPwrite(fd int, p []byte, offset int64) (n int, err error) = SYS_PWRITE64\n//sys\tRenameat(olddirfd int, oldpath string, newdirfd int, newpath string) (err error)\n//sys\tSelect(nfd int, r *FdSet, w *FdSet, e *FdSet, timeout *Timeval) (n int, err error) = SYS__NEWSELECT\n//sys\tsendfile(outfd int, infd int, offset *int64, count int) (written int, err error) = SYS_SENDFILE64\n//sys\tsetfsgid(gid int) (prev int, err error)\n//sys\tsetfsuid(uid int) (prev int, err error)\n//sysnb\tSetregid(rgid int, egid int) (err error)\n//sysnb\tSetresgid(rgid int, egid int, sgid int) (err error)\n//sysnb\tSetresuid(ruid int, euid int, suid int) (err error)\n//sysnb\tSetreuid(ruid int, euid int) (err error)\n//sys\tShutdown(fd int, how int) (err error)\n//sys\tSplice(rfd int, roff *int64, wfd int, woff *int64, len int, flags int) (n int, err error)\n//sys\tSyncFileRange(fd int, off int64, n int64, flags int) (err error)\n//sys\tTruncate(path string, length int64) (err error) = SYS_TRUNCATE64\n//sys\tUstat(dev int, ubuf *Ustat_t) (err error)\n//sys\taccept(s int, rsa *RawSockaddrAny, addrlen *_Socklen) (fd int, err error)\n//sys\taccept4(s int, rsa *RawSockaddrAny, addrlen *_Socklen, flags int) (fd int, err error)\n//sys\tbind(s int, addr unsafe.Pointer, addrlen _Socklen) (err error)\n//sys\tconnect(s int, addr unsafe.Pointer, addrlen _Socklen) (err error)\n//sysnb\tgetgroups(n int, list *_Gid_t) (nn int, err error)\n//sysnb\tsetgroups(n int, list *_Gid_t) (err error)\n//sys\tgetsockopt(s int, level int, name int, val unsafe.Pointer, vallen *_Socklen) (err error)\n//sys\tsetsockopt(s int, level int, name int, val unsafe.Pointer, vallen uintptr) (err error)\n//sysnb\tsocket(domain int, typ int, proto int) (fd int, err error)\n//sysnb\tsocketpair(domain int, typ int, proto int, fd *[2]int32) (err error)\n//sysnb\tgetpeername(fd int, rsa *RawSockaddrAny, addrlen *_Socklen) (err error)\n//sysnb\tgetsockname(fd int, rsa *RawSockaddrAny, addrlen *_Socklen) (err error)\n//sys\trecvfrom(fd int, p []byte, flags int, from *RawSockaddrAny, fromlen *_Socklen) (n int, err error)\n//sys\tsendto(s int, buf []byte, flags int, to unsafe.Pointer, addrlen _Socklen) (err error)\n//sys\trecvmsg(s int, msg *Msghdr, flags int) (n int, err error)\n//sys\tsendmsg(s int, msg *Msghdr, flags int) (n int, err error)\n\n//sysnb\tInotifyInit() (fd int, err error)\n//sys\tIoperm(from int, num int, on int) (err error)\n//sys\tIopl(level int) (err error)\n\n//sys\tfutimesat(dirfd int, path string, times *[2]Timeval) (err error)\n//sysnb\tGettimeofday(tv *Timeval) (err error)\n//sysnb\tTime(t *Time_t) (tt Time_t, err error)\n//sys\tUtime(path string, buf *Utimbuf) (err error)\n//sys\tutimes(path string, times *[2]Timeval) (err error)\n\n//sys\tLstat(path string, stat *Stat_t) (err error) = SYS_LSTAT64\n//sys\tFstat(fd int, stat *Stat_t) (err error) = SYS_FSTAT64\n//sys\tFstatat(dirfd int, path string, stat *Stat_t, flags int) (err error) = SYS_FSTATAT64\n//sys\tStat(path string, stat *Stat_t) (err error) = SYS_STAT64\n\n//sys\tPause() (err error)\n\nfunc Fstatfs(fd int, buf *Statfs_t) (err error) {\n\t_, _, e := Syscall(SYS_FSTATFS64, uintptr(fd), unsafe.Sizeof(*buf), uintptr(unsafe.Pointer(buf)))\n\tif e != 0 {\n\t\terr = errnoErr(e)\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestUnmarshalConfig(t *testing.T) {\n\trawConfig := []byte(`\nissuer: http://127.0.0.1:5556/dex\nstorage:\n  type: postgres\n  config:\n    host: 10.0.0.1\n    port: 65432\n    maxOpenConns: 5\n    maxIdleConns: 3\n    connMaxLifetime: 30\n    connectionTimeout: 3\nweb:\n  http: 127.0.0.1:5556\n\nfrontend:\n  dir: ./web\n  extra:\n    foo: bar\n\nstaticClients:\n- id: example-app\n  redirectURIs:\n  - 'http://127.0.0.1:5555/callback'\n  name: 'Example App'\n  secret: ZXhhbXBsZS1hcHAtc2VjcmV0\n\noauth2:\n  alwaysShowLoginScreen: true\n  grantTypes:\n  - refresh_token\n  - \"urn:ietf:params:oauth:grant-type:token-exchange\"\n\nconnectors:\n- type: mockCallback\n  id: mock\n  name: Example\n- type: oidc\n  id: google\n  name: Google\n  config:\n    issuer: https://accounts.google.com\n    clientID: foo\n    clientSecret: bar\n    redirectURI: http://127.0.0.1:5556/dex/callback/google\n\nenablePasswordDB: true\nstaticPasswords:\n- email: \"admin@example.com\"\n  # bcrypt hash of the string \"password\"\n  hash: \"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"\n  username: \"admin\"\n  userID: \"08a8684b-db88-4b73-90a9-3cd1661f5466\"\n- email: \"foo@example.com\"\n  # base64'd value of the same bcrypt hash above. We want to be able to parse both of these\n  hash: \"JDJhJDEwJDMzRU1UMGNWWVZsUHk2V0FNQ0xzY2VMWWpXaHVIcGJ6NXl1Wnh1L0dBRmowM0o5THl0anV5\"\n  username: \"foo\"\n  userID: \"41331323-6f44-45e6-b3b9-2c4b60c02be5\"\n\nexpiry:\n  signingKeys: \"7h\"\n  idTokens: \"25h\"\n  authRequests: \"25h\"\n  deviceRequests: \"10m\"\n\nlogger:\n  level: \"debug\"\n  format: \"json\"\n`)\n\n\twant := Config{\n\t\tIssuer: \"http://127.0.0.1:5556/dex\",\n\t\tStorage: Storage{\n\t\t\tType: \"postgres\",\n\t\t\tConfig: &sql.Postgres{\n\t\t\t\tNetworkDB: sql.NetworkDB{\n\t\t\t\t\tHost:              \"10.0.0.1\",\n\t\t\t\t\tPort:              65432,\n\t\t\t\t\tMaxOpenConns:      5,\n\t\t\t\t\tMaxIdleConns:      3,\n\t\t\t\t\tConnMaxLifetime:   30,\n\t\t\t\t\tConnectionTimeout: 3,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tWeb: Web{\n\t\t\tHTTP: \"127.0.0.1:5556\",\n\t\t},\n\t\tFrontend: server.WebConfig{\n\t\t\tDir: \"./web\",\n\t\t\tExtra: map[string]string{\n\t\t\t\t\"foo\": \"bar\",\n\t\t\t},\n\t\t},\n\t\tStaticClients: []storage.Client{\n\t\t\t{\n\t\t\t\tID:     \"example-app\",\n\t\t\t\tSecret: \"ZXhhbXBsZS1hcHAtc2VjcmV0\",\n\t\t\t\tName:   \"Example App\",\n\t\t\t\tRedirectURIs: []string{\n\t\t\t\t\t\"http://127.0.0.1:5555/callback\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tOAuth2: OAuth2{\n\t\t\tAlwaysShowLoginScreen: true,\n\t\t\tGrantTypes: []string{\n\t\t\t\t\"refresh_token\",\n\t\t\t\t\"urn:ietf:params:oauth:grant-type:token-exchange\",\n\t\t\t},\n\t\t},\n\t\tStaticConnectors: []Connector{\n\t\t\t{\n\t\t\t\tType:   \"mockCallback\",\n\t\t\t\tID:     \"mock\",\n\t\t\t\tName:   \"Example\",\n\t\t\t\tConfig: &mock.CallbackConfig{},\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"oidc\",\n\t\t\t\tID:   \"google\",\n\t\t\t\tName: \"Google\",\n\t\t\t\tConfig: &oidc.Config{\n\t\t\t\t\tIssuer:       \"https://accounts.google.com\",\n\t\t\t\t\tClientID:     \"foo\",\n\t\t\t\t\tClientSecret: \"bar\",\n\t\t\t\t\tRedirectURI:  \"http://127.0.0.1:5556/dex/callback/google\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tEnablePasswordDB: true,\n\t\tStaticPasswords: []password{\n\t\t\t{\n\t\t\t\tEmail:    \"admin@example.com\",\n\t\t\t\tHash:     []byte(\"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"),\n\t\t\t\tUsername: \"admin\",\n\t\t\t\tUserID:   \"08a8684b-db88-4b73-90a9-3cd1661f5466\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tEmail:    \"foo@example.com\",\n\t\t\t\tHash:     []byte(\"$2a$10$33EMT0cVYVlPy6WAMCLsceLYjWhuHpbz5yuZxu/GAFj03J9Lytjuy\"),\n\t\t\t\tUsername: \"foo\",\n\t\t\t\tUserID:   \"41331323-6f44-45e6-b3b9-2c4b60c02be5\",\n\t\t\t},\n\t\t},\n\t\tExpiry: Expiry{\n\t\t\tSigningKeys:    \"7h\",\n\t\t\tIDTokens:       \"25h\",\n\t\t\tAuthRequests:   \"25h\",\n\t\t\tDeviceRequests: \"10m\",\n\t\t},\n\t\tLogger: Logger{\n\t\t\tLevel:  \"debug\",\n\t\t\tFormat: \"json\",\n\t\t},\n\t}\n\n\tvar c Config\n\tif err := yaml.Unmarshal(rawConfig, &c); err != nil {\n\t\tt.Fatalf(\"failed to decode config: %v\", err)\n\t}\n\tif diff := pretty.Compare(c, want); diff != \"\" {\n\t\tt.Errorf(\"got!=want: %s\", diff)\n\t}\n}\n\nfunc TestUnmarshalConfigWithEnvNoExpand(t *testing.T) {\n\t// If the env variable DEX_EXPAND_ENV is set and has a \"falsy\" value, os.ExpandEnv is disabled.\n\t// ParseBool: \"It accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False.\"\n\tcheckUnmarshalConfigWithEnv(t, \"0\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"f\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"F\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"FALSE\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"false\", false)\n\tcheckUnmarshalConfigWithEnv(t, \"False\", false)\n\tos.Unsetenv(\"DEX_EXPAND_ENV\")\n}\n\nfunc TestUnmarshalConfigWithEnvExpand(t *testing.T) {\n\t// If the env variable DEX_EXPAND_ENV is unset or has a \"truthy\" or unknown value, os.ExpandEnv is enabled.\n\t// ParseBool: \"It accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False.\"\n\tcheckUnmarshalConfigWithEnv(t, \"1\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"t\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"T\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"TRUE\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"true\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"True\", true)\n\t// Values that can't be parsed as bool:\n\tcheckUnmarshalConfigWithEnv(t, \"UNSET\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"\", true)\n\tcheckUnmarshalConfigWithEnv(t, \"whatever - true is default\", true)\n\tos.Unsetenv(\"DEX_EXPAND_ENV\")\n}", "is_vulnerable": 1}
{"code": "func (src *CommandComplete) Encode(dst []byte) []byte {\n\tdst = append(dst, 'C')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\n\tdst = append(dst, src.CommandTag...)\n\tdst = append(dst, 0)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tctx := context.Background()\n\t\t\tstoreID := ulid.Make().String()\n\n\t\t\t// arrange: write model\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              ulid.Make().String(),\n\t\t\t\tSchemaVersion:   test.schema,\n\t\t\t\tTypeDefinitions: parser.MustParse(test.model),\n\t\t\t}\n\t\t\terr := ds.WriteAuthorizationModel(ctx, storeID, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// arrange: write tuples\n\t\t\terr = ds.Write(context.Background(), storeID, nil, test.tuples)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// act: run ListObjects\n\n\t\t\tlistObjectsDeadline := time.Minute\n\t\t\tif test.listObjectsDeadline > 0 {\n\t\t\t\tlistObjectsDeadline = test.listObjectsDeadline\n\t\t\t}\n\n\t\t\tdatastore := ds\n\t\t\tif test.readTuplesDelay > 0 {\n\t\t\t\tdatastore = mocks.NewMockSlowDataStorage(ds, test.readTuplesDelay)\n\t\t\t}\n\n\t\t\tlistObjectsQuery := &commands.ListObjectsQuery{\n\t\t\t\tDatastore:             datastore,\n\t\t\t\tLogger:                logger.NewNoopLogger(),\n\t\t\t\tListObjectsDeadline:   listObjectsDeadline,\n\t\t\t\tListObjectsMaxResults: test.maxResults,\n\t\t\t\tResolveNodeLimit:      DefaultResolveNodeLimit,\n\t\t\t}\n\t\t\ttypesys := typesystem.New(model)\n\t\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\t\t\t// assertions\n\t\t\tt.Run(\"streaming_endpoint\", func(t *testing.T) {\n\t\t\t\tserver := &mockStreamServer{\n\t\t\t\t\tchannel: make(chan string, len(test.allResults)),\n\t\t\t\t}\n\n\t\t\t\tdone := make(chan struct{})\n\t\t\t\tvar streamedObjectIds []string\n\t\t\t\tgo func() {\n\t\t\t\t\tfor x := range server.channel {\n\t\t\t\t\t\tstreamedObjectIds = append(streamedObjectIds, x)\n\t\t\t\t\t}\n\n\t\t\t\t\tdone <- struct{}{}\n\t\t\t\t}()\n\n\t\t\t\terr := listObjectsQuery.ExecuteStreamed(ctx, &openfgapb.StreamedListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t}, server)\n\t\t\t\tclose(server.channel)\n\t\t\t\t<-done\n\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.GreaterOrEqual(t, len(streamedObjectIds), int(test.minimumResultsExpected))\n\t\t\t\trequire.ElementsMatch(t, test.allResults, streamedObjectIds)\n\t\t\t})\n\n\t\t\tt.Run(\"regular_endpoint\", func(t *testing.T) {\n\t\t\t\tres, err := listObjectsQuery.Execute(ctx, &openfgapb.ListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t})\n\n\t\t\t\trequire.NotNil(t, res)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.LessOrEqual(t, len(res.Objects), int(test.maxResults))\n\t\t\t\trequire.GreaterOrEqual(t, len(res.Objects), int(test.minimumResultsExpected))\n\t\t\t\trequire.Subset(t, test.allResults, res.Objects)\n\t\t\t})\n\t\t})", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) StopRportFwdListener(ctx context.Context, in *sliverpb.RportFwdStopListenerReq, opts ...grpc.CallOption) (*sliverpb.RportFwdListener, error) {\n\tout := new(sliverpb.RportFwdListener)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/StopRportFwdListener\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) genFormatCmd(value *JuiceFS, config *[]string, options map[string]string) {\n\n\tvar (\n\t\t// ceFilter for CommunityEdition\n\t\tceFilter = buildFormatCmdFilterForCommunityEdition()\n\t\t// eeFilter for EnterpriseEdition\n\t\teeFilter = buildFormatCmdFilterForEnterpriseEdition()\n\t\t// eeAllowOptions []string = []string{JuiceBucket2, AccessKey2, SecretKey2}\n\t)\n\targs := make([]string, 0)\n\tif config != nil {\n\t\tfor _, option := range *config {\n\t\t\to := strings.TrimSpace(option)\n\t\t\tif o != \"\" {\n\t\t\t\targs = append(args, fmt.Sprintf(\"--%s\", o))\n\t\t\t}\n\t\t}\n\t}\n\tif value.Edition == CommunityEdition {\n\t\t// ce\n\t\tif value.Configs.AccessKeySecret != \"\" {\n\t\t\targs = append(args, \"--access-key=${ACCESS_KEY}\")\n\t\t}\n\t\tif value.Configs.SecretKeySecret != \"\" {\n\t\t\targs = append(args, \"--secret-key=${SECRET_KEY}\")\n\t\t}\n\t\tif value.Configs.Storage == \"\" || value.Configs.Bucket == \"\" {\n\t\t\targs = append(args, \"--no-update\")\n\t\t}\n\t\tif value.Configs.Storage != \"\" {\n\t\t\targs = append(args, fmt.Sprintf(\"--storage=%s\", value.Configs.Storage))\n\t\t}\n\t\tif value.Configs.Bucket != \"\" {\n\t\t\targs = append(args, fmt.Sprintf(\"--bucket=%s\", value.Configs.Bucket))\n\t\t}\n\t\tformatOpts := ceFilter.filterOption(options)\n\t\tfor k, v := range formatOpts {\n\t\t\targs = append(args, fmt.Sprintf(\"--%s=%s\", k, v))\n\t\t}\n\t\tencryptOptions := ceFilter.filterEncryptEnvOptions(value.Configs.EncryptEnvOptions)\n\t\tfor _, v := range encryptOptions {\n\t\t\targs = append(args, fmt.Sprintf(\"--%s=${%s}\", v.Name, v.EnvName))\n\t\t}\n\t\targs = append(args, value.Source, value.Configs.Name)\n\t\tcmd := append([]string{common.JuiceCeCliPath, \"format\"}, args...)\n\t\tvalue.Configs.FormatCmd = strings.Join(cmd, \" \")\n\t\treturn\n\t}\n\t// ee\n\tif value.Configs.TokenSecret == \"\" {\n\t\t// skip juicefs auth\n\t\treturn\n\t}\n\targs = append(args, \"--token=${TOKEN}\")\n\tif value.Configs.AccessKeySecret != \"\" {\n\t\targs = append(args, \"--accesskey=${ACCESS_KEY}\")\n\t}\n\tif value.Configs.SecretKeySecret != \"\" {\n\t\targs = append(args, \"--secretkey=${SECRET_KEY}\")\n\t}\n\tif value.Configs.Bucket != \"\" {\n\t\targs = append(args, fmt.Sprintf(\"--bucket=%s\", value.Configs.Bucket))\n\t}\n\tformatOpts := eeFilter.filterOption(options)\n\tfor k, v := range formatOpts {\n\t\targs = append(args, fmt.Sprintf(\"--%s=%s\", k, v))\n\t}\n\tencryptOptions := eeFilter.filterEncryptEnvOptions(value.Configs.EncryptEnvOptions)\n\tfor _, v := range encryptOptions {\n\t\targs = append(args, fmt.Sprintf(\"--%s=${%s}\", v.Name, v.EnvName))\n\t}\n\targs = append(args, value.Source)\n\tcmd := append([]string{common.JuiceCliPath, \"auth\"}, args...)\n\tvalue.Configs.FormatCmd = strings.Join(cmd, \" \")\n}", "is_vulnerable": 1}
{"code": "func Contexter() macaron.Handler {\n\treturn func(ctx *macaron.Context, l i18n.Locale, cache cache.Cache, sess session.Store, f *session.Flash, x csrf.CSRF) {\n\t\tc := &Context{\n\t\t\tContext: ctx,\n\t\t\tCache:   cache,\n\t\t\tcsrf:    x,\n\t\t\tFlash:   f,\n\t\t\tSession: sess,\n\t\t\tLink:    conf.Server.Subpath + strings.TrimSuffix(ctx.Req.URL.Path, \"/\"),\n\t\t\tRepo: &Repository{\n\t\t\t\tPullRequest: &PullRequest{},\n\t\t\t},\n\t\t\tOrg: &Organization{},\n\t\t}\n\t\tc.Data[\"Link\"] = template.EscapePound(c.Link)\n\t\tc.Data[\"PageStartTime\"] = time.Now()\n\n\t\t// Quick responses appropriate go-get meta with status 200\n\t\t// regardless of if user have access to the repository,\n\t\t// or the repository does not exist at all.\n\t\t// This is particular a workaround for \"go get\" command which does not respect\n\t\t// .netrc file.\n\t\tif c.Query(\"go-get\") == \"1\" {\n\t\t\townerName := c.Params(\":username\")\n\t\t\trepoName := c.Params(\":reponame\")\n\t\t\tbranchName := \"master\"\n\n\t\t\towner, err := db.GetUserByName(ownerName)\n\t\t\tif err != nil {\n\t\t\t\tc.NotFoundOrError(err, \"get user by name\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\trepo, err := db.GetRepositoryByName(owner.ID, repoName)\n\t\t\tif err == nil && len(repo.DefaultBranch) > 0 {\n\t\t\t\tbranchName = repo.DefaultBranch\n\t\t\t}\n\n\t\t\tprefix := conf.Server.ExternalURL + path.Join(ownerName, repoName, \"src\", branchName)\n\t\t\tinsecureFlag := \"\"\n\t\t\tif !strings.HasPrefix(conf.Server.ExternalURL, \"https://\") {\n\t\t\t\tinsecureFlag = \"--insecure \"\n\t\t\t}\n\t\t\tc.PlainText(http.StatusOK, com.Expand(`<!doctype html>\n<html>\n\t<head>\n\t\t<meta name=\"go-import\" content=\"{GoGetImport} git {CloneLink}\">\n\t\t<meta name=\"go-source\" content=\"{GoGetImport} _ {GoDocDirectory} {GoDocFile}\">\n\t</head>\n\t<body>\n\t\tgo get {InsecureFlag}{GoGetImport}\n\t</body>\n</html>\n`, map[string]string{\n\t\t\t\t\"GoGetImport\":    path.Join(conf.Server.URL.Host, conf.Server.Subpath, ownerName, repoName),\n\t\t\t\t\"CloneLink\":      db.ComposeHTTPSCloneURL(ownerName, repoName),\n\t\t\t\t\"GoDocDirectory\": prefix + \"{/dir}\",\n\t\t\t\t\"GoDocFile\":      prefix + \"{/dir}/{file}#L{line}\",\n\t\t\t\t\"InsecureFlag\":   insecureFlag,\n\t\t\t}))\n\t\t\treturn\n\t\t}\n\n\t\tif len(conf.HTTP.AccessControlAllowOrigin) > 0 {\n\t\t\tc.Header().Set(\"Access-Control-Allow-Origin\", conf.HTTP.AccessControlAllowOrigin)\n\t\t\tc.Header().Set(\"'Access-Control-Allow-Credentials' \", \"true\")\n\t\t\tc.Header().Set(\"Access-Control-Max-Age\", \"3600\")\n\t\t\tc.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Access-Control-Allow-Headers, Authorization, X-Requested-With\")\n\t\t}\n\n\t\t// Get user from session or header when possible\n\t\tc.User, c.IsBasicAuth, c.IsTokenAuth = auth.SignedInUser(c.Context, c.Session)\n\n\t\tif c.User != nil {\n\t\t\tc.IsLogged = true\n\t\t\tc.Data[\"IsLogged\"] = c.IsLogged\n\t\t\tc.Data[\"LoggedUser\"] = c.User\n\t\t\tc.Data[\"LoggedUserID\"] = c.User.ID\n\t\t\tc.Data[\"LoggedUserName\"] = c.User.Name\n\t\t\tc.Data[\"IsAdmin\"] = c.User.IsAdmin\n\t\t} else {\n\t\t\tc.Data[\"LoggedUserID\"] = 0\n\t\t\tc.Data[\"LoggedUserName\"] = \"\"\n\t\t}\n\n\t\t// If request sends files, parse them here otherwise the Query() can't be parsed and the CsrfToken will be invalid.\n\t\tif c.Req.Method == \"POST\" && strings.Contains(c.Req.Header.Get(\"Content-Type\"), \"multipart/form-data\") {\n\t\t\tif err := c.Req.ParseMultipartForm(conf.Attachment.MaxSize << 20); err != nil && !strings.Contains(err.Error(), \"EOF\") { // 32MB max size\n\t\t\t\tc.Error(err, \"parse multipart form\")\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tc.Data[\"CSRFToken\"] = x.GetToken()\n\t\tc.Data[\"CSRFTokenHTML\"] = template.Safe(`<input type=\"hidden\" name=\"_csrf\" value=\"` + x.GetToken() + `\">`)\n\t\tlog.Trace(\"Session ID: %s\", sess.ID())\n\t\tlog.Trace(\"CSRF Token: %v\", c.Data[\"CSRFToken\"])\n\n\t\tc.Data[\"ShowRegistrationButton\"] = !conf.Auth.DisableRegistration\n\t\tc.Data[\"ShowFooterBranding\"] = conf.Other.ShowFooterBranding\n\n\t\tc.renderNoticeBanner()\n\n\t\t// \ud83d\udea8 SECURITY: Prevent MIME type sniffing in some browsers,\n\t\t// see https://github.com/gogs/gogs/issues/5397 for details.\n\t\tc.Header().Set(\"X-Content-Type-Options\", \"nosniff\")\n\n\t\tctx.Map(c)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f *Frontend) SendClose(msg *Close) {\n\tprevLen := len(f.wbuf)\n\tf.wbuf = msg.Encode(f.wbuf)\n\tif f.tracer != nil {\n\t\tf.tracer.traceClose('F', int32(len(f.wbuf)-prevLen), msg)\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.description, func(t *testing.T) {\n\t\t\tgotSig, gotb64Sig, err := signatures(test.sigRef, \"\")\n\t\t\tif test.shouldErr && err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif test.shouldErr {\n\t\t\t\tt.Fatal(\"should have received an error\")\n\t\t\t}\n\t\t\tif gotSig != sig {\n\t\t\t\tt.Fatalf(\"unexpected signature, expected: %s got: %s\", sig, gotSig)\n\t\t\t}\n\t\t\tif gotb64Sig != b64sig {\n\t\t\t\tt.Fatalf(\"unexpected encoded signature, expected: %s got: %s\", b64sig, gotb64Sig)\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (t *Teler) checkCommonWebAttack(r *http.Request) error {\n\t// Decode the URL-encoded and unescape HTML entities request URI of the URL\n\turi := stringDeUnescape(r.URL.RequestURI())\n\n\t// Declare byte slice for request body.\n\tvar body string\n\n\t// Initialize buffer to hold request body.\n\tbuf := &bytes.Buffer{}\n\n\t// Use io.Copy to copy the request body to the buffer.\n\t_, err := io.Copy(buf, r.Body)\n\tif err == nil {\n\t\t// If the read not fails, replace the request body\n\t\t// with a new io.ReadCloser that reads from the buffer.\n\t\tr.Body = io.NopCloser(buf)\n\n\t\t// Convert the buffer to a string.\n\t\tbody = buf.String()\n\t}\n\n\t// Decode the URL-encoded and unescape HTML entities of body\n\tbody = stringDeUnescape(body)\n\n\t// Iterate over the filters in the CommonWebAttack data stored in the t.threat.cwa.Filters field\n\tfor _, filter := range t.threat.cwa.Filters {\n\t\t// Initialize a variable to track whether a match is found\n\t\tvar match bool\n\n\t\t// Check the type of the filter's pattern\n\t\tswitch pattern := filter.pattern.(type) {\n\t\tcase *regexp.Regexp: // If the pattern is a regex\n\t\t\tmatch = pattern.MatchString(uri) || pattern.MatchString(body)\n\t\tcase *pcre.Matcher: // If the pattern is a PCRE expr\n\t\t\tmatch = pattern.MatchString(uri, 0) || pattern.MatchString(body, 0)\n\t\tdefault: // If the pattern is of an unknown type, skip to the next iteration\n\t\t\tcontinue\n\t\t}\n\n\t\t// If the pattern matches the request URI or body, return an error indicating a common web attack has been detected\n\t\tif match {\n\t\t\treturn errors.New(filter.Description)\n\t\t}\n\t}\n\n\t// Return nil if no match is found\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tfinalizeLog := func() {\n\t\tif didFinalizeLog {\n\t\t\treturn\n\t\t}\n\t\tdidFinalizeLog = true\n\n\t\t// Print the deferred warning now if there was no error after all\n\t\tfor remainingMessagesBeforeLimit > 0 && len(deferredWarnings) > 0 {\n\t\t\tshownWarnings++\n\t\t\twriteStringWithColor(os.Stderr, deferredWarnings[0].String(options, terminalInfo))\n\t\t\tdeferredWarnings = deferredWarnings[1:]\n\t\t\tremainingMessagesBeforeLimit--\n\t\t}\n\n\t\t// Print out a summary\n\t\tif options.MessageLimit > 0 && errors+warnings > options.MessageLimit {\n\t\t\twriteStringWithColor(os.Stderr, fmt.Sprintf(\"%s shown (disable the message limit with --log-limit=0)\\n\",\n\t\t\t\terrorAndWarningSummary(errors, warnings, shownErrors, shownWarnings)))\n\t\t} else if options.LogLevel <= LevelInfo && (warnings != 0 || errors != 0) {\n\t\t\twriteStringWithColor(os.Stderr, fmt.Sprintf(\"%s\\n\",\n\t\t\t\terrorAndWarningSummary(errors, warnings, shownErrors, shownWarnings)))\n\t\t}\n\t}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) GetPrivs(ctx context.Context, in *sliverpb.GetPrivsReq, opts ...grpc.CallOption) (*sliverpb.GetPrivs, error) {\n\tout := new(sliverpb.GetPrivs)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/GetPrivs\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func shouldValidateSymlink(path string) bool {\n\t// we only check meta directory for now\n\tpathTokens := strings.Split(path, string(os.PathSeparator))\n\tif pathTokens[0] == \"meta\" {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func getFullStateBytesFromSecret(ctx context.Context, k8sClient kubernetes.Interface, name string) ([]byte, error) {\n\tsecret, err := k8sClient.CoreV1().Secrets(metav1.NamespaceSystem).Get(ctx, name, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"[state] error getting secret %s: %w\", name, err)\n\t}\n\n\tdata, ok := secret.Data[name]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"[state] expected secret %s to have field %s, but none was found\", name, name)\n\t}\n\n\treturn data, nil\n}", "is_vulnerable": 0}
{"code": "func mountToRootfs(m *configs.Mount, c *mountConfig) error {\n\trootfs := c.root\n\n\t// procfs and sysfs are special because we need to ensure they are actually\n\t// mounted on a specific path in a container without any funny business.\n\tswitch m.Device {\n\tcase \"proc\", \"sysfs\":\n\t\t// If the destination already exists and is not a directory, we bail\n\t\t// out. This is to avoid mounting through a symlink or similar -- which\n\t\t// has been a \"fun\" attack scenario in the past.\n\t\t// TODO: This won't be necessary once we switch to libpathrs and we can\n\t\t//       stop all of these symlink-exchange attacks.\n\t\tdest := filepath.Clean(m.Destination)\n\t\tif !strings.HasPrefix(dest, rootfs) {\n\t\t\t// Do not use securejoin as it resolves symlinks.\n\t\t\tdest = filepath.Join(rootfs, dest)\n\t\t}\n\t\tif fi, err := os.Lstat(dest); err != nil {\n\t\t\tif !os.IsNotExist(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else if !fi.IsDir() {\n\t\t\treturn fmt.Errorf(\"filesystem %q must be mounted on ordinary directory\", m.Device)\n\t\t}\n\t\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Selinux kernels do not support labeling of /proc or /sys.\n\t\treturn mountPropagate(m, rootfs, \"\", nil)\n\t}\n\n\tmountLabel := c.label\n\tmountFd := c.fd\n\tdest, err := securejoin.SecureJoin(rootfs, m.Destination)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tswitch m.Device {\n\tcase \"mqueue\":\n\t\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := mountPropagate(m, rootfs, \"\", nil); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn label.SetFileLabel(dest, mountLabel)\n\tcase \"tmpfs\":\n\t\tstat, err := os.Stat(dest)\n\t\tif err != nil {\n\t\t\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tif m.Extensions&configs.EXT_COPYUP == configs.EXT_COPYUP {\n\t\t\terr = doTmpfsCopyUp(m, rootfs, mountLabel)\n\t\t} else {\n\t\t\terr = mountPropagate(m, rootfs, mountLabel, nil)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif stat != nil {\n\t\t\tif err = os.Chmod(dest, stat.Mode()); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\tcase \"bind\":\n\t\tif err := prepareBindMount(m, rootfs, mountFd); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := mountPropagate(m, rootfs, mountLabel, mountFd); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// bind mount won't change mount options, we need remount to make mount options effective.\n\t\t// first check that we have non-default options required before attempting a remount\n\t\tif m.Flags&^(unix.MS_REC|unix.MS_REMOUNT|unix.MS_BIND) != 0 {\n\t\t\t// only remount if unique mount options are set\n\t\t\tif err := remount(m, rootfs, mountFd); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tif m.Relabel != \"\" {\n\t\t\tif err := label.Validate(m.Relabel); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tshared := label.IsShared(m.Relabel)\n\t\t\tif err := label.Relabel(m.Source, mountLabel, shared); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase \"cgroup\":\n\t\tif cgroups.IsCgroup2UnifiedMode() {\n\t\t\treturn mountCgroupV2(m, c)\n\t\t}\n\t\treturn mountCgroupV1(m, c)\n\tdefault:\n\t\tif err := checkProcMount(rootfs, dest, m.Source); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := os.MkdirAll(dest, 0o755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn mountPropagate(m, rootfs, mountLabel, mountFd)\n\t}\n\tif err := setRecAttr(m, rootfs); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestAES_GCM_NIST_gcmEncryptExtIV256_PTLen_408_Test_8(t *testing.T) {\n\tiv, _ := hex.DecodeString(\"92f258071d79af3e63672285\")\n\tkey, _ := hex.DecodeString(\"595f259c55abe00ae07535ca5d9b09d6efb9f7e9abb64605c337acbd6b14fc7e\")\n\tplaintext, _ := hex.DecodeString(\"a6fee33eb110a2d769bbc52b0f36969c287874f665681477a25fc4c48015c541fbe2394133ba490a34ee2dd67b898177849a91\")\n\texpected, _ := hex.DecodeString(\"bbca4a9e09ae9690c0f6f8d405e53dccd666aa9c5fa13c8758bc30abe1ddd1bcce0d36a1eaaaaffef20cd3c5970b9673f8a65c26ccecb9976fd6ac9c2c0f372c52c821\")\n\ttag, _ := hex.DecodeString(\"26ccecb9976fd6ac9c2c0f372c52c821\")\n\taesgcmTest(t, iv, key, plaintext, expected, tag)\n}", "is_vulnerable": 1}
{"code": "func TestCronJobStore(t *testing.T) {\n\t// Fixed metadata on type and help text. We prepend this to every expected\n\t// output so we only have to modify a single place when doing adjustments.\n\n\thour := ActiveRunningCronJob1LastScheduleTime.Hour()\n\tActiveRunningCronJob1NextScheduleTime := time.Time{}\n\tswitch {\n\tcase hour < 6:\n\t\tActiveRunningCronJob1NextScheduleTime = time.Date(\n\t\t\tActiveRunningCronJob1LastScheduleTime.Year(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Month(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Day(),\n\t\t\t6,\n\t\t\t0,\n\t\t\t0, 0, time.Local)\n\tcase hour < 12:\n\t\tActiveRunningCronJob1NextScheduleTime = time.Date(\n\t\t\tActiveRunningCronJob1LastScheduleTime.Year(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Month(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Day(),\n\t\t\t12,\n\t\t\t0,\n\t\t\t0, 0, time.Local)\n\tcase hour < 18:\n\t\tActiveRunningCronJob1NextScheduleTime = time.Date(\n\t\t\tActiveRunningCronJob1LastScheduleTime.Year(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Month(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Day(),\n\t\t\t18,\n\t\t\t0,\n\t\t\t0, 0, time.Local)\n\tcase hour < 24:\n\t\tActiveRunningCronJob1NextScheduleTime = time.Date(\n\t\t\tActiveRunningCronJob1LastScheduleTime.Year(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Month(),\n\t\t\tActiveRunningCronJob1LastScheduleTime.Day(),\n\t\t\t24,\n\t\t\t0,\n\t\t\t0, 0, time.Local)\n\t}\n\n\tminute := ActiveCronJob1NoLastScheduledCreationTimestamp.Minute()\n\tActiveCronJob1NoLastScheduledNextScheduleTime := time.Time{}\n\tswitch {\n\tcase minute < 25:\n\t\tActiveCronJob1NoLastScheduledNextScheduleTime = time.Date(\n\t\t\tActiveCronJob1NoLastScheduledCreationTimestamp.Year(),\n\t\t\tActiveCronJob1NoLastScheduledCreationTimestamp.Month(),\n\t\t\tActiveCronJob1NoLastScheduledCreationTimestamp.Day(),\n\t\t\tActiveCronJob1NoLastScheduledCreationTimestamp.Hour(),\n\t\t\t25,\n\t\t\t0, 0, time.Local)\n\tdefault:\n\t\tActiveCronJob1NoLastScheduledNextScheduleTime = time.Date(\n\t\t\tActiveCronJob1NoLastScheduledNextScheduleTime.Year(),\n\t\t\tActiveCronJob1NoLastScheduledNextScheduleTime.Month(),\n\t\t\tActiveCronJob1NoLastScheduledNextScheduleTime.Day(),\n\t\t\tActiveCronJob1NoLastScheduledNextScheduleTime.Hour()+1,\n\t\t\t25,\n\t\t\t0, 0, time.Local)\n\t}\n\n\tconst metadata = `\n\t\t# HELP kube_cronjob_labels Kubernetes labels converted to Prometheus labels.\n\t\t# TYPE kube_cronjob_labels gauge\n\t\t# HELP kube_cronjob_info Info about cronjob.\n\t\t# TYPE kube_cronjob_info gauge\n\t\t# HELP kube_cronjob_created Unix creation timestamp\n\t\t# TYPE kube_cronjob_created gauge\n\t\t# HELP kube_cronjob_spec_starting_deadline_seconds Deadline in seconds for starting the job if it misses scheduled time for any reason.\n\t\t# TYPE kube_cronjob_spec_starting_deadline_seconds gauge\n\t\t# HELP kube_cronjob_spec_suspend Suspend flag tells the controller to suspend subsequent executions.\n\t\t# TYPE kube_cronjob_spec_suspend gauge\n\t\t# HELP kube_cronjob_status_active Active holds pointers to currently running jobs.\n\t\t# TYPE kube_cronjob_status_active gauge\n\t\t# HELP kube_cronjob_status_last_schedule_time LastScheduleTime keeps information of when was the last time the job was successfully scheduled.\n\t\t# TYPE kube_cronjob_status_last_schedule_time gauge\n\t\t# HELP kube_cronjob_next_schedule_time Next time the cronjob should be scheduled. The time after lastScheduleTime, or after the cron job's creation time if it's never been scheduled. Use this to determine if the job is delayed.\n\t\t# TYPE kube_cronjob_next_schedule_time gauge\n\t\t# HELP kube_cronjob_annotations Kubernetes annotations converted to Prometheus labels.\n\t\t# TYPE kube_cronjob_annotations gauge\n\t`\n\tcases := []generateMetricsTestCase{\n\t\t{\n\t\t\tObj: &batchv1beta1.CronJob{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:       \"ActiveRunningCronJob1\",\n\t\t\t\t\tNamespace:  \"ns1\",\n\t\t\t\t\tGeneration: 1,\n\t\t\t\t\tLabels: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-active-running-1\",\n\t\t\t\t\t},\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-active-running-1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: batchv1beta1.CronJobStatus{\n\t\t\t\t\tActive:           []v1.ObjectReference{{Name: \"FakeJob1\"}, {Name: \"FakeJob2\"}},\n\t\t\t\t\tLastScheduleTime: &metav1.Time{Time: ActiveRunningCronJob1LastScheduleTime},\n\t\t\t\t},\n\t\t\t\tSpec: batchv1beta1.CronJobSpec{\n\t\t\t\t\tStartingDeadlineSeconds: &StartingDeadlineSeconds300,\n\t\t\t\t\tConcurrencyPolicy:       \"Forbid\",\n\t\t\t\t\tSuspend:                 &SuspendFalse,\n\t\t\t\t\tSchedule:                \"0 */6 * * *\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\t\tkube_cronjob_info{concurrency_policy=\"Forbid\",cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\",schedule=\"0 */6 * * *\"} 1\n\t\t\t\tkube_cronjob_labels{cronjob=\"ActiveRunningCronJob1\",label_app=\"example-active-running-1\",namespace=\"ns1\"} 1\n\t\t\t\tkube_cronjob_spec_starting_deadline_seconds{cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\"} 300\n\t\t\t\tkube_cronjob_spec_suspend{cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\"} 0\n\t\t\t\tkube_cronjob_status_active{cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\"} 2\n\t\t\t\tkube_cronjob_status_last_schedule_time{cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\"} 1.520742896e+09\n\t\t\t\tkube_cronjob_annotations{cronjob=\"ActiveRunningCronJob1\",namespace=\"ns1\",annotation_app=\"example-active-running-1\"} 1\n` + fmt.Sprintf(\"kube_cronjob_next_schedule_time{cronjob=\\\"ActiveRunningCronJob1\\\",namespace=\\\"ns1\\\"} %ve+09\\n\",\n\t\t\t\tfloat64(ActiveRunningCronJob1NextScheduleTime.Unix())/math.Pow10(9)),\n\t\t\tMetricNames: []string{\"kube_cronjob_next_schedule_time\", \"kube_cronjob_spec_starting_deadline_seconds\", \"kube_cronjob_status_active\", \"kube_cronjob_spec_suspend\", \"kube_cronjob_info\", \"kube_cronjob_created\", \"kube_cronjob_labels\", \"kube_cronjob_status_last_schedule_time\", \"kube_cronjob_annotations\"},\n\t\t},\n\t\t{\n\t\t\tObj: &batchv1beta1.CronJob{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:       \"SuspendedCronJob1\",\n\t\t\t\t\tNamespace:  \"ns1\",\n\t\t\t\t\tGeneration: 1,\n\t\t\t\t\tLabels: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-suspended-1\",\n\t\t\t\t\t},\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-suspended-1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: batchv1beta1.CronJobStatus{\n\t\t\t\t\tActive:           []v1.ObjectReference{},\n\t\t\t\t\tLastScheduleTime: &metav1.Time{Time: SuspendedCronJob1LastScheduleTime},\n\t\t\t\t},\n\t\t\t\tSpec: batchv1beta1.CronJobSpec{\n\t\t\t\t\tStartingDeadlineSeconds: &StartingDeadlineSeconds300,\n\t\t\t\t\tConcurrencyPolicy:       \"Forbid\",\n\t\t\t\t\tSuspend:                 &SuspendTrue,\n\t\t\t\t\tSchedule:                \"0 */3 * * *\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\t\tkube_cronjob_info{concurrency_policy=\"Forbid\",cronjob=\"SuspendedCronJob1\",namespace=\"ns1\",schedule=\"0 */3 * * *\"} 1\n\t\t\t\tkube_cronjob_labels{cronjob=\"SuspendedCronJob1\",label_app=\"example-suspended-1\",namespace=\"ns1\"} 1\n\t\t\t\tkube_cronjob_spec_starting_deadline_seconds{cronjob=\"SuspendedCronJob1\",namespace=\"ns1\"} 300\n\t\t\t\tkube_cronjob_spec_suspend{cronjob=\"SuspendedCronJob1\",namespace=\"ns1\"} 1\n\t\t\t\tkube_cronjob_status_active{cronjob=\"SuspendedCronJob1\",namespace=\"ns1\"} 0\n\t\t\t\tkube_cronjob_status_last_schedule_time{cronjob=\"SuspendedCronJob1\",namespace=\"ns1\"} 1.520762696e+09\n\t\t\t\tkube_cronjob_annotations{cronjob=\"SuspendedCronJob1\",namespace=\"ns1\",annotation_app=\"example-suspended-1\"} 1\n`,\n\t\t\tMetricNames: []string{\"kube_cronjob_spec_starting_deadline_seconds\", \"kube_cronjob_status_active\", \"kube_cronjob_spec_suspend\", \"kube_cronjob_info\", \"kube_cronjob_created\", \"kube_cronjob_labels\", \"kube_cronjob_status_last_schedule_time\", \"kube_cronjob_annotations\"},\n\t\t},\n\t\t{\n\t\t\tObj: &batchv1beta1.CronJob{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:              \"ActiveCronJob1NoLastScheduled\",\n\t\t\t\t\tCreationTimestamp: metav1.Time{Time: ActiveCronJob1NoLastScheduledCreationTimestamp},\n\t\t\t\t\tNamespace:         \"ns1\",\n\t\t\t\t\tGeneration:        1,\n\t\t\t\t\tLabels: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-active-no-last-scheduled-1\",\n\t\t\t\t\t},\n\t\t\t\t\tAnnotations: map[string]string{\n\t\t\t\t\t\t\"app\": \"example-active-no-last-scheduled-1\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tStatus: batchv1beta1.CronJobStatus{\n\t\t\t\t\tActive:           []v1.ObjectReference{},\n\t\t\t\t\tLastScheduleTime: nil,\n\t\t\t\t},\n\t\t\t\tSpec: batchv1beta1.CronJobSpec{\n\t\t\t\t\tStartingDeadlineSeconds: &StartingDeadlineSeconds300,\n\t\t\t\t\tConcurrencyPolicy:       \"Forbid\",\n\t\t\t\t\tSuspend:                 &SuspendFalse,\n\t\t\t\t\tSchedule:                \"25 * * * *\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tWant: `\n\t\t\t\tkube_cronjob_spec_starting_deadline_seconds{cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\"} 300\n\t\t\t\tkube_cronjob_status_active{cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\"} 0\n\t\t\t\tkube_cronjob_spec_suspend{cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\"} 0\n\t\t\t\tkube_cronjob_info{concurrency_policy=\"Forbid\",cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\",schedule=\"25 * * * *\"} 1\n\t\t\t\tkube_cronjob_created{cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\"} 1.520766296e+09\n\t\t\t\tkube_cronjob_labels{cronjob=\"ActiveCronJob1NoLastScheduled\",label_app=\"example-active-no-last-scheduled-1\",namespace=\"ns1\"} 1\n\t\t\t\tkube_cronjob_annotations{cronjob=\"ActiveCronJob1NoLastScheduled\",namespace=\"ns1\",annotation_app=\"example-active-no-last-scheduled-1\"} 1\n` +\n\t\t\t\tfmt.Sprintf(\"kube_cronjob_next_schedule_time{cronjob=\\\"ActiveCronJob1NoLastScheduled\\\",namespace=\\\"ns1\\\"} %ve+09\\n\",\n\t\t\t\t\tfloat64(ActiveCronJob1NoLastScheduledNextScheduleTime.Unix())/math.Pow10(9)),\n\t\t\t// TODO: Do we need to specify metricnames?\n\t\t\tMetricNames: []string{\"kube_cronjob_next_schedule_time\", \"kube_cronjob_spec_starting_deadline_seconds\", \"kube_cronjob_status_active\", \"kube_cronjob_spec_suspend\", \"kube_cronjob_info\", \"kube_cronjob_created\", \"kube_cronjob_labels\", \"kube_cronjob_annotations\"},\n\t\t},\n\t}\n\tfor i, c := range cases {\n\t\tc.Func = metric.ComposeMetricGenFuncs(cronJobMetricFamilies)\n\t\tif err := c.run(); err != nil {\n\t\t\tt.Errorf(\"unexpected collecting result in %vth run:\\n%s\", i, err)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *Server) CheckDeletionToken(deletionToken, token, filename string) error {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif s.storage.IsNotExist(err) {\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn err\n\t} else if metadata.DeletionToken != deletionToken {\n\t\treturn errors.New(\"Deletion token doesn't match.\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\t\t\tsyncOptionsFactory := func() *application.SyncOptions {\n\t\t\t\t\tsyncOptions := application.SyncOptions{}\n\t\t\t\t\titems := make([]string, 0)\n\t\t\t\t\tif replace {\n\t\t\t\t\t\titems = append(items, common.SyncOptionReplace)\n\t\t\t\t\t}\n\t\t\t\t\tif serverSideApply {\n\t\t\t\t\t\titems = append(items, common.SyncOptionServerSideApply)\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(items) == 0 {\n\t\t\t\t\t\t// for prevent send even empty array if not need\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\t\t\t\t\tsyncOptions.Items = items\n\t\t\t\t\treturn &syncOptions\n\t\t\t\t}\n\n\t\t\t\tsyncReq := application.ApplicationSyncRequest{\n\t\t\t\t\tName:         &appName,\n\t\t\t\t\tAppNamespace: &appNs,\n\t\t\t\t\tDryRun:       &dryRun,\n\t\t\t\t\tRevision:     &revision,\n\t\t\t\t\tResources:    filteredResources,\n\t\t\t\t\tPrune:        &prune,\n\t\t\t\t\tManifests:    localObjsStrings,\n\t\t\t\t\tInfos:        getInfos(infos),\n\t\t\t\t\tSyncOptions:  syncOptionsFactory(),\n\t\t\t\t}\n\n\t\t\t\tswitch strategy {\n\t\t\t\tcase \"apply\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Apply: &argoappv1.SyncStrategyApply{}}\n\t\t\t\t\tsyncReq.Strategy.Apply.Force = force\n\t\t\t\tcase \"\", \"hook\":\n\t\t\t\t\tsyncReq.Strategy = &argoappv1.SyncStrategy{Hook: &argoappv1.SyncStrategyHook{}}\n\t\t\t\t\tsyncReq.Strategy.Hook.Force = force\n\t\t\t\tdefault:\n\t\t\t\t\tlog.Fatalf(\"Unknown sync strategy: '%s'\", strategy)\n\t\t\t\t}\n\t\t\t\tif retryLimit > 0 {\n\t\t\t\t\tsyncReq.RetryStrategy = &argoappv1.RetryStrategy{\n\t\t\t\t\t\tLimit: retryLimit,\n\t\t\t\t\t\tBackoff: &argoappv1.Backoff{\n\t\t\t\t\t\t\tDuration:    retryBackoffDuration.String(),\n\t\t\t\t\t\t\tMaxDuration: retryBackoffMaxDuration.String(),\n\t\t\t\t\t\t\tFactor:      pointer.Int64Ptr(retryBackoffFactor),\n\t\t\t\t\t\t},\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif diffChanges {\n\t\t\t\t\tresources, err := appIf.ManagedResources(ctx, &application.ResourcesQuery{\n\t\t\t\t\t\tApplicationName: &appName,\n\t\t\t\t\t\tAppNamespace:    &appNs,\n\t\t\t\t\t})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tconn, settingsIf := acdClient.NewSettingsClientOrDie()\n\t\t\t\t\tdefer argoio.Close(conn)\n\t\t\t\t\targoSettings, err := settingsIf.Get(ctx, &settings.SettingsQuery{})\n\t\t\t\t\terrors.CheckError(err)\n\t\t\t\t\tfoundDiffs := false\n\t\t\t\t\tfmt.Printf(\"====== Previewing differences between live and desired state of application %s ======\\n\", appQualifiedName)\n\n\t\t\t\t\tfoundDiffs = findandPrintDiff(ctx, app, resources, argoSettings, diffOption, ignoreNormalizerOpts)\n\t\t\t\t\tif foundDiffs {\n\t\t\t\t\t\tif !diffChangesConfirm {\n\t\t\t\t\t\t\tyesno := cli.AskToProceed(fmt.Sprintf(\"Please review changes to application %s shown above. Do you want to continue the sync process? (y/n): \", appQualifiedName))\n\t\t\t\t\t\t\tif !yesno {\n\t\t\t\t\t\t\t\tos.Exit(0)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfmt.Printf(\"====== No Differences found ======\\n\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_, err = appIf.Sync(ctx, &syncReq)\n\t\t\t\terrors.CheckError(err)\n\n\t\t\t\tif !async {\n\t\t\t\t\tapp, opState, err := waitOnApplicationStatus(ctx, acdClient, appQualifiedName, timeout, watchOpts{operation: true}, selectedResources)\n\t\t\t\t\terrors.CheckError(err)\n\n\t\t\t\t\tif !dryRun {\n\t\t\t\t\t\tif !opState.Phase.Successful() {\n\t\t\t\t\t\t\tlog.Fatalf(\"Operation has completed with phase: %s\", opState.Phase)\n\t\t\t\t\t\t} else if len(selectedResources) == 0 && app.Status.Sync.Status != argoappv1.SyncStatusCodeSynced {\n\t\t\t\t\t\t\t// Only get resources to be pruned if sync was application-wide and final status is not synced\n\t\t\t\t\t\t\tpruningRequired := opState.SyncResult.Resources.PruningRequired()\n\t\t\t\t\t\t\tif pruningRequired > 0 {\n\t\t\t\t\t\t\t\tlog.Fatalf(\"%d resources require pruning\", pruningRequired)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t},", "is_vulnerable": 0}
{"code": "func (u systemInfoServiceImpl) Init(ctx context.Context) error {\n\tinfo, err := u.Get(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsignedKey = info.InstallID\n\t_, err = initDexConfig(ctx, u.KubeClient, \"http://velaux.com\")\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func RunTestUnconditionalDelete(ctx context.Context, t *testing.T, store storage.Interface) {\n\tkey, storedObj := testPropagateStore(ctx, t, store, &example.Pod{ObjectMeta: metav1.ObjectMeta{Name: \"foo\"}})\n\n\ttests := []struct {\n\t\tname              string\n\t\tkey               string\n\t\texpectedObj       *example.Pod\n\t\texpectNotFoundErr bool\n\t}{{\n\t\tname:              \"existing key\",\n\t\tkey:               key,\n\t\texpectedObj:       storedObj,\n\t\texpectNotFoundErr: false,\n\t}, {\n\t\tname:              \"non-existing key\",\n\t\tkey:               \"/non-existing\",\n\t\texpectedObj:       nil,\n\t\texpectNotFoundErr: true,\n\t}}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tout := &example.Pod{} // reset\n\t\t\terr := store.Delete(ctx, tt.key, out, nil, storage.ValidateAllObjectFunc, nil)\n\t\t\tif tt.expectNotFoundErr {\n\t\t\t\tif err == nil || !storage.IsNotFound(err) {\n\t\t\t\t\tt.Errorf(\"expecting not found error, but get: %s\", err)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Delete failed: %v\", err)\n\t\t\t}\n\t\t\t// We expect the resource version of the returned object to be\n\t\t\t// updated compared to the last existing object.\n\t\t\tif storedObj.ResourceVersion == out.ResourceVersion {\n\t\t\t\tt.Errorf(\"expecting resource version to be updated, but get: %s\", out.ResourceVersion)\n\t\t\t}\n\t\t\tout.ResourceVersion = storedObj.ResourceVersion\n\t\t\tExpectNoDiff(t, \"incorrect pod:\", tt.expectedObj, out)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func MarkTransactionSentBatches(hashArr [][]byte) error {\r\n\treturn DBConn.Exec(\"UPDATE transactions SET sent  = 1 WHERE hash in(?)\", hashArr).Error\r\n}\r", "is_vulnerable": 1}
{"code": "func (ns *ExternalNotificationService) sendNewAnswerNotificationEmail(ctx context.Context,\n\tuserID, email, lang string, rawData *schema.NewAnswerTemplateRawData) {\n\tcodeContent := &schema.EmailCodeContent{\n\t\tSourceType: schema.UnsubscribeSourceType,\n\t\tNotificationSources: []constant.NotificationSource{\n\t\t\tconstant.InboxSource,\n\t\t},\n\t\tEmail:  email,\n\t\tUserID: userID,\n\t}\n\n\t// If receiver has set language, use it to send email.\n\tif len(lang) > 0 {\n\t\tctx = context.WithValue(ctx, constant.AcceptLanguageFlag, i18n.Language(lang))\n\t}\n\ttitle, body, err := ns.emailService.NewAnswerTemplate(ctx, rawData)\n\tif err != nil {\n\t\tlog.Error(err)\n\t\treturn\n\t}\n\n\tns.emailService.SendAndSaveCodeWithTime(\n\t\tctx, email, title, body, rawData.UnsubscribeCode, codeContent.ToJSONString(), 1*24*time.Hour)\n}", "is_vulnerable": 1}
{"code": "func (a *Assertions) YAMLEqf(expected string, actual string, msg string, args ...interface{}) bool {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn YAMLEqf(a.t, expected, actual, msg, args...)\n}", "is_vulnerable": 0}
{"code": "func matchPredicateType(sig oci.Signature, expectedPredicateType string) (bool, string, error) {\n\tif expectedPredicateType != \"\" {\n\t\tstatement, _, err := decodeStatement(sig)\n\t\tif err != nil {\n\t\t\treturn false, \"\", fmt.Errorf(\"failed to decode predicateType: %w\", err)\n\t\t}\n\n\t\tif pType, ok := statement[\"predicateType\"]; ok {\n\t\t\tif pType.(string) == expectedPredicateType {\n\t\t\t\treturn true, pType.(string), nil\n\t\t\t}\n\t\t}\n\t}\n\treturn false, \"\", nil\n}", "is_vulnerable": 1}
{"code": "func TestDockerComposeGetInstance(t *testing.T) {\n\tvar scenarios = []struct {\n\t\tid   string\n\t\twant bool\n\t}{\n\t\t{\"MyApplication.DaprSidecar\", true},\n\t\t{\"does_not_exist\", false},\n\t}\n\n\ttarget := NewInstances(platforms.DockerCompose, nil, \"testdata/docker-compose.yml\")\n\n\tfor _, scenario := range scenarios {\n\t\tt.Run(fmt.Sprintf(\"Should load valid instance data - %t\", scenario.want), func(t *testing.T) {\n\t\t\tinstance := target.GetInstance(\"\", scenario.id)\n\t\t\tassert.NotNil(t, instance, \"Should always return something\")\n\n\t\t\tif scenario.want {\n\t\t\t\tassert.Equal(t, scenario.id, instance.AppID, \"Should return the correct instance\")\n\t\t\t\tassert.Equal(t, 3500, instance.HTTPPort, \"Port should be set\")\n\t\t\t\tassert.Equal(t, false, instance.SupportsLogs, \"Logs are not supported\")\n\t\t\t\tassert.Equal(t, false, instance.SupportsDeletion, \"Delegation is not supported\")\n\t\t\t\tassert.Equal(t, \"MyApplication.DaprSidecar:3500\", instance.Address, \"Address should be set\")\n\t\t\t\tassert.Equal(t, 80, instance.AppPort, \"AppPort should be set\")\n\t\t\t} else {\n\t\t\t\tassert.Empty(t, instance.AppID, \"When instance not valid, AppID is not set\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "\ttester.FuzzConsistency[wire.Proof](f, func(p *wire.Proof, c fuzz.Continue) {\n\t\tswitch c.Intn(5) {\n\t\tcase 0:\n\t\t\tp.Type = wire.MultipleATXs\n\t\t\tdata := wire.AtxProof{}\n\t\t\tc.Fuzz(&data)\n\t\t\tp.Data = &data\n\t\tcase 1:\n\t\t\tp.Type = wire.MultipleBallots\n\t\t\tdata := wire.BallotProof{}\n\t\t\tc.Fuzz(&data)\n\t\t\tp.Data = &data\n\t\tcase 2:\n\t\t\tp.Type = wire.HareEquivocation\n\t\t\tdata := wire.HareProof{}\n\t\t\tc.Fuzz(&data)\n\t\t\tp.Data = &data\n\t\tcase 3:\n\t\t\tp.Type = wire.InvalidPostIndex\n\t\t\tdata := wire.InvalidPostIndexProof{}\n\t\t\tc.Fuzz(&data)\n\t\t\tp.Data = &data\n\t\tcase 4:\n\t\t\tp.Type = wire.InvalidPrevATX\n\t\t\tdata := wire.InvalidPrevATXProof{}\n\t\t\tc.Fuzz(&data)\n\t\t\tp.Data = &data\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (t *assetAction) checkERC20BridgeResumed() error {\n\treturn t.bridgeView.FindBridgeResumed(\n\t\tt.erc20BridgeResumed, t.blockHeight, t.logIndex, t.txHash)\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"New\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\ts := testACLTokensStateStore(t)\n\t\ttoken := &structs.ACLToken{\n\t\t\tAccessorID: \"daf37c07-d04d-4fd5-9678-a8206a57d61a\",\n\t\t\tSecretID:   \"39171632-6f34-4411-827f-9416403687f4\",\n\t\t\tPolicies: []structs.ACLTokenPolicyLink{\n\t\t\t\tstructs.ACLTokenPolicyLink{\n\t\t\t\t\tID: testPolicyID_A,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRoles: []structs.ACLTokenRoleLink{\n\t\t\t\tstructs.ACLTokenRoleLink{\n\t\t\t\t\tID: testRoleID_A,\n\t\t\t\t},\n\t\t\t},\n\t\t\tServiceIdentities: []*structs.ACLServiceIdentity{\n\t\t\t\t&structs.ACLServiceIdentity{\n\t\t\t\t\tServiceName: \"web\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\trequire.NoError(t, s.ACLTokenSet(2, token.Clone(), false))\n\n\t\tidx, rtoken, err := s.ACLTokenGetByAccessor(nil, \"daf37c07-d04d-4fd5-9678-a8206a57d61a\", nil)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, uint64(2), idx)\n\t\trequire.NotEmpty(t, rtoken.Hash)\n\t\tcompareTokens(t, token, rtoken)\n\t\trequire.Equal(t, uint64(2), rtoken.CreateIndex)\n\t\trequire.Equal(t, uint64(2), rtoken.ModifyIndex)\n\t\trequire.Len(t, rtoken.Policies, 1)\n\t\trequire.Equal(t, \"node-read\", rtoken.Policies[0].Name)\n\t\trequire.Len(t, rtoken.Roles, 1)\n\t\trequire.Equal(t, \"node-read-role\", rtoken.Roles[0].Name)\n\t\trequire.Len(t, rtoken.ServiceIdentities, 1)\n\t\trequire.Equal(t, \"web\", rtoken.ServiceIdentities[0].ServiceName)\n\t})", "is_vulnerable": 0}
{"code": "func (h *Handler) HandleSyncedMalfeasanceProof(\n\tctx context.Context,\n\texpHash types.Hash32,\n\t_ p2p.Peer,\n\tdata []byte,\n) error {\n\tvar p wire.MalfeasanceProof\n\tif err := codec.Decode(data, &p); err != nil {\n\t\tnumMalformed.Inc()\n\t\th.logger.With().Error(\"malformed message (sync)\", log.Context(ctx), log.Err(err))\n\t\treturn errMalformedData\n\t}\n\tnodeID, err := h.validateAndSave(ctx, &wire.MalfeasanceGossip{MalfeasanceProof: p})\n\tif err == nil && types.Hash32(nodeID) != expHash {\n\t\treturn fmt.Errorf(\n\t\t\t\"%w: malfeasance proof want %s, got %s\",\n\t\t\terrWrongHash,\n\t\t\texpHash.ShortString(),\n\t\t\tnodeID.ShortString(),\n\t\t)\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (iter *DeploymentOperationsListResultIterator) Next() error {\n\treturn iter.NextWithContext(context.Background())\n}", "is_vulnerable": 0}
{"code": "func ensureMountedAs(mountPoint, options string) error {\n\tmounted, err := Mounted(mountPoint)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !mounted {\n\t\tif err := Mount(mountPoint, mountPoint, \"none\", \"bind,rw\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif _, err = Mounted(mountPoint); err != nil {\n\t\treturn err\n\t}\n\n\treturn ForceMount(\"\", mountPoint, \"none\", options)\n}", "is_vulnerable": 1}
{"code": "func (s *codeMonitorStore) UpdateQueryTrigger(ctx context.Context, id int64, query string) error {\n\tnow := s.Now()\n\ta := actor.FromContext(ctx)\n\tq := sqlf.Sprintf(\n\t\tupdateTriggerQueryFmtStr,\n\t\tquery,\n\t\ta.UID,\n\t\tnow,\n\t\tnow,\n\t\tid,\n\t\tsqlf.Join(queryColumns, \", \"),\n\t)\n\treturn s.Exec(ctx, q)\n}", "is_vulnerable": 1}
{"code": "func EqualErrorf(t TestingT, theError error, errString string, msg string, args ...interface{}) {\n\tif assert.EqualErrorf(t, theError, errString, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (e *EngineInfo) Version() string {\n\treturn e.version\n}", "is_vulnerable": 0}
{"code": "func FromURLQuery(query string) (Map, error) {\n\tvals, err := url.ParseQuery(query)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tm := make(map[string]interface{})\n\tfor k, vals := range vals {\n\t\tm[k] = vals[0]\n\t}\n\treturn New(m), nil\n}", "is_vulnerable": 1}
{"code": "\treturn s.getAppEnforceRBAC(ctx, action, project, namespaceOrDefault, name, func() (*appv1.Application, error) {\n\t\tif !s.isNamespaceEnabled(namespaceOrDefault) {\n\t\t\treturn nil, security.NamespaceNotPermittedError(namespaceOrDefault)\n\t\t}\n\t\treturn s.appclientset.ArgoprojV1alpha1().Applications(namespaceOrDefault).Get(ctx, name, metav1.GetOptions{\n\t\t\tResourceVersion: resourceVersion,\n\t\t})\n\t})", "is_vulnerable": 0}
{"code": "func ensureMountedAs(mountPoint, options string) error {\n\tif err := MakeMount(mountPoint); err != nil {\n\t\treturn err\n\t}\n\n\treturn ForceMount(\"\", mountPoint, \"none\", options)\n}", "is_vulnerable": 0}
{"code": "func NVWriteValue(rw io.ReadWriter, index, offset uint32, data []byte, ownAuth []byte) error {\n\tif ownAuth == nil {\n\t\tif _, _, _, err := nvWriteValue(rw, index, offset, uint32(len(data)), data, nil); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to write to NVRAM: %v\", err)\n\t\t}\n\t\treturn nil\n\t}\n\tsharedSecretOwn, osaprOwn, err := newOSAPSession(rw, etOwner, khOwner, ownAuth[:])\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to start new auth session: %v\", err)\n\t}\n\tdefer osaprOwn.Close(rw)\n\tdefer zeroBytes(sharedSecretOwn[:])\n\tauthIn := []interface{}{ordNVWriteValue, index, offset, len(data), data}\n\tca, err := newCommandAuth(osaprOwn.AuthHandle, osaprOwn.NonceEven, sharedSecretOwn[:], authIn)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to construct owner auth fields: %v\", err)\n\t}\n\tdata, ra, ret, err := nvWriteValue(rw, index, offset, uint32(len(data)), data, ca)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to write to NVRAM: %v\", err)\n\t}\n\traIn := []interface{}{ret, ordNVWriteValue, tpmutil.U32Bytes(data)}\n\tif err := ra.verify(ca.NonceOdd, sharedSecretOwn[:], raIn); err != nil {\n\t\treturn fmt.Errorf(\"failed to verify authenticity of response: %v\", err)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (b BasicEnvoyExtender) patchConnectProxyListener(config *RuntimeConfig, l *envoy_listener_v3.Listener) (proto.Message, bool, error) {\n\tvar resultErr error\n\n\tenvoyID := \"\"\n\tif i := strings.IndexByte(l.Name, ':'); i != -1 {\n\t\tenvoyID = l.Name[:i]\n\t}\n\n\tif config.IsUpstream() && envoyID == xdscommon.OutboundListenerName {\n\t\treturn b.patchTProxyListener(config, l)\n\t}\n\n\t// If the Envoy extension configuration is for an upstream service, the listener's\n\t// name must match the upstream service's EnvoyID or be the outbound listener.\n\tif config.IsUpstream() && envoyID != config.EnvoyID() {\n\t\treturn l, false, nil\n\t}\n\n\t// If the Envoy extension configuration is for inbound resources, the\n\t// listener must be named xdscommon.PublicListenerName.\n\tif !config.IsUpstream() && envoyID != xdscommon.PublicListenerName {\n\t\treturn l, false, nil\n\t}\n\n\tvar patched bool\n\n\tfor _, filterChain := range l.FilterChains {\n\t\tvar filters []*envoy_listener_v3.Filter\n\n\t\tfor _, filter := range filterChain.Filters {\n\t\t\tnewFilter, ok, err := b.Extension.PatchFilter(config, filter)\n\t\t\tif err != nil {\n\t\t\t\tresultErr = multierror.Append(resultErr, fmt.Errorf(\"error patching listener filter: %w\", err))\n\t\t\t\tfilters = append(filters, filter)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif ok {\n\t\t\t\tfilters = append(filters, newFilter)\n\t\t\t\tpatched = true\n\t\t\t} else {\n\t\t\t\tfilters = append(filters, filter)\n\t\t\t}\n\t\t}\n\t\tfilterChain.Filters = filters\n\t}\n\n\treturn l, patched, resultErr\n}", "is_vulnerable": 1}
{"code": "\t\t\tfunc(t *testing.T) {\n\t\t\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\tvar sensor *v1alpha1.Sensor\n\t\t\t\teventBus := &eventbusv1alpha1.EventBus{Spec: eventbusv1alpha1.EventBusSpec{JetStream: &eventbusv1alpha1.JetStreamBus{}}}\n\t\t\t\terr = yaml.Unmarshal(content, &sensor)\n\t\t\t\tassert.NoError(t, err)\n\n\t\t\t\terr = ValidateSensor(sensor, eventBus)\n\t\t\t\tassert.NoError(t, err)\n\t\t\t})", "is_vulnerable": 0}
{"code": "func (src *SASLInitialResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'p')\n\n\tdst = append(dst, []byte(src.AuthMechanism)...)\n\tdst = append(dst, 0)\n\n\tdst = pgio.AppendInt32(dst, int32(len(src.Data)))\n\tdst = append(dst, src.Data...)\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (pt *pollingTrackerBase) updateErrorFromResponse() {\n\tvar err error\n\tif pt.resp.ContentLength != 0 {\n\t\ttype respErr struct {\n\t\t\tServiceError *ServiceError `json:\"error\"`\n\t\t}\n\t\tre := respErr{}\n\t\tdefer pt.resp.Body.Close()\n\t\tvar b []byte\n\t\tif b, err = ioutil.ReadAll(pt.resp.Body); err != nil || len(b) == 0 {\n\t\t\tgoto Default\n\t\t}\n\t\tif err = json.Unmarshal(b, &re); err != nil {\n\t\t\tgoto Default\n\t\t}\n\t\t// unmarshalling the error didn't yield anything, try unwrapped error\n\t\tif re.ServiceError == nil {\n\t\t\terr = json.Unmarshal(b, &re.ServiceError)\n\t\t\tif err != nil {\n\t\t\t\tgoto Default\n\t\t\t}\n\t\t}\n\t\t// the unmarshaller will ensure re.ServiceError is non-nil\n\t\t// even if there was no content unmarshalled so check the code.\n\t\tif re.ServiceError.Code != \"\" {\n\t\t\tpt.Err = re.ServiceError\n\t\t\treturn\n\t\t}\n\t}\nDefault:\n\tse := &ServiceError{\n\t\tCode:    pt.pollingStatus(),\n\t\tMessage: \"The async operation failed.\",\n\t}\n\tif err != nil {\n\t\tse.InnerError = make(map[string]interface{})\n\t\tse.InnerError[\"unmarshalError\"] = err.Error()\n\t}\n\t// stick the response body into the error object in hopes\n\t// it contains something useful to help diagnose the failure.\n\tif len(pt.rawBody) > 0 {\n\t\tse.AdditionalInfo = []map[string]interface{}{\n\t\t\tpt.rawBody,\n\t\t}\n\t}\n\tpt.Err = se\n}", "is_vulnerable": 0}
{"code": "func (c *Conn) Handle() {\n\tdefer c.Close()\n\n\tc.tr = trace.New(\"SMTP.Conn\", c.conn.RemoteAddr().String())\n\tdefer c.tr.Finish()\n\tc.tr.Debugf(\"Connected, mode: %s\", c.mode)\n\n\t// Set the first deadline, which covers possibly the TLS handshake and\n\t// then our initial greeting.\n\tc.conn.SetDeadline(time.Now().Add(c.commandTimeout))\n\n\tif tc, ok := c.conn.(*tls.Conn); ok {\n\t\t// For TLS connections, complete the handshake and get the state, so\n\t\t// it can be used when we say hello below.\n\t\terr := tc.Handshake()\n\t\tif err != nil {\n\t\t\tc.tr.Errorf(\"error completing TLS handshake: %v\", err)\n\t\t\treturn\n\t\t}\n\n\t\tcstate := tc.ConnectionState()\n\t\tc.tlsConnState = &cstate\n\t\tif name := c.tlsConnState.ServerName; name != \"\" {\n\t\t\tc.hostname = name\n\t\t}\n\t}\n\n\t// Set up a buffered reader and writer from the conn.\n\t// They will be used to do line-oriented, limited I/O.\n\tc.reader = bufio.NewReader(c.conn)\n\tc.writer = bufio.NewWriter(c.conn)\n\n\tc.remoteAddr = c.conn.RemoteAddr()\n\tif c.haproxyEnabled {\n\t\tsrc, dst, err := haproxy.Handshake(c.reader)\n\t\tif err != nil {\n\t\t\tc.tr.Errorf(\"error in haproxy handshake: %v\", err)\n\t\t\treturn\n\t\t}\n\t\tc.remoteAddr = src\n\t\tc.tr.Debugf(\"haproxy handshake: %v -> %v\", src, dst)\n\t}\n\n\tc.printfLine(\"220 %s ESMTP chasquid\", c.hostname)\n\n\tvar cmd, params string\n\tvar err error\n\tvar errCount int\n\nloop:\n\tfor {\n\t\tif time.Since(c.deadline) > 0 {\n\t\t\terr = fmt.Errorf(\"connection deadline exceeded\")\n\t\t\tc.tr.Error(err)\n\t\t\tbreak\n\t\t}\n\n\t\tc.conn.SetDeadline(time.Now().Add(c.commandTimeout))\n\n\t\tcmd, params, err = c.readCommand()\n\t\tif err != nil {\n\t\t\tc.printfLine(\"554 error reading command: %v\", err)\n\t\t\tbreak\n\t\t}\n\n\t\tif cmd == \"AUTH\" {\n\t\t\tc.tr.Debugf(\"-> AUTH <redacted>\")\n\t\t} else {\n\t\t\tc.tr.Debugf(\"-> %s %s\", cmd, params)\n\t\t}\n\n\t\tvar code int\n\t\tvar msg string\n\n\t\tswitch cmd {\n\t\tcase \"HELO\":\n\t\t\tcode, msg = c.HELO(params)\n\t\tcase \"EHLO\":\n\t\t\tcode, msg = c.EHLO(params)\n\t\tcase \"HELP\":\n\t\t\tcode, msg = c.HELP(params)\n\t\tcase \"NOOP\":\n\t\t\tcode, msg = c.NOOP(params)\n\t\tcase \"RSET\":\n\t\t\tcode, msg = c.RSET(params)\n\t\tcase \"VRFY\":\n\t\t\tcode, msg = c.VRFY(params)\n\t\tcase \"EXPN\":\n\t\t\tcode, msg = c.EXPN(params)\n\t\tcase \"MAIL\":\n\t\t\tcode, msg = c.MAIL(params)\n\t\tcase \"RCPT\":\n\t\t\tcode, msg = c.RCPT(params)\n\t\tcase \"DATA\":\n\t\t\t// DATA handles the whole sequence.\n\t\t\tcode, msg = c.DATA(params)\n\t\tcase \"STARTTLS\":\n\t\t\tcode, msg = c.STARTTLS(params)\n\t\tcase \"AUTH\":\n\t\t\tcode, msg = c.AUTH(params)\n\t\tcase \"QUIT\":\n\t\t\t_ = c.writeResponse(221, \"2.0.0 Be seeing you...\")\n\t\t\tbreak loop\n\t\tcase \"GET\", \"POST\", \"CONNECT\":\n\t\t\t// HTTP protocol detection, to prevent cross-protocol attacks\n\t\t\t// (e.g. https://alpaca-attack.com/).\n\t\t\twrongProtoCount.Add(cmd, 1)\n\t\t\tc.tr.Errorf(\"http command, closing connection\")\n\t\t\t_ = c.writeResponse(502,\n\t\t\t\t\"5.7.0 You hear someone cursing shoplifters\")\n\t\t\tbreak loop\n\t\tdefault:\n\t\t\t// Sanitize it a bit to avoid filling the logs and events with\n\t\t\t// noisy data. Keep the first 6 bytes for debugging.\n\t\t\tcmd = fmt.Sprintf(\"unknown<%.6q>\", cmd)\n\t\t\tcode = 500\n\t\t\tmsg = \"5.5.1 Unknown command\"\n\t\t}\n\n\t\tcommandCount.Add(cmd, 1)\n\t\tif code > 0 {\n\t\t\tc.tr.Debugf(\"<- %d  %s\", code, msg)\n\n\t\t\tif code >= 400 {\n\t\t\t\t// Be verbose about errors, to help troubleshooting.\n\t\t\t\tc.tr.Errorf(\"%s failed: %d  %s\", cmd, code, msg)\n\n\t\t\t\t// Close the connection after 3 errors.\n\t\t\t\t// This helps prevent cross-protocol attacks.\n\t\t\t\terrCount++\n\t\t\t\tif errCount >= 3 {\n\t\t\t\t\t// https://tools.ietf.org/html/rfc5321#section-4.3.2\n\t\t\t\t\tc.tr.Errorf(\"too many errors, breaking connection\")\n\t\t\t\t\t_ = c.writeResponse(421, \"4.5.0 Too many errors, bye\")\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\terr = c.writeResponse(code, msg)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t} else if code < 0 {\n\t\t\t// Negative code means that we have to break the connection.\n\t\t\t// TODO: This is hacky, it's probably worth it at this point to\n\t\t\t// refactor this into using a custom response type.\n\t\t\tc.tr.Errorf(\"%s closed the connection: %s\", cmd, msg)\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err != nil {\n\t\tif err == io.EOF {\n\t\t\tc.tr.Debugf(\"client closed the connection\")\n\t\t} else {\n\t\t\tc.tr.Errorf(\"exiting with error: %v\", err)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func WithMaxDecompressBufferSize(size int64) DecryptOption {\n\treturn &decryptOption{option.New(identMaxDecompressBufferSize{}, size)}\n}", "is_vulnerable": 0}
{"code": "\tenc := func(stmt *sql.Statement) {\n\t\tstmt.BindInt64(1, int64(epoch))\n\t\tstmt.BindBytes(2, nodeID.Bytes())\n\t}", "is_vulnerable": 1}
{"code": "func (e *GraphiteExecutor) createRequest(dsInfo *models.DataSource, data url.Values) (*http.Request, error) {\n\tu, _ := url.Parse(dsInfo.Url)\n\tu.Path = path.Join(u.Path, \"render\")\n\n\treq, err := http.NewRequest(http.MethodPost, u.String(), strings.NewReader(data.Encode()))\n\tif err != nil {\n\t\tglog.Info(\"Failed to create request\", \"error\", err)\n\t\treturn nil, fmt.Errorf(\"Failed to create request. error: %v\", err)\n\t}\n\n\treq.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\tif dsInfo.BasicAuth {\n\t\treq.SetBasicAuth(dsInfo.BasicAuthUser, dsInfo.DecryptedBasicAuthPassword())\n\t}\n\n\treturn req, err\n}", "is_vulnerable": 0}
{"code": "func (m *Object) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowProto\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Object: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Object: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CustomField1\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProto\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v CustomType\n\t\t\tm.CustomField1 = &v\n\t\t\tif err := m.CustomField1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CustomField2\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProto\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v CustomType\n\t\t\tm.CustomField2 = append(m.CustomField2, v)\n\t\t\tif err := m.CustomField2[len(m.CustomField2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipProto(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\treturn func(comp common.ApplicationComponent, patcher *value.Value, clusterName string, overrideNamespace string, env string) (*unstructured.Unstructured, []*unstructured.Unstructured, bool, error) {\n\t\tt := time.Now()\n\t\tdefer func() { metrics.ApplyComponentTimeHistogram.WithLabelValues(\"-\").Observe(time.Since(t).Seconds()) }()\n\n\t\tctx := multicluster.ContextWithClusterName(context.Background(), clusterName)\n\t\tctx = contextWithComponentNamespace(ctx, overrideNamespace)\n\t\tctx = contextWithReplicaKey(ctx, comp.ReplicaKey)\n\t\tctx = envbinding.ContextWithEnvName(ctx, env)\n\n\t\twl, manifest, err := h.prepareWorkloadAndManifests(ctx, appParser, comp, appRev, patcher, af)\n\t\tif err != nil {\n\t\t\treturn nil, nil, false, err\n\t\t}\n\t\tif len(manifest.PackagedWorkloadResources) != 0 {\n\t\t\tif err := h.Dispatch(ctx, clusterName, common.WorkflowResourceCreator, manifest.PackagedWorkloadResources...); err != nil {\n\t\t\t\treturn nil, nil, false, errors.WithMessage(err, \"cannot dispatch packaged workload resources\")\n\t\t\t}\n\t\t}\n\t\twl.Ctx.SetCtx(auth.ContextWithUserInfo(ctx, h.app))\n\n\t\treadyWorkload, readyTraits, err := renderComponentsAndTraits(h.r.Client, manifest, appRev, clusterName, overrideNamespace, env)\n\t\tif err != nil {\n\t\t\treturn nil, nil, false, err\n\t\t}\n\t\tcheckSkipApplyWorkload(wl)\n\n\t\tdispatchResources := readyTraits\n\t\tif !wl.SkipApplyWorkload {\n\t\t\tdispatchResources = append([]*unstructured.Unstructured{readyWorkload}, readyTraits...)\n\t\t}\n\n\t\tif err := h.Dispatch(ctx, clusterName, common.WorkflowResourceCreator, dispatchResources...); err != nil {\n\t\t\treturn nil, nil, false, errors.WithMessage(err, \"Dispatch\")\n\t\t}\n\n\t\t_, isHealth, err := h.collectHealthStatus(ctx, wl, appRev, overrideNamespace)\n\t\tif err != nil {\n\t\t\treturn nil, nil, false, errors.WithMessage(err, \"CollectHealthStatus\")\n\t\t}\n\n\t\tif DisableResourceApplyDoubleCheck {\n\t\t\treturn readyWorkload, readyTraits, isHealth, nil\n\t\t}\n\t\tworkload, traits, err := getComponentResources(auth.ContextWithUserInfo(ctx, h.app), manifest, wl.SkipApplyWorkload, h.r.Client)\n\t\treturn workload, traits, isHealth, err\n\t}", "is_vulnerable": 0}
{"code": "func GetRuntimeConfigurations(cfgSnap *proxycfg.ConfigSnapshot) map[api.CompoundServiceName][]extensioncommon.RuntimeConfig {\n\textensionsMap := make(map[api.CompoundServiceName][]api.EnvoyExtension)\n\tupstreamMap := make(map[api.CompoundServiceName]*extensioncommon.UpstreamData)\n\tvar kind api.ServiceKind\n\textensionConfigurationsMap := make(map[api.CompoundServiceName][]extensioncommon.RuntimeConfig)\n\n\ttrustDomain := \"\"\n\tif cfgSnap.Roots != nil {\n\t\ttrustDomain = cfgSnap.Roots.TrustDomain\n\t}\n\n\tswitch cfgSnap.Kind {\n\tcase structs.ServiceKindConnectProxy:\n\t\tkind = api.ServiceKindConnectProxy\n\t\toutgoingKindByService := make(map[api.CompoundServiceName]api.ServiceKind)\n\t\tvipForService := make(map[api.CompoundServiceName]string)\n\t\tfor uid, upstreamData := range cfgSnap.ConnectProxy.WatchedUpstreamEndpoints {\n\t\t\tsn := upstreamIDToCompoundServiceName(uid)\n\n\t\t\tfor _, serviceNodes := range upstreamData {\n\t\t\t\tfor _, serviceNode := range serviceNodes {\n\t\t\t\t\tif serviceNode.Service == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tvip := serviceNode.Service.TaggedAddresses[structs.TaggedAddressVirtualIP].Address\n\t\t\t\t\tif vip != \"\" {\n\t\t\t\t\t\tif _, ok := vipForService[sn]; !ok {\n\t\t\t\t\t\t\tvipForService[sn] = vip\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Store the upstream's kind, and for ServiceKindTypical we don't do anything because we'll default\n\t\t\t\t\t// any unset upstreams to ServiceKindConnectProxy below.\n\t\t\t\t\tswitch serviceNode.Service.Kind {\n\t\t\t\t\tcase structs.ServiceKindTypical:\n\t\t\t\t\tdefault:\n\t\t\t\t\t\toutgoingKindByService[sn] = api.ServiceKind(serviceNode.Service.Kind)\n\t\t\t\t\t}\n\t\t\t\t\t// We only need the kind from one instance, so break once we find it.\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// TODO(peering): consider PeerUpstreamEndpoints in addition to DiscoveryChain\n\t\t// These are the discovery chains for upstreams which have the Envoy Extensions applied to the local service.\n\t\tfor uid, dc := range cfgSnap.ConnectProxy.DiscoveryChain {\n\t\t\tcompoundServiceName := upstreamIDToCompoundServiceName(uid)\n\t\t\textensionsMap[compoundServiceName] = convertEnvoyExtensions(dc.EnvoyExtensions)\n\n\t\t\tmeta := uid.EnterpriseMeta\n\t\t\tsni := connect.ServiceSNI(uid.Name, \"\", meta.NamespaceOrDefault(), meta.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\toutgoingKind, ok := outgoingKindByService[compoundServiceName]\n\t\t\tif !ok {\n\t\t\t\toutgoingKind = api.ServiceKindConnectProxy\n\t\t\t}\n\n\t\t\tupstreamMap[compoundServiceName] = &extensioncommon.UpstreamData{\n\t\t\t\tSNI:               map[string]struct{}{sni: {}},\n\t\t\t\tVIP:               vipForService[compoundServiceName],\n\t\t\t\tEnvoyID:           uid.EnvoyID(),\n\t\t\t\tOutgoingProxyKind: outgoingKind,\n\t\t\t}\n\t\t}\n\t\t// Adds extensions configured for the local service to the RuntimeConfig. This only applies to\n\t\t// connect-proxies because extensions are either global or tied to a specific service, so the terminating\n\t\t// gateway's Envoy resources for the local service (i.e not to upstreams) would never need to be modified.\n\t\tlocalSvc := api.CompoundServiceName{\n\t\t\tName:      cfgSnap.Proxy.DestinationServiceName,\n\t\t\tNamespace: cfgSnap.ProxyID.NamespaceOrDefault(),\n\t\t\tPartition: cfgSnap.ProxyID.PartitionOrEmpty(),\n\t\t}\n\t\textensionConfigurationsMap[localSvc] = []extensioncommon.RuntimeConfig{}\n\t\tcfgSnapExts := convertEnvoyExtensions(cfgSnap.Proxy.EnvoyExtensions)\n\t\tfor _, ext := range cfgSnapExts {\n\t\t\textCfg := extensioncommon.RuntimeConfig{\n\t\t\t\tEnvoyExtension:        ext,\n\t\t\t\tServiceName:           localSvc,\n\t\t\t\tIsSourcedFromUpstream: false,\n\t\t\t\tUpstreams:             upstreamMap,\n\t\t\t\tKind:                  kind,\n\t\t\t\tProtocol:              proxyConfigProtocol(cfgSnap.Proxy.Config),\n\t\t\t}\n\t\t\textensionConfigurationsMap[localSvc] = append(extensionConfigurationsMap[localSvc], extCfg)\n\t\t}\n\tcase structs.ServiceKindTerminatingGateway:\n\t\tkind = api.ServiceKindTerminatingGateway\n\t\tfor svc, c := range cfgSnap.TerminatingGateway.ServiceConfigs {\n\t\t\tcompoundServiceName := serviceNameToCompoundServiceName(svc)\n\t\t\textensionsMap[compoundServiceName] = convertEnvoyExtensions(c.EnvoyExtensions)\n\n\t\t\tsni := connect.ServiceSNI(svc.Name, \"\", svc.NamespaceOrDefault(), svc.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\tenvoyID := proxycfg.NewUpstreamIDFromServiceName(svc)\n\n\t\t\tsnis := map[string]struct{}{sni: {}}\n\n\t\t\tresolver, hasResolver := cfgSnap.TerminatingGateway.ServiceResolvers[svc]\n\t\t\tif hasResolver {\n\t\t\t\tfor subsetName := range resolver.Subsets {\n\t\t\t\t\tsni := connect.ServiceSNI(svc.Name, subsetName, svc.NamespaceOrDefault(), svc.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\t\t\tsnis[sni] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tupstreamMap[compoundServiceName] = &extensioncommon.UpstreamData{\n\t\t\t\tSNI:               snis,\n\t\t\t\tEnvoyID:           envoyID.EnvoyID(),\n\t\t\t\tOutgoingProxyKind: api.ServiceKindTerminatingGateway,\n\t\t\t}\n\n\t\t}\n\t}\n\n\t// If applicable, include extension configuration for remote upstreams of the local service.\n\t// This only applies to specific extensions authorized to apply to remote proxies.\n\tfor svc, exts := range extensionsMap {\n\t\textensionConfigurationsMap[svc] = []extensioncommon.RuntimeConfig{}\n\t\tfor _, ext := range exts {\n\t\t\tif appliesToRemoteDownstreams(ext) {\n\t\t\t\textCfg := extensioncommon.RuntimeConfig{\n\t\t\t\t\tEnvoyExtension:        ext,\n\t\t\t\t\tKind:                  kind,\n\t\t\t\t\tServiceName:           svc,\n\t\t\t\t\tIsSourcedFromUpstream: true,\n\t\t\t\t\tUpstreams:             upstreamMap,\n\t\t\t\t\tProtocol:              proxyConfigProtocol(cfgSnap.Proxy.Config),\n\t\t\t\t}\n\t\t\t\textensionConfigurationsMap[svc] = append(extensionConfigurationsMap[svc], extCfg)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn extensionConfigurationsMap\n}", "is_vulnerable": 0}
{"code": "func (src *NoData) Encode(dst []byte) ([]byte, error) {\n\treturn append(dst, 'n', 0, 0, 0, 4), nil\n}", "is_vulnerable": 0}
{"code": "func NewPlayerRepository(ctx context.Context, db dbx.Builder) model.PlayerRepository {\n\tr := &playerRepository{}\n\tr.ctx = ctx\n\tr.db = db\n\tr.registerModel(&model.Player{}, map[string]filterFunc{\n\t\t\"name\": containsFilter(\"player.name\"),\n\t})\n\treturn r\n}", "is_vulnerable": 0}
{"code": "func pathSecretServiceAccountKey(b *backend) *framework.Path {\n\treturn &framework.Path{\n\t\tPattern: fmt.Sprintf(\"key/%s\", framework.GenericNameRegex(\"roleset\")),\n\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\"roleset\": {\n\t\t\t\tType:        framework.TypeString,\n\t\t\t\tDescription: \"Required. Name of the role set.\",\n\t\t\t},\n\t\t\t\"key_algorithm\": {\n\t\t\t\tType:        framework.TypeString,\n\t\t\t\tDescription: fmt.Sprintf(`Private key algorithm for service account key - defaults to %s\"`, keyAlgorithmRSA2k),\n\t\t\t\tDefault:     keyAlgorithmRSA2k,\n\t\t\t},\n\t\t\t\"key_type\": {\n\t\t\t\tType:        framework.TypeString,\n\t\t\t\tDescription: fmt.Sprintf(`Private key type for service account key - defaults to %s\"`, privateKeyTypeJson),\n\t\t\t\tDefault:     privateKeyTypeJson,\n\t\t\t},\n\t\t\t\"ttl\": {\n\t\t\t\tType:        framework.TypeDurationSecond,\n\t\t\t\tDescription: \"Lifetime of the service account key\",\n\t\t\t},\n\t\t},\n\t\tExistenceCheck: b.pathRoleSetExistenceCheck(\"roleset\"),\n\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\tlogical.ReadOperation:   &framework.PathOperation{Callback: b.pathServiceAccountKey},\n\t\t\tlogical.UpdateOperation: &framework.PathOperation{Callback: b.pathServiceAccountKey},\n\t\t},\n\t\tHelpSynopsis:    pathServiceAccountKeySyn,\n\t\tHelpDescription: pathServiceAccountKeyDesc,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (h *addMentionsBroadcastHook) Process(msg *platform.HookedWebSocketEvent, webConn *platform.WebConn, args map[string]any) error {\n\tmentions, err := getTypedArg[model.StringArray](args, \"mentions\")\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"Invalid mentions value passed to addMentionsBroadcastHook\")\n\t}\n\n\tif len(mentions) > 0 && pUtils.Contains[string](mentions, webConn.UserId) {\n\t\t// Note that the client expects this field to be stringified\n\t\tmsg.Add(\"mentions\", model.ArrayToJSON([]string{webConn.UserId}))\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func Test_ProcessResults_whenDifferentPaths_AccumulatesIssues(t *testing.T) {\n\ttestutil.UnitTest(t)\n\tf := NewFolder(\"dummy\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\n\tf.processResults([]snyk.Issue{\n\t\t{ID: \"id1\", AffectedFilePath: \"path1\"},\n\t\t{ID: \"id2\", AffectedFilePath: \"path2\"},\n\t})\n\tf.processResults([]snyk.Issue{{ID: \"id3\", AffectedFilePath: \"path3\"}})\n\n\tassert.Equal(t, 3, f.documentDiagnosticCache.Length())\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path1\"))\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path2\"))\n\tassert.NotNil(t, f.documentDiagnosticCache.Get(\"path3\"))\n}", "is_vulnerable": 0}
{"code": "func LLBBridgeToGatewayClient(ctx context.Context, llbBridge frontend.FrontendLLBBridge, opts map[string]string, inputs map[string]*opspb.Definition, w worker.Infos, sid string, sm *session.Manager) (*BridgeClient, error) {\n\tbc := &BridgeClient{\n\t\topts:              opts,\n\t\tinputs:            inputs,\n\t\tFrontendLLBBridge: llbBridge,\n\t\tsid:               sid,\n\t\tsm:                sm,\n\t\tworkers:           w,\n\t\tworkerRefByID:     make(map[string]*worker.WorkerRef),\n\t}\n\tbc.buildOpts = bc.loadBuildOpts()\n\treturn bc, nil\n}", "is_vulnerable": 1}
{"code": "func NewCountedReader(r io.Reader) *CountedReader {\n\treturn &CountedReader{reader: r}\n}", "is_vulnerable": 0}
{"code": "func (c *Configurator) Update(config Config) error {\n\tc.Lock()\n\t// order of defers matters because log acquires a RLock()\n\tdefer c.log(\"Update\")\n\tdefer c.Unlock()\n\n\tcert, err := loadKeyPair(config.CertFile, config.KeyFile)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpems, err := LoadCAs(config.CAFile, config.CAPath)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpool, err := pool(append(pems, c.autoTLS.caPems()...))\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = c.check(config, pool, cert); err != nil {\n\t\treturn err\n\t}\n\tc.base = &config\n\tc.manual.cert = cert\n\tc.manual.caPems = pems\n\tc.caPool = pool\n\tc.version++\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func ExecWithCheck(name string, a ...string) (string, error) {\n\tif CheckIllegal(a...) {\n\t\treturn \"error exec !\", errors.New(\"There are invalid characters in the command you're executing.\")\n\t}\n\tcmd := exec.Command(name, a...)\n\tvar stdout, stderr bytes.Buffer\n\tcmd.Stdout = &stdout\n\tcmd.Stderr = &stderr\n\terr := cmd.Run()\n\tif err != nil {\n\t\terrMsg := \"\"\n\t\tif len(stderr.String()) != 0 {\n\t\t\terrMsg = fmt.Sprintf(\"stderr: %s\", stderr.String())\n\t\t}\n\t\tif len(stdout.String()) != 0 {\n\t\t\tif len(errMsg) != 0 {\n\t\t\t\terrMsg = fmt.Sprintf(\"%s; stdout: %s\", errMsg, stdout.String())\n\t\t\t} else {\n\t\t\t\terrMsg = fmt.Sprintf(\"stdout: %s\", stdout.String())\n\t\t\t}\n\t\t}\n\t\treturn errMsg, err\n\t}\n\treturn stdout.String(), nil\n}", "is_vulnerable": 1}
{"code": "func UserByID(db *gorm.DB, table, userID, instanceID string) (*model.UserView, error) {\n\tuser := new(model.UserView)\n\n\tquery := db.Raw(userByIDQuery, instanceID, userID)\n\n\ttx := query.BeginTx(context.Background(), &sql.TxOptions{ReadOnly: true})\n\tdefer func() {\n\t\tif err := tx.Commit().Error; err != nil {\n\t\t\tlogging.OnError(err).Info(\"commit failed\")\n\t\t}\n\t\ttx.RollbackUnlessCommitted()\n\t}()\n\n\terr := tx.Scan(user).Error\n\tif err == nil {\n\t\tuser.SetEmptyUserType()\n\t\treturn user, nil\n\t}\n\tif errors.Is(err, gorm.ErrRecordNotFound) {\n\t\treturn nil, zerrors.ThrowNotFound(err, \"VIEW-hodc6\", \"object not found\")\n\t}\n\tlogging.WithFields(\"table \", table).WithError(err).Warn(\"get from cache error\")\n\treturn nil, zerrors.ThrowInternal(err, \"VIEW-qJBg9\", \"cache error\")\n}", "is_vulnerable": 1}
{"code": "func getDownloadBackup(c *gin.Context) {\n\tclient := middleware.ExtractApiClient(c)\n\tmanager := middleware.ExtractManager(c)\n\n\ttoken := tokens.BackupPayload{}\n\tif err := tokens.ParseToken([]byte(c.Query(\"token\")), &token); err != nil {\n\t\tmiddleware.CaptureAndAbort(c, err)\n\t\treturn\n\t}\n\n\tif _, ok := manager.Get(token.ServerUuid); !ok || !token.IsUniqueRequest() {\n\t\tc.AbortWithStatusJSON(http.StatusNotFound, gin.H{\n\t\t\t\"error\": \"The requested resource was not found on this server.\",\n\t\t})\n\t\treturn\n\t}\n\n\tb, st, err := backup.LocateLocal(client, token.BackupUuid)\n\tif err != nil {\n\t\tif errors.Is(err, os.ErrNotExist) {\n\t\t\tc.AbortWithStatusJSON(http.StatusNotFound, gin.H{\n\t\t\t\t\"error\": \"The requested backup was not found on this server.\",\n\t\t\t})\n\t\t\treturn\n\t\t}\n\n\t\tmiddleware.CaptureAndAbort(c, err)\n\t\treturn\n\t}\n\n\t// The use of `os` here is safe as backups are not stored within server\n\t// accessible directories.\n\tf, err := os.Open(b.Path())\n\tif err != nil {\n\t\tmiddleware.CaptureAndAbort(c, err)\n\t\treturn\n\t}\n\tdefer f.Close()\n\n\tc.Header(\"Content-Length\", strconv.Itoa(int(st.Size())))\n\tc.Header(\"Content-Disposition\", \"attachment; filename=\"+strconv.Quote(st.Name()))\n\tc.Header(\"Content-Type\", \"application/octet-stream\")\n\n\t_, _ = bufio.NewReader(f).WriteTo(c.Writer)\n}", "is_vulnerable": 0}
{"code": "func TestAuthorizationModelInvalidSchemaVersion(t *testing.T) {\n\tctx := context.Background()\n\tlogger := logger.NewNoopLogger()\n\ttransport := gateway.NewNoopTransport()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().MaxTypesPerAuthorizationModel().Return(100)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgapb.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_0,\n\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"team\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"member\": typesystem.This(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil)\n\tmockDatastore.EXPECT().ListObjectsByType(gomock.Any(), store, \"repo\").AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := Server{\n\t\tdatastore: mockDatastore,\n\t\ttransport: transport,\n\t\tlogger:    logger,\n\t\tconfig: &Config{\n\t\t\tResolveNodeLimit:      25,\n\t\t\tListObjectsDeadline:   5 * time.Second,\n\t\t\tListObjectsMaxResults: 1000,\n\t\t},\n\t}\n\n\tt.Run(\"invalid_schema_error_in_check\", func(t *testing.T) {\n\t\t_, err := s.Check(ctx, &openfgapb.CheckRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tTupleKey: tuple.NewTupleKey(\n\t\t\t\t\"team:abc\",\n\t\t\t\t\"member\",\n\t\t\t\t\"user:anne\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_list_objects\", func(t *testing.T) {\n\t\t_, err := s.ListObjects(ctx, &openfgapb.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"team\",\n\t\t\tRelation:             \"member\",\n\t\t\tUser:                 \"user:anne\",\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_streamed_list_objects\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgapb.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"team\",\n\t\t\tRelation:             \"member\",\n\t\t\tUser:                 \"user:anne\",\n\t\t}, NewMockStreamServer())\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_expand\", func(t *testing.T) {\n\t\t_, err := s.Expand(ctx, &openfgapb.ExpandRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga\",\n\t\t\t\t\"reader\",\n\t\t\t\t\"user:anne\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write\", func(t *testing.T) {\n\t\t_, err := s.Write(ctx, &openfgapb.WriteRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tWrites: &openfgapb.TupleKeys{TupleKeys: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\",\n\t\t\t\t\t\"reader\",\n\t\t\t\t\t\"user:anne\"),\n\t\t\t}},\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write_model\", func(t *testing.T) {\n\t\t_, err := s.WriteAuthorizationModel(ctx, &openfgapb.WriteAuthorizationModelRequest{\n\t\t\tStoreId:         store,\n\t\t\tSchemaVersion:   typesystem.SchemaVersion1_0,\n\t\t\tTypeDefinitions: parser.MustParse(`type repo`),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_invalid_authorization_model), e.Code(), err)\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write_assertion\", func(t *testing.T) {\n\t\t_, err := s.WriteAssertions(ctx, &openfgapb.WriteAssertionsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tAssertions: []*openfgapb.Assertion{{\n\t\t\t\tTupleKey:    tuple.NewTupleKey(\"repo:test\", \"reader\", \"user:elbuo\"),\n\t\t\t\tExpectation: false,\n\t\t\t}},\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n}", "is_vulnerable": 1}
{"code": "func (p *Policy) AllowUnsafe(allowUnsafe bool) *Policy {\n\tp.init()\n\tp.allowUnsafe = allowUnsafe\n\treturn p\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) genQuotaCmd(value *JuiceFS, mount datav1alpha1.Mount) error {\n\toptions := mount.Options\n\tfor k, v := range options {\n\t\tif k == \"quota\" {\n\t\t\tqs, err := j.getQuota(v)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"invalid quota %s\", v)\n\t\t\t}\n\t\t\tif value.Fuse.SubPath == \"\" {\n\t\t\t\treturn fmt.Errorf(\"subPath must be set when quota is enabled\")\n\t\t\t}\n\t\t\tif value.Edition == CommunityEdition {\n\t\t\t\t// ce\n\t\t\t\t// juicefs quota set ${metaurl} --path ${path} --capacity ${capacity}\n\t\t\t\tvalue.Configs.QuotaCmd = fmt.Sprintf(\"%s quota set %s --path %s --capacity %d\", common.JuiceCeCliPath, value.Source, value.Fuse.SubPath, qs)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\t// ee\n\t\t\t// juicefs quota set ${metaurl} --path ${path} --capacity ${capacity}\n\t\t\tcli := common.JuiceCliPath\n\t\t\tvalue.Configs.QuotaCmd = fmt.Sprintf(\"%s quota set %s --path %s --capacity %d\", cli, value.Source, value.Fuse.SubPath, qs)\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestGithub_Authenticate_Vela_Token(t *testing.T) {\n\t// setup context\n\tgin.SetMode(gin.TestMode)\n\n\tresp := httptest.NewRecorder()\n\tcontext, engine := gin.CreateTestContext(resp)\n\tcontext.Request, _ = http.NewRequest(http.MethodPost, \"/authenticate/token\", nil)\n\tcontext.Request.Header.Set(\"Token\", \"vela\")\n\n\tengine.GET(\"/api/v3/user\", func(c *gin.Context) {\n\t\tc.Header(\"Content-Type\", \"application/json\")\n\t\tc.Status(http.StatusOK)\n\t\tc.File(\"testdata/user.json\")\n\t})\n\n\tengine.POST(\"/api/v3/applications/foo/token\", func(c *gin.Context) {\n\t\tc.Header(\"Content-Type\", \"application/json\")\n\t\tc.Status(http.StatusOK)\n\t})\n\n\ts := httptest.NewServer(engine)\n\tdefer s.Close()\n\n\tclient, _ := NewTest(s.URL)\n\n\t// run test\n\t_, err := client.AuthenticateToken(context.Request)\n\tif resp.Code != http.StatusOK {\n\t\tt.Errorf(\"Authenticate returned %v, want %v\", resp.Code, http.StatusOK)\n\t}\n\n\tif err == nil {\n\t\tt.Error(\"Authenticate should have returned err\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetRandomStringFromRange(a, b int) string {\n\tvar i uint32\n\tif a > b {\n\t\ti = genRandInt(a-b) + uint32(b)\n\t} else {\n\t\ti = genRandInt(b-a) + uint32(a)\n\t}\n\treturn gen(i, charset)\n}", "is_vulnerable": 0}
{"code": "func (ctx *cbcAEAD) Open(dst, nonce, ciphertext, data []byte) ([]byte, error) {\n\tif len(ciphertext) < ctx.authtagBytes {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (too short)\")\n\t}\n\n\toffset := len(ciphertext) - ctx.authtagBytes\n\texpectedTag := ctx.computeAuthTag(data, nonce, ciphertext[:offset])\n\tmatch := subtle.ConstantTimeCompare(expectedTag, ciphertext[offset:])\n\tif match != 1 {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (auth tag mismatch)\")\n\t}\n\n\tcbc := cipher.NewCBCDecrypter(ctx.blockCipher, nonce)\n\n\t// Make copy of ciphertext buffer, don't want to modify in place\n\tbuffer := append([]byte{}, []byte(ciphertext[:offset])...)\n\n\tif len(buffer)%ctx.blockCipher.BlockSize() > 0 {\n\t\treturn nil, errors.New(\"square/go-jose: invalid ciphertext (invalid length)\")\n\t}\n\n\tcbc.CryptBlocks(buffer, buffer)\n\n\t// Remove padding\n\tplaintext, err := unpadBuffer(buffer, ctx.blockCipher.BlockSize())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tret, out := resize(dst, len(dst)+len(plaintext))\n\tcopy(out, plaintext)\n\n\treturn ret, nil\n}", "is_vulnerable": 1}
{"code": "func Unseal(rw io.ReadWriter, sealed []byte, srkAuth []byte) ([]byte, error) {\n\t// Run OSAP for the SRK, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a handle.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etSRK, khSRK, srkAuth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\t// The unseal command needs an OIAP session in addition to the OSAP session.\n\toiapr, err := oiap(rw)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer oiapr.Close(rw)\n\n\t// Convert the sealed value into a tpmStoredData.\n\tvar tsd tpmStoredData\n\tif _, err := tpmutil.Unpack(sealed, &tsd); err != nil {\n\t\treturn nil, errors.New(\"couldn't convert the sealed data into a tpmStoredData struct\")\n\t}\n\n\t// The digest for auth1 and auth2 for the unseal command is computed as\n\t// digest = SHA1(ordUnseal || tsd)\n\tauthIn := []interface{}{ordUnseal, tsd}\n\n\t// The first commandAuth uses the shared secret as an HMAC key.\n\tca1, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, nil, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The second commandAuth is based on OIAP instead of OSAP and uses the\n\t// SRK auth value as an HMAC key instead of the shared secret.\n\tca2, err := newCommandAuth(oiapr.AuthHandle, oiapr.NonceEven, nil, srkAuth, authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tunsealed, ra1, ra2, ret, err := unseal(rw, khSRK, &tsd, ca1, ca2)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check the response authentication.\n\traIn := []interface{}{ret, ordUnseal, tpmutil.U32Bytes(unsealed)}\n\tif err := ra1.verify(ca1.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := ra2.verify(ca2.NonceOdd, srkAuth, raIn); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn unsealed, nil\n}", "is_vulnerable": 0}
{"code": "func (client Client) Update(ctx context.Context, resourceGroupName string, resourceProviderNamespace string, parentResourcePath string, resourceType string, resourceName string, parameters GenericResource) (result UpdateFuture, err error) {\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\w\\._\\(\\)]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"Update\", err.Error())\n\t}\n\n\treq, err := client.UpdatePreparer(ctx, resourceGroupName, resourceProviderNamespace, parentResourcePath, resourceType, resourceName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Update\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresult, err = client.UpdateSender(req)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"Update\", result.Response(), \"Failure sending request\")\n\t\treturn\n\t}\n\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (ec RuntimeConfig) MatchesUpstreamServiceSNI(sni string) bool {\n\tu := ec.Upstreams[ec.ServiceName]\n\t_, match := u.SNI[sni]\n\treturn match\n}", "is_vulnerable": 1}
{"code": "func (r *RepTarget) Valid(v *validation.Validation) {\n\tif len(r.Name) == 0 {\n\t\tv.SetError(\"name\", \"can not be empty\")\n\t}\n\n\tif len(r.Name) > 64 {\n\t\tv.SetError(\"name\", \"max length is 64\")\n\t}\n\n\turl, err := utils.ParseEndpoint(r.URL)\n\tif err != nil {\n\t\tv.SetError(\"endpoint\", err.Error())\n\t} else {\n\t\t// Prevent SSRF security issue #3755\n\t\tr.URL = url.Scheme + \"://\" + url.Host + url.Path\n\t\tif len(r.URL) > 64 {\n\t\t\tv.SetError(\"endpoint\", \"max length is 64\")\n\t\t}\n\t}\n\n\t// password is encoded using base64, the length of this field\n\t// in DB is 64, so the max length in request is 48\n\tif len(r.Password) > 48 {\n\t\tv.SetError(\"password\", \"max length is 48\")\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\tBeforeEach(func() {\n\t\t\t\tif callType.directCall == false {\n\t\t\t\t\terr = vesting.CreateGenericAuthz(s.ctx, s.app.AuthzKeeper, contractAddr, s.address, vesting.FundVestingAccountMsgURL)\n\t\t\t\t\tExpect(err).ToNot(HaveOccurred(), \"error while creating the generic authorization: %v\", err)\n\t\t\t\t}\n\t\t\t})", "is_vulnerable": 1}
{"code": "\tappendMessage = func(targetOffset uint32) bool {\n\t\tfor _, f := range frags {\n\t\t\tif f.handshakeHeader.FragmentOffset == targetOffset {\n\t\t\t\tfragmentEnd := (f.handshakeHeader.FragmentOffset + f.handshakeHeader.FragmentLength)\n\t\t\t\tif fragmentEnd != f.handshakeHeader.Length && f.handshakeHeader.FragmentLength != 0 {\n\t\t\t\t\tif !appendMessage(fragmentEnd) {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\trawMessage = append(f.data, rawMessage...)\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}", "is_vulnerable": 0}
{"code": "func (m *MenuController) UpdateMenu(ctx *gin.Context) {\n\tresp := response.NewResponse()\n\tctx.Set(\"response\", resp)\n\tid, err := strconv.Atoi(ctx.Param(\"id\"))\n\tif err != nil {\n\t\te := &response.AdminError{\n\t\t\tErrorCode:    http.StatusBadRequest,\n\t\t\tErrorMessage: err.Error(),\n\t\t}\n\t\t_ = ctx.Error(e)\n\t\treturn\n\t}\n\tvar data request.MenuUpdateReq\n\tdata.Id = id\n\ttranslator, _ := m.translators[\"zh\"]\n\terr = utils.ValidatorBody[request.MenuUpdateReq](ctx, &data, translator)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\terr = m.sysMenuService.UpdateMenu(ctx, data)\n\tif err != nil {\n\t\t_ = ctx.Error(err)\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func main() {\n\tcfg := config{\n\t\tauth: proxy.Config{\n\t\t\tAuthentication: &authn.AuthnConfig{\n\t\t\t\tX509:   &authn.X509Config{},\n\t\t\t\tHeader: &authn.AuthnHeaderConfig{},\n\t\t\t\tOIDC:   &authn.OIDCConfig{},\n\t\t\t},\n\t\t\tAuthorization: &authz.Config{},\n\t\t},\n\t}\n\tflagset := flag.NewFlagSet(os.Args[0], flag.ExitOnError)\n\tconfigFileName := \"\"\n\n\t// Add glog flags\n\tflagset.AddGoFlagSet(stdflag.CommandLine)\n\n\t// kube-rbac-proxy flags\n\tflagset.StringVar(&cfg.insecureListenAddress, \"insecure-listen-address\", \"\", \"The address the kube-rbac-proxy HTTP server should listen on.\")\n\tflagset.StringVar(&cfg.secureListenAddress, \"secure-listen-address\", \"\", \"The address the kube-rbac-proxy HTTPs server should listen on.\")\n\tflagset.StringVar(&cfg.upstream, \"upstream\", \"\", \"The upstream URL to proxy to once requests have successfully been authenticated and authorized.\")\n\tflagset.BoolVar(&cfg.upstreamForceH2C, \"upstream-force-h2c\", false, \"Force h2c to communiate with the upstream. This is required when the upstream speaks h2c(http/2 cleartext - insecure variant of http/2) only. For example, go-grpc server in the insecure mode, such as helm's tiller w/o TLS, speaks h2c only\")\n\tflagset.StringVar(&configFileName, \"config-file\", \"\", \"Configuration file to configure kube-rbac-proxy.\")\n\n\t// TLS flags\n\tflagset.StringVar(&cfg.tls.certFile, \"tls-cert-file\", \"\", \"File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert)\")\n\tflagset.StringVar(&cfg.tls.keyFile, \"tls-private-key-file\", \"\", \"File containing the default x509 private key matching --tls-cert-file.\")\n\tflagset.StringVar(&cfg.tls.minVersion, \"tls-min-version\", \"VersionTLS12\", \"Minimum TLS version supported. Value must match version names from https://golang.org/pkg/crypto/tls/#pkg-constants.\")\n\tflagset.StringSliceVar(&cfg.tls.cipherSuites, \"tls-cipher-suites\", nil, \"Comma-separated list of cipher suites for the server. Values are from tls package constants (https://golang.org/pkg/crypto/tls/#pkg-constants). If omitted, the default Go cipher suites will be used\")\n\n\t// Auth flags\n\tflagset.StringVar(&cfg.auth.Authentication.X509.ClientCAFile, \"client-ca-file\", \"\", \"If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.\")\n\tflagset.BoolVar(&cfg.auth.Authentication.Header.Enabled, \"auth-header-fields-enabled\", false, \"When set to true, kube-rbac-proxy adds auth-related fields to the headers of http requests sent to the upstream\")\n\tflagset.StringVar(&cfg.auth.Authentication.Header.UserFieldName, \"auth-header-user-field-name\", \"x-remote-user\", \"The name of the field inside a http(2) request header to tell the upstream server about the user's name\")\n\tflagset.StringVar(&cfg.auth.Authentication.Header.GroupsFieldName, \"auth-header-groups-field-name\", \"x-remote-groups\", \"The name of the field inside a http(2) request header to tell the upstream server about the user's groups\")\n\tflagset.StringVar(&cfg.auth.Authentication.Header.GroupSeparator, \"auth-header-groups-field-separator\", \"|\", \"The separator string used for concatenating multiple group names in a groups header field's value\")\n\n\t//Authn OIDC flags\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.IssuerURL, \"oidc-issuer\", \"\", \"The URL of the OpenID issuer, only HTTPS scheme will be accepted. If set, it will be used to verify the OIDC JSON Web Token (JWT).\")\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.ClientID, \"oidc-clientID\", \"\", \"The client ID for the OpenID Connect client, must be set if oidc-issuer-url is set.\")\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.GroupsClaim, \"oidc-groups-claim\", \"groups\", \"Identifier of groups in JWT claim, by default set to 'groups'\")\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.UsernameClaim, \"oidc-username-claim\", \"email\", \"Identifier of the user in JWT claim, by default set to 'email'\")\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.GroupsPrefix, \"oidc-groups-prefix\", \"\", \"If provided, all groups will be prefixed with this value to prevent conflicts with other authentication strategies.\")\n\tflagset.StringArrayVar(&cfg.auth.Authentication.OIDC.SupportedSigningAlgs, \"oidc-sign-alg\", []string{\"RS256\"}, \"Supported signing algorithms, default RS256\")\n\tflagset.StringVar(&cfg.auth.Authentication.OIDC.CAFile, \"oidc-ca-file\", \"\", \"If set, the OpenID server's certificate will be verified by one of the authorities in the oidc-ca-file, otherwise the host's root CA set will be used.\")\n\n\t//Kubeconfig flag\n\tflagset.StringVar(&cfg.kubeconfigLocation, \"kubeconfig\", \"\", \"Path to a kubeconfig file, specifying how to connect to the API server. If unset, in-cluster configuration will be used\")\n\n\tflagset.Parse(os.Args[1:])\n\tkcfg := initKubeConfig(cfg.kubeconfigLocation)\n\n\tupstreamURL, err := url.Parse(cfg.upstream)\n\tif err != nil {\n\t\tglog.Fatalf(\"Failed to build parse upstream URL: %v\", err)\n\t}\n\n\tif configFileName != \"\" {\n\t\tglog.Infof(\"Reading config file: %s\", configFileName)\n\t\tb, err := ioutil.ReadFile(configFileName)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to read resource-attribute file: %v\", err)\n\t\t}\n\n\t\tconfigfile := configfile{}\n\n\t\terr = yaml.Unmarshal(b, &configfile)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to parse config file content: %v\", err)\n\t\t}\n\n\t\tcfg.auth.Authorization = configfile.AuthorizationConfig\n\t}\n\n\tkubeClient, err := kubernetes.NewForConfig(kcfg)\n\tif err != nil {\n\t\tglog.Fatalf(\"Failed to instantiate Kubernetes client: %v\", err)\n\t}\n\n\tvar authenticator authenticator.Request\n\t// If OIDC configuration provided, use oidc authenticator\n\tif cfg.auth.Authentication.OIDC.IssuerURL != \"\" {\n\t\tauthenticator, err = authn.NewOIDCAuthenticator(cfg.auth.Authentication.OIDC)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to instantiate OIDC authenticator: %v\", err)\n\t\t}\n\n\t} else {\n\t\t//Use Delegating authenticator\n\n\t\ttokenClient := kubeClient.AuthenticationV1beta1().TokenReviews()\n\t\tauthenticator, err = authn.NewDelegatingAuthenticator(tokenClient, cfg.auth.Authentication)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to instantiate delegating authenticator: %v\", err)\n\t\t}\n\n\t}\n\n\tsarClient := kubeClient.AuthorizationV1beta1().SubjectAccessReviews()\n\tauthorizer, err := authz.NewAuthorizer(sarClient)\n\n\tif err != nil {\n\t\tglog.Fatalf(\"Failed to create authorizer: %v\", err)\n\t}\n\n\tauth, err := proxy.New(kubeClient, cfg.auth, authorizer, authenticator)\n\n\tif err != nil {\n\t\tglog.Fatalf(\"Failed to create rbac-proxy: %v\", err)\n\t}\n\n\tproxy := httputil.NewSingleHostReverseProxy(upstreamURL)\n\tmux := http.NewServeMux()\n\tmux.Handle(\"/\", http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {\n\t\tok := auth.Handle(w, req)\n\t\tif !ok {\n\t\t\treturn\n\t\t}\n\n\t\tproxy.ServeHTTP(w, req)\n\t}))\n\n\tif cfg.secureListenAddress != \"\" {\n\t\tsrv := &http.Server{Handler: mux, TLSConfig: &tls.Config{}}\n\n\t\tif cfg.tls.certFile == \"\" && cfg.tls.keyFile == \"\" {\n\t\t\tglog.Info(\"Generating self signed cert as no cert is provided\")\n\t\t\tcertBytes, keyBytes, err := certutil.GenerateSelfSignedCertKey(\"\", nil, nil)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatalf(\"Failed to generate self signed cert and key: %v\", err)\n\t\t\t}\n\t\t\tcert, err := tls.X509KeyPair(certBytes, keyBytes)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatalf(\"Failed to load generated self signed cert and key: %v\", err)\n\t\t\t}\n\n\t\t\tsrv.TLSConfig.Certificates = []tls.Certificate{cert}\n\t\t}\n\n\t\tversion, err := tlsVersion(cfg.tls.minVersion)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"TLS version invalid: %v\", err)\n\t\t}\n\n\t\tcipherSuiteIDs, err := k8sapiflag.TLSCipherSuites(cfg.tls.cipherSuites)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to convert TLS cipher suite name to ID: %v\", err)\n\t\t}\n\n\t\tsrv.TLSConfig.CipherSuites = cipherSuiteIDs\n\t\tsrv.TLSConfig.MinVersion = version\n\t\tsrv.TLSConfig.NextProtos = []string{\"h2\"}\n\n\t\tglog.Infof(\"Starting TCP socket on %v\", cfg.secureListenAddress)\n\n\t\tl, err := net.Listen(\"tcp\", cfg.secureListenAddress)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to listen on secure address: %v\", err)\n\t\t}\n\t\tglog.Infof(\"Listening securely on %v\", cfg.secureListenAddress)\n\t\tgo func() {\n\t\t\terr := srv.ServeTLS(l, cfg.tls.certFile, cfg.tls.keyFile)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatalf(\"failed to serve TLS server: %v\", err)\n\t\t\t}\n\t\t}()\n\t}\n\n\tif cfg.insecureListenAddress != \"\" {\n\t\tif cfg.upstreamForceH2C {\n\t\t\t// Force http/2 for connections to the upstream i.e. do not start with HTTP1.1 UPGRADE req to\n\t\t\t// initialize http/2 session.\n\t\t\t// See https://github.com/golang/go/issues/14141#issuecomment-219212895 for more context\n\t\t\tproxy.Transport = &http2.Transport{\n\t\t\t\t// Allow http schema. This doesn't automatically disable TLS\n\t\t\t\tAllowHTTP: true,\n\t\t\t\t// Do disable TLS.\n\t\t\t\t// In combination with the schema check above. We could enforce h2c against the upstream server\n\t\t\t\tDialTLS: func(netw, addr string, cfg *tls.Config) (net.Conn, error) {\n\t\t\t\t\treturn net.Dial(netw, addr)\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\n\t\t// Background:\n\t\t//\n\t\t// golang's http2 server doesn't support h2c\n\t\t// https://github.com/golang/go/issues/16696\n\t\t//\n\t\t//\n\t\t// Action:\n\t\t//\n\t\t// Use hkwi/h2c so that you can properly handle HTTP Upgrade requests over plain TCP,\n\t\t// which is one of consequences for a h2c support.\n\t\t//\n\t\t// See https://github.com/golang/go/issues/14141 for more context.\n\t\t//\n\t\t// Possible alternative:\n\t\t//\n\t\t// We could potentially use grpc-go server's HTTP handler support\n\t\t// which would handle HTTP UPGRADE from http1.1 to http/2, especially in case\n\t\t// what you wanted kube-rbac-proxy to authn/authz was gRPC over h2c calls.\n\t\t//\n\t\t// Note that golang's http server requires a client(including gRPC) to send HTTP Upgrade req to\n\t\t// property start http/2.\n\t\t//\n\t\t// but it isn't straight-forward to understand.\n\t\t// Also note that at time of writing this, grpc-go's server implementation still lacks\n\t\t// a h2c support for communication against the upstream.\n\t\t//\n\t\t// See belows for more information:\n\t\t// - https://github.com/grpc/grpc-go/pull/1406/files\n\t\t// - https://github.com/grpc/grpc-go/issues/549#issuecomment-191458335\n\t\t// - https://github.com/golang/go/issues/14141#issuecomment-176465220\n\t\th2cHandler := &h2c.Server{Handler: mux}\n\n\t\tsrv := &http.Server{Handler: h2cHandler}\n\n\t\tl, err := net.Listen(\"tcp\", cfg.insecureListenAddress)\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"Failed to listen on insecure address: %v\", err)\n\t\t}\n\t\tglog.Infof(\"Listening insecurely on %v\", cfg.insecureListenAddress)\n\t\tgo func() {\n\t\t\terr := srv.Serve(l)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatalf(\"failed to serve server: %v\", err)\n\t\t\t}\n\t\t}()\n\t}\n\n\tterm := make(chan os.Signal, 1)\n\tsignal.Notify(term, os.Interrupt, syscall.SIGTERM)\n\n\tselect {\n\tcase <-term:\n\t\tglog.Info(\"Received SIGTERM, exiting gracefully...\")\n\t}\n}", "is_vulnerable": 0}
{"code": "\tcidr := func(s string) *net.IPNet {\n\t\t_, n, _ := net.ParseCIDR(s)\n\t\treturn n\n\t}\n\n\tflagSrc := []string{`-dev`}\n\tsrc := map[string]string{\n\t\t\"json\": `{\n\t\t\t\"acl_agent_master_token\": \"furuQD0b\",\n\t\t\t\"acl_agent_token\": \"cOshLOQ2\",\n\t\t\t\"acl_datacenter\": \"m3urck3z\",\n\t\t\t\"acl_default_policy\": \"ArK3WIfE\",\n\t\t\t\"acl_down_policy\": \"vZXMfMP0\",\n\t\t\t\"acl_enforce_version_8\": true,\n\t\t\t\"acl_enable_key_list_policy\": true,\n\t\t\t\"acl_master_token\": \"C1Q1oIwh\",\n\t\t\t\"acl_replication_token\": \"LMmgy5dO\",\n\t\t\t\"acl_token\": \"O1El0wan\",\n\t\t\t\"acl_ttl\": \"18060s\",\n\t\t\t\"acl\" : {\n\t\t\t\t\"enabled\" : true,\n\t\t\t\t\"down_policy\" : \"03eb2aee\",\n\t\t\t\t\"default_policy\" : \"72c2e7a0\",\n\t\t\t\t\"enable_key_list_policy\": true,\n\t\t\t\t\"enable_token_persistence\": true,\n\t\t\t\t\"policy_ttl\": \"1123s\",\n\t\t\t\t\"role_ttl\": \"9876s\",\n\t\t\t\t\"token_ttl\": \"3321s\",\n\t\t\t\t\"enable_token_replication\" : true,\n\t\t\t\t\"tokens\" : {\n\t\t\t\t\t\"master\" : \"8a19ac27\",\n\t\t\t\t\t\"agent_master\" : \"64fd0e08\",\n\t\t\t\t\t\"replication\" : \"5795983a\",\n\t\t\t\t\t\"agent\" : \"bed2377c\",\n\t\t\t\t\t\"default\" : \"418fdff1\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"addresses\": {\n\t\t\t\t\"dns\": \"93.95.95.81\",\n\t\t\t\t\"http\": \"83.39.91.39\",\n\t\t\t\t\"https\": \"95.17.17.19\",\n\t\t\t\t\"grpc\": \"32.31.61.91\"\n\t\t\t},\n\t\t\t\"advertise_addr\": \"17.99.29.16\",\n\t\t\t\"advertise_addr_wan\": \"78.63.37.19\",\n\t\t\t\"autopilot\": {\n\t\t\t\t\"cleanup_dead_servers\": true,\n\t\t\t\t\"disable_upgrade_migration\": true,\n\t\t\t\t\"last_contact_threshold\": \"12705s\",\n\t\t\t\t\"max_trailing_logs\": 17849,\n\t\t\t\t\"min_quorum\":\t\t 3,\n\t\t\t\t\"redundancy_zone_tag\": \"3IsufDJf\",\n\t\t\t\t\"server_stabilization_time\": \"23057s\",\n\t\t\t\t\"upgrade_version_tag\": \"W9pDwFAL\"\n\t\t\t},\n\t\t\t\"bind_addr\": \"16.99.34.17\",\n\t\t\t\"bootstrap\": true,\n\t\t\t\"bootstrap_expect\": 53,\n\t\t\t\"ca_file\": \"erA7T0PM\",\n\t\t\t\"ca_path\": \"mQEN1Mfp\",\n\t\t\t\"cert_file\": \"7s4QAzDk\",\n\t\t\t\"check\": {\n\t\t\t\t\"id\": \"fZaCAXww\",\n\t\t\t\t\"name\": \"OOM2eo0f\",\n\t\t\t\t\"notes\": \"zXzXI9Gt\",\n\t\t\t\t\"service_id\": \"L8G0QNmR\",\n\t\t\t\t\"token\": \"oo4BCTgJ\",\n\t\t\t\t\"status\": \"qLykAl5u\",\n\t\t\t\t\"args\": [\"f3BemRjy\", \"e5zgpef7\"],\n\t\t\t\t\"http\": \"29B93haH\",\n\t\t\t\t\"header\": {\n\t\t\t\t\t\"hBq0zn1q\": [ \"2a9o9ZKP\", \"vKwA5lR6\" ],\n\t\t\t\t\t\"f3r6xFtM\": [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t},\n\t\t\t\t\"method\": \"Dou0nGT5\",\n\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\"tcp\": \"JY6fTTcw\",\n\t\t\t\t\"interval\": \"18714s\",\n\t\t\t\t\"docker_container_id\": \"qF66POS9\",\n\t\t\t\t\"shell\": \"sOnDy228\",\n\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\"timeout\": \"5954s\",\n\t\t\t\t\"ttl\": \"30044s\",\n\t\t\t\t\"deregister_critical_service_after\": \"13209s\"\n\t\t\t},\n\t\t\t\"checks\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"uAjE6m9Z\",\n\t\t\t\t\t\"name\": \"QsZRGpYr\",\n\t\t\t\t\t\"notes\": \"VJ7Sk4BY\",\n\t\t\t\t\t\"service_id\": \"lSulPcyz\",\n\t\t\t\t\t\"token\": \"toO59sh8\",\n\t\t\t\t\t\"status\": \"9RlWsXMV\",\n\t\t\t\t\t\"args\": [\"4BAJttck\", \"4D2NPtTQ\"],\n\t\t\t\t\t\"http\": \"dohLcyQ2\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"ZBfTin3L\": [ \"1sDbEqYG\", \"lJGASsWK\" ],\n\t\t\t\t\t\t\"Ui0nU99X\": [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"aldrIQ4l\",\n\t\t\t\t\t\"tcp\": \"RJQND605\",\n\t\t\t\t\t\"interval\": \"22164s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\"shell\": \"qAeOYy0M\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"1813s\",\n\t\t\t\t\t\"ttl\": \"21743s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Cqq95BhP\",\n\t\t\t\t\t\"name\": \"3qXpkS0i\",\n\t\t\t\t\t\"notes\": \"sb5qLTex\",\n\t\t\t\t\t\"service_id\": \"CmUUcRna\",\n\t\t\t\t\t\"token\": \"a3nQzHuy\",\n\t\t\t\t\t\"status\": \"irj26nf3\",\n\t\t\t\t\t\"args\": [\"9s526ogY\", \"gSlOHj1w\"],\n\t\t\t\t\t\"http\": \"yzhgsQ7Y\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"zcqwA8dO\": [ \"qb1zx0DL\", \"sXCxPFsD\" ],\n\t\t\t\t\t\t\"qxvdnSE9\": [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"gLrztrNw\",\n\t\t\t\t\t\"tcp\": \"4jG5casb\",\n\t\t\t\t\t\"interval\": \"28767s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"THW6u7rL\",\n\t\t\t\t\t\"shell\": \"C1Zt3Zwh\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"18506s\",\n\t\t\t\t\t\"ttl\": \"31006s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"2366s\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"check_update_interval\": \"16507s\",\n\t\t\t\"client_addr\": \"93.83.18.19\",\n\t\t\t\"config_entries\": {\n\t\t\t\t\"bootstrap\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"kind\": \"proxy-defaults\",\n\t\t\t\t\t\t\"name\": \"global\",\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t\t\t\"bar\": 1.0\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t]\n                        },\n\t\t\t\"auto_encrypt\": {\n\t\t\t\t\"tls\": true,\n\t\t\t\t\"dns_san\": [\"a.com\", \"b.com\"],\n\t\t\t\t\"ip_san\": [\"192.168.4.139\", \"192.168.4.140\"],\n\t\t\t\t\"allow_tls\": true\n\t\t\t},\n\t\t\t\"connect\": {\n\t\t\t\t\"ca_provider\": \"consul\",\n\t\t\t\t\"ca_config\": {\n\t\t\t\t\t\"rotation_period\": \"90h\",\n\t\t\t\t\t\"intermediate_cert_ttl\": \"8760h\",\n\t\t\t\t\t\"leaf_cert_ttl\": \"1h\",\n\t\t\t\t\t\"csr_max_per_second\": 100,\n\t\t\t\t\t\"csr_max_concurrent\": 2\n\t\t\t\t},\n\t\t\t\t\"enabled\": true\n\t\t\t},\n\t\t\t\"gossip_lan\" : {\n\t\t\t\t\"gossip_nodes\": 6,\n\t\t\t\t\"gossip_interval\" : \"25252s\",\n\t\t\t\t\"retransmit_mult\" : 1234,\n\t\t\t\t\"suspicion_mult\"  : 1235,\n\t\t\t\t\"probe_interval\"  : \"101ms\",\n\t\t\t\t\"probe_timeout\"   : \"102ms\"\n\t\t\t},\n\t\t\t\"gossip_wan\" : {\n\t\t\t\t\"gossip_nodes\" : 2,\n\t\t\t\t\"gossip_interval\" : \"6966s\",\n\t\t\t\t\"retransmit_mult\" : 16384,\n\t\t\t\t\"suspicion_mult\"  : 16385,\n\t\t\t\t\"probe_interval\" : \"103ms\",\n\t\t\t\t\"probe_timeout\"  : \"104ms\"\n\t\t\t},\n\t\t\t\"data_dir\": \"` + dataDir + `\",\n\t\t\t\"datacenter\": \"rzo029wg\",\n\t\t\t\"default_query_time\": \"16743s\",\n\t\t\t\"disable_anonymous_signature\": true,\n\t\t\t\"disable_coordinates\": true,\n\t\t\t\"disable_host_node_id\": true,\n\t\t\t\"disable_http_unprintable_char_filter\": true,\n\t\t\t\"disable_keyring_file\": true,\n\t\t\t\"disable_remote_exec\": true,\n\t\t\t\"disable_update_check\": true,\n\t\t\t\"discard_check_output\": true,\n\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\"domain\": \"7W1xXSqd\",\n\t\t\t\"alt_domain\": \"1789hsd\",\n\t\t\t\"dns_config\": {\n\t\t\t\t\"allow_stale\": true,\n\t\t\t\t\"a_record_limit\": 29907,\n\t\t\t\t\"disable_compression\": true,\n\t\t\t\t\"enable_truncate\": true,\n\t\t\t\t\"max_stale\": \"29685s\",\n\t\t\t\t\"node_ttl\": \"7084s\",\n\t\t\t\t\"only_passing\": true,\n\t\t\t\t\"recursor_timeout\": \"4427s\",\n\t\t\t\t\"service_ttl\": {\n\t\t\t\t\t\"*\": \"32030s\"\n\t\t\t\t},\n\t\t\t\t\"udp_answer_limit\": 29909,\n\t\t\t\t\"use_cache\": true,\n\t\t\t\t\"cache_max_age\": \"5m\"` + entFullDNSJSONConfig + `\n\t\t\t},\n\t\t\t\"enable_acl_replication\": true,\n\t\t\t\"enable_agent_tls_for_checks\": true,\n\t\t\t\"enable_central_service_config\": true,\n\t\t\t\"enable_debug\": true,\n\t\t\t\"enable_script_checks\": true,\n\t\t\t\"enable_local_script_checks\": true,\n\t\t\t\"enable_syslog\": true,\n\t\t\t\"encrypt\": \"A4wELWqH\",\n\t\t\t\"encrypt_verify_incoming\": true,\n\t\t\t\"encrypt_verify_outgoing\": true,\n\t\t\t\"http_config\": {\n\t\t\t\t\"block_endpoints\": [ \"RBvAFcGD\", \"fWOWFznh\" ],\n\t\t\t\t\"allow_write_http_from\": [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ],\n\t\t\t\t\"response_headers\": {\n\t\t\t\t\t\"M6TKa9NP\": \"xjuxjOzQ\",\n\t\t\t\t\t\"JRCrHZed\": \"rl0mTx81\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"key_file\": \"IEkkwgIA\",\n\t\t\t\"leave_on_terminate\": true,\n\t\t\t\"limits\": {\n\t\t\t\t\"http_max_conns_per_client\": 9283,\n\t\t\t\t\"https_handshake_timeout\": \"2391ms\",\n\t\t\t\t\"rpc_handshake_timeout\": \"1932ms\",\n\t\t\t\t\"rpc_rate\": 12029.43,\n\t\t\t\t\"rpc_max_burst\": 44848,\n\t\t\t\t\"rpc_max_conns_per_client\": 2954,\n\t\t\t\t\"kv_max_value_size\": 1234567800000000\n\t\t\t},\n\t\t\t\"log_level\": \"k1zo9Spt\",\n\t\t\t\"log_json\": true,\n\t\t\t\"max_query_time\": \"18237s\",\n\t\t\t\"node_id\": \"AsUIlw99\",\n\t\t\t\"node_meta\": {\n\t\t\t\t\"5mgGQMBk\": \"mJLtVMSG\",\n\t\t\t\t\"A7ynFMJB\": \"0Nx6RGab\"\n\t\t\t},\n\t\t\t\"node_name\": \"otlLxGaI\",\n\t\t\t\"non_voting_server\": true,\n\t\t\t\"performance\": {\n\t\t\t\t\"leave_drain_time\": \"8265s\",\n\t\t\t\t\"raft_multiplier\": 5,\n\t\t\t\t\"rpc_hold_timeout\": \"15707s\"\n\t\t\t},\n\t\t\t\"pid_file\": \"43xN80Km\",\n\t\t\t\"ports\": {\n\t\t\t\t\"dns\": 7001,\n\t\t\t\t\"http\": 7999,\n\t\t\t\t\"https\": 15127,\n\t\t\t\t\"server\": 3757,\n\t\t\t\t\"grpc\": 4881,\n\t\t\t\t\"sidecar_min_port\": 8888,\n\t\t\t\t\"sidecar_max_port\": 9999,\n\t\t\t\t\"expose_min_port\": 1111,\n\t\t\t\t\"expose_max_port\": 2222\n\t\t\t},\n\t\t\t\"protocol\": 30793,\n\t\t\t\"primary_datacenter\": \"ejtmd43d\",\n\t\t\t\"raft_protocol\": 19016,\n\t\t\t\"raft_snapshot_threshold\": 16384,\n\t\t\t\"raft_snapshot_interval\": \"30s\",\n\t\t\t\"raft_trailing_logs\": 83749,\n\t\t\t\"reconnect_timeout\": \"23739s\",\n\t\t\t\"reconnect_timeout_wan\": \"26694s\",\n\t\t\t\"recursors\": [ \"63.38.39.58\", \"92.49.18.18\" ],\n\t\t\t\"rejoin_after_leave\": true,\n\t\t\t\"retry_interval\": \"8067s\",\n\t\t\t\"retry_interval_wan\": \"28866s\",\n\t\t\t\"retry_join\": [ \"pbsSFY7U\", \"l0qLtWij\" ],\n\t\t\t\"retry_join_wan\": [ \"PFsR02Ye\", \"rJdQIhER\" ],\n\t\t\t\"retry_max\": 913,\n\t\t\t\"retry_max_wan\": 23160,\n\t\t\t\"segment\": \"BC2NhTDi\",\n\t\t\t\"segments\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"PExYMe2E\",\n\t\t\t\t\t\"bind\": \"36.73.36.19\",\n\t\t\t\t\t\"port\": 38295,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"UzCvJgup\",\n\t\t\t\t\t\"bind\": \"37.58.38.19\",\n\t\t\t\t\t\"port\": 39292,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"serf_lan\": \"99.43.63.15\",\n\t\t\t\"serf_wan\": \"67.88.33.19\",\n\t\t\t\"server\": true,\n\t\t\t\"server_name\": \"Oerr9n1G\",\n\t\t\t\"service\": {\n\t\t\t\t\"id\": \"dLOXpSCI\",\n\t\t\t\t\"name\": \"o1ynPkp0\",\n\t\t\t\t\"meta\": {\n\t\t\t\t\t\"mymeta\": \"data\"\n\t\t\t\t},\n\t\t\t\t\"tagged_addresses\": {\n\t\t\t\t\t\"lan\": {\n\t\t\t\t\t\t\"address\": \"2d79888a\",\n\t\t\t\t\t\t\"port\": 2143\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": {\n\t\t\t\t\t\t\"address\": \"d4db85e2\",\n\t\t\t\t\t\t\"port\": 6109\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"tags\": [\"nkwshvM5\", \"NTDWn3ek\"],\n\t\t\t\t\"address\": \"cOlSOhbp\",\n\t\t\t\t\"token\": \"msy7iWER\",\n\t\t\t\t\"port\": 24237,\n\t\t\t\t\"weights\": {\n\t\t\t\t\t\"passing\": 100,\n\t\t\t\t\t\"warning\": 1\n\t\t\t\t},\n\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\"check\": {\n\t\t\t\t\t\"id\": \"RMi85Dv8\",\n\t\t\t\t\t\"name\": \"iehanzuq\",\n\t\t\t\t\t\"status\": \"rCvn53TH\",\n\t\t\t\t\t\"notes\": \"fti5lfF3\",\n\t\t\t\t\t\"args\": [\"16WRUmwS\", \"QWk7j7ae\"],\n\t\t\t\t\t\"http\": \"dl3Fgme3\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"rjm4DEd3\": [\"2m3m2Fls\"],\n\t\t\t\t\t\t\"l4HwQ112\": [\"fk56MNlo\", \"dhLK56aZ\"]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"9afLm3Mj\",\n\t\t\t\t\t\"tcp\": \"fjiLFqVd\",\n\t\t\t\t\t\"interval\": \"23926s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"dO5TtRHk\",\n\t\t\t\t\t\"shell\": \"e6q2ttES\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"38483s\",\n\t\t\t\t\t\"ttl\": \"10943s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"68787s\"\n\t\t\t\t},\n\t\t\t\t\"checks\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"Zv99e9Ka\",\n\t\t\t\t\t\t\"name\": \"sgV4F7Pk\",\n\t\t\t\t\t\t\"notes\": \"yP5nKbW0\",\n\t\t\t\t\t\t\"status\": \"7oLMEyfu\",\n\t\t\t\t\t\t\"args\": [\"5wEZtZpv\", \"0Ihyk8cS\"],\n\t\t\t\t\t\t\"http\": \"KyDjGY9H\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"gv5qefTz\": [ \"5Olo2pMG\", \"PvvKWQU5\" ],\n\t\t\t\t\t\t\t\"SHOVq1Vv\": [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"T66MFBfR\",\n\t\t\t\t\t\t\"tcp\": \"bNnNfx2A\",\n\t\t\t\t\t\t\"interval\": \"22224s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\t\"shell\": \"omVZq7Sz\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"18913s\",\n\t\t\t\t\t\t\"ttl\": \"44743s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"G79O6Mpr\",\n\t\t\t\t\t\t\"name\": \"IEqrzrsd\",\n\t\t\t\t\t\t\"notes\": \"SVqApqeM\",\n\t\t\t\t\t\t\"status\": \"XXkVoZXt\",\n\t\t\t\t\t\t\"args\": [\"wD05Bvao\", \"rLYB7kQC\"],\n\t\t\t\t\t\t\"http\": \"kyICZsn8\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"4ebP5vL4\": [ \"G20SrL5Q\", \"DwPKlMbo\" ],\n\t\t\t\t\t\t\t\"p2UI34Qz\": [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"ciYHWors\",\n\t\t\t\t\t\t\"tcp\": \"FfvCwlqH\",\n\t\t\t\t\t\t\"interval\": \"12356s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"HBndBU6R\",\n\t\t\t\t\t\t\"shell\": \"hVI33JjA\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38282s\",\n\t\t\t\t\t\t\"ttl\": \"1181s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"connect\": {\n\t\t\t\t\t\"native\": true\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"services\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"wI1dzxS4\",\n\t\t\t\t\t\"name\": \"7IszXMQ1\",\n\t\t\t\t\t\"tags\": [\"0Zwg8l6v\", \"zebELdN5\"],\n\t\t\t\t\t\"address\": \"9RhqPSPB\",\n\t\t\t\t\t\"token\": \"myjKJkWH\",\n\t\t\t\t\t\"port\": 72219,\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"check\": {\n\t\t\t\t\t\t\"id\": \"qmfeO5if\",\n\t\t\t\t\t\t\"name\": \"atDGP7n5\",\n\t\t\t\t\t\t\"status\": \"pDQKEhWL\",\n\t\t\t\t\t\t\"notes\": \"Yt8EDLev\",\n\t\t\t\t\t\t\"args\": [\"81EDZLPa\", \"bPY5X8xd\"],\n\t\t\t\t\t\t\"http\": \"qzHYvmJO\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"UkpmZ3a3\": [\"2dfzXuxZ\"],\n\t\t\t\t\t\t\t\"cVFpko4u\": [\"gGqdEB6k\", \"9LsRo22u\"]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"X5DrovFc\",\n\t\t\t\t\t\t\"tcp\": \"ICbxkpSF\",\n\t\t\t\t\t\t\"interval\": \"24392s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ZKXr68Yb\",\n\t\t\t\t\t\t\"shell\": \"CEfzx0Fo\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38333s\",\n\t\t\t\t\t\t\"ttl\": \"57201s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"44214s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"connect\": {\n\t\t\t\t\t\t\"sidecar_service\": {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"MRHVMZuD\",\n\t\t\t\t\t\"name\": \"6L6BVfgH\",\n\t\t\t\t\t\"tags\": [\"7Ale4y6o\", \"PMBW08hy\"],\n\t\t\t\t\t\"address\": \"R6H6g8h0\",\n\t\t\t\t\t\"token\": \"ZgY8gjMI\",\n\t\t\t\t\t\"port\": 38292,\n\t\t\t\t\t\"weights\": {\n\t\t\t\t\t\t\"passing\": 1979,\n\t\t\t\t\t\t\"warning\": 6\n\t\t\t\t\t},\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"checks\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"GTti9hCo\",\n\t\t\t\t\t\t\t\"name\": \"9OOS93ne\",\n\t\t\t\t\t\t\t\"notes\": \"CQy86DH0\",\n\t\t\t\t\t\t\t\"status\": \"P0SWDvrk\",\n\t\t\t\t\t\t\t\"args\": [\"EXvkYIuG\", \"BATOyt6h\"],\n\t\t\t\t\t\t\t\"http\": \"u97ByEiW\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"MUlReo8L\": [ \"AUZG7wHG\", \"gsN0Dc2N\" ],\n\t\t\t\t\t\t\t\t\"1UJXjVrT\": [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"5wkAxCUE\",\n\t\t\t\t\t\t\t\"tcp\": \"MN3oA9D2\",\n\t\t\t\t\t\t\t\"interval\": \"32718s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"cU15LMet\",\n\t\t\t\t\t\t\t\"shell\": \"nEz9qz2l\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"34738s\",\n\t\t\t\t\t\t\t\"ttl\": \"22773s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"UHsDeLxG\",\n\t\t\t\t\t\t\t\"name\": \"PQSaPWlT\",\n\t\t\t\t\t\t\t\"notes\": \"jKChDOdl\",\n\t\t\t\t\t\t\t\"status\": \"5qFz6OZn\",\n\t\t\t\t\t\t\t\"args\": [\"NMtYWlT9\", \"vj74JXsm\"],\n\t\t\t\t\t\t\t\"http\": \"1LBDJhw4\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\": [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\": [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"wzByP903\",\n\t\t\t\t\t\t\t\"tcp\": \"2exjZIGE\",\n\t\t\t\t\t\t\t\"interval\": \"5656s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"5tDBWpfA\",\n\t\t\t\t\t\t\t\"shell\": \"rlTpLM8s\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"4868s\",\n\t\t\t\t\t\t\t\"ttl\": \"11222s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"connect\": {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Kh81CPF6\",\n\t\t\t\t\t\"kind\": \"connect-proxy\",\n\t\t\t\t\t\"name\": \"Kh81CPF6-proxy\",\n\t\t\t\t\t\"port\": 31471,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"destination_service_id\": \"6L6BVfgH-id\",\n\t\t\t\t\t\t\"destination_service_name\": \"6L6BVfgH\",\n\t\t\t\t\t\t\"local_service_address\": \"127.0.0.2\",\n\t\t\t\t\t\t\"local_service_port\": 23759,\n\t\t\t\t\t\t\"expose\": {\n\t\t\t\t\t\t\t\"checks\": true,\n\t\t\t\t\t\t\t\"paths\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"path\": \"/health\",\n\t\t\t\t\t\t\t\t\t\"local_path_port\": 8080,\n\t\t\t\t\t\t\t\t\t\"listener_port\": 21500,\n\t\t\t\t\t\t\t\t\t\"protocol\": \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"upstreams\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KPtAj2cb\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 4051,\n\t\t\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KSd8HsRl\",\n\t\t\t\t\t\t\t\t\"destination_namespace\": \"9nakw0td\",\n\t\t\t\t\t\t\t\t\"destination_type\": \"prepared_query\",\n\t\t\t\t\t\t\t\t\"local_bind_address\": \"127.24.88.0\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 11884\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"kvVqbwSE\",\n\t\t\t\t\t\"kind\": \"mesh-gateway\",\n\t\t\t\t\t\"name\": \"gw-primary-dc\",\n\t\t\t\t\t\"port\": 27147,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"1CuJHVfw\" : \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"session_ttl_min\": \"26627s\",\n\t\t\t\"skip_leave_on_interrupt\": true,\n\t\t\t\"start_join\": [ \"LR3hGDoG\", \"MwVpZ4Up\" ],\n\t\t\t\"start_join_wan\": [ \"EbFSc3nA\", \"kwXTh623\" ],\n\t\t\t\"syslog_facility\": \"hHv79Uia\",\n\t\t\t\"tagged_addresses\": {\n\t\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\"\n\t\t\t},\n\t\t\t\"telemetry\": {\n\t\t\t\t\"circonus_api_app\": \"p4QOTe9j\",\n\t\t\t\t\"circonus_api_token\": \"E3j35V23\",\n\t\t\t\t\"circonus_api_url\": \"mEMjHpGg\",\n\t\t\t\t\"circonus_broker_id\": \"BHlxUhed\",\n\t\t\t\t\"circonus_broker_select_tag\": \"13xy1gHm\",\n\t\t\t\t\"circonus_check_display_name\": \"DRSlQR6n\",\n\t\t\t\t\"circonus_check_force_metric_activation\": \"Ua5FGVYf\",\n\t\t\t\t\"circonus_check_id\": \"kGorutad\",\n\t\t\t\t\"circonus_check_instance_id\": \"rwoOL6R4\",\n\t\t\t\t\"circonus_check_search_tag\": \"ovT4hT4f\",\n\t\t\t\t\"circonus_check_tags\": \"prvO4uBl\",\n\t\t\t\t\"circonus_submission_interval\": \"DolzaflP\",\n\t\t\t\t\"circonus_submission_url\": \"gTcbS93G\",\n\t\t\t\t\"disable_hostname\": true,\n\t\t\t\t\"dogstatsd_addr\": \"0wSndumK\",\n\t\t\t\t\"dogstatsd_tags\": [ \"3N81zSUB\",\"Xtj8AnXZ\" ],\n\t\t\t\t\"filter_default\": true,\n\t\t\t\t\"prefix_filter\": [ \"+oJotS8XJ\",\"-cazlEhGn\" ],\n\t\t\t\t\"metrics_prefix\": \"ftO6DySn\",\n\t\t\t\t\"prometheus_retention_time\": \"15s\",\n\t\t\t\t\"statsd_address\": \"drce87cy\",\n\t\t\t\t\"statsite_address\": \"HpFwKB8R\"\n\t\t\t},\n\t\t\t\"tls_cipher_suites\": \"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\t\"tls_min_version\": \"pAOWafkR\",\n\t\t\t\"tls_prefer_server_cipher_suites\": true,\n\t\t\t\"translate_wan_addrs\": true,\n\t\t\t\"ui\": true,\n\t\t\t\"ui_dir\": \"11IFzAUn\",\n\t\t\t\"ui_content_path\": \"consul\",\n\t\t\t\"unix_sockets\": {\n\t\t\t\t\"group\": \"8pFodrV8\",\n\t\t\t\t\"mode\": \"E8sAwOv4\",\n\t\t\t\t\"user\": \"E0nB1DwA\"\n\t\t\t},\n\t\t\t\"verify_incoming\": true,\n\t\t\t\"verify_incoming_https\": true,\n\t\t\t\"verify_incoming_rpc\": true,\n\t\t\t\"verify_outgoing\": true,\n\t\t\t\"verify_server_hostname\": true,\n\t\t\t\"watches\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"key\",\n\t\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\t\"key\": \"j9lF1Tve\",\n\t\t\t\t\t\"handler\": \"90N7S4LN\"\n\t\t\t\t}, {\n\t\t\t\t\t\"type\": \"keyprefix\",\n\t\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\t\"key\": \"sl3Dffu7\",\n\t\t\t\t\t\"args\": [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t\t}\n\t\t\t]\n\t\t}`,\n\t\t\"hcl\": `\n\t\t\tacl_agent_master_token = \"furuQD0b\"\n\t\t\tacl_agent_token = \"cOshLOQ2\"\n\t\t\tacl_datacenter = \"m3urck3z\"\n\t\t\tacl_default_policy = \"ArK3WIfE\"\n\t\t\tacl_down_policy = \"vZXMfMP0\"\n\t\t\tacl_enforce_version_8 = true\n\t\t\tacl_enable_key_list_policy = true\n\t\t\tacl_master_token = \"C1Q1oIwh\"\n\t\t\tacl_replication_token = \"LMmgy5dO\"\n\t\t\tacl_token = \"O1El0wan\"\n\t\t\tacl_ttl = \"18060s\"\n\t\t\tacl = {\n\t\t\t\tenabled = true\n\t\t\t\tdown_policy = \"03eb2aee\"\n\t\t\t\tdefault_policy = \"72c2e7a0\"\n\t\t\t\tenable_key_list_policy = true\n\t\t\t\tenable_token_persistence = true\n\t\t\t\tpolicy_ttl = \"1123s\"\n\t\t\t\trole_ttl = \"9876s\"\n\t\t\t\ttoken_ttl = \"3321s\"\n\t\t\t\tenable_token_replication = true\n\t\t\t\ttokens = {\n\t\t\t\t\tmaster = \"8a19ac27\",\n\t\t\t\t\tagent_master = \"64fd0e08\",\n\t\t\t\t\treplication = \"5795983a\",\n\t\t\t\t\tagent = \"bed2377c\",\n\t\t\t\t\tdefault = \"418fdff1\"\n\t\t\t\t}\n\t\t\t}\n\t\t\taddresses = {\n\t\t\t\tdns = \"93.95.95.81\"\n\t\t\t\thttp = \"83.39.91.39\"\n\t\t\t\thttps = \"95.17.17.19\"\n\t\t\t\tgrpc = \"32.31.61.91\"\n\t\t\t}\n\t\t\tadvertise_addr = \"17.99.29.16\"\n\t\t\tadvertise_addr_wan = \"78.63.37.19\"\n\t\t\tautopilot = {\n\t\t\t\tcleanup_dead_servers = true\n\t\t\t\tdisable_upgrade_migration = true\n\t\t\t\tlast_contact_threshold = \"12705s\"\n\t\t\t\tmax_trailing_logs = 17849\n\t\t\t\tmin_quorum = 3\n\t\t\t\tredundancy_zone_tag = \"3IsufDJf\"\n\t\t\t\tserver_stabilization_time = \"23057s\"\n\t\t\t\tupgrade_version_tag = \"W9pDwFAL\"\n\t\t\t}\n\t\t\tbind_addr = \"16.99.34.17\"\n\t\t\tbootstrap = true\n\t\t\tbootstrap_expect = 53\n\t\t\tca_file = \"erA7T0PM\"\n\t\t\tca_path = \"mQEN1Mfp\"\n\t\t\tcert_file = \"7s4QAzDk\"\n\t\t\tcheck = {\n\t\t\t\tid = \"fZaCAXww\"\n\t\t\t\tname = \"OOM2eo0f\"\n\t\t\t\tnotes = \"zXzXI9Gt\"\n\t\t\t\tservice_id = \"L8G0QNmR\"\n\t\t\t\ttoken = \"oo4BCTgJ\"\n\t\t\t\tstatus = \"qLykAl5u\"\n\t\t\t\targs = [\"f3BemRjy\", \"e5zgpef7\"]\n\t\t\t\thttp = \"29B93haH\"\n\t\t\t\theader = {\n\t\t\t\t\thBq0zn1q = [ \"2a9o9ZKP\", \"vKwA5lR6\" ]\n\t\t\t\t\tf3r6xFtM = [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t}\n\t\t\t\tmethod = \"Dou0nGT5\"\n\t\t\t\ttcp = \"JY6fTTcw\"\n\t\t\t\tinterval = \"18714s\"\n\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\tdocker_container_id = \"qF66POS9\"\n\t\t\t\tshell = \"sOnDy228\"\n\t\t\t\ttls_skip_verify = true\n\t\t\t\ttimeout = \"5954s\"\n\t\t\t\tttl = \"30044s\"\n\t\t\t\tderegister_critical_service_after = \"13209s\"\n\t\t\t},\n\t\t\tchecks = [\n\t\t\t\t{\n\t\t\t\t\tid = \"uAjE6m9Z\"\n\t\t\t\t\tname = \"QsZRGpYr\"\n\t\t\t\t\tnotes = \"VJ7Sk4BY\"\n\t\t\t\t\tservice_id = \"lSulPcyz\"\n\t\t\t\t\ttoken = \"toO59sh8\"\n\t\t\t\t\tstatus = \"9RlWsXMV\"\n\t\t\t\t\targs = [\"4BAJttck\", \"4D2NPtTQ\"]\n\t\t\t\t\thttp = \"dohLcyQ2\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"ZBfTin3L\" = [ \"1sDbEqYG\", \"lJGASsWK\" ]\n\t\t\t\t\t\t\"Ui0nU99X\" = [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"aldrIQ4l\"\n\t\t\t\t\ttcp = \"RJQND605\"\n\t\t\t\t\tinterval = \"22164s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\tshell = \"qAeOYy0M\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"1813s\"\n\t\t\t\t\tttl = \"21743s\"\n\t\t\t\t\tderegister_critical_service_after = \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Cqq95BhP\"\n\t\t\t\t\tname = \"3qXpkS0i\"\n\t\t\t\t\tnotes = \"sb5qLTex\"\n\t\t\t\t\tservice_id = \"CmUUcRna\"\n\t\t\t\t\ttoken = \"a3nQzHuy\"\n\t\t\t\t\tstatus = \"irj26nf3\"\n\t\t\t\t\targs = [\"9s526ogY\", \"gSlOHj1w\"]\n\t\t\t\t\thttp = \"yzhgsQ7Y\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"zcqwA8dO\" = [ \"qb1zx0DL\", \"sXCxPFsD\" ]\n\t\t\t\t\t\t\"qxvdnSE9\" = [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"gLrztrNw\"\n\t\t\t\t\ttcp = \"4jG5casb\"\n\t\t\t\t\tinterval = \"28767s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"THW6u7rL\"\n\t\t\t\t\tshell = \"C1Zt3Zwh\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"18506s\"\n\t\t\t\t\tttl = \"31006s\"\n\t\t\t\t\tderegister_critical_service_after = \"2366s\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tcheck_update_interval = \"16507s\"\n\t\t\tclient_addr = \"93.83.18.19\"\n\t\t\tconfig_entries {\n\t\t\t\t# This is using the repeated block-to-array HCL magic\n\t\t\t\tbootstrap {\n\t\t\t\t\tkind = \"proxy-defaults\"\n\t\t\t\t\tname = \"global\"\n\t\t\t\t\tconfig {\n\t\t\t\t\t\tfoo = \"bar\"\n\t\t\t\t\t\tbar = 1.0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto_encrypt = {\n\t\t\t\ttls = true\n\t\t\t\tdns_san = [\"a.com\", \"b.com\"]\n\t\t\t\tip_san = [\"192.168.4.139\", \"192.168.4.140\"]\n\t\t\t\tallow_tls = true\n\t\t\t}\n\t\t\tconnect {\n\t\t\t\tca_provider = \"consul\"\n\t\t\t\tca_config {\n\t\t\t\t\trotation_period = \"90h\"\n\t\t\t\t\tintermediate_cert_ttl = \"8760h\"\n\t\t\t\t\tleaf_cert_ttl = \"1h\"\n\t\t\t\t\t# hack float since json parses numbers as float and we have to\n\t\t\t\t\t# assert against the same thing\n\t\t\t\t\tcsr_max_per_second = 100.0\n\t\t\t\t\tcsr_max_concurrent = 2.0\n\t\t\t\t}\n\t\t\t\tenabled = true\n\t\t\t}\n\t\t\tgossip_lan {\n\t\t\t\tgossip_nodes    = 6\n\t\t\t\tgossip_interval = \"25252s\"\n\t\t\t\tretransmit_mult = 1234\n\t\t\t\tsuspicion_mult  = 1235\n\t\t\t\tprobe_interval  = \"101ms\"\n\t\t\t\tprobe_timeout   = \"102ms\"\n\t\t\t}\n\t\t\tgossip_wan {\n\t\t\t\tgossip_nodes    = 2\n\t\t\t\tgossip_interval = \"6966s\"\n\t\t\t\tretransmit_mult = 16384\n\t\t\t\tsuspicion_mult  = 16385\n\t\t\t\tprobe_interval  = \"103ms\"\n\t\t\t\tprobe_timeout   = \"104ms\"\n\t\t\t}\n\t\t\tdata_dir = \"` + dataDir + `\"\n\t\t\tdatacenter = \"rzo029wg\"\n\t\t\tdefault_query_time = \"16743s\"\n\t\t\tdisable_anonymous_signature = true\n\t\t\tdisable_coordinates = true\n\t\t\tdisable_host_node_id = true\n\t\t\tdisable_http_unprintable_char_filter = true\n\t\t\tdisable_keyring_file = true\n\t\t\tdisable_remote_exec = true\n\t\t\tdisable_update_check = true\n\t\t\tdiscard_check_output = true\n\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\tdomain = \"7W1xXSqd\"\n\t\t\talt_domain = \"1789hsd\"\n\t\t\tdns_config {\n\t\t\t\tallow_stale = true\n\t\t\t\ta_record_limit = 29907\n\t\t\t\tdisable_compression = true\n\t\t\t\tenable_truncate = true\n\t\t\t\tmax_stale = \"29685s\"\n\t\t\t\tnode_ttl = \"7084s\"\n\t\t\t\tonly_passing = true\n\t\t\t\trecursor_timeout = \"4427s\"\n\t\t\t\tservice_ttl = {\n\t\t\t\t\t\"*\" = \"32030s\"\n\t\t\t\t}\n\t\t\t\tudp_answer_limit = 29909\n\t\t\t\tuse_cache = true\n\t\t\t\tcache_max_age = \"5m\"\n\t\t\t\t` + entFullDNSHCLConfig + `\n\t\t\t}\n\t\t\tenable_acl_replication = true\n\t\t\tenable_agent_tls_for_checks = true\n\t\t\tenable_central_service_config = true\n\t\t\tenable_debug = true\n\t\t\tenable_script_checks = true\n\t\t\tenable_local_script_checks = true\n\t\t\tenable_syslog = true\n\t\t\tencrypt = \"A4wELWqH\"\n\t\t\tencrypt_verify_incoming = true\n\t\t\tencrypt_verify_outgoing = true\n\t\t\thttp_config {\n\t\t\t\tblock_endpoints = [ \"RBvAFcGD\", \"fWOWFznh\" ]\n\t\t\t\tallow_write_http_from = [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ]\n\t\t\t\tresponse_headers = {\n\t\t\t\t\t\"M6TKa9NP\" = \"xjuxjOzQ\"\n\t\t\t\t\t\"JRCrHZed\" = \"rl0mTx81\"\n\t\t\t\t}\n\t\t\t}\n\t\t\tkey_file = \"IEkkwgIA\"\n\t\t\tleave_on_terminate = true\n\t\t\tlimits {\n\t\t\t\thttp_max_conns_per_client = 9283\n\t\t\t\thttps_handshake_timeout = \"2391ms\"\n\t\t\t\trpc_handshake_timeout = \"1932ms\"\n\t\t\t\trpc_rate = 12029.43\n\t\t\t\trpc_max_burst = 44848\n\t\t\t\trpc_max_conns_per_client = 2954\n\t\t\t\tkv_max_value_size = 1234567800000000\n\t\t\t}\n\t\t\tlog_level = \"k1zo9Spt\"\n\t\t\tlog_json = true\n\t\t\tmax_query_time = \"18237s\"\n\t\t\tnode_id = \"AsUIlw99\"\n\t\t\tnode_meta {\n\t\t\t\t\"5mgGQMBk\" = \"mJLtVMSG\"\n\t\t\t\t\"A7ynFMJB\" = \"0Nx6RGab\"\n\t\t\t}\n\t\t\tnode_name = \"otlLxGaI\"\n\t\t\tnon_voting_server = true\n\t\t\tperformance {\n\t\t\t\tleave_drain_time = \"8265s\"\n\t\t\t\traft_multiplier = 5\n\t\t\t\trpc_hold_timeout = \"15707s\"\n\t\t\t}\n\t\t\tpid_file = \"43xN80Km\"\n\t\t\tports {\n\t\t\t\tdns = 7001\n\t\t\t\thttp = 7999\n\t\t\t\thttps = 15127\n\t\t\t\tserver = 3757\n\t\t\t\tgrpc = 4881\n\t\t\t\tproxy_min_port = 2000\n\t\t\t\tproxy_max_port = 3000\n\t\t\t\tsidecar_min_port = 8888\n\t\t\t\tsidecar_max_port = 9999\n\t\t\t\texpose_min_port = 1111\n\t\t\t\texpose_max_port = 2222\n\t\t\t}\n\t\t\tprotocol = 30793\n\t\t\tprimary_datacenter = \"ejtmd43d\"\n\t\t\traft_protocol = 19016\n\t\t\traft_snapshot_threshold = 16384\n\t\t\traft_snapshot_interval = \"30s\"\n\t\t\traft_trailing_logs = 83749\n\t\t\treconnect_timeout = \"23739s\"\n\t\t\treconnect_timeout_wan = \"26694s\"\n\t\t\trecursors = [ \"63.38.39.58\", \"92.49.18.18\" ]\n\t\t\trejoin_after_leave = true\n\t\t\tretry_interval = \"8067s\"\n\t\t\tretry_interval_wan = \"28866s\"\n\t\t\tretry_join = [ \"pbsSFY7U\", \"l0qLtWij\" ]\n\t\t\tretry_join_wan = [ \"PFsR02Ye\", \"rJdQIhER\" ]\n\t\t\tretry_max = 913\n\t\t\tretry_max_wan = 23160\n\t\t\tsegment = \"BC2NhTDi\"\n\t\t\tsegments = [\n\t\t\t\t{\n\t\t\t\t\tname = \"PExYMe2E\"\n\t\t\t\t\tbind = \"36.73.36.19\"\n\t\t\t\t\tport = 38295\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tname = \"UzCvJgup\"\n\t\t\t\t\tbind = \"37.58.38.19\"\n\t\t\t\t\tport = 39292\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tserf_lan = \"99.43.63.15\"\n\t\t\tserf_wan = \"67.88.33.19\"\n\t\t\tserver = true\n\t\t\tserver_name = \"Oerr9n1G\"\n\t\t\tservice = {\n\t\t\t\tid = \"dLOXpSCI\"\n\t\t\t\tname = \"o1ynPkp0\"\n\t\t\t\tmeta = {\n\t\t\t\t\tmymeta = \"data\"\n\t\t\t\t}\n\t\t\t\ttagged_addresses = {\n\t\t\t\t\tlan = {\n\t\t\t\t\t\taddress = \"2d79888a\"\n\t\t\t\t\t\tport = 2143\n\t\t\t\t\t}\n\t\t\t\t\twan = {\n\t\t\t\t\t\taddress = \"d4db85e2\"\n\t\t\t\t\t\tport = 6109\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttags = [\"nkwshvM5\", \"NTDWn3ek\"]\n\t\t\t\taddress = \"cOlSOhbp\"\n\t\t\t\ttoken = \"msy7iWER\"\n\t\t\t\tport = 24237\n\t\t\t\tweights = {\n\t\t\t\t\tpassing = 100,\n\t\t\t\t\twarning = 1\n\t\t\t\t}\n\t\t\t\tenable_tag_override = true\n\t\t\t\tcheck = {\n\t\t\t\t\tid = \"RMi85Dv8\"\n\t\t\t\t\tname = \"iehanzuq\"\n\t\t\t\t\tstatus = \"rCvn53TH\"\n\t\t\t\t\tnotes = \"fti5lfF3\"\n\t\t\t\t\targs = [\"16WRUmwS\", \"QWk7j7ae\"]\n\t\t\t\t\thttp = \"dl3Fgme3\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\trjm4DEd3 = [ \"2m3m2Fls\" ]\n\t\t\t\t\t\tl4HwQ112 = [ \"fk56MNlo\", \"dhLK56aZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"9afLm3Mj\"\n\t\t\t\t\ttcp = \"fjiLFqVd\"\n\t\t\t\t\tinterval = \"23926s\"\n\t\t\t\t\tdocker_container_id = \"dO5TtRHk\"\n\t\t\t\t\tshell = \"e6q2ttES\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"38483s\"\n\t\t\t\t\tttl = \"10943s\"\n\t\t\t\t\tderegister_critical_service_after = \"68787s\"\n\t\t\t\t}\n\t\t\t\tchecks = [\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"Zv99e9Ka\"\n\t\t\t\t\t\tname = \"sgV4F7Pk\"\n\t\t\t\t\t\tnotes = \"yP5nKbW0\"\n\t\t\t\t\t\tstatus = \"7oLMEyfu\"\n\t\t\t\t\t\targs = [\"5wEZtZpv\", \"0Ihyk8cS\"]\n\t\t\t\t\t\thttp = \"KyDjGY9H\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"gv5qefTz\" = [ \"5Olo2pMG\", \"PvvKWQU5\" ]\n\t\t\t\t\t\t\t\"SHOVq1Vv\" = [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"T66MFBfR\"\n\t\t\t\t\t\ttcp = \"bNnNfx2A\"\n\t\t\t\t\t\tinterval = \"22224s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\t\tshell = \"omVZq7Sz\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"18913s\"\n\t\t\t\t\t\tttl = \"44743s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"G79O6Mpr\"\n\t\t\t\t\t\tname = \"IEqrzrsd\"\n\t\t\t\t\t\tnotes = \"SVqApqeM\"\n\t\t\t\t\t\tstatus = \"XXkVoZXt\"\n\t\t\t\t\t\targs = [\"wD05Bvao\", \"rLYB7kQC\"]\n\t\t\t\t\t\thttp = \"kyICZsn8\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"4ebP5vL4\" = [ \"G20SrL5Q\", \"DwPKlMbo\" ]\n\t\t\t\t\t\t\t\"p2UI34Qz\" = [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"ciYHWors\"\n\t\t\t\t\t\ttcp = \"FfvCwlqH\"\n\t\t\t\t\t\tinterval = \"12356s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"HBndBU6R\"\n\t\t\t\t\t\tshell = \"hVI33JjA\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38282s\"\n\t\t\t\t\t\tttl = \"1181s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t\tconnect {\n\t\t\t\t\tnative = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tservices = [\n\t\t\t\t{\n\t\t\t\t\tid = \"wI1dzxS4\"\n\t\t\t\t\tname = \"7IszXMQ1\"\n\t\t\t\t\ttags = [\"0Zwg8l6v\", \"zebELdN5\"]\n\t\t\t\t\taddress = \"9RhqPSPB\"\n\t\t\t\t\ttoken = \"myjKJkWH\"\n\t\t\t\t\tport = 72219\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tcheck = {\n\t\t\t\t\t\tid = \"qmfeO5if\"\n\t\t\t\t\t\tname = \"atDGP7n5\"\n\t\t\t\t\t\tstatus = \"pDQKEhWL\"\n\t\t\t\t\t\tnotes = \"Yt8EDLev\"\n\t\t\t\t\t\targs = [\"81EDZLPa\", \"bPY5X8xd\"]\n\t\t\t\t\t\thttp = \"qzHYvmJO\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\tUkpmZ3a3 = [ \"2dfzXuxZ\" ]\n\t\t\t\t\t\t\tcVFpko4u = [ \"gGqdEB6k\", \"9LsRo22u\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"X5DrovFc\"\n\t\t\t\t\t\ttcp = \"ICbxkpSF\"\n\t\t\t\t\t\tinterval = \"24392s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ZKXr68Yb\"\n\t\t\t\t\t\tshell = \"CEfzx0Fo\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38333s\"\n\t\t\t\t\t\tttl = \"57201s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"44214s\"\n\t\t\t\t\t}\n\t\t\t\t\tconnect {\n\t\t\t\t\t\tsidecar_service {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"MRHVMZuD\"\n\t\t\t\t\tname = \"6L6BVfgH\"\n\t\t\t\t\ttags = [\"7Ale4y6o\", \"PMBW08hy\"]\n\t\t\t\t\taddress = \"R6H6g8h0\"\n\t\t\t\t\ttoken = \"ZgY8gjMI\"\n\t\t\t\t\tport = 38292\n\t\t\t\t\tweights = {\n\t\t\t\t\t\tpassing = 1979,\n\t\t\t\t\t\twarning = 6\n\t\t\t\t\t}\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tchecks = [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"GTti9hCo\"\n\t\t\t\t\t\t\tname = \"9OOS93ne\"\n\t\t\t\t\t\t\tnotes = \"CQy86DH0\"\n\t\t\t\t\t\t\tstatus = \"P0SWDvrk\"\n\t\t\t\t\t\t\targs = [\"EXvkYIuG\", \"BATOyt6h\"]\n\t\t\t\t\t\t\thttp = \"u97ByEiW\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"MUlReo8L\" = [ \"AUZG7wHG\", \"gsN0Dc2N\" ]\n\t\t\t\t\t\t\t\t\"1UJXjVrT\" = [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"5wkAxCUE\"\n\t\t\t\t\t\t\ttcp = \"MN3oA9D2\"\n\t\t\t\t\t\t\tinterval = \"32718s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"cU15LMet\"\n\t\t\t\t\t\t\tshell = \"nEz9qz2l\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"34738s\"\n\t\t\t\t\t\t\tttl = \"22773s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"UHsDeLxG\"\n\t\t\t\t\t\t\tname = \"PQSaPWlT\"\n\t\t\t\t\t\t\tnotes = \"jKChDOdl\"\n\t\t\t\t\t\t\tstatus = \"5qFz6OZn\"\n\t\t\t\t\t\t\targs = [\"NMtYWlT9\", \"vj74JXsm\"]\n\t\t\t\t\t\t\thttp = \"1LBDJhw4\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\" = [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\" = [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"wzByP903\"\n\t\t\t\t\t\t\ttcp = \"2exjZIGE\"\n\t\t\t\t\t\t\tinterval = \"5656s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"5tDBWpfA\"\n\t\t\t\t\t\t\tshell = \"rlTpLM8s\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"4868s\"\n\t\t\t\t\t\t\tttl = \"11222s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t\tconnect {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Kh81CPF6\"\n\t\t\t\t\tname = \"Kh81CPF6-proxy\"\n\t\t\t\t\tport = 31471\n\t\t\t\t\tkind = \"connect-proxy\"\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tdestination_service_name = \"6L6BVfgH\"\n\t\t\t\t\t\tdestination_service_id = \"6L6BVfgH-id\"\n\t\t\t\t\t\tlocal_service_address = \"127.0.0.2\"\n\t\t\t\t\t\tlocal_service_port = 23759\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\tcedGGtZf = \"pWrUNiWw\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tupstreams = [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_name = \"KPtAj2cb\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 4051\n\t\t\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\t\tkzRnZOyd = \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_type = \"prepared_query\"\n\t\t\t\t\t\t\t\tdestination_namespace = \"9nakw0td\"\n\t\t\t\t\t\t\t\tdestination_name = \"KSd8HsRl\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 11884\n\t\t\t\t\t\t\t\tlocal_bind_address = \"127.24.88.0\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t]\n\t\t\t\t\t\texpose {\n\t\t\t\t\t\t\tchecks = true\n\t\t\t\t\t\t\tpaths = [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tpath = \"/health\"\n\t\t\t\t\t\t\t\t\tlocal_path_port = 8080\n\t\t\t\t\t\t\t\t\tlistener_port = 21500\n\t\t\t\t\t\t\t\t\tprotocol = \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"kvVqbwSE\"\n\t\t\t\t\tkind = \"mesh-gateway\"\n\t\t\t\t\tname = \"gw-primary-dc\"\n\t\t\t\t\tport = 27147\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\"1CuJHVfw\" = \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t\tsession_ttl_min = \"26627s\"\n\t\t\tskip_leave_on_interrupt = true\n\t\t\tstart_join = [ \"LR3hGDoG\", \"MwVpZ4Up\" ]\n\t\t\tstart_join_wan = [ \"EbFSc3nA\", \"kwXTh623\" ]\n\t\t\tsyslog_facility = \"hHv79Uia\"\n\t\t\ttagged_addresses = {\n\t\t\t\t\"7MYgHrYH\" = \"dALJAhLD\"\n\t\t\t\t\"h6DdBy6K\" = \"ebrr9zZ8\"\n\t\t\t}\n\t\t\ttelemetry {\n\t\t\t\tcirconus_api_app = \"p4QOTe9j\"\n\t\t\t\tcirconus_api_token = \"E3j35V23\"\n\t\t\t\tcirconus_api_url = \"mEMjHpGg\"\n\t\t\t\tcirconus_broker_id = \"BHlxUhed\"\n\t\t\t\tcirconus_broker_select_tag = \"13xy1gHm\"\n\t\t\t\tcirconus_check_display_name = \"DRSlQR6n\"\n\t\t\t\tcirconus_check_force_metric_activation = \"Ua5FGVYf\"\n\t\t\t\tcirconus_check_id = \"kGorutad\"\n\t\t\t\tcirconus_check_instance_id = \"rwoOL6R4\"\n\t\t\t\tcirconus_check_search_tag = \"ovT4hT4f\"\n\t\t\t\tcirconus_check_tags = \"prvO4uBl\"\n\t\t\t\tcirconus_submission_interval = \"DolzaflP\"\n\t\t\t\tcirconus_submission_url = \"gTcbS93G\"\n\t\t\t\tdisable_hostname = true\n\t\t\t\tdogstatsd_addr = \"0wSndumK\"\n\t\t\t\tdogstatsd_tags = [ \"3N81zSUB\",\"Xtj8AnXZ\" ]\n\t\t\t\tfilter_default = true\n\t\t\t\tprefix_filter = [ \"+oJotS8XJ\",\"-cazlEhGn\" ]\n\t\t\t\tmetrics_prefix = \"ftO6DySn\"\n\t\t\t\tprometheus_retention_time = \"15s\"\n\t\t\t\tstatsd_address = \"drce87cy\"\n\t\t\t\tstatsite_address = \"HpFwKB8R\"\n\t\t\t}\n\t\t\ttls_cipher_suites = \"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"\n\t\t\ttls_min_version = \"pAOWafkR\"\n\t\t\ttls_prefer_server_cipher_suites = true\n\t\t\ttranslate_wan_addrs = true\n\t\t\tui = true\n\t\t\tui_dir = \"11IFzAUn\"\n\t\t\tui_content_path = \"consul\"\n\t\t\tunix_sockets = {\n\t\t\t\tgroup = \"8pFodrV8\"\n\t\t\t\tmode = \"E8sAwOv4\"\n\t\t\t\tuser = \"E0nB1DwA\"\n\t\t\t}\n\t\t\tverify_incoming = true\n\t\t\tverify_incoming_https = true\n\t\t\tverify_incoming_rpc = true\n\t\t\tverify_outgoing = true\n\t\t\tverify_server_hostname = true\n\t\t\twatches = [{\n\t\t\t\ttype = \"key\"\n\t\t\t\tdatacenter = \"GyE6jpeW\"\n\t\t\t\tkey = \"j9lF1Tve\"\n\t\t\t\thandler = \"90N7S4LN\"\n\t\t\t}, {\n\t\t\t\ttype = \"keyprefix\"\n\t\t\t\tdatacenter = \"fYrl3F5d\"\n\t\t\t\tkey = \"sl3Dffu7\"\n\t\t\t\targs = [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t}]\n\t\t`}\n\n\ttail := map[string][]Source{\n\t\t\"json\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"acl_disabled_ttl\": \"957s\",\n\t\t\t\t\t\"acl\" : {\n\t\t\t\t\t\t\"disabled_ttl\" : \"957s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"ae_interval\": \"10003s\",\n\t\t\t\t\t\"check_deregister_interval_min\": \"27870s\",\n\t\t\t\t\t\"check_reap_interval\": \"10662s\",\n\t\t\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\t\t\"segment_limit\": 24705,\n\t\t\t\t\t\"segment_name_limit\": 27046,\n\t\t\t\t\t\"sync_coordinate_interval_min\": \"27983s\",\n\t\t\t\t\t\"sync_coordinate_rate_target\": 137.81\n\t\t\t\t}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"consul\": {\n\t\t\t\t\t\t\"coordinate\": {\n\t\t\t\t\t\t\t\"update_batch_size\": 9244,\n\t\t\t\t\t\t\t\"update_max_batches\": 15164,\n\t\t\t\t\t\t\t\"update_period\": \"25093s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"raft\": {\n\t\t\t\t\t\t\t\"election_timeout\": \"31947s\",\n\t\t\t\t\t\t\t\"heartbeat_timeout\": \"25699s\",\n\t\t\t\t\t\t\t\"leader_lease_timeout\": \"15351s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"server\": {\n\t\t\t\t\t\t\t\"health_interval\": \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}`,\n\t\t\t},\n\t\t},\n\t\t\"hcl\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tacl_disabled_ttl = \"957s\"\n\t\t\t\t\tacl = {\n\t\t\t\t\t\tdisabled_ttl = \"957s\"\n\t\t\t\t\t}\n\t\t\t\t\tae_interval = \"10003s\"\n\t\t\t\t\tcheck_deregister_interval_min = \"27870s\"\n\t\t\t\t\tcheck_reap_interval = \"10662s\"\n\t\t\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\t\t\tsegment_limit = 24705\n\t\t\t\t\tsegment_name_limit = 27046\n\t\t\t\t\tsync_coordinate_interval_min = \"27983s\"\n\t\t\t\t\tsync_coordinate_rate_target = 137.81\n\t\t\t\t`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tconsul = {\n\t\t\t\t\t\tcoordinate = {\n\t\t\t\t\t\t\tupdate_batch_size = 9244\n\t\t\t\t\t\t\tupdate_max_batches = 15164\n\t\t\t\t\t\t\tupdate_period = \"25093s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\traft = {\n\t\t\t\t\t\t\telection_timeout = \"31947s\"\n\t\t\t\t\t\t\theartbeat_timeout = \"25699s\"\n\t\t\t\t\t\t\tleader_lease_timeout = \"15351s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tserver = {\n\t\t\t\t\t\t\thealth_interval = \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t`,\n\t\t\t},\n\t\t},\n\t}\n\n\twant := RuntimeConfig{\n\t\t// non-user configurable values\n\t\tACLDisabledTTL:             957 * time.Second,\n\t\tAEInterval:                 10003 * time.Second,\n\t\tCheckDeregisterIntervalMin: 27870 * time.Second,\n\t\tCheckReapInterval:          10662 * time.Second,\n\t\tSegmentLimit:               24705,\n\t\tSegmentNameLimit:           27046,\n\t\tSyncCoordinateIntervalMin:  27983 * time.Second,\n\t\tSyncCoordinateRateTarget:   137.81,\n\n\t\tRevision:          \"JNtPSav3\",\n\t\tVersion:           \"R909Hblt\",\n\t\tVersionPrerelease: \"ZT1JOQLn\",\n\n\t\t// consul configuration\n\t\tConsulCoordinateUpdateBatchSize:  9244,\n\t\tConsulCoordinateUpdateMaxBatches: 15164,\n\t\tConsulCoordinateUpdatePeriod:     25093 * time.Second,\n\t\tConsulRaftElectionTimeout:        5 * 31947 * time.Second,\n\t\tConsulRaftHeartbeatTimeout:       5 * 25699 * time.Second,\n\t\tConsulRaftLeaderLeaseTimeout:     5 * 15351 * time.Second,\n\t\tGossipLANGossipInterval:          25252 * time.Second,\n\t\tGossipLANGossipNodes:             6,\n\t\tGossipLANProbeInterval:           101 * time.Millisecond,\n\t\tGossipLANProbeTimeout:            102 * time.Millisecond,\n\t\tGossipLANSuspicionMult:           1235,\n\t\tGossipLANRetransmitMult:          1234,\n\t\tGossipWANGossipInterval:          6966 * time.Second,\n\t\tGossipWANGossipNodes:             2,\n\t\tGossipWANProbeInterval:           103 * time.Millisecond,\n\t\tGossipWANProbeTimeout:            104 * time.Millisecond,\n\t\tGossipWANSuspicionMult:           16385,\n\t\tGossipWANRetransmitMult:          16384,\n\t\tConsulServerHealthInterval:       17455 * time.Second,\n\n\t\t// user configurable values\n\n\t\tACLAgentMasterToken:              \"64fd0e08\",\n\t\tACLAgentToken:                    \"bed2377c\",\n\t\tACLsEnabled:                      true,\n\t\tACLDatacenter:                    \"ejtmd43d\",\n\t\tACLDefaultPolicy:                 \"72c2e7a0\",\n\t\tACLDownPolicy:                    \"03eb2aee\",\n\t\tACLEnforceVersion8:               true,\n\t\tACLEnableKeyListPolicy:           true,\n\t\tACLEnableTokenPersistence:        true,\n\t\tACLMasterToken:                   \"8a19ac27\",\n\t\tACLReplicationToken:              \"5795983a\",\n\t\tACLTokenTTL:                      3321 * time.Second,\n\t\tACLPolicyTTL:                     1123 * time.Second,\n\t\tACLRoleTTL:                       9876 * time.Second,\n\t\tACLToken:                         \"418fdff1\",\n\t\tACLTokenReplication:              true,\n\t\tAdvertiseAddrLAN:                 ipAddr(\"17.99.29.16\"),\n\t\tAdvertiseAddrWAN:                 ipAddr(\"78.63.37.19\"),\n\t\tAutopilotCleanupDeadServers:      true,\n\t\tAutopilotDisableUpgradeMigration: true,\n\t\tAutopilotLastContactThreshold:    12705 * time.Second,\n\t\tAutopilotMaxTrailingLogs:         17849,\n\t\tAutopilotMinQuorum:               3,\n\t\tAutopilotRedundancyZoneTag:       \"3IsufDJf\",\n\t\tAutopilotServerStabilizationTime: 23057 * time.Second,\n\t\tAutopilotUpgradeVersionTag:       \"W9pDwFAL\",\n\t\tBindAddr:                         ipAddr(\"16.99.34.17\"),\n\t\tBootstrap:                        true,\n\t\tBootstrapExpect:                  53,\n\t\tCAFile:                           \"erA7T0PM\",\n\t\tCAPath:                           \"mQEN1Mfp\",\n\t\tCertFile:                         \"7s4QAzDk\",\n\t\tCheckOutputMaxSize:               checks.DefaultBufSize,\n\t\tChecks: []*structs.CheckDefinition{\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"uAjE6m9Z\",\n\t\t\t\tName:       \"QsZRGpYr\",\n\t\t\t\tNotes:      \"VJ7Sk4BY\",\n\t\t\t\tServiceID:  \"lSulPcyz\",\n\t\t\t\tToken:      \"toO59sh8\",\n\t\t\t\tStatus:     \"9RlWsXMV\",\n\t\t\t\tScriptArgs: []string{\"4BAJttck\", \"4D2NPtTQ\"},\n\t\t\t\tHTTP:       \"dohLcyQ2\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"ZBfTin3L\": []string{\"1sDbEqYG\", \"lJGASsWK\"},\n\t\t\t\t\t\"Ui0nU99X\": []string{\"LMccm3Qe\", \"k5H5RggQ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"aldrIQ4l\",\n\t\t\t\tTCP:                            \"RJQND605\",\n\t\t\t\tInterval:                       22164 * time.Second,\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\tShell:                          \"qAeOYy0M\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        1813 * time.Second,\n\t\t\t\tTTL:                            21743 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 14232 * time.Second,\n\t\t\t\tEnterpriseMeta:                 *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"Cqq95BhP\",\n\t\t\t\tName:       \"3qXpkS0i\",\n\t\t\t\tNotes:      \"sb5qLTex\",\n\t\t\t\tServiceID:  \"CmUUcRna\",\n\t\t\t\tToken:      \"a3nQzHuy\",\n\t\t\t\tStatus:     \"irj26nf3\",\n\t\t\t\tScriptArgs: []string{\"9s526ogY\", \"gSlOHj1w\"},\n\t\t\t\tHTTP:       \"yzhgsQ7Y\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"zcqwA8dO\": []string{\"qb1zx0DL\", \"sXCxPFsD\"},\n\t\t\t\t\t\"qxvdnSE9\": []string{\"6wBPUYdF\", \"YYh8wtSZ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"gLrztrNw\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"4jG5casb\",\n\t\t\t\tInterval:                       28767 * time.Second,\n\t\t\t\tDockerContainerID:              \"THW6u7rL\",\n\t\t\t\tShell:                          \"C1Zt3Zwh\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        18506 * time.Second,\n\t\t\t\tTTL:                            31006 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 2366 * time.Second,\n\t\t\t\tEnterpriseMeta:                 *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"fZaCAXww\",\n\t\t\t\tName:       \"OOM2eo0f\",\n\t\t\t\tNotes:      \"zXzXI9Gt\",\n\t\t\t\tServiceID:  \"L8G0QNmR\",\n\t\t\t\tToken:      \"oo4BCTgJ\",\n\t\t\t\tStatus:     \"qLykAl5u\",\n\t\t\t\tScriptArgs: []string{\"f3BemRjy\", \"e5zgpef7\"},\n\t\t\t\tHTTP:       \"29B93haH\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"hBq0zn1q\": {\"2a9o9ZKP\", \"vKwA5lR6\"},\n\t\t\t\t\t\"f3r6xFtM\": {\"RyuIdDWv\", \"QbxEcIUM\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"Dou0nGT5\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"JY6fTTcw\",\n\t\t\t\tInterval:                       18714 * time.Second,\n\t\t\t\tDockerContainerID:              \"qF66POS9\",\n\t\t\t\tShell:                          \"sOnDy228\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        5954 * time.Second,\n\t\t\t\tTTL:                            30044 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 13209 * time.Second,\n\t\t\t\tEnterpriseMeta:                 *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t},\n\t\tCheckUpdateInterval: 16507 * time.Second,\n\t\tClientAddrs:         []*net.IPAddr{ipAddr(\"93.83.18.19\")},\n\t\tConfigEntryBootstrap: []structs.ConfigEntry{\n\t\t\t&structs.ProxyConfigEntry{\n\t\t\t\tKind: structs.ProxyDefaults,\n\t\t\t\tName: structs.ProxyConfigGlobal,\n\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t// has to be a float due to being a map[string]interface\n\t\t\t\t\t\"bar\": float64(1),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tAutoEncryptTLS:        true,\n\t\tAutoEncryptDNSSAN:     []string{\"a.com\", \"b.com\"},\n\t\tAutoEncryptIPSAN:      []net.IP{net.ParseIP(\"192.168.4.139\"), net.ParseIP(\"192.168.4.140\")},\n\t\tAutoEncryptAllowTLS:   true,\n\t\tConnectEnabled:        true,\n\t\tConnectSidecarMinPort: 8888,\n\t\tConnectSidecarMaxPort: 9999,\n\t\tExposeMinPort:         1111,\n\t\tExposeMaxPort:         2222,\n\t\tConnectCAProvider:     \"consul\",\n\t\tConnectCAConfig: map[string]interface{}{\n\t\t\t\"RotationPeriod\":      \"90h\",\n\t\t\t\"IntermediateCertTTL\": \"8760h\",\n\t\t\t\"LeafCertTTL\":         \"1h\",\n\t\t\t\"CSRMaxPerSecond\":     float64(100),\n\t\t\t\"CSRMaxConcurrent\":    float64(2),\n\t\t},\n\t\tDNSAddrs:                         []net.Addr{tcpAddr(\"93.95.95.81:7001\"), udpAddr(\"93.95.95.81:7001\")},\n\t\tDNSARecordLimit:                  29907,\n\t\tDNSAllowStale:                    true,\n\t\tDNSDisableCompression:            true,\n\t\tDNSDomain:                        \"7W1xXSqd\",\n\t\tDNSAltDomain:                     \"1789hsd\",\n\t\tDNSEnableTruncate:                true,\n\t\tDNSMaxStale:                      29685 * time.Second,\n\t\tDNSNodeTTL:                       7084 * time.Second,\n\t\tDNSOnlyPassing:                   true,\n\t\tDNSPort:                          7001,\n\t\tDNSRecursorTimeout:               4427 * time.Second,\n\t\tDNSRecursors:                     []string{\"63.38.39.58\", \"92.49.18.18\"},\n\t\tDNSSOA:                           RuntimeSOAConfig{Refresh: 3600, Retry: 600, Expire: 86400, Minttl: 0},\n\t\tDNSServiceTTL:                    map[string]time.Duration{\"*\": 32030 * time.Second},\n\t\tDNSUDPAnswerLimit:                29909,\n\t\tDNSNodeMetaTXT:                   true,\n\t\tDNSUseCache:                      true,\n\t\tDNSCacheMaxAge:                   5 * time.Minute,\n\t\tDataDir:                          dataDir,\n\t\tDatacenter:                       \"rzo029wg\",\n\t\tDefaultQueryTime:                 16743 * time.Second,\n\t\tDevMode:                          true,\n\t\tDisableAnonymousSignature:        true,\n\t\tDisableCoordinates:               true,\n\t\tDisableHostNodeID:                true,\n\t\tDisableHTTPUnprintableCharFilter: true,\n\t\tDisableKeyringFile:               true,\n\t\tDisableRemoteExec:                true,\n\t\tDisableUpdateCheck:               true,\n\t\tDiscardCheckOutput:               true,\n\t\tDiscoveryMaxStale:                5 * time.Second,\n\t\tEnableAgentTLSForChecks:          true,\n\t\tEnableCentralServiceConfig:       true,\n\t\tEnableDebug:                      true,\n\t\tEnableRemoteScriptChecks:         true,\n\t\tEnableLocalScriptChecks:          true,\n\t\tEnableSyslog:                     true,\n\t\tEnableUI:                         true,\n\t\tEncryptKey:                       \"A4wELWqH\",\n\t\tEncryptVerifyIncoming:            true,\n\t\tEncryptVerifyOutgoing:            true,\n\t\tGRPCPort:                         4881,\n\t\tGRPCAddrs:                        []net.Addr{tcpAddr(\"32.31.61.91:4881\")},\n\t\tHTTPAddrs:                        []net.Addr{tcpAddr(\"83.39.91.39:7999\")},\n\t\tHTTPBlockEndpoints:               []string{\"RBvAFcGD\", \"fWOWFznh\"},\n\t\tAllowWriteHTTPFrom:               []*net.IPNet{cidr(\"127.0.0.0/8\"), cidr(\"22.33.44.55/32\"), cidr(\"0.0.0.0/0\")},\n\t\tHTTPPort:                         7999,\n\t\tHTTPResponseHeaders:              map[string]string{\"M6TKa9NP\": \"xjuxjOzQ\", \"JRCrHZed\": \"rl0mTx81\"},\n\t\tHTTPSAddrs:                       []net.Addr{tcpAddr(\"95.17.17.19:15127\")},\n\t\tHTTPMaxConnsPerClient:            9283,\n\t\tHTTPSHandshakeTimeout:            2391 * time.Millisecond,\n\t\tHTTPSPort:                        15127,\n\t\tKeyFile:                          \"IEkkwgIA\",\n\t\tKVMaxValueSize:                   1234567800000000,\n\t\tLeaveDrainTime:                   8265 * time.Second,\n\t\tLeaveOnTerm:                      true,\n\t\tLogLevel:                         \"k1zo9Spt\",\n\t\tLogJSON:                          true,\n\t\tMaxQueryTime:                     18237 * time.Second,\n\t\tNodeID:                           types.NodeID(\"AsUIlw99\"),\n\t\tNodeMeta:                         map[string]string{\"5mgGQMBk\": \"mJLtVMSG\", \"A7ynFMJB\": \"0Nx6RGab\"},\n\t\tNodeName:                         \"otlLxGaI\",\n\t\tNonVotingServer:                  true,\n\t\tPidFile:                          \"43xN80Km\",\n\t\tPrimaryDatacenter:                \"ejtmd43d\",\n\t\tRPCAdvertiseAddr:                 tcpAddr(\"17.99.29.16:3757\"),\n\t\tRPCBindAddr:                      tcpAddr(\"16.99.34.17:3757\"),\n\t\tRPCHandshakeTimeout:              1932 * time.Millisecond,\n\t\tRPCHoldTimeout:                   15707 * time.Second,\n\t\tRPCProtocol:                      30793,\n\t\tRPCRateLimit:                     12029.43,\n\t\tRPCMaxBurst:                      44848,\n\t\tRPCMaxConnsPerClient:             2954,\n\t\tRaftProtocol:                     19016,\n\t\tRaftSnapshotThreshold:            16384,\n\t\tRaftSnapshotInterval:             30 * time.Second,\n\t\tRaftTrailingLogs:                 83749,\n\t\tReconnectTimeoutLAN:              23739 * time.Second,\n\t\tReconnectTimeoutWAN:              26694 * time.Second,\n\t\tRejoinAfterLeave:                 true,\n\t\tRetryJoinIntervalLAN:             8067 * time.Second,\n\t\tRetryJoinIntervalWAN:             28866 * time.Second,\n\t\tRetryJoinLAN:                     []string{\"pbsSFY7U\", \"l0qLtWij\"},\n\t\tRetryJoinMaxAttemptsLAN:          913,\n\t\tRetryJoinMaxAttemptsWAN:          23160,\n\t\tRetryJoinWAN:                     []string{\"PFsR02Ye\", \"rJdQIhER\"},\n\t\tSegmentName:                      \"BC2NhTDi\",\n\t\tSegments: []structs.NetworkSegment{\n\t\t\t{\n\t\t\t\tName:        \"PExYMe2E\",\n\t\t\t\tBind:        tcpAddr(\"36.73.36.19:38295\"),\n\t\t\t\tAdvertise:   tcpAddr(\"63.39.19.18:38295\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:        \"UzCvJgup\",\n\t\t\t\tBind:        tcpAddr(\"37.58.38.19:39292\"),\n\t\t\t\tAdvertise:   tcpAddr(\"83.58.26.27:39292\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t},\n\t\tSerfPortLAN: 8301,\n\t\tSerfPortWAN: 8302,\n\t\tServerMode:  true,\n\t\tServerName:  \"Oerr9n1G\",\n\t\tServerPort:  3757,\n\t\tServices: []*structs.ServiceDefinition{\n\t\t\t{\n\t\t\t\tID:      \"wI1dzxS4\",\n\t\t\t\tName:    \"7IszXMQ1\",\n\t\t\t\tTags:    []string{\"0Zwg8l6v\", \"zebELdN5\"},\n\t\t\t\tAddress: \"9RhqPSPB\",\n\t\t\t\tToken:   \"myjKJkWH\",\n\t\t\t\tPort:    72219,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: []*structs.CheckType{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"qmfeO5if\",\n\t\t\t\t\t\tName:       \"atDGP7n5\",\n\t\t\t\t\t\tStatus:     \"pDQKEhWL\",\n\t\t\t\t\t\tNotes:      \"Yt8EDLev\",\n\t\t\t\t\t\tScriptArgs: []string{\"81EDZLPa\", \"bPY5X8xd\"},\n\t\t\t\t\t\tHTTP:       \"qzHYvmJO\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"UkpmZ3a3\": {\"2dfzXuxZ\"},\n\t\t\t\t\t\t\t\"cVFpko4u\": {\"gGqdEB6k\", \"9LsRo22u\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"X5DrovFc\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"ICbxkpSF\",\n\t\t\t\t\t\tInterval:                       24392 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ZKXr68Yb\",\n\t\t\t\t\t\tShell:                          \"CEfzx0Fo\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38333 * time.Second,\n\t\t\t\t\t\tTTL:                            57201 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 44214 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t// Note that although this SidecarService is only syntax sugar for\n\t\t\t\t// registering another service, that has to happen in the agent code so\n\t\t\t\t// it can make intelligent decisions about automatic port assignments\n\t\t\t\t// etc. So we expect config just to pass it through verbatim.\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tSidecarService: &structs.ServiceDefinition{\n\t\t\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\t\t\tPassing: 1,\n\t\t\t\t\t\t\tWarning: 1,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:      \"MRHVMZuD\",\n\t\t\t\tName:    \"6L6BVfgH\",\n\t\t\t\tTags:    []string{\"7Ale4y6o\", \"PMBW08hy\"},\n\t\t\t\tAddress: \"R6H6g8h0\",\n\t\t\t\tToken:   \"ZgY8gjMI\",\n\t\t\t\tPort:    38292,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1979,\n\t\t\t\t\tWarning: 6,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"GTti9hCo\",\n\t\t\t\t\t\tName:       \"9OOS93ne\",\n\t\t\t\t\t\tNotes:      \"CQy86DH0\",\n\t\t\t\t\t\tStatus:     \"P0SWDvrk\",\n\t\t\t\t\t\tScriptArgs: []string{\"EXvkYIuG\", \"BATOyt6h\"},\n\t\t\t\t\t\tHTTP:       \"u97ByEiW\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"MUlReo8L\": {\"AUZG7wHG\", \"gsN0Dc2N\"},\n\t\t\t\t\t\t\t\"1UJXjVrT\": {\"OJgxzTfk\", \"xZZrFsq7\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"5wkAxCUE\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"MN3oA9D2\",\n\t\t\t\t\t\tInterval:                       32718 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"cU15LMet\",\n\t\t\t\t\t\tShell:                          \"nEz9qz2l\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        34738 * time.Second,\n\t\t\t\t\t\tTTL:                            22773 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 84282 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"UHsDeLxG\",\n\t\t\t\t\t\tName:       \"PQSaPWlT\",\n\t\t\t\t\t\tNotes:      \"jKChDOdl\",\n\t\t\t\t\t\tStatus:     \"5qFz6OZn\",\n\t\t\t\t\t\tScriptArgs: []string{\"NMtYWlT9\", \"vj74JXsm\"},\n\t\t\t\t\t\tHTTP:       \"1LBDJhw4\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"cXPmnv1M\": {\"imDqfaBx\", \"NFxZ1bQe\"},\n\t\t\t\t\t\t\t\"vr7wY7CS\": {\"EtCoNPPL\", \"9vAarJ5s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"wzByP903\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"2exjZIGE\",\n\t\t\t\t\t\tInterval:                       5656 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"5tDBWpfA\",\n\t\t\t\t\t\tShell:                          \"rlTpLM8s\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        4868 * time.Second,\n\t\t\t\t\t\tTTL:                            11222 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tConnect:        &structs.ServiceConnect{},\n\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"Kh81CPF6\",\n\t\t\t\tName: \"Kh81CPF6-proxy\",\n\t\t\t\tPort: 31471,\n\t\t\t\tKind: \"connect-proxy\",\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tDestinationServiceName: \"6L6BVfgH\",\n\t\t\t\t\tDestinationServiceID:   \"6L6BVfgH-id\",\n\t\t\t\t\tLocalServiceAddress:    \"127.0.0.2\",\n\t\t\t\t\tLocalServicePort:       23759,\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\",\n\t\t\t\t\t},\n\t\t\t\t\tUpstreams: structs.Upstreams{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType: \"service\", // Default should be explicitly filled\n\t\t\t\t\t\t\tDestinationName: \"KPtAj2cb\",\n\t\t\t\t\t\t\tLocalBindPort:   4051,\n\t\t\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType:      \"prepared_query\",\n\t\t\t\t\t\t\tDestinationNamespace: \"9nakw0td\",\n\t\t\t\t\t\t\tDestinationName:      \"KSd8HsRl\",\n\t\t\t\t\t\t\tLocalBindPort:        11884,\n\t\t\t\t\t\t\tLocalBindAddress:     \"127.24.88.0\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tExpose: structs.ExposeConfig{\n\t\t\t\t\t\tChecks: true,\n\t\t\t\t\t\tPaths: []structs.ExposePath{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tPath:          \"/health\",\n\t\t\t\t\t\t\t\tLocalPathPort: 8080,\n\t\t\t\t\t\t\t\tListenerPort:  21500,\n\t\t\t\t\t\t\t\tProtocol:      \"http\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"kvVqbwSE\",\n\t\t\t\tKind: \"mesh-gateway\",\n\t\t\t\tName: \"gw-primary-dc\",\n\t\t\t\tPort: 27147,\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"1CuJHVfw\": \"Kzqsa7yc\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"dLOXpSCI\",\n\t\t\t\tName: \"o1ynPkp0\",\n\t\t\t\tTaggedAddresses: map[string]structs.ServiceAddress{\n\t\t\t\t\t\"lan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"2d79888a\",\n\t\t\t\t\t\tPort:    2143,\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"d4db85e2\",\n\t\t\t\t\t\tPort:    6109,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tTags:    []string{\"nkwshvM5\", \"NTDWn3ek\"},\n\t\t\t\tAddress: \"cOlSOhbp\",\n\t\t\t\tToken:   \"msy7iWER\",\n\t\t\t\tMeta:    map[string]string{\"mymeta\": \"data\"},\n\t\t\t\tPort:    24237,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 100,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tNative: true,\n\t\t\t\t},\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"Zv99e9Ka\",\n\t\t\t\t\t\tName:       \"sgV4F7Pk\",\n\t\t\t\t\t\tNotes:      \"yP5nKbW0\",\n\t\t\t\t\t\tStatus:     \"7oLMEyfu\",\n\t\t\t\t\t\tScriptArgs: []string{\"5wEZtZpv\", \"0Ihyk8cS\"},\n\t\t\t\t\t\tHTTP:       \"KyDjGY9H\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"gv5qefTz\": {\"5Olo2pMG\", \"PvvKWQU5\"},\n\t\t\t\t\t\t\t\"SHOVq1Vv\": {\"jntFhyym\", \"GYJh32pp\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"T66MFBfR\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"bNnNfx2A\",\n\t\t\t\t\t\tInterval:                       22224 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\t\t\tShell:                          \"omVZq7Sz\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        18913 * time.Second,\n\t\t\t\t\t\tTTL:                            44743 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 8482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"G79O6Mpr\",\n\t\t\t\t\t\tName:       \"IEqrzrsd\",\n\t\t\t\t\t\tNotes:      \"SVqApqeM\",\n\t\t\t\t\t\tStatus:     \"XXkVoZXt\",\n\t\t\t\t\t\tScriptArgs: []string{\"wD05Bvao\", \"rLYB7kQC\"},\n\t\t\t\t\t\tHTTP:       \"kyICZsn8\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"4ebP5vL4\": {\"G20SrL5Q\", \"DwPKlMbo\"},\n\t\t\t\t\t\t\t\"p2UI34Qz\": {\"UsG1D0Qh\", \"NHhRiB6s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"ciYHWors\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"FfvCwlqH\",\n\t\t\t\t\t\tInterval:                       12356 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"HBndBU6R\",\n\t\t\t\t\t\tShell:                          \"hVI33JjA\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38282 * time.Second,\n\t\t\t\t\t\tTTL:                            1181 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 4992 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"RMi85Dv8\",\n\t\t\t\t\t\tName:       \"iehanzuq\",\n\t\t\t\t\t\tStatus:     \"rCvn53TH\",\n\t\t\t\t\t\tNotes:      \"fti5lfF3\",\n\t\t\t\t\t\tScriptArgs: []string{\"16WRUmwS\", \"QWk7j7ae\"},\n\t\t\t\t\t\tHTTP:       \"dl3Fgme3\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"rjm4DEd3\": {\"2m3m2Fls\"},\n\t\t\t\t\t\t\t\"l4HwQ112\": {\"fk56MNlo\", \"dhLK56aZ\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"9afLm3Mj\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"fjiLFqVd\",\n\t\t\t\t\t\tInterval:                       23926 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"dO5TtRHk\",\n\t\t\t\t\t\tShell:                          \"e6q2ttES\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38483 * time.Second,\n\t\t\t\t\t\tTTL:                            10943 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68787 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEnterpriseMeta: *structs.DefaultEnterpriseMeta(),\n\t\t\t},\n\t\t},\n\t\tSerfAdvertiseAddrLAN: tcpAddr(\"17.99.29.16:8301\"),\n\t\tSerfAdvertiseAddrWAN: tcpAddr(\"78.63.37.19:8302\"),\n\t\tSerfBindAddrLAN:      tcpAddr(\"99.43.63.15:8301\"),\n\t\tSerfBindAddrWAN:      tcpAddr(\"67.88.33.19:8302\"),\n\t\tSessionTTLMin:        26627 * time.Second,\n\t\tSkipLeaveOnInt:       true,\n\t\tStartJoinAddrsLAN:    []string{\"LR3hGDoG\", \"MwVpZ4Up\"},\n\t\tStartJoinAddrsWAN:    []string{\"EbFSc3nA\", \"kwXTh623\"},\n\t\tSyslogFacility:       \"hHv79Uia\",\n\t\tTelemetry: lib.TelemetryConfig{\n\t\t\tCirconusAPIApp:                     \"p4QOTe9j\",\n\t\t\tCirconusAPIToken:                   \"E3j35V23\",\n\t\t\tCirconusAPIURL:                     \"mEMjHpGg\",\n\t\t\tCirconusBrokerID:                   \"BHlxUhed\",\n\t\t\tCirconusBrokerSelectTag:            \"13xy1gHm\",\n\t\t\tCirconusCheckDisplayName:           \"DRSlQR6n\",\n\t\t\tCirconusCheckForceMetricActivation: \"Ua5FGVYf\",\n\t\t\tCirconusCheckID:                    \"kGorutad\",\n\t\t\tCirconusCheckInstanceID:            \"rwoOL6R4\",\n\t\t\tCirconusCheckSearchTag:             \"ovT4hT4f\",\n\t\t\tCirconusCheckTags:                  \"prvO4uBl\",\n\t\t\tCirconusSubmissionInterval:         \"DolzaflP\",\n\t\t\tCirconusSubmissionURL:              \"gTcbS93G\",\n\t\t\tDisableHostname:                    true,\n\t\t\tDogstatsdAddr:                      \"0wSndumK\",\n\t\t\tDogstatsdTags:                      []string{\"3N81zSUB\", \"Xtj8AnXZ\"},\n\t\t\tFilterDefault:                      true,\n\t\t\tAllowedPrefixes:                    []string{\"oJotS8XJ\"},\n\t\t\tBlockedPrefixes:                    []string{\"cazlEhGn\"},\n\t\t\tMetricsPrefix:                      \"ftO6DySn\",\n\t\t\tPrometheusRetentionTime:            15 * time.Second,\n\t\t\tStatsdAddr:                         \"drce87cy\",\n\t\t\tStatsiteAddr:                       \"HpFwKB8R\",\n\t\t},\n\t\tTLSCipherSuites:             []uint16{tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384},\n\t\tTLSMinVersion:               \"pAOWafkR\",\n\t\tTLSPreferServerCipherSuites: true,\n\t\tTaggedAddresses: map[string]string{\n\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\",\n\t\t\t\"lan\":      \"17.99.29.16\",\n\t\t\t\"lan_ipv4\": \"17.99.29.16\",\n\t\t\t\"wan\":      \"78.63.37.19\",\n\t\t\t\"wan_ipv4\": \"78.63.37.19\",\n\t\t},\n\t\tTranslateWANAddrs:    true,\n\t\tUIContentPath:        \"/consul/\",\n\t\tUIDir:                \"11IFzAUn\",\n\t\tUnixSocketUser:       \"E0nB1DwA\",\n\t\tUnixSocketGroup:      \"8pFodrV8\",\n\t\tUnixSocketMode:       \"E8sAwOv4\",\n\t\tVerifyIncoming:       true,\n\t\tVerifyIncomingHTTPS:  true,\n\t\tVerifyIncomingRPC:    true,\n\t\tVerifyOutgoing:       true,\n\t\tVerifyServerHostname: true,\n\t\tWatches: []map[string]interface{}{\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"key\",\n\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\"key\":        \"j9lF1Tve\",\n\t\t\t\t\"handler\":    \"90N7S4LN\",\n\t\t\t},\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"keyprefix\",\n\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\"key\":        \"sl3Dffu7\",\n\t\t\t\t\"args\":       []interface{}{\"dltjDJ2a\", \"flEa7C2d\"},\n\t\t\t},\n\t\t},\n\t\tEnterpriseRuntimeConfig: entFullRuntimeConfig,\n\t}\n\n\twarns := []string{\n\t\t`The 'acl_datacenter' field is deprecated. Use the 'primary_datacenter' field instead.`,\n\t\t`bootstrap_expect > 0: expecting 53 servers`,\n\t}\n\n\t// ensure that all fields are set to unique non-zero values\n\t// todo(fs): This currently fails since ServiceDefinition.Check is not used\n\t// todo(fs): not sure on how to work around this. Possible options are:\n\t// todo(fs):  * move first check into the Check field\n\t// todo(fs):  * ignore the Check field\n\t// todo(fs): both feel like a hack\n\tif err := nonZero(\"RuntimeConfig\", nil, want); err != nil {\n\t\tt.Log(err)\n\t}\n\n\tfor format, data := range src {\n\t\tt.Run(format, func(t *testing.T) {\n\t\t\t// parse the flags since this is the only way we can set the\n\t\t\t// DevMode flag\n\t\t\tvar flags Flags\n\t\t\tfs := flag.NewFlagSet(\"\", flag.ContinueOnError)\n\t\t\tAddFlags(fs, &flags)\n\t\t\tif err := fs.Parse(flagSrc); err != nil {\n\t\t\t\tt.Fatalf(\"ParseFlags: %s\", err)\n\t\t\t}\n\n\t\t\t// ensure that all fields are set to unique non-zero values\n\t\t\t// if err := nonZero(\"Config\", nil, c); err != nil {\n\t\t\t// \tt.Fatal(err)\n\t\t\t// }\n\n\t\t\tb, err := NewBuilder(flags)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"NewBuilder: %s\", err)\n\t\t\t}\n\t\t\tb.Sources = append(b.Sources, Source{Name: \"full.\" + format, Data: data})\n\t\t\tb.Tail = append(b.Tail, tail[format]...)\n\t\t\tb.Tail = append(b.Tail, VersionSource(\"JNtPSav3\", \"R909Hblt\", \"ZT1JOQLn\"))\n\n\t\t\t// construct the runtime config\n\t\t\trt, err := b.Build()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Build: %s\", err)\n\t\t\t}\n\n\t\t\t// verify that all fields are set\n\t\t\tif !verify.Values(t, \"runtime_config\", rt, want) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\n\t\t\t// at this point we have confirmed that the parsing worked\n\t\t\t// for all fields but the validation will fail since certain\n\t\t\t// combinations are not allowed. Since it is not possible to have\n\t\t\t// all fields with non-zero values and to have a valid configuration\n\t\t\t// we are patching a handful of safe fields to make validation pass.\n\t\t\trt.Bootstrap = false\n\t\t\trt.DevMode = false\n\t\t\trt.EnableUI = false\n\t\t\trt.SegmentName = \"\"\n\t\t\trt.Segments = nil\n\n\t\t\t// validate the runtime config\n\t\t\tif err := b.Validate(rt); err != nil {\n\t\t\t\tt.Fatalf(\"Validate: %s\", err)\n\t\t\t}\n\n\t\t\t// check the warnings\n\t\t\tif got, want := b.Warnings, warns; !verify.Values(t, \"warnings\", got, want) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestVerifyX509TrustedIdentities(t *testing.T) {\n\n\tcerts, _ := corex509.ReadCertificateFile(filepath.FromSlash(\"testdata/verifier/signing-cert.pem\")) // cert's subject is \"CN=SomeCN,OU=SomeOU,O=SomeOrg,L=Seattle,ST=WA,C=US\"\n\n\ttests := []struct {\n\t\tx509Identities []string\n\t\twantErr        bool\n\t}{\n\t\t{[]string{\"x509.subject:C=US,O=SomeOrg,ST=WA\"}, false},\n\t\t{[]string{\"x509.subject:C=US,O=SomeOrg,ST=WA\", \"nonX509Prefix:my-custom-identity\"}, false},\n\t\t{[]string{\"x509.subject:C=US,O=SomeOrg,ST=WA\", \"x509.subject:C=IND,O=SomeOrg,ST=TS\"}, false},\n\t\t{[]string{\"nonX509Prefix:my-custom-identity\"}, true},\n\t\t{[]string{\"*\"}, false},\n\t\t{[]string{\"x509.subject:C=IND,O=SomeOrg,ST=TS\"}, true},\n\t\t{[]string{\"x509.subject:C=IND,O=SomeOrg,ST=TS\", \"nonX509Prefix:my-custom-identity\"}, true},\n\t\t{[]string{\"x509.subject:C=IND,O=SomeOrg,ST=TS\", \"x509.subject:C=LOL,O=LOL,ST=LOL\"}, true},\n\t}\n\tfor i, tt := range tests {\n\t\tt.Run(strconv.Itoa(i), func(t *testing.T) {\n\t\t\ttrustPolicy := trustpolicy.TrustPolicy{\n\t\t\t\tName:                  \"test-statement-name\",\n\t\t\t\tRegistryScopes:        []string{\"registry.acme-rockets.io/software/net-monitor\"},\n\t\t\t\tSignatureVerification: trustpolicy.SignatureVerification{VerificationLevel: \"strict\"},\n\t\t\t\tTrustStores:           []string{\"ca:test-store\"},\n\t\t\t\tTrustedIdentities:     tt.x509Identities,\n\t\t\t}\n\t\t\terr := verifyX509TrustedIdentities(certs, &trustPolicy)\n\n\t\t\tif tt.wantErr != (err != nil) {\n\t\t\t\tt.Fatalf(\"TestVerifyX509TrustedIdentities Error: %q WantErr: %v\", err, tt.wantErr)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) TrafficEncoderMap(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.TrafficEncoderMap, error) {\n\tout := new(clientpb.TrafficEncoderMap)\n\terr := c.cc.Invoke(ctx, SliverRPC_TrafficEncoderMap_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockClient) GetResponseTypes() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetResponseTypes\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (m *ProjectManager) ListProjects(ctx context.Context, request admin.ProjectListRequest) (*admin.Projects, error) {\n\tspec := util.FilterSpec{\n\t\tRequestFilters: request.Filters,\n\t}\n\tfilters, err := util.GetDbFilters(spec, common.Project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.ProjectColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif sortParameter == nil {\n\t\tsortParameter = alphabeticalSortParam\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListProjects\", request.Token)\n\t}\n\n\t// And finally, query the database\n\tlistProjectsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\tprojectModels, err := m.db.ProjectRepo().List(ctx, listProjectsInput)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprojects := transformers.FromProjectModels(projectModels, m.getDomains())\n\n\tvar token string\n\tif len(projects) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(projects))\n\t}\n\n\treturn &admin.Projects{\n\t\tProjects: projects,\n\t\tToken:    token,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "\t\tclient.Handlers.Send.PushBack(func(r *request.Request) {\n\t\t\tbodyBytes, err := ioutil.ReadAll(r.Body)\n\t\t\tif err != nil {\n\t\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\t\tStatusCode: 500,\n\t\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(err.Error()))),\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tvar actual s3crypto.Envelope\n\t\t\terr = json.Unmarshal(bodyBytes, &actual)\n\t\t\tif err != nil {\n\t\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\t\tStatusCode: 500,\n\t\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(err.Error()))),\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif e, a := c.expected, actual; !reflect.DeepEqual(e, a) {\n\t\t\t\tt.Errorf(\"expected %v, got %v\", e, a)\n\t\t\t}\n\n\t\t\tr.HTTPResponse = &http.Response{\n\t\t\t\tStatusCode: 200,\n\t\t\t\tBody:       ioutil.NopCloser(bytes.NewReader([]byte(\"\"))),\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func Zero(t TestingT, i interface{}, msgAndArgs ...interface{}) {\n\tif assert.Zero(t, i, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tt.in, func(t *testing.T) {\n\t\t\tvar out model.StringList\n\t\t\tif err := json.Unmarshal([]byte(tt.in), &out); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(out, tt.expect) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.expect, out)\n\t\t\t}\n\t\t\tb, err := json.Marshal(out)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif tt.noRoundTrip {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(string(b), tt.in) {\n\t\t\t\tt.Fatalf(\"Expected %v, got %v\", tt.in, string(b))\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "\tt.Run(\"sanity: Verify with single key\", func(t *testing.T) {\n\t\tkey, err := jwk.ParseKey([]byte(`{\n    \"kty\": \"oct\",\n    \"k\": \"AyM1SysPpbyDfgZld3umj1qzKObwVMkoqQ-EstJQLr_T-1qS0gZH75aKtMN3Yj0iPS4hcgUuTwjAzZr1Z9CAow\"\n  }`))\n\t\tif !assert.NoError(t, err, `jwk.ParseKey should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tpayload, err := jws.Verify([]byte(exampleCompactSerialization), jws.WithKey(jwa.HS256, key))\n\t\tif !assert.NoError(t, err, `jws.Verify should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tif !assert.Equal(t, []byte(examplePayload), payload, `payloads should match`) {\n\t\t\treturn\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func TestProxyFromEmptyContext(t *testing.T) {\n\tproxyUrl, err := proxyFromContext(&http.Request{})\n\n\tassert.NoError(t, err)\n\tassert.Nil(t, proxyUrl)\n}", "is_vulnerable": 0}
{"code": "\treturn iofs.WalkDir(fsys, \".\", func(path string, d iofs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\t// Stop walking if the context is canceled.\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\tinfo, err := d.Info()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif atomic.AddInt64(&size, info.Size())+dirSize > fs.MaxDisk() {\n\t\t\t\treturn newFilesystemError(ErrCodeDiskSpace, nil)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func (m *NinNestedStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinNestedStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinNestedStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field1 == nil {\n\t\t\t\tm.Field1 = &NinOptStruct{}\n\t\t\t}\n\t\t\tif err := m.Field1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field2 = append(m.Field2, &NinRepStruct{})\n\t\t\tif err := m.Field2[len(m.Field2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func InitiateDeviceAuth(sender Sender, oauthConfig OAuthConfig, clientID, resource string) (*DeviceCode, error) {\n\treturn InitiateDeviceAuthWithContext(context.Background(), sender, oauthConfig, clientID, resource)\n}", "is_vulnerable": 0}
{"code": "func (o *LoginOperatorCreated) WithPayload(payload *models.LoginResponse) *LoginOperatorCreated {\n\to.Payload = payload\n\treturn o\n}", "is_vulnerable": 1}
{"code": "\t\t\tprojActions.UpdateProject(func(proj *AppProject) {\n\t\t\t\tproj.Spec.Destinations = nil\n\t\t\t\tproj.Spec.SourceRepos = nil\n\t\t\t})", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn authReq{r}\n}", "is_vulnerable": 1}
{"code": "func TestServer_DeltaAggregatedResources_v3_BasicProtocol_HTTP2(t *testing.T) {\n\taclResolve := func(id string) (acl.Authorizer, error) {\n\t\t// Allow all\n\t\treturn acl.RootAuthorizer(\"manage\"), nil\n\t}\n\tscenario := newTestServerDeltaScenario(t, aclResolve, \"web-sidecar-proxy\", \"\", 0)\n\tmgr, errCh, envoy := scenario.mgr, scenario.errCh, scenario.envoy\n\n\tsid := structs.NewServiceID(\"web-sidecar-proxy\", nil)\n\n\t// Register the proxy to create state needed to Watch() on\n\tmgr.RegisterProxy(t, sid)\n\n\t// Send initial cluster discover (empty payload)\n\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, nil)\n\n\t// Check no response sent yet\n\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t// Deliver a new snapshot (tcp with one http upstream)\n\tsnap := newTestSnapshot(t, nil, \"http2\", &structs.ServiceConfigEntry{\n\t\tKind:     structs.ServiceDefaults,\n\t\tName:     \"db\",\n\t\tProtocol: \"http2\",\n\t})\n\tmgr.DeliverConfig(t, sid, snap)\n\n\ttestutil.RunStep(t, \"no-rds\", func(t *testing.T) {\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ClusterType,\n\t\t\tNonce:   hexString(1),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:local_app\"),\n\t\t\t\tmakeTestCluster(t, snap, \"http2:db\"),\n\t\t\t\tmakeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// Envoy then tries to discover endpoints for those clusters.\n\t\tenvoy.SendDeltaReq(t, xdscommon.EndpointType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t\t\"geo-cache.default.dc1.query.11111111-2222-3333-4444-555555555555.consul\",\n\t\t\t},\n\t\t})\n\n\t\t// We should get a response immediately since the config is already present in\n\t\t// the server for endpoints. Note that this should not be racy if the server\n\t\t// is behaving well since the Cluster send above should be blocked until we\n\t\t// deliver a new config version.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.EndpointType,\n\t\t\tNonce:   hexString(2),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestEndpoints(t, snap, \"http2:db\"),\n\t\t\t\tmakeTestEndpoints(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// After receiving the endpoints Envoy sends an ACK for the clusters\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ClusterType, 1)\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// Envoy now sends listener request\n\t\tenvoy.SendDeltaReq(t, xdscommon.ListenerType, nil)\n\n\t\t// It also (in parallel) issues the endpoint ACK\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.EndpointType, 2)\n\n\t\t// And should get a response immediately.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ListenerType,\n\t\t\tNonce:   hexString(3),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestListener(t, snap, \"tcp:public_listener\"),\n\t\t\t\tmakeTestListener(t, snap, \"http2:db\"),\n\t\t\t\tmakeTestListener(t, snap, \"tcp:geo-cache\"),\n\t\t\t),\n\t\t})\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// ACKs the listener\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ListenerType, 3)\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\t// -- reconfigure with a no-op discovery chain\n\n\tsnap = newTestSnapshot(t, snap, \"http2\", &structs.ServiceConfigEntry{\n\t\tKind:     structs.ServiceDefaults,\n\t\tName:     \"db\",\n\t\tProtocol: \"http2\",\n\t}, &structs.ServiceRouterConfigEntry{\n\t\tKind:   structs.ServiceRouter,\n\t\tName:   \"db\",\n\t\tRoutes: nil,\n\t})\n\tmgr.DeliverConfig(t, sid, snap)\n\n\ttestutil.RunStep(t, \"with-rds\", func(t *testing.T) {\n\t\t// Just the \"db\" listener sees a change\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.ListenerType,\n\t\t\tNonce:   hexString(4),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestListener(t, snap, \"http2:db:rds\"),\n\t\t\t),\n\t\t})\n\n\t\t// We are caught up, so there should be nothing queued to send.\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\n\t\t// Envoy now sends routes request\n\t\tenvoy.SendDeltaReq(t, xdscommon.RouteType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\t\tResourceNamesSubscribe: []string{\n\t\t\t\t\"db\",\n\t\t\t},\n\t\t})\n\n\t\t// And should get a response immediately.\n\t\tassertDeltaResponseSent(t, envoy.deltaStream.sendCh, &envoy_discovery_v3.DeltaDiscoveryResponse{\n\t\t\tTypeUrl: xdscommon.RouteType,\n\t\t\tNonce:   hexString(5),\n\t\t\tResources: makeTestResources(t,\n\t\t\t\tmakeTestRoute(t, \"http2:db\"),\n\t\t\t),\n\t\t})\n\n\t\t// After receiving the routes, Envoy sends acks back for the listener and routes.\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.ListenerType, 4)\n\t\tenvoy.SendDeltaReqACK(t, xdscommon.RouteType, 5)\n\n\t\tassertDeltaChanBlocked(t, envoy.deltaStream.sendCh)\n\t})\n\n\tenvoy.Close()\n\tselect {\n\tcase err := <-errCh:\n\t\trequire.NoError(t, err)\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatalf(\"timed out waiting for handler to finish\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (volCreateRequest VolumeCreateRequest) Validate() error {\n\treturn validation.ValidateStruct(&volCreateRequest,\n\t\tvalidation.Field(&volCreateRequest.Size, validation.Required, validation.Min(1)),\n\t\tvalidation.Field(&volCreateRequest.Clusters, validation.By(ValidateUUID)),\n\t\tvalidation.Field(&volCreateRequest.Name, validation.Match(volumeNameRe)),\n\t\tvalidation.Field(&volCreateRequest.Durability, validation.Skip),\n\t\tvalidation.Field(&volCreateRequest.Gid, validation.Skip),\n\t\tvalidation.Field(&volCreateRequest.GlusterVolumeOptions, validation.Skip),\n\t\t// This is possibly a bug in validation lib, ignore next two lines for now\n\t\t// validation.Field(&volCreateRequest.Snapshot.Enable, validation.In(true, false)),\n\t\t// validation.Field(&volCreateRequest.Snapshot.Factor, validation.Min(1.0)),\n\t)\n}", "is_vulnerable": 0}
{"code": "\treturn func(hostname string, remote net.Addr, key PublicKey) error {\n\t\treturn nil\n\t}", "is_vulnerable": 0}
{"code": "func readBuf(r io.Reader, buf []byte, lim int64) ([]byte, error) {\n\tb := bytes.NewBuffer(buf[:0])\n\t_, err := b.ReadFrom(io.LimitReader(r, lim))\n\treturn b.Bytes(), err\n}", "is_vulnerable": 0}
{"code": "func TestAllocDir_ReadAt_SecretDir(t *testing.T) {\n\ttmp := t.TempDir()\n\n\td := NewAllocDir(testlog.HCLogger(t), tmp)\n\terr := d.Build()\n\trequire.NoError(t, err)\n\tdefer func() {\n\t\t_ = d.Destroy()\n\t}()\n\n\ttd := d.NewTaskDir(t1.Name)\n\terr = td.Build(false, nil)\n\trequire.NoError(t, err)\n\n\t// something to write and test reading\n\ttarget := filepath.Join(t1.Name, TaskSecrets, \"test_file\")\n\n\t// create target file in the task secrets dir\n\tfull := filepath.Join(d.AllocDir, target)\n\terr = ioutil.WriteFile(full, []byte(\"hi\"), 0600)\n\trequire.NoError(t, err)\n\n\t// ReadAt of a file in the task secrets dir should fail\n\t_, err = d.ReadAt(target, 0)\n\trequire.EqualError(t, err, \"Reading secret file prohibited: web/secrets/test_file\")\n}", "is_vulnerable": 0}
{"code": "func (cd *Dispatcher) DispatchLookupResources(req *v1.DispatchLookupResourcesRequest, stream dispatch.LookupResourcesStream) error {\n\tcd.lookupResourcesTotalCounter.Inc()\n\n\tif req.OptionalLimit == 0 {\n\t\treturn spiceerrors.MustBugf(\"a limit must be specified on lookup resources to use with the caching dispatcher\")\n\t}\n\n\trequestKey, err := cd.keyHandler.LookupResourcesCacheKey(stream.Context(), req)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif cachedResultRaw, found := cd.c.Get(requestKey); found {\n\t\tcd.lookupResourcesFromCacheCounter.Inc()\n\t\tfor _, slice := range cachedResultRaw.([][]byte) {\n\t\t\tvar response v1.DispatchLookupResourcesResponse\n\t\t\tif err := response.UnmarshalVT(slice); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := stream.Publish(&response); err != nil {\n\t\t\t\t// don't wrap error with additional context, as it may be a grpc status.Status.\n\t\t\t\t// status.FromError() is unable to unwrap status.Status values, and as a consequence\n\t\t\t\t// the Dispatcher wouldn't properly propagate the gRPC error code\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tvar (\n\t\tmu             sync.Mutex\n\t\ttoCacheResults [][]byte\n\t)\n\twrapped := &dispatch.WrappedDispatchStream[*v1.DispatchLookupResourcesResponse]{\n\t\tStream: stream,\n\t\tCtx:    stream.Context(),\n\t\tProcessor: func(result *v1.DispatchLookupResourcesResponse) (*v1.DispatchLookupResourcesResponse, bool, error) {\n\t\t\tadjustedResult := result.CloneVT()\n\t\t\tadjustedResult.Metadata.CachedDispatchCount = adjustedResult.Metadata.DispatchCount\n\t\t\tadjustedResult.Metadata.DispatchCount = 0\n\t\t\tadjustedResult.Metadata.DebugInfo = nil\n\n\t\t\tadjustedBytes, err := adjustedResult.MarshalVT()\n\t\t\tif err != nil {\n\t\t\t\treturn &v1.DispatchLookupResourcesResponse{Metadata: &v1.ResponseMeta{}}, false, err\n\t\t\t}\n\n\t\t\tmu.Lock()\n\t\t\ttoCacheResults = append(toCacheResults, adjustedBytes)\n\t\t\tmu.Unlock()\n\n\t\t\treturn result, true, nil\n\t\t},\n\t}\n\n\tif err := cd.d.DispatchLookupResources(req, wrapped); err != nil {\n\t\treturn err\n\t}\n\n\tvar size int64\n\tfor _, slice := range toCacheResults {\n\t\tsize += sliceSize(slice)\n\t}\n\n\tcd.c.Set(requestKey, toCacheResults, size)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Events(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (SliverRPC_EventsClient, error) {\n\tstream, err := c.cc.NewStream(ctx, &SliverRPC_ServiceDesc.Streams[5], \"/rpcpb.SliverRPC/Events\", opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tx := &sliverRPCEventsClient{stream}\n\tif err := x.ClientStream.SendMsg(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := x.ClientStream.CloseSend(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn x, nil\n}", "is_vulnerable": 0}
{"code": "func TestBlocksStoreQuerier_Labels(t *testing.T) {\n\tt.Parallel()\n\n\tconst (\n\t\tmetricName = \"test_metric\"\n\t\tminT       = int64(10)\n\t\tmaxT       = int64(20)\n\t)\n\n\tvar (\n\t\tblock1  = ulid.MustNew(1, nil)\n\t\tblock2  = ulid.MustNew(2, nil)\n\t\tblock3  = ulid.MustNew(3, nil)\n\t\tblock4  = ulid.MustNew(4, nil)\n\t\tseries1 = labels.FromMap(map[string]string{\n\t\t\tlabels.MetricName: metricName + \"_1\",\n\t\t\t\"series1\":         \"1\",\n\t\t})\n\t\tseries2 = labels.FromMap(map[string]string{\n\t\t\tlabels.MetricName: metricName + \"_2\",\n\t\t\t\"series2\":         \"1\",\n\t\t})\n\t)\n\n\ttests := map[string]struct {\n\t\tfinderResult        bucketindex.Blocks\n\t\tfinderErr           error\n\t\tstoreSetResponses   []interface{}\n\t\texpectedLabelNames  []string\n\t\texpectedLabelValues []string // For __name__\n\t\texpectedErr         string\n\t\texpectedMetrics     string\n\t}{\n\t\t\"no block in the storage matching the query time range\": {\n\t\t\tfinderResult: nil,\n\t\t\texpectedErr:  \"\",\n\t\t},\n\t\t\"error while finding blocks matching the query time range\": {\n\t\t\tfinderErr:   errors.New(\"unable to find blocks\"),\n\t\t\texpectedErr: \"unable to find blocks\",\n\t\t},\n\t\t\"error while getting clients to query the store-gateway\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\terrors.New(\"no client found\"),\n\t\t\t},\n\t\t\texpectedErr: \"no client found\",\n\t\t},\n\t\t\"a single store-gateway instance holds the required blocks\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1, block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1, block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1, block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks without overlapping series\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks with overlapping series (single returned series)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1),\n\t\t},\n\t\t\"multiple store-gateway instances holds the required blocks with overlapping series (multiple returned series)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\t// Block1 has series1 and series2\n\t\t\t// Block2 has only series1\n\t\t\t// Block3 has only series2\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"3.3.3.3\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block3},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\texpectedMetrics: `\n\t\t\t\t# HELP cortex_querier_storegateway_instances_hit_per_query Number of store-gateway instances hit for a single query.\n\t\t\t\t# TYPE cortex_querier_storegateway_instances_hit_per_query histogram\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"2\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"3\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"4\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"5\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"6\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"7\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"8\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"9\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"10\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_sum 3\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_count 1\n\n\t\t\t\t# HELP cortex_querier_storegateway_refetches_per_query Number of re-fetches attempted while querying store-gateway instances due to missing blocks.\n\t\t\t\t# TYPE cortex_querier_storegateway_refetches_per_query histogram\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"0\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"1\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"2\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_sum 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_count 1\n\t\t\t`,\n\t\t},\n\t\t\"a single store-gateway instance has some missing blocks (consistency check failed)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns an error because there are no other store-gateways left.\n\t\t\t\terrors.New(\"no store-gateway remaining after exclude\"),\n\t\t\t},\n\t\t\texpectedErr: fmt.Sprintf(\"consistency check failed because some blocks were not queried: %s\", block2.String()),\n\t\t},\n\t\t\"multiple store-gateway instances have some missing blocks (consistency check failed)\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t\t{ID: block3},\n\t\t\t\t{ID: block4},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns an error because there are no other store-gateways left.\n\t\t\t\terrors.New(\"no store-gateway remaining after exclude\"),\n\t\t\t},\n\t\t\texpectedErr: fmt.Sprintf(\"consistency check failed because some blocks were not queried: %s %s\", block3.String(), block4.String()),\n\t\t},\n\t\t\"multiple store-gateway instances have some missing blocks but queried from a replica during subsequent attempts\": {\n\t\t\t// Block1 has series1\n\t\t\t// Block2 has series2\n\t\t\t// Block3 has series1 and series2\n\t\t\t// Block4 has no series (poor lonely block)\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t\t{ID: block2},\n\t\t\t\t{ID: block3},\n\t\t\t\t{ID: block4},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\t// First attempt returns a client whose response does not include all expected blocks.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1, block3},\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block2),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block2, block4},\n\t\t\t\t},\n\t\t\t\t// Second attempt returns 1 missing block.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"3.3.3.3\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block3),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block3, block4},\n\t\t\t\t},\n\t\t\t\t// Third attempt returns the last missing block.\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"4.4.4.4\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    []string{},\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block4),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   []string{},\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block4),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block4},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1, series2),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1, series2),\n\t\t\texpectedMetrics: `\n\t\t\t\t# HELP cortex_querier_storegateway_instances_hit_per_query Number of store-gateway instances hit for a single query.\n\t\t\t\t# TYPE cortex_querier_storegateway_instances_hit_per_query histogram\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"2\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"3\"} 0\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"4\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"5\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"6\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"7\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"8\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"9\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"10\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_sum 4\n\t\t\t\tcortex_querier_storegateway_instances_hit_per_query_count 1\n\n\t\t\t\t# HELP cortex_querier_storegateway_refetches_per_query Number of re-fetches attempted while querying store-gateway instances due to missing blocks.\n\t\t\t\t# TYPE cortex_querier_storegateway_refetches_per_query histogram\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"0\"} 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"1\"} 0\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"2\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_bucket{le=\"+Inf\"} 1\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_sum 2\n\t\t\t\tcortex_querier_storegateway_refetches_per_query_count 1\n\t\t\t`,\n\t\t},\n\t\t\"multiple store-gateways has the block, but one of them fails to return\": {\n\t\t\tfinderResult: bucketindex.Blocks{\n\t\t\t\t{ID: block1},\n\t\t\t},\n\t\t\tstoreSetResponses: []interface{}{\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"1.1.1.1\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesErr: status.Error(codes.Unavailable, \"unavailable\"),\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t\tmap[BlocksStoreClient][]ulid.ULID{\n\t\t\t\t\t&storeGatewayClientMock{\n\t\t\t\t\t\tremoteAddr: \"2.2.2.2\",\n\t\t\t\t\t\tmockedLabelNamesResponse: &storepb.LabelNamesResponse{\n\t\t\t\t\t\t\tNames:    namesFromSeries(series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockNamesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tmockedLabelValuesResponse: &storepb.LabelValuesResponse{\n\t\t\t\t\t\t\tValues:   valuesFromSeries(labels.MetricName, series1),\n\t\t\t\t\t\t\tWarnings: []string{},\n\t\t\t\t\t\t\tHints:    mockValuesHints(block1),\n\t\t\t\t\t\t},\n\t\t\t\t\t}: {block1},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectedLabelNames:  namesFromSeries(series1),\n\t\t\texpectedLabelValues: valuesFromSeries(labels.MetricName, series1),\n\t\t},\n\t}\n\n\tfor testName, testData := range tests {\n\t\ttestData := testData\n\t\tt.Run(testName, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\t// Splitting it because we need a new registry for names and values.\n\t\t\t// And also the initial expectedErr checking needs to be done for both.\n\t\t\tfor _, testFunc := range []string{\"LabelNames\", \"LabelValues\"} {\n\t\t\t\tctx := user.InjectOrgID(context.Background(), \"user-1\")\n\t\t\t\treg := prometheus.NewPedanticRegistry()\n\t\t\t\tstores := &blocksStoreSetMock{mockedResponses: testData.storeSetResponses}\n\t\t\t\tfinder := &blocksFinderMock{}\n\t\t\t\tfinder.On(\"GetBlocks\", mock.Anything, \"user-1\", minT, maxT).Return(testData.finderResult, map[ulid.ULID]*bucketindex.BlockDeletionMark(nil), testData.finderErr)\n\n\t\t\t\tq := &blocksStoreQuerier{\n\t\t\t\t\tminT:        minT,\n\t\t\t\t\tmaxT:        maxT,\n\t\t\t\t\tfinder:      finder,\n\t\t\t\t\tstores:      stores,\n\t\t\t\t\tconsistency: NewBlocksConsistencyChecker(0, 0, log.NewNopLogger(), nil),\n\t\t\t\t\tlogger:      log.NewNopLogger(),\n\t\t\t\t\tmetrics:     newBlocksStoreQueryableMetrics(reg),\n\t\t\t\t\tlimits:      &blocksStoreLimitsMock{},\n\t\t\t\t}\n\n\t\t\t\tif testFunc == \"LabelNames\" {\n\t\t\t\t\tnames, warnings, err := q.LabelNames(ctx)\n\t\t\t\t\tif testData.expectedErr != \"\" {\n\t\t\t\t\t\trequire.Equal(t, testData.expectedErr, err.Error())\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.Equal(t, 0, len(warnings))\n\t\t\t\t\trequire.Equal(t, testData.expectedLabelNames, names)\n\n\t\t\t\t\t// Assert on metrics (optional, only for test cases defining it).\n\t\t\t\t\tif testData.expectedMetrics != \"\" {\n\t\t\t\t\t\tassert.NoError(t, testutil.GatherAndCompare(reg, strings.NewReader(testData.expectedMetrics)))\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif testFunc == \"LabelValues\" {\n\t\t\t\t\tvalues, warnings, err := q.LabelValues(ctx, labels.MetricName)\n\t\t\t\t\tif testData.expectedErr != \"\" {\n\t\t\t\t\t\trequire.Equal(t, testData.expectedErr, err.Error())\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.Equal(t, 0, len(warnings))\n\t\t\t\t\trequire.Equal(t, testData.expectedLabelValues, values)\n\n\t\t\t\t\t// Assert on metrics (optional, only for test cases defining it).\n\t\t\t\t\tif testData.expectedMetrics != \"\" {\n\t\t\t\t\t\tassert.NoError(t, testutil.GatherAndCompare(reg, strings.NewReader(testData.expectedMetrics)))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdoc, err := query.Parse(tc.query)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tcontext := newContext(s, doc, tc.maxDepth)\n\t\t\top := doc.Operations[0]\n\n\t\t\topc := &opContext{context: context, ops: doc.Operations}\n\n\t\t\tactual := validateMaxDepth(opc, op.Selections, 1)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"expected %t, actual %t\", tc.expected, actual)\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func newTestSnapshot(\n\tt *testing.T,\n\tprevSnap *proxycfg.ConfigSnapshot,\n\tdbServiceProtocol string,\n\tnsFn func(ns *structs.NodeService),\n\tadditionalEntries ...structs.ConfigEntry,\n) *proxycfg.ConfigSnapshot {\n\tsnap := proxycfg.TestConfigSnapshotDiscoveryChain(t, \"default\", false, nsFn, nil, additionalEntries...)\n\tsnap.ConnectProxy.PreparedQueryEndpoints = map[proxycfg.UpstreamID]structs.CheckServiceNodes{\n\t\tUID(\"prepared_query:geo-cache\"): proxycfg.TestPreparedQueryNodes(t, \"geo-cache\"),\n\t}\n\tif prevSnap != nil {\n\t\tsnap.Roots = prevSnap.Roots\n\t\tsnap.ConnectProxy.Leaf = prevSnap.ConnectProxy.Leaf\n\t}\n\tif dbServiceProtocol != \"\" {\n\t\t// Simulate ServiceManager injection of protocol\n\t\tsnap.Proxy.Upstreams[0].Config[\"protocol\"] = dbServiceProtocol\n\t\tsnap.ConnectProxy.ConfigSnapshotUpstreams.UpstreamConfig = proxycfg.UpstreamsToMap(snap.Proxy.Upstreams)\n\t}\n\treturn snap\n}", "is_vulnerable": 0}
{"code": "func (VDEAgentChainInfo) TableName() string {\r\n\treturn \"vde_agent_chain_info\"\r\n}\r", "is_vulnerable": 0}
{"code": "func TestListObjects_UnhappyPaths(t *testing.T) {\n\tctx := context.Background()\n\tlogger := logger.NewNoopLogger()\n\ttransport := gateway.NewNoopTransport()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgapb.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_1,\n\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"document\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"viewer\": typesystem.This(),\n\t\t\t\t},\n\t\t\t\tMetadata: &openfgapb.Metadata{\n\t\t\t\t\tRelations: map[string]*openfgapb.RelationMetadata{\n\t\t\t\t\t\t\"viewer\": {\n\t\t\t\t\t\t\tDirectlyRelatedUserTypes: []*openfgapb.RelationReference{\n\t\t\t\t\t\t\t\ttypesystem.DirectRelationReference(\"user\", \"\"),\n\t\t\t\t\t\t\t\ttypesystem.WildcardRelationReference(\"user\"),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, storage.ReadStartingWithUserFilter{\n\t\tObjectType: \"document\",\n\t\tRelation:   \"viewer\",\n\t\tUserFilter: []*openfgapb.ObjectRelation{\n\t\t\t{Object: \"user:*\"},\n\t\t\t{Object: \"user:bob\"},\n\t\t}}).AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := New(&Dependencies{\n\t\tDatastore: mockDatastore,\n\t\tTransport: transport,\n\t\tLogger:    logger,\n\t}, &Config{\n\t\tResolveNodeLimit:      test.DefaultResolveNodeLimit,\n\t\tListObjectsDeadline:   5 * time.Second,\n\t\tListObjectsMaxResults: 1000,\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_non-streaming_version\", func(t *testing.T) {\n\t\tres, err := s.ListObjects(ctx, &openfgapb.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t})\n\n\t\trequire.Nil(t, res)\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n\n\tt.Run(\"error_listing_objects_from_storage_in_streaming_version\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgapb.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"document\",\n\t\t\tRelation:             \"viewer\",\n\t\t\tUser:                 \"user:bob\",\n\t\t}, NewMockStreamServer())\n\n\t\trequire.ErrorIs(t, err, serverErrors.NewInternalError(\"\", errors.New(\"error reading from storage\")))\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *LocalChecker) checkComputedUserset(parentctx context.Context, req *ResolveCheckRequest, rewrite *openfgav1.Userset_ComputedUserset) CheckHandlerFunc {\n\treturn func(ctx context.Context) (*ResolveCheckResponse, error) {\n\t\tctx, span := tracer.Start(ctx, \"checkComputedUserset\")\n\t\tdefer span.End()\n\n\t\treturn c.dispatch(\n\t\t\tctx,\n\t\t\t&ResolveCheckRequest{\n\t\t\t\tStoreID:              req.GetStoreID(),\n\t\t\t\tAuthorizationModelID: req.GetAuthorizationModelID(),\n\t\t\t\tTupleKey: tuple.NewTupleKey(\n\t\t\t\t\treq.TupleKey.GetObject(),\n\t\t\t\t\trewrite.ComputedUserset.GetRelation(),\n\t\t\t\t\treq.TupleKey.GetUser(),\n\t\t\t\t),\n\t\t\t\tResolutionMetadata: &ResolutionMetadata{\n\t\t\t\t\tDepth:               req.GetResolutionMetadata().Depth - 1,\n\t\t\t\t\tDatastoreQueryCount: req.GetResolutionMetadata().DatastoreQueryCount,\n\t\t\t\t},\n\t\t\t})(ctx)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *nativeHelmChart) GetIndex(noCache bool, maxIndexSize int64) (*Index, error) {", "is_vulnerable": 0}
{"code": "func TestWithoutAnnotations(t *testing.T) {\n\ting := buildIngress()\n\t_, err := NewParser(mockBackend{}).Parse(ing)\n\tif err != nil {\n\t\tt.Error(\"unexpected error with ingress without annotations\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (va ClawbackVestingAccount) GetUnlockedVestedCoins(blockTime time.Time) sdk.Coins {\n\tcoins := va.GetUnlockedCoins(blockTime).Min(va.GetVestedCoins(blockTime))\n\tif coins.IsZero() {\n\t\treturn sdk.Coins{}\n\t}\n\treturn coins\n}", "is_vulnerable": 0}
{"code": "\terr := wait.PollImmediate(5*time.Second, 5*time.Minute, func() (bool, error) {\n\t\tservice := &corev1.Service{}\n\t\tif err := kclient.Get(context.TODO(), controller.LoadBalancerServiceName(ic), service); err != nil {\n\t\t\tif errors.IsNotFound(err) {\n\t\t\t\treturn false, nil\n\t\t\t} else {\n\t\t\t\tt.Logf(\"failed to get ingresscontroller %s: %v\", name.Name, err)\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t}\n\t\tif isServiceInternal(service) {\n\t\t\treturn true, nil\n\t\t}\n\t\tt.Logf(\"service is still external: %#v\\n\", service)\n\t\treturn false, nil\n\t})", "is_vulnerable": 1}
{"code": "func (context *DatabaseContext) QueryRoleAccess(username string) (sgbucket.QueryResultIterator, error) {\n\n\t// View Query\n\tif context.Options.UseViews {\n\t\topts := map[string]interface{}{\"stale\": false, \"key\": username}\n\t\treturn context.ViewQueryWithStats(DesignDocSyncGateway(), ViewRoleAccess, opts)\n\t}\n\n\t// N1QL Query\n\tif username == \"\" {\n\t\tbase.Warnf(base.KeyAll, \"QueryRoleAccess called with empty username\")\n\t\treturn &EmptyResultIterator{}, nil\n\t}\n\n\taccessQueryStatement := context.buildRoleAccessQuery(username)\n\tparams := make(map[string]interface{}, 0)\n\tparams[QueryParamUserName] = username\n\treturn context.N1QLQueryWithStats(QueryTypeRoleAccess, accessQueryStatement, params, gocb.RequestPlus, QueryRoleAccess.adhoc)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) StartServiceByName(ctx context.Context, in *sliverpb.StartServiceByNameReq, opts ...grpc.CallOption) (*sliverpb.ServiceInfo, error) {\n\tout := new(sliverpb.ServiceInfo)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/StartServiceByName\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (s *StateDB) fastDeleteStorage(addrHash common.Hash, root common.Hash) (bool, common.StorageSize, map[common.Hash][]byte, *trienode.NodeSet, error) {\n\titer, err := s.snaps.StorageIterator(s.originalRoot, addrHash, common.Hash{})\n\tif err != nil {\n\t\treturn false, 0, nil, nil, err\n\t}\n\tdefer iter.Release()\n\n\tvar (\n\t\tsize  common.StorageSize\n\t\tnodes = trienode.NewNodeSet(addrHash)\n\t\tslots = make(map[common.Hash][]byte)\n\t)\n\tstack := trie.NewStackTrie(func(path []byte, hash common.Hash, blob []byte) {\n\t\tnodes.AddNode(path, trienode.NewDeleted())\n\t\tsize += common.StorageSize(len(path))\n\t})\n\tfor iter.Next() {\n\t\tif size > storageDeleteLimit {\n\t\t\treturn true, size, nil, nil, nil\n\t\t}\n\t\tslot := common.CopyBytes(iter.Slot())\n\t\tif err := iter.Error(); err != nil { // error might occur after Slot function\n\t\t\treturn false, 0, nil, nil, err\n\t\t}\n\t\tsize += common.StorageSize(common.HashLength + len(slot))\n\t\tslots[iter.Hash()] = slot\n\n\t\tif err := stack.Update(iter.Hash().Bytes(), slot); err != nil {\n\t\t\treturn false, 0, nil, nil, err\n\t\t}\n\t}\n\tif err := iter.Error(); err != nil { // error might occur during iteration\n\t\treturn false, 0, nil, nil, err\n\t}\n\tif stack.Hash() != root {\n\t\treturn false, 0, nil, nil, fmt.Errorf(\"snapshot is not matched, exp %x, got %x\", root, stack.Hash())\n\t}\n\treturn false, size, slots, nodes, nil\n}", "is_vulnerable": 0}
{"code": "func main() {\n\tvar (\n\t\tcfg                  cortex.Config\n\t\teventSampleRate      int\n\t\tballastBytes         int\n\t\tmutexProfileFraction int\n\t\tblockProfileRate     int\n\t\tprintVersion         bool\n\t\tprintModules         bool\n\t)\n\n\targs := os.Args[1:]\n\tconfigFile, expandENV := parseConfigFileParameter(args)\n\n\t// This sets default values from flags to the config.\n\t// It needs to be called before parsing the config file!\n\tflagext.RegisterFlags(&cfg)\n\n\tif configFile != \"\" {\n\t\tif err := LoadConfig(configFile, expandENV, &cfg); err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"error loading config from %s: %v\\n\", configFile, err)\n\t\t\tif testMode {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tos.Exit(1)\n\t\t}\n\t} else if len(args) == 0 {\n\t\tfmt.Fprintf(os.Stderr, \"please set configuration file. For example: -config.file=./docs/configuration/single-process-config-blocks-local.yaml\\n\")\n\t\tif testMode {\n\t\t\treturn\n\t\t}\n\t\tos.Exit(1)\n\t}\n\n\t// Ignore -config.file and -config.expand-env here, since it was already parsed, but it's still present on command line.\n\tflagext.IgnoredFlag(flag.CommandLine, configFileOption, \"Configuration file to load.\")\n\t_ = flag.CommandLine.Bool(configExpandENV, false, \"Expands ${var} or $var in config according to the values of the environment variables.\")\n\n\tflag.IntVar(&eventSampleRate, \"event.sample-rate\", 0, \"How often to sample observability events (0 = never).\")\n\tflag.IntVar(&ballastBytes, \"mem-ballast-size-bytes\", 0, \"Size of memory ballast to allocate.\")\n\tflag.IntVar(&mutexProfileFraction, \"debug.mutex-profile-fraction\", 0, \"Fraction of mutex contention events that are reported in the mutex profile. On average 1/rate events are reported. 0 to disable.\")\n\tflag.IntVar(&blockProfileRate, \"debug.block-profile-rate\", 0, \"Fraction of goroutine blocking events that are reported in the blocking profile. 1 to include every blocking event in the profile, 0 to disable.\")\n\tflag.BoolVar(&printVersion, \"version\", false, \"Print Cortex version and exit.\")\n\tflag.BoolVar(&printModules, \"modules\", false, \"List available values that can be used as target.\")\n\n\tusage := flag.CommandLine.Usage\n\tflag.CommandLine.Usage = func() { /* don't do anything by default, we will print usage ourselves, but only when requested. */ }\n\tflag.CommandLine.Init(flag.CommandLine.Name(), flag.ContinueOnError)\n\n\terr := flag.CommandLine.Parse(os.Args[1:])\n\tif err == flag.ErrHelp {\n\t\t// Print available parameters to stdout, so that users can grep/less it easily.\n\t\tflag.CommandLine.SetOutput(os.Stdout)\n\t\tusage()\n\t\tif !testMode {\n\t\t\tos.Exit(2)\n\t\t}\n\t} else if err != nil {\n\t\tfmt.Fprintln(flag.CommandLine.Output(), \"Run with -help to get list of available parameters\")\n\t\tif !testMode {\n\t\t\tos.Exit(2)\n\t\t}\n\t}\n\n\tif printVersion {\n\t\tfmt.Fprintln(os.Stdout, version.Print(\"Cortex\"))\n\t\treturn\n\t}\n\n\t// Validate the config once both the config file has been loaded\n\t// and CLI flags parsed.\n\terr = cfg.Validate(util_log.Logger)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"error validating config: %v\\n\", err)\n\t\tif !testMode {\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\t// Continue on if -modules flag is given. Code handling the\n\t// -modules flag will not start cortex.\n\tif testMode && !printModules {\n\t\tDumpYaml(&cfg)\n\t\treturn\n\t}\n\n\tif mutexProfileFraction > 0 {\n\t\truntime.SetMutexProfileFraction(mutexProfileFraction)\n\t}\n\tif blockProfileRate > 0 {\n\t\truntime.SetBlockProfileRate(blockProfileRate)\n\t}\n\n\tutil_log.InitLogger(&cfg.Server)\n\n\t// Allocate a block of memory to alter GC behaviour. See https://github.com/golang/go/issues/23044\n\tballast := make([]byte, ballastBytes)\n\n\tutil.InitEvents(eventSampleRate)\n\n\tctx, cancelFn := context.WithCancel(context.Background())\n\t// In testing mode skip tracing setup to avoid panic due to\n\t// \"duplicate metrics collector registration attempted\"\n\tif !testMode {\n\t\tname := \"cortex\"\n\t\tif len(cfg.Target) == 1 {\n\t\t\tname += \"-\" + cfg.Target[0]\n\t\t}\n\n\t\tif close, err := tracing.SetupTracing(ctx, name, cfg.Tracing); err != nil {\n\t\t\tlevel.Error(util_log.Logger).Log(\"msg\", \"Failed to setup tracing\", \"err\", err.Error())\n\t\t} else {\n\t\t\tdefer close(ctx) // nolint:errcheck\n\t\t}\n\t}\n\n\t// Initialise seed for randomness usage.\n\trand.New(rand.NewSource(time.Now().UnixNano()))\n\n\tt, err := cortex.New(cfg)\n\tutil_log.CheckFatal(\"initializing cortex\", err)\n\n\tif printModules {\n\t\tallDeps := t.ModuleManager.DependenciesForModule(cortex.All)\n\n\t\tfor _, m := range t.ModuleManager.UserVisibleModuleNames() {\n\t\t\tix := sort.SearchStrings(allDeps, m)\n\t\t\tincluded := ix < len(allDeps) && allDeps[ix] == m\n\n\t\t\tif included {\n\t\t\t\tfmt.Fprintln(os.Stdout, m, \"*\")\n\t\t\t} else {\n\t\t\t\tfmt.Fprintln(os.Stdout, m)\n\t\t\t}\n\t\t}\n\n\t\tfmt.Fprintln(os.Stdout)\n\t\tfmt.Fprintln(os.Stdout, \"Modules marked with * are included in target All.\")\n\t\treturn\n\t}\n\n\tlevel.Info(util_log.Logger).Log(\"msg\", \"Starting Cortex\", \"version\", version.Info())\n\n\terr = t.Run()\n\tcancelFn()\n\n\truntime.KeepAlive(ballast)\n\tutil_log.CheckFatal(\"running cortex\", err)\n}", "is_vulnerable": 0}
{"code": "func getMatchingPolicies(store cache.Store, user user.Info, sa user.Info, authz authorizer.Authorizer) ([]*extensions.PodSecurityPolicy, error) {\n\tmatchedPolicies := make([]*extensions.PodSecurityPolicy, 0)\n\n\tfor _, c := range store.List() {\n\t\tconstraint, ok := c.(*extensions.PodSecurityPolicy)\n\t\tif !ok {\n\t\t\treturn nil, errors.NewInternalError(fmt.Errorf(\"error converting object from store to a pod security policy: %v\", c))\n\t\t}\n\n\t\tif authorizedForPolicy(user, constraint, authz) || authorizedForPolicy(sa, constraint, authz) {\n\t\t\tmatchedPolicies = append(matchedPolicies, constraint)\n\t\t}\n\t}\n\n\treturn matchedPolicies, nil\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetClient() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetClient\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetClient))\n}", "is_vulnerable": 0}
{"code": "func (m *Mount) IsBind() bool {\n\treturn m.Flags&unix.MS_BIND != 0\n}", "is_vulnerable": 0}
{"code": "func (a *AccountClaims) IsRevoked(_ string) bool {\n\treturn true\n}", "is_vulnerable": 0}
{"code": "\tds.UserByIDFunc = func(ctx context.Context, id uint) (*fleet.User, error) {\n\t\tswitch id {\n\t\tcase userTeamMaintainerID:\n\t\t\treturn &fleet.User{\n\t\t\t\tID:    userTeamMaintainerID,\n\t\t\t\tTeams: []fleet.UserTeam{{Team: fleet.Team{ID: 1}, Role: fleet.RoleMaintainer}},\n\t\t\t}, nil\n\t\tcase userGlobalMaintainerID:\n\t\t\treturn &fleet.User{\n\t\t\t\tID:         userGlobalMaintainerID,\n\t\t\t\tGlobalRole: ptr.String(fleet.RoleMaintainer),\n\t\t\t}, nil\n\t\tdefault:\n\t\t\treturn self, nil\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func (r *MySQL) Probe() (bool, string) {\n\n\tif r.tls != nil {\n\t\tmysql.RegisterTLSConfig(global.DefaultProg, r.tls)\n\t}\n\n\tdb, err := sql.Open(\"mysql\", r.ConnStr)\n\tif err != nil {\n\t\treturn false, err.Error()\n\t}\n\tdefer db.Close()\n\n\t// Check if we need to query specific data\n\tif len(r.Data) > 0 {\n\t\tif err := r.ProbeWithDataVerification(db); err != nil {\n\t\t\treturn false, err.Error()\n\t\t}\n\t} else {\n\t\tif err := r.ProbeWithPing(db); err != nil {\n\t\t\treturn false, err.Error()\n\t\t}\n\t}\n\n\treturn true, \"Check MySQL Server Successfully!\"\n\n}", "is_vulnerable": 0}
{"code": "func ensureBridge(brName string, mtu int, promiscMode, vlanFiltering bool) (*netlink.Bridge, error) {\n\tbr := &netlink.Bridge{\n\t\tLinkAttrs: netlink.LinkAttrs{\n\t\t\tName: brName,\n\t\t\tMTU:  mtu,\n\t\t\t// Let kernel use default txqueuelen; leaving it unset\n\t\t\t// means 0, and a zero-length TX queue messes up FIFO\n\t\t\t// traffic shapers which use TX queue length as the\n\t\t\t// default packet limit\n\t\t\tTxQLen: -1,\n\t\t},\n\t}\n\tif vlanFiltering {\n\t\tbr.VlanFiltering = &vlanFiltering\n\t}\n\n\terr := netlink.LinkAdd(br)\n\tif err != nil && err != syscall.EEXIST {\n\t\treturn nil, fmt.Errorf(\"could not add %q: %v\", brName, err)\n\t}\n\n\tif promiscMode {\n\t\tif err := netlink.SetPromiscOn(br); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"could not set promiscuous mode on %q: %v\", brName, err)\n\t\t}\n\t}\n\n\t// Re-fetch link to read all attributes and if it already existed,\n\t// ensure it's really a bridge with similar configuration\n\tbr, err = bridgeByName(brName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// we want to own the routes for this interface\n\t_, _ = sysctl.Sysctl(fmt.Sprintf(\"net/ipv6/conf/%s/accept_ra\", brName), \"0\")\n\n\tif err := netlink.LinkSetUp(br); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn br, nil\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) SetDiskLimit(i int64) {\n\tfs.unixFS.SetLimit(i)\n}", "is_vulnerable": 0}
{"code": "func TestRelPath(t *testing.T) {\n\troot := `/tmp/fakedata`\n\ttt := [][2]string{\n\t\t{\n\t\t\t\"dev/null\",\n\t\t\t\"/dev/null\",\n\t\t},\n\t\t{\n\t\t\t\"dev/null\",\n\t\t\t\"./dev/null\",\n\t\t},\n\t\t{\n\t\t\t\"dev/null\",\n\t\t\t\"dev/null\",\n\t\t},\n\t\t{\n\t\t\t\"dev/null\",\n\t\t\tstrings.Repeat(\"../\", 10) + \"dev/null\",\n\t\t},\n\t\t{\n\t\t\t\"dev/null\",\n\t\t\tstrings.Repeat(\"../\", 10) + \"dev/./../dev/null\",\n\t\t},\n\t}\n\n\tfor _, tc := range tt {\n\t\twant := filepath.Join(root, tc[0])\n\t\tt.Logf(\"in: %q + %q\", root, tc[1])\n\t\tgot := relPath(root, tc[1])\n\t\tt.Logf(\"got: %q, want: %q\", got, want)\n\t\tif got != want {\n\t\t\tt.Error()\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetLatestVersion() (string, error) {\n\t// curl https://kubeedge.io/latestversion\n\tresp, err := http.Get(latestReleaseVersionURL)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to get latest version from %s: %v\", latestReleaseVersionURL, err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn \"\", fmt.Errorf(\"failed to get latest version from %s, expected %d, got status code: %d\", latestReleaseVersionURL, http.StatusOK, resp.StatusCode)\n\t}\n\tbody, err := io.ReadAll(io.LimitReader(resp.Body, constants.MaxRespBodyLength))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(body), nil\n}", "is_vulnerable": 0}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"projects can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gitlab.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Gitlab)\n\n\tfor name, value := range eventSource.Spec.Gitlab {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tGitlabEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockCoreStrategyMockRecorder) GenerateRefreshToken(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GenerateRefreshToken\", reflect.TypeOf((*MockCoreStrategy)(nil).GenerateRefreshToken), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func InitV1Router() *gin.Engine {\n\tginMode := gin.ReleaseMode\n\tif config.ServerInfo.RunMode != \"\" {\n\t\tginMode = config.ServerInfo.RunMode\n\t}\n\tif os.Getenv(gin.EnvGinMode) != \"\" {\n\t\tginMode = os.Getenv(gin.EnvGinMode)\n\t}\n\tgin.SetMode(ginMode)\n\n\tr := gin.New()\n\tr.Use(gin.Recovery())\n\tr.Use(middleware.Cors())\n\tr.Use(gzip.Gzip(gzip.DefaultCompression))\n\tif ginMode != gin.ReleaseMode {\n\t\tr.Use(middleware.WriteLog())\n\t}\n\n\tr.GET(\"/v1/sys/debug\", v1.GetSystemConfigDebug) // //debug\n\n\tr.GET(\"/v1/sys/version/check\", v1.GetSystemCheckVersion)\n\tr.GET(\"/ping\", func(ctx *gin.Context) {\n\t\tctx.String(200, \"pong\")\n\t})\n\tr.GET(\"/v1/recover/:type\", v1.GetRecoverStorage)\n\tv1Group := r.Group(\"/v1\")\n\n\tv1Group.Use(jwt.JWT(\n\t\tfunc() (*ecdsa.PublicKey, error) {\n\t\t\treturn external.GetPublicKey(config.CommonInfo.RuntimePath)\n\t\t},\n\t))\n\t{\n\n\t\tv1SysGroup := v1Group.Group(\"/sys\")\n\t\tv1SysGroup.Use()\n\t\t{\n\t\t\tv1SysGroup.GET(\"/version\", v1.GetSystemCheckVersion) // version/check\n\n\t\t\tv1SysGroup.POST(\"/update\", v1.SystemUpdate)\n\n\t\t\tv1SysGroup.GET(\"/hardware\", v1.GetSystemHardwareInfo) // hardware/info\n\n\t\t\tv1SysGroup.GET(\"/wsssh\", v1.WsSsh)\n\t\t\tv1SysGroup.POST(\"/ssh-login\", v1.PostSshLogin)\n\t\t\t// v1SysGroup.GET(\"/config\", v1.GetSystemConfig) //delete\n\t\t\t// v1SysGroup.POST(\"/config\", v1.PostSetSystemConfig)\n\t\t\tv1SysGroup.GET(\"/logs\", v1.GetCasaOSErrorLogs) // error/logs\n\t\t\t// v1SysGroup.GET(\"/widget/config\", v1.GetWidgetConfig)//delete\n\t\t\t// v1SysGroup.POST(\"/widget/config\", v1.PostSetWidgetConfig)//delete\n\n\t\t\tv1SysGroup.POST(\"/stop\", v1.PostKillCasaOS)\n\n\t\t\tv1SysGroup.GET(\"/utilization\", v1.GetSystemUtilization)\n\t\t\t// v1SysGroup.GET(\"/cpu\", v1.GetSystemCupInfo)\n\t\t\t// v1SysGroup.GET(\"/mem\", v1.GetSystemMemInfo)\n\t\t\t// v1SysGroup.GET(\"/disk\", v1.GetSystemDiskInfo)\n\t\t\t// v1SysGroup.GET(\"/network\", v1.GetSystemNetInfo)\n\n\t\t\tv1SysGroup.GET(\"/server-info\", nil)\n\t\t\tv1SysGroup.PUT(\"/server-info\", nil)\n\t\t\t// v1SysGroup.GET(\"/port\", v1.GetCasaOSPort)\n\t\t\t// v1SysGroup.PUT(\"/port\", v1.PutCasaOSPort)\n\t\t\tv1SysGroup.GET(\"/proxy\", v1.GetSystemProxy)\n\t\t\tv1SysGroup.PUT(\"/state/:state\", v1.PutSystemState)\n\t\t}\n\t\tv1PortGroup := v1Group.Group(\"/port\")\n\t\tv1PortGroup.Use()\n\t\t{\n\t\t\tv1PortGroup.GET(\"/\", v1.GetPort)              // app/port\n\t\t\tv1PortGroup.GET(\"/state/:port\", v1.PortCheck) // app/check/:port\n\t\t}\n\n\t\tv1FileGroup := v1Group.Group(\"/file\")\n\t\tv1FileGroup.Use()\n\t\t{\n\t\t\tv1FileGroup.GET(\"\", v1.GetDownloadSingleFile) // download/:path\n\t\t\tv1FileGroup.POST(\"\", v1.PostCreateFile)\n\t\t\tv1FileGroup.PUT(\"\", v1.PutFileContent)\n\t\t\tv1FileGroup.PUT(\"/name\", v1.RenamePath)\n\t\t\t// file/rename\n\t\t\tv1FileGroup.GET(\"/content\", v1.GetFilerContent) // file/read\n\n\t\t\t// File uploads need to be handled separately, and will not be modified here\n\t\t\t//v1FileGroup.POST(\"/upload\", v1.PostFileUpload)\n\t\t\tv1FileGroup.POST(\"/upload\", v1.PostFileUpload)\n\t\t\tv1FileGroup.GET(\"/upload\", v1.GetFileUpload)\n\t\t\t// v1FileGroup.GET(\"/download\", v1.UserFileDownloadCommonService)\n\t\t\tv1FileGroup.GET(\"/ws\", v1.ConnectWebSocket)\n\t\t\tv1FileGroup.GET(\"/peers\", v1.GetPeers)\n\t\t}\n\t\tv1CloudGroup := v1Group.Group(\"/cloud\")\n\t\tv1CloudGroup.Use()\n\t\t{\n\t\t\tv1CloudGroup.GET(\"\", v1.ListStorages)\n\t\t\tv1CloudGroup.DELETE(\"\", v1.UmountStorage)\n\t\t}\n\t\tv1DriverGroup := v1Group.Group(\"/driver\")\n\t\tv1DriverGroup.Use()\n\t\t{\n\t\t\tv1DriverGroup.GET(\"\", v1.ListDriverInfo)\n\t\t}\n\n\t\tv1FolderGroup := v1Group.Group(\"/folder\")\n\t\tv1FolderGroup.Use()\n\t\t{\n\t\t\tv1FolderGroup.PUT(\"/name\", v1.RenamePath)\n\t\t\tv1FolderGroup.GET(\"\", v1.DirPath)   ///file/dirpath\n\t\t\tv1FolderGroup.POST(\"\", v1.MkdirAll) ///file/mkdir\n\t\t\tv1FolderGroup.GET(\"/size\", v1.GetSize)\n\t\t\tv1FolderGroup.GET(\"/count\", v1.GetFileCount)\n\t\t}\n\t\tv1BatchGroup := v1Group.Group(\"/batch\")\n\t\tv1BatchGroup.Use()\n\t\t{\n\n\t\t\tv1BatchGroup.DELETE(\"\", v1.DeleteFile) // file/delete\n\t\t\tv1BatchGroup.DELETE(\"/:id/task\", v1.DeleteOperateFileOrDir)\n\t\t\tv1BatchGroup.POST(\"/task\", v1.PostOperateFileOrDir) // file/operate\n\t\t\tv1BatchGroup.GET(\"\", v1.GetDownloadFile)\n\t\t}\n\t\tv1ImageGroup := v1Group.Group(\"/image\")\n\t\tv1ImageGroup.Use()\n\t\t{\n\t\t\tv1ImageGroup.GET(\"\", v1.GetFileImage)\n\t\t}\n\t\tv1SambaGroup := v1Group.Group(\"/samba\")\n\t\tv1SambaGroup.Use()\n\t\t{\n\t\t\tv1ConnectionsGroup := v1SambaGroup.Group(\"/connections\")\n\t\t\tv1ConnectionsGroup.Use()\n\t\t\t{\n\t\t\t\tv1ConnectionsGroup.GET(\"\", v1.GetSambaConnectionsList)\n\t\t\t\tv1ConnectionsGroup.POST(\"\", v1.PostSambaConnectionsCreate)\n\t\t\t\tv1ConnectionsGroup.DELETE(\"/:id\", v1.DeleteSambaConnections)\n\t\t\t}\n\t\t\tv1SharesGroup := v1SambaGroup.Group(\"/shares\")\n\t\t\tv1SharesGroup.Use()\n\t\t\t{\n\t\t\t\tv1SharesGroup.GET(\"\", v1.GetSambaSharesList)\n\t\t\t\tv1SharesGroup.POST(\"\", v1.PostSambaSharesCreate)\n\t\t\t\tv1SharesGroup.DELETE(\"/:id\", v1.DeleteSambaShares)\n\t\t\t\tv1SharesGroup.GET(\"/status\", v1.GetSambaStatus)\n\t\t\t}\n\t\t}\n\t\tv1NotifyGroup := v1Group.Group(\"/notify\")\n\t\tv1NotifyGroup.Use()\n\t\t{\n\t\t\tv1NotifyGroup.POST(\"/:path\", v1.PostNotifyMessage)\n\t\t\t// merge to system\n\t\t\tv1NotifyGroup.POST(\"/system_status\", v1.PostSystemStatusNotify)\n\t\t}\n\n\t\tv1OtherGroup := v1Group.Group(\"/other\")\n\t\tv1OtherGroup.Use()\n\t\t{\n\t\t\tv1OtherGroup.GET(\"/search\", v1.GetSearchResult)\n\n\t\t}\n\t}\n\n\treturn r\n}", "is_vulnerable": 0}
{"code": "func (r *MySQL) ProbeWithPing(db *sql.DB) error {\n\tif err := db.Ping(); err != nil {\n\t\treturn err\n\t}\n\trow, err := db.Query(\"show status like \\\"uptime\\\"\") // run a SQL to test\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer row.Close()\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tmalleate           func()\n\t\texpectedSuccess    bool\n\t\texpCommPoolBalance math.Int\n\t}{\n\t\t{\n\t\t\t\"Mainnet - success\",\n\t\t\tmainnetChainID,\n\t\t\tfunc() {},\n\t\t\ttrue,\n\t\t\texpCommPoolBalance,\n\t\t},\n\t\t{\n\t\t\t\"Mainnet - insufficient funds on reward account - fail\",\n\t\t\tmainnetChainID,\n\t\t\tfunc() {\n\t\t\t\terr := suite.app.BankKeeper.SendCoins(\n\t\t\t\t\tsuite.ctx,\n\t\t\t\t\tfundingAcc,\n\t\t\t\t\tsdk.AccAddress(utiltx.GenerateAddress().Bytes()),\n\t\t\t\t\tsdk.NewCoins(\n\t\t\t\t\t\tsdk.NewCoin(utils.BaseDenom, balance.Quo(math.NewInt(2))),\n\t\t\t\t\t),\n\t\t\t\t)\n\t\t\t\tsuite.NoError(err)\n\t\t\t},\n\t\t\tfalse,\n\t\t\tmath.ZeroInt(),\n\t\t},\n\t\t{\n\t\t\t\"Mainnet - invalid reward amount - fail\",\n\t\t\tmainnetChainID,\n\t\t\tfunc() {\n\t\t\t\tv11.Allocations[0][1] = \"a0151as2021231a\"\n\t\t\t},\n\t\t\tfalse,\n\t\t\tmath.ZeroInt(),\n\t\t},\n\t\t{\n\t\t\t\"Testnet - no-op\",\n\t\t\tutils.TestnetChainID + \"-4\",\n\t\t\tfunc() {},\n\t\t\tfalse,\n\t\t\tmath.ZeroInt(),\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tsuite.Run(fmt.Sprintf(\"Case %s\", tc.name), func() {\n\t\t\tsuite.SetupTest(tc.chainID)\n\t\t\tsuite.fundTestnetRewardsAcc(balance)\n\t\t\ttc.malleate()\n\n\t\t\t// create validators\n\t\t\tsuite.setValidators(validatorAddresses)\n\n\t\t\t// check no delegations for validators initially\n\t\t\tinitialDel := suite.getDelegatedTokens(validatorAddresses...)\n\t\t\tsuite.Require().Equal(math.ZeroInt(), initialDel)\n\n\t\t\tif utils.IsMainnet(tc.chainID) {\n\t\t\t\tv11.HandleRewardDistribution(suite.ctx, suite.app.Logger(), suite.app.BankKeeper, *suite.app.StakingKeeper.Keeper, suite.app.DistrKeeper)\n\t\t\t}\n\n\t\t\t// account not in list should NOT get rewards\n\t\t\t// balance should be 0\n\t\t\tbalance := suite.app.BankKeeper.GetBalance(suite.ctx, noRewardAddr, utils.BaseDenom)\n\t\t\tsuite.Require().Equal(math.ZeroInt(), balance.Amount)\n\n\t\t\t// get staked (delegated) tokens - no delegations expected\n\t\t\tdelegated := suite.app.StakingKeeper.GetAllDelegatorDelegations(suite.ctx, noRewardAddr)\n\t\t\tsuite.Require().Empty(delegated)\n\n\t\t\tcommPoolFinalBalance := suite.app.BankKeeper.GetBalance(suite.ctx, communityPool, utils.BaseDenom)\n\t\t\tsuite.Require().Equal(tc.expCommPoolBalance, commPoolFinalBalance.Amount)\n\n\t\t\t// do allocations\n\t\t\tfor i := range v11.Allocations {\n\t\t\t\taddr := sdk.MustAccAddressFromBech32(v11.Allocations[i][0])\n\t\t\t\tvalShare, _ := math.NewIntFromString(v11.Allocations[i][1])\n\n\t\t\t\tbalance := suite.app.BankKeeper.GetBalance(suite.ctx, addr, utils.BaseDenom)\n\t\t\t\tsuite.Require().Equal(math.ZeroInt(), balance.Amount)\n\n\t\t\t\t// get staked (delegated) tokens\n\t\t\t\tdelegated := suite.app.StakingKeeper.GetAllDelegatorDelegations(suite.ctx, addr)\n\t\t\t\tif tc.expectedSuccess {\n\t\t\t\t\t// sum of all delegations should be equal to rewards\n\t\t\t\t\tdelegatedAmt := suite.sumDelegatorDelegations(delegated...)\n\t\t\t\t\tsuite.Require().Equal(valShare, delegatedAmt)\n\t\t\t\t} else {\n\t\t\t\t\tsuite.Require().Empty(delegated)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// check delegation for each validator\n\t\t\ttotalDelegations := math.ZeroInt()\n\t\t\tfor _, v := range validatorAddresses {\n\t\t\t\tdelTokens := suite.getDelegatedTokens(v)\n\t\t\t\tif tc.expectedSuccess {\n\t\t\t\t\t// amount delegated should be equal to sums calculated pre-tests\n\t\t\t\t\tsuite.Require().Equal(validatorDelegations[v], delTokens)\n\t\t\t\t} else {\n\t\t\t\t\tsuite.Require().Equal(math.ZeroInt(), delTokens)\n\t\t\t\t}\n\t\t\t\ttotalDelegations = totalDelegations.Add(delTokens)\n\t\t\t}\n\n\t\t\tif tc.expectedSuccess {\n\t\t\t\t// sum of all delegations should be equal to rewards\n\t\t\t\tsuite.Require().Equal(expRewards, totalDelegations)\n\t\t\t\t// Funding acc balance should be 0 after the rewards distribution\n\t\t\t\tfinalFundingAccBalance := suite.app.BankKeeper.GetBalance(suite.ctx, fundingAcc, utils.BaseDenom)\n\t\t\t\tsuite.Require().Equal(math.NewInt(0), finalFundingAccBalance.Amount)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAliasRegexp(t *testing.T) {\n\tfor name, shouldPass := range map[string]bool{\n\t\t\"abcdefghijklmnopqrstuvwxyzABCDEFG0987654321_-\": true,\n\t\t\"$foo\":     false,\n\t\t\"bar$\":     false,\n\t\t\"foo\\nbar\": false,\n\t} {\n\t\tif aliasRegexp.MatchString(name) != shouldPass {\n\t\t\tt.Errorf(\"name %q failed to pass its test\", name)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (g *rfc4122Generator) getClockSequence() (uint64, uint16, error) {\n\tvar err error\n\tg.clockSequenceOnce.Do(func() {\n\t\tbuf := make([]byte, 2)\n\t\tif _, err = g.rand.Read(buf); err != nil {\n\t\t\treturn\n\t\t}\n\t\tg.clockSequence = binary.BigEndian.Uint16(buf)\n\t})\n\tif err != nil {\n\t\treturn 0, 0, err\n\t}\n\n\tg.storageMutex.Lock()\n\tdefer g.storageMutex.Unlock()\n\n\ttimeNow := g.getEpoch()\n\t// Clock didn't change since last UUID generation.\n\t// Should increase clock sequence.\n\tif timeNow <= g.lastTime {\n\t\tg.clockSequence++\n\t}\n\tg.lastTime = timeNow\n\n\treturn timeNow, g.clockSequence, nil\n}", "is_vulnerable": 1}
{"code": "func (evpool *Pool) AddEvidence(ev types.Evidence) error {\n\tevpool.logger.Debug(\"Attempting to add evidence\", \"ev\", ev)\n\n\t// We have already verified this piece of evidence - no need to do it again\n\tif evpool.isPending(ev) {\n\t\tevpool.logger.Info(\"Evidence already pending, ignoring this one\", \"ev\", ev)\n\t\treturn nil\n\t}\n\n\t// check that the evidence isn't already committed\n\tif evpool.isCommitted(ev) {\n\t\t// this can happen if the peer that sent us the evidence is behind so we shouldn't\n\t\t// punish the peer.\n\t\tevpool.logger.Debug(\"Evidence was already committed, ignoring this one\", \"ev\", ev)\n\t\treturn nil\n\t}\n\n\t// 1) Verify against state.\n\terr := evpool.verify(ev)\n\tif err != nil {\n\t\treturn types.NewErrInvalidEvidence(ev, err)\n\t}\n\n\t// 2) Save to store.\n\tif err := evpool.addPendingEvidence(ev); err != nil {\n\t\treturn fmt.Errorf(\"can't add evidence to pending list: %w\", err)\n\t}\n\n\t// 3) Add evidence to clist.\n\tevpool.evidenceList.PushBack(ev)\n\n\tevpool.logger.Info(\"Verified new evidence of byzantine behavior\", \"evidence\", ev)\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestAppJsonPatch(t *testing.T) {\n\ttestApp := newTestAppWithAnnotations()\n\tctx := context.Background()\n\t// nolint:staticcheck\n\tctx = context.WithValue(ctx, \"claims\", &jwt.StandardClaims{Subject: \"admin\"})\n\tappServer := newTestAppServer(t, testApp)\n\tappServer.enf.SetDefaultRole(\"\")\n\n\tapp, err := appServer.Patch(ctx, &application.ApplicationPatchRequest{Name: &testApp.Name, Patch: pointer.String(\"garbage\")})\n\tassert.Error(t, err)\n\tassert.Nil(t, app)\n\n\tapp, err = appServer.Patch(ctx, &application.ApplicationPatchRequest{Name: &testApp.Name, Patch: pointer.String(\"[]\")})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, app)\n\n\tapp, err = appServer.Patch(ctx, &application.ApplicationPatchRequest{Name: &testApp.Name, Patch: pointer.String(`[{\"op\": \"replace\", \"path\": \"/spec/source/path\", \"value\": \"foo\"}]`)})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"foo\", app.Spec.Source.Path)\n\n\tapp, err = appServer.Patch(ctx, &application.ApplicationPatchRequest{Name: &testApp.Name, Patch: pointer.String(`[{\"op\": \"remove\", \"path\": \"/metadata/annotations/test.annotation\"}]`)})\n\tassert.NoError(t, err)\n\tassert.NotContains(t, app.Annotations, \"test.annotation\")\n}", "is_vulnerable": 0}
{"code": "func NewServicePrincipalTokenWithSecret(oauthConfig OAuthConfig, id string, resource string, secret ServicePrincipalSecret, callbacks ...TokenRefreshCallback) (*ServicePrincipalToken, error) {\n\tif err := validateOAuthConfig(oauthConfig); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := validateStringParam(id, \"id\"); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := validateStringParam(resource, \"resource\"); err != nil {\n\t\treturn nil, err\n\t}\n\tif secret == nil {\n\t\treturn nil, fmt.Errorf(\"parameter 'secret' cannot be nil\")\n\t}\n\tspt := &ServicePrincipalToken{\n\t\tinner: servicePrincipalToken{\n\t\t\tToken:         newToken(),\n\t\t\tOauthConfig:   oauthConfig,\n\t\t\tSecret:        secret,\n\t\t\tClientID:      id,\n\t\t\tResource:      resource,\n\t\t\tAutoRefresh:   true,\n\t\t\tRefreshWithin: defaultRefresh,\n\t\t},\n\t\trefreshLock:      &sync.RWMutex{},\n\t\tsender:           sender(),\n\t\trefreshCallbacks: callbacks,\n\t}\n\treturn spt, nil\n}", "is_vulnerable": 0}
{"code": "func GenerateConsoleSessionCredentials(source io.Reader) (types.Credential, error) {\n\tvar (\n\t\tkey     [32]byte // key is 32 random bytes\n\t\tkeyText [44]byte // keyText is the base64 encoded key - 44 characters\n\t\tcred    types.Credential\n\t)\n\tif source == nil {\n\t\tsource = rand.Reader\n\t}\n\tif _, err := io.ReadFull(source, key[:]); err != nil {\n\t\treturn cred, fmt.Errorf(\"error generating console session key: %s\", err)\n\t}\n\tbase64.URLEncoding.Encode(keyText[:], key[:])\n\treturn types.Credential{\n\t\tCA:          \"\",\n\t\tName:        types.ConsoleSessionSecret,\n\t\tSubject:     \"\",\n\t\tConnectJson: false,\n\t\tData: map[string][]byte{\n\t\t\t\"session_secret\": keyText[:],\n\t\t},\n\t\tPost: false,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestCompilerSingle(t *testing.T) {\n\tvar testCases = []struct {\n\t\texpression string\n\t\tvalues     []sqltypes.Value\n\t\tresult     string\n\t}{\n\t\t{\n\t\t\texpression: \"1 + column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewInt64(1)},\n\t\t\tresult:     \"INT64(2)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"1 + column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(1)},\n\t\t\tresult:     \"FLOAT64(2)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"1.0e0 - column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(1)},\n\t\t\tresult:     \"FLOAT64(0)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"128 - column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(1)},\n\t\t\tresult:     \"FLOAT64(127)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"(128 - column0) * 3\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(1)},\n\t\t\tresult:     \"FLOAT64(381)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"1.0e0 < column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(2)},\n\t\t\tresult:     \"INT64(1)\",\n\t\t},\n\t\t{\n\t\t\texpression: \"1.0e0 < column0\",\n\t\t\tvalues:     []sqltypes.Value{sqltypes.NewFloat64(-1)},\n\t\t\tresult:     \"INT64(0)\",\n\t\t},\n\t\t{\n\t\t\texpression: `'foo' = 'FOO' collate utf8mb4_0900_as_cs`,\n\t\t\tresult:     \"INT64(0)\",\n\t\t},\n\t\t{\n\t\t\texpression: `'foo' < 'bar'`,\n\t\t\tresult:     \"INT64(0)\",\n\t\t},\n\t\t{\n\t\t\texpression: `case when false then 0 else 18446744073709551615 end`,\n\t\t\tresult:     `DECIMAL(18446744073709551615)`,\n\t\t},\n\t\t{\n\t\t\texpression: `case when true then _binary \"foobar\" else 'foo' collate utf8mb4_0900_as_cs end`,\n\t\t\tresult:     `VARCHAR(\"foobar\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `- 18446744073709551615`,\n\t\t\tresult:     `DECIMAL(-18446744073709551615)`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(CAST(true AS JSON) AS BINARY)`,\n\t\t\tresult:     `BLOB(\"true\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `JSON_ARRAY(true, 1.0)`,\n\t\t\tresult:     `JSON(\"[true, 1.0]\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(true as json) + 0`,\n\t\t\tresult:     `FLOAT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(CAST(0 AS JSON) AS CHAR(16))`,\n\t\t\tresult:     `VARCHAR(\"0\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `1 OR cast('invalid' as json)`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `NULL AND 1`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `CONV(-1.5e0, 1.5e0, 1.5e0)`,\n\t\t\tresult:     `VARCHAR(\"1111111111111111111111111111111111111111111111111111111111111111\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CONV(9223372036854775810.4, 13, 7)`,\n\t\t\tresult:     `VARCHAR(\"45012021522523134134601\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CONV(-9223372036854775809, 13e0, 13e0)`,\n\t\t\tresult:     `VARCHAR(\"0\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `0 + time '10:04:58'`,\n\t\t\tresult:     `INT64(100458)`,\n\t\t},\n\t\t{\n\t\t\texpression: `0 + time '101:34:58'`,\n\t\t\tresult:     `INT64(1013458)`,\n\t\t},\n\t\t{\n\t\t\texpression: `time '10:04:58' < '101:34:58'`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `1.7 / 173458`,\n\t\t\tresult:     `DECIMAL(0.00001)`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(time '5 12:34:58' as json)`,\n\t\t\tresult:     `JSON(\"\\\"04:34:58.000000\\\"\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(20000229235959.999950 AS DATETIME(4))`,\n\t\t\tresult:     `DATETIME(\"2000-03-01 00:00:00.0000\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(1.5678 AS TIME(2))`,\n\t\t\tresult:     `TIME(\"00:00:01.57\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(235959.995 AS TIME(2))`,\n\t\t\tresult:     `TIME(\"24:00:00.00\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(-235959.995 AS TIME(2))`,\n\t\t\tresult:     `TIME(\"-24:00:00.00\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `WEEK('2000-01-02', 6)`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `WEEK(date '2000-01-01', 4)`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\t// This is the day of DST change in Europe/Amsterdam when\n\t\t\t// the year started on a Wednesday. Regression test for\n\t\t\t// using 24 hour time diffing instead of days.\n\t\t\texpression: `WEEK(date '2014-10-26', 6)`,\n\t\t\tresult:     `INT64(44)`,\n\t\t},\n\t\t{\n\t\t\texpression: `MAKEDATE(cast('invalid' as json), NULL)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `MAKETIME(NULL, '', cast('invalid' as json))`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `1 = ' 1 '`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST(' 0 ' AS TIME)`,\n\t\t\tresult:     `TIME(\"00:00:00\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `CAST('0' AS TIME)`,\n\t\t\tresult:     `TIME(\"00:00:00\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `timestamp '2000-01-01 10:34:58.978654' DIV '\\t1 foo\\t'`,\n\t\t\tresult:     `INT64(20000101103458)`,\n\t\t},\n\t\t{\n\t\t\texpression: `UNHEX('f')`,\n\t\t\tresult:     `VARBINARY(\"\\x0f\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `STRCMP(1234, '12_4')`,\n\t\t\tresult:     `INT64(-1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, 0)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 1, 0)`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 1, 0, 0)`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, -1, 0, 0)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 1, 1, 1)`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, -1, -1, -1)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, 1)`,\n\t\t\tresult:     `INT64(2)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, -1)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, NULL, 0, 0)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(NULL, 0, 0, 0)`,\n\t\t\tresult:     `INT64(-1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, NULL)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, NULL, 1, 1)`,\n\t\t\tresult:     `INT64(3)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 2, NULL, 1, 1)`,\n\t\t\tresult:     `INT64(1)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 2, -1, NULL, -1, 1)`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 2, NULL, NULL, -1, 1)`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, NULL, NULL, NULL, -1, 1)`,\n\t\t\tresult:     `INT64(4)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, -1, NULL, 1)`,\n\t\t\tresult:     `INT64(4)`,\n\t\t},\n\t\t{\n\t\t\texpression: `INTERVAL(0, 0, 0, -1, NULL, NULL, 1)`,\n\t\t\tresult:     `INT64(5)`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(null * 1 as CHAR)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(null + 1 as CHAR)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(null - 1 as CHAR)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(null / 1 as CHAR)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(null % 1 as CHAR)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `1 AND NULL * 1`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `case 0 when NULL then 1 else 0 end`,\n\t\t\tresult:     `INT64(0)`,\n\t\t},\n\t\t{\n\t\t\texpression: `case when null is null then 23 else null end`,\n\t\t\tresult:     `INT64(23)`,\n\t\t},\n\t\t{\n\t\t\texpression: `week('2023-12-31', 4)`,\n\t\t\tresult:     `INT64(53)`,\n\t\t},\n\t\t{\n\t\t\texpression: `week('2023-12-31', 2)`,\n\t\t\tresult:     `INT64(53)`,\n\t\t},\n\t\t{\n\t\t\texpression: `week('2024-12-31', 1)`,\n\t\t\tresult:     `INT64(53)`,\n\t\t},\n\t\t{\n\t\t\texpression: `week('2024-12-31', 5)`,\n\t\t\tresult:     `INT64(53)`,\n\t\t},\n\t\t{\n\t\t\texpression: `convert(0xFF using utf16)`,\n\t\t\tresult:     `VARCHAR(\"\u00ff\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `_utf16 0xFF`,\n\t\t\tresult:     `VARCHAR(\"\u00ff\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `convert(0xFF using utf32)`,\n\t\t\tresult:     `NULL`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(_utf32 0xFF as binary)`,\n\t\t\tresult:     `VARBINARY(\"\\x00\\x00\\x00\\xff\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(_utf32 0x00FF as binary)`,\n\t\t\tresult:     `VARBINARY(\"\\x00\\x00\\x00\\xff\")`,\n\t\t},\n\t\t{\n\t\t\texpression: `cast(_utf32 0x0000FF as binary)`,\n\t\t\tresult:     `VARBINARY(\"\\x00\\x00\\x00\\xff\")`,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.expression, func(t *testing.T) {\n\t\t\texpr, err := sqlparser.ParseExpr(tc.expression)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tfields := evalengine.FieldResolver(makeFields(tc.values))\n\t\t\tcfg := &evalengine.Config{\n\t\t\t\tResolveColumn: fields.Column,\n\t\t\t\tResolveType:   fields.Type,\n\t\t\t\tCollation:     collations.CollationUtf8mb4ID,\n\t\t\t\tOptimization:  evalengine.OptimizationLevelCompilerDebug,\n\t\t\t}\n\n\t\t\tconverted, err := evalengine.Translate(expr, cfg)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tenv := evalengine.EmptyExpressionEnv()\n\t\t\tenv.Row = tc.values\n\n\t\t\texpected, err := env.Evaluate(evalengine.Deoptimize(converted))\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\tif expected.String() != tc.result {\n\t\t\t\tt.Fatalf(\"bad evaluation from eval engine: got %s, want %s\", expected.String(), tc.result)\n\t\t\t}\n\n\t\t\tif cfg.CompilerErr != nil {\n\t\t\t\tt.Fatalf(\"bad compilation: %v\", cfg.CompilerErr)\n\t\t\t}\n\n\t\t\t// re-run the same evaluation multiple times to ensure results are always consistent\n\t\t\tfor i := 0; i < 8; i++ {\n\t\t\t\tres, err := env.EvaluateVM(converted.(*evalengine.CompiledExpr))\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\n\t\t\t\tif res.String() != tc.result {\n\t\t\t\t\tt.Errorf(\"bad evaluation from compiler: got %s, want %s (iteration %d)\", res, tc.result, i)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (r *TerraformRunnerServer) ShowPlanFileRaw(ctx context.Context, req *ShowPlanFileRawRequest) (*ShowPlanFileRawReply, error) {\n\tlog := controllerruntime.LoggerFrom(ctx, \"instance-id\", r.InstanceID).WithName(loggerName)\n\tlog.Info(\"show the raw plan file\")\n\tif req.TfInstance != r.InstanceID {\n\t\terr := fmt.Errorf(\"no TF instance found\")\n\t\tlog.Error(err, \"no terraform\")\n\t\treturn nil, err\n\t}\n\n\trawOutput, err := r.tfShowPlanFileRaw(ctx, req.Filename)\n\tif err != nil {\n\t\tlog.Error(err, \"unable to get the raw plan output\")\n\t\treturn nil, err\n\t}\n\n\treturn &ShowPlanFileRawReply{RawOutput: rawOutput}, nil\n}", "is_vulnerable": 0}
{"code": "func newBaseMatcher(rule *jwtauthnv3.RequirementRule) *baseMatcher {\n\t// default case sensitive\n\tcaseSensitive := true\n\tif rule.Match.CaseSensitive != nil {\n\t\tcaseSensitive = rule.Match.CaseSensitive.Value\n\t}\n\n\treturn &baseMatcher{\n\t\tcaseSensitive:   caseSensitive,\n\t\theaders:         rule.GetMatch().GetHeaders(),\n\t\tqueryParameters: rule.GetMatch().GetQueryParameters(),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *NoExtensionsMap) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NoExtensionsMap: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NoExtensionsMap: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tdefault:\n\t\t\tif (fieldNum >= 100) && (fieldNum < 200) {\n\t\t\t\tvar sizeOfWire int\n\t\t\t\tfor {\n\t\t\t\t\tsizeOfWire++\n\t\t\t\t\twire >>= 7\n\t\t\t\t\tif wire == 0 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tiNdEx -= sizeOfWire\n\t\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tgithub_com_gogo_protobuf_proto.AppendExtension(m, int32(fieldNum), dAtA[iNdEx:iNdEx+skippy])\n\t\t\t\tiNdEx += skippy\n\t\t\t} else {\n\t\t\t\tiNdEx = preIndex\n\t\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\t\tiNdEx += skippy\n\t\t\t}\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\t\tfunc(ctx etreeutils.NSContext, signedInfo *etree.Element) error {\n\t\t\t\tdetachedSignedInfo, err := etreeutils.NSDetatch(ctx, signedInfo)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tc14NMethod, err := etreeutils.NSFindOneChildCtx(ctx, detachedSignedInfo, Namespace, CanonicalizationMethodTag)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tif c14NMethod == nil {\n\t\t\t\t\treturn errors.New(\"missing CanonicalizationMethod on Signature\")\n\t\t\t\t}\n\n\t\t\t\tc14NAlgorithm := c14NMethod.SelectAttrValue(AlgorithmAttr, \"\")\n\n\t\t\t\tvar canonicalSignedInfo *etree.Element\n\n\t\t\t\tswitch AlgorithmID(c14NAlgorithm) {\n\t\t\t\tcase CanonicalXML10ExclusiveAlgorithmId:\n\t\t\t\t\terr := etreeutils.TransformExcC14n(detachedSignedInfo, \"\")\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\t// NOTE: TransformExcC14n transforms the element in-place,\n\t\t\t\t\t// while canonicalPrep isn't meant to. Once we standardize\n\t\t\t\t\t// this behavior we can drop this, as well as the adding and\n\t\t\t\t\t// removing of elements below.\n\t\t\t\t\tcanonicalSignedInfo = detachedSignedInfo\n\n\t\t\t\tcase CanonicalXML11AlgorithmId:\n\t\t\t\t\tcanonicalSignedInfo = canonicalPrep(detachedSignedInfo, map[string]struct{}{})\n\n\t\t\t\tcase CanonicalXML10RecAlgorithmId:\n\t\t\t\t\tcanonicalSignedInfo = canonicalPrep(detachedSignedInfo, map[string]struct{}{})\n\n\t\t\t\tcase CanonicalXML10CommentAlgorithmId:\n\t\t\t\t\tcanonicalSignedInfo = canonicalPrep(detachedSignedInfo, map[string]struct{}{})\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn fmt.Errorf(\"invalid CanonicalizationMethod on Signature: %s\", c14NAlgorithm)\n\t\t\t\t}\n\n\t\t\t\tsignatureEl.RemoveChild(signedInfo)\n\t\t\t\tsignatureEl.AddChild(canonicalSignedInfo)\n\n\t\t\t\tfound = true\n\n\t\t\t\treturn etreeutils.ErrTraversalHalted\n\t\t\t})", "is_vulnerable": 0}
{"code": "func (s *store) GuaranteedUpdate(\n\tctx context.Context, key string, destination runtime.Object, ignoreNotFound bool,\n\tpreconditions *storage.Preconditions, tryUpdate storage.UpdateFunc, cachedExistingObject runtime.Object) error {\n\tpreparedKey, err := s.prepareKey(key)\n\tif err != nil {\n\t\treturn err\n\t}\n\tctx, span := tracing.Start(ctx, \"GuaranteedUpdate etcd3\",\n\t\tattribute.String(\"audit-id\", audit.GetAuditIDTruncated(ctx)),\n\t\tattribute.String(\"key\", key),\n\t\tattribute.String(\"type\", getTypeName(destination)),\n\t\tattribute.String(\"resource\", s.groupResourceString))\n\tdefer span.End(500 * time.Millisecond)\n\n\tv, err := conversion.EnforcePtr(destination)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to convert output object to pointer: %v\", err)\n\t}\n\n\tgetCurrentState := func() (*objState, error) {\n\t\tstartTime := time.Now()\n\t\tgetResp, err := s.client.KV.Get(ctx, preparedKey)\n\t\tmetrics.RecordEtcdRequestLatency(\"get\", s.groupResourceString, startTime)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn s.getState(ctx, getResp, preparedKey, v, ignoreNotFound)\n\t}\n\n\tvar origState *objState\n\tvar origStateIsCurrent bool\n\tif cachedExistingObject != nil {\n\t\torigState, err = s.getStateFromObject(cachedExistingObject)\n\t} else {\n\t\torigState, err = getCurrentState()\n\t\torigStateIsCurrent = true\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\tspan.AddEvent(\"initial value restored\")\n\n\ttransformContext := authenticatedDataString(preparedKey)\n\tfor {\n\t\tif err := preconditions.Check(preparedKey, origState.obj); err != nil {\n\t\t\t// If our data is already up to date, return the error\n\t\t\tif origStateIsCurrent {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// It's possible we were working with stale data\n\t\t\t// Actually fetch\n\t\t\torigState, err = getCurrentState()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\torigStateIsCurrent = true\n\t\t\t// Retry\n\t\t\tcontinue\n\t\t}\n\n\t\tret, ttl, err := s.updateState(origState, tryUpdate)\n\t\tif err != nil {\n\t\t\t// If our data is already up to date, return the error\n\t\t\tif origStateIsCurrent {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// It's possible we were working with stale data\n\t\t\t// Remember the revision of the potentially stale data and the resulting update error\n\t\t\tcachedRev := origState.rev\n\t\t\tcachedUpdateErr := err\n\n\t\t\t// Actually fetch\n\t\t\torigState, err = getCurrentState()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\torigStateIsCurrent = true\n\n\t\t\t// it turns out our cached data was not stale, return the error\n\t\t\tif cachedRev == origState.rev {\n\t\t\t\treturn cachedUpdateErr\n\t\t\t}\n\n\t\t\t// Retry\n\t\t\tcontinue\n\t\t}\n\n\t\tspan.AddEvent(\"About to Encode\")\n\t\tdata, err := runtime.Encode(s.codec, ret)\n\t\tif err != nil {\n\t\t\tspan.AddEvent(\"Encode failed\", attribute.Int(\"len\", len(data)), attribute.String(\"err\", err.Error()))\n\t\t\treturn err\n\t\t}\n\t\tspan.AddEvent(\"Encode succeeded\", attribute.Int(\"len\", len(data)))\n\t\tif !origState.stale && bytes.Equal(data, origState.data) {\n\t\t\t// if we skipped the original Get in this loop, we must refresh from\n\t\t\t// etcd in order to be sure the data in the store is equivalent to\n\t\t\t// our desired serialization\n\t\t\tif !origStateIsCurrent {\n\t\t\t\torigState, err = getCurrentState()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\torigStateIsCurrent = true\n\t\t\t\tif !bytes.Equal(data, origState.data) {\n\t\t\t\t\t// original data changed, restart loop\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\t// recheck that the data from etcd is not stale before short-circuiting a write\n\t\t\tif !origState.stale {\n\t\t\t\treturn decode(s.codec, s.versioner, origState.data, destination, origState.rev)\n\t\t\t}\n\t\t}\n\n\t\tnewData, err := s.transformer.TransformToStorage(ctx, data, transformContext)\n\t\tif err != nil {\n\t\t\tspan.AddEvent(\"TransformToStorage failed\", attribute.String(\"err\", err.Error()))\n\t\t\treturn storage.NewInternalError(err.Error())\n\t\t}\n\t\tspan.AddEvent(\"TransformToStorage succeeded\")\n\n\t\topts, err := s.ttlOpts(ctx, int64(ttl))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tspan.AddEvent(\"Transaction prepared\")\n\n\t\tstartTime := time.Now()\n\t\ttxnResp, err := s.client.KV.Txn(ctx).If(\n\t\t\tclientv3.Compare(clientv3.ModRevision(preparedKey), \"=\", origState.rev),\n\t\t).Then(\n\t\t\tclientv3.OpPut(preparedKey, string(newData), opts...),\n\t\t).Else(\n\t\t\tclientv3.OpGet(preparedKey),\n\t\t).Commit()\n\t\tmetrics.RecordEtcdRequestLatency(\"update\", s.groupResourceString, startTime)\n\t\tif err != nil {\n\t\t\tspan.AddEvent(\"Txn call failed\", attribute.String(\"err\", err.Error()))\n\t\t\treturn err\n\t\t}\n\t\tspan.AddEvent(\"Txn call completed\")\n\t\tspan.AddEvent(\"Transaction committed\")\n\t\tif !txnResp.Succeeded {\n\t\t\tgetResp := (*clientv3.GetResponse)(txnResp.Responses[0].GetResponseRange())\n\t\t\tklog.V(4).Infof(\"GuaranteedUpdate of %s failed because of a conflict, going to retry\", preparedKey)\n\t\t\torigState, err = s.getState(ctx, getResp, preparedKey, v, ignoreNotFound)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tspan.AddEvent(\"Retry value restored\")\n\t\t\torigStateIsCurrent = true\n\t\t\tcontinue\n\t\t}\n\t\tputResp := txnResp.Responses[0].GetResponsePut()\n\n\t\terr = decode(s.codec, s.versioner, data, destination, putResp.Header.Revision)\n\t\tif err != nil {\n\t\t\tspan.AddEvent(\"decode failed\", attribute.Int(\"len\", len(data)), attribute.String(\"err\", err.Error()))\n\t\t\treturn err\n\t\t}\n\t\tspan.AddEvent(\"decode succeeded\", attribute.Int(\"len\", len(data)))\n\t\treturn nil\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *StreamClient) ReadL() (int, error) {\n\tif _, err := io.ReadFull(c.Server, c.RB[:2+16]); err != nil {\n\t\treturn 0, err\n\t}\n\tif _, err := c.sa.Open(c.RB[:0], c.sn, c.RB[:2+16], nil); err != nil {\n\t\treturn 0, err\n\t}\n\tl := int(binary.BigEndian.Uint16(c.RB[:2]))\n\tif _, err := io.ReadFull(c.Server, c.RB[2+16:2+16+l+16]); err != nil {\n\t\treturn 0, err\n\t}\n\tNextNonce(c.sn)\n\tif _, err := c.sa.Open(c.RB[:2+16], c.sn, c.RB[2+16:2+16+l+16], nil); err != nil {\n\t\treturn 0, err\n\t}\n\tNextNonce(c.sn)\n\treturn l, nil\n}", "is_vulnerable": 1}
{"code": "func (c *Server) CrossOrigin(w http.ResponseWriter, r *http.Request) {\n\tr.Header.Set(\"Origin\", \"*\")\n\tw.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\n\tw.Header().Set(\"Access-Control-Allow-Headers\", \"Authorization, Content-Type, Depth, User-Agent, X-File-Size, X-Requested-With, X-Requested-By, If-Modified-Since, X-File-Name, X-File-Type, Cache-Control, Origin\")\n\tw.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, OPTIONS, PUT, DELETE\")\n\tw.Header().Set(\"Access-Control-Expose-Headers\", \"Authorization\")\n\t//https://blog.csdn.net/yanzisu_congcong/article/details/80552155\n}", "is_vulnerable": 0}
{"code": "\treturn func(db *gorm.DB) *gorm.DB {\n\t\tsort := c.ctx.DefaultQuery(\"order\", \"desc\")\n\t\tif sort != \"desc\" && sort != \"asc\" {\n\t\t\tsort = \"desc\"\n\t\t}\n\n\t\t// check if the order field is valid\n\t\t// todo: maybe we can use more generic way to check if the sort_by is valid\n\t\torder := DefaultQuery(c.ctx, \"sort_by\", c.itemKey)\n\t\ts, _ := schema.Parse(c.Model, &sync.Map{}, schema.NamingStrategy{})\n\t\tif _, ok := s.FieldsByDBName[order]; ok {\n\t\t\torder = fmt.Sprintf(\"%s %s\", order, sort)\n\t\t\treturn db.Order(order)\n\t\t} else {\n\t\t\tlogger.Error(\"invalid order field:\", order)\n\t\t}\n\n\t\treturn db\n\t}\n}", "is_vulnerable": 0}
{"code": "func compareBase64Strings(got string, expected string) error {\n\tdecodeFirst, err := base64.StdEncoding.DecodeString(got)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"decoding base64 string %s\", got)\n\t}\n\tdecodeSecond, err := base64.StdEncoding.DecodeString(expected)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"decoding base64 string %s\", expected)\n\t}\n\tif !bytes.Equal(decodeFirst, decodeSecond) {\n\t\treturn fmt.Errorf(\"comparing base64 strings, expected %s, got %s\", expected, got)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (req *CodeRequest) StoreResult(db ethdb.Database) {\n\trawdb.WriteCode(db, req.Hash, req.Data)\n}", "is_vulnerable": 0}
{"code": "func newServiceWithCommitSHA(root, revision string) *Service {\n\tvar revisionErr error\n\n\tcommitSHARegex := regexp.MustCompile(\"^[0-9A-Fa-f]{40}$\")\n\tif !commitSHARegex.MatchString(revision) {\n\t\trevisionErr = errors.New(\"not a commit SHA\")\n\t}\n\n\tservice, gitClient := newServiceWithOpt(func(gitClient *gitmocks.Client) {\n\t\tgitClient.On(\"Init\").Return(nil)\n\t\tgitClient.On(\"Fetch\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"Checkout\", mock.Anything, mock.Anything).Return(nil)\n\t\tgitClient.On(\"LsRemote\", revision).Return(revision, revisionErr)\n\t\tgitClient.On(\"CommitSHA\").Return(\"632039659e542ed7de0c170a4fcc1c571b288fc0\", nil)\n\t\tgitClient.On(\"Root\").Return(root)\n\t})\n\n\tservice.newGitClient = func(rawRepoURL string, creds git.Creds, insecure bool, enableLfs bool, proxy string, opts ...git.ClientOpts) (client git.Client, e error) {\n\t\treturn gitClient, nil\n\t}\n\n\treturn service\n}", "is_vulnerable": 0}
{"code": "\tif rf, ok := ret.Get(0).(func(string, kube.ResourceKey, func(v1alpha1.ResourceNode, string) bool) error); ok {\n\t\tr0 = rf(server, key, action)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}", "is_vulnerable": 0}
{"code": "func (fs *UnixFS) Mkdirat(dirfd int, name string, mode FileMode) error {\n\treturn convertErrorType(unix.Mkdirat(dirfd, name, uint32(mode)))\n}", "is_vulnerable": 0}
{"code": "func (fs *fileStat) Mode() FileMode     { return fs.mode }", "is_vulnerable": 0}
{"code": "func (f *Fosite) WriteRevocationResponse(rw http.ResponseWriter, err error) {\n\trw.Header().Set(\"Cache-Control\", \"no-store\")\n\trw.Header().Set(\"Pragma\", \"no-cache\")\n\n\tif err == nil {\n\t\trw.WriteHeader(http.StatusOK)\n\t\treturn\n\t}\n\n\tif errors.Is(err, ErrInvalidRequest) {\n\t\trw.Header().Set(\"Content-Type\", \"application/json;charset=UTF-8\")\n\n\t\tjs, err := json.Marshal(ErrInvalidRequest)\n\t\tif err != nil {\n\t\t\thttp.Error(rw, fmt.Sprintf(`{\"error\": \"%s\"}`, err.Error()), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\trw.WriteHeader(ErrInvalidRequest.Code)\n\t\t_, _ = rw.Write(js)\n\t} else if errors.Is(err, ErrInvalidClient) {\n\t\trw.Header().Set(\"Content-Type\", \"application/json;charset=UTF-8\")\n\n\t\tjs, err := json.Marshal(ErrInvalidClient)\n\t\tif err != nil {\n\t\t\thttp.Error(rw, fmt.Sprintf(`{\"error\": \"%s\"}`, err.Error()), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\trw.WriteHeader(ErrInvalidClient.Code)\n\t\t_, _ = rw.Write(js)\n\t} else {\n\t\t// 200 OK\n\t\trw.WriteHeader(http.StatusOK)\n\t}\n}", "is_vulnerable": 0}
{"code": "func chaCha20_ctr32_vsx(out, inp *byte, len int, key *[8]uint32, counter *uint32)\n\nfunc (c *Cipher) xorKeyStreamAsm(dst, src []byte) {\n\t// This implementation can handle buffers that aren't multiples of\n\t// 256.\n\tif len(src) >= bufSize {\n\t\tchaCha20_ctr32_vsx(&dst[0], &src[0], len(src), &c.key, &c.counter)\n\t} else if len(src)%bufSize != 0 {\n\t\tchaCha20_ctr32_vsx(&c.buf[0], &c.buf[0], bufSize, &c.key, &c.counter)\n\t\tstart := len(src) - len(src)%bufSize\n\t\tts, td, tb := src[start:], dst[start:], c.buf[:]\n\t\t// Unroll loop to XOR 32 bytes per iteration.\n\t\tfor i := 0; i < len(ts)-32; i += 32 {\n\t\t\ttd, tb = td[:len(ts)], tb[:len(ts)] // bounds check elimination\n\t\t\ts0 := binary.LittleEndian.Uint64(ts[0:8])\n\t\t\ts1 := binary.LittleEndian.Uint64(ts[8:16])\n\t\t\ts2 := binary.LittleEndian.Uint64(ts[16:24])\n\t\t\ts3 := binary.LittleEndian.Uint64(ts[24:32])\n\t\t\tb0 := binary.LittleEndian.Uint64(tb[0:8])\n\t\t\tb1 := binary.LittleEndian.Uint64(tb[8:16])\n\t\t\tb2 := binary.LittleEndian.Uint64(tb[16:24])\n\t\t\tb3 := binary.LittleEndian.Uint64(tb[24:32])\n\t\t\tbinary.LittleEndian.PutUint64(td[0:8], s0^b0)\n\t\t\tbinary.LittleEndian.PutUint64(td[8:16], s1^b1)\n\t\t\tbinary.LittleEndian.PutUint64(td[16:24], s2^b2)\n\t\t\tbinary.LittleEndian.PutUint64(td[24:32], s3^b3)\n\t\t\tts, td, tb = ts[32:], td[32:], tb[32:]\n\t\t}\n\t\ttd, tb = td[:len(ts)], tb[:len(ts)] // bounds check elimination\n\t\tfor i, v := range ts {\n\t\t\ttd[i] = tb[i] ^ v\n\t\t}\n\t\tc.len = bufSize - (len(src) % bufSize)\n\t}\n\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"valid StartupMessage\", func(t *testing.T) {\n\t\twant := &pgproto3.StartupMessage{\n\t\t\tProtocolVersion: pgproto3.ProtocolVersionNumber,\n\t\t\tParameters: map[string]string{\n\t\t\t\t\"username\": \"tester\",\n\t\t\t},\n\t\t}\n\t\tdst, err := want.Encode([]byte{})\n\t\trequire.NoError(t, err)\n\n\t\tserver := &interruptReader{}\n\t\tserver.push(dst)\n\n\t\tbackend := pgproto3.NewBackend(pgproto3.NewChunkReader(server), nil)\n\n\t\tmsg, err := backend.ReceiveStartupMessage()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, want, msg)\n\t})", "is_vulnerable": 0}
{"code": "\tbench.Run(fmt.Sprintf(\"%s-Gas=%d\", test.Name, reqGas), func(bench *testing.B) {\n\t\tbench.ReportAllocs()\n\t\tstart := time.Now().Nanosecond()\n\t\tbench.ResetTimer()\n\t\tfor i := 0; i < bench.N; i++ {\n\t\t\tcopy(data, in)\n\t\t\tres, _, err = RunPrecompiledContract(p, data, reqGas)\n\t\t}\n\t\tbench.StopTimer()\n\t\telapsed := float64(time.Now().Nanosecond() - start)\n\t\tif elapsed < 1 {\n\t\t\telapsed = 1\n\t\t}\n\t\tgasUsed := reqGas * uint64(bench.N)\n\t\tbench.ReportMetric(float64(reqGas), \"gas/op\")\n\t\tbench.ReportMetric(float64(gasUsed*1000)/elapsed, \"mgas/s\")\n\t\t//Check if it is correct\n\t\tif err != nil {\n\t\t\tbench.Error(err)\n\t\t\treturn\n\t\t}\n\t\tif common.Bytes2Hex(res) != test.Expected {\n\t\t\tbench.Error(fmt.Sprintf(\"Expected %v, got %v\", test.Expected, common.Bytes2Hex(res)))\n\t\t\treturn\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func TestListWorkflows_Order(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tworkflows := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(workflows)\n\n\tsortParameter, _ := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t}, models.WorkflowColumns)\n\t_, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}", "is_vulnerable": 0}
{"code": "func TestIsTrustedAddress(t *testing.T) {\n\tcases := []struct {\n\t\tname    string\n\t\tcidr    string\n\t\tpeer    string\n\t\ttrusted bool\n\t}{\n\t\t{\n\t\t\tname:    \"localhost client with port\",\n\t\t\tcidr:    \"\",\n\t\t\tpeer:    \"127.0.0.1:9901\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\t// Should never happen, added test case for testing it.\n\t\t\tname:    \"localhost client without port\",\n\t\t\tcidr:    \"\",\n\t\t\tpeer:    \"127.0.0.1\",\n\t\t\ttrusted: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"external client without trusted cidr\",\n\t\t\tcidr:    \"\",\n\t\t\tpeer:    \"172.0.0.1\",\n\t\t\ttrusted: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr in range\",\n\t\t\tcidr:    \"172.17.0.0/16,192.17.0.0/16\",\n\t\t\tpeer:    \"172.17.0.2:9901\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr in range with both ipv6 and ipv4\",\n\t\t\tcidr:    \"172.17.0.0/16,2001:db8:1234:1a00::/56\",\n\t\t\tpeer:    \"[2001:0db8:1234:1a00:0000:0000:0000:0000]:80\",\n\t\t\ttrusted: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"cidr outside range\",\n\t\t\tcidr:    \"172.17.0.0/16,172.17.0.0/16\",\n\t\t\tpeer:    \"110.17.0.2\",\n\t\t\ttrusted: false,\n\t\t},\n\t}\n\n\tfor _, tt := range cases {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif result := isTrustedAddress(tt.peer, strings.Split(tt.cidr, \",\")); result != tt.trusted {\n\t\t\t\tt.Errorf(\"Unexpected authentication result: want %v but got %v\",\n\t\t\t\t\ttt.trusted, result)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func Test_buildControlPlanePrefixRoute(t *testing.T) {\n\toptions := config.NewDefaultOptions()\n\tb := &Builder{filemgr: filemgr.NewManager()}\n\troute := b.buildControlPlanePrefixRoute(options, \"/hello/world/\", false, false)\n\ttestutil.AssertProtoJSONEqual(t, `\n\t\t{\n\t\t\t\"name\": \"pomerium-prefix-/hello/world/\",\n\t\t\t\"match\": {\n\t\t\t\t\"prefix\": \"/hello/world/\"\n\t\t\t},\n\t\t\t\"responseHeadersToAdd\": [\n\t\t\t\t{\n\t\t\t\t\t\"appendAction\": \"OVERWRITE_IF_EXISTS_OR_ADD\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t  \"key\": \"X-Frame-Options\",\n\t\t\t\t\t  \"value\": \"SAMEORIGIN\"\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"appendAction\": \"OVERWRITE_IF_EXISTS_OR_ADD\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t  \"key\": \"X-XSS-Protection\",\n\t\t\t\t\t  \"value\": \"1; mode=block\"\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"route\": {\n\t\t\t\t\"cluster\": \"pomerium-control-plane-http\"\n\t\t\t},\n\t\t\t\"typedPerFilterConfig\": {\n\t\t\t\t\"envoy.filters.http.ext_authz\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthzPerRoute\",\n\t\t\t\t\t\"disabled\": true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t`, route)\n}", "is_vulnerable": 1}
{"code": "func (*cacheClient) Delete(ctx context.Context, key string) error {\n\treturn cache.Default().Delete(ctx, key)\n}", "is_vulnerable": 1}
{"code": "func ApplyClusterPatches(patchContext networking.EnvoyFilter_PatchContext, proxy *model.Proxy,\n\tpush *model.PushContext, clusters []*xdsapi.Cluster) []*xdsapi.Cluster {\n\n\tenvoyFilterWrappers := push.EnvoyFilters(proxy)\n\tclustersRemoved := false\n\tfor _, efw := range envoyFilterWrappers {\n\t\tfor _, cp := range efw.Patches[networking.EnvoyFilter_CLUSTER] {\n\t\t\tif cp.Operation != networking.EnvoyFilter_Patch_REMOVE &&\n\t\t\t\tcp.Operation != networking.EnvoyFilter_Patch_MERGE {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor i := range clusters {\n\t\t\t\tif clusters[i] == nil {\n\t\t\t\t\t// deleted by the remove operation\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif commonConditionMatch(proxy, patchContext, cp) && clusterMatch(clusters[i], cp) {\n\t\t\t\t\tif cp.Operation == networking.EnvoyFilter_Patch_REMOVE {\n\t\t\t\t\t\tclusters[i] = nil\n\t\t\t\t\t\tclustersRemoved = true\n\t\t\t\t\t} else {\n\t\t\t\t\t\tproto.Merge(clusters[i], cp.Value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Add cluster if the operation is add, and patch context matches\n\t\tfor _, cp := range efw.Patches[networking.EnvoyFilter_CLUSTER] {\n\t\t\tif cp.Operation == networking.EnvoyFilter_Patch_ADD {\n\t\t\t\tif commonConditionMatch(proxy, patchContext, cp) {\n\t\t\t\t\tclusters = append(clusters, proto.Clone(cp.Value).(*xdsapi.Cluster))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif clustersRemoved {\n\t\ttrimmedClusters := make([]*xdsapi.Cluster, 0, len(clusters))\n\t\tfor i := range clusters {\n\t\t\tif clusters[i] == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ttrimmedClusters = append(trimmedClusters, clusters[i])\n\t\t}\n\t\tclusters = trimmedClusters\n\t}\n\treturn clusters\n}", "is_vulnerable": 1}
{"code": "func (va ClawbackVestingAccount) GetVestedCoins(blockTime time.Time) sdk.Coins {\n\t// It's likely that one or the other schedule will be nearly trivial,\n\t// so there should be little overhead in recomputing the conjunction each time.\n\tcoins := va.GetUnlockedOnly(blockTime).Min(va.GetVestedOnly(blockTime))\n\tif coins.IsZero() {\n\t\treturn nil\n\t}\n\treturn coins\n}", "is_vulnerable": 1}
{"code": "\t\treturn httpclient.RoundTripperFunc(func(req *http.Request) (*http.Response, error) {\n\t\t\tfor _, cookie := range forwardedCookies {\n\t\t\t\treq.AddCookie(cookie)\n\t\t\t}\n\t\t\tproxyutil.ClearCookieHeader(req, allowedCookies, disallowedCookies)\n\t\t\treturn next.RoundTrip(req)\n\t\t})", "is_vulnerable": 0}
{"code": "func (s *stepCounter) CaptureState(env *vm.EVM, pc uint64, op vm.OpCode, gas, cost uint64, memory *vm.Memory, stack *vm.Stack, rStack *vm.ReturnStack, contract *vm.Contract, depth int, err error) error {\n\ts.steps++\n\t// Enable this for more output\n\t//s.inner.CaptureState(env, pc, op, gas, cost, memory, stack, rStack, contract, depth, err)\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (web *Web) handleInstallCheckConfig(w http.ResponseWriter, r *http.Request) {\n\treq := &checkConfReq{}\n\n\terr := json.NewDecoder(r.Body).Decode(req)\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusBadRequest, \"decoding the request: %s\", err)\n\n\t\treturn\n\t}\n\n\tresp := &checkConfResp{}\n\ttcpPorts := aghalg.UniqChecker[tcpPort]{}\n\tif err = req.validateWeb(tcpPorts); err != nil {\n\t\tresp.Web.Status = err.Error()\n\t}\n\n\tif resp.DNS.CanAutofix, err = req.validateDNS(tcpPorts); err != nil {\n\t\tresp.DNS.Status = err.Error()\n\t} else if !req.DNS.IP.IsUnspecified() {\n\t\tresp.StaticIP = handleStaticIP(req.DNS.IP, req.SetStaticIP)\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\terr = json.NewEncoder(w).Encode(resp)\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"encoding the response: %s\", err)\n\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *infosController) DefaultCacheManager() (cache.Manager, error) {\n\tw, err := c.c.GetDefault()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn w.CacheManager(), nil\n}", "is_vulnerable": 0}
{"code": "func RandStringCharset(n int, charset string) string {\n\tb := make([]byte, n)\n\t// A src.Int63() generates 63 random bits, enough for letterIdxMax characters!\n\tfor i, cache, remain := n-1, src.Int63(), letterIdxMax; i >= 0; {\n\t\tif remain == 0 {\n\t\t\tcache, remain = src.Int63(), letterIdxMax\n\t\t}\n\t\tif idx := int(cache & letterIdxMask); idx < len(charset) {\n\t\t\tb[i] = charset[idx]\n\t\t\ti--\n\t\t}\n\t\tcache >>= letterIdxBits\n\t\tremain--\n\t}\n\treturn string(b)\n}", "is_vulnerable": 1}
{"code": "\tassertNoFilesInRoot := func(t testing.TB, fs afero.Fs) {\n\t\tt.Helper()\n\n\t\tallowableFiles := strset.New(\"tmp\")\n\n\t\t// list all files in root\n\t\tfiles, err := afero.ReadDir(fs, \"/\")\n\t\trequire.NoError(t, err)\n\n\t\tfor _, f := range files {\n\t\t\tassert.True(t, allowableFiles.Has(f.Name()), \"unexpected file in root: %s\", f.Name())\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func Test_setInstance(t *testing.T) {\n\ttype args struct {\n\t\tctx            context.Context\n\t\treq            interface{}\n\t\tinfo           *grpc.UnaryServerInfo\n\t\thandler        grpc.UnaryHandler\n\t\tverifier       authz.InstanceVerifier\n\t\theaderName     string\n\t\texternalDomain string\n\t}\n\ttype res struct {\n\t\twant interface{}\n\t\terr  bool\n\t}\n\ttests := []struct {\n\t\tname string\n\t\targs args\n\t\tres  res\n\t}{\n\t\t{\n\t\t\t\"hostname not found, error\",\n\t\t\targs{\n\t\t\t\tctx: context.Background(),\n\t\t\t},\n\t\t\tres{\n\t\t\t\twant: nil,\n\t\t\t\terr:  true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"invalid host, error\",\n\t\t\targs{\n\t\t\t\tctx:        metadata.NewIncomingContext(context.Background(), metadata.Pairs(\"header\", \"host2\")),\n\t\t\t\treq:        &mockRequest{},\n\t\t\t\tverifier:   &mockInstanceVerifier{\"host\"},\n\t\t\t\theaderName: \"header\",\n\t\t\t},\n\t\t\tres{\n\t\t\t\twant: nil,\n\t\t\t\terr:  true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\t\"valid host\",\n\t\t\targs{\n\t\t\t\tctx:        metadata.NewIncomingContext(context.Background(), metadata.Pairs(\"header\", \"host\")),\n\t\t\t\treq:        &mockRequest{},\n\t\t\t\tverifier:   &mockInstanceVerifier{\"host\"},\n\t\t\t\theaderName: \"header\",\n\t\t\t\thandler: func(ctx context.Context, req interface{}) (interface{}, error) {\n\t\t\t\t\treturn req, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\tres{\n\t\t\t\twant: &mockRequest{},\n\t\t\t\terr:  false,\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot, err := setInstance(tt.args.ctx, tt.args.req, tt.args.info, tt.args.handler, tt.args.verifier, tt.args.headerName, \"\", nil)\n\t\t\tif (err != nil) != tt.res.err {\n\t\t\t\tt.Errorf(\"setInstance() error = %v, wantErr %v\", err, tt.res.err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(got, tt.res.want) {\n\t\t\t\tt.Errorf(\"setInstance() got = %v, want %v\", got, tt.res.want)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *kubeGenericRuntimeManager) getSeccompProfile(annotations map[string]string, containerName string,\n\tpodSecContext *v1.PodSecurityContext, containerSecContext *v1.SecurityContext, fallbackToRuntimeDefault bool) (*runtimeapi.SecurityProfile, error) {\n\t// container fields are applied first\n\tif containerSecContext != nil && containerSecContext.SeccompProfile != nil {\n\t\treturn fieldSeccompProfile(containerSecContext.SeccompProfile, m.seccompProfileRoot, fallbackToRuntimeDefault)\n\t}\n\n\t// when container seccomp is not defined, try to apply from pod field\n\tif podSecContext != nil && podSecContext.SeccompProfile != nil {\n\t\treturn fieldSeccompProfile(podSecContext.SeccompProfile, m.seccompProfileRoot, fallbackToRuntimeDefault)\n\t}\n\n\tif fallbackToRuntimeDefault {\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t}, nil\n\t}\n\n\treturn &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func TestValidateTrustedIdentities(t *testing.T) {\n\n\t// No trusted identity prefix throws error\n\tpolicyDoc := dummyPolicyDocument()\n\tpolicyStatement := dummyPolicyStatement()\n\tpolicyStatement.TrustedIdentities = []string{\"C=US, ST=WA, O=wabbit-network.io, OU=org1\"}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr := policyDoc.Validate()\n\tif err == nil || err.Error() != \"trust policy statement \\\"test-statement-name\\\" has trusted identity \\\"C=US, ST=WA, O=wabbit-network.io, OU=org1\\\" missing separator\" {\n\t\tt.Fatalf(\"trusted identity without separator should return error\")\n\t}\n\n\t// Accept unknown identity prefixes\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tpolicyStatement.TrustedIdentities = []string{\"unknown:my-trusted-idenity\"}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"unknown identity prefix should not return an error. Error: %q\", err)\n\t}\n\n\t// Validate x509.subject identities\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN := \"x509.subject:,,,\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"parsing distinguished name (DN) \\\",,,\\\" failed with err: incomplete type, value pair. A valid DN must contain 'C', 'ST', and 'O' RDN attributes at a minimum, and follow RFC 4514 standard\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// Validate duplicate RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN = \"x509.subject:C=US,C=IN\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US,C=IN\\\" has duplicate RDN attribute for \\\"C\\\", DN can only have unique RDN attributes\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// Validate mandatory RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tinvalidDN = \"x509.subject:C=US,ST=WA\"\n\tpolicyStatement.TrustedIdentities = []string{invalidDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US,ST=WA\\\" has no mandatory RDN attribute for \\\"O\\\", it must contain 'C', 'ST', and 'O' RDN attributes at a minimum\" {\n\t\tt.Fatalf(\"invalid x509.subject identity should return error. Error : %q\", err)\n\t}\n\n\t// DN may have optional RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN := \"x509.subject:C=US,ST=WA,O=MyOrg,CustomRDN=CustomValue\"\n\tpolicyStatement.TrustedIdentities = []string{validDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"valid x509.subject identity should not return error. Error : %q\", err)\n\t}\n\n\t// Validate rfc4514 DNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN1 := \"x509.subject:C=US,ST=WA,O=MyOrg\"\n\tvalidDN2 := \"x509.subject:C=US,ST=WA,O=  My.  Org\"\n\tvalidDN3 := \"x509.subject:C=US,ST=WA,O=My \\\"special\\\" Org \\\\, \\\\; \\\\\\\\ others\"\n\tvalidDN4 := \"x509.subject:C=US,ST=WA,O=My Org,1.3.6.1.4.1.1466.0=#04024869\"\n\tpolicyStatement.TrustedIdentities = []string{validDN1, validDN2, validDN3, validDN4}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err != nil {\n\t\tt.Fatalf(\"valid x509.subject identity should not return error. Error : %q\", err)\n\t}\n\n\t// Validate overlapping DNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tvalidDN1 = \"x509.subject:C=US,ST=WA,O=MyOrg\"\n\tvalidDN2 = \"x509.subject:C=US,ST=WA,O=MyOrg,X=Y\"\n\tpolicyStatement.TrustedIdentities = []string{validDN1, validDN2}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"trust policy statement \\\"test-statement-name\\\" has overlapping x509 trustedIdentities, \\\"x509.subject:C=US,ST=WA,O=MyOrg\\\" overlaps with \\\"x509.subject:C=US,ST=WA,O=MyOrg,X=Y\\\"\" {\n\t\tt.Fatalf(\"overlapping DNs should return error\")\n\t}\n\n\t// Validate multi-valued RDNs\n\tpolicyDoc = dummyPolicyDocument()\n\tpolicyStatement = dummyPolicyStatement()\n\tmultiValduedRDN := \"x509.subject:C=US+ST=WA,O=MyOrg\"\n\tpolicyStatement.TrustedIdentities = []string{multiValduedRDN}\n\tpolicyDoc.TrustPolicies = []TrustPolicy{policyStatement}\n\terr = policyDoc.Validate()\n\tif err == nil || err.Error() != \"distinguished name (DN) \\\"C=US+ST=WA,O=MyOrg\\\" has multi-valued RDN attributes, remove multi-valued RDN attributes as they are not supported\" {\n\t\tt.Fatalf(\"multi-valued RDN should return error. Error : %q\", err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func OciRun(ctx context.Context, containerID string, args *OciArgs) error {\n\tdir, err := instance.GetDir(containerID, instance.OciSubDir)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\treturn err\n\t}\n\targs.SyncSocketPath = filepath.Join(dir, \"run.sock\")\n\n\tl, err := unix.CreateSocket(args.SyncSocketPath)\n\tif err != nil {\n\t\tos.Remove(args.SyncSocketPath)\n\t\treturn err\n\t}\n\n\tdefer l.Close()\n\n\tstatus := make(chan string, 1)\n\n\tif err := OciCreate(containerID, args); err != nil {\n\t\tdefer os.Remove(args.SyncSocketPath)\n\t\tif _, err1 := getState(containerID); err1 != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := OciDelete(ctx, containerID); err != nil {\n\t\t\tsylog.Warningf(\"can't delete container %s\", containerID)\n\t\t}\n\t\treturn err\n\t}\n\n\tdefer exitContainer(ctx, containerID, true)\n\tdefer os.Remove(args.SyncSocketPath)\n\n\tgo func() {\n\t\tvar state specs.State\n\n\t\tfor {\n\t\t\tc, err := l.Accept()\n\t\t\tif err != nil {\n\t\t\t\tstatus <- err.Error()\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tdec := json.NewDecoder(c)\n\t\t\tif err := dec.Decode(&state); err != nil {\n\t\t\t\tstatus <- err.Error()\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tc.Close()\n\n\t\t\tswitch state.Status {\n\t\t\tcase ociruntime.Created:\n\t\t\t\t// ignore error there and wait for stopped status\n\t\t\t\tOciStart(containerID)\n\t\t\tcase ociruntime.Running:\n\t\t\t\tstatus <- state.Status\n\t\t\tcase ociruntime.Stopped:\n\t\t\t\tstatus <- state.Status\n\t\t\t}\n\t\t}\n\t}()\n\n\t// wait running status\n\ts := <-status\n\tif s != ociruntime.Running {\n\t\treturn fmt.Errorf(\"%s\", s)\n\t}\n\n\tengineConfig, err := getEngineConfig(containerID)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := attach(engineConfig, true); err != nil {\n\t\t// kill container before deletion\n\t\tsylog.Errorf(\"%s\", err)\n\t\tOciKill(containerID, \"SIGKILL\", 1)\n\t\treturn err\n\t}\n\n\t// wait stopped status\n\ts = <-status\n\tif s != ociruntime.Stopped {\n\t\treturn fmt.Errorf(\"%s\", s)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tvisitor := func(entry TarFileEntry) error {\n\t\ttarget := filepath.Join(dst, entry.Header.Name)\n\n\t\tswitch entry.Header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// limit the reader on each file read to prevent decompression bomb attacks\n\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))\n\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {\n\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)\n\t\t\t}\n\n\t\t\tif err = f.Close(); err != nil {\n\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}", "is_vulnerable": 1}
{"code": "func (c *managedIdentityClient) createCloudShellAuthRequest(ctx context.Context, id ManagedIDKind, scopes []string) (*policy.Request, error) {\n\trequest, err := azruntime.NewRequest(ctx, http.MethodPost, c.endpoint)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\trequest.Raw().Header.Set(headerMetadata, \"true\")\n\tdata := url.Values{}\n\tdata.Set(\"resource\", strings.Join(scopes, \" \"))\n\tdataEncoded := data.Encode()\n\tbody := streaming.NopCloser(strings.NewReader(dataEncoded))\n\tif err := request.SetBody(body, \"application/x-www-form-urlencoded\"); err != nil {\n\t\treturn nil, err\n\t}\n\tif id != nil {\n\t\tlog.Write(EventAuthentication, \"WARNING: Cloud Shell doesn't support user-assigned managed identities\")\n\t\tq := request.Raw().URL.Query()\n\t\tif id.idKind() == miResourceID {\n\t\t\tq.Add(miResID, id.String())\n\t\t} else {\n\t\t\tq.Add(qpClientID, id.String())\n\t\t}\n\t}\n\treturn request, nil\n}", "is_vulnerable": 0}
{"code": "func ginkgoNodeFromCallExpr(fset *token.FileSet, ce *ast.CallExpr, ginkgoPackageName *string) (*ginkgoNode, bool) {\n\tpackageName, identName, ok := packageAndIdentNamesFromCallExpr(ce)\n\tif !ok {\n\t\treturn nil, false\n\t}\n\n\tn := ginkgoNode{}\n\tn.Name = identName\n\tn.Start, n.End = absoluteOffsetsForNode(fset, ce)\n\tn.Nodes = make([]*ginkgoNode, 0)\n\tswitch identName {\n\tcase \"It\", \"Specify\", \"Entry\":\n\t\tn.Spec = true\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\tn.Pending = pendingFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"FIt\", \"FSpecify\", \"FEntry\":\n\t\tn.Spec = true\n\t\tn.Focused = true\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"PIt\", \"PSpecify\", \"XIt\", \"XSpecify\", \"PEntry\", \"XEntry\":\n\t\tn.Spec = true\n\t\tn.Pending = true\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"Context\", \"Describe\", \"When\", \"DescribeTable\":\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\tn.Pending = pendingFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"FContext\", \"FDescribe\", \"FWhen\", \"FDescribeTable\":\n\t\tn.Focused = true\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"PContext\", \"PDescribe\", \"PWhen\", \"XContext\", \"XDescribe\", \"XWhen\", \"PDescribeTable\", \"XDescribeTable\":\n\t\tn.Pending = true\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\tn.Labels = labelFromCallExpr(ce)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"By\":\n\t\tn.Text = textOrAltFromCallExpr(ce, undefinedTextAlt)\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"AfterEach\", \"BeforeEach\":\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"JustAfterEach\", \"JustBeforeEach\":\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"AfterSuite\", \"BeforeSuite\":\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tcase \"SynchronizedAfterSuite\", \"SynchronizedBeforeSuite\":\n\t\treturn &n, ginkgoPackageName != nil && *ginkgoPackageName == packageName\n\tdefault:\n\t\treturn nil, false\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t *TestServerStream) RecvMsg(m interface{}) error {\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tmakeExpected := func(message, field string) *admissionv1.AdmissionResponse {\n\t\treturn webhookutils.ToAdmissionResponse([]metav1.StatusCause{\n\t\t\t{\n\t\t\t\tType:    metav1.CauseTypeFieldValueInvalid,\n\t\t\t\tMessage: message,\n\t\t\t\tField:   field,\n\t\t\t},\n\t\t})\n\t}\n\n\tDescribeTable(\"Should properly calculate the hotplugvolumes\", func(volumes []v1.Volume, statuses []v1.VolumeStatus, expected map[string]v1.Volume) {\n\t\tresult := getHotplugVolumes(volumes, statuses)\n\t\tExpect(equality.Semantic.DeepEqual(result, expected)).To(BeTrue(), \"result: %v and expected: %v do not match\", result, expected)\n\t},\n\t\tEntry(\"Should be empty if statuses is empty\", makeVolumes(), makeStatus(0, 0), emptyResult()),\n\t\tEntry(\"Should be empty if statuses has multiple entries, but no hotplug\", makeVolumes(), makeStatus(2, 0), emptyResult()),\n\t\tEntry(\"Should be empty if statuses has one entry, but no hotplug\", makeVolumes(), makeStatus(1, 0), emptyResult()),\n\t\tEntry(\"Should have a single hotplug if status has one hotplug\", makeVolumes(0, 1), makeStatus(2, 1), makeResult(1)),\n\t\tEntry(\"Should have a multiple hotplug if status has multiple hotplug\", makeVolumes(0, 1, 2, 3), makeStatus(4, 2), makeResult(2, 3)),\n\t)\n\n\tDescribeTable(\"Should properly calculate the permanent volumes\", func(volumes []v1.Volume, statusVolumes []v1.VolumeStatus, expected map[string]v1.Volume) {\n\t\tresult := getPermanentVolumes(volumes, statusVolumes)\n\t\tExpect(equality.Semantic.DeepEqual(result, expected)).To(BeTrue(), \"result: %v and expected: %v do not match\", result, expected)\n\t},\n\t\tEntry(\"Should be empty if volume is empty\", makeVolumes(), makeStatus(0, 0), emptyResult()),\n\t\tEntry(\"Should be empty if all volumes are hotplugged\", makeVolumes(0, 1, 2, 3), makeStatus(4, 4), emptyResult()),\n\t\tEntry(\"Should return all volumes if hotplugged is empty with multiple volumes\", makeVolumes(0, 1, 2, 3), makeStatus(4, 0), makeResult(0, 1, 2, 3)),\n\t\tEntry(\"Should return all volumes if hotplugged is empty with a single volume\", makeVolumes(0), makeStatus(1, 0), makeResult(0)),\n\t\tEntry(\"Should return 3 volumes if  1 hotplugged volume\", makeVolumes(0, 1, 2, 3), makeStatus(4, 1), makeResult(0, 1, 2)),\n\t)\n\n\tDescribeTable(\"Should return proper admission response\", func(newVolumes, oldVolumes []v1.Volume, newDisks, oldDisks []v1.Disk, volumeStatuses []v1.VolumeStatus, expected *admissionv1.AdmissionResponse) {\n\t\tnewVMI := api.NewMinimalVMI(\"testvmi\")\n\t\tnewVMI.Spec.Volumes = newVolumes\n\t\tnewVMI.Spec.Domain.Devices.Disks = newDisks\n\n\t\tresult := admitHotplug(newVolumes, oldVolumes, newDisks, oldDisks, volumeStatuses, newVMI, vmiUpdateAdmitter.ClusterConfig)\n\t\tExpect(equality.Semantic.DeepEqual(result, expected)).To(BeTrue(), \"result: %v and expected: %v do not match\", result, expected)\n\t},\n\t\tEntry(\"Should accept if no volumes are there or added\",\n\t\t\tmakeVolumes(),\n\t\t\tmakeVolumes(),\n\t\t\tmakeDisks(),\n\t\t\tmakeDisks(),\n\t\t\tmakeStatus(0, 0),\n\t\t\tnil),\n\t\tEntry(\"Should reject if #volumes != #disks\",\n\t\t\tmakeVolumes(1, 2),\n\t\t\tmakeVolumes(1, 2),\n\t\t\tmakeDisks(1),\n\t\t\tmakeDisks(1),\n\t\t\tmakeStatus(0, 0),\n\t\t\tmakeExpected(\"number of disks (1) does not equal the number of volumes (2)\", \"\")),\n\t\tEntry(\"Should reject if we remove a permanent volume\",\n\t\t\tmakeVolumes(),\n\t\t\tmakeVolumes(0),\n\t\t\tmakeDisks(),\n\t\t\tmakeDisks(0),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"Number of permanent volumes has changed\", \"\")),\n\t\tEntry(\"Should reject if we add a disk without a matching volume\",\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeVolumes(0),\n\t\t\tmakeDisksNoVolume(0, 1),\n\t\t\tmakeDisksNoVolume(0),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"Disk volume-name-1 does not exist\", \"\")),\n\t\tEntry(\"Should reject if we modify existing volume to be invalid\",\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeDisksNoVolume(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"permanent disk volume-name-0, changed\", \"\")),\n\t\tEntry(\"Should reject if a hotplug volume changed\",\n\t\t\tmakeInvalidVolumes(2, 1),\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"hotplug volume volume-name-1, changed\", \"\")),\n\t\tEntry(\"Should reject if we add volumes that are not PVC or DV\",\n\t\t\tmakeInvalidVolumes(2, 1),\n\t\t\tmakeVolumes(0),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeDisks(0),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"volume volume-name-1 is not a PVC or DataVolume\", \"\")),\n\t\tEntry(\"Should accept if we add volumes and disk properly\",\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeStatus(2, 1),\n\t\t\tnil),\n\t\tEntry(\"Should reject if we add disk with invalid bus\",\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeVolumes(0),\n\t\t\tmakeDisksInvalidBusLastDisk(0, 1),\n\t\t\tmakeDisks(0),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"hotplugged Disk volume-name-1 does not use a scsi bus\", \"\")),\n\t\tEntry(\"Should reject if we add disk with invalid boot order\",\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeVolumes(0),\n\t\t\tmakeDisksInvalidBootOrder(0, 1),\n\t\t\tmakeDisks(0),\n\t\t\tmakeStatus(1, 0),\n\t\t\tmakeExpected(\"spec.domain.devices.disks[1] must have a boot order > 0, if supplied\", \"spec.domain.devices.disks[1].bootOrder\")),\n\t\tEntry(\"Should accept if memory dump volume exists without matching disk\",\n\t\t\tmakeVolumesWithMemoryDumpVol(3, 2),\n\t\t\tmakeVolumes(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeDisks(0, 1),\n\t\t\tmakeStatus(3, 1),\n\t\t\tnil),\n\t\tEntry(\"Should reject if #volumes != #disks even when there is memory dump volume\",\n\t\t\tmakeVolumesWithMemoryDumpVol(3, 2),\n\t\t\tmakeVolumesWithMemoryDumpVol(3, 2),\n\t\t\tmakeDisks(1),\n\t\t\tmakeDisks(1),\n\t\t\tmakeStatus(0, 0),\n\t\t\tmakeExpected(\"number of disks (1) does not equal the number of volumes (2)\", \"\")),\n\t)\n\n\tDescribeTable(\"Admit or deny based on user\", func(user string, expected types.GomegaMatcher) {\n\t\tvmi := api.NewMinimalVMI(\"testvmi\")\n\t\tvmi.Spec.Volumes = makeVolumes(1)\n\t\tvmi.Spec.Domain.Devices.Disks = makeDisks(1)\n\t\tvmi.Status.VolumeStatus = makeStatus(1, 0)\n\t\tupdateVmi := vmi.DeepCopy()\n\t\tupdateVmi.Spec.Volumes = makeVolumes(2)\n\t\tupdateVmi.Spec.Domain.Devices.Disks = makeDisks(2)\n\t\tupdateVmi.Status.VolumeStatus = makeStatus(2, 1)\n\n\t\tnewVMIBytes, _ := json.Marshal(&updateVmi)\n\t\toldVMIBytes, _ := json.Marshal(&vmi)\n\t\tar := &admissionv1.AdmissionReview{\n\t\t\tRequest: &admissionv1.AdmissionRequest{\n\t\t\t\tUserInfo: authv1.UserInfo{Username: user},\n\t\t\t\tResource: webhooks.VirtualMachineInstanceGroupVersionResource,\n\t\t\t\tObject: runtime.RawExtension{\n\t\t\t\t\tRaw: newVMIBytes,\n\t\t\t\t},\n\t\t\t\tOldObject: runtime.RawExtension{\n\t\t\t\t\tRaw: oldVMIBytes,\n\t\t\t\t},\n\t\t\t\tOperation: admissionv1.Update,\n\t\t\t},\n\t\t}\n\t\tresp := vmiUpdateAdmitter.Admit(ar)\n\t\tExpect(resp.Allowed).To(expected)\n\t},\n\t\tEntry(\"Should admit internal sa\", \"system:serviceaccount:kubevirt:\"+rbac.ApiServiceAccountName, BeTrue()),\n\t\tEntry(\"Should reject regular user\", \"system:serviceaccount:someNamespace:someUser\", BeFalse()),\n\t)\n})", "is_vulnerable": 1}
{"code": "\t\t\trtCfg: func(ent bool) *extensioncommon.RuntimeConfig {\n\t\t\t\trt := makeTestRuntimeConfig(ent)\n\t\t\t\trt.Upstreams = nil\n\t\t\t\treturn rt\n\t\t\t},\n\t\t\tisInboundFilter: true,\n\t\t\tinputFilters:    makeTestHttpFilters,\n\t\t\terrStr:          \"no upstream found for remote service\",\n\t\t\texpPatched:      false,\n\t\t},\n\t}\n\n\tfor _, enterprise := range []bool{false, true} {\n\n\t\tfor name, c := range cases {\n\t\t\tc := c\n\t\t\tt.Run(fmt.Sprintf(\"%s_ent_%t\", name, enterprise), func(t *testing.T) {\n\t\t\t\tt.Parallel()\n\t\t\t\trtCfg := c.rtCfg(enterprise)\n\t\t\t\trtCfg.EnvoyExtension = api.EnvoyExtension{\n\t\t\t\t\tName:      c.extName,\n\t\t\t\t\tArguments: c.args(enterprise),\n\t\t\t\t}\n\n\t\t\t\tw, err := construct(rtCfg.EnvoyExtension)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, c.canApply, w.CanApply(rtCfg))\n\t\t\t\tif !c.canApply {\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\troute, patched, err := w.PatchRoute(c.rtCfg(enterprise), nil)\n\t\t\t\trequire.Nil(t, route)\n\t\t\t\trequire.False(t, patched)\n\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\tcluster, patched, err := w.PatchCluster(c.rtCfg(enterprise), nil)\n\t\t\t\trequire.Nil(t, cluster)\n\t\t\t\trequire.False(t, patched)\n\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\tinputHttpConMgr := makeHttpConMgr(t, c.inputFilters())\n\t\t\t\tobsHttpConMgr, patched, err := w.PatchFilter(c.rtCfg(enterprise), inputHttpConMgr, c.isInboundFilter)\n\t\t\t\tif c.errStr == \"\" {\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\trequire.Equal(t, c.expPatched, patched)\n\n\t\t\t\t\tcfg := testWasmConfigFromMap(t, c.args(enterprise))\n\t\t\t\t\texpHttpConMgr := makeHttpConMgr(t, c.expFilters(cfg))\n\n\t\t\t\t\tif c.debug {\n\t\t\t\t\t\tt.Logf(\"cfg =\\n%s\\n\\n\", cfg.toJSON(t))\n\t\t\t\t\t\tt.Logf(\"expFilterJSON =\\n%s\\n\\n\", protoToJSON(t, expHttpConMgr))\n\t\t\t\t\t\tt.Logf(\"obsfilterJSON =\\n%s\\n\\n\", protoToJSON(t, obsHttpConMgr))\n\t\t\t\t\t}\n\n\t\t\t\t\tprototest.AssertDeepEqual(t, expHttpConMgr, obsHttpConMgr)\n\t\t\t\t} else {\n\t\t\t\t\trequire.Error(t, err)\n\t\t\t\t\trequire.Contains(t, err.Error(), c.errStr)\n\t\t\t\t}\n\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\t\tif err := filepath.Walk(tempDir, func(p string, fi os.FileInfo, err error) error {\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tif !fi.IsDir() {\n\t\t\t\t\tmatches = append(matches, p)\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}); err != nil {", "is_vulnerable": 0}
{"code": "func (s *Service) loadCsvFile(fileName string) (*data.Frame, error) {\n\tvalidFileName := regexp.MustCompile(`^\\w+\\.csv$`)\n\n\tif !validFileName.MatchString(fileName) {\n\t\treturn nil, fmt.Errorf(\"invalid csv file name: %q\", fileName)\n\t}\n\n\tcsvFilepath := filepath.Clean(filepath.Join(\"/\", fileName))\n\tfilePath := filepath.Join(s.cfg.StaticRootPath, \"testdata\", csvFilepath)\n\n\t// Can ignore gosec G304 here, because we check the file pattern above\n\t// nolint:gosec\n\tfileReader, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed open file: %v\", err)\n\t}\n\n\tdefer func() {\n\t\tif err := fileReader.Close(); err != nil {\n\t\t\ts.logger.Warn(\"Failed to close file\", \"err\", err, \"path\", fileName)\n\t\t}\n\t}()\n\n\treturn LoadCsvContent(fileReader, fileName)\n}", "is_vulnerable": 0}
{"code": "func (mgr *MetricsManager) updateServer(cfg *Config) {\n\tif cfg.Options.MetricsAddr == mgr.addr &&\n\t\tcfg.Options.MetricsBasicAuth == mgr.basicAuth &&\n\t\tcfg.Options.InstallationID == mgr.installationID {\n\t\treturn\n\t}\n\n\tmgr.addr = cfg.Options.MetricsAddr\n\tmgr.basicAuth = cfg.Options.MetricsBasicAuth\n\tmgr.installationID = cfg.Options.InstallationID\n\tmgr.handler = nil\n\n\tif mgr.addr == \"\" {\n\t\tlog.Info(context.TODO()).Msg(\"metrics: http server disabled\")\n\t\treturn\n\t}\n\n\thandler, err := metrics.PrometheusHandler(EnvoyAdminURL, mgr.installationID)\n\tif err != nil {\n\t\tlog.Error(context.TODO()).Err(err).Msg(\"metrics: failed to create prometheus handler\")\n\t\treturn\n\t}\n\n\tif username, password, ok := cfg.Options.GetMetricsBasicAuth(); ok {\n\t\thandler = middleware.RequireBasicAuth(username, password)(handler)\n\t}\n\n\tmgr.handler = handler\n}", "is_vulnerable": 1}
{"code": "func (s *Server) UpdateConfigurationFiles() {\n\tpool := workerpool.New(runtime.NumCPU())\n\n\ts.Log().Debug(\"acquiring process configuration files...\")\n\tfiles := s.ProcessConfiguration().ConfigurationFiles\n\ts.Log().Debug(\"acquired process configuration files\")\n\tfor _, cf := range files {\n\t\tf := cf\n\n\t\tpool.Submit(func() {\n\t\t\tp, err := s.Filesystem().SafePath(f.FileName)\n\t\t\tif err != nil {\n\t\t\t\ts.Log().WithField(\"error\", err).Error(\"failed to generate safe path for configuration file\")\n\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif err := f.Parse(p, false); err != nil {\n\t\t\t\ts.Log().WithField(\"error\", err).Error(\"failed to parse and update server configuration file\")\n\t\t\t}\n\n\t\t\ts.Log().WithField(\"path\", f.FileName).Debug(\"finished processing server configuration file\")\n\t\t})\n\t}\n\n\tpool.StopWait()\n}", "is_vulnerable": 1}
{"code": "func getNmapURLs() (urls []string, err error) {\n\n\txml, err := ioutil.ReadFile(options.NmapFile)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tnmapXML, err := nmap.Parse(xml)\n\tif err != nil {\n\t\treturn\n\t}\n\n\t// parse the data and generate URL's\n\tfor _, host := range nmapXML.Hosts {\n\t\tfor _, address := range host.Addresses {\n\n\t\t\tif !lib.SliceContainsString([]string{\"ipv4\", \"ipv6\"}, address.AddrType) {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tfor _, port := range host.Ports {\n\t\t\t\t// skip port if the --open flag has been set and the port is filtered/closed\n\t\t\t\tif options.NmapOpenPortsOnly && port.State.State != \"open\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// skip port if the port id does not match the provided ports to filter\n\t\t\t\tif len(options.NmapPorts) > 0 && !lib.SliceContainsInt(options.NmapPorts, port.PortId) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// skip port if the service name flag has been set and the service name does not match the filter\n\t\t\t\tif len(options.NmapService) > 0 && !lib.SliceContainsString(options.NmapService, port.Service.Name) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// skip port if the service contains flag has been set and the service name does not contain the filter\n\t\t\t\tif len(options.NmapServiceContains) > 0 && !strings.Contains(port.Service.Name, options.NmapServiceContains) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// add the hostnames if the option has been set\n\t\t\t\tif options.NmapScanHostanmes {\n\t\t\t\t\tfor _, hn := range host.Hostnames {\n\t\t\t\t\t\turls = append(urls, buildURI(hn.Name, port.PortId)...)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// process the port successfully\n\t\t\t\turls = append(urls, buildURI(address.Addr, port.PortId)...)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func Contains(t TestingT, s interface{}, contains interface{}, msgAndArgs ...interface{}) {\n\tif assert.Contains(t, s, contains, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func (s *sigs) Get() ([]oci.Signature, error) {\n\tmanifest, err := s.Image.Manifest()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnumLayers := int64(len(manifest.Layers))\n\tif numLayers > maxLayers {\n\t\treturn nil, oci.NewMaxLayersExceeded(numLayers, maxLayers)\n\t}\n\tsignatures := make([]oci.Signature, 0, numLayers)\n\tfor _, desc := range manifest.Layers {\n\t\tl, err := s.Image.LayerByDigest(desc.Digest)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsignatures = append(signatures, signature.New(l, desc))\n\t}\n\treturn signatures, nil\n}", "is_vulnerable": 0}
{"code": "\tgo func() {\n\t\terr := srv.ListenAndServe()\n\t\tif err != http.ErrServerClosed {\n\t\t\tfmt.Fprintf(os.Stderr, \"could not start http server: %s\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}()", "is_vulnerable": 1}
{"code": "func (p *PgFortuneBackend) Run() error {\n\tdefer p.Close()\n\n\terr := p.handleStartup()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor {\n\t\tmsg, err := p.backend.Receive()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error receiving message: %w\", err)\n\t\t}\n\n\t\tswitch msg.(type) {\n\t\tcase *pgproto3.Query:\n\t\t\tresponse, err := p.responder()\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error generating query response: %w\", err)\n\t\t\t}\n\n\t\t\tbuf := mustEncode((&pgproto3.RowDescription{Fields: []pgproto3.FieldDescription{\n\t\t\t\t{\n\t\t\t\t\tName:                 []byte(\"fortune\"),\n\t\t\t\t\tTableOID:             0,\n\t\t\t\t\tTableAttributeNumber: 0,\n\t\t\t\t\tDataTypeOID:          25,\n\t\t\t\t\tDataTypeSize:         -1,\n\t\t\t\t\tTypeModifier:         -1,\n\t\t\t\t\tFormat:               0,\n\t\t\t\t},\n\t\t\t}}).Encode(nil))\n\t\t\tbuf = mustEncode((&pgproto3.DataRow{Values: [][]byte{response}}).Encode(buf))\n\t\t\tbuf = mustEncode((&pgproto3.CommandComplete{CommandTag: []byte(\"SELECT 1\")}).Encode(buf))\n\t\t\tbuf = mustEncode((&pgproto3.ReadyForQuery{TxStatus: 'I'}).Encode(buf))\n\t\t\t_, err = p.conn.Write(buf)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"error writing query response: %w\", err)\n\t\t\t}\n\t\tcase *pgproto3.Terminate:\n\t\t\treturn nil\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"received message other than Query from client: %#v\", msg)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func Install() error {\n\t// Make sure the RNG is seeded.\n\tseedrng.EnsureSeeded()\n\n\t// Configure logging before anything else.\n\tlogrus.SetFormatter(&logutils.Formatter{Component: \"cni-installer\"})\n\n\t// Clean up any existing binaries / config / assets.\n\tif err := os.RemoveAll(winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls\")); err != nil && !os.IsNotExist(err) {\n\t\tlogrus.WithError(err).Warnf(\"Error removing old TLS directory\")\n\t}\n\n\t// Load config.\n\tc := loadConfig()\n\n\t// Determine if we're running as a Kubernetes pod.\n\tvar kubecfg *rest.Config\n\n\tserviceAccountTokenFile := winutils.GetHostPath(\"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n\tc.ServiceAccountToken = make([]byte, 0)\n\tvar err error\n\tif fileExists(serviceAccountTokenFile) {\n\t\tlogrus.Info(\"Running as a Kubernetes pod\")\n\t\t// FIXME: get rid of this and call rest.InClusterConfig() directly when containerd v1.6 is EOL'd\n\t\tkubecfg, err = winutils.GetInClusterConfig()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = rest.LoadTLSFiles(kubecfg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tc.ServiceAccountToken, err = os.ReadFile(serviceAccountTokenFile)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Copy over any TLS assets from the SECRETS_MOUNT_DIR to the host.\n\t// First check if the dir exists and has anything in it.\n\tif directoryExists(c.TLSAssetsDir) {\n\t\t// Only install TLS assets if at least one of them exists in the dir.\n\t\tetcdCaPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-ca\")\n\t\tetcdCertPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-cert\")\n\t\tetcdKeyPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-key\")\n\t\tif !fileExists(etcdCaPath) && !fileExists(etcdCertPath) && !fileExists(etcdKeyPath) {\n\t\t\tlogrus.Infof(\"No TLS assets found in %s, skipping\", c.TLSAssetsDir)\n\t\t} else {\n\t\t\tlogrus.Info(\"Installing any TLS assets\")\n\t\t\tmkdir(winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls\"))\n\t\t\tif err := copyFileAndPermissions(etcdCaPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-ca\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-ca\")\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(etcdCertPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-cert\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-cert\")\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(etcdKeyPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-key\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-key\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Place the new binaries if the directory is writeable.\n\tdirs := []string{winutils.GetHostPath(\"/host/opt/cni/bin\"), winutils.GetHostPath(\"/host/secondary-bin-dir\")}\n\tbinsWritten := false\n\tfor _, d := range dirs {\n\t\tif err := fileutil.IsDirWriteable(d); err != nil {\n\t\t\tlogrus.Infof(\"%s is not writeable, skipping\", d)\n\t\t\tcontinue\n\t\t}\n\t\t// Don't exec the 'calico' binary later on if it has been skipped\n\t\tcalicoBinarySkipped := true\n\n\t\tcontainerBinDir := \"/opt/cni/bin/\"\n\t\t// The binaries dir in the container needs to be prepended by the CONTAINER_SANDBOX_MOUNT_POINT env var on Windows Host Process Containers\n\t\t// see https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/#containerd-v1-7-and-greater\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tcontainerBinDir = os.Getenv(\"CONTAINER_SANDBOX_MOUNT_POINT\") + \"/\" + containerBinDir\n\t\t}\n\t\t// Iterate through each binary we might want to install.\n\t\tfiles, err := os.ReadDir(containerBinDir)\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\t\tfor _, binary := range files {\n\t\t\ttarget := fmt.Sprintf(\"%s/%s\", d, binary.Name())\n\t\t\tsource := fmt.Sprintf(\"%s/%s\", containerBinDir, binary.Name())\n\t\t\t// Skip the 'install' binary as it is not needed on the host\n\t\t\tif binary.Name() == \"install\" || binary.Name() == \"install.exe\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif c.skipBinary(binary.Name()) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif fileExists(target) && !c.UpdateCNIBinaries {\n\t\t\t\tlogrus.Infof(\"Skipping installation of %s\", target)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(source, target); err != nil {\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed to install %s\", target)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tif binary.Name() == \"calico\" || binary.Name() == \"calico.exe\" {\n\t\t\t\tcalicoBinarySkipped = false\n\t\t\t}\n\t\t\tlogrus.Infof(\"Installed %s\", target)\n\t\t}\n\n\t\t// Binaries were placed into at least one directory\n\t\tlogrus.Infof(\"Wrote Calico CNI binaries to %s\\n\", d)\n\t\tbinsWritten = true\n\n\t\t// Don't exec the 'calico' binary later on if it has been skipped\n\t\tif !calicoBinarySkipped {\n\t\t\t// Print CNI plugin version to confirm that the binary was actually written.\n\t\t\t// If this fails, it means something has gone wrong so we should retry.\n\t\t\tcmd := exec.Command(d+\"/calico\", \"-v\")\n\t\t\tvar out bytes.Buffer\n\t\t\tcmd.Stdout = &out\n\t\t\terr = cmd.Run()\n\t\t\tif err != nil {\n\t\t\t\tlogrus.WithError(err).Warnf(\"Failed getting CNI plugin version from installed binary, exiting\")\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tlogrus.Infof(\"CNI plugin version: %s\", out.String())\n\t\t}\n\t}\n\n\t// If binaries were not placed, exit\n\tif !binsWritten {\n\t\tlogrus.WithError(err).Fatalf(\"found no writeable directory, exiting\")\n\t}\n\n\tif kubecfg != nil {\n\t\t// If running as a Kubernetes pod, then write out a kubeconfig for the\n\t\t// CNI plugin to use.\n\t\twriteKubeconfig(kubecfg)\n\t}\n\n\t// Write a CNI config file.\n\twriteCNIConfig(c)\n\n\t// Unless told otherwise, sleep forever.\n\t// This prevents Kubernetes from restarting the pod repeatedly.\n\tlogrus.Infof(\"Done configuring CNI.  Sleep= %v\", c.ShouldSleep)\n\tfor c.ShouldSleep {\n\t\t// Kubernetes Secrets can be updated.  If so, we need to install the updated\n\t\t// version to the host. Just check the timestamp on the certificate to see if it\n\t\t// has been updated.  A bit hokey, but likely good enough.\n\t\tfilename := c.TLSAssetsDir + \"/etcd-cert\"\n\n\t\twatcher, err := fsnotify.NewWatcher()\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\n\t\tdone := make(chan bool)\n\n\t\t// Process events\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-watcher.Events:\n\t\t\t\t\tlogrus.Infoln(\"Updating installed secrets at:\", time.Now().String())\n\t\t\t\t\tfiles, err := os.ReadDir(c.TLSAssetsDir)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlogrus.Warn(err)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, f := range files {\n\t\t\t\t\t\tif err = copyFileAndPermissions(winutils.GetHostPath(c.TLSAssetsDir+\"/\"+f.Name()), winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/\"+f.Name())); err != nil {\n\t\t\t\t\t\t\tlogrus.Warn(err)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase err := <-watcher.Errors:\n\t\t\t\t\tlogrus.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\terr = watcher.Add(filename)\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\n\t\t<-done\n\n\t\twatcher.Close()\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\t\tsetup: func() sdk.Coin {\n\t\t\t\terr := setupClawbackVestingAccount(ctx, nw, delegatorAddr, funderAddr, testutil.TestVestingSchedule.TotalVestingCoins)\n\t\t\t\trequire.NoError(t, err)\n\n\t\t\t\t// Between first and second lockup periods\n\t\t\t\t// vested coins are unlocked\n\t\t\t\tlockDuration := time.Duration(testutil.TestVestingSchedule.LockupPeriodLength)\n\t\t\t\tnw.NextBlockAfter(lockDuration * time.Second)\n\t\t\t\tctx = nw.GetContext()\n\n\t\t\t\tacc := nw.App.AccountKeeper.GetAccount(ctx, delegatorAddr)\n\t\t\t\tvestAcc, ok := acc.(*vestingtypes.ClawbackVestingAccount)\n\t\t\t\trequire.True(t, ok)\n\n\t\t\t\tunlockedVested := vestAcc.GetUnlockedVestedCoins(ctx.BlockTime())\n\t\t\t\trequire.True(t, unlockedVested.IsAllGT(sdk.NewCoins()))\n\n\t\t\t\t// returned delegation coins are the locked vested coins\n\t\t\t\treturn unlockedVested[0]\n\t\t\t},\n\t\t\texpErr: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tnw = network.NewUnitTestNetwork()\n\t\t\tctx = nw.GetContext()\n\t\t\tdelCoin := tc.setup()\n\n\t\t\tsrv := keeper.NewMsgServerImpl(&nw.App.StakingKeeper)\n\t\t\tres, err := srv.Delegate(ctx, &types.MsgDelegate{\n\t\t\t\tDelegatorAddress: delegatorAddr.String(),\n\t\t\t\tValidatorAddress: nw.GetValidators()[0].OperatorAddress,\n\t\t\t\tAmount:           delCoin,\n\t\t\t})\n\n\t\t\tif tc.expErr {\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.Contains(t, err.Error(), tc.errMsg)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.NotNil(t, res)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (va ClawbackVestingAccount) GetLockedUpCoins(blockTime time.Time) sdk.Coins {\n\treturn va.OriginalVesting.Sub(va.GetUnlockedCoins(blockTime)...)\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_outgoingWrapper_OK(t *testing.T) {\n\tconfig := Config{\n\t\tCAFile:               \"../test/hostname/CertAuth.crt\",\n\t\tCertFile:             \"../test/hostname/Alice.crt\",\n\t\tKeyFile:              \"../test/hostname/Alice.key\",\n\t\tVerifyServerHostname: true,\n\t\tVerifyOutgoing:       true,\n\t\tDomain:               \"consul\",\n\t}\n\n\tclient, errc := startTLSServer(&config)\n\tif client == nil {\n\t\tt.Fatalf(\"startTLSServer err: %v\", <-errc)\n\t}\n\n\tc, err := NewConfigurator(config, nil)\n\trequire.NoError(t, err)\n\twrap := c.OutgoingRPCWrapper()\n\trequire.NotNil(t, wrap)\n\n\ttlsClient, err := wrap(\"dc1\", client)\n\trequire.NoError(t, err)\n\n\tdefer tlsClient.Close()\n\terr = tlsClient.(*tls.Conn).Handshake()\n\trequire.NoError(t, err)\n\n\terr = <-errc\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) ExecuteWindows(ctx context.Context, in *sliverpb.ExecuteWindowsReq, opts ...grpc.CallOption) (*sliverpb.Execute, error) {\n\tout := new(sliverpb.Execute)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/ExecuteWindows\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (a *Agent) checkHostSignature(hostport string, remote net.Addr, key ssh.PublicKey) error {\n\tcert, ok := key.(*ssh.Certificate)\n\tif !ok {\n\t\treturn trace.BadParameter(\"expected certificate\")\n\t}\n\tcas, err := a.AccessPoint.GetCertAuthorities(services.HostCA, false)\n\tif err != nil {\n\t\treturn trace.Wrap(err, \"failed to fetch remote certs\")\n\t}\n\tfor _, ca := range cas {\n\t\tcheckers, err := ca.Checkers()\n\t\tif err != nil {\n\t\t\treturn trace.BadParameter(\"error parsing key: %v\", err)\n\t\t}\n\t\tfor _, checker := range checkers {\n\t\t\tif sshutils.KeysEqual(checker, cert.SignatureKey) {\n\t\t\t\ta.setPrincipals(cert.ValidPrincipals)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\treturn trace.NotFound(\n\t\t\"no matching keys found when checking server's host signature\")\n}", "is_vulnerable": 1}
{"code": "func generateRecoveryCodes(w http.ResponseWriter, r *http.Request) {\n\tr.Body = http.MaxBytesReader(w, r.Body, maxRequestSize)\n\tclaims, err := getTokenClaims(r)\n\tif err != nil || claims.Username == \"\" {\n\t\tsendAPIResponse(w, r, err, \"Invalid token claims\", http.StatusBadRequest)\n\t\treturn\n\t}\n\trecoveryCodes := make([]string, 0, 12)\n\taccountRecoveryCodes := make([]dataprovider.RecoveryCode, 0, 12)\n\tfor i := 0; i < 12; i++ {\n\t\tcode := getNewRecoveryCode()\n\t\trecoveryCodes = append(recoveryCodes, code)\n\t\taccountRecoveryCodes = append(accountRecoveryCodes, dataprovider.RecoveryCode{Secret: kms.NewPlainSecret(code)})\n\t}\n\tif claims.hasUserAudience() {\n\t\tuser, err := dataprovider.UserExists(claims.Username)\n\t\tif err != nil {\n\t\t\tsendAPIResponse(w, r, err, \"\", getRespStatus(err))\n\t\t\treturn\n\t\t}\n\t\tif !user.Filters.TOTPConfig.Enabled {\n\t\t\tsendAPIResponse(w, r, errRecoveryCodeForbidden, \"\", http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tuser.Filters.RecoveryCodes = accountRecoveryCodes\n\t\tif err := dataprovider.UpdateUser(&user, dataprovider.ActionExecutorSelf, util.GetIPFromRemoteAddress(r.RemoteAddr)); err != nil {\n\t\t\tsendAPIResponse(w, r, err, \"\", getRespStatus(err))\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tadmin, err := dataprovider.AdminExists(claims.Username)\n\t\tif err != nil {\n\t\t\tsendAPIResponse(w, r, err, \"\", getRespStatus(err))\n\t\t\treturn\n\t\t}\n\t\tif !admin.Filters.TOTPConfig.Enabled {\n\t\t\tsendAPIResponse(w, r, errRecoveryCodeForbidden, \"\", http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tadmin.Filters.RecoveryCodes = accountRecoveryCodes\n\t\tif err := dataprovider.UpdateAdmin(&admin, dataprovider.ActionExecutorSelf, util.GetIPFromRemoteAddress(r.RemoteAddr)); err != nil {\n\t\t\tsendAPIResponse(w, r, err, \"\", getRespStatus(err))\n\t\t\treturn\n\t\t}\n\t}\n\n\trender.JSON(w, r, recoveryCodes)\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleMkcol(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\treqPath, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\trelease, status, err := h.confirmLocks(r, reqPath, \"\")\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\treqPath = path.Join(user.BasePath, reqPath)\n\n\tif r.ContentLength > 0 {\n\t\treturn http.StatusUnsupportedMediaType, nil\n\t}\n\tif err := fs.MakeDir(ctx, reqPath); err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn http.StatusConflict, err\n\t\t}\n\t\treturn http.StatusMethodNotAllowed, err\n\t}\n\tfs.ClearCache(path.Dir(reqPath))\n\treturn http.StatusCreated, nil\n}", "is_vulnerable": 1}
{"code": "func TestAPIEndpoint_Metrics_QueryMetricsV2(t *testing.T) {\n\tqds := query.ProvideService(\n\t\tsetting.NewCfg(),\n\t\tnil,\n\t\tnil,\n\t\t&fakePluginRequestValidator{},\n\t\tfakes.NewFakeSecretsService(),\n\t\t&fakePluginClient{\n\t\t\tQueryDataHandlerFunc: func(ctx context.Context, req *backend.QueryDataRequest) (*backend.QueryDataResponse, error) {\n\t\t\t\tresp := backend.Responses{\n\t\t\t\t\t\"A\": backend.DataResponse{\n\t\t\t\t\t\tError: fmt.Errorf(\"query failed\"),\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\treturn &backend.QueryDataResponse{Responses: resp}, nil\n\t\t\t},\n\t\t},\n\t\t&fakeOAuthTokenService{},\n\t)\n\tserverFeatureEnabled := SetupAPITestServer(t, func(hs *HTTPServer) {\n\t\ths.queryDataService = qds\n\t\ths.Features = featuremgmt.WithFeatures(featuremgmt.FlagDatasourceQueryMultiStatus, true)\n\t})\n\tserverFeatureDisabled := SetupAPITestServer(t, func(hs *HTTPServer) {\n\t\ths.queryDataService = qds\n\t\ths.Features = featuremgmt.WithFeatures(featuremgmt.FlagDatasourceQueryMultiStatus, false)\n\t})\n\n\tt.Run(\"Status code is 400 when data source response has an error and feature toggle is disabled\", func(t *testing.T) {\n\t\treq := serverFeatureDisabled.NewPostRequest(\"/api/ds/query\", strings.NewReader(queryDatasourceInput))\n\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{UserId: 1, OrgId: 1, OrgRole: models.ROLE_VIEWER})\n\t\tresp, err := serverFeatureDisabled.SendJSON(req)\n\t\trequire.NoError(t, err)\n\t\trequire.NoError(t, resp.Body.Close())\n\t\trequire.Equal(t, http.StatusBadRequest, resp.StatusCode)\n\t})\n\n\tt.Run(\"Status code is 207 when data source response has an error and feature toggle is enabled\", func(t *testing.T) {\n\t\treq := serverFeatureEnabled.NewPostRequest(\"/api/ds/query\", strings.NewReader(queryDatasourceInput))\n\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{UserId: 1, OrgId: 1, OrgRole: models.ROLE_VIEWER})\n\t\tresp, err := serverFeatureEnabled.SendJSON(req)\n\t\trequire.NoError(t, err)\n\t\trequire.NoError(t, resp.Body.Close())\n\t\trequire.Equal(t, http.StatusMultiStatus, resp.StatusCode)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) GetRequestedAudience() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetRequestedAudience\", reflect.TypeOf((*MockAccessRequester)(nil).GetRequestedAudience))\n}", "is_vulnerable": 0}
{"code": "func TestPasswordLength(t *testing.T) {\n\tfor i := 0; i <= 128; i++ {\n\t\ts, err := Password(i)\n\t\trequire.NoError(t, err)\n\t\t// expected length is number of bytes rounded up\n\t\texpected := i / 8\n\t\tif i%8 != 0 {\n\t\t\texpected++\n\t\t}\n\t\t// then converted to base 64\n\t\texpected = (expected*8 + 5) / 6\n\t\tassert.Equal(t, expected, len(s), i)\n\t}\n}", "is_vulnerable": 0}
{"code": "func untarAll(reader io.Reader, destFile, prefix string) error {\n\tentrySeq := -1\n\n\t// TODO: use compression here?\n\ttarReader := tar.NewReader(reader)\n\tfor {\n\t\theader, err := tarReader.Next()\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tentrySeq++\n\t\tmode := header.FileInfo().Mode()\n\t\toutFileName := path.Join(destFile, header.Name[len(prefix):])\n\t\tbaseName := path.Dir(outFileName)\n\t\tif err := os.MkdirAll(baseName, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif header.FileInfo().IsDir() {\n\t\t\tif err := os.MkdirAll(outFileName, 0755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// handle coping remote file into local directory\n\t\tif entrySeq == 0 && !header.FileInfo().IsDir() {\n\t\t\texists, err := dirExists(outFileName)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif exists {\n\t\t\t\toutFileName = filepath.Join(outFileName, path.Base(header.Name))\n\t\t\t}\n\t\t}\n\n\t\tif mode&os.ModeSymlink != 0 {\n\t\t\terr := os.Symlink(header.Linkname, outFileName)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\toutFile, err := os.Create(outFileName)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer outFile.Close()\n\t\t\tif _, err := io.Copy(outFile, tarReader); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := outFile.Close(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tif entrySeq == -1 {\n\t\t//if no file was copied\n\t\terrInfo := fmt.Sprintf(\"error: %s no such file or directory\", prefix)\n\t\treturn errors.New(errInfo)\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func newFileBasedRingBuffer(\n\tfd *os.File,\n\tconfig_obj *config_proto.Config,\n\tlog_ctx *logging.LogContext) (*FileBasedRingBuffer, error) {\n\n\theader := &Header{\n\t\t// Pad the header a bit to allow for extensions.\n\t\tWritePointer:   FirstRecordOffset,\n\t\tAvailableBytes: 0,\n\t\tLeasedBytes:    0,\n\t\tReadPointer:    FirstRecordOffset,\n\t\tMaxSize: int64(config_obj.Client.LocalBuffer.DiskSize) +\n\t\t\tFirstRecordOffset,\n\t}\n\tdata := make([]byte, FirstRecordOffset)\n\tn, err := fd.ReadAt(data, 0)\n\tif n > 0 && n < FirstRecordOffset && err == io.EOF {\n\t\tlog_ctx.Error(\"Possible corruption detected: file too short.\")\n\t\terr = fd.Truncate(0)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif n > 0 && (err == nil || err == io.EOF) {\n\t\terr := header.UnmarshalBinary(data[:n])\n\t\t// The header is not valid, truncate the file and\n\t\t// start again.\n\t\tif err != nil {\n\t\t\tlog_ctx.Errorf(\"Possible corruption detected: %v.\", err)\n\t\t\terr = fd.Truncate(0)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\t// If we opened a file which is not yet fully committed adjust\n\t// the available bytes again so we can replay the lost\n\t// messages.\n\tif header.LeasedBytes != 0 {\n\t\theader.AvailableBytes += header.LeasedBytes\n\t\theader.LeasedBytes = 0\n\t}\n\n\tresult := &FileBasedRingBuffer{\n\t\tconfig_obj:     config_obj,\n\t\tfd:             fd,\n\t\theader:         header,\n\t\tread_buf:       make([]byte, 8),\n\t\twrite_buf:      make([]byte, 8),\n\t\tleased_pointer: header.ReadPointer,\n\t\tlog_ctx:        log_ctx,\n\t}\n\n\tresult.c = sync.NewCond(&result.mu)\n\n\tlog_ctx.WithFields(logrus.Fields{\n\t\t\"filename\": fd.Name(),\n\t\t\"max_size\": result.header.MaxSize,\n\t}).Info(\"Ring Buffer: Creation\")\n\n\treturn result, nil\n}", "is_vulnerable": 0}
{"code": "func (k ed25519PublicKey) Verify(b []byte, sig *Signature) error {\n\tif sig.Format != k.Type() {\n\t\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\n\t}\n\tif l := len(k); l != ed25519.PublicKeySize {\n\t\treturn fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\n\t}\n\n\tif ok := ed25519.Verify(ed25519.PublicKey(k), b, sig.Blob); !ok {\n\t\treturn errors.New(\"ssh: signature did not verify\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessRequesterMockRecorder) GetRequestForm() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetRequestForm\", reflect.TypeOf((*MockAccessRequester)(nil).GetRequestForm))\n}", "is_vulnerable": 0}
{"code": "func InstanceInterceptor(verifier authz.InstanceVerifier, headerName, externalDomain string, ignoredPrefixes ...string) *instanceInterceptor {\n\treturn &instanceInterceptor{\n\t\tverifier:        verifier,\n\t\theaderName:      headerName,\n\t\texternalDomain:  externalDomain,\n\t\tignoredPrefixes: ignoredPrefixes,\n\t\ttranslator:      newZitadelTranslator(),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (j JuiceFileUtils) GetUsedSpace(juicefsPath string) (usedSpace int64, err error) {\n\tvar (\n\t\tcommand = []string{\"df\", \"--block-size=1\"}\n\t\tstdout  string\n\t\tstderr  string\n\t)\n\n\tstdout, stderr, err = j.exec(command)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"execute command %v with expectedErr: %v stdout %s and stderr %s\", command, err, stdout, stderr)\n\t\treturn\n\t}\n\n\tvar str string\n\tlines := strings.Split(stdout, \"\\n\")\n\tfor _, line := range lines {\n\t\tif strings.Contains(line, juicefsPath) {\n\t\t\tstr = line\n\t\t\tbreak\n\t\t}\n\t}\n\t// [<Filesystem>       <Size>  <Used> <Avail> <Use>% <Mounted on>]\n\tdata := strings.Fields(str)\n\tif len(data) != 6 {\n\t\terr = fmt.Errorf(\"failed to parse %s in GetUsedSpace method\", data)\n\t\treturn\n\t}\n\n\tusedSpace, err = strconv.ParseInt(data[2], 10, 64)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn usedSpace, err\n}", "is_vulnerable": 0}
{"code": "func (src *Query) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'Q')\n\tdst = append(dst, src.String...)\n\tdst = append(dst, 0)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func (hs *HTTPServer) checkDatasourceHealth(c *models.ReqContext, ds *datasources.DataSource) response.Response {\n\tplugin, exists := hs.pluginStore.Plugin(c.Req.Context(), ds.Type)\n\tif !exists {\n\t\treturn response.Error(http.StatusInternalServerError, \"Unable to find datasource plugin\", nil)\n\t}\n\n\tdsInstanceSettings, err := adapters.ModelToInstanceSettings(ds, hs.decryptSecureJsonDataFn(c.Req.Context()))\n\tif err != nil {\n\t\treturn response.Error(http.StatusInternalServerError, \"Unable to get datasource model\", err)\n\t}\n\treq := &backend.CheckHealthRequest{\n\t\tPluginContext: backend.PluginContext{\n\t\t\tUser:                       adapters.BackendUserFromSignedInUser(c.SignedInUser),\n\t\t\tOrgID:                      c.OrgId,\n\t\t\tPluginID:                   plugin.ID,\n\t\t\tDataSourceInstanceSettings: dsInstanceSettings,\n\t\t},\n\t\tHeaders: map[string]string{},\n\t}\n\n\tvar dsURL string\n\tif req.PluginContext.DataSourceInstanceSettings != nil {\n\t\tdsURL = req.PluginContext.DataSourceInstanceSettings.URL\n\t}\n\n\terr = hs.PluginRequestValidator.Validate(dsURL, c.Req)\n\tif err != nil {\n\t\treturn response.Error(http.StatusForbidden, \"Access denied\", err)\n\t}\n\n\tif hs.DataProxy.OAuthTokenService.IsOAuthPassThruEnabled(ds) {\n\t\tif token := hs.DataProxy.OAuthTokenService.GetCurrentOAuthToken(c.Req.Context(), c.SignedInUser); token != nil {\n\t\t\treq.Headers[\"Authorization\"] = fmt.Sprintf(\"%s %s\", token.Type(), token.AccessToken)\n\t\t\tidToken, ok := token.Extra(\"id_token\").(string)\n\t\t\tif ok && idToken != \"\" {\n\t\t\t\treq.Headers[\"X-ID-Token\"] = idToken\n\t\t\t}\n\t\t}\n\t}\n\n\tproxyutil.ClearCookieHeader(c.Req, ds.AllowedCookies(), []string{hs.Cfg.LoginCookieName})\n\tif cookieStr := c.Req.Header.Get(\"Cookie\"); cookieStr != \"\" {\n\t\treq.Headers[\"Cookie\"] = cookieStr\n\t}\n\n\tresp, err := hs.pluginClient.CheckHealth(c.Req.Context(), req)\n\tif err != nil {\n\t\treturn translatePluginRequestErrorToAPIError(err)\n\t}\n\n\tpayload := map[string]interface{}{\n\t\t\"status\":  resp.Status.String(),\n\t\t\"message\": resp.Message,\n\t}\n\n\t// Unmarshal JSONDetails if it's not empty.\n\tif len(resp.JSONDetails) > 0 {\n\t\tvar jsonDetails map[string]interface{}\n\t\terr = json.Unmarshal(resp.JSONDetails, &jsonDetails)\n\t\tif err != nil {\n\t\t\treturn response.Error(http.StatusInternalServerError, \"Failed to unmarshal detailed response from backend plugin\", err)\n\t\t}\n\n\t\tpayload[\"details\"] = jsonDetails\n\t}\n\n\tif resp.Status != backend.HealthStatusOk {\n\t\treturn response.JSON(http.StatusBadRequest, payload)\n\t}\n\n\treturn response.JSON(http.StatusOK, payload)\n}", "is_vulnerable": 0}
{"code": "func (kp kmsKeyHandler) decryptHandler(env Envelope) (CipherDataDecrypter, error) {\n\tm := MaterialDescription{}\n\terr := m.decodeDescription([]byte(env.MatDesc))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcmkID, ok := m[\"kms_cmk_id\"]\n\tif !ok {\n\t\treturn nil, awserr.New(\"MissingCMKIDError\", \"Material description is missing CMK ID\", nil)\n\t}\n\n\tkp.CipherData.MaterialDescription = m\n\tkp.cmkID = cmkID\n\tkp.WrapAlgorithm = KMSWrap\n\treturn &kp, nil\n}", "is_vulnerable": 1}
{"code": "func TestCheckerValidateFIPS(t *testing.T) {\n\tchecker := CertChecker{\n\t\tFIPS: true,\n\t}\n\n\trsaKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\trequire.NoError(t, err)\n\tsmallRSAKey, err := rsa.GenerateKey(rand.Reader, 1024)\n\trequire.NoError(t, err)\n\tellipticKey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\trequire.NoError(t, err)\n\n\t// 2048-bit RSA keys are valid.\n\tcryptoKey := rsaKey.Public()\n\tsshKey, err := ssh.NewPublicKey(cryptoKey)\n\trequire.NoError(t, err)\n\terr = checker.validateFIPS(sshKey)\n\trequire.NoError(t, err)\n\n\t// 1024-bit RSA keys are not valid.\n\tcryptoKey = smallRSAKey.Public()\n\tsshKey, err = ssh.NewPublicKey(cryptoKey)\n\trequire.NoError(t, err)\n\terr = checker.validateFIPS(sshKey)\n\trequire.Error(t, err)\n\n\t// ECDSA keys are not valid.\n\tcryptoKey = ellipticKey.Public()\n\tsshKey, err = ssh.NewPublicKey(cryptoKey)\n\trequire.NoError(t, err)\n\terr = checker.validateFIPS(sshKey)\n\trequire.Error(t, err)\n}", "is_vulnerable": 0}
{"code": "func (mr *MockResourceOwnerPasswordCredentialsGrantStorageMockRecorder) GetAccessTokenSession(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetAccessTokenSession\", reflect.TypeOf((*MockResourceOwnerPasswordCredentialsGrantStorage)(nil).GetAccessTokenSession), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func enableExternalNameService(t *testing.T) func(eh *contour.EventHandler) {\n\treturn func(eh *contour.EventHandler) {\n\n\t\tlog := fixture.NewTestLogger(t)\n\t\tlog.SetLevel(logrus.DebugLevel)\n\n\t\teh.Builder.Processors = []dag.Processor{\n\t\t\t&dag.IngressProcessor{\n\t\t\t\tEnableExternalNameService: true,\n\t\t\t\tFieldLogger:               log.WithField(\"context\", \"IngressProcessor\"),\n\t\t\t},\n\t\t\t&dag.HTTPProxyProcessor{\n\t\t\t\tEnableExternalNameService: true,\n\t\t\t},\n\t\t\t&dag.ExtensionServiceProcessor{\n\t\t\t\tFieldLogger: log.WithField(\"context\", \"ExtensionServiceProcessor\"),\n\t\t\t},\n\t\t\t&dag.ListenerProcessor{},\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "\tg.POST(\"/memo\", func(c echo.Context) error {\n\t\tctx := c.Request().Context()\n\t\tuserID, ok := c.Get(getUserIDContextKey()).(int)\n\t\tif !ok {\n\t\t\treturn echo.NewHTTPError(http.StatusUnauthorized, \"Missing user in session\")\n\t\t}\n\n\t\tmemoCreate := &api.MemoCreate{}\n\t\tif err := json.NewDecoder(c.Request().Body).Decode(memoCreate); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Malformatted post memo request\").SetInternal(err)\n\t\t}\n\t\tif memoCreate.Content == \"\" {\n\t\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Memo content shouldn't be empty\")\n\t\t}\n\n\t\tif memoCreate.Visibility == \"\" {\n\t\t\tuserSettingMemoVisibilityKey := api.UserSettingMemoVisibilityKey\n\t\t\tuserMemoVisibilitySetting, err := s.Store.FindUserSetting(ctx, &api.UserSettingFind{\n\t\t\t\tUserID: userID,\n\t\t\t\tKey:    &userSettingMemoVisibilityKey,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to find user setting\").SetInternal(err)\n\t\t\t}\n\n\t\t\tif userMemoVisibilitySetting != nil {\n\t\t\t\tmemoVisibility := api.Private\n\t\t\t\terr := json.Unmarshal([]byte(userMemoVisibilitySetting.Value), &memoVisibility)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to unmarshal user setting value\").SetInternal(err)\n\t\t\t\t}\n\t\t\t\tmemoCreate.Visibility = memoVisibility\n\t\t\t} else {\n\t\t\t\t// Private is the default memo visibility.\n\t\t\t\tmemoCreate.Visibility = api.Private\n\t\t\t}\n\t\t}\n\n\t\tmemoCreate.CreatorID = userID\n\t\tmemo, err := s.Store.CreateMemo(ctx, memoCreate)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to create memo\").SetInternal(err)\n\t\t}\n\t\ts.Collector.Collect(ctx, &metric.Metric{\n\t\t\tName: \"memo created\",\n\t\t})\n\n\t\tfor _, resourceID := range memoCreate.ResourceIDList {\n\t\t\tif _, err := s.Store.UpsertMemoResource(ctx, &api.MemoResourceUpsert{\n\t\t\t\tMemoID:     memo.ID,\n\t\t\t\tResourceID: resourceID,\n\t\t\t}); err != nil {\n\t\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to upsert memo resource\").SetInternal(err)\n\t\t\t}\n\t\t}\n\n\t\tmemo, err = s.Store.ComposeMemo(ctx, memo)\n\t\tif err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to compose memo\").SetInternal(err)\n\t\t}\n\n\t\tc.Response().Header().Set(echo.HeaderContentType, echo.MIMEApplicationJSONCharsetUTF8)\n\t\tif err := json.NewEncoder(c.Response().Writer).Encode(composeResponse(memo)); err != nil {\n\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to encode memo response\").SetInternal(err)\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (s *KeyAgentTestSuite) TestAddKey(c *check.C) {\n\t// make a new local agent\n\tlka, err := NewLocalAgent(\n\t\tLocalAgentConfig{\n\t\t\tKeysDir:          s.keyDir,\n\t\t\tProxyHost:        s.hostname,\n\t\t\tUsername:         s.username,\n\t\t\tUseLocalSSHAgent: true,\n\t\t})\n\tc.Assert(err, check.IsNil)\n\n\t// add the key to the local agent, this should write the key\n\t// to disk as well as load it in the agent\n\t_, err = lka.AddKey(s.key)\n\tc.Assert(err, check.IsNil)\n\n\t// check that the key has been written to disk\n\tfor _, ext := range []string{fileExtCert, \"\", fileExtPub} {\n\t\t_, err := os.Stat(fmt.Sprintf(\"%v/keys/%v/%v%v\", s.keyDir, s.hostname, s.username, ext))\n\t\tc.Assert(err, check.IsNil)\n\t}\n\n\t// get all agent keys from teleport agent and system agent\n\tteleportAgentKeys, err := lka.Agent.List()\n\tc.Assert(err, check.IsNil)\n\tsystemAgentKeys, err := lka.sshAgent.List()\n\tc.Assert(err, check.IsNil)\n\n\t// check that we've loaded a cert as well as a private key into the teleport agent\n\t// and it's for the user we expected to add a certificate for\n\tc.Assert(teleportAgentKeys, check.HasLen, 2)\n\tc.Assert(teleportAgentKeys[0].Type(), check.Equals, \"ssh-rsa-cert-v01@openssh.com\")\n\tc.Assert(teleportAgentKeys[0].Comment, check.Equals, \"teleport:\"+s.username)\n\tc.Assert(teleportAgentKeys[1].Type(), check.Equals, \"ssh-rsa\")\n\tc.Assert(teleportAgentKeys[1].Comment, check.Equals, \"teleport:\"+s.username)\n\n\t// check that we've loaded a cert as well as a private key into the system again\n\tfound := false\n\tfor _, sak := range systemAgentKeys {\n\t\tif sak.Comment == \"teleport:\"+s.username && sak.Type() == \"ssh-rsa\" {\n\t\t\tfound = true\n\t\t}\n\t}\n\tc.Assert(true, check.Equals, found)\n\tfound = false\n\tfor _, sak := range systemAgentKeys {\n\t\tif sak.Comment == \"teleport:\"+s.username && sak.Type() == \"ssh-rsa-cert-v01@openssh.com\" {\n\t\t\tfound = true\n\t\t}\n\t}\n\tc.Assert(true, check.Equals, found)\n\n\t// unload all keys for this user from the teleport agent and system agent\n\terr = lka.UnloadKey()\n\tc.Assert(err, check.IsNil)\n}", "is_vulnerable": 0}
{"code": "func openAndStartupTPM(path string, doStartup bool) (io.ReadWriteCloser, error) {\n\trwc, err := tpmutil.OpenTPM(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Make sure this is a TPM 1.2\n\t_, err = GetManufacturer(rwc)\n\tif doStartup && err == tpmError(errInvalidPostInit) {\n\t\tif err = startup(rwc); err == nil {\n\t\t\t_, err = GetManufacturer(rwc)\n\t\t}\n\t}\n\tif err != nil {\n\t\trwc.Close()\n\t\treturn nil, fmt.Errorf(\"open %s: device is not a TPM 1.2: %v\", path, err)\n\t}\n\treturn rwc, nil\n}", "is_vulnerable": 0}
{"code": "func p256SelectAffine(res *p256AffinePoint, table *p256AffineTable, idx int)\n\n// Point addition with an affine point and constant time conditions.\n// If zero is 0, sets res = in2. If sel is 0, sets res = in1.\n// If sign is not 0, sets res = in1 + -in2. Otherwise, sets res = in1 + in2\n//\n//go:noescape\nfunc p256PointAddAffineAsm(res, in1 *P256Point, in2 *p256AffinePoint, sign, sel, zero int)\n\n// Point addition. Sets res = in1 + in2. Returns one if the two input points\n// were equal and zero otherwise. If in1 or in2 are the point at infinity, res\n// and the return value are undefined.\n//\n//go:noescape\nfunc p256PointAddAsm(res, in1, in2 *P256Point) int\n\n// Point doubling. Sets res = in + in. in can be the point at infinity.\n//\n//go:noescape\nfunc p256PointDoubleAsm(res, in *P256Point)\n\n// p256OrdElement is a P-256 scalar field element in [0, ord(G)-1] in the\n// Montgomery domain (with R 2\u00b2\u2075\u2076) as four uint64 limbs in little-endian order.\ntype p256OrdElement [4]uint64\n\n// p256OrdReduce ensures s is in the range [0, ord(G)-1].\nfunc p256OrdReduce(s *p256OrdElement) {\n\t// Since 2 * ord(G) > 2\u00b2\u2075\u2076, we can just conditionally subtract ord(G),\n\t// keeping the result if it doesn't underflow.\n\tt0, b := bits.Sub64(s[0], 0xf3b9cac2fc632551, 0)\n\tt1, b := bits.Sub64(s[1], 0xbce6faada7179e84, b)\n\tt2, b := bits.Sub64(s[2], 0xffffffffffffffff, b)\n\tt3, b := bits.Sub64(s[3], 0xffffffff00000000, b)\n\ttMask := b - 1 // zero if subtraction underflowed\n\ts[0] ^= (t0 ^ s[0]) & tMask\n\ts[1] ^= (t1 ^ s[1]) & tMask\n\ts[2] ^= (t2 ^ s[2]) & tMask\n\ts[3] ^= (t3 ^ s[3]) & tMask\n}", "is_vulnerable": 0}
{"code": "func (m *EnumValue) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowType\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: EnumValue: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: EnumValue: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Name\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Name = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Number\", wireType)\n\t\t\t}\n\t\t\tm.Number = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Number |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Options\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowType\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Options = append(m.Options, &Option{})\n\t\t\tif err := m.Options[len(m.Options)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipType(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthType\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestInvalidImportTokenValuesValidation(t *testing.T) {\n\tak := createAccountNKey(t)\n\tak2 := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\takp2 := publicKey(ak2, t)\n\ti := &Import{Subject: \"test\", Account: akp2, To: \"bar\", Type: Stream}\n\n\tvr := CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports should not generate an issue\")\n\t}\n\n\ti.Type = Service\n\tvr = CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports should not generate an issue\")\n\t}\n\n\tactivation := NewActivationClaims(akp)\n\tactivation.Expires = time.Now().Add(time.Hour).UTC().Unix()\n\n\tactivation.ImportSubject = \"test\"\n\tactivation.ImportType = Stream\n\tactJWT := encode(activation, ak2, t)\n\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports with token should be valid\")\n\t}\n\n\tactJWT = encode(activation, ak, t) // wrong issuer\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif vr.IsEmpty() {\n\t\tt.Errorf(\"imports with wrong issuer\")\n\t}\n\n\tactivation.Subject = akp2           // wrong subject\n\tactJWT = encode(activation, ak2, t) // right issuer\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif vr.IsEmpty() {\n\t\tt.Errorf(\"imports with wrong issuer\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestMarshalBytes(t *testing.T) {\n\tbytsNode := basicnode.NewBytes([]byte(\"byte me\"))\n\tmapNode, err := qp.BuildMap(basicnode.Prototype.Any, -1, func(ma datamodel.MapAssembler) {\n\t\tqp.MapEntry(ma, \"Byts\", qp.Node(bytsNode))\n\t})\n\tqt.Assert(t, err, qt.IsNil)\n\n\tt.Run(\"bytes dag-json\", func(t *testing.T) {\n\t\tbyts, err := ipld.Encode(bytsNode, Encode)\n\t\tqt.Assert(t, err, qt.IsNil)\n\t\tqt.Assert(t, string(byts), qt.Equals,\n\t\t\t`{\"/\":{\"bytes\":\"Ynl0ZSBtZQ\"}}`)\n\t})\n\tt.Run(\"nested bytes dag-json\", func(t *testing.T) {\n\t\tbyts, err := ipld.Encode(mapNode, Encode)\n\t\tqt.Assert(t, err, qt.IsNil)\n\t\tqt.Assert(t, string(byts), qt.Equals,\n\t\t\t`{\"Byts\":{\"/\":{\"bytes\":\"Ynl0ZSBtZQ\"}}}`)\n\t})\n}", "is_vulnerable": 0}
{"code": "func gatewayProxyForBridge(gateway *structs.ConsulGateway) *structs.ConsulGatewayProxy {\n\tif gateway == nil {\n\t\treturn nil\n\t}\n\n\t// operator has supplied custom proxy configuration, just use that without\n\t// modification\n\tif !gatewayProxyIsDefault(gateway.Proxy) {\n\t\treturn gateway.Proxy\n\t}\n\n\t// copy over unrelated fields if proxy block exists\n\tproxy := new(structs.ConsulGatewayProxy)\n\tif gateway.Proxy != nil {\n\t\tproxy.ConnectTimeout = gateway.Proxy.ConnectTimeout\n\t\tproxy.EnvoyDNSDiscoveryType = gateway.Proxy.EnvoyDNSDiscoveryType\n\t\tproxy.Config = gateway.Proxy.Config\n\t}\n\n\t// set default connect timeout if not set\n\tif proxy.ConnectTimeout == nil {\n\t\tproxy.ConnectTimeout = helper.TimeToPtr(defaultConnectTimeout)\n\t}\n\n\t// magically configure bind address(es) for bridge networking, per gateway type\n\t// non-default configuration is gated above\n\tswitch {\n\tcase gateway.Ingress != nil:\n\t\tproxy.EnvoyGatewayNoDefaultBind = true\n\t\tproxy.EnvoyGatewayBindTaggedAddresses = false\n\t\tproxy.EnvoyGatewayBindAddresses = gatewayBindAddressesIngress(gateway.Ingress)\n\tcase gateway.Terminating != nil:\n\t\tproxy.EnvoyGatewayNoDefaultBind = true\n\t\tproxy.EnvoyGatewayBindTaggedAddresses = false\n\t\tproxy.EnvoyGatewayBindAddresses = map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\"default\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    -1, // filled in later with dynamic port\n\t\t\t}}\n\tcase gateway.Mesh != nil:\n\t\tproxy.EnvoyGatewayNoDefaultBind = true\n\t\tproxy.EnvoyGatewayBindTaggedAddresses = false\n\t\tproxy.EnvoyGatewayBindAddresses = map[string]*structs.ConsulGatewayBindAddress{\n\t\t\t\"wan\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    -1, // filled in later with configured port\n\t\t\t},\n\t\t\t\"lan\": {\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    -1, // filled in later with generated port\n\t\t\t},\n\t\t}\n\t}\n\n\treturn proxy\n}", "is_vulnerable": 1}
{"code": "func GetSystemSecret(k8sClient kubernetes.Interface, secretName string) (*v1.Secret, error) {\n\treturn GetSecret(k8sClient, secretName, metav1.NamespaceSystem)\n}", "is_vulnerable": 0}
{"code": "func TestAnnotations(t *testing.T) {\n\ting := buildIngress()\n\tdata := map[string]string{}\n\n\tdata[parser.GetAnnotationWithPrefix(proxySSLSecretAnnotation)] = \"default/demo-secret\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-ciphers\")] = \"HIGH:-SHA\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-name\")] = \"$host\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-protocols\")] = \"TLSv1.3 SSLv2 TLSv1   TLSv1.2\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-server-name\")] = \"on\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-session-reuse\")] = \"off\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-verify\")] = \"on\"\n\tdata[parser.GetAnnotationWithPrefix(\"proxy-ssl-verify-depth\")] = \"3\"\n\n\ting.SetAnnotations(data)\n\n\tfakeSecret := &mockSecret{}\n\ti, err := NewParser(fakeSecret).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error with ingress: %v\", err)\n\t}\n\n\tu, ok := i.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected *Config but got %v\", u)\n\t}\n\n\tsecret, err := fakeSecret.GetAuthCertificate(\"default/demo-secret\")\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error getting secret %v\", err)\n\t}\n\n\tif u.AuthSSLCert.Secret != secret.Secret {\n\t\tt.Errorf(\"expected %v but got %v\", secret.Secret, u.AuthSSLCert.Secret)\n\t}\n\tif u.Ciphers != \"HIGH:-SHA\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"HIGH:-SHA\", u.Ciphers)\n\t}\n\tif u.Protocols != \"SSLv2 TLSv1 TLSv1.2 TLSv1.3\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"SSLv2 TLSv1 TLSv1.2 TLSv1.3\", u.Protocols)\n\t}\n\tif u.Verify != \"on\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"on\", u.Verify)\n\t}\n\tif u.VerifyDepth != 3 {\n\t\tt.Errorf(\"expected %v but got %v\", 3, u.VerifyDepth)\n\t}\n\tif u.ProxySSLName != \"$host\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"$host\", u.ProxySSLName)\n\t}\n\tif u.ProxySSLServerName != \"on\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"on\", u.ProxySSLServerName)\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func NewIntegrationCoordinator(t *testing.T, preConfiguredChains []network.Network) *IntegrationCoordinator {\n\tcoord := &ibctesting.Coordinator{\n\t\tT:           t,\n\t\tCurrentTime: GlobalTime,\n\t}\n\tibcChains := getIBCChains(t, coord, preConfiguredChains)\n\tdummyChains, dummyChainsIds := generateDummyChains(t, coord, AmountOfDummyChains)\n\ttotalChains := mergeMaps(ibcChains, dummyChains)\n\tcoord.Chains = totalChains\n\treturn &IntegrationCoordinator{\n\t\tcoord:          coord,\n\t\tdummyChainsIds: dummyChainsIds,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (g *Group) Static(prefix, root string) {\n\tg.static(prefix, root, g.GET)\n}", "is_vulnerable": 1}
{"code": "func isLocal(path string) bool {\n\treturn unixIsLocal(path)\n}", "is_vulnerable": 0}
{"code": "func ExecDb(db *sql.DB, sqlStatement string, sqlParams ...interface{}) (int64, error) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t}()\n\n\tSqlSafe(&sqlStatement)\n\n\tsqlUpper := strings.ToUpper(sqlStatement)\n\tif strings.HasPrefix(sqlUpper, \"UPDATE \") ||\n\t\tstrings.HasPrefix(sqlUpper, \"INSERT \") ||\n\t\tstrings.HasPrefix(sqlUpper, \"DELETE FROM \") {\n\t\tresult, err := db.Exec(sqlStatement, sqlParams...)\n\t\tif err != nil {\n\t\t\tfmt.Println(err)\n\t\t\treturn 0, err\n\t\t}\n\t\treturn result.RowsAffected()\n\t}\n\treturn 0, errors.New(fmt.Sprint(\"Invalid SQL:\", sqlStatement))\n}", "is_vulnerable": 0}
{"code": "func sender(renengotiation tls.RenegotiationSupport) Sender {\n\t// Use behaviour compatible with DefaultTransport, but require TLS minimum version.\n\tdefaultTransport := http.DefaultTransport.(*http.Transport)\n\ttransport := &http.Transport{\n\t\tProxy:                 defaultTransport.Proxy,\n\t\tDialContext:           defaultTransport.DialContext,\n\t\tMaxIdleConns:          defaultTransport.MaxIdleConns,\n\t\tIdleConnTimeout:       defaultTransport.IdleConnTimeout,\n\t\tTLSHandshakeTimeout:   defaultTransport.TLSHandshakeTimeout,\n\t\tExpectContinueTimeout: defaultTransport.ExpectContinueTimeout,\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tMinVersion:    tls.VersionTLS12,\n\t\t\tRenegotiation: renengotiation,\n\t\t},\n\t}\n\tvar roundTripper http.RoundTripper = transport\n\tif tracing.IsEnabled() {\n\t\troundTripper = tracing.NewTransport(transport)\n\t}\n\tj, _ := cookiejar.New(nil)\n\treturn &http.Client{Jar: j, Transport: roundTripper}\n}", "is_vulnerable": 0}
{"code": "\tgetItemCursor := func(taskIndex int) (cursorInformation, error) {\n\t\t// Create an updated cursor referencing the current item's cursor, so that any items returned know to resume from this point.\n\t\tcurrentCursor, err := ci.withOutgoingSection(name, tuple.StringWithoutCaveat(itemsToBeProcessed[taskIndex].cursor))\n\t\tif err != nil {\n\t\t\treturn currentCursor, err\n\t\t}\n\n\t\t// If not the first iteration, we need to clear incoming sections to ensure the iteration starts at the top\n\t\t// of the cursor.\n\t\tif taskIndex > 0 {\n\t\t\tcurrentCursor = currentCursor.clearIncoming()\n\t\t}\n\n\t\treturn currentCursor, nil\n\t}", "is_vulnerable": 0}
{"code": "\tfunc() {\n\t\tsnap := fsm2.state.Snapshot()\n\t\tdefer snap.Close()\n\t\tstones, err := snap.Tombstones()\n\t\trequire.NoError(t, err)\n\t\tstone := stones.Next().(*state.Tombstone)\n\t\trequire.NotNil(t, stone)\n\t\trequire.Equal(t, \"/remove\", stone.Key)\n\t\trequire.Nil(t, stones.Next())\n\t}()", "is_vulnerable": 0}
{"code": "func (tz *TzArchive) syncFiles() {\n\ttz.files = make([]*File, tz.NumFiles)\n\tfor i, f := range tz.File {\n\t\ttz.files[i] = &File{}\n\t\ttz.files[i].Header = f\n\t\ttz.files[i].Name = cae.Clean(strings.ReplaceAll(f.Name, \"\\\\\", \"/\"))\n\t\tif f.FileInfo().IsDir() && !strings.HasSuffix(tz.files[i].Name, \"/\") {\n\t\t\ttz.files[i].Name += \"/\"\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (web *Web) handleInstallGetAddresses(w http.ResponseWriter, r *http.Request) {\n\tdata := getAddrsResponse{\n\t\tVersion: version.Version(),\n\n\t\tWebPort: defaultPortHTTP,\n\t\tDNSPort: defaultPortDNS,\n\t}\n\n\tifaces, err := aghnet.GetValidNetInterfacesForWeb()\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"Couldn't get interfaces: %s\", err)\n\n\t\treturn\n\t}\n\n\tdata.Interfaces = make(map[string]*aghnet.NetInterface)\n\tfor _, iface := range ifaces {\n\t\tdata.Interfaces[iface.Name] = iface\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\terr = json.NewEncoder(w).Encode(data)\n\tif err != nil {\n\t\taghhttp.Error(\n\t\t\tr,\n\t\t\tw,\n\t\t\thttp.StatusInternalServerError,\n\t\t\t\"Unable to marshal default addresses to json: %s\",\n\t\t\terr,\n\t\t)\n\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *PrecompileTestSuite) CreateTestClawbackVestingAccount(funder, vestingAddr common.Address) {\n\tmsgArgs := []interface{}{funder, vestingAddr, false}\n\tmsg, _, _, err := vesting.NewMsgCreateClawbackVestingAccount(msgArgs)\n\ts.Require().NoError(err)\n\terr = evmosutil.FundAccount(s.ctx, s.app.BankKeeper, vestingAddr.Bytes(), sdk.NewCoins(sdk.NewCoin(utils.BaseDenom, math.NewInt(100))))\n\ts.Require().NoError(err)\n\t_, err = s.app.VestingKeeper.CreateClawbackVestingAccount(s.ctx, msg)\n\ts.Require().NoError(err)\n}", "is_vulnerable": 0}
{"code": "\tvar doRecover func()\n\n\tdoStart = func() {\n\t\tmlog.Debug(\"Hub is starting\", mlog.Int(\"index\", h.connectionIndex))\n\n\t\tticker := time.NewTicker(inactiveConnReaperInterval)\n\t\tdefer ticker.Stop()\n\n\t\tconnIndex := newHubConnectionIndex(inactiveConnReaperInterval)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase webSessionMessage := <-h.checkRegistered:\n\t\t\t\tconns := connIndex.ForUser(webSessionMessage.userID)\n\t\t\t\tvar isRegistered bool\n\t\t\t\tfor _, conn := range conns {\n\t\t\t\t\tif !conn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif conn.GetSessionToken() == webSessionMessage.sessionToken {\n\t\t\t\t\t\tisRegistered = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\twebSessionMessage.isRegistered <- isRegistered\n\t\t\tcase req := <-h.checkConn:\n\t\t\t\tvar res *CheckConnResult\n\t\t\t\tconn := connIndex.RemoveInactiveByConnectionID(req.userID, req.connectionID)\n\t\t\t\tif conn != nil {\n\t\t\t\t\tres = &CheckConnResult{\n\t\t\t\t\t\tConnectionID:     req.connectionID,\n\t\t\t\t\t\tUserID:           req.userID,\n\t\t\t\t\t\tActiveQueue:      conn.send,\n\t\t\t\t\t\tDeadQueue:        conn.deadQueue,\n\t\t\t\t\t\tDeadQueuePointer: conn.deadQueuePointer,\n\t\t\t\t\t\tReuseCount:       conn.reuseCount + 1,\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treq.result <- res\n\t\t\tcase <-ticker.C:\n\t\t\t\tconnIndex.RemoveInactiveConnections()\n\t\t\tcase webConn := <-h.register:\n\t\t\t\t// Mark the current one as active.\n\t\t\t\t// There is no need to check if it was inactive or not,\n\t\t\t\t// we will anyways need to make it active.\n\t\t\t\twebConn.active.Store(true)\n\n\t\t\t\tconnIndex.Add(webConn)\n\t\t\t\tatomic.StoreInt64(&h.connectionCount, int64(connIndex.AllActive()))\n\n\t\t\t\tif webConn.IsAuthenticated() && webConn.reuseCount == 0 {\n\t\t\t\t\t// The hello message should only be sent when the reuseCount is 0.\n\t\t\t\t\t// i.e in server restart, or long timeout, or fresh connection case.\n\t\t\t\t\t// In case of seq number not found in dead queue, it is handled by\n\t\t\t\t\t// the webconn write pump.\n\t\t\t\t\twebConn.send <- webConn.createHelloMessage()\n\t\t\t\t}\n\t\t\tcase webConn := <-h.unregister:\n\t\t\t\t// If already removed (via queue full), then removing again becomes a noop.\n\t\t\t\t// But if not removed, mark inactive.\n\t\t\t\twebConn.active.Store(false)\n\n\t\t\t\tatomic.StoreInt64(&h.connectionCount, int64(connIndex.AllActive()))\n\n\t\t\t\tif webConn.UserId == \"\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tconns := connIndex.ForUser(webConn.UserId)\n\t\t\t\tif len(conns) == 0 || areAllInactive(conns) {\n\t\t\t\t\tuserID := webConn.UserId\n\t\t\t\t\th.platform.Go(func() {\n\t\t\t\t\t\th.platform.SetStatusOffline(userID, false)\n\t\t\t\t\t})\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tvar latestActivity int64\n\t\t\t\tfor _, conn := range conns {\n\t\t\t\t\tif !conn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif conn.lastUserActivityAt > latestActivity {\n\t\t\t\t\t\tlatestActivity = conn.lastUserActivityAt\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif h.platform.isUserAway(latestActivity) {\n\t\t\t\t\tuserID := webConn.UserId\n\t\t\t\t\th.platform.Go(func() {\n\t\t\t\t\t\th.platform.SetStatusLastActivityAt(userID, latestActivity)\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\tcase userID := <-h.invalidateUser:\n\t\t\t\tfor _, webConn := range connIndex.ForUser(userID) {\n\t\t\t\t\twebConn.InvalidateCache()\n\t\t\t\t}\n\t\t\tcase activity := <-h.activity:\n\t\t\t\tfor _, webConn := range connIndex.ForUser(activity.userID) {\n\t\t\t\t\tif !webConn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif webConn.GetSessionToken() == activity.sessionToken {\n\t\t\t\t\t\twebConn.lastUserActivityAt = activity.activityAt\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase directMsg := <-h.directMsg:\n\t\t\t\tif !connIndex.Has(directMsg.conn) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase directMsg.conn.send <- directMsg.msg:\n\t\t\t\tdefault:\n\t\t\t\t\t// Don't log the warning if it's an inactive connection.\n\t\t\t\t\tif directMsg.conn.active.Load() {\n\t\t\t\t\t\tmlog.Error(\"webhub.broadcast: cannot send, closing websocket for user\",\n\t\t\t\t\t\t\tmlog.String(\"user_id\", directMsg.conn.UserId),\n\t\t\t\t\t\t\tmlog.String(\"conn_id\", directMsg.conn.GetConnectionID()))\n\t\t\t\t\t}\n\t\t\t\t\tclose(directMsg.conn.send)\n\t\t\t\t\tconnIndex.Remove(directMsg.conn)\n\t\t\t\t}\n\t\t\tcase msg := <-h.broadcast:\n\t\t\t\tif metrics := h.platform.metricsIFace; metrics != nil {\n\t\t\t\t\tmetrics.DecrementWebSocketBroadcastBufferSize(strconv.Itoa(h.connectionIndex), 1)\n\t\t\t\t}\n\t\t\t\tmsg = msg.PrecomputeJSON()\n\t\t\t\tbroadcast := func(webConn *WebConn) {\n\t\t\t\t\tif !connIndex.Has(webConn) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif webConn.ShouldSendEvent(msg) {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase webConn.send <- msg:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t// Don't log the warning if it's an inactive connection.\n\t\t\t\t\t\t\tif webConn.active.Load() {\n\t\t\t\t\t\t\t\tmlog.Error(\"webhub.broadcast: cannot send, closing websocket for user\",\n\t\t\t\t\t\t\t\t\tmlog.String(\"user_id\", webConn.UserId),\n\t\t\t\t\t\t\t\t\tmlog.String(\"conn_id\", webConn.GetConnectionID()))\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tclose(webConn.send)\n\t\t\t\t\t\t\tconnIndex.Remove(webConn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif connID := msg.GetBroadcast().ConnectionId; connID != \"\" {\n\t\t\t\t\tif webConn := connIndex.byConnectionId[connID]; webConn != nil {\n\t\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t} else if msg.GetBroadcast().UserId != \"\" {\n\t\t\t\t\tcandidates := connIndex.ForUser(msg.GetBroadcast().UserId)\n\t\t\t\t\tfor _, webConn := range candidates {\n\t\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tcandidates := connIndex.All()\n\t\t\t\tfor webConn := range candidates {\n\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t}\n\t\t\tcase <-h.stop:\n\t\t\t\tfor webConn := range connIndex.All() {\n\t\t\t\t\twebConn.Close()\n\t\t\t\t\th.platform.SetStatusOffline(webConn.UserId, false)\n\t\t\t\t}\n\n\t\t\t\th.explicitStop = true\n\t\t\t\tclose(h.didStop)\n\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tdoRecoverableStart = func() {\n\t\tdefer doRecover()\n\t\tdoStart()\n\t}\n\n\tdoRecover = func() {\n\t\tif !h.explicitStop {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tmlog.Error(\"Recovering from Hub panic.\", mlog.Any(\"panic\", r))\n\t\t\t} else {\n\t\t\t\tmlog.Error(\"Webhub stopped unexpectedly. Recovering.\")\n\t\t\t}\n\n\t\t\tmlog.Error(string(debug.Stack()))\n\n\t\t\tgo doRecoverableStart()\n\t\t}\n\t}\n\n\tgo doRecoverableStart()\n}", "is_vulnerable": 1}
{"code": "func TestConfigMap(t *testing.T) {\n\ttype Expectation struct {\n\t\tEnableLocalApp                    bool\n\t\tRunDbDeleter                      bool\n\t\tDisableDynamicAuthProviderLogin   bool\n\t\tDisableWorkspaceGarbageCollection bool\n\t\tDefaultBaseImageRegistryWhiteList []string\n\t\tWorkspaceImage                    string\n\t\tJWTSecret                         string\n\t\tSessionSecret                     string\n\t\tGitHubApp                         experimental.GithubApp\n\t\tAuth                              auth.Config\n\t\tRedis                             redis.Configuration\n\t}\n\n\texpectation := Expectation{\n\t\tEnableLocalApp:                    true,\n\t\tDisableDynamicAuthProviderLogin:   true,\n\t\tRunDbDeleter:                      false,\n\t\tDisableWorkspaceGarbageCollection: true,\n\t\tDefaultBaseImageRegistryWhiteList: []string{\"some-registry\"},\n\t\tWorkspaceImage:                    \"some-workspace-image\",\n\t\tJWTSecret:                         \"some-jwt-secret\",\n\t\tSessionSecret:                     \"some-session-secret\",\n\t\tGitHubApp: experimental.GithubApp{\n\t\t\tAppId:           123,\n\t\t\tAuthProviderId:  \"some-auth-provider-id\",\n\t\t\tBaseUrl:         \"some-base-url\",\n\t\t\tCertPath:        \"some-cert-path\",\n\t\t\tEnabled:         true,\n\t\t\tLogLevel:        \"some-log-level\",\n\t\t\tMarketplaceName: \"some-marketplace-name\",\n\t\t\tWebhookSecret:   \"some-webhook-secret\",\n\t\t\tCertSecretName:  \"some-cert-secret-name\",\n\t\t},\n\t\tAuth: auth.Config{\n\t\t\tPKI: auth.PKIConfig{\n\t\t\t\tSigning: auth.KeyPair{\n\t\t\t\t\tID:             \"0001\",\n\t\t\t\t\tPrivateKeyPath: \"/secrets/auth-pki/signing/tls.key\",\n\t\t\t\t\tPublicKeyPath:  \"/secrets/auth-pki/signing/tls.crt\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tSession: auth.SessionConfig{\n\t\t\t\tLifetimeSeconds: int64((7 * 24 * time.Hour).Seconds()),\n\t\t\t\tIssuer:          \"https://awesome.domain\",\n\t\t\t\tCookie: auth.CookieConfig{\n\t\t\t\t\tName:     \"_awesome_domain_jwt2_\",\n\t\t\t\t\tMaxAge:   int64((7 * 24 * time.Hour).Seconds()),\n\t\t\t\t\tSameSite: \"lax\",\n\t\t\t\t\tSecure:   true,\n\t\t\t\t\tHTTPOnly: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tRedis: redis.Configuration{\n\t\t\tAddress: \"redis.test_namespace.svc.cluster.local:6379\",\n\t\t},\n\t}\n\n\tctx, err := common.NewRenderContext(config.Config{\n\t\tDomain: \"awesome.domain\",\n\t\tWorkspace: config.Workspace{\n\t\t\tWorkspaceImage: expectation.WorkspaceImage,\n\t\t},\n\t\tContainerRegistry: config.ContainerRegistry{\n\t\t\tPrivateBaseImageAllowList: expectation.DefaultBaseImageRegistryWhiteList,\n\t\t},\n\t\tExperimental: &experimental.Config{\n\t\t\tWebApp: &experimental.WebAppConfig{\n\t\t\t\tServer: &experimental.ServerConfig{\n\t\t\t\t\tDisableDynamicAuthProviderLogin:   expectation.DisableDynamicAuthProviderLogin,\n\t\t\t\t\tEnableLocalApp:                    pointer.Bool(expectation.EnableLocalApp),\n\t\t\t\t\tRunDbDeleter:                      pointer.Bool(expectation.RunDbDeleter),\n\t\t\t\t\tDisableWorkspaceGarbageCollection: expectation.DisableWorkspaceGarbageCollection,\n\t\t\t\t\tOAuthServer: experimental.OAuthServer{\n\t\t\t\t\t\tJWTSecret: expectation.JWTSecret,\n\t\t\t\t\t},\n\t\t\t\t\tSession: experimental.Session{\n\t\t\t\t\t\tSecret: expectation.SessionSecret,\n\t\t\t\t\t},\n\t\t\t\t\tGithubApp: &expectation.GitHubApp,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, versions.Manifest{}, \"test_namespace\")\n\n\trequire.NoError(t, err)\n\tobjs, err := configmap(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"failed to generate configmap: %s\\n\", err)\n\t}\n\n\tconfigmap, ok := objs[0].(*corev1.ConfigMap)\n\tif !ok {\n\t\tt.Fatalf(\"rendering configmap did not return a configMap\")\n\t\treturn\n\t}\n\n\tconfigJson, ok := configmap.Data[\"config.json\"]\n\tif ok == false {\n\t\tt.Errorf(\"no %q key found in configmap data\", \"config.json\")\n\t}\n\n\tvar config ConfigSerialized\n\tif err := json.Unmarshal([]byte(configJson), &config); err != nil {\n\t\tt.Errorf(\"failed to unmarshal config json: %s\", err)\n\t}\n\n\tactual := Expectation{\n\t\tDisableDynamicAuthProviderLogin:   config.DisableDynamicAuthProviderLogin,\n\t\tEnableLocalApp:                    config.EnableLocalApp,\n\t\tRunDbDeleter:                      config.RunDbDeleter,\n\t\tDisableWorkspaceGarbageCollection: config.WorkspaceGarbageCollection.Disabled,\n\t\tDefaultBaseImageRegistryWhiteList: config.DefaultBaseImageRegistryWhitelist,\n\t\tWorkspaceImage:                    config.WorkspaceDefaults.WorkspaceImage,\n\t\tJWTSecret:                         config.OAuthServer.JWTSecret,\n\t\tSessionSecret:                     config.Session.Secret,\n\t\tGitHubApp: experimental.GithubApp{\n\t\t\tAppId:           config.GitHubApp.AppId,\n\t\t\tAuthProviderId:  config.GitHubApp.AuthProviderId,\n\t\t\tBaseUrl:         config.GitHubApp.BaseUrl,\n\t\t\tCertPath:        config.GitHubApp.CertPath,\n\t\t\tEnabled:         config.GitHubApp.Enabled,\n\t\t\tLogLevel:        config.GitHubApp.LogLevel,\n\t\t\tMarketplaceName: config.GitHubApp.MarketplaceName,\n\t\t\tWebhookSecret:   config.GitHubApp.WebhookSecret,\n\t\t\tCertSecretName:  config.GitHubApp.CertSecretName,\n\t\t},\n\t\tAuth:  config.Auth,\n\t\tRedis: config.Redis,\n\t}\n\n\tassert.Equal(t, expectation, actual)\n}", "is_vulnerable": 1}
{"code": "func testUpdateSnapshotClass(ctrl *csiSnapshotCommonController, reactor *snapshotReactor, test controllerTest) error {\n\tsnap, err := ctrl.checkAndUpdateSnapshotClass(test.initialSnapshots[0])\n\t// syncSnapshotByKey expects that checkAndUpdateSnapshotClass always returns a snapshot\n\tif snap == nil {\n\t\treturn testError(fmt.Sprintf(\"checkAndUpdateSnapshotClass returned nil snapshot on error: %v\", err))\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "\tg.clockSequenceOnce.Do(func() {\n\t\tbuf := make([]byte, 2)\n\t\tif _, err = g.rand.Read(buf); err != nil {\n\t\t\treturn\n\t\t}\n\t\tg.clockSequence = binary.BigEndian.Uint16(buf)\n\t})", "is_vulnerable": 1}
{"code": "func Search(w http.ResponseWriter, r *http.Request) {\n\n\tsearchTerm := getParameterValue(\"q\", r)\n\tvar packages []models.Package\n\tvar err error\n\n\tif strings.Contains(searchTerm, \"@\") {\n\t\tvar maintainers []models.Maintainer\n\t\tdatabase.DBCon.Model(&maintainers).Where(\"email = ?\", searchTerm).Select()\n\t\tif len(maintainers) > 0 {\n\t\t\thttp.Redirect(w, r, \"/maintainer/\"+searchTerm, http.StatusMovedPermanently)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif strings.Contains(searchTerm, \"*\") {\n\t\t// if the query contains wildcards\n\t\twildcardSearchTerm := strings.ReplaceAll(searchTerm, \"*\", \"%\")\n\t\terr = database.DBCon.Model(&packages).\n\t\t\tWhereOr(\"atom LIKE ? \", wildcardSearchTerm).\n\t\t\tWhereOr(\"name LIKE ? \", wildcardSearchTerm).\n\t\t\tRelation(\"Versions\").\n\t\t\tOrderExpr(\"name <-> '\" + searchTerm + \"'\").\n\t\t\tSelect()\n\t} else {\n\t\t// if the query contains no wildcards do a fuzzy search\n\t\tsearchQuery := BuildSearchQuery(searchTerm)\n\t\terr = database.DBCon.Model(&packages).\n\t\t\tWhere(searchQuery).\n\t\t\tWhereOr(\"atom LIKE ? \", (\"%\" + searchTerm + \"%\")).\n\t\t\tRelation(\"Versions\").\n\t\t\tOrderExpr(\"name <-> '\" + searchTerm + \"'\").\n\t\t\tSelect()\n\t}\n\n\tif err != nil && err != pg.ErrNoRows {\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\n\t\t\thttp.StatusInternalServerError)\n\t\treturn\n\t}\n\n\trenderPackageTemplate(\"search\",\n\t\t\"search\",\n\t\tGetFuncMap(),\n\t\tgetSearchData(packages, searchTerm),\n\t\tw)\n}", "is_vulnerable": 1}
{"code": "func fromFS(path string) (string, error) {\n\tif !utf8.ValidString(path) {\n\t\treturn \"\", errInvalidPath\n\t}\n\tfor len(path) > 1 && path[0] == '/' && path[1] == '/' {\n\t\tpath = path[1:]\n\t}\n\tcontainsSlash := false\n\tfor p := path; p != \"\"; {\n\t\t// Find the next path element.\n\t\ti := 0\n\t\tdot := -1\n\t\tfor i < len(p) && p[i] != '/' {\n\t\t\tswitch p[i] {\n\t\t\tcase 0, '\\\\', ':':\n\t\t\t\treturn \"\", errInvalidPath\n\t\t\tcase '.':\n\t\t\t\tif dot < 0 {\n\t\t\t\t\tdot = i\n\t\t\t\t}\n\t\t\t}\n\t\t\ti++\n\t\t}\n\t\tpart := p[:i]\n\t\tif i < len(p) {\n\t\t\tcontainsSlash = true\n\t\t\tp = p[i+1:]\n\t\t} else {\n\t\t\tp = \"\"\n\t\t}\n\t\t// Trim the extension and look for a reserved name.\n\t\tbase := part\n\t\tif dot >= 0 {\n\t\t\tbase = part[:dot]\n\t\t}\n\t\tif isReservedName(base) {\n\t\t\tif dot < 0 {\n\t\t\t\treturn \"\", errInvalidPath\n\t\t\t}\n\t\t\t// The path element is a reserved name with an extension.\n\t\t\t// Some Windows versions consider this a reserved name,\n\t\t\t// while others do not. Use FullPath to see if the name is\n\t\t\t// reserved.\n\t\t\tif p, _ := syscall.FullPath(part); len(p) >= 4 && p[:4] == `\\\\.\\` {\n\t\t\t\treturn \"\", errInvalidPath\n\t\t\t}\n\t\t}\n\t}\n\tif containsSlash {\n\t\t// We can't depend on strings, so substitute \\ for / manually.\n\t\tbuf := []byte(path)\n\t\tfor i, b := range buf {\n\t\t\tif b == '/' {\n\t\t\t\tbuf[i] = '\\\\'\n\t\t\t}\n\t\t}\n\t\tpath = string(buf)\n\t}\n\treturn path, nil\n}", "is_vulnerable": 1}
{"code": "func NewStore(secure bool, maxAgeSeconds int, secrets ...string) Store {\n\tvalues := [][]byte{}\n\tfor _, secret := range secrets {\n\t\tvalues = append(values, []byte(secret))\n\t}\n\tcookie := sessions.NewCookieStore(values...)\n\tcookie.Options.MaxAge = maxAgeSeconds\n\tcookie.Options.HttpOnly = true\n\tcookie.Options.Secure = secure\n\treturn store{cookie}\n}", "is_vulnerable": 0}
{"code": "func TestUnmarshallToEmbeddedNoData(t *testing.T) {\n\tdata := map[string][]string{\n\t\t\"F3\": {\"raw a\"},\n\t}\n\n\ts := &S24e{}\n\n\tdecoder := NewDecoder()\n\terr := decoder.Decode(s, data)\n\n\texpectedErr := `schema: invalid path \"F3\"`\n\tif err.Error() != expectedErr {\n\t\tt.Fatalf(\"got %q, want %q\", err, expectedErr)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *state) MainRRDP(pSpan opentracing.Span) {\n\ttracer := opentracing.GlobalTracer()\n\tspan := tracer.StartSpan(\n\t\t\"rrdp\",\n\t\topentracing.ChildOf(pSpan.Context()),\n\t)\n\tdefer span.Finish()\n\n\tfor vv, rsync := range s.RRDPFetch {\n\t\trSpan := tracer.StartSpan(\n\t\t\t\"sync\",\n\t\t\topentracing.ChildOf(span.Context()),\n\t\t)\n\t\trSpan.SetTag(\"rrdp\", vv)\n\t\trSpan.SetTag(\"rsync\", rsync)\n\t\trSpan.SetTag(\"type\", \"rrdp\")\n\t\tlog.Infof(\"RRDP sync %v\", vv)\n\n\t\trrdpid := rsync\n\n\t\tpath := vv\n\t\tinfo := s.RRDPInfo[rrdpid]\n\n\t\tMetricSIACounts.With(\n\t\t\tprometheus.Labels{\n\t\t\t\t\"address\": vv,\n\t\t\t\t\"type\":    \"rrdp\",\n\t\t\t}).Set(0)\n\n\t\ttmpStats := s.RRDPStats[vv]\n\t\ttmpStats.URI = vv\n\t\ttmpStats.Iteration++\n\t\ttmpStats.Count = 0\n\t\ts.RRDPStats[vv] = tmpStats\n\t\tt1 := time.Now().UTC()\n\n\t\trrdp := &syncpki.RRDPSystem{\n\t\t\tCallback: s.ReceiveRRDPFileCallback,\n\n\t\t\tPath:    path,\n\t\t\tFetcher: s.HTTPFetcher,\n\n\t\t\tSessionID: info.SessionID,\n\t\t\tSerial:    info.Serial,\n\n\t\t\tLog: log.StandardLogger(),\n\t\t}\n\t\terr := rrdp.FetchRRDP(s.RRDPFetchDomain[vv])\n\t\tt2 := time.Now().UTC()\n\t\tif err != nil {\n\t\t\trSpan.SetTag(\"error\", true)\n\n\t\t\tsentry.WithScope(func(scope *sentry.Scope) {\n\t\t\t\tif errC, ok := err.(interface{ SetURL(string, string) }); ok {\n\t\t\t\t\terrC.SetURL(vv, rsync)\n\t\t\t\t}\n\t\t\t\tif errC, ok := err.(interface{ SetSentryScope(*sentry.Scope) }); ok {\n\t\t\t\t\terrC.SetSentryScope(scope)\n\t\t\t\t}\n\t\t\t\trrdp.SetSentryScope(scope)\n\t\t\t\tscope.SetTag(\"Rsync\", rsync)\n\t\t\t\tscope.SetTag(\"RRDP\", vv)\n\t\t\t\tsentry.CaptureException(err)\n\t\t\t})\n\n\t\t\t// GHSA-g9wh-3vrx-r7hg: Do not process responses that are too large\n\t\t\tif s.RRDPFailover && err.Error() != \"http: request body too large\" {\n\t\t\t\tlog.Errorf(\"Error when processing %v (for %v): %v. Will add to rsync.\", path, rsync, err)\n\t\t\t\trSpan.LogKV(\"event\", \"rrdp failure\", \"type\", \"failover to rsync\", \"message\", err)\n\t\t\t} else {\n\t\t\t\tlog.Errorf(\"Error when processing %v (for %v): %v.Skipping failover to rsync.\", path, rsync, err)\n\t\t\t\trSpan.LogKV(\"event\", \"rrdp failure\", \"type\", \"skipping failover to rsync\", \"message\", err)\n\t\t\t\tdelete(s.RsyncFetch, rsync)\n\t\t\t}\n\n\t\t\tMetricRRDPErrors.With(\n\t\t\t\tprometheus.Labels{\n\t\t\t\t\t\"address\": vv,\n\t\t\t\t}).Inc()\n\n\t\t\ttmpStats = s.RRDPStats[vv]\n\t\t\ttmpStats.Errors++\n\t\t\ttmpStats.LastFetchError = int(time.Now().UTC().UnixNano() / 1000000000)\n\t\t\ttmpStats.LastError = fmt.Sprint(err)\n\t\t\ttmpStats.Duration = t2.Sub(t1).Seconds()\n\t\t\ts.RRDPStats[vv] = tmpStats\n\t\t\trSpan.Finish()\n\t\t\tcontinue\n\t\t} else {\n\t\t\tlog.Debugf(\"Success fetching %s, removing rsync %s\", vv, rsync)\n\t\t\tdelete(s.RsyncFetch, rsync)\n\t\t}\n\n\t\trSpan.LogKV(\"event\", \"rrdp\", \"type\", \"success\", \"message\", \"rrdp successfully fetched\")\n\t\tsentry.WithScope(func(scope *sentry.Scope) {\n\t\t\tscope.SetLevel(sentry.LevelInfo)\n\t\t\tscope.SetTag(\"Rsync\", rsync)\n\t\t\tscope.SetTag(\"RRDP\", vv)\n\t\t\trrdp.SetSentryScope(scope)\n\t\t\tsentry.CaptureMessage(\"fetched rrdp successfully\")\n\t\t})\n\n\t\trSpan.Finish()\n\t\tMetricRRDPSerial.With(\n\t\t\tprometheus.Labels{\n\t\t\t\t\"address\": vv,\n\t\t\t}).Set(float64(rrdp.Serial))\n\t\tlastFetch := time.Now().UTC().UnixNano() / 1000000000\n\t\tMetricLastFetch.With(\n\t\t\tprometheus.Labels{\n\t\t\t\t\"address\": vv,\n\t\t\t\t\"type\":    \"rrdp\",\n\t\t\t}).Set(float64(lastFetch))\n\t\ttmpStats = s.RRDPStats[vv]\n\t\ttmpStats.LastFetch = int(lastFetch)\n\t\ttmpStats.RRDPSerial = rrdp.Serial\n\t\ttmpStats.RRDPSessionID = rrdp.SessionID\n\t\ttmpStats.Duration = t2.Sub(t1).Seconds()\n\t\ts.RRDPStats[vv] = tmpStats\n\n\t\ts.RRDPInfo[rrdpid] = RRDPInfo{\n\t\t\tRsync:     rsync,\n\t\t\tPath:      path,\n\t\t\tSessionID: rrdp.SessionID,\n\t\t\tSerial:    rrdp.Serial,\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAMConfigAccess(t *testing.T) {\n\tt.Skip(\"skip broken test\")\n\n\tdir, path := testinfra.CreateGrafDir(t, testinfra.GrafanaOpts{\n\t\tDisableLegacyAlerting: true,\n\t\tEnableUnifiedAlerting: true,\n\t\tDisableAnonymous:      true,\n\t\tAppModeProduction:     true,\n\t})\n\n\tgrafanaListedAddr, store := testinfra.StartGrafana(t, dir, path)\n\n\t// Create a users to make authenticated requests\n\tcreateUser(t, store, user.CreateUserCommand{\n\t\tDefaultOrgRole: string(org.RoleViewer),\n\t\tPassword:       \"viewer\",\n\t\tLogin:          \"viewer\",\n\t})\n\tcreateUser(t, store, user.CreateUserCommand{\n\t\tDefaultOrgRole: string(org.RoleEditor),\n\t\tPassword:       \"editor\",\n\t\tLogin:          \"editor\",\n\t})\n\tcreateUser(t, store, user.CreateUserCommand{\n\t\tDefaultOrgRole: string(org.RoleAdmin),\n\t\tPassword:       \"admin\",\n\t\tLogin:          \"admin\",\n\t})\n\n\ttype testCase struct {\n\t\tdesc      string\n\t\turl       string\n\t\texpStatus int\n\t\texpBody   string\n\t}\n\n\tt.Run(\"when creating alertmanager configuration\", func(t *testing.T) {\n\t\tbody := `\n\t\t{\n\t\t\t\"alertmanager_config\": {\n\t\t\t\t\"route\": {\n\t\t\t\t\t\"receiver\": \"grafana-default-email\"\n\t\t\t\t},\n\t\t\t\t\"receivers\": [{\n\t\t\t\t\t\"name\": \"grafana-default-email\",\n\t\t\t\t\t\"grafana_managed_receiver_configs\": [{\n\t\t\t\t\t\t\"uid\": \"\",\n\t\t\t\t\t\t\"name\": \"email receiver\",\n\t\t\t\t\t\t\"type\": \"email\",\n\t\t\t\t\t\t\"isDefault\": true,\n\t\t\t\t\t\t\"settings\": {\n\t\t\t\t\t\t\t\"addresses\": \"<example@email.com>\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}]\n\t\t\t\t}]\n\t\t\t}\n\t\t}\n\t\t`\n\n\t\ttestCases := []testCase{\n\t\t\t{\n\t\t\t\tdesc:      \"un-authenticated request should fail\",\n\t\t\t\turl:       \"http://%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusUnauthorized,\n\t\t\t\texpBody:   `{\"message\":\"Unauthorized\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"viewer request should fail\",\n\t\t\t\turl:       \"http://viewer:viewer@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusForbidden,\n\t\t\t\texpBody:   `\"title\":\"Access denied\"`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"editor request should succeed\",\n\t\t\t\turl:       \"http://editor:editor@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusAccepted,\n\t\t\t\texpBody:   `{\"message\":\"configuration created\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"admin request should succeed\",\n\t\t\t\turl:       \"http://admin:admin@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusAccepted,\n\t\t\t\texpBody:   `{\"message\":\"configuration created\"}`,\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\t\turl := fmt.Sprintf(tc.url, grafanaListedAddr)\n\t\t\t\tbuf := bytes.NewReader([]byte(body))\n\t\t\t\t// nolint:gosec\n\t\t\t\tresp, err := http.Post(url, \"application/json\", buf)\n\t\t\t\tt.Cleanup(func() {\n\t\t\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\t\t})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, tc.expStatus, resp.StatusCode)\n\t\t\t\tb, err := io.ReadAll(resp.Body)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Contains(t, string(b), tc.expBody)\n\t\t\t})\n\t\t}\n\t})\n\n\tt.Run(\"when retrieve alertmanager configuration\", func(t *testing.T) {\n\t\tcfgBody := `\n\t\t{\n\t\t\t\"template_files\": null,\n\t\t\t\"alertmanager_config\": {\n\t\t\t\t\"route\": {\n\t\t\t\t\t\"receiver\": \"grafana-default-email\"\n\t\t\t\t},\n\t\t\t\t\"templates\": null,\n\t\t\t\t\"receivers\": [{\n\t\t\t\t\t\"name\": \"grafana-default-email\",\n\t\t\t\t\t\"grafana_managed_receiver_configs\": [{\n\t\t\t\t\t\t\"disableResolveMessage\": false,\n\t\t\t\t\t\t\"uid\": \"\",\n\t\t\t\t\t\t\"name\": \"email receiver\",\n\t\t\t\t\t\t\"type\": \"email\",\n\t\t\t\t\t\t\"secureFields\": {},\n\t\t\t\t\t\t\"settings\": {\n\t\t\t\t\t\t\t\"addresses\": \"<example@email.com>\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}]\n\t\t\t\t}]\n\t\t\t}\n\t\t}\n\t\t`\n\t\ttestCases := []testCase{\n\t\t\t{\n\t\t\t\tdesc:      \"un-authenticated request should fail\",\n\t\t\t\turl:       \"http://%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusUnauthorized,\n\t\t\t\texpBody:   `{\"message\": \"Unauthorized\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"viewer request should succeed\",\n\t\t\t\turl:       \"http://viewer:viewer@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t\texpBody:   cfgBody,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"editor request should succeed\",\n\t\t\t\turl:       \"http://editor:editor@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t\texpBody:   cfgBody,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"admin request should succeed\",\n\t\t\t\turl:       \"http://admin:admin@%s/api/alertmanager/grafana/config/api/v1/alerts\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t\texpBody:   cfgBody,\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\t\tresp, err := http.Get(fmt.Sprintf(tc.url, grafanaListedAddr))\n\t\t\t\tt.Cleanup(func() {\n\t\t\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\t\t})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, tc.expStatus, resp.StatusCode)\n\t\t\t\tb, err := io.ReadAll(resp.Body)\n\t\t\t\tif tc.expStatus == http.StatusOK {\n\t\t\t\t\tre := regexp.MustCompile(`\"uid\":\"([\\w|-]+)\"`)\n\t\t\t\t\tb = re.ReplaceAll(b, []byte(`\"uid\":\"\"`))\n\t\t\t\t}\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.JSONEq(t, tc.expBody, string(b))\n\t\t\t})\n\t\t}\n\t})\n\n\tt.Run(\"when creating silence\", func(t *testing.T) {\n\t\tnow := time.Now()\n\t\tbody := fmt.Sprintf(`\n\t\t{\n\t\t\t\"comment\": \"string\",\n\t\t\t\"createdBy\": \"string\",\n\t\t\t\"matchers\": [\n\t\t\t  {\n\t\t\t\t\"isRegex\": true,\n\t\t\t\t\"name\": \"string\",\n\t\t\t\t\"value\": \"string\"\n\t\t\t  }\n\t\t\t],\n\t\t\t\"startsAt\": \"%s\",\n\t\t\t\"endsAt\": \"%s\"\n\t\t  }\n\t\t`, now.Format(time.RFC3339), now.Add(10*time.Second).Format(time.RFC3339))\n\n\t\ttestCases := []testCase{\n\t\t\t{\n\t\t\t\tdesc:      \"un-authenticated request should fail\",\n\t\t\t\turl:       \"http://%s/api/alertmanager/grafana/config/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusUnauthorized,\n\t\t\t\texpBody:   `{\"message\":\"Unauthorized\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"viewer request should fail\",\n\t\t\t\turl:       \"http://viewer:viewer@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusForbidden,\n\t\t\t\texpBody:   `\"title\":\"Access denied\"`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"editor request should succeed\",\n\t\t\t\turl:       \"http://editor:editor@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusAccepted,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"admin request should succeed\",\n\t\t\t\turl:       \"http://admin:admin@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusAccepted,\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\t\turl := fmt.Sprintf(tc.url, grafanaListedAddr)\n\t\t\t\tbuf := bytes.NewReader([]byte(body))\n\t\t\t\t// nolint:gosec\n\t\t\t\tresp, err := http.Post(url, \"application/json\", buf)\n\t\t\t\tt.Cleanup(func() {\n\t\t\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\t\t})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, tc.expStatus, resp.StatusCode)\n\t\t\t\tb, err := io.ReadAll(resp.Body)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif tc.expStatus == http.StatusAccepted {\n\t\t\t\t\tresponse := apimodels.PostSilencesOKBody{}\n\t\t\t\t\trequire.NoError(t, json.Unmarshal(b, &response))\n\t\t\t\t\trequire.NotEmpty(t, response.SilenceID)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\trequire.Contains(t, string(b), tc.expBody)\n\t\t\t})\n\t\t}\n\t})\n\n\tvar blob []byte\n\tt.Run(\"when getting silences\", func(t *testing.T) {\n\t\ttestCases := []testCase{\n\t\t\t{\n\t\t\t\tdesc:      \"un-authenticated request should fail\",\n\t\t\t\turl:       \"http://%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusUnauthorized,\n\t\t\t\texpBody:   `{\"message\": \"Unauthorized\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"viewer request should succeed\",\n\t\t\t\turl:       \"http://viewer:viewer@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"editor request should succeed\",\n\t\t\t\turl:       \"http://editor:editor@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"admin request should succeed\",\n\t\t\t\turl:       \"http://admin:admin@%s/api/alertmanager/grafana/api/v2/silences\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\t\turl := fmt.Sprintf(tc.url, grafanaListedAddr)\n\t\t\t\t// nolint:gosec\n\t\t\t\tresp, err := http.Get(url)\n\t\t\t\tt.Cleanup(func() {\n\t\t\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\t\t})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, tc.expStatus, resp.StatusCode)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif tc.expStatus == http.StatusOK {\n\t\t\t\t\tb, err := io.ReadAll(resp.Body)\n\t\t\t\t\trequire.NoError(t, err)\n\t\t\t\t\tblob = b\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t})\n\n\tvar silences apimodels.GettableSilences\n\terr := json.Unmarshal(blob, &silences)\n\trequire.NoError(t, err)\n\tassert.Len(t, silences, 2)\n\tsilenceIDs := make([]string, 0, len(silences))\n\tfor _, s := range silences {\n\t\tsilenceIDs = append(silenceIDs, *s.ID)\n\t}\n\n\tunconsumedSilenceIdx := 0\n\tt.Run(\"when deleting a silence\", func(t *testing.T) {\n\t\ttestCases := []testCase{\n\t\t\t{\n\t\t\t\tdesc:      \"un-authenticated request should fail\",\n\t\t\t\turl:       \"http://%s/api/alertmanager/grafana/api/v2/silence/%s\",\n\t\t\t\texpStatus: http.StatusUnauthorized,\n\t\t\t\texpBody:   `{\"message\":\"Unauthorized\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"viewer request should fail\",\n\t\t\t\turl:       \"http://viewer:viewer@%s/api/alertmanager/grafana/api/v2/silence/%s\",\n\t\t\t\texpStatus: http.StatusForbidden,\n\t\t\t\texpBody:   `\"title\":\"Access denied\"`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"editor request should succeed\",\n\t\t\t\turl:       \"http://editor:editor@%s/api/alertmanager/grafana/api/v2/silence/%s\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t\texpBody:   `{\"message\":\"silence deleted\"}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdesc:      \"admin request should succeed\",\n\t\t\t\turl:       \"http://admin:admin@%s/api/alertmanager/grafana/api/v2/silence/%s\",\n\t\t\t\texpStatus: http.StatusOK,\n\t\t\t\texpBody:   `{\"message\":\"silence deleted\"}`,\n\t\t\t},\n\t\t}\n\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\t\turl := fmt.Sprintf(tc.url, grafanaListedAddr, silenceIDs[unconsumedSilenceIdx])\n\n\t\t\t\t// Create client\n\t\t\t\tclient := &http.Client{}\n\n\t\t\t\t// Create request\n\t\t\t\treq, err := http.NewRequest(\"DELETE\", url, nil)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Println(err)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Fetch Request\n\t\t\t\tresp, err := client.Do(req)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tt.Cleanup(func() {\n\t\t\t\t\trequire.NoError(t, resp.Body.Close())\n\t\t\t\t})\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, tc.expStatus, resp.StatusCode)\n\t\t\t\tb, err := io.ReadAll(resp.Body)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\tif tc.expStatus == http.StatusOK {\n\t\t\t\t\tunconsumedSilenceIdx++\n\t\t\t\t}\n\t\t\t\trequire.Contains(t, string(b), tc.expBody)\n\t\t\t})\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func (a *Auth) AuthPlain(username, password string) error {\n\tif a.useHelper {\n\t\treturn external.AuthUsingHelper(a.helperPath, username, password)\n\t}\n\n\tent, err := Lookup(username)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !ent.IsAccountValid() {\n\t\treturn fmt.Errorf(\"shadow: account is expired\")\n\t}\n\n\tif !ent.IsPasswordValid() {\n\t\treturn fmt.Errorf(\"shadow: password is expired\")\n\t}\n\n\tif err := ent.VerifyPassword(password); err != nil {\n\t\tif err == ErrWrongPassword {\n\t\t\treturn module.ErrUnknownCredentials\n\t\t}\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tsaveState := func(ctx context.Context) (bool, error) {\n\t\t// Check if the secret already exists.\n\t\texistingSecret, err := secrets.Get(ctx, FullStateSecretName, metav1.GetOptions{})\n\t\tif err == nil {\n\t\t\t// The secret already exists, update it.\n\t\t\texistingSecretCopy := existingSecret.DeepCopy()\n\t\t\texistingSecretCopy.Data[FullStateSecretName] = stateBytes\n\t\t\tif _, err := secrets.Update(ctx, existingSecretCopy, metav1.UpdateOptions{}); err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"[state] error updating secret: %w\", err)\n\t\t\t}\n\t\t} else if apierrors.IsNotFound(err) {\n\t\t\t// The secret does not exist, create it.\n\t\t\t_, err := secrets.Create(ctx, &v1.Secret{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:      FullStateSecretName,\n\t\t\t\t\tNamespace: metav1.NamespaceSystem,\n\t\t\t\t},\n\t\t\t\tData: map[string][]byte{\n\t\t\t\t\tFullStateSecretName: stateBytes,\n\t\t\t\t},\n\t\t\t}, metav1.CreateOptions{})\n\t\t\tif err != nil {\n\t\t\t\treturn false, fmt.Errorf(\"[state] error creating secret: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\treturn false, fmt.Errorf(\"[state] error getting secret: %w\", err)\n\t\t}\n\n\t\t// Delete the old configmap.\n\t\terr = configMaps.Delete(ctx, FullStateConfigMapName, metav1.DeleteOptions{})\n\t\tif err != nil && !apierrors.IsNotFound(err) {\n\t\t\treturn false, fmt.Errorf(\"[state] error deleting configmap: %w\", err)\n\t\t}\n\n\t\treturn true, nil\n\t}", "is_vulnerable": 0}
{"code": "func (s *Operations) createPod(secretData map[string][]byte) (*v1.Pod, *podimpersonation.PodOptions) {\n\tsecret := &v1.Secret{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tGenerateName: \"helm-operation-\",\n\t\t\tNamespace:    s.namespace,\n\t\t},\n\t\tData: secretData,\n\t}\n\tpod := &v1.Pod{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tGenerateName: \"helm-operation-\",\n\t\t\tNamespace:    s.namespace,\n\t\t},\n\t\tSpec: v1.PodSpec{\n\t\t\tVolumes: []v1.Volume{\n\t\t\t\t{\n\t\t\t\t\tName: \"data\",\n\t\t\t\t\tVolumeSource: v1.VolumeSource{\n\t\t\t\t\t\tSecret: &v1.SecretVolumeSource{\n\t\t\t\t\t\t\tSecretName: \"helm-operation-\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tTerminationGracePeriodSeconds: new(int64),\n\t\t\tRestartPolicy:                 v1.RestartPolicyNever,\n\t\t\tNodeSelector: map[string]string{\n\t\t\t\t\"kubernetes.io/os\": \"linux\",\n\t\t\t},\n\t\t\tTolerations: []v1.Toleration{\n\t\t\t\t{\n\t\t\t\t\tKey:      \"cattle.io/os\",\n\t\t\t\t\tOperator: \"Equal\",\n\t\t\t\t\tValue:    \"linux\",\n\t\t\t\t\tEffect:   \"NoSchedule\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tKey:      \"node-role.kubernetes.io/controlplane\",\n\t\t\t\t\tOperator: \"Equal\",\n\t\t\t\t\tValue:    \"true\",\n\t\t\t\t\tEffect:   \"NoSchedule\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tKey:      \"node-role.kubernetes.io/etcd\",\n\t\t\t\t\tOperator: \"Equal\",\n\t\t\t\t\tValue:    \"true\",\n\t\t\t\t\tEffect:   \"NoExecute\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tContainers: []v1.Container{\n\t\t\t\t{\n\t\t\t\t\tName: \"helm\",\n\t\t\t\t\tEnv: []v1.EnvVar{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  \"KUBECONFIG\",\n\t\t\t\t\t\t\tValue: \"/home/shell/.kube/config\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tStdin:           true,\n\t\t\t\t\tTTY:             true,\n\t\t\t\t\tStdinOnce:       true,\n\t\t\t\t\tImage:           settings.FullShellImage(),\n\t\t\t\t\tImagePullPolicy: v1.PullIfNotPresent,\n\t\t\t\t\tCommand:         []string{\"helm-cmd\"},\n\t\t\t\t\tWorkingDir:      helmDataPath,\n\t\t\t\t\tVolumeMounts: []v1.VolumeMount{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:      \"data\",\n\t\t\t\t\t\t\tMountPath: helmDataPath,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\treturn pod, &podimpersonation.PodOptions{\n\t\tSecretsToCreate: []*v1.Secret{\n\t\t\tsecret,\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func jsonUnmarshal(reader io.Reader, obj interface{}, opts ...JSONOpt) error {\n\td := json.NewDecoder(reader)\n\tfor _, opt := range opts {\n\t\td = opt(d)\n\t}\n\tif err := d.Decode(&obj); err != nil {\n\t\treturn fmt.Errorf(\"while decoding JSON: %v\", err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestHandler_ProcessAtx_SamePrevATX(t *testing.T) {\n\t// Arrange\n\tgoldenATXID := types.ATXID{2, 3, 4}\n\tatxHdlr := newTestHandler(t, goldenATXID)\n\n\tsig, err := signing.NewEdSigner()\n\trequire.NoError(t, err)\n\n\tcoinbase := types.GenerateAddress([]byte(\"aaaa\"))\n\n\t// Act & Assert\n\tprevATX := newActivationTx(\n\t\tt,\n\t\tsig,\n\t\t0,\n\t\ttypes.EmptyATXID,\n\t\ttypes.EmptyATXID,\n\t\tnil,\n\t\ttypes.EpochID(2),\n\t\t0,\n\t\t100,\n\t\tcoinbase,\n\t\t100,\n\t\t&types.NIPost{PostMetadata: &types.PostMetadata{}},\n\t\twithVrfNonce(7),\n\t)\n\tatxHdlr.mbeacon.EXPECT().OnAtx(gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnAtx(gomock.Any(), gomock.Any(), gomock.Any())\n\tproof, err := atxHdlr.processVerifiedATX(context.Background(), prevATX)\n\trequire.NoError(t, err)\n\trequire.Nil(t, proof)\n\n\t// valid first non-initial ATX\n\tatx1 := newActivationTx(\n\t\tt,\n\t\tsig,\n\t\t1,\n\t\tprevATX.ID(),\n\t\tprevATX.ID(),\n\t\tnil,\n\t\ttypes.EpochID(3),\n\t\t0,\n\t\t100,\n\t\tcoinbase,\n\t\t100,\n\t\t&types.NIPost{PostMetadata: &types.PostMetadata{}},\n\t)\n\tatxHdlr.mbeacon.EXPECT().OnAtx(gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnAtx(gomock.Any(), gomock.Any(), gomock.Any())\n\tproof, err = atxHdlr.processVerifiedATX(context.Background(), atx1)\n\trequire.NoError(t, err)\n\trequire.Nil(t, proof)\n\n\t// second non-initial ATX references prevATX as prevATX\n\tatx2 := newActivationTx(\n\t\tt,\n\t\tsig,\n\t\t2,\n\t\tprevATX.ID(),\n\t\tatx1.ID(),\n\t\tnil,\n\t\ttypes.EpochID(4),\n\t\t0,\n\t\t100,\n\t\tcoinbase,\n\t\t100,\n\t\t&types.NIPost{PostMetadata: &types.PostMetadata{}},\n\t)\n\tatxHdlr.mbeacon.EXPECT().OnAtx(gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnAtx(gomock.Any(), gomock.Any(), gomock.Any())\n\tatxHdlr.mtortoise.EXPECT().OnMalfeasance(gomock.Any())\n\tatxHdlr.mclock.EXPECT().CurrentLayer().Return(types.EpochID(4).FirstLayer())\n\tproof, err = atxHdlr.processVerifiedATX(context.Background(), atx2)\n\trequire.NoError(t, err)\n\tproof.SetReceived(time.Time{})\n\tnodeID, err := malfeasance.Validate(\n\t\tcontext.Background(),\n\t\tatxHdlr.log,\n\t\tatxHdlr.cdb,\n\t\tatxHdlr.edVerifier,\n\t\tnil,\n\t\t&mwire.MalfeasanceGossip{\n\t\t\tMalfeasanceProof: *proof,\n\t\t},\n\t)\n\trequire.NoError(t, err)\n\trequire.Equal(t, sig.NodeID(), nodeID)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CredsUpdate(ctx context.Context, in *clientpb.Credentials, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CredsUpdate_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_CommonTLSConfigServerNameNodeName(t *testing.T) {\n\ttype variant struct {\n\t\tconfig *Config\n\t\tresult string\n\t}\n\tvariants := []variant{\n\t\t{config: &Config{NodeName: \"node\", ServerName: \"server\"},\n\t\t\tresult: \"server\"},\n\t\t{config: &Config{ServerName: \"server\"},\n\t\t\tresult: \"server\"},\n\t\t{config: &Config{NodeName: \"node\"},\n\t\t\tresult: \"node\"},\n\t}\n\tfor _, v := range variants {\n\t\tc := NewConfigurator(v.config)\n\t\ttlsConf, err := c.commonTLSConfig(false)\n\t\trequire.NoError(t, err)\n\t\trequire.Empty(t, tlsConf.ServerName)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) MemfilesAdd(ctx context.Context, in *sliverpb.MemfilesAddReq, opts ...grpc.CallOption) (*sliverpb.MemfilesAdd, error) {\n\tout := new(sliverpb.MemfilesAdd)\n\terr := c.cc.Invoke(ctx, SliverRPC_MemfilesAdd_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestCachedCheckDatastoreQueryCount(t *testing.T) {\n\tt.Parallel()\n\n\tds := memory.New()\n\tdefer ds.Close()\n\n\tstoreID := ulid.Make().String()\n\n\terr := ds.Write(context.Background(), storeID, nil, []*openfgav1.TupleKey{\n\t\ttuple.NewTupleKey(\"document:x\", \"a\", \"user:jon\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"a\", \"user:maria\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"b\", \"user:maria\"),\n\t\ttuple.NewTupleKey(\"document:x\", \"parent\", \"org:fga\"),\n\t\ttuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t})\n\trequire.NoError(t, err)\n\n\tmodel := testutils.MustTransformDSLToProtoWithID(`model\n\tschema 1.1\ntype user\n\ntype org\n  relations\n\tdefine member: [user]\n\ntype document\n  relations\n\tdefine a: [user]\n\tdefine b: [user]\n\tdefine union: a or b\n\tdefine union_rewrite: union\n\tdefine intersection: a and b\n\tdefine difference: a but not b\n\tdefine ttu: member from parent\n\tdefine union_and_ttu: union and ttu\n\tdefine union_or_ttu: union or ttu or union_rewrite\n\tdefine intersection_of_ttus: union_or_ttu and union_and_ttu\n\tdefine parent: [org]`)\n\n\tctx := typesystem.ContextWithTypesystem(\n\t\tcontext.Background(),\n\t\ttypesystem.New(model),\n\t)\n\n\tctx = storage.ContextWithRelationshipTupleReader(ctx, ds)\n\n\tcheckCache := ccache.New(\n\t\tccache.Configure[*CachedResolveCheckResponse]().MaxSize(100),\n\t)\n\tdefer checkCache.Stop()\n\n\tcachedCheckResolver := NewCachedCheckResolver(\n\t\tWithExistingCache(checkCache),\n\t\tWithCacheTTL(10*time.Hour),\n\t)\n\tdefer cachedCheckResolver.Close()\n\n\t// Running the first check\n\tlocalCheckResolver := NewLocalChecker(\n\t\tWithMaxConcurrentReads(1),\n\t)\n\tdefer localCheckResolver.Close()\n\n\tcachedCheckResolver.SetDelegate(localCheckResolver)\n\tlocalCheckResolver.SetDelegate(cachedCheckResolver)\n\n\tres, err := cachedCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(1), res.GetResolutionMetadata().DatastoreQueryCount)\n\n\tres, err = cachedCheckResolver.ResolveCheck(ctx, &ResolveCheckRequest{\n\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"org:fga\", \"member\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(0), res.GetResolutionMetadata().DatastoreQueryCount)\n\n\t// The ttuLocalChecker will use partial result from the cache and partial result from the local checker\n\n\tttuLocalChecker := NewLocalChecker(\n\t\tWithMaxConcurrentReads(1),\n\t)\n\tttuLocalChecker.SetDelegate(cachedCheckResolver)\n\n\tres, err = ttuLocalChecker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\tStoreID:          storeID,\n\t\tTupleKey:         tuple.NewTupleKey(\"document:x\", \"ttu\", \"user:maria\"),\n\t\tContextualTuples: nil,\n\t\tRequestMetadata:  NewCheckRequestMetadata(25),\n\t})\n\n\tttuLocalChecker.Close()\n\n\trequire.NoError(t, err)\n\trequire.Equal(t, uint32(1), res.GetResolutionMetadata().DatastoreQueryCount)\n}", "is_vulnerable": 1}
{"code": "func newManagedIdentityClient(options *ManagedIdentityCredentialOptions) (*managedIdentityClient, error) {\n\tif options == nil {\n\t\toptions = &ManagedIdentityCredentialOptions{}\n\t}\n\tcp := options.ClientOptions\n\tc := managedIdentityClient{id: options.ID, endpoint: imdsEndpoint, msiType: msiTypeIMDS}\n\tenv := \"IMDS\"\n\tif endpoint, ok := os.LookupEnv(identityEndpoint); ok {\n\t\tif _, ok := os.LookupEnv(identityHeader); ok {\n\t\t\tif _, ok := os.LookupEnv(identityServerThumbprint); ok {\n\t\t\t\tenv = \"Service Fabric\"\n\t\t\t\tc.endpoint = endpoint\n\t\t\t\tc.msiType = msiTypeServiceFabric\n\t\t\t} else {\n\t\t\t\tenv = \"App Service\"\n\t\t\t\tc.endpoint = endpoint\n\t\t\t\tc.msiType = msiTypeAppService\n\t\t\t}\n\t\t} else if _, ok := os.LookupEnv(arcIMDSEndpoint); ok {\n\t\t\tenv = \"Azure Arc\"\n\t\t\tc.endpoint = endpoint\n\t\t\tc.msiType = msiTypeAzureArc\n\t\t}\n\t} else if endpoint, ok := os.LookupEnv(msiEndpoint); ok {\n\t\tc.endpoint = endpoint\n\t\tif _, ok := os.LookupEnv(msiSecret); ok {\n\t\t\tenv = \"Azure ML\"\n\t\t\tc.msiType = msiTypeAzureML\n\t\t} else {\n\t\t\tenv = \"Cloud Shell\"\n\t\t\tc.msiType = msiTypeCloudShell\n\t\t}\n\t} else {\n\t\tc.probeIMDS = options.dac\n\t\tsetIMDSRetryOptionDefaults(&cp.Retry)\n\t}\n\n\tclient, err := azcore.NewClient(module, version, runtime.PipelineOptions{\n\t\tTracing: runtime.TracingOptions{\n\t\t\tNamespace: traceNamespace,\n\t\t},\n\t}, &cp)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.azClient = client\n\n\tif log.Should(EventAuthentication) {\n\t\tlog.Writef(EventAuthentication, \"Managed Identity Credential will use %s managed identity\", env)\n\t}\n\n\treturn &c, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Mock) findExpectedCall(method string, arguments ...interface{}) (int, *Call) {\n\tvar expectedCall *Call\n\n\tfor i, call := range m.ExpectedCalls {\n\t\tif call.Method == method {\n\t\t\t_, diffCount := call.Arguments.Diff(arguments)\n\t\t\tif diffCount == 0 {\n\t\t\t\texpectedCall = call\n\t\t\t\tif call.Repeatability > -1 {\n\t\t\t\t\treturn i, call\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1, expectedCall\n}", "is_vulnerable": 0}
{"code": "func (cfg *Config) Clone() *Config {\n\tnewOptions := new(Options)\n\t*newOptions = *cfg.Options\n\treturn &Config{\n\t\tOptions:          newOptions,\n\t\tAutoCertificates: cfg.AutoCertificates,\n\t\tEnvoyVersion:     cfg.EnvoyVersion,\n\n\t\tGRPCPort:     cfg.GRPCPort,\n\t\tHTTPPort:     cfg.HTTPPort,\n\t\tOutboundPort: cfg.OutboundPort,\n\t\tMetricsPort:  cfg.MetricsPort,\n\t\tDebugPort:    cfg.DebugPort,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (v *cosignVerifier) VerifySignature(ctx context.Context, opts images.Options) (*images.Response, error) {\n\tref, err := name.ParseReference(opts.ImageRef)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse image %s\", opts.ImageRef)\n\t}\n\n\tsignatures, bundleVerified, err := tracing.ChildSpan3(\n\t\tctx,\n\t\t\"\",\n\t\t\"VERIFY IMG SIGS\",\n\t\tfunc(ctx context.Context, span trace.Span) ([]oci.Signature, bool, error) {\n\t\t\tcosignOpts, err := buildCosignOptions(ctx, opts)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, false, err\n\t\t\t}\n\t\t\treturn client.VerifyImageSignatures(ctx, ref, cosignOpts)\n\t\t},\n\t)\n\tif err != nil {\n\t\tlogger.Info(\"image verification failed\", \"error\", err.Error())\n\t\treturn nil, err\n\t}\n\n\tlogger.V(3).Info(\"verified image\", \"count\", len(signatures), \"bundleVerified\", bundleVerified)\n\tpayload, err := extractPayload(signatures)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := matchSignatures(signatures, opts.Subject, opts.Issuer, opts.AdditionalExtensions); err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = checkAnnotations(payload, opts.Annotations)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar digest string\n\tif opts.PredicateType == \"\" {\n\t\tdigest, err = extractDigest(opts.ImageRef, payload)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &images.Response{Digest: digest}, nil\n}", "is_vulnerable": 1}
{"code": "\t\t\tcreateDefaultName := func() js_ast.LocRef {\n\t\t\t\t// This must be named \"default\" for when \"--keep-names\" is active\n\t\t\t\tdefaultName := js_ast.LocRef{Loc: defaultLoc, Ref: p.newSymbol(js_ast.SymbolOther, \"default\")}\n\t\t\t\tp.currentScope.Generated = append(p.currentScope.Generated, defaultName.Ref)\n\t\t\t\treturn defaultName\n\t\t\t}\n\n\t\t\t// TypeScript decorators only work on class declarations\n\t\t\t// \"@decorator export default class Foo {}\"\n\t\t\t// \"@decorator export default abstract class Foo {}\"\n\t\t\tif opts.tsDecorators != nil && p.lexer.Token != js_lexer.TClass && !p.lexer.IsContextualKeyword(\"abstract\") {\n\t\t\t\tp.logMisplacedDecoratorError(opts.tsDecorators)\n\t\t\t}\n\n\t\t\tif p.lexer.IsContextualKeyword(\"async\") {\n\t\t\t\tasyncRange := p.lexer.Range()\n\t\t\t\tp.lexer.Next()\n\n\t\t\t\tif p.lexer.Token == js_lexer.TFunction && !p.lexer.HasNewlineBefore {\n\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\tstmt := p.parseFnStmt(loc, parseStmtOpts{\n\t\t\t\t\t\tisNameOptional: true,\n\t\t\t\t\t\tlexicalDecl:    lexicalDeclAllowAll,\n\t\t\t\t\t}, true /* isAsync */, asyncRange)\n\t\t\t\t\tif _, ok := stmt.Data.(*js_ast.STypeScript); ok {\n\t\t\t\t\t\treturn stmt // This was just a type annotation\n\t\t\t\t\t}\n\n\t\t\t\t\t// Use the statement name if present, since it's a better name\n\t\t\t\t\tvar defaultName js_ast.LocRef\n\t\t\t\t\tif s, ok := stmt.Data.(*js_ast.SFunction); ok && s.Fn.Name != nil {\n\t\t\t\t\t\tdefaultName = js_ast.LocRef{Loc: defaultLoc, Ref: s.Fn.Name.Ref}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdefaultName = createDefaultName()\n\t\t\t\t\t}\n\n\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportDefault{DefaultName: defaultName, Value: stmt}}\n\t\t\t\t}\n\n\t\t\t\tdefaultName := createDefaultName()\n\t\t\t\texpr := p.parseSuffix(p.parseAsyncPrefixExpr(asyncRange, js_ast.LComma, 0), js_ast.LComma, nil, 0)\n\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportDefault{\n\t\t\t\t\tDefaultName: defaultName, Value: js_ast.Stmt{Loc: loc, Data: &js_ast.SExpr{Value: expr}}}}\n\t\t\t}\n\n\t\t\tif p.lexer.Token == js_lexer.TFunction || p.lexer.Token == js_lexer.TClass || p.lexer.IsContextualKeyword(\"interface\") {\n\t\t\t\tstmt := p.parseStmt(parseStmtOpts{\n\t\t\t\t\ttsDecorators:   opts.tsDecorators,\n\t\t\t\t\tisNameOptional: true,\n\t\t\t\t\tlexicalDecl:    lexicalDeclAllowAll,\n\t\t\t\t})\n\t\t\t\tif _, ok := stmt.Data.(*js_ast.STypeScript); ok {\n\t\t\t\t\treturn stmt // This was just a type annotation\n\t\t\t\t}\n\n\t\t\t\t// Use the statement name if present, since it's a better name\n\t\t\t\tvar defaultName js_ast.LocRef\n\t\t\t\tswitch s := stmt.Data.(type) {\n\t\t\t\tcase *js_ast.SFunction:\n\t\t\t\t\tif s.Fn.Name != nil {\n\t\t\t\t\t\tdefaultName = js_ast.LocRef{Loc: defaultLoc, Ref: s.Fn.Name.Ref}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdefaultName = createDefaultName()\n\t\t\t\t\t}\n\t\t\t\tcase *js_ast.SClass:\n\t\t\t\t\tif s.Class.Name != nil {\n\t\t\t\t\t\tdefaultName = js_ast.LocRef{Loc: defaultLoc, Ref: s.Class.Name.Ref}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdefaultName = createDefaultName()\n\t\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t\tpanic(\"Internal error\")\n\t\t\t\t}\n\n\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportDefault{DefaultName: defaultName, Value: stmt}}\n\t\t\t}\n\n\t\t\tisIdentifier := p.lexer.Token == js_lexer.TIdentifier\n\t\t\tname := p.lexer.Identifier.String\n\t\t\texpr := p.parseExpr(js_ast.LComma)\n\n\t\t\t// Handle the default export of an abstract class in TypeScript\n\t\t\tif p.options.ts.Parse && isIdentifier && name == \"abstract\" {\n\t\t\t\tif _, ok := expr.Data.(*js_ast.EIdentifier); ok && (p.lexer.Token == js_lexer.TClass || opts.tsDecorators != nil) {\n\t\t\t\t\tstmt := p.parseClassStmt(loc, parseStmtOpts{\n\t\t\t\t\t\ttsDecorators:   opts.tsDecorators,\n\t\t\t\t\t\tisNameOptional: true,\n\t\t\t\t\t})\n\n\t\t\t\t\t// Use the statement name if present, since it's a better name\n\t\t\t\t\tvar defaultName js_ast.LocRef\n\t\t\t\t\tif s, ok := stmt.Data.(*js_ast.SClass); ok && s.Class.Name != nil {\n\t\t\t\t\t\tdefaultName = js_ast.LocRef{Loc: defaultLoc, Ref: s.Class.Name.Ref}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdefaultName = createDefaultName()\n\t\t\t\t\t}\n\n\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportDefault{DefaultName: defaultName, Value: stmt}}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\tdefaultName := createDefaultName()\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportDefault{\n\t\t\t\tDefaultName: defaultName, Value: js_ast.Stmt{Loc: loc, Data: &js_ast.SExpr{Value: expr}}}}\n\n\t\tcase js_lexer.TAsterisk:\n\t\t\tif !opts.isModuleScope && (!opts.isNamespaceScope || !opts.isTypeScriptDeclare) {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t}\n\n\t\t\tp.lexer.Next()\n\t\t\tvar namespaceRef js_ast.Ref\n\t\t\tvar alias *js_ast.ExportStarAlias\n\t\t\tvar pathLoc logger.Loc\n\t\t\tvar pathText string\n\t\t\tvar assertions *ast.ImportAssertions\n\t\t\tvar flags ast.ImportRecordFlags\n\n\t\t\tif p.lexer.IsContextualKeyword(\"as\") {\n\t\t\t\t// \"export * as ns from 'path'\"\n\t\t\t\tp.lexer.Next()\n\t\t\t\tname := p.parseClauseAlias(\"export\")\n\t\t\t\tnamespaceRef = p.storeNameInRef(name)\n\t\t\t\talias = &js_ast.ExportStarAlias{Loc: p.lexer.Loc(), OriginalName: name.String}\n\t\t\t\tp.lexer.Next()\n\t\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\t\t\t\tpathLoc, pathText, assertions, flags = p.parsePath()\n\t\t\t} else {\n\t\t\t\t// \"export * from 'path'\"\n\t\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\t\t\t\tpathLoc, pathText, assertions, flags = p.parsePath()\n\t\t\t\tname := js_ast.GenerateNonUniqueNameFromPath(pathText) + \"_star\"\n\t\t\t\tnamespaceRef = p.storeNameInRef(js_lexer.MaybeSubstring{String: name})\n\t\t\t}\n\t\t\timportRecordIndex := p.addImportRecord(ast.ImportStmt, pathLoc, pathText, assertions, flags)\n\n\t\t\t// Export-star statements anywhere in the file disable top-level const\n\t\t\t// local prefix because import cycles can be used to trigger TDZ\n\t\t\tp.currentScope.IsAfterConstLocalPrefix = true\n\n\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportStar{\n\t\t\t\tNamespaceRef:      namespaceRef,\n\t\t\t\tAlias:             alias,\n\t\t\t\tImportRecordIndex: importRecordIndex,\n\t\t\t}}\n\n\t\tcase js_lexer.TOpenBrace:\n\t\t\tif !opts.isModuleScope && (!opts.isNamespaceScope || !opts.isTypeScriptDeclare) {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t}\n\n\t\t\titems, isSingleLine := p.parseExportClause()\n\t\t\tif p.lexer.IsContextualKeyword(\"from\") {\n\t\t\t\t// \"export {} from 'path'\"\n\t\t\t\tp.lexer.Next()\n\t\t\t\tpathLoc, pathText, assertions, flags := p.parsePath()\n\t\t\t\timportRecordIndex := p.addImportRecord(ast.ImportStmt, pathLoc, pathText, assertions, flags)\n\t\t\t\tname := \"import_\" + js_ast.GenerateNonUniqueNameFromPath(pathText)\n\t\t\t\tnamespaceRef := p.storeNameInRef(js_lexer.MaybeSubstring{String: name})\n\n\t\t\t\t// Export clause statements anywhere in the file disable top-level const\n\t\t\t\t// local prefix because import cycles can be used to trigger TDZ\n\t\t\t\tp.currentScope.IsAfterConstLocalPrefix = true\n\n\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportFrom{\n\t\t\t\t\tItems:             items,\n\t\t\t\t\tNamespaceRef:      namespaceRef,\n\t\t\t\t\tImportRecordIndex: importRecordIndex,\n\t\t\t\t\tIsSingleLine:      isSingleLine,\n\t\t\t\t}}\n\t\t\t}\n\n\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportClause{Items: items, IsSingleLine: isSingleLine}}\n\n\t\tcase js_lexer.TEquals:\n\t\t\t// \"export = value;\"\n\t\t\tp.esmExportKeyword = previousExportKeyword // This wasn't an ESM export statement after all\n\t\t\tif p.options.ts.Parse {\n\t\t\t\tp.lexer.Next()\n\t\t\t\tvalue := p.parseExpr(js_ast.LLowest)\n\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExportEquals{Value: value}}\n\t\t\t}\n\t\t\tp.lexer.Unexpected()\n\t\t\treturn js_ast.Stmt{}\n\n\t\tdefault:\n\t\t\tp.lexer.Unexpected()\n\t\t\treturn js_ast.Stmt{}\n\t\t}\n\n\tcase js_lexer.TFunction:\n\t\tp.lexer.Next()\n\t\treturn p.parseFnStmt(loc, opts, false /* isAsync */, logger.Range{})\n\n\tcase js_lexer.TEnum:\n\t\tif !p.options.ts.Parse {\n\t\t\tp.lexer.Unexpected()\n\t\t}\n\t\treturn p.parseTypeScriptEnumStmt(loc, opts)\n\n\tcase js_lexer.TAt:\n\t\t// Parse decorators before class statements, which are potentially exported\n\t\tif p.options.ts.Parse {\n\t\t\tscopeIndex := len(p.scopesInOrder)\n\t\t\ttsDecorators := p.parseTypeScriptDecorators(p.currentScope)\n\n\t\t\t// If this turns out to be a \"declare class\" statement, we need to undo the\n\t\t\t// scopes that were potentially pushed while parsing the decorator arguments.\n\t\t\t// That can look like any one of the following:\n\t\t\t//\n\t\t\t//   \"@decorator declare class Foo {}\"\n\t\t\t//   \"@decorator declare abstract class Foo {}\"\n\t\t\t//   \"@decorator export declare class Foo {}\"\n\t\t\t//   \"@decorator export declare abstract class Foo {}\"\n\t\t\t//\n\t\t\topts.tsDecorators = &deferredTSDecorators{\n\t\t\t\tvalues:     tsDecorators,\n\t\t\t\tscopeIndex: scopeIndex,\n\t\t\t}\n\n\t\t\t// \"@decorator class Foo {}\"\n\t\t\t// \"@decorator abstract class Foo {}\"\n\t\t\t// \"@decorator declare class Foo {}\"\n\t\t\t// \"@decorator declare abstract class Foo {}\"\n\t\t\t// \"@decorator export class Foo {}\"\n\t\t\t// \"@decorator export abstract class Foo {}\"\n\t\t\t// \"@decorator export declare class Foo {}\"\n\t\t\t// \"@decorator export declare abstract class Foo {}\"\n\t\t\t// \"@decorator export default class Foo {}\"\n\t\t\t// \"@decorator export default abstract class Foo {}\"\n\t\t\tif p.lexer.Token != js_lexer.TClass && p.lexer.Token != js_lexer.TExport &&\n\t\t\t\t!p.lexer.IsContextualKeyword(\"abstract\") && !p.lexer.IsContextualKeyword(\"declare\") {\n\t\t\t\tp.logMisplacedDecoratorError(opts.tsDecorators)\n\t\t\t}\n\n\t\t\treturn p.parseStmt(opts)\n\t\t}\n\n\t\tp.lexer.Unexpected()\n\t\treturn js_ast.Stmt{}\n\n\tcase js_lexer.TClass:\n\t\tif opts.lexicalDecl != lexicalDeclAllowAll {\n\t\t\tp.forbidLexicalDecl(loc)\n\t\t}\n\t\treturn p.parseClassStmt(loc, opts)\n\n\tcase js_lexer.TVar:\n\t\tp.lexer.Next()\n\t\tdecls := p.parseAndDeclareDecls(js_ast.SymbolHoisted, opts)\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SLocal{\n\t\t\tKind:     js_ast.LocalVar,\n\t\t\tDecls:    decls,\n\t\t\tIsExport: opts.isExport,\n\t\t}}\n\n\tcase js_lexer.TConst:\n\t\tif opts.lexicalDecl != lexicalDeclAllowAll {\n\t\t\tp.forbidLexicalDecl(loc)\n\t\t}\n\t\tp.markSyntaxFeature(compat.ConstAndLet, p.lexer.Range())\n\t\tp.lexer.Next()\n\n\t\tif p.options.ts.Parse && p.lexer.Token == js_lexer.TEnum {\n\t\t\treturn p.parseTypeScriptEnumStmt(loc, opts)\n\t\t}\n\n\t\tdecls := p.parseAndDeclareDecls(js_ast.SymbolConst, opts)\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\tif !opts.isTypeScriptDeclare {\n\t\t\tp.requireInitializers(decls)\n\t\t}\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SLocal{\n\t\t\tKind:     js_ast.LocalConst,\n\t\t\tDecls:    decls,\n\t\t\tIsExport: opts.isExport,\n\t\t}}\n\n\tcase js_lexer.TIf:\n\t\tp.lexer.Next()\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\ttest := p.parseExpr(js_ast.LLowest)\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\t\tyes := p.parseStmt(parseStmtOpts{lexicalDecl: lexicalDeclAllowFnInsideIf})\n\t\tvar noOrNil js_ast.Stmt\n\t\tif p.lexer.Token == js_lexer.TElse {\n\t\t\tp.lexer.Next()\n\t\t\tnoOrNil = p.parseStmt(parseStmtOpts{lexicalDecl: lexicalDeclAllowFnInsideIf})\n\t\t}\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SIf{Test: test, Yes: yes, NoOrNil: noOrNil}}\n\n\tcase js_lexer.TDo:\n\t\tp.lexer.Next()\n\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\tp.lexer.Expect(js_lexer.TWhile)\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\ttest := p.parseExpr(js_ast.LLowest)\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\n\t\t// This is a weird corner case where automatic semicolon insertion applies\n\t\t// even without a newline present\n\t\tif p.lexer.Token == js_lexer.TSemicolon {\n\t\t\tp.lexer.Next()\n\t\t}\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SDoWhile{Body: body, Test: test}}\n\n\tcase js_lexer.TWhile:\n\t\tp.lexer.Next()\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\ttest := p.parseExpr(js_ast.LLowest)\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SWhile{Test: test, Body: body}}\n\n\tcase js_lexer.TWith:\n\t\tp.lexer.Next()\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\ttest := p.parseExpr(js_ast.LLowest)\n\t\tbodyLoc := p.lexer.Loc()\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\n\t\t// Push a scope so we make sure to prevent any bare identifiers referenced\n\t\t// within the body from being renamed. Renaming them might change the\n\t\t// semantics of the code.\n\t\tp.pushScopeForParsePass(js_ast.ScopeWith, bodyLoc)\n\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\tp.popScope()\n\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SWith{Value: test, BodyLoc: bodyLoc, Body: body}}\n\n\tcase js_lexer.TSwitch:\n\t\tp.lexer.Next()\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\ttest := p.parseExpr(js_ast.LLowest)\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\n\t\tbodyLoc := p.lexer.Loc()\n\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, bodyLoc)\n\t\tdefer p.popScope()\n\n\t\tp.lexer.Expect(js_lexer.TOpenBrace)\n\t\tcases := []js_ast.Case{}\n\t\tfoundDefault := false\n\n\t\tfor p.lexer.Token != js_lexer.TCloseBrace {\n\t\t\tvar value js_ast.Expr\n\t\t\tbody := []js_ast.Stmt{}\n\t\t\tcaseLoc := p.lexer.Loc()\n\n\t\t\tif p.lexer.Token == js_lexer.TDefault {\n\t\t\t\tif foundDefault {\n\t\t\t\t\tp.log.AddError(&p.tracker, p.lexer.Range(), \"Multiple default clauses are not allowed\")\n\t\t\t\t\tpanic(js_lexer.LexerPanic{})\n\t\t\t\t}\n\t\t\t\tfoundDefault = true\n\t\t\t\tp.lexer.Next()\n\t\t\t\tp.lexer.Expect(js_lexer.TColon)\n\t\t\t} else {\n\t\t\t\tp.lexer.Expect(js_lexer.TCase)\n\t\t\t\tvalue = p.parseExpr(js_ast.LLowest)\n\t\t\t\tp.lexer.Expect(js_lexer.TColon)\n\t\t\t}\n\n\t\tcaseBody:\n\t\t\tfor {\n\t\t\t\tswitch p.lexer.Token {\n\t\t\t\tcase js_lexer.TCloseBrace, js_lexer.TCase, js_lexer.TDefault:\n\t\t\t\t\tbreak caseBody\n\n\t\t\t\tdefault:\n\t\t\t\t\tbody = append(body, p.parseStmt(parseStmtOpts{lexicalDecl: lexicalDeclAllowAll}))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcases = append(cases, js_ast.Case{ValueOrNil: value, Body: body, Loc: caseLoc})\n\t\t}\n\n\t\tcloseBraceLoc := p.lexer.Loc()\n\t\tp.lexer.Expect(js_lexer.TCloseBrace)\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SSwitch{\n\t\t\tTest:          test,\n\t\t\tCases:         cases,\n\t\t\tBodyLoc:       bodyLoc,\n\t\t\tCloseBraceLoc: closeBraceLoc,\n\t\t}}\n\n\tcase js_lexer.TTry:\n\t\tp.lexer.Next()\n\t\tblockLoc := p.lexer.Loc()\n\t\tp.lexer.Expect(js_lexer.TOpenBrace)\n\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, loc)\n\t\tbody := p.parseStmtsUpTo(js_lexer.TCloseBrace, parseStmtOpts{})\n\t\tp.popScope()\n\t\tcloseBraceLoc := p.lexer.Loc()\n\t\tp.lexer.Next()\n\n\t\tvar catch *js_ast.Catch = nil\n\t\tvar finally *js_ast.Finally = nil\n\n\t\tif p.lexer.Token == js_lexer.TCatch {\n\t\t\tcatchLoc := p.lexer.Loc()\n\t\t\tp.pushScopeForParsePass(js_ast.ScopeCatchBinding, catchLoc)\n\t\t\tp.lexer.Next()\n\t\t\tvar bindingOrNil js_ast.Binding\n\n\t\t\t// The catch binding is optional, and can be omitted\n\t\t\tif p.lexer.Token == js_lexer.TOpenBrace {\n\t\t\t\tif p.options.unsupportedJSFeatures.Has(compat.OptionalCatchBinding) {\n\t\t\t\t\t// Generate a new symbol for the catch binding for older browsers\n\t\t\t\t\tref := p.newSymbol(js_ast.SymbolOther, \"e\")\n\t\t\t\t\tp.currentScope.Generated = append(p.currentScope.Generated, ref)\n\t\t\t\t\tbindingOrNil = js_ast.Binding{Loc: p.lexer.Loc(), Data: &js_ast.BIdentifier{Ref: ref}}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\t\t\t\tbindingOrNil = p.parseBinding()\n\n\t\t\t\t// Skip over types\n\t\t\t\tif p.options.ts.Parse && p.lexer.Token == js_lexer.TColon {\n\t\t\t\t\tp.lexer.Expect(js_lexer.TColon)\n\t\t\t\t\tp.skipTypeScriptType(js_ast.LLowest)\n\t\t\t\t}\n\n\t\t\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\n\t\t\t\t// Bare identifiers are a special case\n\t\t\t\tkind := js_ast.SymbolOther\n\t\t\t\tif _, ok := bindingOrNil.Data.(*js_ast.BIdentifier); ok {\n\t\t\t\t\tkind = js_ast.SymbolCatchIdentifier\n\t\t\t\t}\n\t\t\t\tp.declareBinding(kind, bindingOrNil, parseStmtOpts{})\n\t\t\t}\n\n\t\t\tblockLoc := p.lexer.Loc()\n\t\t\tp.lexer.Expect(js_lexer.TOpenBrace)\n\n\t\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, blockLoc)\n\t\t\tstmts := p.parseStmtsUpTo(js_lexer.TCloseBrace, parseStmtOpts{})\n\t\t\tp.popScope()\n\n\t\t\tcloseBraceLoc := p.lexer.Loc()\n\t\t\tp.lexer.Next()\n\t\t\tcatch = &js_ast.Catch{Loc: catchLoc, BindingOrNil: bindingOrNil, BlockLoc: blockLoc, Block: js_ast.SBlock{Stmts: stmts, CloseBraceLoc: closeBraceLoc}}\n\t\t\tp.popScope()\n\t\t}\n\n\t\tif p.lexer.Token == js_lexer.TFinally || catch == nil {\n\t\t\tfinallyLoc := p.lexer.Loc()\n\t\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, finallyLoc)\n\t\t\tp.lexer.Expect(js_lexer.TFinally)\n\t\t\tp.lexer.Expect(js_lexer.TOpenBrace)\n\t\t\tstmts := p.parseStmtsUpTo(js_lexer.TCloseBrace, parseStmtOpts{})\n\t\t\tcloseBraceLoc := p.lexer.Loc()\n\t\t\tp.lexer.Next()\n\t\t\tfinally = &js_ast.Finally{Loc: finallyLoc, Block: js_ast.SBlock{Stmts: stmts, CloseBraceLoc: closeBraceLoc}}\n\t\t\tp.popScope()\n\t\t}\n\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STry{\n\t\t\tBlockLoc: blockLoc,\n\t\t\tBlock:    js_ast.SBlock{Stmts: body, CloseBraceLoc: closeBraceLoc},\n\t\t\tCatch:    catch,\n\t\t\tFinally:  finally,\n\t\t}}\n\n\tcase js_lexer.TFor:\n\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, loc)\n\t\tdefer p.popScope()\n\n\t\tp.lexer.Next()\n\n\t\t// \"for await (let x of y) {}\"\n\t\tisForAwait := p.lexer.IsContextualKeyword(\"await\")\n\t\tif isForAwait {\n\t\t\tawaitRange := p.lexer.Range()\n\t\t\tif p.fnOrArrowDataParse.await != allowExpr {\n\t\t\t\tp.log.AddError(&p.tracker, awaitRange, \"Cannot use \\\"await\\\" outside an async function\")\n\t\t\t\tisForAwait = false\n\t\t\t} else {\n\t\t\t\tdidGenerateError := false\n\t\t\t\tif p.fnOrArrowDataParse.isTopLevel {\n\t\t\t\t\tp.topLevelAwaitKeyword = awaitRange\n\t\t\t\t\tdidGenerateError = p.markSyntaxFeature(compat.TopLevelAwait, awaitRange)\n\t\t\t\t}\n\t\t\t\tif !didGenerateError && p.options.unsupportedJSFeatures.Has(compat.AsyncAwait) && p.options.unsupportedJSFeatures.Has(compat.Generator) {\n\t\t\t\t\t// If for-await loops aren't supported, then we only support lowering\n\t\t\t\t\t// if either async/await or generators is supported. Otherwise we\n\t\t\t\t\t// cannot lower for-await loops.\n\t\t\t\t\tp.markSyntaxFeature(compat.ForAwait, awaitRange)\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.lexer.Next()\n\t\t}\n\n\t\tp.lexer.Expect(js_lexer.TOpenParen)\n\n\t\tvar initOrNil js_ast.Stmt\n\t\tvar testOrNil js_ast.Expr\n\t\tvar updateOrNil js_ast.Expr\n\n\t\t// \"in\" expressions aren't allowed here\n\t\tp.allowIn = false\n\n\t\tvar badLetRange logger.Range\n\t\tif p.lexer.IsContextualKeyword(\"let\") {\n\t\t\tbadLetRange = p.lexer.Range()\n\t\t}\n\t\tdecls := []js_ast.Decl{}\n\t\tinitLoc := p.lexer.Loc()\n\t\tisVar := false\n\t\tswitch p.lexer.Token {\n\t\tcase js_lexer.TVar:\n\t\t\tisVar = true\n\t\t\tp.lexer.Next()\n\t\t\tdecls = p.parseAndDeclareDecls(js_ast.SymbolHoisted, parseStmtOpts{})\n\t\t\tinitOrNil = js_ast.Stmt{Loc: initLoc, Data: &js_ast.SLocal{Kind: js_ast.LocalVar, Decls: decls}}\n\n\t\tcase js_lexer.TConst:\n\t\t\tp.markSyntaxFeature(compat.ConstAndLet, p.lexer.Range())\n\t\t\tp.lexer.Next()\n\t\t\tdecls = p.parseAndDeclareDecls(js_ast.SymbolConst, parseStmtOpts{})\n\t\t\tinitOrNil = js_ast.Stmt{Loc: initLoc, Data: &js_ast.SLocal{Kind: js_ast.LocalConst, Decls: decls}}\n\n\t\tcase js_lexer.TSemicolon:\n\n\t\tdefault:\n\t\t\tvar expr js_ast.Expr\n\t\t\tvar stmt js_ast.Stmt\n\t\t\texpr, stmt, decls = p.parseExprOrLetStmt(parseStmtOpts{\n\t\t\t\tlexicalDecl:        lexicalDeclAllowAll,\n\t\t\t\tisForLoopInit:      true,\n\t\t\t\tisForAwaitLoopInit: isForAwait,\n\t\t\t})\n\t\t\tif stmt.Data != nil {\n\t\t\t\tbadLetRange = logger.Range{}\n\t\t\t\tinitOrNil = stmt\n\t\t\t} else {\n\t\t\t\tinitOrNil = js_ast.Stmt{Loc: expr.Loc, Data: &js_ast.SExpr{Value: expr}}\n\t\t\t}\n\t\t}\n\n\t\t// \"in\" expressions are allowed again\n\t\tp.allowIn = true\n\n\t\t// Detect for-of loops\n\t\tif p.lexer.IsContextualKeyword(\"of\") || isForAwait {\n\t\t\tif badLetRange.Len > 0 {\n\t\t\t\tp.log.AddError(&p.tracker, badLetRange, \"\\\"let\\\" must be wrapped in parentheses to be used as an expression here:\")\n\t\t\t}\n\t\t\tif isForAwait && !p.lexer.IsContextualKeyword(\"of\") {\n\t\t\t\tif initOrNil.Data != nil {\n\t\t\t\t\tp.lexer.ExpectedString(\"\\\"of\\\"\")\n\t\t\t\t} else {\n\t\t\t\t\tp.lexer.Unexpected()\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.forbidInitializers(decls, \"of\", false)\n\t\t\tp.markSyntaxFeature(compat.ForOf, p.lexer.Range())\n\t\t\tp.lexer.Next()\n\t\t\tvalue := p.parseExpr(js_ast.LComma)\n\t\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\t\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SForOf{IsAwait: isForAwait, Init: initOrNil, Value: value, Body: body}}\n\t\t}\n\n\t\t// Detect for-in loops\n\t\tif p.lexer.Token == js_lexer.TIn {\n\t\t\tp.forbidInitializers(decls, \"in\", isVar)\n\t\t\tp.lexer.Next()\n\t\t\tvalue := p.parseExpr(js_ast.LLowest)\n\t\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\t\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SForIn{Init: initOrNil, Value: value, Body: body}}\n\t\t}\n\n\t\t// Only require \"const\" statement initializers when we know we're a normal for loop\n\t\tif local, ok := initOrNil.Data.(*js_ast.SLocal); ok && local.Kind == js_ast.LocalConst {\n\t\t\tp.requireInitializers(decls)\n\t\t}\n\n\t\tp.lexer.Expect(js_lexer.TSemicolon)\n\n\t\tif p.lexer.Token != js_lexer.TSemicolon {\n\t\t\ttestOrNil = p.parseExpr(js_ast.LLowest)\n\t\t}\n\n\t\tp.lexer.Expect(js_lexer.TSemicolon)\n\n\t\tif p.lexer.Token != js_lexer.TCloseParen {\n\t\t\tupdateOrNil = p.parseExpr(js_ast.LLowest)\n\t\t}\n\n\t\tp.lexer.Expect(js_lexer.TCloseParen)\n\t\tbody := p.parseStmt(parseStmtOpts{})\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SFor{\n\t\t\tInitOrNil:   initOrNil,\n\t\t\tTestOrNil:   testOrNil,\n\t\t\tUpdateOrNil: updateOrNil,\n\t\t\tBody:        body,\n\t\t}}\n\n\tcase js_lexer.TImport:\n\t\tpreviousImportStatementKeyword := p.esmImportStatementKeyword\n\t\tp.esmImportStatementKeyword = p.lexer.Range()\n\t\tp.lexer.Next()\n\t\tstmt := js_ast.SImport{}\n\t\twasOriginallyBareImport := false\n\n\t\t// \"export import foo = bar\"\n\t\t// \"import foo = bar\" in a namespace\n\t\tif (opts.isExport || (opts.isNamespaceScope && !opts.isTypeScriptDeclare)) && p.lexer.Token != js_lexer.TIdentifier {\n\t\t\tp.lexer.Expected(js_lexer.TIdentifier)\n\t\t}\n\n\t\tswitch p.lexer.Token {\n\t\tcase js_lexer.TOpenParen, js_lexer.TDot:\n\t\t\t// \"import('path')\"\n\t\t\t// \"import.meta\"\n\t\t\tp.esmImportStatementKeyword = previousImportStatementKeyword // This wasn't an ESM import statement after all\n\t\t\texpr := p.parseSuffix(p.parseImportExpr(loc, js_ast.LLowest), js_ast.LLowest, nil, 0)\n\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExpr{Value: expr}}\n\n\t\tcase js_lexer.TStringLiteral, js_lexer.TNoSubstitutionTemplateLiteral:\n\t\t\t// \"import 'path'\"\n\t\t\tif !opts.isModuleScope && (!opts.isNamespaceScope || !opts.isTypeScriptDeclare) {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t\treturn js_ast.Stmt{}\n\t\t\t}\n\n\t\t\twasOriginallyBareImport = true\n\n\t\tcase js_lexer.TAsterisk:\n\t\t\t// \"import * as ns from 'path'\"\n\t\t\tif !opts.isModuleScope && (!opts.isNamespaceScope || !opts.isTypeScriptDeclare) {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t\treturn js_ast.Stmt{}\n\t\t\t}\n\n\t\t\tp.lexer.Next()\n\t\t\tp.lexer.ExpectContextualKeyword(\"as\")\n\t\t\tstmt.NamespaceRef = p.storeNameInRef(p.lexer.Identifier)\n\t\t\tstarLoc := p.lexer.Loc()\n\t\t\tstmt.StarNameLoc = &starLoc\n\t\t\tp.lexer.Expect(js_lexer.TIdentifier)\n\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\n\t\tcase js_lexer.TOpenBrace:\n\t\t\t// \"import {item1, item2} from 'path'\"\n\t\t\tif !opts.isModuleScope && (!opts.isNamespaceScope || !opts.isTypeScriptDeclare) {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t\treturn js_ast.Stmt{}\n\t\t\t}\n\n\t\t\titems, isSingleLine := p.parseImportClause()\n\t\t\tstmt.Items = &items\n\t\t\tstmt.IsSingleLine = isSingleLine\n\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\n\t\tcase js_lexer.TIdentifier:\n\t\t\t// \"import defaultItem from 'path'\"\n\t\t\t// \"import foo = bar\"\n\t\t\tif !opts.isModuleScope && !opts.isNamespaceScope {\n\t\t\t\tp.lexer.Unexpected()\n\t\t\t\treturn js_ast.Stmt{}\n\t\t\t}\n\n\t\t\tdefaultName := p.lexer.Identifier\n\t\t\tstmt.DefaultName = &js_ast.LocRef{Loc: p.lexer.Loc(), Ref: p.storeNameInRef(defaultName)}\n\t\t\tp.lexer.Next()\n\n\t\t\tif p.options.ts.Parse {\n\t\t\t\t// Skip over type-only imports\n\t\t\t\tif defaultName.String == \"type\" {\n\t\t\t\t\tswitch p.lexer.Token {\n\t\t\t\t\tcase js_lexer.TIdentifier:\n\t\t\t\t\t\tif p.lexer.Identifier.String != \"from\" {\n\t\t\t\t\t\t\tdefaultName = p.lexer.Identifier\n\t\t\t\t\t\t\tstmt.DefaultName.Loc = p.lexer.Loc()\n\t\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\t\tif p.lexer.Token == js_lexer.TEquals {\n\t\t\t\t\t\t\t\t// \"import type foo = require('bar');\"\n\t\t\t\t\t\t\t\t// \"import type foo = bar.baz;\"\n\t\t\t\t\t\t\t\topts.isTypeScriptDeclare = true\n\t\t\t\t\t\t\t\treturn p.parseTypeScriptImportEqualsStmt(loc, opts, stmt.DefaultName.Loc, defaultName.String)\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t// \"import type foo from 'bar';\"\n\t\t\t\t\t\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\t\t\t\t\t\t\t\tp.parsePath()\n\t\t\t\t\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\tcase js_lexer.TAsterisk:\n\t\t\t\t\t\t// \"import type * as foo from 'bar';\"\n\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\tp.lexer.ExpectContextualKeyword(\"as\")\n\t\t\t\t\t\tp.lexer.Expect(js_lexer.TIdentifier)\n\t\t\t\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\t\t\t\t\t\tp.parsePath()\n\t\t\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\n\t\t\t\t\tcase js_lexer.TOpenBrace:\n\t\t\t\t\t\t// \"import type {foo} from 'bar';\"\n\t\t\t\t\t\tp.parseImportClause()\n\t\t\t\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\t\t\t\t\t\tp.parsePath()\n\t\t\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Parse TypeScript import assignment statements\n\t\t\t\tif p.lexer.Token == js_lexer.TEquals || opts.isExport || (opts.isNamespaceScope && !opts.isTypeScriptDeclare) {\n\t\t\t\t\tp.esmImportStatementKeyword = previousImportStatementKeyword // This wasn't an ESM import statement after all\n\t\t\t\t\treturn p.parseTypeScriptImportEqualsStmt(loc, opts, stmt.DefaultName.Loc, defaultName.String)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif p.lexer.Token == js_lexer.TComma {\n\t\t\t\tp.lexer.Next()\n\t\t\t\tswitch p.lexer.Token {\n\t\t\t\tcase js_lexer.TAsterisk:\n\t\t\t\t\t// \"import defaultItem, * as ns from 'path'\"\n\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\tp.lexer.ExpectContextualKeyword(\"as\")\n\t\t\t\t\tstmt.NamespaceRef = p.storeNameInRef(p.lexer.Identifier)\n\t\t\t\t\tstarLoc := p.lexer.Loc()\n\t\t\t\t\tstmt.StarNameLoc = &starLoc\n\t\t\t\t\tp.lexer.Expect(js_lexer.TIdentifier)\n\n\t\t\t\tcase js_lexer.TOpenBrace:\n\t\t\t\t\t// \"import defaultItem, {item1, item2} from 'path'\"\n\t\t\t\t\titems, isSingleLine := p.parseImportClause()\n\t\t\t\t\tstmt.Items = &items\n\t\t\t\t\tstmt.IsSingleLine = isSingleLine\n\n\t\t\t\tdefault:\n\t\t\t\t\tp.lexer.Unexpected()\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tp.lexer.ExpectContextualKeyword(\"from\")\n\n\t\tdefault:\n\t\t\tp.lexer.Unexpected()\n\t\t\treturn js_ast.Stmt{}\n\t\t}\n\n\t\tpathLoc, pathText, assertions, flags := p.parsePath()\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\n\t\t// If TypeScript's \"preserveValueImports\": true setting is active, TypeScript's\n\t\t// \"importsNotUsedAsValues\": \"preserve\" setting is NOT active, and the import\n\t\t// clause is present and empty (or is non-empty but filled with type-only\n\t\t// items), then the import statement should still be removed entirely to match\n\t\t// the behavior of the TypeScript compiler:\n\t\t//\n\t\t//   // Keep these\n\t\t//   import 'x'\n\t\t//   import { y } from 'x'\n\t\t//   import { y, type z } from 'x'\n\t\t//\n\t\t//   // Remove these\n\t\t//   import {} from 'x'\n\t\t//   import { type y } from 'x'\n\t\t//\n\t\t//   // Remove the items from these\n\t\t//   import d, {} from 'x'\n\t\t//   import d, { type y } from 'x'\n\t\t//\n\t\tif p.options.ts.Parse && p.options.unusedImportFlagsTS == config.UnusedImportKeepValues && stmt.Items != nil && len(*stmt.Items) == 0 {\n\t\t\tif stmt.DefaultName == nil {\n\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t}\n\t\t\tstmt.Items = nil\n\t\t}\n\n\t\tif wasOriginallyBareImport {\n\t\t\tflags |= ast.WasOriginallyBareImport\n\t\t}\n\t\tstmt.ImportRecordIndex = p.addImportRecord(ast.ImportStmt, pathLoc, pathText, assertions, flags)\n\n\t\tif stmt.StarNameLoc != nil {\n\t\t\tname := p.loadNameFromRef(stmt.NamespaceRef)\n\t\t\tstmt.NamespaceRef = p.declareSymbol(js_ast.SymbolImport, *stmt.StarNameLoc, name)\n\t\t} else {\n\t\t\t// Generate a symbol for the namespace\n\t\t\tname := \"import_\" + js_ast.GenerateNonUniqueNameFromPath(pathText)\n\t\t\tstmt.NamespaceRef = p.newSymbol(js_ast.SymbolOther, name)\n\t\t\tp.currentScope.Generated = append(p.currentScope.Generated, stmt.NamespaceRef)\n\t\t}\n\t\titemRefs := make(map[string]js_ast.LocRef)\n\n\t\t// Link the default item to the namespace\n\t\tif stmt.DefaultName != nil {\n\t\t\tname := p.loadNameFromRef(stmt.DefaultName.Ref)\n\t\t\tref := p.declareSymbol(js_ast.SymbolImport, stmt.DefaultName.Loc, name)\n\t\t\tp.isImportItem[ref] = true\n\t\t\tstmt.DefaultName.Ref = ref\n\t\t}\n\n\t\t// Link each import item to the namespace\n\t\tif stmt.Items != nil {\n\t\t\tfor i, item := range *stmt.Items {\n\t\t\t\tname := p.loadNameFromRef(item.Name.Ref)\n\t\t\t\tref := p.declareSymbol(js_ast.SymbolImport, item.Name.Loc, name)\n\t\t\t\tp.checkForUnrepresentableIdentifier(item.AliasLoc, item.Alias)\n\t\t\t\tp.isImportItem[ref] = true\n\t\t\t\t(*stmt.Items)[i].Name.Ref = ref\n\t\t\t\titemRefs[item.Alias] = js_ast.LocRef{Loc: item.Name.Loc, Ref: ref}\n\t\t\t}\n\t\t}\n\n\t\t// Track the items for this namespace\n\t\tp.importItemsForNamespace[stmt.NamespaceRef] = namespaceImportItems{\n\t\t\tentries:           itemRefs,\n\t\t\timportRecordIndex: stmt.ImportRecordIndex,\n\t\t}\n\n\t\t// Import statements anywhere in the file disable top-level const\n\t\t// local prefix because import cycles can be used to trigger TDZ\n\t\tp.currentScope.IsAfterConstLocalPrefix = true\n\t\treturn js_ast.Stmt{Loc: loc, Data: &stmt}\n\n\tcase js_lexer.TBreak:\n\t\tp.lexer.Next()\n\t\tname := p.parseLabelName()\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SBreak{Label: name}}\n\n\tcase js_lexer.TContinue:\n\t\tp.lexer.Next()\n\t\tname := p.parseLabelName()\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SContinue{Label: name}}\n\n\tcase js_lexer.TReturn:\n\t\tif p.fnOrArrowDataParse.isReturnDisallowed {\n\t\t\tp.log.AddError(&p.tracker, p.lexer.Range(), \"A return statement cannot be used here:\")\n\t\t}\n\t\tp.lexer.Next()\n\t\tvar value js_ast.Expr\n\t\tif p.lexer.Token != js_lexer.TSemicolon &&\n\t\t\t!p.lexer.HasNewlineBefore &&\n\t\t\tp.lexer.Token != js_lexer.TCloseBrace &&\n\t\t\tp.lexer.Token != js_lexer.TEndOfFile {\n\t\t\tvalue = p.parseExpr(js_ast.LLowest)\n\t\t}\n\t\tp.latestReturnHadSemicolon = p.lexer.Token == js_lexer.TSemicolon\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SReturn{ValueOrNil: value}}\n\n\tcase js_lexer.TThrow:\n\t\tp.lexer.Next()\n\t\tif p.lexer.HasNewlineBefore {\n\t\t\tendLoc := logger.Loc{Start: loc.Start + 5}\n\t\t\tp.log.AddError(&p.tracker, logger.Range{Loc: endLoc},\n\t\t\t\t\"Unexpected newline after \\\"throw\\\"\")\n\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SThrow{Value: js_ast.Expr{Loc: endLoc, Data: js_ast.ENullShared}}}\n\t\t}\n\t\texpr := p.parseExpr(js_ast.LLowest)\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SThrow{Value: expr}}\n\n\tcase js_lexer.TDebugger:\n\t\tp.lexer.Next()\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: js_ast.SDebuggerShared}\n\n\tcase js_lexer.TOpenBrace:\n\t\tp.pushScopeForParsePass(js_ast.ScopeBlock, loc)\n\t\tdefer p.popScope()\n\n\t\tp.lexer.Next()\n\t\tstmts := p.parseStmtsUpTo(js_lexer.TCloseBrace, parseStmtOpts{})\n\t\tcloseBraceLoc := p.lexer.Loc()\n\t\tp.lexer.Next()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SBlock{Stmts: stmts, CloseBraceLoc: closeBraceLoc}}\n\n\tdefault:\n\t\tisIdentifier := p.lexer.Token == js_lexer.TIdentifier\n\t\tname := p.lexer.Identifier.String\n\n\t\t// Parse either an async function, an async expression, or a normal expression\n\t\tvar expr js_ast.Expr\n\t\tif isIdentifier && p.lexer.Raw() == \"async\" {\n\t\t\tasyncRange := p.lexer.Range()\n\t\t\tp.lexer.Next()\n\t\t\tif p.lexer.Token == js_lexer.TFunction && !p.lexer.HasNewlineBefore {\n\t\t\t\tp.lexer.Next()\n\t\t\t\treturn p.parseFnStmt(asyncRange.Loc, opts, true /* isAsync */, asyncRange)\n\t\t\t}\n\t\t\texpr = p.parseSuffix(p.parseAsyncPrefixExpr(asyncRange, js_ast.LLowest, 0), js_ast.LLowest, nil, 0)\n\t\t} else {\n\t\t\tvar stmt js_ast.Stmt\n\t\t\texpr, stmt, _ = p.parseExprOrLetStmt(opts)\n\t\t\tif stmt.Data != nil {\n\t\t\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\t\t\treturn stmt\n\t\t\t}\n\t\t}\n\n\t\tif isIdentifier {\n\t\t\tif ident, ok := expr.Data.(*js_ast.EIdentifier); ok {\n\t\t\t\tif p.lexer.Token == js_lexer.TColon && opts.tsDecorators == nil {\n\t\t\t\t\tp.pushScopeForParsePass(js_ast.ScopeLabel, loc)\n\t\t\t\t\tdefer p.popScope()\n\n\t\t\t\t\t// Parse a labeled statement\n\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\tname := js_ast.LocRef{Loc: expr.Loc, Ref: ident.Ref}\n\t\t\t\t\tnestedOpts := parseStmtOpts{}\n\t\t\t\t\tif opts.lexicalDecl == lexicalDeclAllowAll || opts.lexicalDecl == lexicalDeclAllowFnInsideLabel {\n\t\t\t\t\t\tnestedOpts.lexicalDecl = lexicalDeclAllowFnInsideLabel\n\t\t\t\t\t}\n\t\t\t\t\tstmt := p.parseStmt(nestedOpts)\n\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SLabel{Name: name, Stmt: stmt}}\n\t\t\t\t}\n\n\t\t\t\tif p.options.ts.Parse {\n\t\t\t\t\tswitch name {\n\t\t\t\t\tcase \"type\":\n\t\t\t\t\t\tif p.lexer.Token == js_lexer.TIdentifier && !p.lexer.HasNewlineBefore {\n\t\t\t\t\t\t\t// \"type Foo = any\"\n\t\t\t\t\t\t\tp.skipTypeScriptTypeStmt(parseStmtOpts{isModuleScope: opts.isModuleScope})\n\t\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t\t}\n\n\t\t\t\t\tcase \"namespace\", \"module\":\n\t\t\t\t\t\t// \"namespace Foo {}\"\n\t\t\t\t\t\t// \"module Foo {}\"\n\t\t\t\t\t\t// \"declare module 'fs' {}\"\n\t\t\t\t\t\t// \"declare module 'fs';\"\n\t\t\t\t\t\tif (opts.isModuleScope || opts.isNamespaceScope) && (p.lexer.Token == js_lexer.TIdentifier ||\n\t\t\t\t\t\t\t(p.lexer.Token == js_lexer.TStringLiteral && opts.isTypeScriptDeclare)) {\n\t\t\t\t\t\t\treturn p.parseTypeScriptNamespaceStmt(loc, opts)\n\t\t\t\t\t\t}\n\n\t\t\t\t\tcase \"interface\":\n\t\t\t\t\t\t// \"interface Foo {}\"\n\t\t\t\t\t\tp.skipTypeScriptInterfaceStmt(parseStmtOpts{isModuleScope: opts.isModuleScope})\n\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\n\t\t\t\t\tcase \"abstract\":\n\t\t\t\t\t\tif p.lexer.Token == js_lexer.TClass || opts.tsDecorators != nil {\n\t\t\t\t\t\t\treturn p.parseClassStmt(loc, opts)\n\t\t\t\t\t\t}\n\n\t\t\t\t\tcase \"global\":\n\t\t\t\t\t\t// \"declare module 'fs' { global { namespace NodeJS {} } }\"\n\t\t\t\t\t\tif opts.isNamespaceScope && opts.isTypeScriptDeclare && p.lexer.Token == js_lexer.TOpenBrace {\n\t\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\t\tp.parseStmtsUpTo(js_lexer.TCloseBrace, opts)\n\t\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t\t}\n\n\t\t\t\t\tcase \"declare\":\n\t\t\t\t\t\topts.lexicalDecl = lexicalDeclAllowAll\n\t\t\t\t\t\topts.isTypeScriptDeclare = true\n\n\t\t\t\t\t\t// \"@decorator declare class Foo {}\"\n\t\t\t\t\t\t// \"@decorator declare abstract class Foo {}\"\n\t\t\t\t\t\tif opts.tsDecorators != nil && p.lexer.Token != js_lexer.TClass && !p.lexer.IsContextualKeyword(\"abstract\") {\n\t\t\t\t\t\t\tp.logMisplacedDecoratorError(opts.tsDecorators)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// \"declare global { ... }\"\n\t\t\t\t\t\tif p.lexer.IsContextualKeyword(\"global\") {\n\t\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\t\tp.lexer.Expect(js_lexer.TOpenBrace)\n\t\t\t\t\t\t\tp.parseStmtsUpTo(js_lexer.TCloseBrace, opts)\n\t\t\t\t\t\t\tp.lexer.Next()\n\t\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// \"declare const x: any\"\n\t\t\t\t\t\tstmt := p.parseStmt(opts)\n\t\t\t\t\t\tif opts.tsDecorators != nil {\n\t\t\t\t\t\t\tp.discardScopesUpTo(opts.tsDecorators.scopeIndex)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Unlike almost all uses of \"declare\", statements that use\n\t\t\t\t\t\t// \"export declare\" with \"var/let/const\" inside a namespace affect\n\t\t\t\t\t\t// code generation. They cause any declared bindings to be\n\t\t\t\t\t\t// considered exports of the namespace. Identifier references to\n\t\t\t\t\t\t// those names must be converted into property accesses off the\n\t\t\t\t\t\t// namespace object:\n\t\t\t\t\t\t//\n\t\t\t\t\t\t//   namespace ns {\n\t\t\t\t\t\t//     export declare const x\n\t\t\t\t\t\t//     export function y() { return x }\n\t\t\t\t\t\t//   }\n\t\t\t\t\t\t//\n\t\t\t\t\t\t//   (ns as any).x = 1\n\t\t\t\t\t\t//   console.log(ns.y())\n\t\t\t\t\t\t//\n\t\t\t\t\t\t// In this example, \"return x\" must be replaced with \"return ns.x\".\n\t\t\t\t\t\t// This is handled by replacing each \"export declare\" statement\n\t\t\t\t\t\t// inside a namespace with an \"export var\" statement containing all\n\t\t\t\t\t\t// of the declared bindings. That \"export var\" statement will later\n\t\t\t\t\t\t// cause identifiers to be transformed into property accesses.\n\t\t\t\t\t\tif opts.isNamespaceScope && opts.isExport {\n\t\t\t\t\t\t\tvar decls []js_ast.Decl\n\t\t\t\t\t\t\tif s, ok := stmt.Data.(*js_ast.SLocal); ok {\n\t\t\t\t\t\t\t\tfor _, decl := range s.Decls {\n\t\t\t\t\t\t\t\t\tdecls = extractDeclsForBinding(decl.Binding, decls)\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif len(decls) > 0 {\n\t\t\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SLocal{\n\t\t\t\t\t\t\t\t\tKind:     js_ast.LocalVar,\n\t\t\t\t\t\t\t\t\tIsExport: true,\n\t\t\t\t\t\t\t\t\tDecls:    decls,\n\t\t\t\t\t\t\t\t}}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.STypeScript{}}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tp.lexer.ExpectOrInsertSemicolon()\n\t\treturn js_ast.Stmt{Loc: loc, Data: &js_ast.SExpr{Value: expr}}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *NinRepPackedNativeUnsafe) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNativeUnsafe: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNativeUnsafe: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipPacked(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func validateGlobalConfig(cfg config.GlobalConfig) error {\n\tif cfg.OpsGenieAPIKeyFile != \"\" {\n\t\treturn errOpsGenieAPIKeyFileNotAllowed\n\t}\n\tif cfg.SlackAPIURLFile != \"\" {\n\t\treturn errSlackAPIURLFileNotAllowed\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) assignStorageTasks(success chan *storageResponse, fail chan *storageRequest, cancel chan struct{}) {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\n\t// Sort the peers by download capacity to use faster ones if many available\n\tidlers := &capacitySort{\n\t\tids:  make([]string, 0, len(s.storageIdlers)),\n\t\tcaps: make([]int, 0, len(s.storageIdlers)),\n\t}\n\ttargetTTL := s.rates.TargetTimeout()\n\tfor id := range s.storageIdlers {\n\t\tif _, ok := s.statelessPeers[id]; ok {\n\t\t\tcontinue\n\t\t}\n\t\tidlers.ids = append(idlers.ids, id)\n\t\tidlers.caps = append(idlers.caps, s.rates.Capacity(id, StorageRangesMsg, targetTTL))\n\t}\n\tif len(idlers.ids) == 0 {\n\t\treturn\n\t}\n\tsort.Sort(sort.Reverse(idlers))\n\n\t// Iterate over all the tasks and try to find a pending one\n\tfor _, task := range s.tasks {\n\t\t// Skip any tasks not in the storage retrieval phase\n\t\tif task.res == nil {\n\t\t\tcontinue\n\t\t}\n\t\t// Skip tasks that are already retrieving (or done with) all small states\n\t\tif len(task.SubTasks) == 0 && len(task.stateTasks) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\t// Task pending retrieval, try to find an idle peer. If no such peer\n\t\t// exists, we probably assigned tasks for all (or they are stateless).\n\t\t// Abort the entire assignment mechanism.\n\t\tif len(idlers.ids) == 0 {\n\t\t\treturn\n\t\t}\n\t\tvar (\n\t\t\tidle = idlers.ids[0]\n\t\t\tpeer = s.peers[idle]\n\t\t\tcap  = idlers.caps[0]\n\t\t)\n\t\tidlers.ids, idlers.caps = idlers.ids[1:], idlers.caps[1:]\n\n\t\t// Matched a pending task to an idle peer, allocate a unique request id\n\t\tvar reqid uint64\n\t\tfor {\n\t\t\treqid = uint64(rand.Int63())\n\t\t\tif reqid == 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif _, ok := s.storageReqs[reqid]; ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\t// Generate the network query and send it to the peer. If there are\n\t\t// large contract tasks pending, complete those before diving into\n\t\t// even more new contracts.\n\t\tif cap > maxRequestSize {\n\t\t\tcap = maxRequestSize\n\t\t}\n\t\tif cap < minRequestSize { // Don't bother with peers below a bare minimum performance\n\t\t\tcap = minRequestSize\n\t\t}\n\t\tstorageSets := cap / 1024\n\n\t\tvar (\n\t\t\taccounts = make([]common.Hash, 0, storageSets)\n\t\t\troots    = make([]common.Hash, 0, storageSets)\n\t\t\tsubtask  *storageTask\n\t\t)\n\t\tfor account, subtasks := range task.SubTasks {\n\t\t\tfor _, st := range subtasks {\n\t\t\t\t// Skip any subtasks already filling\n\t\t\t\tif st.req != nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// Found an incomplete storage chunk, schedule it\n\t\t\t\taccounts = append(accounts, account)\n\t\t\t\troots = append(roots, st.root)\n\t\t\t\tsubtask = st\n\t\t\t\tbreak // Large contract chunks are downloaded individually\n\t\t\t}\n\t\t\tif subtask != nil {\n\t\t\t\tbreak // Large contract chunks are downloaded individually\n\t\t\t}\n\t\t}\n\t\tif subtask == nil {\n\t\t\t// No large contract required retrieval, but small ones available\n\t\t\tfor account, root := range task.stateTasks {\n\t\t\t\tdelete(task.stateTasks, account)\n\n\t\t\t\taccounts = append(accounts, account)\n\t\t\t\troots = append(roots, root)\n\n\t\t\t\tif len(accounts) >= storageSets {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// If nothing was found, it means this task is actually already fully\n\t\t// retrieving, but large contracts are hard to detect. Skip to the next.\n\t\tif len(accounts) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\treq := &storageRequest{\n\t\t\tpeer:     idle,\n\t\t\tid:       reqid,\n\t\t\ttime:     time.Now(),\n\t\t\tdeliver:  success,\n\t\t\trevert:   fail,\n\t\t\tcancel:   cancel,\n\t\t\tstale:    make(chan struct{}),\n\t\t\taccounts: accounts,\n\t\t\troots:    roots,\n\t\t\tmainTask: task,\n\t\t\tsubTask:  subtask,\n\t\t}\n\t\tif subtask != nil {\n\t\t\treq.origin = subtask.Next\n\t\t\treq.limit = subtask.Last\n\t\t}\n\t\treq.timeout = time.AfterFunc(s.rates.TargetTimeout(), func() {\n\t\t\tpeer.Log().Debug(\"Storage request timed out\", \"reqid\", reqid)\n\t\t\ts.rates.Update(idle, StorageRangesMsg, 0, 0)\n\t\t\ts.scheduleRevertStorageRequest(req)\n\t\t})\n\t\ts.storageReqs[reqid] = req\n\t\tdelete(s.storageIdlers, idle)\n\n\t\ts.pend.Add(1)\n\t\tgo func(root common.Hash) {\n\t\t\tdefer s.pend.Done()\n\n\t\t\t// Attempt to send the remote request and revert if it fails\n\t\t\tvar origin, limit []byte\n\t\t\tif subtask != nil {\n\t\t\t\torigin, limit = req.origin[:], req.limit[:]\n\t\t\t}\n\t\t\tif err := peer.RequestStorageRanges(reqid, root, accounts, origin, limit, uint64(cap)); err != nil {\n\t\t\t\tlog.Debug(\"Failed to request storage\", \"err\", err)\n\t\t\t\ts.scheduleRevertStorageRequest(req)\n\t\t\t}\n\t\t}(s.root)\n\n\t\t// Inject the request into the subtask to block further assignments\n\t\tif subtask != nil {\n\t\t\tsubtask.req = req\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (m *CustomOneof) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomOneof: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomOneof: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 34:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Stringy\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_Stringy{string(dAtA[iNdEx:postIndex])}\n\t\t\tiNdEx = postIndex\n\t\tcase 35:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CustomType\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar vv github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tv := &vv\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_CustomType{*v}\n\t\t\tiNdEx = postIndex\n\t\tcase 36:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CastType\", wireType)\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_casttype.MyUint64Type\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_CastType{v}\n\t\tcase 37:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyCustomName\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_MyCustomName{v}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (a sslCipher) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, sslCipherAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (a *ActivationClaims) validateWithTimeChecks(vr *ValidationResults, timeChecks bool) {\n\tif timeChecks {\n\t\ta.ClaimsData.Validate(vr)\n\t}\n\ta.Activation.Validate(vr)\n\tif a.IssuerAccount != \"\" && !nkeys.IsValidPublicAccountKey(a.IssuerAccount) {\n\t\tvr.AddError(\"account_id is not an account public key\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func GetRuntimeConfigurations(cfgSnap *proxycfg.ConfigSnapshot) map[api.CompoundServiceName][]extensioncommon.RuntimeConfig {\n\textensionsMap := make(map[api.CompoundServiceName][]api.EnvoyExtension)\n\tupstreamMap := make(map[api.CompoundServiceName]*extensioncommon.UpstreamData)\n\tvar kind api.ServiceKind\n\textensionConfigurationsMap := make(map[api.CompoundServiceName][]extensioncommon.RuntimeConfig)\n\n\ttrustDomain := \"\"\n\tif cfgSnap.Roots != nil {\n\t\ttrustDomain = cfgSnap.Roots.TrustDomain\n\t}\n\n\tswitch cfgSnap.Kind {\n\tcase structs.ServiceKindConnectProxy:\n\t\tkind = api.ServiceKindConnectProxy\n\t\toutgoingKindByService := make(map[api.CompoundServiceName]api.ServiceKind)\n\t\tvipForService := make(map[api.CompoundServiceName]string)\n\t\tfor uid, upstreamData := range cfgSnap.ConnectProxy.WatchedUpstreamEndpoints {\n\t\t\tsn := upstreamIDToCompoundServiceName(uid)\n\n\t\t\tfor _, serviceNodes := range upstreamData {\n\t\t\t\tfor _, serviceNode := range serviceNodes {\n\t\t\t\t\tif serviceNode.Service == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tvip := serviceNode.Service.TaggedAddresses[structs.TaggedAddressVirtualIP].Address\n\t\t\t\t\tif vip != \"\" {\n\t\t\t\t\t\tif _, ok := vipForService[sn]; !ok {\n\t\t\t\t\t\t\tvipForService[sn] = vip\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// Store the upstream's kind, and for ServiceKindTypical we don't do anything because we'll default\n\t\t\t\t\t// any unset upstreams to ServiceKindConnectProxy below.\n\t\t\t\t\tswitch serviceNode.Service.Kind {\n\t\t\t\t\tcase structs.ServiceKindTypical:\n\t\t\t\t\tdefault:\n\t\t\t\t\t\toutgoingKindByService[sn] = api.ServiceKind(serviceNode.Service.Kind)\n\t\t\t\t\t}\n\t\t\t\t\t// We only need the kind from one instance, so break once we find it.\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// TODO(peering): consider PeerUpstreamEndpoints in addition to DiscoveryChain\n\t\t// These are the discovery chains for upstreams which have the Envoy Extensions applied to the local service.\n\t\tfor uid, dc := range cfgSnap.ConnectProxy.DiscoveryChain {\n\t\t\tcompoundServiceName := upstreamIDToCompoundServiceName(uid)\n\t\t\textensionsMap[compoundServiceName] = convertEnvoyExtensions(dc.EnvoyExtensions)\n\n\t\t\tmeta := uid.EnterpriseMeta\n\t\t\tsni := connect.ServiceSNI(uid.Name, \"\", meta.NamespaceOrDefault(), meta.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\toutgoingKind, ok := outgoingKindByService[compoundServiceName]\n\t\t\tif !ok {\n\t\t\t\toutgoingKind = api.ServiceKindConnectProxy\n\t\t\t}\n\n\t\t\tupstreamMap[compoundServiceName] = &extensioncommon.UpstreamData{\n\t\t\t\tSNI:               map[string]struct{}{sni: {}},\n\t\t\t\tVIP:               vipForService[compoundServiceName],\n\t\t\t\tEnvoyID:           uid.EnvoyID(),\n\t\t\t\tOutgoingProxyKind: outgoingKind,\n\t\t\t}\n\t\t}\n\t\t// Adds extensions configured for the local service to the RuntimeConfig. This only applies to\n\t\t// connect-proxies because extensions are either global or tied to a specific service, so the terminating\n\t\t// gateway's Envoy resources for the local service (i.e not to upstreams) would never need to be modified.\n\t\tlocalSvc := api.CompoundServiceName{\n\t\t\tName:      cfgSnap.Proxy.DestinationServiceName,\n\t\t\tNamespace: cfgSnap.ProxyID.NamespaceOrDefault(),\n\t\t\tPartition: cfgSnap.ProxyID.PartitionOrEmpty(),\n\t\t}\n\t\textensionConfigurationsMap[localSvc] = []extensioncommon.RuntimeConfig{}\n\t\tcfgSnapExts := convertEnvoyExtensions(cfgSnap.Proxy.EnvoyExtensions)\n\t\tfor _, ext := range cfgSnapExts {\n\t\t\textCfg := extensioncommon.RuntimeConfig{\n\t\t\t\tEnvoyExtension: ext,\n\t\t\t\tServiceName:    localSvc,\n\t\t\t\t// Upstreams is nil to signify this extension is not being applied to an upstream service, but rather to the local service.\n\t\t\t\tUpstreams:      nil,\n\t\t\t\tLocalUpstreams: upstreamMap,\n\t\t\t\tKind:           kind,\n\t\t\t\tProtocol:       proxyConfigProtocol(cfgSnap.Proxy.Config),\n\t\t\t}\n\t\t\textensionConfigurationsMap[localSvc] = append(extensionConfigurationsMap[localSvc], extCfg)\n\t\t}\n\tcase structs.ServiceKindTerminatingGateway:\n\t\tkind = api.ServiceKindTerminatingGateway\n\t\tfor svc, c := range cfgSnap.TerminatingGateway.ServiceConfigs {\n\t\t\tcompoundServiceName := serviceNameToCompoundServiceName(svc)\n\t\t\textensionsMap[compoundServiceName] = convertEnvoyExtensions(c.EnvoyExtensions)\n\n\t\t\tsni := connect.ServiceSNI(svc.Name, \"\", svc.NamespaceOrDefault(), svc.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\tenvoyID := proxycfg.NewUpstreamIDFromServiceName(svc)\n\n\t\t\tsnis := map[string]struct{}{sni: {}}\n\n\t\t\tresolver, hasResolver := cfgSnap.TerminatingGateway.ServiceResolvers[svc]\n\t\t\tif hasResolver {\n\t\t\t\tfor subsetName := range resolver.Subsets {\n\t\t\t\t\tsni := connect.ServiceSNI(svc.Name, subsetName, svc.NamespaceOrDefault(), svc.PartitionOrDefault(), cfgSnap.Datacenter, trustDomain)\n\t\t\t\t\tsnis[sni] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tupstreamMap[compoundServiceName] = &extensioncommon.UpstreamData{\n\t\t\t\tSNI:               snis,\n\t\t\t\tEnvoyID:           envoyID.EnvoyID(),\n\t\t\t\tOutgoingProxyKind: api.ServiceKindTerminatingGateway,\n\t\t\t}\n\n\t\t}\n\t}\n\n\tfor svc, exts := range extensionsMap {\n\t\textensionConfigurationsMap[svc] = []extensioncommon.RuntimeConfig{}\n\t\tfor _, ext := range exts {\n\t\t\textCfg := extensioncommon.RuntimeConfig{\n\t\t\t\tEnvoyExtension: ext,\n\t\t\t\tKind:           kind,\n\t\t\t\tServiceName:    svc,\n\t\t\t\tUpstreams:      upstreamMap,\n\t\t\t\tProtocol:       proxyConfigProtocol(cfgSnap.Proxy.Config),\n\t\t\t}\n\t\t\textensionConfigurationsMap[svc] = append(extensionConfigurationsMap[svc], extCfg)\n\t\t}\n\t}\n\n\treturn extensionConfigurationsMap\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) Msf(ctx context.Context, in *clientpb.MSFReq, opts ...grpc.CallOption) (*sliverpb.Task, error) {\n\tout := new(sliverpb.Task)\n\terr := c.cc.Invoke(ctx, SliverRPC_Msf_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func MakeEmailPrimary(email *EmailAddress) error {\n\thas, err := x.Get(email)\n\tif err != nil {\n\t\treturn err\n\t} else if !has {\n\t\treturn errors.EmailNotFound{Email: email.Email}\n\t}\n\n\tif !email.IsActivated {\n\t\treturn errors.EmailNotVerified{Email: email.Email}\n\t}\n\n\tuser := &User{ID: email.UID}\n\thas, err = x.Get(user)\n\tif err != nil {\n\t\treturn err\n\t} else if !has {\n\t\treturn errors.UserNotExist{UserID: email.UID}\n\t}\n\n\t// Make sure the former primary email doesn't disappear.\n\tformerPrimaryEmail := &EmailAddress{Email: user.Email}\n\thas, err = x.Get(formerPrimaryEmail)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tsess := x.NewSession()\n\tdefer sess.Close()\n\tif err = sess.Begin(); err != nil {\n\t\treturn err\n\t}\n\n\tif !has {\n\t\tformerPrimaryEmail.UID = user.ID\n\t\tformerPrimaryEmail.IsActivated = user.IsActive\n\t\tif _, err = sess.Insert(formerPrimaryEmail); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tuser.Email = email.Email\n\tif _, err = sess.ID(user.ID).AllCols().Update(user); err != nil {\n\t\treturn err\n\t}\n\n\treturn sess.Commit()\n}", "is_vulnerable": 1}
{"code": "func evalAndValidateSymlink(c Container, path string) (symlinkInfo, error) {\n\tpathTokens := strings.Split(path, string(os.PathSeparator))\n\t// check if meta directory is a symlink\n\tif len(pathTokens) == 1 && pathTokens[0] == \"meta\" {\n\t\treturn symlinkInfo{}, fmt.Errorf(\"meta directory cannot be a symlink\")\n\t}\n\n\tinfo, err := evalSymlink(c, path)\n\tif err != nil {\n\t\treturn symlinkInfo{}, err\n\t}\n\n\tif info.isExternal {\n\t\treturn symlinkInfo{}, fmt.Errorf(\"external symlink found: %s -> %s\", path, info.naiveTarget)\n\t}\n\n\t// symlinks like this don't look innocent\n\tbadTargets := []string{\".\", \"meta\"}\n\tfor _, badTarget := range badTargets {\n\t\tif info.target == badTarget {\n\t\t\treturn symlinkInfo{}, fmt.Errorf(\"bad symlink found: %s -> %s\", path, info.naiveTarget)\n\t\t}\n\t}\n\n\treturn info, nil\n}", "is_vulnerable": 0}
{"code": "func (fs *fileStat) Sys() any           { return &fs.sys }", "is_vulnerable": 0}
{"code": "func findObjectStorage(ctx context.Context, dataStore *store.Store) (*s3.Client, error) {\n\tworkspaceStorageSetting, err := dataStore.GetWorkspaceStorageSetting(ctx)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Failed to find workspaceStorageSetting\")\n\t}\n\tif workspaceStorageSetting.StorageType != storepb.WorkspaceStorageSetting_STORAGE_TYPE_EXTERNAL || workspaceStorageSetting.ActivedExternalStorageId == nil {\n\t\treturn nil, nil\n\t}\n\tstorage, err := dataStore.GetStorageV1(ctx, &store.FindStorage{ID: workspaceStorageSetting.ActivedExternalStorageId})\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Failed to find storage\")\n\t}\n\tif storage == nil {\n\t\treturn nil, nil\n\t}\n\n\tstorageMessage := apiv2.ConvertStorageFromStore(storage)\n\tif storageMessage.Type != apiv2pb.Storage_S3 {\n\t\treturn nil, nil\n\t}\n\n\ts3Config := storageMessage.Config.GetS3Config()\n\treturn s3.NewClient(ctx, &s3.Config{\n\t\tAccessKey: s3Config.AccessKey,\n\t\tSecretKey: s3Config.SecretKey,\n\t\tEndPoint:  s3Config.EndPoint,\n\t\tRegion:    s3Config.Region,\n\t\tBucket:    s3Config.Bucket,\n\t\tURLPrefix: s3Config.UrlPrefix,\n\t\tURLSuffix: s3Config.UrlSuffix,\n\t\tPreSign:   s3Config.PreSign,\n\t})\n}", "is_vulnerable": 0}
{"code": "func (s *Server) updateLocalACLPolicies(policies structs.ACLPolicies, ctx context.Context) (bool, error) {\n\tticker := time.NewTicker(time.Second / time.Duration(s.config.ACLReplicationApplyLimit))\n\tdefer ticker.Stop()\n\n\t// outer loop handles submitting a batch\n\tfor batchStart := 0; batchStart < len(policies); {\n\t\t// inner loop finds the last element to include in this batch.\n\t\tbatchSize := 0\n\t\tbatchEnd := batchStart\n\t\tfor ; batchEnd < len(policies) && batchSize < aclBatchUpsertSize; batchEnd += 1 {\n\t\t\tbatchSize += policies[batchEnd].EstimateSize()\n\t\t}\n\n\t\treq := structs.ACLPolicyBatchSetRequest{\n\t\t\tPolicies: policies[batchStart:batchEnd],\n\t\t}\n\n\t\tresp, err := s.raftApply(structs.ACLPolicySetRequestType, &req)\n\t\tif err != nil {\n\t\t\treturn false, fmt.Errorf(\"Failed to apply policy upserts: %v\", err)\n\t\t}\n\t\tif respErr, ok := resp.(error); ok && err != nil {\n\t\t\treturn false, fmt.Errorf(\"Failed to apply policy upsert: %v\", respErr)\n\t\t}\n\t\ts.logger.Printf(\"[DEBUG] acl: policy replication - upserted 1 batch with %d policies of size %d\", batchEnd-batchStart, batchSize)\n\n\t\t// policies[batchEnd] wasn't include as the slicing doesn't include the element at the stop index\n\t\tbatchStart = batchEnd\n\n\t\t// prevent waiting if we are done\n\t\tif batchEnd < len(policies) {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn true, nil\n\t\t\tcase <-ticker.C:\n\t\t\t\t// nothing to do - just rate limiting\n\t\t\t}\n\t\t}\n\t}\n\treturn false, nil\n}", "is_vulnerable": 1}
{"code": "func TestListNodeExecutions_Order(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`execution_project desc`)\n\tmockQuery.WithReply(nodeExecutions)\n\n\tsortParameter, err := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"execution_project\",\n\t}, models.NodeExecutionColumns)\n\trequire.NoError(t, err)\n\n\t_, err = nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}", "is_vulnerable": 0}
{"code": "func (iter *ProviderListResultIterator) Next() error {\n\treturn iter.NextWithContext(context.Background())\n}", "is_vulnerable": 0}
{"code": "func (r Resource) MarshalJSON() ([]byte, error) {\n\tobjectMap := make(map[string]interface{})\n\tif r.ID != nil {\n\t\tobjectMap[\"id\"] = r.ID\n\t}\n\tif r.Name != nil {\n\t\tobjectMap[\"name\"] = r.Name\n\t}\n\tif r.Type != nil {\n\t\tobjectMap[\"type\"] = r.Type\n\t}\n\tif r.Location != nil {\n\t\tobjectMap[\"location\"] = r.Location\n\t}\n\tif r.Tags != nil {\n\t\tobjectMap[\"tags\"] = r.Tags\n\t}\n\treturn json.Marshal(objectMap)\n}", "is_vulnerable": 1}
{"code": "func (c *CookieHandler) httpSetWithSameSite(w http.ResponseWriter, name, host, value string, maxAge int, sameSite http.SameSite) {\n\tdomain := strings.Split(host, \":\")[0]\n\t// same site none requires the secure flag, so we'll set it even if the cookie is set on non-TLS for localhost\n\tsecure := c.secureOnly || (sameSite == http.SameSiteNoneMode && domain == \"localhost\")\n\t// prefix the cookie for secure cookies (TLS only, therefore not for samesite none on http://localhost)\n\tprefixedName := SetCookiePrefix(name, c.secureOnly, c.prefix)\n\t// in case the host prefix is set, we need to make sure the domain is not set (otherwise the browser will reject the cookie)\n\tif secure && c.prefix == PrefixHost {\n\t\tdomain = \"\"\n\t}\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     prefixedName,\n\t\tValue:    value,\n\t\tDomain:   domain,\n\t\tPath:     c.path,\n\t\tMaxAge:   maxAge,\n\t\tHttpOnly: c.httpOnly,\n\t\tSecure:   secure,\n\t\tSameSite: sameSite,\n\t})\n\tvaryValues := w.Header().Values(\"vary\")\n\tfor _, vary := range varyValues {\n\t\tif vary == \"Cookie\" {\n\t\t\treturn\n\t\t}\n\t}\n\tw.Header().Add(\"vary\", \"Cookie\")\n}", "is_vulnerable": 0}
{"code": "func (a ipallowlist) Parse(ing *networking.Ingress) (interface{}, error) {", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) MsfRemote(ctx context.Context, in *clientpb.MSFRemoteReq, opts ...grpc.CallOption) (*sliverpb.Task, error) {\n\tout := new(sliverpb.Task)\n\terr := c.cc.Invoke(ctx, SliverRPC_MsfRemote_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func NewSyscallError(syscall string, err error) error {\n\treturn os.NewSyscallError(syscall, err)\n}", "is_vulnerable": 0}
{"code": "func (a *Actions) AddSource(repo string) *Actions {\n\ta.runCli(\"proj\", \"add-source\", a.context.name, repo)\n\treturn a\n}", "is_vulnerable": 0}
{"code": "func (a servicePrincipalClientSecretAuth) populateConfig(c *Config) error {\n\tc.AuthenticatedAsAServicePrincipal = true\n\tc.GetAuthenticatedObjectID = buildServicePrincipalObjectIDFunc(c)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestGetSeccompProfileDefaultSeccomp(t *testing.T) {\n\t_, _, m, err := createTestRuntimeManager()\n\trequire.NoError(t, err)\n\n\tunconfinedProfile := &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t}\n\n\truntimeDefaultProfile := &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t}\n\n\ttests := []struct {\n\t\tdescription     string\n\t\tannotation      map[string]string\n\t\tpodSc           *v1.PodSecurityContext\n\t\tcontainerSc     *v1.SecurityContext\n\t\tcontainerName   string\n\t\texpectedProfile *runtimeapi.SecurityProfile\n\t\texpectedError   string\n\t}{\n\t\t{\n\t\t\tdescription:     \"no seccomp should return RuntimeDefault\",\n\t\t\texpectedProfile: runtimeDefaultProfile,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"pod seccomp profile set to unconfined returns unconfined\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\texpectedProfile: unconfinedProfile,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"container seccomp profile set to unconfined returns unconfined\",\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\texpectedProfile: unconfinedProfile,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"pod seccomp profile set to SeccompProfileTypeRuntimeDefault returns runtime/default\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: runtimeDefaultProfile,\n\t\t},\n\t\t{\n\t\t\tdescription:     \"container seccomp profile set to SeccompProfileTypeRuntimeDefault returns runtime/default\",\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: runtimeDefaultProfile,\n\t\t},\n\t\t{\n\t\t\tdescription: \"pod seccomp profile set to SeccompProfileTypeLocalhost returns 'localhost/' + LocalhostProfile\",\n\t\t\tpodSc:       &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"filename\")}},\n\t\t\texpectedProfile: &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType:  runtimeapi.SecurityProfile_Localhost,\n\t\t\t\tLocalhostRef: seccompLocalhostRef(\"filename\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdescription:   \"pod seccomp profile set to SeccompProfileTypeLocalhost with empty LocalhostProfile returns error\",\n\t\t\tpodSc:         &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost}},\n\t\t\texpectedError: \"localhostProfile must be set if seccompProfile type is Localhost.\",\n\t\t},\n\t\t{\n\t\t\tdescription:   \"container seccomp profile set to SeccompProfileTypeLocalhost with empty LocalhostProfile returns error\",\n\t\t\tcontainerSc:   &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost}},\n\t\t\texpectedError: \"localhostProfile must be set if seccompProfile type is Localhost.\",\n\t\t},\n\t\t{\n\t\t\tdescription: \"container seccomp profile set to SeccompProfileTypeLocalhost returns 'localhost/' + LocalhostProfile\",\n\t\t\tcontainerSc: &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"filename2\")}},\n\t\t\texpectedProfile: &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType:  runtimeapi.SecurityProfile_Localhost,\n\t\t\t\tLocalhostRef: seccompLocalhostRef(\"filename2\"),\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tdescription:     \"prioritise container field over pod field\",\n\t\t\tpodSc:           &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeUnconfined}},\n\t\t\tcontainerSc:     &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeRuntimeDefault}},\n\t\t\texpectedProfile: runtimeDefaultProfile,\n\t\t},\n\t\t{\n\t\t\tdescription:   \"prioritise container field over pod field\",\n\t\t\tpodSc:         &v1.PodSecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"field-pod-profile.json\")}},\n\t\t\tcontainerSc:   &v1.SecurityContext{SeccompProfile: &v1.SeccompProfile{Type: v1.SeccompProfileTypeLocalhost, LocalhostProfile: getLocal(\"field-cont-profile.json\")}},\n\t\t\tcontainerName: \"container1\",\n\t\t\texpectedProfile: &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType:  runtimeapi.SecurityProfile_Localhost,\n\t\t\t\tLocalhostRef: seccompLocalhostRef(\"field-cont-profile.json\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tseccompProfile, err := m.getSeccompProfile(test.annotation, test.containerName, test.podSc, test.containerSc, true)\n\t\tif test.expectedError != \"\" {\n\t\t\tassert.EqualError(t, err, test.expectedError, \"TestCase[%d]: %s\", i, test.description)\n\t\t} else {\n\t\t\tassert.NoError(t, err, \"TestCase[%d]: %s\", i, test.description)\n\t\t\tassert.Equal(t, test.expectedProfile, seccompProfile, \"TestCase[%d]: %s\", i, test.description)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestRetryableAuth(t *testing.T) {\n\tn := 0\n\tpasswords := []string{\"WRONG1\", \"WRONG2\"}\n\n\tconfig := &ClientConfig{\n\t\tUser: \"testuser\",\n\t\tAuth: []AuthMethod{\n\t\t\tRetryableAuthMethod(PasswordCallback(func() (string, error) {\n\t\t\t\tp := passwords[n]\n\t\t\t\tn++\n\t\t\t\treturn p, nil\n\t\t\t}), 2),\n\t\t\tPublicKeys(testSigners[\"rsa\"]),\n\t\t},\n\t\tHostKeyCallback: InsecureIgnoreHostKey(),\n\t}\n\n\tif err := tryAuth(t, config); err != nil {\n\t\tt.Fatalf(\"unable to dial remote side: %s\", err)\n\t}\n\tif n != 2 {\n\t\tt.Fatalf(\"Did not try all passwords\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func isRepositoryGitPath(path string) bool {\n\tpath = strings.ToLower(path)\n\treturn strings.HasSuffix(path, \".git\") ||\n\t\tstrings.Contains(path, \".git/\") ||\n\t\tstrings.Contains(path, `.git\\`) ||\n\t\t// Windows treats \".git.\" the same as \".git\"\n\t\tstrings.HasSuffix(path, \".git.\") ||\n\t\tstrings.Contains(path, \".git./\") ||\n\t\tstrings.Contains(path, `.git.\\`)\n}", "is_vulnerable": 0}
{"code": "func withDatastoreCursorInCursor(\n\tci cursorInformation,\n\tname string,\n\thandler func(queryCursor options.Cursor, ci cursorInformation) (options.Cursor, error),\n) error {\n\t// Retrieve the *datastore* cursor, if one is found at the head of the incoming cursor.\n\tvar datastoreCursor options.Cursor\n\tdatastoreCursorString, err := ci.sectionValue(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif datastoreCursorString != \"\" {\n\t\tdatastoreCursor = tuple.MustParse(datastoreCursorString)\n\t}\n\n\t// Execute the loop, starting at the datastore's cursor (if any), until there is no additional\n\t// datastore cursor returned.\n\tisFirstIteration := true\n\tfor {\n\t\tif ci.limits.hasExhaustedLimit() {\n\t\t\treturn nil\n\t\t}\n\n\t\tcurrentCursor, err := ci.withOutgoingSection(name, tuple.MustString(datastoreCursor))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !isFirstIteration {\n\t\t\tcurrentCursor = currentCursor.clearIncoming()\n\t\t}\n\n\t\tnextDCCursor, err := handler(datastoreCursor, currentCursor)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif nextDCCursor == nil {\n\t\t\treturn nil\n\t\t}\n\t\tdatastoreCursor = nextDCCursor\n\t\tisFirstIteration = false\n\t}\n}", "is_vulnerable": 1}
{"code": "func (g *HgGetter) Get(ctx context.Context, req *Request) error {\n\tif _, err := exec.LookPath(\"hg\"); err != nil {\n\t\treturn fmt.Errorf(\"hg must be available and on the PATH\")\n\t}\n\n\tnewURL, err := urlhelper.Parse(req.u.String())\n\tif err != nil {\n\t\treturn err\n\t}\n\tif fixWindowsDrivePath(newURL) {\n\t\t// See valid file path form on http://www.selenic.com/hg/help/urls\n\t\tnewURL.Path = fmt.Sprintf(\"/%s\", newURL.Path)\n\t}\n\n\t// Extract some query parameters we use\n\tvar rev string\n\tq := newURL.Query()\n\tif len(q) > 0 {\n\t\trev = q.Get(\"rev\")\n\t\tq.Del(\"rev\")\n\n\t\tnewURL.RawQuery = q.Encode()\n\t}\n\n\t_, err = os.Stat(req.Dst)\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn err\n\t}\n\tif err != nil {\n\t\tif err := g.clone(req.Dst, newURL); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := g.pull(req.Dst, newURL); err != nil {\n\t\treturn err\n\t}\n\n\treturn g.update(ctx, req.Dst, newURL, rev)\n}", "is_vulnerable": 1}
{"code": "func (s *PrecompileTestSuite) NextBlockAfter(t time.Duration) {\n\tvar err error\n\ts.ctx, err = evmosutil.CommitAndCreateNewCtx(s.ctx, s.app, t, nil)\n\tExpect(err).To(BeNil(), \"failed to commit block\")\n}", "is_vulnerable": 0}
{"code": "func NewApiPluginProxy(ctx *models.ReqContext, proxyPath string, route *plugins.Route,\n\tappID string, cfg *setting.Cfg, store sqlstore.Store, secretsService secrets.Service) *httputil.ReverseProxy {\n\tdirector := func(req *http.Request) {\n\t\tquery := models.GetPluginSettingByIdQuery{OrgId: ctx.OrgId, PluginId: appID}\n\t\tif err := store.GetPluginSettingById(ctx.Req.Context(), &query); err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to fetch plugin settings\", err)\n\t\t\treturn\n\t\t}\n\n\t\tsecureJsonData, err := secretsService.DecryptJsonData(ctx.Req.Context(), query.Result.SecureJsonData)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to decrypt plugin settings\", err)\n\t\t\treturn\n\t\t}\n\n\t\tdata := templateData{\n\t\t\tJsonData:       query.Result.JsonData,\n\t\t\tSecureJsonData: secureJsonData,\n\t\t}\n\n\t\tinterpolatedURL, err := interpolateString(route.URL, data)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Could not interpolate plugin route url\", err)\n\t\t\treturn\n\t\t}\n\t\ttargetURL, err := url.Parse(interpolatedURL)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"Could not parse url\", err)\n\t\t\treturn\n\t\t}\n\t\treq.URL.Scheme = targetURL.Scheme\n\t\treq.URL.Host = targetURL.Host\n\t\treq.Host = targetURL.Host\n\t\treq.URL.Path = util.JoinURLFragments(targetURL.Path, proxyPath)\n\n\t\t// clear cookie headers\n\t\treq.Header.Del(\"Cookie\")\n\t\treq.Header.Del(\"Set-Cookie\")\n\n\t\tproxyutil.PrepareProxyRequest(req)\n\n\t\t// Create a HTTP header with the context in it.\n\t\tctxJSON, err := json.Marshal(ctx.SignedInUser)\n\t\tif err != nil {\n\t\t\tctx.JsonApiErr(500, \"failed to marshal context to json.\", err)\n\t\t\treturn\n\t\t}\n\n\t\treq.Header.Set(\"X-Grafana-Context\", string(ctxJSON))\n\n\t\tapplyUserHeader(cfg.SendUserHeader, req, ctx.SignedInUser)\n\n\t\tif err := addHeaders(&req.Header, route, data); err != nil {\n\t\t\tctx.JsonApiErr(500, \"Failed to render plugin headers\", err)\n\t\t\treturn\n\t\t}\n\n\t\tif err := setBodyContent(req, route, data); err != nil {\n\t\t\tlogger.Error(\"Failed to set plugin route body content\", \"error\", err)\n\t\t}\n\t}\n\n\treturn &httputil.ReverseProxy{Director: director}\n}", "is_vulnerable": 1}
{"code": "func (c *contextDialer) startDialerPod(ctx context.Context) (err error) {\n\tcliConf := GetClientConfig()\n\tc.restConf, err = cliConf.ClientConfig()\n\tif err != nil {\n\t\treturn\n\t}\n\tc.restConf.WarningHandler = restclient.NoWarnings{}\n\n\terr = setConfigDefaults(c.restConf)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tclient, err := kubernetes.NewForConfig(c.restConf)\n\tif err != nil {\n\t\treturn\n\t}\n\tc.coreV1 = client.CoreV1()\n\n\tc.namespace, err = GetNamespace(\"\")\n\tif err != nil {\n\t\treturn\n\t}\n\n\tpods := client.CoreV1().Pods(c.namespace)\n\n\tc.podName = \"in-cluster-dialer-\" + rand.String(5)\n\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tc.Close()\n\t\t}\n\t}()\n\n\tpod := &coreV1.Pod{\n\t\tObjectMeta: metaV1.ObjectMeta{\n\t\t\tName:        c.podName,\n\t\t\tLabels:      nil,\n\t\t\tAnnotations: nil,\n\t\t},\n\t\tSpec: coreV1.PodSpec{\n\t\t\tContainers: []coreV1.Container{\n\t\t\t\t{\n\t\t\t\t\tName:            c.podName,\n\t\t\t\t\tImage:           SocatImage,\n\t\t\t\t\tStdin:           true,\n\t\t\t\t\tStdinOnce:       true,\n\t\t\t\t\tCommand:         []string{\"socat\", \"-u\", \"-\", \"OPEN:/dev/null\"},\n\t\t\t\t\tSecurityContext: defaultSecurityContext(),\n\t\t\t\t},\n\t\t\t},\n\t\t\tDNSPolicy:     coreV1.DNSClusterFirst,\n\t\t\tRestartPolicy: coreV1.RestartPolicyNever,\n\t\t},\n\t}\n\tcreatOpts := metaV1.CreateOptions{}\n\n\tready := podReady(ctx, c.coreV1, c.podName, c.namespace)\n\n\t_, err = pods.Create(ctx, pod, creatOpts)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tselect {\n\tcase err = <-ready:\n\tcase <-ctx.Done():\n\t\terr = ctx.Err()\n\tcase <-time.After(time.Minute * 1):\n\t\terr = errors.New(\"timeout\")\n\t}\n\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to start dialer container: %w\", err)\n\t}\n\n\t// attaching to the stdin to automatically Complete the pod on exit\n\tgo func() {\n\t\t_ = attach(c.coreV1.RESTClient(), c.restConf, c.podName, c.namespace, emptyBlockingReader(c.detachChan), io.Discard, io.Discard)\n\t}()\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestGuaranteedUpdate(t *testing.T) {\n\tctx, store, etcdClient := testSetup(t)\n\tstoragetesting.RunTestGuaranteedUpdate(ctx, t, &storeWithPrefixTransformer{store}, checkStorageInvariants(etcdClient, store.codec))\n}", "is_vulnerable": 0}
{"code": "func (m *Foo) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Num1 = append(m.Num1, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Num1) == 0 {\n\t\t\t\t\tm.Num1 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Num1 = append(m.Num1, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Num1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Num2 = append(m.Num2, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Num2) == 0 {\n\t\t\t\t\tm.Num2 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Num2 = append(m.Num2, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Num2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Str1\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Str1 = append(m.Str1, string(dAtA[iNdEx:postIndex]))\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Dat1\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue503\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Dat1 = append(m.Dat1, make([]byte, postIndex-iNdEx))\n\t\t\tcopy(m.Dat1[len(m.Dat1)-1], dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue503(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue503\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (fs *UnixFS) modeTypeFromDirent(fd int, de *unix.Dirent, osDirname, osBasename string) (FileMode, error) {\n\tswitch de.Type {\n\tcase unix.DT_REG:\n\t\treturn 0, nil\n\tcase unix.DT_DIR:\n\t\treturn ModeDir, nil\n\tcase unix.DT_LNK:\n\t\treturn ModeSymlink, nil\n\tcase unix.DT_CHR:\n\t\treturn ModeDevice | ModeCharDevice, nil\n\tcase unix.DT_BLK:\n\t\treturn ModeDevice, nil\n\tcase unix.DT_FIFO:\n\t\treturn ModeNamedPipe, nil\n\tcase unix.DT_SOCK:\n\t\treturn ModeSocket, nil\n\tdefault:\n\t\t// If syscall returned unknown type (e.g., DT_UNKNOWN, DT_WHT), then\n\t\t// resolve actual mode by reading file information.\n\t\treturn fs.modeType(fd, filepath.Join(osDirname, osBasename))\n\t}\n}", "is_vulnerable": 0}
{"code": "func getTeamSearchSQLBase(filteredUsers []string) string {\n\treturn `SELECT\n\t\tteam.id AS id,\n\t\tteam.org_id,\n\t\tteam.name AS name,\n\t\tteam.email AS email,\n\t\tteam_member.permission, ` +\n\t\tgetTeamMemberCount(filteredUsers) +\n\t\t` FROM team AS team\n\t\tINNER JOIN team_member ON team.id = team_member.team_id AND team_member.user_id = ? `\n}", "is_vulnerable": 1}
{"code": "func Version() string {\n\treturn version.Number\n}", "is_vulnerable": 1}
{"code": "func (m *OrBranch) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: OrBranch: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: OrBranch: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Left\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Left.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Right\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Right.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) updateCachedDiskUsage() (int64, error) {\n\t// Obtain an exclusive lock on this process so that we don't unintentionally run it at the same\n\t// time as another running process. Once the lock is available it'll read from the cache for the\n\t// second call rather than hitting the disk in parallel.\n\tfs.mu.Lock()\n\tdefer fs.mu.Unlock()\n\n\t// Signal that we're currently updating the disk size so that other calls to the disk checking\n\t// functions can determine if they should queue up additional calls to this function. Ensure that\n\t// we always set this back to \"false\" when this process is done executing.\n\tfs.lookupInProgress.Store(true)\n\tdefer fs.lookupInProgress.Store(false)\n\n\t// If there is no size its either because there is no data (in which case running this function\n\t// will have effectively no impact), or there is nothing in the cache, in which case we need to\n\t// grab the size of their data directory. This is a taxing operation, so we want to store it in\n\t// the cache once we've gotten it.\n\tsize, err := fs.DirectorySize(\"/\")\n\n\t// Always cache the size, even if there is an error. We want to always return that value\n\t// so that we don't cause an endless loop of determining the disk size if there is a temporary\n\t// error encountered.\n\tfs.lastLookupTime.Set(time.Now())\n\n\tatomic.StoreInt64(&fs.diskUsed, size)\n\n\treturn size, err\n}", "is_vulnerable": 1}
{"code": "func (s *X11InterfaceSuite) TestAppArmorSpec(c *C) {\n\t// case A: x11 slot is provided by the classic system\n\trestore := release.MockOnClassic(true)\n\tdefer restore()\n\n\t// Plug side connection permissions\n\tspec := &apparmor.Specification{}\n\tc.Assert(spec.AddConnectedPlug(s.iface, s.plug, s.classicSlot), IsNil)\n\tc.Assert(spec.SecurityTags(), DeepEquals, []string{\"snap.consumer.app\"})\n\tc.Assert(spec.SnippetForTag(\"snap.consumer.app\"), testutil.Contains, \"fontconfig\")\n\tc.Assert(spec.UpdateNS(), HasLen, 1)\n\tc.Assert(spec.UpdateNS()[0], testutil.Contains, `mount options=(rw, bind) /var/lib/snapd/hostfs/tmp/.X11-unix/ -> /tmp/.X11-unix/,`)\n\n\t// case B: x11 slot is provided by another snap on the system\n\trestore = release.MockOnClassic(false)\n\tdefer restore()\n\n\t// Plug side connection permissions\n\tspec = &apparmor.Specification{}\n\tc.Assert(spec.AddConnectedPlug(s.iface, s.plug, s.coreSlot), IsNil)\n\tc.Assert(spec.SecurityTags(), DeepEquals, []string{\"snap.consumer.app\"})\n\tc.Assert(spec.SnippetForTag(\"snap.consumer.app\"), testutil.Contains, \"fontconfig\")\n\tc.Assert(spec.UpdateNS(), HasLen, 1)\n\tc.Assert(spec.UpdateNS()[0], testutil.Contains, `mount options=(rw, bind) /var/lib/snapd/hostfs/tmp/snap-private-tmp/snap.x11/tmp/.X11-unix/ -> /tmp/.X11-unix/,`)\n\n\t// Slot side connection permissions\n\tspec = &apparmor.Specification{}\n\tc.Assert(spec.AddConnectedSlot(s.iface, s.plug, s.coreSlot), IsNil)\n\tc.Assert(spec.SecurityTags(), DeepEquals, []string{\"snap.x11.app\"})\n\tc.Assert(spec.SnippetForTag(\"snap.x11.app\"), testutil.Contains, `peer=(label=\"snap.consumer.app\"),`)\n\tc.Assert(spec.UpdateNS(), HasLen, 0)\n\n\t// Slot side permantent permissions\n\tspec = &apparmor.Specification{}\n\tc.Assert(spec.AddPermanentSlot(s.iface, s.coreSlotInfo), IsNil)\n\tc.Assert(spec.SecurityTags(), DeepEquals, []string{\"snap.x11.app\"})\n\tc.Assert(spec.SnippetForTag(\"snap.x11.app\"), testutil.Contains, \"capability sys_tty_config,\")\n\tc.Assert(spec.UpdateNS(), HasLen, 0)\n\n\t// case C: x11 slot is both provided and consumed by a snap on the system.\n\tspec = &apparmor.Specification{}\n\tc.Assert(spec.AddConnectedPlug(s.iface, s.corePlug, s.coreSlot), IsNil)\n\tc.Assert(spec.SecurityTags(), DeepEquals, []string{\"snap.x11.app\"})\n\tc.Assert(spec.SnippetForTag(\"snap.x11.app\"), testutil.Contains, \"fontconfig\")\n\t// Self-connection does not need bind mounts, so no additional permissions are provided to snap-update-ns.\n\tc.Assert(spec.UpdateNS(), HasLen, 0)\n}", "is_vulnerable": 0}
{"code": "func NewSeriesStatsAggregatorFactory(\n\treg prometheus.Registerer,\n\tdurationQuantiles []float64,\n\tsampleQuantiles []float64,\n\tseriesQuantiles []float64,\n) *seriesStatsAggregatorFactory {\n\treturn &seriesStatsAggregatorFactory{\n\t\tqueryDuration: promauto.With(reg).NewHistogramVec(prometheus.HistogramOpts{\n\t\t\tName:    \"thanos_store_api_query_duration_seconds\",\n\t\t\tHelp:    \"Duration of the Thanos Store API select phase for a query.\",\n\t\t\tBuckets: durationQuantiles,\n\t\t}, []string{\"series_le\", \"samples_le\"}),\n\t\tseriesLeBuckets:  seriesQuantiles,\n\t\tsamplesLeBuckets: sampleQuantiles,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (clh *cloudHypervisor) createSandbox(ctx context.Context, id string, networkNS NetworkNamespace, hypervisorConfig *HypervisorConfig, stateful bool) error {\n\tclh.ctx = ctx\n\n\tspan, _ := clh.trace(\"createSandbox\")\n\tdefer span.Finish()\n\n\terr := hypervisorConfig.valid()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tclh.id = id\n\tclh.config = *hypervisorConfig\n\tclh.state.state = clhNotReady\n\n\t// version check only applicable to 'cloud-hypervisor' executable\n\tclhPath, perr := clh.clhPath()\n\tif perr != nil {\n\t\treturn perr\n\n\t}\n\tif strings.HasSuffix(clhPath, \"cloud-hypervisor\") {\n\t\terr = clh.getAvailableVersion()\n\t\tif err != nil {\n\t\t\treturn err\n\n\t\t}\n\n\t\tif err := clh.checkVersion(); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t}\n\n\tclh.Logger().WithField(\"function\", \"createSandbox\").Info(\"creating Sandbox\")\n\n\tvirtiofsdSocketPath, err := clh.virtioFsSocketPath(clh.id)\n\tif err != nil {\n\t\treturn nil\n\n\t}\n\n\tif clh.state.PID > 0 {\n\t\tclh.Logger().WithField(\"function\", \"createSandbox\").Info(\"Sandbox already exist, loading from state\")\n\t\tclh.virtiofsd = &virtiofsd{\n\t\t\tPID:        clh.state.VirtiofsdPID,\n\t\t\tsourcePath: filepath.Join(kataHostSharedDir(), clh.id),\n\t\t\tdebug:      clh.config.Debug,\n\t\t\tsocketPath: virtiofsdSocketPath,\n\t\t}\n\t\treturn nil\n\t}\n\n\t// No need to return an error from there since there might be nothing\n\t// to fetch if this is the first time the hypervisor is created.\n\tclh.Logger().WithField(\"function\", \"createSandbox\").WithError(err).Info(\"Sandbox not found creating \")\n\n\t// Set initial memomory size of the virtual machine\n\t// Convert to int64 openApiClient only support int64\n\tclh.vmconfig.Memory.Size = int64((utils.MemUnit(clh.config.MemorySize) * utils.MiB).ToBytes())\n\tclh.vmconfig.Memory.File = \"/dev/shm\"\n\t// shared memory should be enabled if using vhost-user(kata uses virtiofsd)\n\tclh.vmconfig.Memory.Shared = true\n\thostMemKb, err := getHostMemorySizeKb(procMemInfo)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\t// OpenAPI only supports int64 values\n\tclh.vmconfig.Memory.HotplugSize = int64((utils.MemUnit(hostMemKb) * utils.KiB).ToBytes())\n\t// Set initial amount of cpu's for the virtual machine\n\tclh.vmconfig.Cpus = chclient.CpusConfig{\n\t\t// cast to int32, as openAPI has a limitation that it does not support unsigned values\n\t\tBootVcpus: int32(clh.config.NumVCPUs),\n\t\tMaxVcpus:  int32(clh.config.DefaultMaxVCPUs),\n\t}\n\n\t// Add the kernel path\n\tkernelPath, err := clh.config.KernelAssetPath()\n\tif err != nil {\n\t\treturn err\n\t}\n\tclh.vmconfig.Kernel = chclient.KernelConfig{\n\t\tPath: kernelPath,\n\t}\n\n\t// First take the default parameters defined by this driver\n\tparams := clhKernelParams\n\n\t// Followed by extra debug parameters if debug enabled in configuration file\n\tif clh.config.Debug {\n\t\tparams = append(params, clhDebugKernelParams...)\n\t}\n\n\t// Followed by extra debug parameters defined in the configuration file\n\tparams = append(params, clh.config.KernelParams...)\n\n\tclh.vmconfig.Cmdline.Args = kernelParamsToString(params)\n\n\t// set random device generator to hypervisor\n\tclh.vmconfig.Rng = chclient.RngConfig{\n\t\tSrc: clh.config.EntropySource,\n\t}\n\n\t// set the initial root/boot disk of hypervisor\n\timagePath, err := clh.config.ImageAssetPath()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif imagePath == \"\" {\n\t\treturn errors.New(\"image path is empty\")\n\t}\n\n\tpmem := chclient.PmemConfig{\n\t\tFile:          imagePath,\n\t\tDiscardWrites: true,\n\t}\n\tclh.vmconfig.Pmem = append(clh.vmconfig.Pmem, pmem)\n\n\t// set the serial console to the cloud hypervisor\n\tif clh.config.Debug {\n\t\tclh.vmconfig.Serial = chclient.ConsoleConfig{\n\t\t\tMode: cctTTY,\n\t\t}\n\n\t} else {\n\t\tclh.vmconfig.Serial = chclient.ConsoleConfig{\n\t\t\tMode: cctNULL,\n\t\t}\n\t}\n\n\tclh.vmconfig.Console = chclient.ConsoleConfig{\n\t\tMode: cctOFF,\n\t}\n\n\t// Overwrite the default value of HTTP API socket path for cloud hypervisor\n\tapiSocketPath, err := clh.apiSocketPath(id)\n\tif err != nil {\n\t\tclh.Logger().Info(\"Invalid api socket path for cloud-hypervisor\")\n\t\treturn nil\n\t}\n\tclh.state.apiSocket = apiSocketPath\n\n\tclh.virtiofsd = &virtiofsd{\n\t\tpath:       clh.config.VirtioFSDaemon,\n\t\tsourcePath: filepath.Join(kataHostSharedDir(), clh.id),\n\t\tsocketPath: virtiofsdSocketPath,\n\t\textraArgs:  clh.config.VirtioFSExtraArgs,\n\t\tdebug:      clh.config.Debug,\n\t\tcache:      clh.config.VirtioFSCache,\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) RemoveService(ctx context.Context, in *sliverpb.RemoveServiceReq, opts ...grpc.CallOption) (*sliverpb.ServiceInfo, error) {\n\tout := new(sliverpb.ServiceInfo)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/RemoveService\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (m *Foo) Unmarshal(dAtA []byte) error {\n\tvar hasFields [1]uint64\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowProto\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProto\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Bar = &v\n\t\t\thasFields[0] |= uint64(0x00000001)\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipProto(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\tif hasFields[0]&uint64(0x00000001) == 0 {\n\t\treturn github_com_gogo_protobuf_proto.NewRequiredNotSetError(\"bar\")\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func dumpEnvoy(rootDir string, resource string, fileName string, postProcess postProcessFunc) error {\n\t// curl --unix-socket /var/run/cilium/envoy-admin.sock http:/admin/config_dump\\?include_eds > dump.json\n\tc := &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tDialContext: func(_ context.Context, _, _ string) (net.Conn, error) {\n\t\t\t\treturn net.Dial(\"unix\", \"/var/run/cilium/envoy-admin.sock\")\n\t\t\t},\n\t\t},\n\t}\n\n\tif postProcess == nil {\n\t\treturn downloadToFile(c, resource, filepath.Join(rootDir, fileName))\n\t}\n\treturn downloadToFileWithPostProcess(c, resource, filepath.Join(rootDir, fileName), postProcess)\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) CreateOrUpdateSender(req *http.Request) (future DeploymentsCreateOrUpdateFuture, err error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\tvar resp *http.Response\n\tresp, err = autorest.SendWithSender(client, req, sd...)\n\tif err != nil {\n\t\treturn\n\t}\n\tfuture.Future, err = azure.NewFutureFromResponse(resp)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (cli *DaemonCli) start(opts daemonOptions) (err error) {\n\tstopc := make(chan bool)\n\tdefer close(stopc)\n\n\t// warn from uuid package when running the daemon\n\tuuid.Loggerf = logrus.Warnf\n\n\topts.common.SetDefaultOptions(opts.flags)\n\n\tif cli.Config, err = loadDaemonCliConfig(opts); err != nil {\n\t\treturn err\n\t}\n\tcli.configFile = &opts.configFile\n\tcli.flags = opts.flags\n\n\tif cli.Config.Debug {\n\t\tdebug.Enable()\n\t}\n\n\tif cli.Config.Experimental {\n\t\tlogrus.Warn(\"Running experimental build\")\n\t}\n\n\tlogrus.SetFormatter(&logrus.TextFormatter{\n\t\tTimestampFormat: jsonlog.RFC3339NanoFixed,\n\t\tDisableColors:   cli.Config.RawLogs,\n\t})\n\n\tif err := setDefaultUmask(); err != nil {\n\t\treturn fmt.Errorf(\"Failed to set umask: %v\", err)\n\t}\n\n\tif len(cli.LogConfig.Config) > 0 {\n\t\tif err := logger.ValidateLogOpts(cli.LogConfig.Type, cli.LogConfig.Config); err != nil {\n\t\t\treturn fmt.Errorf(\"Failed to set log opts: %v\", err)\n\t\t}\n\t}\n\n\t// Create the daemon root before we create ANY other files (PID, or migrate keys)\n\t// to ensure the appropriate ACL is set (particularly relevant on Windows)\n\tif err := daemon.CreateDaemonRoot(cli.Config); err != nil {\n\t\treturn err\n\t}\n\n\tif cli.Pidfile != \"\" {\n\t\tpf, err := pidfile.New(cli.Pidfile)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error starting daemon: %v\", err)\n\t\t}\n\t\tdefer func() {\n\t\t\tif err := pf.Remove(); err != nil {\n\t\t\t\tlogrus.Error(err)\n\t\t\t}\n\t\t}()\n\t}\n\n\tserverConfig := &apiserver.Config{\n\t\tLogging:     true,\n\t\tSocketGroup: cli.Config.SocketGroup,\n\t\tVersion:     dockerversion.Version,\n\t\tEnableCors:  cli.Config.EnableCors,\n\t\tCorsHeaders: cli.Config.CorsHeaders,\n\t}\n\n\tif cli.Config.TLS {\n\t\ttlsOptions := tlsconfig.Options{\n\t\t\tCAFile:             cli.Config.CommonTLSOptions.CAFile,\n\t\t\tCertFile:           cli.Config.CommonTLSOptions.CertFile,\n\t\t\tKeyFile:            cli.Config.CommonTLSOptions.KeyFile,\n\t\t\tExclusiveRootPools: true,\n\t\t}\n\n\t\tif cli.Config.TLSVerify {\n\t\t\t// server requires and verifies client's certificate\n\t\t\ttlsOptions.ClientAuth = tls.RequireAndVerifyClientCert\n\t\t}\n\t\ttlsConfig, err := tlsconfig.Server(tlsOptions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tserverConfig.TLSConfig = tlsConfig\n\t}\n\n\tif len(cli.Config.Hosts) == 0 {\n\t\tcli.Config.Hosts = make([]string, 1)\n\t}\n\n\tapi := apiserver.New(serverConfig)\n\tcli.api = api\n\n\tfor i := 0; i < len(cli.Config.Hosts); i++ {\n\t\tvar err error\n\t\tif cli.Config.Hosts[i], err = dopts.ParseHost(cli.Config.TLS, cli.Config.Hosts[i]); err != nil {\n\t\t\treturn fmt.Errorf(\"error parsing -H %s : %v\", cli.Config.Hosts[i], err)\n\t\t}\n\n\t\tprotoAddr := cli.Config.Hosts[i]\n\t\tprotoAddrParts := strings.SplitN(protoAddr, \"://\", 2)\n\t\tif len(protoAddrParts) != 2 {\n\t\t\treturn fmt.Errorf(\"bad format %s, expected PROTO://ADDR\", protoAddr)\n\t\t}\n\n\t\tproto := protoAddrParts[0]\n\t\taddr := protoAddrParts[1]\n\n\t\t// It's a bad idea to bind to TCP without tlsverify.\n\t\tif proto == \"tcp\" && (serverConfig.TLSConfig == nil || serverConfig.TLSConfig.ClientAuth != tls.RequireAndVerifyClientCert) {\n\t\t\tlogrus.Warn(\"[!] DON'T BIND ON ANY IP ADDRESS WITHOUT setting --tlsverify IF YOU DON'T KNOW WHAT YOU'RE DOING [!]\")\n\t\t}\n\t\tls, err := listeners.Init(proto, addr, serverConfig.SocketGroup, serverConfig.TLSConfig)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tls = wrapListeners(proto, ls)\n\t\t// If we're binding to a TCP port, make sure that a container doesn't try to use it.\n\t\tif proto == \"tcp\" {\n\t\t\tif err := allocateDaemonPort(addr); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tlogrus.Debugf(\"Listener created for HTTP on %s (%s)\", proto, addr)\n\t\tapi.Accept(addr, ls...)\n\t}\n\n\tregistryService := registry.NewService(cli.Config.ServiceOptions)\n\tcontainerdRemote, err := libcontainerd.New(cli.getLibcontainerdRoot(), cli.getPlatformRemoteOptions()...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsignal.Trap(func() {\n\t\tcli.stop()\n\t\t<-stopc // wait for daemonCli.start() to return\n\t})\n\n\t// Notify that the API is active, but before daemon is set up.\n\tpreNotifySystem()\n\n\tpluginStore := plugin.NewStore()\n\n\tif err := cli.initMiddlewares(api, serverConfig, pluginStore); err != nil {\n\t\tlogrus.Fatalf(\"Error creating middlewares: %v\", err)\n\t}\n\n\td, err := daemon.NewDaemon(cli.Config, registryService, containerdRemote, pluginStore)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Error starting daemon: %v\", err)\n\t}\n\n\t// validate after NewDaemon has restored enabled plugins. Dont change order.\n\tif err := validateAuthzPlugins(cli.Config.AuthorizationPlugins, pluginStore); err != nil {\n\t\treturn fmt.Errorf(\"Error validating authorization plugin: %v\", err)\n\t}\n\n\tif cli.Config.MetricsAddress != \"\" {\n\t\tif !d.HasExperimental() {\n\t\t\treturn fmt.Errorf(\"metrics-addr is only supported when experimental is enabled\")\n\t\t}\n\t\tif err := startMetricsServer(cli.Config.MetricsAddress); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tname, _ := os.Hostname()\n\n\tc, err := cluster.New(cluster.Config{\n\t\tRoot:                   cli.Config.Root,\n\t\tName:                   name,\n\t\tBackend:                d,\n\t\tNetworkSubnetsProvider: d,\n\t\tDefaultAdvertiseAddr:   cli.Config.SwarmDefaultAdvertiseAddr,\n\t\tRuntimeRoot:            cli.getSwarmRunRoot(),\n\t})\n\tif err != nil {\n\t\tlogrus.Fatalf(\"Error creating cluster component: %v\", err)\n\t}\n\td.SetCluster(c)\n\terr = c.Start()\n\tif err != nil {\n\t\tlogrus.Fatalf(\"Error starting cluster component: %v\", err)\n\t}\n\n\t// Restart all autostart containers which has a swarm endpoint\n\t// and is not yet running now that we have successfully\n\t// initialized the cluster.\n\td.RestartSwarmContainers()\n\n\tlogrus.Info(\"Daemon has completed initialization\")\n\n\tlogrus.WithFields(logrus.Fields{\n\t\t\"version\":     dockerversion.Version,\n\t\t\"commit\":      dockerversion.GitCommit,\n\t\t\"graphdriver\": d.GraphDriverName(),\n\t}).Info(\"Docker daemon\")\n\n\tcli.d = d\n\n\tinitRouter(api, d, c)\n\n\tcli.setupConfigReloadTrap()\n\n\t// The serve API routine never exits unless an error occurs\n\t// We need to start it as a goroutine and wait on it so\n\t// daemon doesn't exit\n\tserveAPIWait := make(chan error)\n\tgo api.Wait(serveAPIWait)\n\n\t// after the daemon is done setting up we can notify systemd api\n\tnotifySystem()\n\n\t// Daemon is fully initialized and handling API traffic\n\t// Wait for serve API to complete\n\terrAPI := <-serveAPIWait\n\tc.Cleanup()\n\tshutdownDaemon(d)\n\tcontainerdRemote.Cleanup()\n\tif errAPI != nil {\n\t\treturn fmt.Errorf(\"Shutting down due to ServeAPI error: %v\", errAPI)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (a rewrite) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, rewriteAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func TestCheckDispatchCount(t *testing.T) {\n\tds := memory.New()\n\tctx := storage.ContextWithRelationshipTupleReader(context.Background(), ds)\n\n\tt.Run(\"dispatch_count_ttu\", func(t *testing.T) {\n\t\tstoreID := ulid.Make().String()\n\n\t\tmodel := parser.MustTransformDSLToProto(`model\n  schema 1.1\n\ntype user\n\ntype folder\n  \trelations\n\t\tdefine viewer: [user] or viewer from parent\n\t\tdefine parent: [folder]\n\ntype doc\n\trelations\n\t\tdefine viewer: [user] or viewer from parent\n\t\tdefine parent: [folder]\n`)\n\n\t\terr := ds.Write(ctx, storeID, nil, []*openfgav1.TupleKey{\n\t\t\ttuple.NewTupleKey(\"folder:C\", \"viewer\", \"user:jon\"),\n\t\t\ttuple.NewTupleKey(\"folder:B\", \"parent\", \"folder:C\"),\n\t\t\ttuple.NewTupleKey(\"folder:A\", \"parent\", \"folder:B\"),\n\t\t\ttuple.NewTupleKey(\"doc:readme\", \"parent\", \"folder:A\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\tchecker := NewLocalChecker()\n\n\t\ttypesys, err := typesystem.NewAndValidate(\n\t\t\tcontext.Background(),\n\t\t\tmodel,\n\t\t)\n\t\trequire.NoError(t, err)\n\n\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\t\tcheckRequestMetadata := NewCheckRequestMetadata(5)\n\n\t\tresp, err := checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"doc:readme\", \"viewer\", \"user:jon\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, resp.Allowed)\n\n\t\trequire.Equal(t, uint32(3), checkRequestMetadata.DispatchCounter.Load())\n\n\t\tt.Run(\"direct_lookup_requires_no_dispatch\", func(t *testing.T) {\n\t\t\tcheckRequestMetadata := NewCheckRequestMetadata(5)\n\n\t\t\tresp, err := checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\t\tStoreID:              storeID,\n\t\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\t\tTupleKey:             tuple.NewTupleKey(\"doc:readme\", \"parent\", \"folder:A\"),\n\t\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t\t})\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.True(t, resp.Allowed)\n\n\t\t\trequire.Zero(t, checkRequestMetadata.DispatchCounter.Load())\n\t\t})\n\t})\n\n\tt.Run(\"dispatch_count_multiple_direct_userset_lookups\", func(t *testing.T) {\n\t\tstoreID := ulid.Make().String()\n\n\t\tmodel := parser.MustTransformDSLToProto(`model\n\t  schema 1.1\n\t\n\ttype user\n\t\n\ttype group\n\t  relations\n\t    define member: [user, group#member]\n\n\ttype document\n\t  relations\n\t\tdefine viewer: [group#member]\n\t`)\n\n\t\terr := ds.Write(ctx, storeID, nil, []*openfgav1.TupleKey{\n\t\t\ttuple.NewTupleKey(\"group:1\", \"member\", \"user:jon\"),\n\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"group:1#member\"),\n\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"group:2#member\"),\n\t\t\ttuple.NewTupleKey(\"group:eng\", \"member\", \"group:3#member\"),\n\t\t\ttuple.NewTupleKey(\"document:1\", \"viewer\", \"group:eng#member\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\tchecker := NewLocalChecker()\n\n\t\ttypesys, err := typesystem.NewAndValidate(\n\t\t\tcontext.Background(),\n\t\t\tmodel,\n\t\t)\n\t\trequire.NoError(t, err)\n\n\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\t\tcheckRequestMetadata := NewCheckRequestMetadata(5)\n\n\t\tresp, err := checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"document:1\", \"viewer\", \"user:jon\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, resp.Allowed)\n\n\t\trequire.GreaterOrEqual(t, checkRequestMetadata.DispatchCounter.Load(), uint32(2))\n\t\trequire.LessOrEqual(t, checkRequestMetadata.DispatchCounter.Load(), uint32(4))\n\n\t\tcheckRequestMetadata = NewCheckRequestMetadata(5)\n\n\t\tresp, err = checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"document:1\", \"viewer\", \"user:other\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, resp.Allowed)\n\n\t\trequire.Equal(t, uint32(4), checkRequestMetadata.DispatchCounter.Load())\n\t})\n\n\tt.Run(\"dispatch_count_computed_userset_lookups\", func(t *testing.T) {\n\t\tstoreID := ulid.Make().String()\n\n\t\tmodel := parser.MustTransformDSLToProto(`model\n\t\tschema 1.1\n\n\t\ttype user\n  \t\n\t\ttype document\n\t\t\trelations\n\t\t   \t\tdefine owner: [user]\n\t\t   \t\tdefine editor: [user] or owner`)\n\n\t\terr := ds.Write(ctx, storeID, nil, []*openfgav1.TupleKey{\n\t\t\ttuple.NewTupleKey(\"document:1\", \"owner\", \"user:jon\"),\n\t\t\ttuple.NewTupleKey(\"document:2\", \"editor\", \"user:will\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\n\t\tchecker := NewLocalChecker()\n\n\t\ttypesys, err := typesystem.NewAndValidate(\n\t\t\tcontext.Background(),\n\t\t\tmodel,\n\t\t)\n\t\trequire.NoError(t, err)\n\n\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\t\tcheckRequestMetadata := NewCheckRequestMetadata(5)\n\t\tresp, err := checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"document:1\", \"owner\", \"user:jon\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, resp.Allowed)\n\n\t\trequire.Zero(t, checkRequestMetadata.DispatchCounter.Load())\n\n\t\tcheckRequestMetadata = NewCheckRequestMetadata(5)\n\n\t\tresp, err = checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"document:2\", \"editor\", \"user:will\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, resp.Allowed)\n\n\t\trequire.LessOrEqual(t, checkRequestMetadata.DispatchCounter.Load(), uint32(1))\n\t\trequire.GreaterOrEqual(t, checkRequestMetadata.DispatchCounter.Load(), uint32(0))\n\n\t\tcheckRequestMetadata = NewCheckRequestMetadata(5)\n\t\tresp, err = checker.ResolveCheck(ctx, &ResolveCheckRequest{\n\t\t\tStoreID:              storeID,\n\t\t\tAuthorizationModelID: model.GetId(),\n\t\t\tTupleKey:             tuple.NewTupleKey(\"document:2\", \"editor\", \"user:jon\"),\n\t\t\tRequestMetadata:      checkRequestMetadata,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.False(t, resp.Allowed)\n\t\trequire.Equal(t, uint32(1), checkRequestMetadata.DispatchCounter.Load())\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestBuilder_BuildBootstrapAdmin(t *testing.T) {\n\tb := New(\"local-grpc\", \"local-http\", \"local-metrics\", filemgr.NewManager(), nil)\n\tt.Run(\"valid\", func(t *testing.T) {\n\t\tadminCfg, err := b.BuildBootstrapAdmin(&config.Config{\n\t\t\tOptions: &config.Options{\n\t\t\t\tEnvoyAdminAddress: \"localhost:9901\",\n\t\t\t},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"address\": {\n\t\t\t\t\t\"socketAddress\": {\n\t\t\t\t\t\t\"address\": \"127.0.0.1\",\n\t\t\t\t\t\t\"portValue\": 9901\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t`, adminCfg)\n\t})\n\tt.Run(\"bad address\", func(t *testing.T) {\n\t\t_, err := b.BuildBootstrapAdmin(&config.Config{\n\t\t\tOptions: &config.Options{\n\t\t\t\tEnvoyAdminAddress: \"xyz1234:zyx4321\",\n\t\t\t},\n\t\t})\n\t\tassert.Error(t, err)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *liveStateCache) getCluster(server string) (clustercache.ClusterCache, error) {\n\tc.lock.RLock()\n\tclusterCache, ok := c.clusters[server]\n\tcacheSettings := c.cacheSettings\n\tc.lock.RUnlock()\n\n\tif ok {\n\t\treturn clusterCache, nil\n\t}\n\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tclusterCache, ok = c.clusters[server]\n\tif ok {\n\t\treturn clusterCache, nil\n\t}\n\n\tcluster, err := c.db.GetCluster(context.Background(), server)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting cluster: %w\", err)\n\t}\n\n\tif !c.canHandleCluster(cluster) {\n\t\treturn nil, fmt.Errorf(\"controller is configured to ignore cluster %s\", cluster.Server)\n\t}\n\n\tresourceCustomLabels, err := c.settingsMgr.GetResourceCustomLabels()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting custom label: %w\", err)\n\t}\n\n\trespectRBAC, err := c.settingsMgr.RespectRBAC()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error getting value for %v: %w\", settings.RespectRBAC, err)\n\t}\n\n\tclusterCacheConfig := cluster.RESTConfig()\n\t// Controller dynamically fetches all resource types available on the cluster\n\t// using a discovery API that may contain deprecated APIs.\n\t// This causes log flooding when managing a large number of clusters.\n\t// https://github.com/argoproj/argo-cd/issues/11973\n\t// However, we can safely suppress deprecation warnings\n\t// because we do not rely on resources with a particular API group or version.\n\t// https://kubernetes.io/blog/2020/09/03/warnings/#customize-client-handling\n\t//\n\t// Completely suppress warning logs only for log levels that are less than Debug.\n\tif log.GetLevel() < log.DebugLevel {\n\t\tclusterCacheConfig.WarningHandler = rest.NoWarnings{}\n\t}\n\n\tclusterCacheOpts := []clustercache.UpdateSettingsFunc{\n\t\tclustercache.SetListSemaphore(semaphore.NewWeighted(clusterCacheListSemaphoreSize)),\n\t\tclustercache.SetListPageSize(clusterCacheListPageSize),\n\t\tclustercache.SetListPageBufferSize(clusterCacheListPageBufferSize),\n\t\tclustercache.SetWatchResyncTimeout(clusterCacheWatchResyncDuration),\n\t\tclustercache.SetClusterSyncRetryTimeout(clusterSyncRetryTimeoutDuration),\n\t\tclustercache.SetResyncTimeout(clusterCacheResyncDuration),\n\t\tclustercache.SetSettings(cacheSettings.clusterSettings),\n\t\tclustercache.SetNamespaces(cluster.Namespaces),\n\t\tclustercache.SetClusterResources(cluster.ClusterResources),\n\t\tclustercache.SetPopulateResourceInfoHandler(func(un *unstructured.Unstructured, isRoot bool) (interface{}, bool) {\n\t\t\tres := &ResourceInfo{}\n\t\t\tpopulateNodeInfo(un, res, resourceCustomLabels)\n\t\t\tc.lock.RLock()\n\t\t\tcacheSettings := c.cacheSettings\n\t\t\tc.lock.RUnlock()\n\n\t\t\tres.Health, _ = health.GetResourceHealth(un, cacheSettings.clusterSettings.ResourceHealthOverride)\n\n\t\t\tappName := c.resourceTracking.GetAppName(un, cacheSettings.appInstanceLabelKey, cacheSettings.trackingMethod)\n\t\t\tif isRoot && appName != \"\" {\n\t\t\t\tres.AppName = appName\n\t\t\t}\n\n\t\t\tgvk := un.GroupVersionKind()\n\n\t\t\tif cacheSettings.ignoreResourceUpdatesEnabled && shouldHashManifest(appName, gvk) {\n\t\t\t\thash, err := generateManifestHash(un, nil, cacheSettings.resourceOverrides)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorf(\"Failed to generate manifest hash: %v\", err)\n\t\t\t\t} else {\n\t\t\t\t\tres.manifestHash = hash\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// edge case. we do not label CRDs, so they miss the tracking label we inject. But we still\n\t\t\t// want the full resource to be available in our cache (to diff), so we store all CRDs\n\t\t\treturn res, res.AppName != \"\" || gvk.Kind == kube.CustomResourceDefinitionKind\n\t\t}),\n\t\tclustercache.SetLogr(logutils.NewLogrusLogger(log.WithField(\"server\", cluster.Server))),\n\t\tclustercache.SetRetryOptions(clusterCacheAttemptLimit, clusterCacheRetryUseBackoff, isRetryableError),\n\t\tclustercache.SetRespectRBAC(respectRBAC),\n\t}\n\n\tclusterCache = clustercache.NewClusterCache(clusterCacheConfig, clusterCacheOpts...)\n\n\t_ = clusterCache.OnResourceUpdated(func(newRes *clustercache.Resource, oldRes *clustercache.Resource, namespaceResources map[kube.ResourceKey]*clustercache.Resource) {\n\t\ttoNotify := make(map[string]bool)\n\t\tvar ref v1.ObjectReference\n\t\tif newRes != nil {\n\t\t\tref = newRes.Ref\n\t\t} else {\n\t\t\tref = oldRes.Ref\n\t\t}\n\n\t\tc.lock.RLock()\n\t\tcacheSettings := c.cacheSettings\n\t\tc.lock.RUnlock()\n\n\t\tif cacheSettings.ignoreResourceUpdatesEnabled && oldRes != nil && newRes != nil && skipResourceUpdate(resInfo(oldRes), resInfo(newRes)) {\n\t\t\t// Additional check for debug level so we don't need to evaluate the\n\t\t\t// format string in case of non-debug scenarios\n\t\t\tif log.GetLevel() >= log.DebugLevel {\n\t\t\t\tnamespace := ref.Namespace\n\t\t\t\tif ref.Namespace == \"\" {\n\t\t\t\t\tnamespace = \"(cluster-scoped)\"\n\t\t\t\t}\n\t\t\t\tlog.WithFields(log.Fields{\n\t\t\t\t\t\"server\":      cluster.Server,\n\t\t\t\t\t\"namespace\":   namespace,\n\t\t\t\t\t\"name\":        ref.Name,\n\t\t\t\t\t\"api-version\": ref.APIVersion,\n\t\t\t\t\t\"kind\":        ref.Kind,\n\t\t\t\t}).Debug(\"Ignoring change of object because none of the watched resource fields have changed\")\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tfor _, r := range []*clustercache.Resource{newRes, oldRes} {\n\t\t\tif r == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tapp := getApp(r, namespaceResources)\n\t\t\tif app == \"\" || skipAppRequeuing(r.ResourceKey()) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\ttoNotify[app] = isRootAppNode(r) || toNotify[app]\n\t\t}\n\t\tc.onObjectUpdated(toNotify, ref)\n\t})\n\n\t_ = clusterCache.OnEvent(func(event watch.EventType, un *unstructured.Unstructured) {\n\t\tgvk := un.GroupVersionKind()\n\t\tc.metricsServer.IncClusterEventsCount(cluster.Server, gvk.Group, gvk.Kind)\n\t})\n\n\tc.clusters[server] = clusterCache\n\n\treturn clusterCache, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) CrackFileDelete(ctx context.Context, in *clientpb.CrackFile, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CrackFileDelete_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestVCSLookup(t *testing.T) {\n\t// TODO: Expand to make sure it detected the right vcs.\n\turlList := map[string]struct {\n\t\twork bool\n\t\tt    Type\n\t}{\n\t\t\"https://github.com/masterminds\":                                   {work: false, t: Git},\n\t\t\"https://github.com/Masterminds/VCSTestRepo\":                       {work: true, t: Git},\n\t\t\"https://bitbucket.org/mattfarina/testhgrepo\":                      {work: true, t: Hg},\n\t\t\"https://bitbucket.org/mattfarina/repo-does-not-exist\":             {work: false, t: Hg},\n\t\t\"https://bitbucket.org/mattfarina/private-repo-for-vcs-testing\":    {work: false, t: Hg},\n\t\t\"https://launchpad.net/govcstestbzrrepo/trunk\":                     {work: true, t: Bzr},\n\t\t\"https://launchpad.net/~mattfarina/+junk/mygovcstestbzrrepo\":       {work: true, t: Bzr},\n\t\t\"https://launchpad.net/~mattfarina/+junk/mygovcstestbzrrepo/trunk\": {work: true, t: Bzr},\n\t\t\"https://git.launchpad.net/govcstestgitrepo\":                       {work: true, t: Git},\n\t\t\"https://git.launchpad.net/~mattfarina/+git/mygovcstestgitrepo\":    {work: true, t: Git},\n\t\t\"https://hub.jazz.net/git/user1/pkgname\":                           {work: true, t: Git},\n\t\t\"https://hub.jazz.net/git/user1/pkgname/subpkg/subpkg/subpkg\":      {work: true, t: Git},\n\t\t\"https://hubs.jazz.net/git/user1/pkgname\":                          {work: false, t: Git},\n\t\t\"https://example.com/foo/bar.git\":                                  {work: true, t: Git},\n\t\t\"https://example.com/foo/bar.svn\":                                  {work: true, t: Svn},\n\t\t\"https://example.com/foo/bar/baz.bzr\":                              {work: true, t: Bzr},\n\t\t\"https://example.com/foo/bar/baz.hg\":                               {work: true, t: Hg},\n\t\t\"https://gopkg.in/tomb.v1\":                                         {work: true, t: Git},\n\t\t\"https://golang.org/x/net\":                                         {work: true, t: Git},\n\t\t\"https://git.openstack.org/foo/bar\":                                {work: true, t: Git},\n\t\t\"git@github.com:Masterminds/vcs.git\":                               {work: true, t: Git},\n\t\t\"git@example.com:foo.git\":                                          {work: true, t: Git},\n\t\t\"ssh://hg@bitbucket.org/mattfarina/testhgrepo\":                     {work: true, t: Hg},\n\t\t\"git@bitbucket.org:mattfarina/glide-bitbucket-example.git\":         {work: true, t: Git},\n\t\t\"git+ssh://example.com/foo/bar\":                                    {work: true, t: Git},\n\t\t\"git://example.com/foo/bar\":                                        {work: true, t: Git},\n\t\t\"bzr+ssh://example.com/foo/bar\":                                    {work: true, t: Bzr},\n\t\t\"svn+ssh://example.com/foo/bar\":                                    {work: true, t: Svn},\n\t\t\"git@example.com:foo/bar\":                                          {work: true, t: Git},\n\t\t\"hg@example.com:foo/bar\":                                           {work: true, t: Hg},\n\t}\n\n\tfor u, c := range urlList {\n\t\tty, _, err := detectVcsFromRemote(u)\n\t\tif err == nil && !c.work {\n\t\t\tt.Errorf(\"Error detecting VCS from URL(%s)\", u)\n\t\t}\n\n\t\tif err == ErrCannotDetectVCS && c.work {\n\t\t\tt.Errorf(\"Error detecting VCS from URL(%s)\", u)\n\t\t}\n\n\t\tif err != nil && c.work {\n\t\t\tt.Errorf(\"Error detecting VCS from URL(%s): %s\", u, err)\n\t\t}\n\n\t\tif err != nil &&\n\t\t\terr != ErrCannotDetectVCS &&\n\t\t\t!strings.HasSuffix(err.Error(), \"Not Found\") &&\n\t\t\t!strings.HasSuffix(err.Error(), \"Access Denied\") &&\n\t\t\t!c.work {\n\t\t\tt.Errorf(\"Unexpected error returned (%s): %s\", u, err)\n\t\t}\n\n\t\tif c.work && ty != c.t {\n\t\t\tt.Errorf(\"Incorrect VCS type returned(%s)\", u)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *sigs) Get() ([]oci.Signature, error) {\n\tmanifest, err := s.Image.Manifest()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsignatures := make([]oci.Signature, 0, len(manifest.Layers))\n\tfor _, desc := range manifest.Layers {\n\t\tl, err := s.Image.LayerByDigest(desc.Digest)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsignatures = append(signatures, signature.New(l, desc))\n\t}\n\treturn signatures, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Struct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Struct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Struct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Fields\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Fields == nil {\n\t\t\t\tm.Fields = make(map[string]*Value)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue *Value\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowStruct\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Value{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipStruct(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Fields[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipStruct(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthStruct\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (b Builder) Build() (*Config, error) {\n\tconfig := Config{\n\t\tClientID:                      b.ClientID,\n\t\tSubscriptionID:                b.SubscriptionID,\n\t\tTenantID:                      b.TenantID,\n\t\tEnvironment:                   b.Environment,\n\t\tCustomResourceManagerEndpoint: b.CustomResourceManagerEndpoint,\n\t}\n\n\t// NOTE: the ordering here is important\n\t// since the Azure CLI Parsing should always be the last thing checked\n\tsupportedAuthenticationMethods := []authMethod{\n\t\tservicePrincipalClientCertificateAuth{},\n\t\tservicePrincipalClientSecretAuth{},\n\t\tmanagedServiceIdentityAuth{},\n\t\tazureCliTokenAuth{},\n\t}\n\n\tfor _, method := range supportedAuthenticationMethods {\n\t\tname := method.name()\n\t\tlog.Printf(\"Testing if %s is applicable for Authentication..\", name)\n\t\tif method.isApplicable(b) {\n\t\t\tlog.Printf(\"Using %s for Authentication\", name)\n\t\t\tauth, err := method.build(b)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// populate authentication specific fields on the Config\n\t\t\t// (e.g. is service principal, fields parsed from the azure cli)\n\t\t\terr = auth.populateConfig(&config)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tconfig.authMethod = auth\n\t\t\treturn config.validate()\n\t\t}\n\t}\n\n\treturn nil, fmt.Errorf(\"No supported authentication methods were found!\")\n}", "is_vulnerable": 1}
{"code": "func (m *UInt64Value) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowWrappers\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: UInt64Value: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: UInt64Value: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tm.Value = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowWrappers\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Value |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipWrappers(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthWrappers\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (d pngGenerator) GetOriginDimensions(b []byte, contentType string, ctx rcontext.RequestContext) (bool, int, int, error) {\n\ti, _, err := image.DecodeConfig(bytes.NewBuffer(b))\n\tif err != nil {\n\t\treturn false, 0, 0, err\n\t}\n\treturn true, i.Width, i.Height, nil\n}", "is_vulnerable": 0}
{"code": "func TestVerifyImageSignatureWithSigVerifierAndRekor(t *testing.T) {\n\tsv, privKey, err := signature.NewDefaultECDSASignerVerifier()\n\tif err != nil {\n\t\tt.Fatalf(\"error generating verifier: %v\", err)\n\t}\n\n\tpayload := []byte{1, 2, 3, 4}\n\th := sha256.Sum256(payload)\n\tsig, _ := privKey.Sign(rand.Reader, h[:], crypto.SHA256)\n\tociSig, _ := static.NewSignature(payload, base64.StdEncoding.EncodeToString(sig))\n\n\t// Add a fake rekor client - this makes it look like there's a matching\n\t// tlog entry for the signature during validation (even though it does not\n\t// match the underlying data / key)\n\tmClient := new(client.Rekor)\n\tmClient.Entries = &mock.EntriesClient{}\n\n\tif _, err := VerifyImageSignature(context.TODO(), ociSig, v1.Hash{}, &CheckOpts{\n\t\tSigVerifier: sv,\n\t\tRekorClient: mClient,\n\t}); err == nil || !strings.Contains(err.Error(), \"verifying inclusion proof\") {\n\t\t// TODO(wlynch): This is a weak test, since this is really failing because\n\t\t// there is no inclusion proof for the Rekor entry rather than failing to\n\t\t// validate the Rekor public key itself. At the very least this ensures\n\t\t// that we're hitting tlog validation during signature checking,\n\t\t// but we should look into improving this once there is an in-memory\n\t\t// Rekor client that is capable of performing inclusion proof validation\n\t\t// in unit tests.\n\t\tt.Fatal(\"expected error while verifying signature\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (svc Service) GetTeamScheduledQueries(ctx context.Context, teamID uint, opts fleet.ListOptions) ([]*fleet.ScheduledQuery, error) {\n\tif err := svc.authz.Authorize(ctx, &fleet.Pack{TeamIDs: []uint{teamID}}, fleet.ActionRead); err != nil {\n\t\treturn nil, err\n\t}\n\n\tgp, err := svc.ds.EnsureTeamPack(ctx, teamID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn svc.ds.ListScheduledQueriesInPackWithStats(ctx, gp.ID, opts)\n}", "is_vulnerable": 1}
{"code": "func NewServer(config *Config) (*Server, error) {\n\treturn NewServerLogger(config, nil, new(token.Store), tlsutil.NewConfigurator(config.ToTLSUtilConfig()))\n}", "is_vulnerable": 1}
{"code": "func (t *assetAction) checkERC20AssetLimitsUpdated() error {\n\tasset, _ := t.asset.ERC20()\n\treturn t.bridgeView.FindAssetLimitsUpdated(\n\t\tt.erc20AssetLimitsUpdated, t.blockHeight, t.logIndex, asset.Address(), t.txHash,\n\t)\n}", "is_vulnerable": 0}
{"code": "\t\th.activeUsers = util.NewActiveUsersCleanupWithDefaultValues(func(user string) {\n\t\t\th.querySeconds.DeleteLabelValues(user)\n\t\t\th.querySeries.DeleteLabelValues(user)\n\t\t\th.queryBytes.DeleteLabelValues(user)\n\t\t})", "is_vulnerable": 0}
{"code": "func (t *Transport) refreshToken(ctx context.Context) error {\n\t// Convert InstallationTokenOptions into a ReadWriter to pass as an argument to http.NewRequest.\n\tbody, err := GetReadWriter(t.InstallationTokenOptions)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not convert installation token parameters into json: %s\", err)\n\t}\n\n\treq, err := http.NewRequest(\"POST\", fmt.Sprintf(\"%s/app/installations/%v/access_tokens\", t.BaseURL, t.installationID), body)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not create request: %s\", err)\n\t}\n\n\t// Set Content and Accept headers.\n\tif body != nil {\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t}\n\treq.Header.Set(\"Accept\", acceptHeader)\n\n\tif ctx != nil {\n\t\treq = req.WithContext(ctx)\n\t}\n\n\tt.appsTransport.BaseURL = t.BaseURL\n\tt.appsTransport.Client = t.Client\n\tresp, err := t.appsTransport.RoundTrip(req)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not get access_tokens from GitHub API for installation ID %v: %v\", t.installationID, err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode/100 != 2 {\n\t\treturn fmt.Errorf(\"request %+v received non 2xx response status %q with body %+v and TLS %+v\", resp.Request, resp.Body, resp.Request, resp.TLS)\n\t}\n\n\treturn json.NewDecoder(resp.Body).Decode(&t.token)\n}", "is_vulnerable": 1}
{"code": "func (a *Auth) AuthPlain(username, password string) ([]string, error) {\n\tkey, err := precis.UsernameCaseMapped.CompareKey(username)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tidentities := make([]string, 0, 1)\n\tif len(a.userTbls) != 0 {\n\t\tfor _, tbl := range a.userTbls {\n\t\t\trepl, ok, err := tbl.Lookup(key)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif repl != \"\" {\n\t\t\t\tidentities = append(identities, repl)\n\t\t\t} else {\n\t\t\t\tidentities = append(identities, key)\n\t\t\t}\n\t\t\tif a.onlyFirstID && len(identities) != 0 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif len(identities) == 0 {\n\t\t\treturn nil, errors.New(\"plain_separate: unknown credentials\")\n\t\t}\n\t}\n\n\tvar (\n\t\tlastErr error\n\t\tok      bool\n\t)\n\tfor _, pass := range a.passwd {\n\t\tpassIDs, err := pass.AuthPlain(username, password)\n\t\tif err != nil {\n\t\t\tlastErr = err\n\t\t\tcontinue\n\t\t}\n\t\tif len(a.userTbls) == 0 {\n\t\t\tidentities = append(identities, passIDs...)\n\t\t}\n\t\tok = true\n\t}\n\tif !ok {\n\t\treturn nil, lastErr\n\t}\n\n\treturn identities, nil\n}", "is_vulnerable": 1}
{"code": "func hostKeyCallback(caCerts [][]byte, withHostKeyFallback bool) (ssh.HostKeyCallback, error) {\n\ttrustedKeys, err := sshutils.ParseKnownHosts(caCerts)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// No CAs are provided, return a nil callback which will prompt the user\n\t// for trust.\n\tif len(trustedKeys) == 0 {\n\t\treturn nil, nil\n\t}\n\n\tcallbackConfig := sshutils.HostKeyCallbackConfig{\n\t\tGetHostCheckers: func() ([]ssh.PublicKey, error) {\n\t\t\treturn trustedKeys, nil\n\t\t},\n\t}\n\n\tif withHostKeyFallback {\n\t\tcallbackConfig.HostKeyFallback = hostKeyFallbackFunc(trustedKeys)\n\t}\n\n\tcallback, err := sshutils.NewHostKeyCallback(callbackConfig)\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn callback, nil\n}", "is_vulnerable": 0}
{"code": "func addRemoveLdapGroupMember(t *testing.T, cfg *ldaputil.ConfigEntry, userCN string, req *ldap.ModifyRequest) {\n\tlogger := log.New(nil)\n\tldapClient := ldaputil.Client{LDAP: ldaputil.NewLDAP(), Logger: logger}\n\t// LDAP server won't accept changes unless we connect with TLS.  This\n\t// isn't the default config returned by PrepareTestContainer because\n\t// the Vault LDAP backend won't work with it, even with InsecureTLS,\n\t// because the ServerName should be planetexpress.com and not localhost.\n\tconn, err := ldapClient.DialLDAP(cfg)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer conn.Close()\n\n\terr = conn.Bind(cfg.BindDN, cfg.BindPassword)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\terr = conn.Modify(req)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func CreateTarFromSrc(source string, dest string) error {\n\tfile, err := os.Create(dest)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not create tarball file '%s': %w\", dest, err)\n\t}\n\tdefer file.Close()\n\treturn TarChrootToFilesystem(source, file)\n}", "is_vulnerable": 0}
{"code": "func (c *LocalChecker) checkDirect(parentctx context.Context, req *ResolveCheckRequest) CheckHandlerFunc {\n\treturn func(ctx context.Context) (*ResolveCheckResponse, error) {\n\t\tctx, span := tracer.Start(ctx, \"checkDirect\")\n\t\tdefer span.End()\n\n\t\tif ctx.Err() != nil {\n\t\t\treturn nil, ctx.Err()\n\t\t}\n\n\t\ttypesys, ok := typesystem.TypesystemFromContext(parentctx) // note: use of 'parentctx' not 'ctx' - this is important\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"typesystem missing in context\")\n\t\t}\n\n\t\tds, ok := storage.RelationshipTupleReaderFromContext(parentctx)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"relationship tuple reader datastore missing in context\")\n\t\t}\n\n\t\tstoreID := req.GetStoreID()\n\t\treqTupleKey := req.GetTupleKey()\n\t\tobjectType := tuple.GetType(reqTupleKey.GetObject())\n\t\trelation := reqTupleKey.GetRelation()\n\n\t\t// directlyRelatedUsersetTypes could be \"user:*\" or \"group#member\"\n\t\tdirectlyRelatedUsersetTypes, _ := typesys.DirectlyRelatedUsersets(objectType, relation)\n\n\t\tfn1 := func(ctx context.Context) (*ResolveCheckResponse, error) {\n\t\t\tctx, span := tracer.Start(ctx, \"checkDirectUserTuple\", trace.WithAttributes(attribute.String(\"tuple_key\", reqTupleKey.String())))\n\t\t\tdefer span.End()\n\n\t\t\tresponse := &ResolveCheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\t\t\tDatastoreQueryCount: req.GetRequestMetadata().DatastoreQueryCount + 1,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tt, err := ds.ReadUserTuple(ctx, storeID, reqTupleKey)\n\t\t\tif err != nil {\n\t\t\t\tif errors.Is(err, storage.ErrNotFound) {\n\t\t\t\t\treturn response, nil\n\t\t\t\t}\n\n\t\t\t\treturn response, err\n\t\t\t}\n\n\t\t\t// filter out invalid tuples yielded by the database query\n\t\t\ttupleKey := t.GetKey()\n\t\t\terr = validation.ValidateTuple(typesys, tupleKey)\n\n\t\t\tif t != nil && err == nil {\n\t\t\t\tcondEvalResult, err := eval.EvaluateTupleCondition(ctx, tupleKey, typesys, req.GetContext())\n\t\t\t\tif err != nil {\n\t\t\t\t\ttelemetry.TraceError(span, err)\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\tif len(condEvalResult.MissingParameters) > 0 {\n\t\t\t\t\tevalErr := condition.NewEvaluationError(\n\t\t\t\t\t\ttupleKey.GetCondition().GetName(),\n\t\t\t\t\t\tfmt.Errorf(\"context is missing parameters '%v'\", condEvalResult.MissingParameters),\n\t\t\t\t\t)\n\t\t\t\t\ttelemetry.TraceError(span, evalErr)\n\t\t\t\t\treturn nil, evalErr\n\t\t\t\t}\n\n\t\t\t\tif !condEvalResult.ConditionMet {\n\t\t\t\t\treturn response, nil\n\t\t\t\t}\n\n\t\t\t\tspan.SetAttributes(attribute.Bool(\"allowed\", true))\n\t\t\t\tresponse.Allowed = true\n\t\t\t\treturn response, nil\n\t\t\t}\n\t\t\treturn response, nil\n\t\t}\n\n\t\tfn2 := func(ctx context.Context) (*ResolveCheckResponse, error) {\n\t\t\tctx, span := tracer.Start(ctx, \"checkDirectUsersetTuples\", trace.WithAttributes(attribute.String(\"userset\", tuple.ToObjectRelationString(reqTupleKey.GetObject(), reqTupleKey.GetRelation()))))\n\t\t\tdefer span.End()\n\n\t\t\tif ctx.Err() != nil {\n\t\t\t\treturn nil, ctx.Err()\n\t\t\t}\n\n\t\t\tresponse := &ResolveCheckResponse{\n\t\t\t\tAllowed: false,\n\t\t\t\tResolutionMetadata: &ResolveCheckResponseMetadata{\n\t\t\t\t\tDatastoreQueryCount: req.GetRequestMetadata().DatastoreQueryCount,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\titer, err := ds.ReadUsersetTuples(ctx, storeID, storage.ReadUsersetTuplesFilter{\n\t\t\t\tObject:                      reqTupleKey.GetObject(),\n\t\t\t\tRelation:                    reqTupleKey.GetRelation(),\n\t\t\t\tAllowedUserTypeRestrictions: directlyRelatedUsersetTypes,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn response, err\n\t\t\t}\n\t\t\tdefer iter.Stop()\n\n\t\t\t// filter out invalid tuples yielded by the database iterator\n\t\t\tfilteredIter := storage.NewFilteredTupleKeyIterator(\n\t\t\t\tstorage.NewTupleKeyIteratorFromTupleIterator(iter),\n\t\t\t\tvalidation.FilterInvalidTuples(typesys),\n\t\t\t)\n\t\t\tdefer filteredIter.Stop()\n\n\t\t\tvar errs *multierror.Error\n\t\t\tvar handlers []CheckHandlerFunc\n\t\t\tfor {\n\t\t\t\tt, err := filteredIter.Next(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\tif errors.Is(err, storage.ErrIteratorDone) {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\treturn response, err\n\t\t\t\t}\n\n\t\t\t\tcondEvalResult, err := eval.EvaluateTupleCondition(ctx, t, typesys, req.GetContext())\n\t\t\t\tif err != nil {\n\t\t\t\t\terrs = multierror.Append(errs, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif len(condEvalResult.MissingParameters) > 0 {\n\t\t\t\t\terrs = multierror.Append(errs, condition.NewEvaluationError(\n\t\t\t\t\t\tt.GetCondition().GetName(),\n\t\t\t\t\t\tfmt.Errorf(\"tuple '%s' is missing context parameters '%v'\",\n\t\t\t\t\t\t\ttuple.TupleKeyToString(t),\n\t\t\t\t\t\t\tcondEvalResult.MissingParameters),\n\t\t\t\t\t))\n\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif !condEvalResult.ConditionMet {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tusersetObject, usersetRelation := tuple.SplitObjectRelation(t.GetUser())\n\n\t\t\t\t// if the user value is a typed wildcard and the type of the wildcard\n\t\t\t\t// matches the target user objectType, then we're done searching\n\t\t\t\tif tuple.IsTypedWildcard(usersetObject) && typesystem.IsSchemaVersionSupported(typesys.GetSchemaVersion()) {\n\t\t\t\t\twildcardType := tuple.GetType(usersetObject)\n\n\t\t\t\t\tif tuple.GetType(reqTupleKey.GetUser()) == wildcardType {\n\t\t\t\t\t\tspan.SetAttributes(attribute.Bool(\"allowed\", true))\n\t\t\t\t\t\tresponse.Allowed = true\n\t\t\t\t\t\treturn response, nil\n\t\t\t\t\t}\n\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif usersetRelation != \"\" {\n\t\t\t\t\ttupleKey := tuple.NewTupleKey(usersetObject, usersetRelation, reqTupleKey.GetUser())\n\t\t\t\t\thandlers = append(handlers, c.dispatch(ctx, req, tupleKey))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(handlers) == 0 && errs.ErrorOrNil() != nil {\n\t\t\t\ttelemetry.TraceError(span, errs)\n\t\t\t\treturn nil, errs\n\t\t\t}\n\n\t\t\tresp, err := union(ctx, c.concurrencyLimit, handlers...)\n\t\t\tif err != nil {\n\t\t\t\ttelemetry.TraceError(span, err)\n\t\t\t\treturn nil, multierror.Append(errs, err)\n\t\t\t}\n\n\t\t\treturn resp, nil\n\t\t}\n\n\t\tvar checkFuncs []CheckHandlerFunc\n\n\t\tshouldCheckDirectTuple, _ := typesys.IsDirectlyRelated(\n\t\t\ttypesystem.DirectRelationReference(objectType, relation),                                                           // target\n\t\t\ttypesystem.DirectRelationReference(tuple.GetType(reqTupleKey.GetUser()), tuple.GetRelation(reqTupleKey.GetUser())), // source\n\t\t)\n\n\t\tif shouldCheckDirectTuple {\n\t\t\tcheckFuncs = []CheckHandlerFunc{fn1}\n\t\t}\n\n\t\tif len(directlyRelatedUsersetTypes) > 0 {\n\t\t\tcheckFuncs = append(checkFuncs, fn2)\n\t\t}\n\n\t\tresp, err := union(ctx, c.concurrencyLimit, checkFuncs...)\n\t\tif err != nil {\n\t\t\ttelemetry.TraceError(span, err)\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// count db reads after they happen in the case that we didn't find 'allowed=false' but we still incurred reads\n\t\tif len(directlyRelatedUsersetTypes) > 0 {\n\t\t\t// if we had N userset checks, that was 1 read, not N\n\t\t\tresp.GetResolutionMetadata().DatastoreQueryCount++\n\t\t}\n\n\t\treturn resp, nil\n\t}\n}", "is_vulnerable": 1}
{"code": "func (f Formatter) nonStringKey(v any) string {\n\treturn fmt.Sprintf(\"<non-string-key: %s>\", f.snippet(v))\n}", "is_vulnerable": 0}
{"code": "func TestParseAnnotationsWithDefaultConfig(t *testing.T) {\n\ting := buildIngress()\n\n\tmockBackend := mockBackend{}\n\n\ttests := map[string]struct {\n\t\tnet        string\n\t\texpectCidr []string\n\t\texpectErr  bool\n\t\terrOut     string\n\t}{\n\t\t\"test parse a valid net\": {\n\t\t\tnet:        \"10.0.0.0/24\",\n\t\t\texpectCidr: []string{\"10.0.0.0/24\"},\n\t\t\texpectErr:  false,\n\t\t},\n\t\t\"test parse a invalid net\": {\n\t\t\tnet:       \"ww\",\n\t\t\texpectErr: true,\n\t\t\terrOut:    \"annotation nginx.ingress.kubernetes.io/allowlist-source-range contains invalid value\",\n\t\t},\n\t\t\"test parse a empty net\": {\n\t\t\tnet:       \"\",\n\t\t\texpectErr: true,\n\t\t\terrOut:    \"the annotation nginx.ingress.kubernetes.io/allowlist-source-range does not contain a valid value ()\",\n\t\t},\n\t\t\"test parse multiple valid cidr\": {\n\t\t\tnet:        \"2.2.2.2/32,1.1.1.1/32,3.3.3.0/24\",\n\t\t\texpectCidr: []string{\"1.1.1.1/32\", \"2.2.2.2/32\", \"3.3.3.0/24\"},\n\t\t\texpectErr:  false,\n\t\t},\n\t}\n\n\tfor testName, test := range tests {\n\t\tdata := map[string]string{}\n\t\tdata[parser.GetAnnotationWithPrefix(ipAllowlistAnnotation)] = test.net\n\t\ting.SetAnnotations(data)\n\t\tp := NewParser(mockBackend)\n\t\ti, err := p.Parse(ing)\n\t\tif (err != nil) != test.expectErr {\n\t\t\tt.Errorf(\"expected error: %t got error: %t err value: %s. %+v\", test.expectErr, err != nil, err, i)\n\t\t}\n\t\tif test.expectErr && err != nil {\n\t\t\tif err.Error() != test.errOut {\n\t\t\t\tt.Errorf(\"expected error %s but got %s\", test.errOut, err)\n\t\t\t}\n\t\t}\n\t\tif !test.expectErr {\n\t\t\tsr, ok := i.(*SourceRange)\n\t\t\tif !ok {\n\t\t\t\tt.Errorf(\"%v:expected a SourceRange type\", testName)\n\t\t\t}\n\t\t\tif !strsEquals(sr.CIDR, test.expectCidr) {\n\t\t\t\tt.Errorf(\"%v:expected %v CIDR but %v returned\", testName, test.expectCidr, sr.CIDR)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *CommonController) authErrExit() {\n\tc.SetJsonData(ResultDataStruct{Status: -1, Msg: \"Author error\", Data: nil})\n\tc.StopServeJSON()\n}", "is_vulnerable": 0}
{"code": "func TestStrictKEXResetSeqFirstKEX(t *testing.T) {\n\tif runtime.GOOS == \"plan9\" {\n\t\tt.Skip(\"see golang.org/issue/7237\")\n\t}\n\n\tchecker := &syncChecker{\n\t\twaitCall: make(chan int, 10),\n\t\tcalled:   make(chan int, 10),\n\t}\n\n\tchecker.waitCall <- 1\n\ttrC, trS, err := handshakePair(&ClientConfig{HostKeyCallback: checker.Check}, \"addr\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"handshakePair: %v\", err)\n\t}\n\t<-checker.called\n\n\tt.Cleanup(func() {\n\t\ttrC.Close()\n\t\ttrS.Close()\n\t})\n\n\t// Throw away the msgExtInfo packet sent during the handshake by the server\n\t_, err = trC.readPacket()\n\tif err != nil {\n\t\tt.Fatalf(\"readPacket failed: %s\", err)\n\t}\n\n\t// close the handshake transports before checking the sequence number to\n\t// avoid races.\n\ttrC.Close()\n\ttrS.Close()\n\n\t// check that the sequence number counters. We reset after msgNewKeys, but\n\t// then the server immediately writes msgExtInfo, and we close the\n\t// transports so we expect read 2, write 0 on the client and read 1, write 1\n\t// on the server.\n\tif trC.conn.(*transport).reader.seqNum != 2 || trC.conn.(*transport).writer.seqNum != 0 ||\n\t\ttrS.conn.(*transport).reader.seqNum != 1 || trS.conn.(*transport).writer.seqNum != 1 {\n\t\tt.Errorf(\n\t\t\t\"unexpected sequence counters:\\nclient: reader %d (expected 2), writer %d (expected 0)\\nserver: reader %d (expected 1), writer %d (expected 1)\",\n\t\t\ttrC.conn.(*transport).reader.seqNum,\n\t\t\ttrC.conn.(*transport).writer.seqNum,\n\t\t\ttrS.conn.(*transport).reader.seqNum,\n\t\t\ttrS.conn.(*transport).writer.seqNum,\n\t\t)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestUnsafeAllowPrivateRanges(t *testing.T) {\n\ta := assert.New(t)\n\n\tconf := NewConfig()\n\ta.NoError(conf.SetDenyRanges([]string{\"192.168.0.0/24\", \"10.0.0.0/8\"}))\n\tconf.ConnectTimeout = 10 * time.Second\n\tconf.ExitTimeout = 10 * time.Second\n\tconf.AdditionalErrorMessageOnDeny = \"Proxy denied\"\n\n\tconf.UnsafeAllowPrivateRanges = true\n\n\ttestIPs := []testCase{\n\t\ttestCase{\"8.8.8.8\", 1, ipAllowDefault},\n\n\t\t// Specific blocked networks\n\t\ttestCase{\"10.0.0.1\", 1, ipDenyUserConfigured},\n\t\ttestCase{\"10.0.0.1\", 321, ipDenyUserConfigured},\n\t\ttestCase{\"10.0.1.1\", 1, ipDenyUserConfigured},\n\t\ttestCase{\"172.16.0.1\", 1, ipAllowDefault},\n\t\ttestCase{\"172.16.1.1\", 1, ipAllowDefault},\n\t\ttestCase{\"192.168.0.1\", 1, ipDenyUserConfigured},\n\t\ttestCase{\"192.168.1.1\", 1, ipAllowDefault},\n\n\t\t// localhost\n\t\ttestCase{\"127.0.0.1\", 1, ipDenyNotGlobalUnicast},\n\t\ttestCase{\"127.255.255.255\", 1, ipDenyNotGlobalUnicast},\n\t\ttestCase{\"::1\", 1, ipDenyNotGlobalUnicast},\n\n\t\t// ec2 metadata endpoint\n\t\ttestCase{\"169.254.169.254\", 1, ipDenyNotGlobalUnicast},\n\n\t\t// Broadcast addresses\n\t\ttestCase{\"255.255.255.255\", 1, ipDenyNotGlobalUnicast},\n\t\ttestCase{\"ff02:0:0:0:0:0:0:2\", 1, ipDenyNotGlobalUnicast},\n\t}\n\n\tfor _, test := range testIPs {\n\t\tlocalIP := net.ParseIP(test.ip)\n\t\tif localIP == nil {\n\t\t\tt.Errorf(\"Could not parse IP from string: %s\", test.ip)\n\t\t\tcontinue\n\t\t}\n\t\tlocalAddr := net.TCPAddr{\n\t\t\tIP:   localIP,\n\t\t\tPort: test.port,\n\t\t}\n\n\t\tgot := classifyAddr(conf, &localAddr)\n\t\tif got != test.expected {\n\t\t\tt.Errorf(\"Misclassified IP (%s): should be %s, but is instead %s.\", localIP, test.expected, got)\n\t\t}\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func TestConfig_KeyPair_Valid(t *testing.T) {\n\tconf := &Config{\n\t\tCertFile: \"../test/key/ourdomain.cer\",\n\t\tKeyFile:  \"../test/key/ourdomain.key\",\n\t}\n\tcert, err := conf.KeyPair()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tif cert == nil {\n\t\tt.Fatalf(\"expected cert\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (as *AdminServer) registerRoutes() {\n\trouter := mux.NewRouter()\n\t// Base Front-end routes\n\trouter.HandleFunc(\"/\", mid.Use(as.Base, mid.RequireLogin))\n\trouter.HandleFunc(\"/login\", mid.Use(as.Login, as.limiter.Limit))\n\trouter.HandleFunc(\"/logout\", mid.Use(as.Logout, mid.RequireLogin))\n\trouter.HandleFunc(\"/reset_password\", mid.Use(as.ResetPassword, mid.RequireLogin))\n\trouter.HandleFunc(\"/campaigns\", mid.Use(as.Campaigns, mid.RequireLogin))\n\trouter.HandleFunc(\"/campaigns/{id:[0-9]+}\", mid.Use(as.CampaignID, mid.RequireLogin))\n\trouter.HandleFunc(\"/templates\", mid.Use(as.Templates, mid.RequireLogin))\n\trouter.HandleFunc(\"/groups\", mid.Use(as.Groups, mid.RequireLogin))\n\trouter.HandleFunc(\"/landing_pages\", mid.Use(as.LandingPages, mid.RequireLogin))\n\trouter.HandleFunc(\"/sending_profiles\", mid.Use(as.SendingProfiles, mid.RequireLogin))\n\trouter.HandleFunc(\"/settings\", mid.Use(as.Settings, mid.RequireLogin))\n\trouter.HandleFunc(\"/users\", mid.Use(as.UserManagement, mid.RequirePermission(models.PermissionModifySystem), mid.RequireLogin))\n\trouter.HandleFunc(\"/webhooks\", mid.Use(as.Webhooks, mid.RequirePermission(models.PermissionModifySystem), mid.RequireLogin))\n\trouter.HandleFunc(\"/impersonate\", mid.Use(as.Impersonate, mid.RequirePermission(models.PermissionModifySystem), mid.RequireLogin))\n\t// Create the API routes\n\tapi := api.NewServer(\n\t\tapi.WithWorker(as.worker),\n\t\tapi.WithLimiter(as.limiter),\n\t)\n\trouter.PathPrefix(\"/api/\").Handler(api)\n\n\t// Setup static file serving\n\trouter.PathPrefix(\"/\").Handler(http.FileServer(unindexed.Dir(\"./static/\")))\n\n\t// Setup CSRF Protection\n\tcsrfKey := []byte(as.config.CSRFKey)\n\tif len(csrfKey) == 0 {\n\t\tcsrfKey = []byte(auth.GenerateSecureKey(auth.APIKeyLength))\n\t}\n\tcsrfHandler := csrf.Protect(csrfKey,\n\t\tcsrf.FieldName(\"csrf_token\"),\n\t\tcsrf.Secure(as.config.UseTLS))\n\tadminHandler := csrfHandler(router)\n\tadminHandler = mid.Use(adminHandler.ServeHTTP, mid.CSRFExceptions, mid.GetContext, mid.ApplySecurityHeaders)\n\n\t// Setup GZIP compression\n\tgzipWrapper, _ := gziphandler.NewGzipLevelHandler(gzip.BestCompression)\n\tadminHandler = gzipWrapper(adminHandler)\n\n\t// Setup logging\n\tadminHandler = handlers.CombinedLoggingHandler(log.Writer(), adminHandler)\n\tas.server.Handler = adminHandler\n}", "is_vulnerable": 0}
{"code": "func (m *MockPKCERequestStorage) CreatePKCERequestSession(arg0 context.Context, arg1 string, arg2 fosite.Requester) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"CreatePKCERequestSession\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "\thandler := func(w http.ResponseWriter, r *http.Request) {\n\t\tgot <- r\n\t\tw.WriteHeader(http.StatusOK)\n\t}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetRequestedAt() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetRequestedAt\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetRequestedAt))\n}", "is_vulnerable": 0}
{"code": "func (c CanonType) Parse(s string) (t Tag, err error) {\n\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tt = Tag{}\n\t\t\terr = language.ErrSyntax\n\t\t}\n\t}()\n\n\ttt, err := language.Parse(s)\n\tif err != nil {\n\t\treturn makeTag(tt), err\n\t}\n\ttt, changed := canonicalize(c, tt)\n\tif changed {\n\t\ttt.RemakeString()\n\t}\n\treturn makeTag(tt), err\n}", "is_vulnerable": 0}
{"code": "func withDebug(debug bool) ctlOption {\n\treturn func(cx *ctlCtx) {\n\t\tcx.cfg.debug = debug\n\t}\n}", "is_vulnerable": 0}
{"code": "func Marshal(o interface{}) ([]byte, error) {\n\tj, err := json.Marshal(o)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error marshaling into JSON: %v\", err)\n\t}\n\n\ty, err := JSONToYAML(j)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error converting JSON to YAML: %v\", err)\n\t}\n\n\treturn y, nil\n}", "is_vulnerable": 1}
{"code": "func tweakCapabilities(basics, adds, drops []string) ([]string, error) {\n\t// Moby mixes 2 different capabilities formats: prefixed with \"CAP_\"\n\t// and not. We do the conversion here to have a consistent,\n\t// non-prefixed format on the Nomad side.\n\tfor i, cap := range basics {\n\t\tbasics[i] = \"CAP_\" + cap\n\t}\n\n\teffectiveCaps, err := caps.TweakCapabilities(basics, adds, drops, nil, false)\n\tif err != nil {\n\t\treturn effectiveCaps, err\n\t}\n\n\tfor i, cap := range effectiveCaps {\n\t\teffectiveCaps[i] = cap[len(\"CAP_\"):]\n\t}\n\n\treturn effectiveCaps, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Grep(ctx context.Context, in *sliverpb.GrepReq, opts ...grpc.CallOption) (*sliverpb.Grep, error) {\n\tout := new(sliverpb.Grep)\n\terr := c.cc.Invoke(ctx, SliverRPC_Grep_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func TestListObjectsRespectsMaxResults(t *testing.T, ds storage.OpenFGADatastore) {\n\ttestCases := []listObjectsTestCase{\n\t\t{\n\t\t\tname:   \"respects_when_schema_1_1_and_reverse_expansion_implementation\",\n\t\t\tschema: typesystem.SchemaVersion1_1,\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype repo\n\t\t\t  relations\n\t\t\t\tdefine admin: [user] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:       \"user:alice\",\n\t\t\tobjectType: \"repo\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgapb.TupleKey{tuple.NewTupleKey(\"repo:3\", \"admin\", \"user:alice\")},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"repo:1\", \"repo:2\", \"repo:3\"},\n\t\t},\n\t\t{\n\t\t\tname:   \"respects_when_schema_1_1_and_ttu_in_model_and_reverse_expansion_implementation\",\n\t\t\tschema: typesystem.SchemaVersion1_1,\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype folder\n\t\t\t  relations\n\t\t\t    define viewer: [user] as self\n\t\t\ttype document\n\t\t\t  relations\n\t\t\t    define parent: [folder] as self\n\t\t\t    define viewer as viewer from parent\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"folder:x\", \"viewer\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"folder:x\"),\n\t\t\t\ttuple.NewTupleKey(\"document:2\", \"parent\", \"folder:x\"),\n\t\t\t\ttuple.NewTupleKey(\"document:3\", \"parent\", \"folder:x\"),\n\t\t\t},\n\t\t\tuser:                   \"user:alice\",\n\t\t\tobjectType:             \"document\",\n\t\t\trelation:               \"viewer\",\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"document:1\", \"document:2\", \"document:3\"},\n\t\t},\n\t\t{\n\t\t\tname:   \"respects_when_schema_1_1_and_concurrent_checks_implementation\",\n\t\t\tschema: typesystem.SchemaVersion1_1,\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype org\n\t\t\t  relations\n\t\t\t\tdefine blocked: [user] as self\n\t\t\t\tdefine admin: [user] as self but not blocked\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"org:1\", \"admin\", \"user:charlie\"),\n\t\t\t\ttuple.NewTupleKey(\"org:2\", \"admin\", \"user:charlie\"),\n\t\t\t},\n\t\t\tuser:       \"user:charlie\",\n\t\t\tobjectType: \"org\",\n\t\t\trelation:   \"admin\",\n\t\t\tcontextualTuples: &openfgapb.ContextualTupleKeys{\n\t\t\t\tTupleKeys: []*openfgapb.TupleKey{tuple.NewTupleKey(\"org:3\", \"admin\", \"user:charlie\")},\n\t\t\t},\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 2,\n\t\t\tallResults:             []string{\"org:1\", \"org:2\", \"org:3\"},\n\t\t},\n\t\t{\n\t\t\tname:   \"respects_when_schema_1_1_and_maxresults_is_higher_than_actual_result_length\",\n\t\t\tschema: typesystem.SchemaVersion1_1,\n\t\t\tmodel: `\n\t\t\ttype user\n\n\t\t\ttype team\n\t\t\t  relations\n\t\t\t    define admin: [user] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"team:1\", \"admin\", \"user:bob\"),\n\t\t\t},\n\t\t\tuser:                   \"user:bob\",\n\t\t\tobjectType:             \"team\",\n\t\t\trelation:               \"admin\",\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 1,\n\t\t\tallResults:             []string{\"team:1\"},\n\t\t},\n\t\t{\n\t\t\tname:   \"respects_max_results_when_deadline_timeout_and_returns_no_error_and_no_results\",\n\t\t\tschema: typesystem.SchemaVersion1_1,\n\t\t\tmodel: `\n\t\t\ttype user\n\t\t\ttype repo\n\t\t\t  relations\n\t\t\t\tdefine admin: [user] as self\n\t\t\t`,\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:1\", \"admin\", \"user:alice\"),\n\t\t\t\ttuple.NewTupleKey(\"repo:2\", \"admin\", \"user:alice\"),\n\t\t\t},\n\t\t\tuser:                   \"user:alice\",\n\t\t\tobjectType:             \"repo\",\n\t\t\trelation:               \"admin\",\n\t\t\tmaxResults:             2,\n\t\t\tminimumResultsExpected: 0,\n\t\t\t// We expect empty array to be returned as list object will timeout due to readTuplesDelay > listObjectsDeadline\n\t\t\tallResults:          []string{},\n\t\t\tlistObjectsDeadline: 1 * time.Second,\n\t\t\treadTuplesDelay:     2 * time.Second, // We are mocking the ds to slow down the read call and simulate timeout\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\t\ttest := test\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\t\t\tctx := context.Background()\n\t\t\tstoreID := ulid.Make().String()\n\n\t\t\t// arrange: write model\n\t\t\tmodel := &openfgapb.AuthorizationModel{\n\t\t\t\tId:              ulid.Make().String(),\n\t\t\t\tSchemaVersion:   test.schema,\n\t\t\t\tTypeDefinitions: parser.MustParse(test.model),\n\t\t\t}\n\t\t\terr := ds.WriteAuthorizationModel(ctx, storeID, model)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// arrange: write tuples\n\t\t\terr = ds.Write(context.Background(), storeID, nil, test.tuples)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// act: run ListObjects\n\n\t\t\tlistObjectsDeadline := time.Minute\n\t\t\tif test.listObjectsDeadline > 0 {\n\t\t\t\tlistObjectsDeadline = test.listObjectsDeadline\n\t\t\t}\n\n\t\t\tdatastore := ds\n\t\t\tif test.readTuplesDelay > 0 {\n\t\t\t\tdatastore = mocks.NewMockSlowDataStorage(ds, test.readTuplesDelay)\n\t\t\t}\n\n\t\t\tlistObjectsQuery := &commands.ListObjectsQuery{\n\t\t\t\tDatastore:             datastore,\n\t\t\t\tLogger:                logger.NewNoopLogger(),\n\t\t\t\tListObjectsDeadline:   listObjectsDeadline,\n\t\t\t\tListObjectsMaxResults: test.maxResults,\n\t\t\t\tResolveNodeLimit:      defaultResolveNodeLimit,\n\t\t\t}\n\t\t\ttypesys := typesystem.New(model)\n\t\t\tctx = typesystem.ContextWithTypesystem(ctx, typesys)\n\n\t\t\t// assertions\n\t\t\tt.Run(\"streaming_endpoint\", func(t *testing.T) {\n\t\t\t\tserver := &mockStreamServer{\n\t\t\t\t\tchannel: make(chan string, len(test.allResults)),\n\t\t\t\t}\n\n\t\t\t\tdone := make(chan struct{})\n\t\t\t\tvar streamedObjectIds []string\n\t\t\t\tgo func() {\n\t\t\t\t\tfor x := range server.channel {\n\t\t\t\t\t\tstreamedObjectIds = append(streamedObjectIds, x)\n\t\t\t\t\t}\n\n\t\t\t\t\tdone <- struct{}{}\n\t\t\t\t}()\n\n\t\t\t\terr := listObjectsQuery.ExecuteStreamed(ctx, &openfgapb.StreamedListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t}, server)\n\t\t\t\tclose(server.channel)\n\t\t\t\t<-done\n\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.GreaterOrEqual(t, len(streamedObjectIds), int(test.minimumResultsExpected))\n\t\t\t\trequire.ElementsMatch(t, test.allResults, streamedObjectIds)\n\t\t\t})\n\n\t\t\tt.Run(\"regular_endpoint\", func(t *testing.T) {\n\t\t\t\tres, err := listObjectsQuery.Execute(ctx, &openfgapb.ListObjectsRequest{\n\t\t\t\t\tStoreId:          storeID,\n\t\t\t\t\tType:             test.objectType,\n\t\t\t\t\tRelation:         test.relation,\n\t\t\t\t\tUser:             test.user,\n\t\t\t\t\tContextualTuples: test.contextualTuples,\n\t\t\t\t})\n\n\t\t\t\trequire.NotNil(t, res)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.LessOrEqual(t, len(res.Objects), int(test.maxResults))\n\t\t\t\trequire.GreaterOrEqual(t, len(res.Objects), int(test.minimumResultsExpected))\n\t\t\t\trequire.Subset(t, test.allResults, res.Objects)\n\t\t\t})\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func setupEncryption(localIP, advIP, remoteIP net.IP, vni uint32, em *encrMap, keys []*key) error {\n\tlogrus.Debugf(\"Programming encryption for vxlan %d between %s and %s\", vni, localIP, remoteIP)\n\trIPs := remoteIP.String()\n\n\tindices := make([]*spi, 0, len(keys))\n\n\terr := programMangle(vni, true)\n\tif err != nil {\n\t\tlogrus.Warn(err)\n\t}\n\n\terr = programInput(vni, true)\n\tif err != nil {\n\t\tlogrus.Warn(err)\n\t}\n\n\tfor i, k := range keys {\n\t\tspis := &spi{buildSPI(advIP, remoteIP, k.tag), buildSPI(remoteIP, advIP, k.tag)}\n\t\tdir := reverse\n\t\tif i == 0 {\n\t\t\tdir = bidir\n\t\t}\n\t\tfSA, rSA, err := programSA(localIP, remoteIP, spis, k, dir, true)\n\t\tif err != nil {\n\t\t\tlogrus.Warn(err)\n\t\t}\n\t\tindices = append(indices, spis)\n\t\tif i != 0 {\n\t\t\tcontinue\n\t\t}\n\t\terr = programSP(fSA, rSA, true)\n\t\tif err != nil {\n\t\t\tlogrus.Warn(err)\n\t\t}\n\t}\n\n\tem.Lock()\n\tem.nodes[rIPs] = indices\n\tem.Unlock()\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestVariablesEndpoint_auth(t *testing.T) {\n\n\tci.Parallel(t)\n\tsrv, _, shutdown := TestACLServer(t, func(c *Config) {\n\t\tc.NumSchedulers = 0 // Prevent automatic dequeue\n\t})\n\tdefer shutdown()\n\ttestutil.WaitForLeader(t, srv.RPC)\n\n\tconst ns = \"nondefault-namespace\"\n\n\talloc1 := mock.Alloc()\n\talloc1.ClientStatus = structs.AllocClientStatusFailed\n\talloc1.Job.Namespace = ns\n\talloc1.Namespace = ns\n\tjobID := alloc1.JobID\n\n\t// create an alloc that will have no access to variables we create\n\talloc2 := mock.Alloc()\n\talloc2.Job.TaskGroups[0].Name = \"other-no-permissions\"\n\talloc2.TaskGroup = \"other-no-permissions\"\n\talloc2.ClientStatus = structs.AllocClientStatusRunning\n\talloc2.Job.Namespace = ns\n\talloc2.Namespace = ns\n\n\talloc3 := mock.Alloc()\n\talloc3.ClientStatus = structs.AllocClientStatusRunning\n\talloc3.Job.Namespace = ns\n\talloc3.Namespace = ns\n\talloc3.Job.ParentID = jobID\n\n\tstore := srv.fsm.State()\n\tmust.NoError(t, store.UpsertNamespaces(1000, []*structs.Namespace{{Name: ns}}))\n\tmust.NoError(t, store.UpsertAllocs(\n\t\tstructs.MsgTypeTestSetup, 1001, []*structs.Allocation{alloc1, alloc2, alloc3}))\n\n\tclaims1 := alloc1.ToTaskIdentityClaims(nil, \"web\")\n\tidToken, err := srv.encrypter.SignClaims(claims1)\n\tmust.NoError(t, err)\n\n\tclaims2 := alloc2.ToTaskIdentityClaims(nil, \"web\")\n\tnoPermissionsToken, err := srv.encrypter.SignClaims(claims2)\n\tmust.NoError(t, err)\n\n\tclaims3 := alloc3.ToTaskIdentityClaims(alloc3.Job, \"web\")\n\tidDispatchToken, err := srv.encrypter.SignClaims(claims3)\n\tmust.NoError(t, err)\n\n\t// corrupt the signature of the token\n\tidTokenParts := strings.Split(idToken, \".\")\n\tmust.Len(t, 3, idTokenParts)\n\tsig := []string(strings.Split(idTokenParts[2], \"\"))\n\trand.Shuffle(len(sig), func(i, j int) {\n\t\tsig[i], sig[j] = sig[j], sig[i]\n\t})\n\tidTokenParts[2] = strings.Join(sig, \"\")\n\tinvalidIDToken := strings.Join(idTokenParts, \".\")\n\n\tpolicy := mock.ACLPolicy()\n\tpolicy.Rules = `namespace \"nondefault-namespace\" {\n\t\tvariables {\n\t\t    path \"nomad/jobs/*\" { capabilities = [\"list\"] }\n\t\t    path \"other/path\" { capabilities = [\"read\"] }\n\t\t}}`\n\tpolicy.JobACL = &structs.JobACL{\n\t\tNamespace: ns,\n\t\tJobID:     jobID,\n\t\tGroup:     alloc1.TaskGroup,\n\t}\n\tpolicy.SetHash()\n\terr = store.UpsertACLPolicies(structs.MsgTypeTestSetup, 1100, []*structs.ACLPolicy{policy})\n\tmust.NoError(t, err)\n\n\taclToken := mock.ACLToken()\n\taclToken.Policies = []string{policy.Name}\n\terr = store.UpsertACLTokens(structs.MsgTypeTestSetup, 1150, []*structs.ACLToken{aclToken})\n\tmust.NoError(t, err)\n\n\tt.Run(\"terminal alloc should be denied\", func(t *testing.T) {\n\t\t_, err = srv.staticEndpoints.Variables.handleMixedAuthEndpoint(\n\t\t\tstructs.QueryOptions{AuthToken: idToken, Namespace: ns}, \"n/a\",\n\t\t\tfmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID))\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t})\n\n\t// make alloc non-terminal\n\talloc1.ClientStatus = structs.AllocClientStatusRunning\n\tmust.NoError(t, store.UpsertAllocs(\n\t\tstructs.MsgTypeTestSetup, 1200, []*structs.Allocation{alloc1}))\n\n\tt.Run(\"wrong namespace should be denied\", func(t *testing.T) {\n\t\t_, err = srv.staticEndpoints.Variables.handleMixedAuthEndpoint(\n\t\t\tstructs.QueryOptions{AuthToken: idToken, Namespace: structs.DefaultNamespace}, \"n/a\",\n\t\t\tfmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID))\n\t\tmust.EqError(t, err, structs.ErrPermissionDenied.Error())\n\t})\n\n\ttestCases := []struct {\n\t\tname        string\n\t\ttoken       string\n\t\tcap         string\n\t\tpath        string\n\t\texpectedErr error\n\t}{\n\t\t{\n\t\t\tname:        \"valid claim for path with task secret\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID),\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for path with group secret\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web\", jobID),\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for path with job secret\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s\", jobID),\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for path with dispatch job secret\",\n\t\t\ttoken:       idDispatchToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s\", jobID),\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for path with namespace secret\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        \"nomad/jobs\",\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for job-attached policy\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         acl.PolicyRead,\n\t\t\tpath:        \"other/path\",\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for job-attached policy path denied\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         acl.PolicyRead,\n\t\t\tpath:        \"other/not-allowed\",\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for job-attached policy capability denied\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         acl.PolicyWrite,\n\t\t\tpath:        \"other/path\",\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim for job-attached policy capability with cross-job access\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         acl.PolicyList,\n\t\t\tpath:        \"nomad/jobs/some-other\",\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim with no permissions denied by path\",\n\t\t\ttoken:       noPermissionsToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/w\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim with no permissions allowed by namespace\",\n\t\t\ttoken:       noPermissionsToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        \"nomad/jobs\",\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"valid claim with no permissions denied by capability\",\n\t\t\ttoken:       noPermissionsToken,\n\t\t\tcap:         acl.PolicyRead,\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/w\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"extra trailing slash is denied\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid prefix is denied\",\n\t\t\ttoken:       idToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/w\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"missing auth token is denied\",\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid signature is denied\",\n\t\t\ttoken:       invalidIDToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid claim for dispatched ID\",\n\t\t\ttoken:       idDispatchToken,\n\t\t\tcap:         \"n/a\",\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s\", alloc3.JobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t\t{\n\t\t\tname:        \"acl token read policy is allowed to list\",\n\t\t\ttoken:       aclToken.SecretID,\n\t\t\tcap:         acl.PolicyList,\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID),\n\t\t\texpectedErr: nil,\n\t\t},\n\t\t{\n\t\t\tname:        \"acl token read policy is not allowed to write\",\n\t\t\ttoken:       aclToken.SecretID,\n\t\t\tcap:         acl.PolicyWrite,\n\t\t\tpath:        fmt.Sprintf(\"nomad/jobs/%s/web/web\", jobID),\n\t\t\texpectedErr: structs.ErrPermissionDenied,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\t_, err := srv.staticEndpoints.Variables.handleMixedAuthEndpoint(\n\t\t\t\tstructs.QueryOptions{AuthToken: tc.token, Namespace: ns}, tc.cap, tc.path)\n\t\t\tif tc.expectedErr == nil {\n\t\t\t\tmust.NoError(t, err)\n\t\t\t} else {\n\t\t\t\tmust.EqError(t, err, tc.expectedErr.Error())\n\t\t\t}\n\t\t})\n\t}\n\n}", "is_vulnerable": 1}
{"code": "func TestAPIEndpoint_Metrics_PluginDecryptionFailure(t *testing.T) {\n\tqds := query.ProvideService(\n\t\tsetting.NewCfg(),\n\t\tnil,\n\t\tnil,\n\t\t&fakePluginRequestValidator{},\n\t\t&fakeDatasources.FakeDataSourceService{SimulatePluginFailure: true},\n\t\t&fakePluginClient{\n\t\t\tQueryDataHandlerFunc: func(ctx context.Context, req *backend.QueryDataRequest) (*backend.QueryDataResponse, error) {\n\t\t\t\tresp := backend.Responses{\n\t\t\t\t\t\"A\": backend.DataResponse{\n\t\t\t\t\t\tError: fmt.Errorf(\"query failed\"),\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\treturn &backend.QueryDataResponse{Responses: resp}, nil\n\t\t\t},\n\t\t},\n\t\t&fakeOAuthTokenService{},\n\t)\n\thttpServer := SetupAPITestServer(t, func(hs *HTTPServer) {\n\t\ths.queryDataService = qds\n\t\ths.QuotaService = quotatest.NewQuotaServiceFake()\n\t})\n\n\tt.Run(\"Status code is 500 and a secrets plugin error is returned if there is a problem getting secrets from the remote plugin\", func(t *testing.T) {\n\t\treq := httpServer.NewPostRequest(\"/api/ds/query\", strings.NewReader(queryDatasourceInput))\n\t\twebtest.RequestWithSignedInUser(req, &models.SignedInUser{UserId: 1, OrgId: 1, OrgRole: models.ROLE_VIEWER})\n\t\tresp, err := httpServer.SendJSON(req)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, http.StatusInternalServerError, resp.StatusCode)\n\t\tbuf := new(bytes.Buffer)\n\t\t_, err = buf.ReadFrom(resp.Body)\n\t\trequire.NoError(t, err)\n\t\trequire.NoError(t, resp.Body.Close())\n\t\tvar resObj secretsErrorResponseBody\n\t\terr = json.Unmarshal(buf.Bytes(), &resObj)\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, \"unknown error\", resObj.Error)\n\t\trequire.Contains(t, resObj.Message, \"Secrets Plugin error:\")\n\t})\n}", "is_vulnerable": 0}
{"code": "func TestCheckPermissionOverSchema(t *testing.T) {\n\ttestCases := []struct {\n\t\tname                   string\n\t\tschema                 string\n\t\trelationships          []*core.RelationTuple\n\t\tresource               *core.ObjectAndRelation\n\t\tsubject                *core.ObjectAndRelation\n\t\texpectedPermissionship v1.ResourceCheckResult_Membership\n\t\texpectedCaveat         *core.CaveatExpression\n\t}{\n\t\t{\n\t\t\t\"basic union\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic intersection\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer & editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#editor@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic exclusion\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic union, multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#editor@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic union no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic intersection no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer & editor\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic exclusion no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation banned: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - banned\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#viewer@user:tom\"),\n\t\t\t\ttuple.MustParse(\"document:first#banned@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"exclusion with multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation banned: user\n\t\t\t \tpermission view = member - banned\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#banned@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"intersection with multiple branches\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation other: user\n\t\t\t \tpermission view = member & other\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#other@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"exclusion with multiple branches no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation banned: user\n\t\t\t \tpermission view = member - banned\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:first#banned@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#banned@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"intersection with multiple branches no permission\",\n\t\t\t`definition user {}\n\t\t\n\t\t\t definition group {\n\t\t\t \trelation member: user\n\t\t\t\trelation other: user\n\t\t\t \tpermission view = member & other\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation group: group\n\t\t\t\tpermission view = group->view\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#group@group:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#group@group:second\"),\n\t\t\t\ttuple.MustParse(\"group:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"group:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic arrow\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs->member\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic any arrow\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.any(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow negative\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive with different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow negative over different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@someotherresource:other\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"basic all arrow positive over different types\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\n\t\t\t definition someotherresource {\n\t\t\t  \trelation member: user\n  \t\t\t}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization | someotherresource\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:second\"),\n\t\t\t\ttuple.MustParse(\"document:first#orgs@someotherresource:other\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"organization:second#member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"someotherresource:other#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"all arrow for single org\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"document:first#orgs@organization:first\"),\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"all arrow for no orgs\",\n\t\t\t`definition user {}\n\n\t\t\t definition organization {\n\t\t\t \trelation member: user\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation orgs: organization\n\t\t\t\tpermission view = orgs.all(member)\n  \t\t\t }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"organization:first#member@user:tom\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"first\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_all negative\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n    permission view_by_any = team.any(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"threeteams\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_any positive\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n\trelation viewer: user\n    permission view_by_all = team.all(member) + viewer\n    permission view_by_any = team.any(member) + viewer\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#viewer@user:rachel\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"threeteams\", \"view_by_any\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"view_by_any positive directly\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  definition resource {\n    relation team: team\n\trelation viewer: user\n    permission view_by_all = team.all(member) + viewer\n    permission view_by_any = team.any(member) + viewer\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:fred\"),\n\t\t\t\ttuple.MustParse(\"team:second#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"team:third#direct_member@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:twoteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:first\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:second\"),\n\t\t\t\ttuple.MustParse(\"resource:threeteams#team@team:third\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#viewer@user:rachel\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_any\"),\n\t\t\tONR(\"user\", \"rachel\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first[somecaveat]\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t},\n\t\t{\n\t\t\t\"intersection arrow with caveated member\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom[somecaveat]\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with caveated member\",\n\t\t\t`  definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"team:first#direct_member@user:tom[somecaveat]\"),\n\t\t\t\ttuple.MustParse(\"resource:oneteam#team@team:first[somecaveat]\"),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with caveated member, different context\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with anothercaveat\n    permission member = direct_member\n  }\n\n  caveat anothercaveat(someparam int) {\n    someparam == 43\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam == 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom[anothercaveat:{\"someparam\": 43}]`),\n\t\t\t\ttuple.MustParse(`resource:oneteam#team@team:first[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"oneteam\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"anothercaveat\", map[string]any{\"someparam\": int64(43)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with multiple caveated branches\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first[somecaveat:{\"someparam\": 41}]`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second[somecaveat:{\"someparam\": 42}]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(41)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t},\n\n\t\t{\n\t\t\t\"caveated intersection arrow with multiple caveated members\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom[somecaveat:{\"someparam\": 41}]`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAnd(\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(41)}),\n\t\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t\t),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with one caveated branch\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat | team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second[somecaveat:{\"someparam\": 42}]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow with one caveated member\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user with somecaveat\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team\n    permission view_by_all = team.all(member)\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:second`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t\ttuple.MustParse(`team:second#direct_member@user:tom[somecaveat:{\"someparam\": 42}]`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", map[string]any{\"someparam\": int64(42)}),\n\t\t},\n\t\t{\n\t\t\t\"caveated intersection arrow multiple paths to the same subject\",\n\t\t\t`definition user {}\n\n  definition team {\n    relation direct_member: user\n    permission member = direct_member\n  }\n\n  caveat somecaveat(someparam int) {\n    someparam >= 42\n  }\n\n  definition resource {\n    relation team: team with somecaveat | team#direct_member with somecaveat\n    permission view_by_all = team.all(member) // Note: this points to the same team twice\n  }`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first`),\n\t\t\t\ttuple.MustParse(`resource:someresource#team@team:first#direct_member[somecaveat]`),\n\t\t\t\ttuple.MustParse(`team:first#direct_member@user:tom`),\n\t\t\t},\n\t\t\tONR(\"resource\", \"someresource\", \"view_by_all\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_CAVEATED_MEMBER,\n\t\t\tcaveatAndCtx(\"somecaveat\", nil),\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow positive result\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow negative result\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"recursive all arrow negative result due to recursion missing a folder\",\n\t\t\t`definition user {}\n\n\t\t\tdefinition folder {\n\t\t\t\trelation parent: folder\n\t\t\t\trelation owner: user\n\n\t\t\t\tpermission view = parent.all(owner)\n\t\t\t}\n\n\t\t\tdefinition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder.all(view)\n\t\t\t}`,\n\t\t\t[]*core.RelationTuple{\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:tom\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root1#owner@user:sarah\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:fred\"),\n\t\t\t\ttuple.MustParse(\"folder:root2#owner@user:sarah\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root2\"),\n\t\t\t\ttuple.MustParse(\"folder:child1#parent@folder:root3\"),\n\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root1\"),\n\t\t\t\ttuple.MustParse(\"folder:child2#parent@folder:root2\"),\n\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child1\"),\n\t\t\t\ttuple.MustParse(\"document:doc1#folder@folder:child2\"),\n\t\t\t},\n\t\t\tONR(\"document\", \"doc1\", \"view\"),\n\t\t\tONR(\"user\", \"fred\", \"...\"),\n\t\t\tv1.ResourceCheckResult_NOT_MEMBER,\n\t\t\tnil,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\trequire := require.New(t)\n\n\t\t\tdispatcher := NewLocalOnlyDispatcher(10, 100)\n\n\t\t\tds, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\t\t\trequire.NoError(err)\n\n\t\t\tds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(ds, tc.schema, tc.relationships, require)\n\n\t\t\tctx := datastoremw.ContextWithHandle(context.Background())\n\t\t\trequire.NoError(datastoremw.SetInContext(ctx, ds))\n\n\t\t\tresp, err := dispatcher.DispatchCheck(ctx, &v1.DispatchCheckRequest{\n\t\t\t\tResourceRelation: RR(tc.resource.Namespace, tc.resource.Relation),\n\t\t\t\tResourceIds:      []string{tc.resource.ObjectId},\n\t\t\t\tSubject:          tc.subject,\n\t\t\t\tMetadata: &v1.ResolverMeta{\n\t\t\t\t\tAtRevision:     revision.String(),\n\t\t\t\t\tDepthRemaining: 50,\n\t\t\t\t},\n\t\t\t\tResultsSetting: v1.DispatchCheckRequest_ALLOW_SINGLE_RESULT,\n\t\t\t})\n\t\t\trequire.NoError(err)\n\n\t\t\tmembership := v1.ResourceCheckResult_NOT_MEMBER\n\t\t\tif r, ok := resp.ResultsByResourceId[tc.resource.ObjectId]; ok {\n\t\t\t\tmembership = r.Membership\n\t\t\t}\n\n\t\t\trequire.Equal(tc.expectedPermissionship, membership)\n\n\t\t\tif tc.expectedCaveat != nil {\n\t\t\t\trequire.NotEmpty(resp.ResultsByResourceId[tc.resource.ObjectId].Expression)\n\t\t\t\ttestutil.RequireProtoEqual(t, tc.expectedCaveat, resp.ResultsByResourceId[tc.resource.ObjectId].Expression, \"mismatch in caveat\")\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (this *Stats) Equal(that interface{}) bool {\n\tif that == nil {\n\t\treturn this == nil\n\t}\n\n\tthat1, ok := that.(*Stats)\n\tif !ok {\n\t\tthat2, ok := that.(Stats)\n\t\tif ok {\n\t\t\tthat1 = &that2\n\t\t} else {\n\t\t\treturn false\n\t\t}\n\t}\n\tif that1 == nil {\n\t\treturn this == nil\n\t} else if this == nil {\n\t\treturn false\n\t}\n\tif this.WallTime != that1.WallTime {\n\t\treturn false\n\t}\n\tif this.FetchedSeriesCount != that1.FetchedSeriesCount {\n\t\treturn false\n\t}\n\tif this.FetchedChunkBytes != that1.FetchedChunkBytes {\n\t\treturn false\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func ConvertODT(r io.Reader) (string, map[string]string, error) {\n\tmeta := make(map[string]string)\n\tvar textBody string\n\n\tb, err := ioutil.ReadAll(r)\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\tzr, err := zip.NewReader(bytes.NewReader(b), int64(len(b)))\n\tif err != nil {\n\t\treturn \"\", nil, fmt.Errorf(\"error unzipping data: %v\", err)\n\t}\n\n\tfor _, f := range zr.File {\n\t\tswitch f.Name {\n\t\tcase \"meta.xml\":\n\t\t\trc, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"error extracting '%v' from archive: %v\", f.Name, err)\n\t\t\t}\n\t\t\tdefer rc.Close()\n\n\t\t\tinfo, err := XMLToMap(rc)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"error parsing '%v': %v\", f.Name, err)\n\t\t\t}\n\n\t\t\tif tmp, ok := info[\"creator\"]; ok {\n\t\t\t\tmeta[\"Author\"] = tmp\n\t\t\t}\n\t\t\tif tmp, ok := info[\"date\"]; ok {\n\t\t\t\tif t, err := time.Parse(\"2006-01-02T15:04:05\", tmp); err == nil {\n\t\t\t\t\tmeta[\"ModifiedDate\"] = fmt.Sprintf(\"%d\", t.Unix())\n\t\t\t\t}\n\t\t\t}\n\t\t\tif tmp, ok := info[\"creation-date\"]; ok {\n\t\t\t\tif t, err := time.Parse(\"2006-01-02T15:04:05\", tmp); err == nil {\n\t\t\t\t\tmeta[\"CreatedDate\"] = fmt.Sprintf(\"%d\", t.Unix())\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"content.xml\":\n\t\t\trc, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"error extracting '%v' from archive: %v\", f.Name, err)\n\t\t\t}\n\t\t\tdefer rc.Close()\n\n\t\t\ttextBody, err = XMLToText(rc, []string{\"br\", \"p\", \"tab\"}, []string{}, true)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"error parsing '%v': %v\", f.Name, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn textBody, meta, nil\n}", "is_vulnerable": 1}
{"code": "\t\tvar funcs []func() (bool, error)\n\n\t\tif !exists {\n\t\t\tsecretType := secretutil.GetSecretType(strings.TrimSpace(secretObj.Type))\n\n\t\t\tdatamap := make(map[string][]byte)\n\t\t\tif datamap, err = secretutil.GetSecretData(secretObj.Data, secretType, files); err != nil {\n\t\t\t\tr.generateEvent(podObjectReference, corev1.EventTypeWarning, secretCreationFailedReason, fmt.Sprintf(\"failed to get data in spc %s/%s for secret %s, err: %+v\", req.Namespace, spcName, secretName, err))\n\t\t\t\tlog.Errorf(\"failed to get data in spc %s/%s for secret %s, err: %+v\", req.Namespace, spcName, secretName, err)\n\t\t\t\terrs = append(errs, fmt.Errorf(\"failed to get data in spc %s/%s for secret %s, err: %+v\", req.Namespace, spcName, secretName, err))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tlabelsMap := make(map[string]string)\n\t\t\tif secretObj.Labels != nil {\n\t\t\t\tlabelsMap = secretObj.Labels\n\t\t\t}\n\t\t\t// Set secrets-store.csi.k8s.io/managed=true label on the secret that's created and managed\n\t\t\t// by the secrets-store-csi-driver. This label will be used to perform a filtered list watch\n\t\t\t// only on secrets created and managed by the driver\n\t\t\tlabelsMap[secretManagedLabel] = \"true\"\n\n\t\t\tcreateFn := func() (bool, error) {\n\t\t\t\tif err := r.createK8sSecret(ctx, secretName, req.Namespace, datamap, labelsMap, secretType); err != nil {\n\t\t\t\t\tlogger.Errorf(\"failed createK8sSecret, err: %v for secret: %s\", err, secretName)\n\t\t\t\t\treturn false, nil\n\t\t\t\t}\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t\tfuncs = append(funcs, createFn)\n\t\t}\n\n\t\tfor _, f := range funcs {\n\t\t\tif err := wait.ExponentialBackoff(wait.Backoff{\n\t\t\t\tSteps:    5,\n\t\t\t\tDuration: 1 * time.Millisecond,\n\t\t\t\tFactor:   1.0,\n\t\t\t\tJitter:   0.1,\n\t\t\t}, f); err != nil {\n\t\t\t\tr.generateEvent(podObjectReference, corev1.EventTypeWarning, secretCreationFailedReason, err.Error())\n\t\t\t\treturn ctrl.Result{RequeueAfter: 5 * time.Second}, err\n\t\t\t}\n\t\t}\n\t}\n\n\tif len(errs) > 0 {\n\t\treturn ctrl.Result{Requeue: true}, nil\n\t}\n\n\tlogger.Info(\"reconcile complete\")\n\t// requeue the spc pod status again after 5mins to check if secret and ownerRef exists\n\t// and haven't been modified. If secret doesn't exist, then this requeue will ensure it's\n\t// created in the next reconcile and the owner ref patched again\n\treturn ctrl.Result{RequeueAfter: 5 * time.Minute}, nil\n}", "is_vulnerable": 1}
{"code": "func (p *BinaryProtocol) ReadMapBegin() (kType, vType Type, size int, err error) {\n\tk, e := p.ReadByte()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\tkType = Type(k)\n\tv, e := p.ReadByte()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\tvType = Type(v)\n\tsize32, e := p.ReadI32()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\tif size32 < 0 {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tif uint64(size32*2) > p.trans.RemainingBytes() || p.trans.RemainingBytes() == UnknownRemaining {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tsize = int(size32)\n\treturn kType, vType, size, nil\n}", "is_vulnerable": 0}
{"code": "func (c *Conn) DATA(params string) (code int, msg string) {\n\tif c.ehloDomain == \"\" {\n\t\treturn 503, \"5.5.1 Invisible customers are not welcome!\"\n\t}\n\tif c.mailFrom == \"\" {\n\t\treturn 503, \"5.5.1 Sender not yet given\"\n\t}\n\tif len(c.rcptTo) == 0 {\n\t\treturn 503, \"5.5.1 Need an address to send to\"\n\t}\n\n\t// We're going ahead.\n\terr := c.writeResponse(354, \"You suddenly realize it is unnaturally quiet\")\n\tif err != nil {\n\t\treturn 554, fmt.Sprintf(\"5.4.0 Error writing DATA response: %v\", err)\n\t}\n\n\tc.tr.Debugf(\"<- 354  You experience a strange sense of peace\")\n\tif c.onTLS {\n\t\ttlsCount.Add(\"tls\", 1)\n\t} else {\n\t\ttlsCount.Add(\"plain\", 1)\n\t}\n\n\t// Increase the deadline for the data transfer to the connection-level\n\t// one, we don't want the command timeout to interfere.\n\tc.conn.SetDeadline(c.deadline)\n\n\t// Create a dot reader, limited to the maximum size.\n\tdotr := textproto.NewReader(bufio.NewReader(\n\t\tio.LimitReader(c.reader, c.maxDataSize))).DotReader()\n\tc.data, err = io.ReadAll(dotr)\n\tif err != nil {\n\t\tif err == io.ErrUnexpectedEOF {\n\t\t\t// Message is too big already. But we need to keep reading until we see\n\t\t\t// the \"\\r\\n.\\r\\n\", otherwise we will treat the remanent data that\n\t\t\t// the user keeps sending as commands, and that's a security\n\t\t\t// issue.\n\t\t\treadUntilDot(c.reader)\n\t\t\treturn 552, \"5.3.4 Message too big\"\n\t\t}\n\t\treturn 554, fmt.Sprintf(\"5.4.0 Error reading DATA: %v\", err)\n\t}\n\n\tc.tr.Debugf(\"-> ... %d bytes of data\", len(c.data))\n\n\tif err := checkData(c.data); err != nil {\n\t\tmaillog.Rejected(c.remoteAddr, c.mailFrom, c.rcptTo, err.Error())\n\t\treturn 554, err.Error()\n\t}\n\n\tc.addReceivedHeader()\n\n\thookOut, permanent, err := c.runPostDataHook(c.data)\n\tif err != nil {\n\t\tmaillog.Rejected(c.remoteAddr, c.mailFrom, c.rcptTo, err.Error())\n\t\tif permanent {\n\t\t\treturn 554, err.Error()\n\t\t}\n\t\treturn 451, err.Error()\n\t}\n\tc.data = append(hookOut, c.data...)\n\n\t// There are no partial failures here: we put it in the queue, and then if\n\t// individual deliveries fail, we report via email.\n\t// If we fail to queue, return a transient error.\n\tmsgID, err := c.queue.Put(c.tr, c.mailFrom, c.rcptTo, c.data)\n\tif err != nil {\n\t\treturn 451, fmt.Sprintf(\"4.3.0 Failed to queue message: %v\", err)\n\t}\n\n\tc.tr.Printf(\"Queued from %s to %s - %s\", c.mailFrom, c.rcptTo, msgID)\n\tmaillog.Queued(c.remoteAddr, c.mailFrom, c.rcptTo, msgID)\n\n\t// It is very important that we reset the envelope before returning,\n\t// so clients can send other emails right away without needing to RSET.\n\tc.resetEnvelope()\n\n\tmsgs := []string{\n\t\t\"You offer the Amulet of Yendor to Anhur...\",\n\t\t\"An invisible choir sings, and you are bathed in radiance...\",\n\t\t\"The voice of Anhur booms out: Congratulations, mortal!\",\n\t\t\"In return to thy service, I grant thee the gift of Immortality!\",\n\t\t\"You ascend to the status of Demigod(dess)...\",\n\t}\n\treturn 250, \"2.0.0 \" + msgs[rand.Int()%len(msgs)]\n}", "is_vulnerable": 1}
{"code": "func TestStringToURL(t *testing.T) {\n\tvalidURL := \"http://bar.foo.com/external-auth\"\n\tvalidParsedURL, _ := url.Parse(validURL)\n\n\ttests := []struct {\n\t\ttitle   string\n\t\turl     string\n\t\tmessage string\n\t\tparsed  *url.URL\n\t\texpErr  bool\n\t}{\n\t\t{\"empty\", \"\", \"url scheme is empty\", nil, true},\n\t\t{\"no scheme\", \"bar\", \"url scheme is empty\", nil, true},\n\t\t{\"invalid parse\", \"://lala.com\", \"://lala.com is not a valid URL: parse \\\"://lala.com\\\": missing protocol scheme\", nil, true},\n\t\t{\"invalid host\", \"http://\", \"url host is empty\", nil, true},\n\t\t{\"invalid host (multiple dots)\", \"http://foo..bar.com\", \"invalid url host\", nil, true},\n\t\t{\"valid URL\", validURL, \"\", validParsedURL, false},\n\t}\n\n\tfor _, test := range tests {\n\t\ti, err := StringToURL(test.url)\n\t\tif test.expErr {\n\t\t\tif err == nil {\n\t\t\t\tt.Fatalf(\"%v: expected error but none returned\", test.title)\n\t\t\t}\n\n\t\t\tif err.Error() != test.message {\n\t\t\t\tt.Errorf(\"%v: expected error \\\"%v\\\" but \\\"%v\\\" was returned\", test.title, test.message, err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif i.String() != test.parsed.String() {\n\t\t\tt.Errorf(\"%v: expected \\\"%v\\\" but \\\"%v\\\" was returned\", test.title, test.parsed, i)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (fs *Quota) Remove(name string) error {\n\t// For information on why this interface is used here, check its\n\t// documentation.\n\ts, err := fs.RemoveStat(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Don't reduce the quota's usage as `name` is not a regular file.\n\tif !s.Mode().IsRegular() {\n\t\treturn nil\n\t}\n\n\t// Remove the size of the deleted file from the quota usage.\n\tfs.Add(-s.Size())\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestAES_GCM_NIST_gcmEncryptExtIV256_PTLen_104_Test_3(t *testing.T) {\n\tiv, _ := hex.DecodeString(\"4742357c335913153ff0eb0f\")\n\tkey, _ := hex.DecodeString(\"e5a0eb92cc2b064e1bc80891faf1fab5e9a17a9c3a984e25416720e30e6c2b21\")\n\tplaintext, _ := hex.DecodeString(\"8499893e16b0ba8b007d54665a\")\n\texpected, _ := hex.DecodeString(\"eb8e6175f1fe38eb1acf95fd5188a8b74bb74fda553e91020a23deed45\")\n\ttag, _ := hex.DecodeString(\"88a8b74bb74fda553e91020a23deed45\")\n\taesgcmTest(t, iv, key, plaintext, expected, tag)\n}", "is_vulnerable": 1}
{"code": "func TestSyncGit(t *testing.T) {\n\tctx := context.Background()\n\tappServer := newTestAppServer(t)\n\ttestApp := newTestApp()\n\ttestApp.Spec.Source.RepoURL = \"https://github.com/org/test\"\n\ttestApp.Spec.Source.Path = \"deploy\"\n\ttestApp.Spec.Source.TargetRevision = \"0.7.*\"\n\tapp, err := appServer.Create(ctx, &application.ApplicationCreateRequest{Application: testApp})\n\tassert.NoError(t, err)\n\tsyncReq := &application.ApplicationSyncRequest{\n\t\tName: &app.Name,\n\t\tManifests: []string{\n\t\t\t`apiVersion: v1\n\t\t\tkind: ServiceAccount\n\t\t\tmetadata:\n\t\t\t  name: test\n\t\t\t  namespace: test`,\n\t\t},\n\t}\n\tapp, err = appServer.Sync(ctx, syncReq)\n\tassert.NoError(t, err)\n\tassert.NotNil(t, app)\n\tassert.NotNil(t, app.Operation)\n\tevents, err := appServer.kubeclientset.CoreV1().Events(appServer.ns).List(context.Background(), metav1.ListOptions{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"Unknown user initiated sync locally\", events.Items[1].Message)\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"Not pick admin user from the queue\", func(t *testing.T) {\n\t\tfailures := map[string]LoginAttempts{\n\t\t\t\"admin\": {\n\t\t\t\tFailCount: 1,\n\t\t\t},\n\t\t\t\"test2\": {\n\t\t\t\tFailCount: 1,\n\t\t\t},\n\t\t}\n\n\t\t// inside pickRandomNonAdminLoginFailure, it uses random, so we need to test it multiple times\n\t\tfor i := 0; i < 1000; i++ {\n\t\t\tuser := pickRandomNonAdminLoginFailure(failures, \"test\")\n\t\t\tassert.Equal(t, \"test2\", *user)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func doesPolicySignatureV2Match(formValues http.Header) (auth.Credentials, APIErrorCode) {\n\taccessKey := formValues.Get(xhttp.AmzAccessKeyID)\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\tpolicy := formValues.Get(\"Policy\")\n\tsignature := formValues.Get(xhttp.AmzSignatureV2)\n\tif !compareSignatureV2(signature, calculateSignatureV2(policy, cred.SecretKey)) {\n\t\treturn cred, ErrSignatureDoesNotMatch\n\t}\n\treturn cred, ErrNone\n}", "is_vulnerable": 0}
{"code": "func (c *immuClient) VerifyRow(ctx context.Context, row *schema.Row, table string, pkVals []*schema.SQLValue) error {\n\tif row == nil || len(table) == 0 || len(pkVals) == 0 {\n\t\treturn ErrIllegalArguments\n\t}\n\n\tif len(row.Columns) == 0 || len(row.Columns) != len(row.Values) {\n\t\treturn sql.ErrCorruptedData\n\t}\n\n\tif !c.IsConnected() {\n\t\treturn ErrNotConnected\n\t}\n\n\terr := c.StateService.CacheLock()\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer c.StateService.CacheUnlock()\n\n\tstate, err := c.StateService.GetState(ctx, c.currentDatabase())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvEntry, err := c.ServiceClient.VerifiableSQLGet(ctx, &schema.VerifiableSQLGetRequest{\n\t\tSqlGetRequest: &schema.SQLGetRequest{Table: table, PkValues: pkVals},\n\t\tProveSinceTx:  state.TxId,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif len(vEntry.PKIDs) < len(pkVals) {\n\t\treturn ErrIllegalArguments\n\t}\n\n\tentrySpecDigest, err := store.EntrySpecDigestFor(int(vEntry.VerifiableTx.Tx.Header.Version))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tinclusionProof := schema.InclusionProofFromProto(vEntry.InclusionProof)\n\tdualProof := schema.DualProofFromProto(vEntry.VerifiableTx.DualProof)\n\n\tvar eh [sha256.Size]byte\n\n\tvar sourceID, targetID uint64\n\tvar sourceAlh, targetAlh [sha256.Size]byte\n\n\tvTx := vEntry.SqlEntry.Tx\n\n\tdbID := vEntry.DatabaseId\n\ttableID := vEntry.TableId\n\n\tvalbuf := bytes.Buffer{}\n\n\tfor i, pkVal := range pkVals {\n\t\tpkID := vEntry.PKIDs[i]\n\n\t\tpkType, ok := vEntry.ColTypesById[pkID]\n\t\tif !ok {\n\t\t\treturn sql.ErrCorruptedData\n\t\t}\n\n\t\tpkLen, ok := vEntry.ColLenById[pkID]\n\t\tif !ok {\n\t\t\treturn sql.ErrCorruptedData\n\t\t}\n\n\t\tpkEncVal, err := sql.EncodeAsKey(schema.RawValue(pkVal), pkType, int(pkLen))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t_, err = valbuf.Write(pkEncVal)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tpkKey := sql.MapKey(\n\t\t[]byte{SQLPrefix},\n\t\tsql.PIndexPrefix,\n\t\tsql.EncodeID(dbID),\n\t\tsql.EncodeID(tableID),\n\t\tsql.EncodeID(sql.PKIndexID),\n\t\tvalbuf.Bytes())\n\n\tdecodedRow, err := decodeRow(vEntry.SqlEntry.Value, vEntry.ColTypesById)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = verifyRowAgainst(row, decodedRow, vEntry.ColIdsByName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\te := &store.EntrySpec{Key: pkKey, Value: vEntry.SqlEntry.Value}\n\n\tif state.TxId <= vTx {\n\t\teh = schema.DigestFromProto(vEntry.VerifiableTx.DualProof.TargetTxHeader.EH)\n\n\t\tsourceID = state.TxId\n\t\tsourceAlh = schema.DigestFromProto(state.TxHash)\n\t\ttargetID = vTx\n\t\ttargetAlh = dualProof.TargetTxHeader.Alh()\n\t} else {\n\t\teh = schema.DigestFromProto(vEntry.VerifiableTx.DualProof.SourceTxHeader.EH)\n\n\t\tsourceID = vTx\n\t\tsourceAlh = dualProof.SourceTxHeader.Alh()\n\t\ttargetID = state.TxId\n\t\ttargetAlh = schema.DigestFromProto(state.TxHash)\n\t}\n\n\tverifies := store.VerifyInclusion(\n\t\tinclusionProof,\n\t\tentrySpecDigest(e),\n\t\teh)\n\tif !verifies {\n\t\treturn store.ErrCorruptedData\n\t}\n\n\tif state.TxId > 0 {\n\t\tverifies = store.VerifyDualProof(\n\t\t\tdualProof,\n\t\t\tsourceID,\n\t\t\ttargetID,\n\t\t\tsourceAlh,\n\t\t\ttargetAlh,\n\t\t)\n\t\tif !verifies {\n\t\t\treturn store.ErrCorruptedData\n\t\t}\n\t}\n\n\tnewState := &schema.ImmutableState{\n\t\tDb:        c.currentDatabase(),\n\t\tTxId:      targetID,\n\t\tTxHash:    targetAlh[:],\n\t\tSignature: vEntry.VerifiableTx.Signature,\n\t}\n\n\tif c.serverSigningPubKey != nil {\n\t\tok, err := newState.CheckSignature(c.serverSigningPubKey)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !ok {\n\t\t\treturn store.ErrCorruptedData\n\t\t}\n\t}\n\n\terr = c.StateService.SetState(c.currentDatabase(), newState)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Tun) Activate() error {\n\tvar err error\n\tc.Interface, err = water.New(water.Config{\n\t\tDeviceType: water.TUN,\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Activate failed: %v\", err)\n\t}\n\n\tc.Device = c.Interface.Name()\n\n\t// TODO use syscalls instead of exec.Command\n\tif err = exec.Command(\"ifconfig\", c.Device, c.Cidr.String(), c.Cidr.IP.String()).Run(); err != nil {\n\t\treturn fmt.Errorf(\"failed to run 'ifconfig': %s\", err)\n\t}\n\tif err = exec.Command(\"route\", \"-n\", \"add\", \"-net\", c.Cidr.String(), \"-interface\", c.Device).Run(); err != nil {\n\t\treturn fmt.Errorf(\"failed to run 'route add': %s\", err)\n\t}\n\tif err = exec.Command(\"ifconfig\", c.Device, \"mtu\", strconv.Itoa(c.MTU)).Run(); err != nil {\n\t\treturn fmt.Errorf(\"failed to run 'ifconfig': %s\", err)\n\t}\n\t// Unsafe path routes\n\tfor _, r := range c.UnsafeRoutes {\n\t\tif err = exec.Command(\"route\", \"-n\", \"add\", \"-net\", r.route.String(), \"-interface\", c.Device).Run(); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to run 'route add' for unsafe_route %s: %s\", r.route.String(), err)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func GetHost(r *http.Request, scheme string) string {\n\thost := r.Header.Get(ForwardedAPIHostHeader)\n\tif host != \"\" {\n\t\treturn host\n\t}\n\n\thost = strings.Split(r.Header.Get(ForwardedHostHeader), \",\")[0]\n\tif host != \"\" {\n\t\treturn host\n\t}\n\n\treturn r.Host\n}", "is_vulnerable": 1}
{"code": "func getMethod(headers []*envoy_config_route_v3.HeaderMatcher) *string {\n\tfor _, h := range headers {\n\t\tif h.Name == \":method\" {\n\t\t\treturn model.AddressOf(h.GetStringMatch().GetExact())\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *KeyAgentTestSuite) TestHostCertVerification(c *check.C) {\n\t// Make a new local agent.\n\tkeystore, err := NewFSLocalKeyStore(s.keyDir)\n\tc.Assert(err, check.IsNil)\n\tlka, err := NewLocalAgent(LocalAgentConfig{\n\t\tKeystore:   keystore,\n\t\tProxyHost:  s.hostname,\n\t\tUsername:   s.username,\n\t\tKeysOption: AddKeysToAgentAuto,\n\t})\n\tc.Assert(err, check.IsNil)\n\n\t// By default user has not refused any hosts.\n\tc.Assert(lka.UserRefusedHosts(), check.Equals, false)\n\n\t// Create a CA, generate a keypair for the CA, and add it to the known\n\t// hosts cache (done by \"tsh login\").\n\tkeygen := testauthority.New()\n\tcaPriv, caPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\tcaPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(caPub)\n\tc.Assert(err, check.IsNil)\n\terr = lka.keyStore.AddKnownHostKeys(\"example.com\", []ssh.PublicKey{caPublicKey})\n\tc.Assert(err, check.IsNil)\n\n\t// Generate a host certificate for node with role \"node\".\n\t_, hostPub, err := keygen.GenerateKeyPair(\"\")\n\tc.Assert(err, check.IsNil)\n\troles, err := teleport.ParseRoles(\"node\")\n\tc.Assert(err, check.IsNil)\n\thostCertBytes, err := keygen.GenerateHostCert(services.HostCertParams{\n\t\tPrivateCASigningKey: caPriv,\n\t\tCASigningAlg:        defaults.CASignatureAlgorithm,\n\t\tPublicHostKey:       hostPub,\n\t\tHostID:              \"5ff40d80-9007-4f28-8f49-7d4fda2f574d\",\n\t\tNodeName:            \"server01\",\n\t\tPrincipals: []string{\n\t\t\t\"127.0.0.1\",\n\t\t},\n\t\tClusterName: \"example.com\",\n\t\tRoles:       roles,\n\t\tTTL:         1 * time.Hour,\n\t})\n\tc.Assert(err, check.IsNil)\n\thostPublicKey, _, _, _, err := ssh.ParseAuthorizedKey(hostCertBytes)\n\tc.Assert(err, check.IsNil)\n\n\ttests := []struct {\n\t\tinAddr   string\n\t\toutError bool\n\t}{\n\t\t// Correct DNS is valid.\n\t\t{\n\t\t\tinAddr:   \"server01.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Hostname only is valid.\n\t\t{\n\t\t\tinAddr:   \"server01:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// IP is valid.\n\t\t{\n\t\t\tinAddr:   \"127.0.0.1:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// UUID is valid.\n\t\t{\n\t\t\tinAddr:   \"5ff40d80-9007-4f28-8f49-7d4fda2f574d.example.com:3022\",\n\t\t\toutError: false,\n\t\t},\n\t\t// Wrong DNS name is invalid.\n\t\t{\n\t\t\tinAddr:   \"server02.example.com:3022\",\n\t\t\toutError: true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\terr = lka.CheckHostSignature(tt.inAddr, nil, hostPublicKey)\n\t\tif tt.outError {\n\t\t\tc.Assert(err, check.NotNil)\n\t\t} else {\n\t\t\tc.Assert(err, check.IsNil)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewGenerator(root string, kustomization kustomizev1.Kustomization) *KustomizeGenerator {\n\treturn &KustomizeGenerator{\n\t\troot:          root,\n\t\tkustomization: kustomization,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAccessTokenStrategyMockRecorder) AccessTokenSignature(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AccessTokenSignature\", reflect.TypeOf((*MockAccessTokenStrategy)(nil).AccessTokenSignature), arg0)\n}", "is_vulnerable": 0}
{"code": "func (s *Stats) LoadFetchedSeries() uint64 {\n\tif s == nil {\n\t\treturn 0\n\t}\n\n\treturn atomic.LoadUint64(&s.FetchedSeriesCount)\n}", "is_vulnerable": 0}
{"code": "func GetSecretsList(k8sClient *kubernetes.Clientset, namespace string) (*v1.SecretList, error) {\n\treturn k8sClient.CoreV1().Secrets(\"\").List(context.TODO(), metav1.ListOptions{})\n}", "is_vulnerable": 1}
{"code": "func UnpackTar(filename string, destination string, verbosityLevel int) (err error) {\n\tVerbose = verbosityLevel\n\tf, err := os.Stat(destination)\n\tif os.IsNotExist(err) {\n\t\treturn fmt.Errorf(\"destination directory '%s' does not exist\", destination)\n\t}\n\tfilemode := f.Mode()\n\tif !filemode.IsDir() {\n\t\treturn fmt.Errorf(\"destination '%s' is not a directory\", destination)\n\t}\n\tif !validSuffix(filename) {\n\t\treturn fmt.Errorf(\"unrecognized archive suffix\")\n\t}\n\tvar file *os.File\n\t// #nosec G304\n\tif file, err = os.Open(filename); err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\terr = os.Chdir(destination)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"error changing directory to %s\", destination)\n\t}\n\tvar fileReader io.Reader = file\n\tvar decompressor *gzip.Reader\n\tif strings.HasSuffix(filename, globals.GzExt) {\n\t\tif decompressor, err = gzip.NewReader(file); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer decompressor.Close()\n\t}\n\tvar reader *tar.Reader\n\tif decompressor != nil {\n\t\treader = tar.NewReader(decompressor)\n\t} else {\n\t\treader = tar.NewReader(fileReader)\n\t}\n\treturn unpackTarFiles(reader)\n}", "is_vulnerable": 1}
{"code": "func (ds DataSession) Push(ctx context.Context) error {\n\tgitAuth, err := wgit.GetGitAuth(ds.distro.Absolute.AdvisoriesHTTPSCloneURL())\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting git auth: %w\", err)\n\t}\n\n\terr = ds.repo.PushContext(ctx, &git.PushOptions{\n\t\tRemoteURL: ds.distro.Absolute.AdvisoriesHTTPSCloneURL(),\n\t\tAuth:      gitAuth,\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"pushing changes: %w\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (sp *ServiceProvider) ParseResponse(req *http.Request, possibleRequestIDs []string) (*Assertion, error) {\n\tnow := TimeNow()\n\n\tvar assertion *Assertion\n\n\tretErr := &InvalidResponseError{\n\t\tNow:      now,\n\t\tResponse: req.PostForm.Get(\"SAMLResponse\"),\n\t}\n\n\tif req.Form.Get(\"SAMLart\") != \"\" {\n\t\tretErr.Response = req.Form.Get(\"SAMLart\")\n\n\t\treq, err := sp.MakeArtifactResolveRequest(req.Form.Get(\"SAMLart\"))\n\t\tif err != nil {\n\t\t\tretErr.PrivateErr = fmt.Errorf(\"Cannot generate artifact resolution request: %s\", err)\n\t\t\treturn nil, retErr\n\t\t}\n\n\t\tdoc := etree.NewDocument()\n\t\tdoc.SetRoot(req.SoapRequest())\n\n\t\tvar requestBuffer bytes.Buffer\n\t\tdoc.WriteTo(&requestBuffer)\n\t\tclient := sp.HTTPClient\n\t\tif client == nil {\n\t\t\tclient = http.DefaultClient\n\t\t}\n\t\tresponse, err := client.Post(sp.GetArtifactBindingLocation(SOAPBinding), \"text/xml\", &requestBuffer)\n\t\tif err != nil {\n\t\t\tretErr.PrivateErr = fmt.Errorf(\"Error during artifact resolution: %s\", err)\n\t\t\treturn nil, retErr\n\t\t}\n\t\tdefer response.Body.Close()\n\t\tif response.StatusCode != 200 {\n\t\t\tretErr.PrivateErr = fmt.Errorf(\"Error during artifact resolution: HTTP status %d (%s)\", response.StatusCode, response.Status)\n\t\t\treturn nil, retErr\n\t\t}\n\t\trawResponseBuf, err := ioutil.ReadAll(response.Body)\n\t\tif err != nil {\n\t\t\tretErr.PrivateErr = fmt.Errorf(\"Error during artifact resolution: %s\", err)\n\t\t\treturn nil, retErr\n\t\t}\n\t\tassertion, err = sp.ParseXMLArtifactResponse(rawResponseBuf, possibleRequestIDs, req.ID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\trawResponseBuf, err := base64.StdEncoding.DecodeString(req.PostForm.Get(\"SAMLResponse\"))\n\t\tif err != nil {\n\t\t\tretErr.PrivateErr = fmt.Errorf(\"cannot parse base64: %s\", err)\n\t\t\treturn nil, retErr\n\t\t}\n\t\tretErr.Response = string(rawResponseBuf)\n\t\tassertion, err = sp.ParseXMLResponse(rawResponseBuf, possibleRequestIDs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn assertion, nil\n\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"Get User by login - user_2 uses user_1.email as login\", func(t *testing.T) {\n\t\tss = InitTestDB(t)\n\n\t\t// create user_1\n\t\tcmd := models.CreateUserCommand{\n\t\t\tEmail:      \"user_1@mail.com\",\n\t\t\tName:       \"user_1\",\n\t\t\tLogin:      \"user_1\",\n\t\t\tPassword:   \"user_1_password\",\n\t\t\tIsDisabled: true,\n\t\t}\n\t\tuser_1, err := ss.CreateUser(context.Background(), cmd)\n\t\trequire.Nil(t, err)\n\n\t\t// create user_2\n\t\tcmd = models.CreateUserCommand{\n\t\t\tEmail:      \"user_2@mail.com\",\n\t\t\tName:       \"user_2\",\n\t\t\tLogin:      \"user_1@mail.com\",\n\t\t\tPassword:   \"user_2_password\",\n\t\t\tIsDisabled: true,\n\t\t}\n\t\tuser_2, err := ss.CreateUser(context.Background(), cmd)\n\t\trequire.Nil(t, err)\n\n\t\t// query user database for user_1 email\n\t\tquery := models.GetUserByLoginQuery{LoginOrEmail: \"user_1@mail.com\"}\n\t\terr = ss.GetUserByLogin(context.Background(), &query)\n\t\trequire.Nil(t, err)\n\n\t\t// expect user_1 as result\n\t\trequire.Equal(t, user_1.Email, query.Result.Email)\n\t\trequire.Equal(t, user_1.Login, query.Result.Login)\n\t\trequire.Equal(t, user_1.Name, query.Result.Name)\n\t\trequire.NotEqual(t, user_2.Email, query.Result.Email)\n\t\trequire.NotEqual(t, user_2.Login, query.Result.Login)\n\t\trequire.NotEqual(t, user_2.Name, query.Result.Name)\n\t})", "is_vulnerable": 0}
{"code": "func staticHandler(ctx *Context, log *log.Logger, opt StaticOptions) bool {\n\tif ctx.Req.Method != \"GET\" && ctx.Req.Method != \"HEAD\" {\n\t\treturn false\n\t}\n\n\tfile := ctx.Req.URL.Path\n\t// if we have a prefix, filter requests by stripping the prefix\n\tif opt.Prefix != \"\" {\n\t\tif !strings.HasPrefix(file, opt.Prefix) {\n\t\t\treturn false\n\t\t}\n\t\tfile = file[len(opt.Prefix):]\n\t\tif file != \"\" && file[0] != '/' {\n\t\t\treturn false\n\t\t}\n\t}\n\n\tf, err := opt.FileSystem.Open(file)\n\tif err != nil {\n\t\treturn false\n\t}\n\tdefer f.Close()\n\n\tfi, err := f.Stat()\n\tif err != nil {\n\t\treturn true // File exists but fail to open.\n\t}\n\n\t// Try to serve index file\n\tif fi.IsDir() {\n\t\t// Redirect if missing trailing slash.\n\t\tif !strings.HasSuffix(ctx.Req.URL.Path, \"/\") {\n\t\t\thttp.Redirect(ctx.Resp, ctx.Req.Request, ctx.Req.URL.Path+\"/\", http.StatusFound)\n\t\t\treturn true\n\t\t}\n\n\t\tfile = path.Join(file, opt.IndexFile)\n\t\tf, err = opt.FileSystem.Open(file)\n\t\tif err != nil {\n\t\t\treturn false // Discard error.\n\t\t}\n\t\tdefer f.Close()\n\n\t\tfi, err = f.Stat()\n\t\tif err != nil || fi.IsDir() {\n\t\t\treturn true\n\t\t}\n\t}\n\n\tif !opt.SkipLogging {\n\t\tlog.Println(\"[Static] Serving \" + file)\n\t}\n\n\t// Add an Expires header to the static content\n\tif opt.Expires != nil {\n\t\tctx.Resp.Header().Set(\"Expires\", opt.Expires())\n\t}\n\n\tif opt.ETag {\n\t\ttag := GenerateETag(string(fi.Size()), fi.Name(), fi.ModTime().UTC().Format(http.TimeFormat))\n\t\tctx.Resp.Header().Set(\"ETag\", `\"`+tag+`\"`)\n\t}\n\n\thttp.ServeContent(ctx.Resp, ctx.Req.Request, file, fi.ModTime(), f)\n\treturn true\n}", "is_vulnerable": 1}
{"code": "func TestGetRuntimeConfigurations_ConnectProxy(t *testing.T) {\n\tdbService := api.CompoundServiceName{\n\t\tName:      \"db\",\n\t\tPartition: \"default\",\n\t\tNamespace: \"default\",\n\t}\n\twebService := api.CompoundServiceName{\n\t\tName:      \"web\",\n\t\tPartition: \"\",\n\t\tNamespace: \"default\",\n\t}\n\n\t// Setup multiple extensions to ensure only the expected one (AWS) is in the ExtensionConfiguration map\n\t// sourced from upstreams, and all local extensions are included.\n\tenvoyExtensions := []structs.EnvoyExtension{\n\t\t{\n\t\t\tName: api.BuiltinAWSLambdaExtension,\n\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\"ARN\":                \"arn:aws:lambda:us-east-1:111111111111:function:lambda-1234\",\n\t\t\t\t\"PayloadPassthrough\": true,\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tName: \"ext2\",\n\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\"arg1\": 1,\n\t\t\t\t\"arg2\": \"val2\",\n\t\t\t},\n\t\t},\n\t}\n\n\tserviceDefaults := &structs.ServiceConfigEntry{\n\t\tKind:            structs.ServiceDefaults,\n\t\tName:            \"db\",\n\t\tProtocol:        \"http\",\n\t\tEnvoyExtensions: envoyExtensions,\n\t}\n\n\t// Setup a snapshot where the db upstream is on a connect proxy.\n\tsnapConnect := proxycfg.TestConfigSnapshotDiscoveryChain(t, \"default\", false, nil, nil, serviceDefaults)\n\t// Setup a snapshot where the db upstream is on a terminating gateway.\n\tsnapTermGw := proxycfg.TestConfigSnapshotDiscoveryChain(t, \"register-to-terminating-gateway\", false, nil, nil, serviceDefaults)\n\t// Setup a snapshot with the local service web has extensions.\n\tsnapWebConnect := proxycfg.TestConfigSnapshotDiscoveryChain(t, \"default\", false, func(ns *structs.NodeService) {\n\t\tns.Proxy.EnvoyExtensions = envoyExtensions\n\t}, nil)\n\n\ttype testCase struct {\n\t\tsnapshot *proxycfg.ConfigSnapshot\n\t\texpected map[api.CompoundServiceName][]extensioncommon.RuntimeConfig\n\t}\n\tcases := map[string]testCase{\n\t\t\"connect proxy upstream\": {\n\t\t\tsnapshot: snapConnect,\n\t\t\texpected: map[api.CompoundServiceName][]extensioncommon.RuntimeConfig{\n\t\t\t\tdbService: {\n\t\t\t\t\t{\n\t\t\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\t\t\tName: api.BuiltinAWSLambdaExtension,\n\t\t\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"ARN\":                \"arn:aws:lambda:us-east-1:111111111111:function:lambda-1234\",\n\t\t\t\t\t\t\t\t\"PayloadPassthrough\": true,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tServiceName:           dbService,\n\t\t\t\t\t\tIsSourcedFromUpstream: true,\n\t\t\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\t\t\tdbService: {\n\t\t\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnvoyID:           \"db\",\n\t\t\t\t\t\t\t\tOutgoingProxyKind: \"connect-proxy\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tKind: api.ServiceKindConnectProxy,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\twebService: {},\n\t\t\t},\n\t\t},\n\t\t\"terminating gateway upstream\": {\n\t\t\tsnapshot: snapTermGw,\n\t\t\texpected: map[api.CompoundServiceName][]extensioncommon.RuntimeConfig{\n\t\t\t\tdbService: {\n\t\t\t\t\t{\n\t\t\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\t\t\tName: api.BuiltinAWSLambdaExtension,\n\t\t\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"ARN\":                \"arn:aws:lambda:us-east-1:111111111111:function:lambda-1234\",\n\t\t\t\t\t\t\t\t\"PayloadPassthrough\": true,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tServiceName:           dbService,\n\t\t\t\t\t\tIsSourcedFromUpstream: true,\n\t\t\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\t\t\tdbService: {\n\t\t\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnvoyID:           \"db\",\n\t\t\t\t\t\t\t\tOutgoingProxyKind: \"terminating-gateway\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tKind: api.ServiceKindConnectProxy,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\twebService: {},\n\t\t\t},\n\t\t},\n\t\t\"local service extensions\": {\n\t\t\tsnapshot: snapWebConnect,\n\t\t\texpected: map[api.CompoundServiceName][]extensioncommon.RuntimeConfig{\n\t\t\t\tdbService: {},\n\t\t\t\twebService: {\n\t\t\t\t\t{\n\t\t\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\t\t\tName: api.BuiltinAWSLambdaExtension,\n\t\t\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"ARN\":                \"arn:aws:lambda:us-east-1:111111111111:function:lambda-1234\",\n\t\t\t\t\t\t\t\t\"PayloadPassthrough\": true,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tServiceName:           webService,\n\t\t\t\t\t\tKind:                  api.ServiceKindConnectProxy,\n\t\t\t\t\t\tIsSourcedFromUpstream: false,\n\t\t\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\t\t\tdbService: {\n\t\t\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnvoyID:           \"db\",\n\t\t\t\t\t\t\t\tOutgoingProxyKind: \"connect-proxy\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\t\t\tName: \"ext2\",\n\t\t\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"arg1\": 1,\n\t\t\t\t\t\t\t\t\"arg2\": \"val2\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tServiceName:           webService,\n\t\t\t\t\t\tKind:                  api.ServiceKindConnectProxy,\n\t\t\t\t\t\tIsSourcedFromUpstream: false,\n\t\t\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\t\t\tdbService: {\n\t\t\t\t\t\t\t\tSNI: map[string]struct{}{\n\t\t\t\t\t\t\t\t\t\"db.default.dc1.internal.11111111-2222-3333-4444-555555555555.consul\": {},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnvoyID:           \"db\",\n\t\t\t\t\t\t\t\tOutgoingProxyKind: \"connect-proxy\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tfor name, tc := range cases {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\trequire.Equal(t, tc.expected, GetRuntimeConfigurations(tc.snapshot))\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func cleanJoin(root, dest string) (string, error) {\n\n\t// On Windows, this is a drive separator. On UNIX-like, this is the path list separator.\n\t// In neither case do we want to trust a TAR that contains these.\n\tif strings.Contains(dest, \":\") {\n\t\treturn \"\", errors.New(\"path contains ':', which is illegal\")\n\t}\n\n\t// The Go tar library does not convert separators for us.\n\t// We assume here, as we do elsewhere, that `\\\\` means a Windows path.\n\tdest = strings.ReplaceAll(dest, \"\\\\\", \"/\")\n\n\t// We want to alert the user that something bad was attempted. Cleaning it\n\t// is not a good practice.\n\tfor _, part := range strings.Split(dest, \"/\") {\n\t\tif part == \"..\" {\n\t\t\treturn \"\", errors.New(\"path contains '..', which is illegal\")\n\t\t}\n\t}\n\n\t// If a path is absolute, the creator of the TAR is doing something shady.\n\tif path.IsAbs(dest) {\n\t\treturn \"\", errors.New(\"path is absolute, which is illegal\")\n\t}\n\n\t// SecureJoin will do some cleaning, as well as some rudimentary checking of symlinks.\n\tnewpath, err := securejoin.SecureJoin(root, dest)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn filepath.ToSlash(newpath), nil\n}", "is_vulnerable": 0}
{"code": "func TestContainerdBuilder_Complex(t *testing.T) {\n\trunContainerdBuilderTest(t, \"complex\", distributions.DistributionUbuntu2004)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CrackstationBenchmark(ctx context.Context, in *clientpb.CrackBenchmark, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CrackstationBenchmark_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) SaveHTTPC2Profile(ctx context.Context, in *clientpb.HTTPC2ConfigReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_SaveHTTPC2Profile_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (db *Database) Cap(limit common.StorageSize) error {\n\t// Create a database batch to flush persistent data out. It is important that\n\t// outside code doesn't see an inconsistent state (referenced data removed from\n\t// memory cache during commit but not yet in persistent storage). This is ensured\n\t// by only uncaching existing data when the database write finalizes.\n\tnodes, storage, start := len(db.dirties), db.dirtiesSize, time.Now()\n\tbatch := db.diskdb.NewBatch()\n\n\t// db.dirtiesSize only contains the useful data in the cache, but when reporting\n\t// the total memory consumption, the maintenance metadata is also needed to be\n\t// counted.\n\tsize := db.dirtiesSize + common.StorageSize((len(db.dirties)-1)*cachedNodeSize)\n\tsize += db.childrenSize - common.StorageSize(len(db.dirties[common.Hash{}].children)*(common.HashLength+2))\n\n\t// We reuse an ephemeral buffer for the keys. The batch Put operation\n\t// copies it internally, so we can reuse it.\n\tvar keyBuf [secureKeyLength]byte\n\tcopy(keyBuf[:], secureKeyPrefix)\n\n\t// If the preimage cache got large enough, push to disk. If it's still small\n\t// leave for later to deduplicate writes.\n\tflushPreimages := db.preimagesSize > 4*1024*1024\n\tif flushPreimages {\n\t\tfor hash, preimage := range db.preimages {\n\t\t\tcopy(keyBuf[secureKeyPrefixLength:], hash[:])\n\t\t\tif err := batch.Put(keyBuf[:], preimage); err != nil {\n\t\t\t\tlog.Error(\"Failed to commit preimage from trie database\", \"err\", err)\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif batch.ValueSize() > ethdb.IdealBatchSize {\n\t\t\t\tif err := batch.Write(); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tbatch.Reset()\n\t\t\t}\n\t\t}\n\t}\n\t// Keep committing nodes from the flush-list until we're below allowance\n\toldest := db.oldest\n\tfor size > limit && oldest != (common.Hash{}) {\n\t\t// Fetch the oldest referenced node and push into the batch\n\t\tnode := db.dirties[oldest]\n\t\tif err := batch.Put(oldest[:], node.rlp()); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// If we exceeded the ideal batch size, commit and reset\n\t\tif batch.ValueSize() >= ethdb.IdealBatchSize {\n\t\t\tif err := batch.Write(); err != nil {\n\t\t\t\tlog.Error(\"Failed to write flush list to disk\", \"err\", err)\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tbatch.Reset()\n\t\t}\n\t\t// Iterate to the next flush item, or abort if the size cap was achieved. Size\n\t\t// is the total size, including the useful cached data (hash -> blob), the\n\t\t// cache item metadata, as well as external children mappings.\n\t\tsize -= common.StorageSize(common.HashLength + int(node.size) + cachedNodeSize)\n\t\tif node.children != nil {\n\t\t\tsize -= common.StorageSize(cachedNodeChildrenSize + len(node.children)*(common.HashLength+2))\n\t\t}\n\t\toldest = node.flushNext\n\t}\n\t// Flush out any remainder data from the last batch\n\tif err := batch.Write(); err != nil {\n\t\tlog.Error(\"Failed to write flush list to disk\", \"err\", err)\n\t\treturn err\n\t}\n\t// Write successful, clear out the flushed data\n\tdb.lock.Lock()\n\tdefer db.lock.Unlock()\n\n\tif flushPreimages {\n\t\tdb.preimages = make(map[common.Hash][]byte)\n\t\tdb.preimagesSize = 0\n\t}\n\tfor db.oldest != oldest {\n\t\tnode := db.dirties[db.oldest]\n\t\tdelete(db.dirties, db.oldest)\n\t\tdb.oldest = node.flushNext\n\n\t\tdb.dirtiesSize -= common.StorageSize(common.HashLength + int(node.size))\n\t\tif node.children != nil {\n\t\t\tdb.childrenSize -= common.StorageSize(cachedNodeChildrenSize + len(node.children)*(common.HashLength+2))\n\t\t}\n\t}\n\tif db.oldest != (common.Hash{}) {\n\t\tdb.dirties[db.oldest].flushPrev = common.Hash{}\n\t}\n\tdb.flushnodes += uint64(nodes - len(db.dirties))\n\tdb.flushsize += storage - db.dirtiesSize\n\tdb.flushtime += time.Since(start)\n\n\tmemcacheFlushTimeTimer.Update(time.Since(start))\n\tmemcacheFlushSizeMeter.Mark(int64(storage - db.dirtiesSize))\n\tmemcacheFlushNodesMeter.Mark(int64(nodes - len(db.dirties)))\n\n\tlog.Debug(\"Persisted nodes from memory database\", \"nodes\", nodes-len(db.dirties), \"size\", storage-db.dirtiesSize, \"time\", time.Since(start),\n\t\t\"flushnodes\", db.flushnodes, \"flushsize\", db.flushsize, \"flushtime\", db.flushtime, \"livenodes\", len(db.dirties), \"livesize\", db.dirtiesSize)\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\t\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\t\t\tServices:    test.serviceConfig,\n\t\t\t\t\tRouters:     test.routersConfig,\n\t\t\t\t\tMiddlewares: test.middlewaresConfig,\n\t\t\t\t},\n\t\t\t})\n\n\t\t\troundTripperManager := service.NewRoundTripperManager()\n\t\t\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\t\t\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\t\t\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\t\t\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\n\t\t\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry())\n\n\t\t\thandlers := routerManager.BuildHandlers(context.Background(), test.entryPoints, false)\n\n\t\t\tw := httptest.NewRecorder()\n\t\t\treq := testhelpers.MustNewRequest(http.MethodGet, \"http://foo.bar/\", nil)\n\n\t\t\treqHost := requestdecorator.New(nil)\n\t\t\treqHost.ServeHTTP(w, req, handlers[\"web\"].ServeHTTP)\n\n\t\t\tassert.Equal(t, test.expected.StatusCode, w.Code)\n\n\t\t\tfor key, value := range test.expected.RequestHeaders {\n\t\t\t\tassert.Equal(t, value, req.Header.Get(key))\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (vfs *VirtualFilesystem) ConnectMountAt(ctx context.Context, creds *auth.Credentials, mnt *Mount, target *PathOperation) error {\n\t// We can't hold vfs.mountMu while calling FilesystemImpl methods due to\n\t// lock ordering.\n\tvd, err := vfs.GetDentryAt(ctx, creds, target, &GetDentryOptions{})\n\tif err != nil {\n\t\treturn err\n\t}\n\tvfs.lockMounts()\n\tdefer vfs.unlockMounts(ctx)\n\tmp, err := vfs.lockMountpoint(vd)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif mp.mount.neverConnected() || mp.mount.umounted {\n\t\tmp.dentry.mu.Unlock()\n\t\tvfs.delayDecRef(mp)\n\t\treturn linuxerr.EINVAL\n\t}\n\treturn vfs.attachTreeLocked(ctx, mnt, mp)\n}", "is_vulnerable": 0}
{"code": "func TestGlobalRateLimiting(t *testing.T) {\n\ting := buildIngress()\n\n\tannRateLimit := parser.GetAnnotationWithPrefix(\"global-rate-limit\")\n\tannRateLimitWindow := parser.GetAnnotationWithPrefix(\"global-rate-limit-window\")\n\tannRateLimitKey := parser.GetAnnotationWithPrefix(\"global-rate-limit-key\")\n\tannRateLimitIgnoredCIDRs := parser.GetAnnotationWithPrefix(\"global-rate-limit-ignored-cidrs\")\n\n\ttestCases := []struct {\n\t\ttitle          string\n\t\tannotations    map[string]string\n\t\texpectedConfig *Config\n\t\texpectedErr    error\n\t}{\n\t\t{\n\t\t\t\"no annotation\",\n\t\t\tnil,\n\t\t\t&Config{},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"minimum required annotations\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2m\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$remote_addr\",\n\t\t\t\tIgnoredCIDRs: make([]string, 0),\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"global-rate-limit-key annotation\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2m\",\n\t\t\t\tannRateLimitKey:    \"$http_x_api_user\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$http_x_api_user\",\n\t\t\t\tIgnoredCIDRs: make([]string, 0),\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"global-rate-limit-ignored-cidrs annotation\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:             \"100\",\n\t\t\t\tannRateLimitWindow:       \"2m\",\n\t\t\t\tannRateLimitKey:          \"$http_x_api_user\",\n\t\t\t\tannRateLimitIgnoredCIDRs: \"127.0.0.1, 200.200.24.0/24\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"$http_x_api_user\",\n\t\t\t\tIgnoredCIDRs: []string{\"127.0.0.1\", \"200.200.24.0/24\"},\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"global-rate-limit-complex-key\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2m\",\n\t\t\t\tannRateLimitKey:    \"${http_x_api_user}${otherinfo}\",\n\t\t\t},\n\t\t\t&Config{\n\t\t\t\tNamespace:    expectedUID,\n\t\t\t\tLimit:        100,\n\t\t\t\tWindowSize:   120,\n\t\t\t\tKey:          \"${http_x_api_user}${otherinfo}\",\n\t\t\t\tIgnoredCIDRs: make([]string, 0),\n\t\t\t},\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"incorrect duration for window\",\n\t\t\tmap[string]string{\n\t\t\t\tannRateLimit:       \"100\",\n\t\t\t\tannRateLimitWindow: \"2mb\",\n\t\t\t\tannRateLimitKey:    \"$http_x_api_user\",\n\t\t\t},\n\t\t\t&Config{},\n\t\t\ting_errors.ValidationError{\n\t\t\t\tReason: fmt.Errorf(\"failed to parse 'global-rate-limit-window' value: annotation nginx.ingress.kubernetes.io/global-rate-limit-window contains invalid value\"),\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ting.SetAnnotations(testCase.annotations)\n\n\t\ti, actualErr := NewParser(mockBackend{}).Parse(ing)\n\t\tif (testCase.expectedErr == nil || actualErr == nil) && testCase.expectedErr != actualErr {\n\t\t\tt.Errorf(\"%s expected error '%v' but got '%v'\", testCase.title, testCase.expectedErr, actualErr)\n\t\t} else if testCase.expectedErr != nil && actualErr != nil &&\n\t\t\ttestCase.expectedErr.Error() != actualErr.Error() {\n\t\t\tt.Errorf(\"expected error '%v' but got '%v'\", testCase.expectedErr, actualErr)\n\t\t}\n\n\t\tactualConfig := i.(*Config)\n\t\tif !testCase.expectedConfig.Equal(actualConfig) {\n\t\t\texpectedJSON, _ := json.Marshal(testCase.expectedConfig)\n\t\t\tactualJSON, _ := json.Marshal(actualConfig)\n\t\t\tt.Errorf(\"%v: expected config '%s' but got '%s'\", testCase.title, expectedJSON, actualJSON)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func pipeExtensions(cfg *config.Configuration, request *pipeRequest) (response pipeResponse, err error) {\n\tvar extcmds []*extCommand\n\tdefer func() {\n\t\t// In the case of an early return before the end of this\n\t\t// function (in response to an error, etc), kill all running\n\t\t// processes. Errors are ignored since the function has already\n\t\t// returned.\n\t\t//\n\t\t// In the happy path, the commands will have already been\n\t\t// `Wait()`-ed upon and e.cmd.Process.Kill() will return an\n\t\t// error, but we can ignore it.\n\t\tfor _, e := range extcmds {\n\t\t\tif e.cmd.Process != nil {\n\t\t\t\te.cmd.Process.Kill()\n\t\t\t}\n\t\t}\n\t}()\n\n\tfor _, e := range request.extensions {\n\t\tvar pieces []string\n\t\tswitch request.action {\n\t\tcase \"clean\":\n\t\t\tpieces = strings.Split(e.Clean, \" \")\n\t\tcase \"smudge\":\n\t\t\tpieces = strings.Split(e.Smudge, \" \")\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"Invalid action: \" + request.action)\n\t\t\treturn\n\t\t}\n\t\tname := strings.Trim(pieces[0], \" \")\n\t\tvar args []string\n\t\tfor _, value := range pieces[1:] {\n\t\t\targ := strings.Replace(value, \"%f\", request.fileName, -1)\n\t\t\targs = append(args, arg)\n\t\t}\n\t\tcmd := exec.Command(name, args...)\n\t\tec := &extCommand{cmd: cmd, result: &pipeExtResult{name: e.Name}}\n\t\textcmds = append(extcmds, ec)\n\t}\n\n\thasher := sha256.New()\n\tpipeReader, pipeWriter := io.Pipe()\n\tmultiWriter := io.MultiWriter(hasher, pipeWriter)\n\n\tvar input io.Reader\n\tvar output io.WriteCloser\n\tinput = pipeReader\n\textcmds[0].cmd.Stdin = input\n\tif response.file, err = TempFile(cfg, \"\"); err != nil {\n\t\treturn\n\t}\n\tdefer response.file.Close()\n\toutput = response.file\n\n\tlast := len(extcmds) - 1\n\tfor i, ec := range extcmds {\n\t\tec.hasher = sha256.New()\n\n\t\tif i == last {\n\t\t\tec.cmd.Stdout = io.MultiWriter(ec.hasher, output)\n\t\t\tec.out = output\n\t\t\tcontinue\n\t\t}\n\n\t\tnextec := extcmds[i+1]\n\t\tvar nextStdin io.WriteCloser\n\t\tvar stdout io.ReadCloser\n\t\tif nextStdin, err = nextec.cmd.StdinPipe(); err != nil {\n\t\t\treturn\n\t\t}\n\t\tif stdout, err = ec.cmd.StdoutPipe(); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tec.cmd.Stdin = input\n\t\tec.cmd.Stdout = io.MultiWriter(ec.hasher, nextStdin)\n\t\tec.out = nextStdin\n\n\t\tinput = stdout\n\n\t\tvar errBuff bytes.Buffer\n\t\tec.err = &errBuff\n\t\tec.cmd.Stderr = ec.err\n\t}\n\n\tfor _, ec := range extcmds {\n\t\tif err = ec.cmd.Start(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tif _, err = io.Copy(multiWriter, request.reader); err != nil {\n\t\treturn\n\t}\n\tif err = pipeWriter.Close(); err != nil {\n\t\treturn\n\t}\n\n\tfor _, ec := range extcmds {\n\t\tif err = ec.cmd.Wait(); err != nil {\n\t\t\tif ec.err != nil {\n\t\t\t\terrStr := ec.err.String()\n\t\t\t\terr = fmt.Errorf(\"extension '%s' failed with: %s\", ec.result.name, errStr)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif err = ec.out.Close(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\toid := hex.EncodeToString(hasher.Sum(nil))\n\tfor _, ec := range extcmds {\n\t\tec.result.oidIn = oid\n\t\toid = hex.EncodeToString(ec.hasher.Sum(nil))\n\t\tec.result.oidOut = oid\n\t\tresponse.results = append(response.results, ec.result)\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestIAMInternalIDPServerSuite(t *testing.T) {\n\tif runtime.GOOS == globalWindowsOSName {\n\t\tt.Skip(\"windows is clunky disable these tests\")\n\t}\n\tfor i, testCase := range iamTestSuites {\n\t\tt.Run(\n\t\t\tfmt.Sprintf(\"Test: %d, ServerType: %s\", i+1, testCase.ServerTypeDescription),\n\t\t\tfunc(t *testing.T) {\n\t\t\t\tsuite := testCase\n\t\t\t\tc := &check{t, testCase.serverType}\n\n\t\t\t\tsuite.SetUpSuite(c)\n\t\t\t\tsuite.TestUserCreate(c)\n\t\t\t\tsuite.TestUserPolicyEscalationBug(c)\n\t\t\t\tsuite.TestPolicyCreate(c)\n\t\t\t\tsuite.TestCannedPolicies(c)\n\t\t\t\tsuite.TestGroupAddRemove(c)\n\t\t\t\tsuite.TestServiceAccountOpsByAdmin(c)\n\t\t\t\tsuite.TestServiceAccountPrivilegeEscalationBug(c)\n\t\t\t\tsuite.TestServiceAccountOpsByUser(c)\n\t\t\t\tsuite.TestAddServiceAccountPerms(c)\n\t\t\t\tsuite.TearDownSuite(c)\n\t\t\t},\n\t\t)\n\t}\n}", "is_vulnerable": 0}
{"code": "func WithMaxPBES2Count(v int) GlobalOption {\n\treturn &globalOption{option.New(identMaxPBES2Count{}, v)}\n}", "is_vulnerable": 0}
{"code": "func TestFunctionCall_EncodeDecode(t *testing.T) {\n\ttype fields struct {\n\t\tFunction         uint32\n\t\tArgFormatCodes   []uint16\n\t\tArguments        [][]byte\n\t\tResultFormatCode uint16\n\t}\n\ttests := []struct {\n\t\tname    string\n\t\tfields  fields\n\t\twantErr bool\n\t}{\n\t\t{\"valid\", fields{uint32(123), []uint16{0, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(1)}, false},\n\t\t{\"invalid format code\", fields{uint32(123), []uint16{2, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(0)}, true},\n\t\t{\"invalid result format code\", fields{uint32(123), []uint16{1, 1, 0, 1}, [][]byte{[]byte(\"foo\"), []byte(\"bar\"), []byte(\"baz\")}, uint16(2)}, true},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tsrc := &FunctionCall{\n\t\t\t\tFunction:         tt.fields.Function,\n\t\t\t\tArgFormatCodes:   tt.fields.ArgFormatCodes,\n\t\t\t\tArguments:        tt.fields.Arguments,\n\t\t\t\tResultFormatCode: tt.fields.ResultFormatCode,\n\t\t\t}\n\t\t\tencoded, err := src.Encode([]byte{})\n\t\t\trequire.NoError(t, err)\n\t\t\tdst := &FunctionCall{}\n\t\t\t// Check the header\n\t\t\tmsgTypeCode := encoded[0]\n\t\t\tif msgTypeCode != 'F' {\n\t\t\t\tt.Errorf(\"msgTypeCode %v should be 'F'\", msgTypeCode)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t// Check length, does not include type code character\n\t\t\tl := binary.BigEndian.Uint32(encoded[1:5])\n\t\t\tif int(l) != (len(encoded) - 1) {\n\t\t\t\tt.Errorf(\"Incorrect message length, got = %v, wanted = %v\", l, len(encoded))\n\t\t\t}\n\t\t\t// Check decoding works as expected\n\t\t\terr = dst.Decode(encoded[5:])\n\t\t\tif err != nil {\n\t\t\t\tif !tt.wantErr {\n\t\t\t\t\tt.Errorf(\"FunctionCall.Decode() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif !reflect.DeepEqual(src, dst) {\n\t\t\t\tt.Error(\"difference after encode / decode cycle\")\n\t\t\t\tt.Errorf(\"src = %v\", src)\n\t\t\t\tt.Errorf(\"dst = %v\", dst)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func handleStatus(w http.ResponseWriter, r *http.Request) {\n\tdnsAddrs, err := collectDNSAddresses()\n\tif err != nil {\n\t\t// Don't add a lot of formatting, since the error is already\n\t\t// wrapped by collectDNSAddresses.\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"%s\", err)\n\n\t\treturn\n\t}\n\n\tvar resp statusResponse\n\tfunc() {\n\t\tconfig.RLock()\n\t\tdefer config.RUnlock()\n\n\t\tresp = statusResponse{\n\t\t\tDNSAddrs:  dnsAddrs,\n\t\t\tDNSPort:   config.DNS.Port,\n\t\t\tHTTPPort:  config.BindPort,\n\t\t\tIsRunning: isRunning(),\n\t\t\tVersion:   version.Version(),\n\t\t\tLanguage:  config.Language,\n\t\t}\n\t}()\n\n\tvar c *dnsforward.FilteringConfig\n\tif Context.dnsServer != nil {\n\t\tc = &dnsforward.FilteringConfig{}\n\t\tContext.dnsServer.WriteDiskConfig(c)\n\t\tresp.IsProtectionEnabled = c.ProtectionEnabled\n\t}\n\n\t// IsDHCPAvailable field is now false by default for Windows.\n\tif runtime.GOOS != \"windows\" {\n\t\tresp.IsDHCPAvailable = Context.dhcpServer != nil\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\terr = json.NewEncoder(w).Encode(resp)\n\tif err != nil {\n\t\taghhttp.Error(r, w, http.StatusInternalServerError, \"Unable to write response json: %s\", err)\n\n\t\treturn\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c Config) GetOAuthConfig(activeDirectoryEndpoint string) (*adal.OAuthConfig, error) {\n\tlog.Printf(\"Getting OAuth config for endpoint %s with  tenant %s\", activeDirectoryEndpoint, c.TenantID)\n\n\t// fix for ADFS environments, if the login endpoint ends in `/adfs` it's an adfs environment\n\t// the login endpoint ends up residing in `ActiveDirectoryEndpoint`\n\toAuthTenant := c.TenantID\n\tif strings.HasSuffix(strings.ToLower(activeDirectoryEndpoint), \"/adfs\") {\n\t\tlog.Printf(\"[DEBUG] ADFS environment detected - overriding Tenant ID to `adfs`!\")\n\t\toAuthTenant = \"adfs\"\n\t}\n\n\toauth, err := adal.NewOAuthConfig(activeDirectoryEndpoint, oAuthTenant)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// OAuthConfigForTenant returns a pointer, which can be nil.\n\tif oauth == nil {\n\t\treturn nil, fmt.Errorf(\"Unable to configure OAuthConfig for tenant %s\", c.TenantID)\n\t}\n\n\treturn oauth, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) TrafficEncoderAdd(ctx context.Context, in *clientpb.TrafficEncoder, opts ...grpc.CallOption) (*clientpb.TrafficEncoderTests, error) {\n\tout := new(clientpb.TrafficEncoderTests)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/TrafficEncoderAdd\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) handleCopyMove(w http.ResponseWriter, r *http.Request) (status int, err error) {\n\thdr := r.Header.Get(\"Destination\")\n\tif hdr == \"\" {\n\t\treturn http.StatusBadRequest, errInvalidDestination\n\t}\n\tu, err := url.Parse(hdr)\n\tif err != nil {\n\t\treturn http.StatusBadRequest, errInvalidDestination\n\t}\n\tif u.Host != \"\" && u.Host != r.Host {\n\t\treturn http.StatusBadGateway, errInvalidDestination\n\t}\n\n\tsrc, status, err := h.stripPrefix(r.URL.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\n\tdst, status, err := h.stripPrefix(u.Path)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\n\tif dst == \"\" {\n\t\treturn http.StatusBadGateway, errInvalidDestination\n\t}\n\tif dst == src {\n\t\treturn http.StatusForbidden, errDestinationEqualsSource\n\t}\n\n\tctx := r.Context()\n\tuser := ctx.Value(\"user\").(*model.User)\n\tsrc, err = user.JoinPath(src)\n\tif err != nil {\n\t\treturn 403, err\n\t}\n\tdst, err = user.JoinPath(dst)\n\tif err != nil {\n\t\treturn 403, err\n\t}\n\n\tif r.Method == \"COPY\" {\n\t\t// Section 7.5.1 says that a COPY only needs to lock the destination,\n\t\t// not both destination and source. Strictly speaking, this is racy,\n\t\t// even though a COPY doesn't modify the source, if a concurrent\n\t\t// operation modifies the source. However, the litmus test explicitly\n\t\t// checks that COPYing a locked-by-another source is OK.\n\t\trelease, status, err := h.confirmLocks(r, \"\", dst)\n\t\tif err != nil {\n\t\t\treturn status, err\n\t\t}\n\t\tdefer release()\n\n\t\t// Section 9.8.3 says that \"The COPY method on a collection without a Depth\n\t\t// header must act as if a Depth header with value \"infinity\" was included\".\n\t\tdepth := infiniteDepth\n\t\tif hdr := r.Header.Get(\"Depth\"); hdr != \"\" {\n\t\t\tdepth = parseDepth(hdr)\n\t\t\tif depth != 0 && depth != infiniteDepth {\n\t\t\t\t// Section 9.8.3 says that \"A client may submit a Depth header on a\n\t\t\t\t// COPY on a collection with a value of \"0\" or \"infinity\".\"\n\t\t\t\treturn http.StatusBadRequest, errInvalidDepth\n\t\t\t}\n\t\t}\n\t\treturn copyFiles(ctx, src, dst, r.Header.Get(\"Overwrite\") != \"F\")\n\t}\n\n\trelease, status, err := h.confirmLocks(r, src, dst)\n\tif err != nil {\n\t\treturn status, err\n\t}\n\tdefer release()\n\n\t// Section 9.9.2 says that \"The MOVE method on a collection must act as if\n\t// a \"Depth: infinity\" header was used on it. A client must not submit a\n\t// Depth header on a MOVE on a collection with any value but \"infinity\".\"\n\tif hdr := r.Header.Get(\"Depth\"); hdr != \"\" {\n\t\tif parseDepth(hdr) != infiniteDepth {\n\t\t\treturn http.StatusBadRequest, errInvalidDepth\n\t\t}\n\t}\n\treturn moveFiles(ctx, src, dst, r.Header.Get(\"Overwrite\") == \"T\")\n}", "is_vulnerable": 0}
{"code": "func setprocattr(attr, value string) error {\n\t// Under AppArmor you can only change your own attr, so use /proc/self/\n\t// instead of /proc/<tid>/ like libapparmor does\n\tpath := fmt.Sprintf(\"/proc/self/attr/%s\", attr)\n\n\tf, err := os.OpenFile(path, os.O_WRONLY, 0)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer f.Close()\n\n\t_, err = fmt.Fprintf(f, \"%s\", value)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func NewBearerAuthRoundTripper(bearer string, rt http.RoundTripper) http.RoundTripper {\n\treturn &bearerAuthRoundTripper{bearer, rt}\n}", "is_vulnerable": 1}
{"code": "func (c *Context) Sign(signers []*Key, plain, sig *Data, mode SigMode) error {\n\tC.gpgme_signers_clear(c.ctx)\n\tfor _, k := range signers {\n\t\tif err := handleError(C.gpgme_signers_add(c.ctx, k.k)); err != nil {\n\t\t\tC.gpgme_signers_clear(c.ctx)\n\t\t\treturn err\n\t\t}\n\t}\n\terr := handleError(C.gpgme_op_sign(c.ctx, plain.dh, sig.dh, C.gpgme_sig_mode_t(mode)))\n\truntime.KeepAlive(plain)\n\truntime.KeepAlive(sig)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func Commands(con *console.SliverClient) []*cobra.Command {\n\t// [ Generate ] --------------------------------------------------------------\n\tgenerateCmd := &cobra.Command{\n\t\tUse:   consts.GenerateStr,\n\t\tShort: \"Generate an implant binary\",\n\t\tLong:  help.GetHelpFor([]string{consts.GenerateStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tGenerateCmd(cmd, con, args)\n\t\t},\n\t\tGroupID: consts.PayloadsHelpGroup,\n\t}\n\tflags.Bind(\"generate\", true, generateCmd, func(f *pflag.FlagSet) {\n\t\tf.IntP(\"timeout\", \"t\", flags.DefaultTimeout, \"grpc timeout in seconds\")\n\t})\n\n\t// Session flags and completions.\n\tcoreImplantFlags(\"session\", generateCmd)\n\tcompileImplantFlags(\"session\", generateCmd)\n\tcoreImplantFlagCompletions(generateCmd, con)\n\n\tgenerateBeaconCmd := &cobra.Command{\n\t\tUse:   consts.BeaconStr,\n\t\tShort: \"Generate a beacon binary\",\n\t\tLong:  help.GetHelpFor([]string{consts.GenerateStr, consts.BeaconStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tGenerateBeaconCmd(cmd, con, args)\n\t\t},\n\t}\n\n\t// Beacon flags and completions.\n\tcoreImplantFlags(\"beacon\", generateBeaconCmd)\n\tcompileImplantFlags(\"beacon\", generateBeaconCmd)\n\tcoreBeaconFlags(\"beacon\", generateBeaconCmd)\n\tcoreImplantFlagCompletions(generateBeaconCmd, con)\n\n\tgenerateCmd.AddCommand(generateBeaconCmd)\n\n\tgenerateStagerCmd := &cobra.Command{\n\t\tUse:   consts.MsfStagerStr,\n\t\tShort: \"Generate a stager using Metasploit (requires local Metasploit installation)\",\n\t\tLong:  help.GetHelpFor([]string{consts.MsfStagerStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tGenerateStagerCmd(cmd, con, args)\n\t\t},\n\t}\n\tflags.Bind(\"stager\", false, generateStagerCmd, func(f *pflag.FlagSet) {\n\t\tf.StringP(\"os\", \"o\", \"windows\", \"operating system\")\n\t\tf.StringP(\"arch\", \"a\", \"amd64\", \"cpu architecture\")\n\t\tf.StringP(\"lhost\", \"L\", \"\", \"Listening host\")\n\t\tf.Uint32P(\"lport\", \"l\", 8443, \"Listening port\")\n\t\tf.StringP(\"protocol\", \"r\", \"tcp\", \"Staging protocol (tcp/http/https)\")\n\t\tf.StringP(\"format\", \"f\", \"raw\", \"Output format (msfvenom formats, see help generate msf-stager for the list)\")\n\t\tf.StringP(\"badchars\", \"b\", \"\", \"bytes to exclude from stage shellcode\")\n\t\tf.StringP(\"save\", \"s\", \"\", \"directory to save the generated stager to\")\n\t\tf.StringP(\"advanced\", \"d\", \"\", \"Advanced options for the stager using URI query syntax (option1=value1&option2=value2...)\")\n\t})\n\tflags.BindFlagCompletions(generateStagerCmd, func(comp *carapace.ActionMap) {\n\t\t(*comp)[\"save\"] = carapace.ActionFiles().Tag(\"directory/file to save implant\")\n\t})\n\tgenerateCmd.AddCommand(generateStagerCmd)\n\n\tgenerateInfoCmd := &cobra.Command{\n\t\tUse:   consts.CompilerInfoStr,\n\t\tShort: \"Get information about the server's compiler\",\n\t\tLong:  help.GetHelpFor([]string{consts.CompilerInfoStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tGenerateInfoCmd(cmd, con, args)\n\t\t},\n\t}\n\tgenerateCmd.AddCommand(generateInfoCmd)\n\n\t// Traffic Encoder SubCommands\n\ttrafficEncodersCmd := &cobra.Command{\n\t\tUse:   consts.TrafficEncodersStr,\n\t\tShort: \"Manage implant traffic encoders\",\n\t\tLong:  help.GetHelpFor([]string{consts.GenerateStr, consts.TrafficEncodersStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tTrafficEncodersCmd(cmd, con, args)\n\t\t},\n\t}\n\tgenerateCmd.AddCommand(trafficEncodersCmd)\n\n\ttrafficEncodersAddCmd := &cobra.Command{\n\t\tUse:   consts.AddStr,\n\t\tShort: \"Add a new traffic encoder to the server from the local file system\",\n\t\tLong:  help.GetHelpFor([]string{consts.GenerateStr, consts.TrafficEncodersStr, consts.AddStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tTrafficEncodersAddCmd(cmd, con, args)\n\t\t},\n\t}\n\tflags.Bind(\"\", false, trafficEncodersAddCmd, func(f *pflag.FlagSet) {\n\t\tf.BoolP(\"skip-tests\", \"s\", false, \"skip testing the traffic encoder (not recommended)\")\n\t})\n\tcarapace.Gen(trafficEncodersAddCmd).PositionalCompletion(carapace.ActionFiles(\"wasm\").Tag(\"wasm files\").Usage(\"local file path (expects .wasm)\"))\n\ttrafficEncodersCmd.AddCommand(trafficEncodersAddCmd)\n\n\ttrafficEncodersRmCmd := &cobra.Command{\n\t\tUse:   consts.RmStr,\n\t\tShort: \"Remove a traffic encoder from the server\",\n\t\tLong:  help.GetHelpFor([]string{consts.GenerateStr, consts.TrafficEncodersStr, consts.RmStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tTrafficEncodersRemoveCmd(cmd, con, args)\n\t\t},\n\t}\n\tcarapace.Gen(trafficEncodersRmCmd).PositionalCompletion(TrafficEncodersCompleter(con).Usage(\"traffic encoder to remove\"))\n\ttrafficEncodersCmd.AddCommand(trafficEncodersRmCmd)\n\n\t// [ Regenerate ] --------------------------------------------------------------\n\n\tregenerateCmd := &cobra.Command{\n\t\tUse:   consts.RegenerateStr,\n\t\tShort: \"Regenerate an implant\",\n\t\tLong:  help.GetHelpFor([]string{consts.RegenerateStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tRegenerateCmd(cmd, con, args)\n\t\t},\n\t\tGroupID: consts.PayloadsHelpGroup,\n\t}\n\tflags.Bind(\"regenerate\", false, regenerateCmd, func(f *pflag.FlagSet) {\n\t\tf.StringP(\"save\", \"s\", \"\", \"directory/file to the binary to\")\n\t})\n\tflags.BindFlagCompletions(regenerateCmd, func(comp *carapace.ActionMap) {\n\t\t(*comp)[\"save\"] = carapace.ActionFiles().Tag(\"directory/file to save implant\")\n\t})\n\tcarapace.Gen(regenerateCmd).PositionalCompletion(ImplantBuildNameCompleter(con))\n\n\t// [ Profiles ] --------------------------------------------------------------\n\n\tprofilesCmd := &cobra.Command{\n\t\tUse:   consts.ProfilesStr,\n\t\tShort: \"List existing profiles\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesCmd(cmd, con, args)\n\t\t},\n\t\tGroupID: consts.PayloadsHelpGroup,\n\t}\n\tflags.Bind(\"profiles\", true, profilesCmd, func(f *pflag.FlagSet) {\n\t\tf.IntP(\"timeout\", \"t\", flags.DefaultTimeout, \"grpc timeout in seconds\")\n\t})\n\n\tprofilesGenerateCmd := &cobra.Command{\n\t\tUse:   consts.GenerateStr,\n\t\tShort: \"Generate implant from a profile\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.GenerateStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesGenerateCmd(cmd, con, args)\n\t\t},\n\t}\n\tflags.Bind(\"profiles\", false, profilesGenerateCmd, func(f *pflag.FlagSet) {\n\t\tf.StringP(\"save\", \"s\", \"\", \"directory/file to the binary to\")\n\t\tf.BoolP(\"disable-sgn\", \"G\", false, \"disable shikata ga nai shellcode encoder\")\n\t})\n\tflags.BindFlagCompletions(profilesGenerateCmd, func(comp *carapace.ActionMap) {\n\t\t(*comp)[\"save\"] = carapace.ActionFiles().Tag(\"directory/file to save implant\")\n\t})\n\tcarapace.Gen(profilesGenerateCmd).PositionalCompletion(ProfileNameCompleter(con))\n\tprofilesCmd.AddCommand(profilesGenerateCmd)\n\n\tprofilesNewCmd := &cobra.Command{\n\t\tUse:   consts.NewStr,\n\t\tShort: \"Create a new implant profile (interactive session)\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.NewStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesNewCmd(cmd, con, args)\n\t\t},\n\t}\n\tprofilesCmd.AddCommand(profilesNewCmd)\n\n\tprofilesStageCmd := &cobra.Command{\n\t\tUse:   consts.StageStr,\n\t\tShort: \"Generate implant from a profile and encode or encrypt it\",\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.StageStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesStageCmd(cmd, con, args)\n\t\t},\n\t}\n\tflags.Bind(\"profiles\", false, profilesStageCmd, func(f *pflag.FlagSet) {\n\t\tf.StringP(\"save\", \"s\", \"\", \"directory/file to the binary to\")\n\t\tf.StringP(\"name\", \"n\", \"\", \"Implant name\")\n\t\tf.StringP(\"aes-encrypt-key\", \"k\", \"\", \"AES Encryption Key\")\n\t\tf.StringP(\"aes-encrypt-iv\", \"i\", \"\", \"AES Encryption IV\")\n\t\tf.StringP(\"rc4-encrypt-key\", \"r\", \"\", \"RC4 encryption key\")\n\t\tf.BoolP(\"prepend-size\", \"p\", false, \"Prepend stage size\")\n\t\tf.StringP(\"compress\", \"c\", \"\", \"Compress stage (zlib, gzip, deflate9 or deflate)\")\n\t})\n\n\tcarapace.Gen(profilesStageCmd).PositionalCompletion(ProfileNameCompleter(con))\n\tprofilesCmd.AddCommand(profilesStageCmd)\n\n\t// Session flags and completions.\n\tcoreImplantFlags(\"session\", profilesNewCmd)\n\tcompileImplantFlags(\"session\", profilesNewCmd)\n\tcoreImplantFlagCompletions(profilesNewCmd, con)\n\n\tprofilesNewBeaconCmd := &cobra.Command{\n\t\tUse:   consts.BeaconStr,\n\t\tShort: \"Create a new implant profile (beacon)\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.NewStr, consts.BeaconStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesNewBeaconCmd(cmd, con, args)\n\t\t},\n\t}\n\tprofilesNewCmd.AddCommand(profilesNewBeaconCmd)\n\n\t// Beacon flags and completions.\n\tcoreImplantFlags(\"beacon\", profilesNewBeaconCmd)\n\tcompileImplantFlags(\"beacon\", profilesNewBeaconCmd)\n\tcoreBeaconFlags(\"beacon\", profilesNewBeaconCmd)\n\tcoreImplantFlagCompletions(profilesNewBeaconCmd, con)\n\n\tprofilesRmCmd := &cobra.Command{\n\t\tUse:   consts.RmStr,\n\t\tShort: \"Remove a profile\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.RmStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tProfilesRmCmd(cmd, con, args)\n\t\t},\n\t}\n\tcarapace.Gen(profilesRmCmd).PositionalCompletion(ProfileNameCompleter(con))\n\tprofilesCmd.AddCommand(profilesRmCmd)\n\n\tprofilesInfoCmd := &cobra.Command{\n\t\tUse:   consts.InfoStr,\n\t\tShort: \"Details about a profile\",\n\t\tLong:  help.GetHelpFor([]string{consts.ProfilesStr, consts.RmStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tPrintProfileInfo(args[0], con)\n\t\t},\n\t}\n\tcarapace.Gen(profilesInfoCmd).PositionalCompletion(ProfileNameCompleter(con))\n\tprofilesCmd.AddCommand(profilesInfoCmd)\n\n\t// [ Implants ] --------------------------------------------------------------\n\n\timplantBuildsCmd := &cobra.Command{\n\t\tUse:   consts.ImplantBuildsStr,\n\t\tShort: \"List implant builds\",\n\t\tLong:  help.GetHelpFor([]string{consts.ImplantBuildsStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tImplantsCmd(cmd, con, args)\n\t\t},\n\t\tGroupID: consts.PayloadsHelpGroup,\n\t}\n\tflags.Bind(\"implants\", true, implantBuildsCmd, func(f *pflag.FlagSet) {\n\t\tf.IntP(\"timeout\", \"t\", flags.DefaultTimeout, \"grpc timeout in seconds\")\n\t})\n\tflags.Bind(\"implants\", false, implantBuildsCmd, func(f *pflag.FlagSet) {\n\t\tf.StringP(\"os\", \"o\", \"\", \"filter builds by operating system\")\n\t\tf.StringP(\"arch\", \"a\", \"\", \"filter builds by cpu architecture\")\n\t\tf.StringP(\"format\", \"f\", \"\", \"filter builds by artifact format\")\n\t\tf.BoolP(\"only-sessions\", \"s\", false, \"filter interactive sessions\")\n\t\tf.BoolP(\"only-beacons\", \"b\", false, \"filter beacons\")\n\t\tf.BoolP(\"no-debug\", \"d\", false, \"filter builds by debug flag\")\n\t})\n\tflags.BindFlagCompletions(implantBuildsCmd, func(comp *carapace.ActionMap) {\n\t\t(*comp)[\"os\"] = OSCompleter(con)\n\t\t(*comp)[\"arch\"] = ArchCompleter(con)\n\t\t(*comp)[\"format\"] = FormatCompleter()\n\t})\n\n\timplantsRmCmd := &cobra.Command{\n\t\tUse:   consts.RmStr,\n\t\tShort: \"Remove implant build\",\n\t\tLong:  help.GetHelpFor([]string{consts.ImplantBuildsStr, consts.RmStr}),\n\t\tArgs:  cobra.ExactArgs(1),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tImplantsRmCmd(cmd, con, args)\n\t\t},\n\t}\n\tcarapace.Gen(implantsRmCmd).PositionalCompletion(ImplantBuildNameCompleter(con))\n\timplantBuildsCmd.AddCommand(implantsRmCmd)\n\n\timplantsStageCmd := &cobra.Command{\n\t\tUse:   consts.StageStr,\n\t\tShort: \"Serve a previously generated build\",\n\t\tLong:  help.GetHelpFor([]string{consts.ImplantBuildsStr, consts.StageStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tImplantsStageCmd(cmd, con, args)\n\t\t},\n\t}\n\timplantBuildsCmd.AddCommand(implantsStageCmd)\n\n\tcanariesCmd := &cobra.Command{\n\t\tUse:   consts.CanariesStr,\n\t\tShort: \"List previously generated canaries\",\n\t\tLong:  help.GetHelpFor([]string{consts.CanariesStr}),\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\tCanariesCmd(cmd, con, args)\n\t\t},\n\t\tGroupID: consts.PayloadsHelpGroup,\n\t}\n\tflags.Bind(\"canaries\", false, canariesCmd, func(f *pflag.FlagSet) {\n\t\tf.BoolP(\"burned\", \"b\", false, \"show only triggered/burned canaries\")\n\t\tf.Int64P(\"timeout\", \"t\", flags.DefaultTimeout, \"grpc timeout in seconds\")\n\t})\n\n\treturn []*cobra.Command{generateCmd, regenerateCmd, profilesCmd, implantBuildsCmd}\n}", "is_vulnerable": 1}
{"code": "func (c *Context) TextMode() bool {\n\tres := C.gpgme_get_textmode(c.ctx) != 0\n\truntime.KeepAlive(c)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func (m *NestedNinOptNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowRequiredexample\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NestedNinOptNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NestedNinOptNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NestedNinOpts\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowRequiredexample\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthRequiredexample\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthRequiredexample\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.NestedNinOpts = append(m.NestedNinOpts, &NinOptNative{})\n\t\t\tif err := m.NestedNinOpts[len(m.NestedNinOpts)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipRequiredexample(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthRequiredexample\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthRequiredexample\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func BenchmarkRouterServe(b *testing.B) {\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {}))\n\n\tb.Cleanup(func() { server.Close() })\n\n\tres := &http.Response{\n\t\tStatusCode: http.StatusOK,\n\t\tBody:       io.NopCloser(strings.NewReader(\"\")),\n\t}\n\n\troutersConfig := map[string]*dynamic.Router{\n\t\t\"foo\": {\n\t\t\tEntryPoints: []string{\"web\"},\n\t\t\tService:     \"foo-service\",\n\t\t\tRule:        \"Host(`foo.bar`) && Path(`/`)\",\n\t\t},\n\t}\n\tserviceConfig := map[string]*dynamic.Service{\n\t\t\"foo-service\": {\n\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t{\n\t\t\t\t\t\tURL: server.URL,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tentryPoints := []string{\"web\"}\n\n\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\tServices:    serviceConfig,\n\t\t\tRouters:     routersConfig,\n\t\t\tMiddlewares: map[string]*dynamic.Middleware{},\n\t\t},\n\t})\n\n\tserviceManager := service.NewManager(rtConf.Services, nil, nil, staticRoundTripperGetter{res})\n\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\ttlsManager := tls.NewManager()\n\n\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry(), tlsManager)\n\n\thandlers := routerManager.BuildHandlers(context.Background(), entryPoints, false)\n\n\tw := httptest.NewRecorder()\n\treq := testhelpers.MustNewRequest(http.MethodGet, \"http://foo.bar/\", nil)\n\n\treqHost := requestdecorator.New(nil)\n\tb.ReportAllocs()\n\tfor i := 0; i < b.N; i++ {\n\t\treqHost.ServeHTTP(w, req, handlers[\"web\"].ServeHTTP)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockCoreStrategyMockRecorder) ValidateAccessToken(arg0, arg1, arg2 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ValidateAccessToken\", reflect.TypeOf((*MockCoreStrategy)(nil).ValidateAccessToken), arg0, arg1, arg2)\n}", "is_vulnerable": 0}
{"code": "func TestAuthorizationModelInvalidSchemaVersion(t *testing.T) {\n\tctx := context.Background()\n\tlogger := logger.NewNoopLogger()\n\ttransport := gateway.NewNoopTransport()\n\tstore := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().MaxTypesPerAuthorizationModel().Return(100)\n\n\tmockDatastore.EXPECT().ReadAuthorizationModel(gomock.Any(), store, modelID).AnyTimes().Return(&openfgapb.AuthorizationModel{\n\t\tSchemaVersion: typesystem.SchemaVersion1_0,\n\t\tTypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t{\n\t\t\t\tType: \"user\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tType: \"team\",\n\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\"member\": typesystem.This(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, nil)\n\tmockDatastore.EXPECT().ListObjectsByType(gomock.Any(), store, \"repo\").AnyTimes().Return(nil, errors.New(\"error reading from storage\"))\n\n\ts := Server{\n\t\tdatastore: mockDatastore,\n\t\ttransport: transport,\n\t\tlogger:    logger,\n\t\tconfig: &Config{\n\t\t\tResolveNodeLimit:      test.DefaultResolveNodeLimit,\n\t\t\tListObjectsDeadline:   5 * time.Second,\n\t\t\tListObjectsMaxResults: 1000,\n\t\t},\n\t}\n\n\tt.Run(\"invalid_schema_error_in_check\", func(t *testing.T) {\n\t\t_, err := s.Check(ctx, &openfgapb.CheckRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tTupleKey: tuple.NewTupleKey(\n\t\t\t\t\"team:abc\",\n\t\t\t\t\"member\",\n\t\t\t\t\"user:anne\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_list_objects\", func(t *testing.T) {\n\t\t_, err := s.ListObjects(ctx, &openfgapb.ListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"team\",\n\t\t\tRelation:             \"member\",\n\t\t\tUser:                 \"user:anne\",\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_streamed_list_objects\", func(t *testing.T) {\n\t\terr := s.StreamedListObjects(&openfgapb.StreamedListObjectsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tType:                 \"team\",\n\t\t\tRelation:             \"member\",\n\t\t\tUser:                 \"user:anne\",\n\t\t}, NewMockStreamServer())\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_expand\", func(t *testing.T) {\n\t\t_, err := s.Expand(ctx, &openfgapb.ExpandRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tTupleKey: tuple.NewTupleKey(\"repo:openfga\",\n\t\t\t\t\"reader\",\n\t\t\t\t\"user:anne\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write\", func(t *testing.T) {\n\t\t_, err := s.Write(ctx, &openfgapb.WriteRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tWrites: &openfgapb.TupleKeys{TupleKeys: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"repo:openfga/openfga\",\n\t\t\t\t\t\"reader\",\n\t\t\t\t\t\"user:anne\"),\n\t\t\t}},\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write_model\", func(t *testing.T) {\n\t\t_, err := s.WriteAuthorizationModel(ctx, &openfgapb.WriteAuthorizationModelRequest{\n\t\t\tStoreId:         store,\n\t\t\tSchemaVersion:   typesystem.SchemaVersion1_0,\n\t\t\tTypeDefinitions: parser.MustParse(`type repo`),\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_invalid_authorization_model), e.Code(), err)\n\t})\n\n\tt.Run(\"invalid_schema_error_in_write_assertion\", func(t *testing.T) {\n\t\t_, err := s.WriteAssertions(ctx, &openfgapb.WriteAssertionsRequest{\n\t\t\tStoreId:              store,\n\t\t\tAuthorizationModelId: modelID,\n\t\t\tAssertions: []*openfgapb.Assertion{{\n\t\t\t\tTupleKey:    tuple.NewTupleKey(\"repo:test\", \"reader\", \"user:elbuo\"),\n\t\t\t\tExpectation: false,\n\t\t\t}},\n\t\t})\n\t\trequire.Error(t, err)\n\t\te, ok := status.FromError(err)\n\t\trequire.True(t, ok)\n\t\trequire.Equal(t, codes.Code(openfgapb.ErrorCode_validation_error), e.Code())\n\t})\n}", "is_vulnerable": 0}
{"code": "func BenchmarkBitfield(t *testing.B) {\n\tbf := NewBitfield(benchmarkSize)\n\tt.ResetTimer()\n\tfor i := 0; i < t.N; i++ {\n\t\tif bf.Bit(i % benchmarkSize) {\n\t\t\tt.Fatal(\"bad\", i)\n\t\t}\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tif !bf.Bit(i % benchmarkSize) {\n\t\t\tt.Fatal(\"bad\", i)\n\t\t}\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tbf.SetBit(i % benchmarkSize)\n\t\tbf.UnsetBit(i % benchmarkSize)\n\t\tif bf.Bit(i % benchmarkSize) {\n\t\t\tt.Fatal(\"bad\", i)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func pipeExtensions(cfg *config.Configuration, request *pipeRequest) (response pipeResponse, err error) {\n\tvar extcmds []*extCommand\n\tdefer func() {\n\t\t// In the case of an early return before the end of this\n\t\t// function (in response to an error, etc), kill all running\n\t\t// processes. Errors are ignored since the function has already\n\t\t// returned.\n\t\t//\n\t\t// In the happy path, the commands will have already been\n\t\t// `Wait()`-ed upon and e.cmd.Process.Kill() will return an\n\t\t// error, but we can ignore it.\n\t\tfor _, e := range extcmds {\n\t\t\tif e.cmd.Process != nil {\n\t\t\t\te.cmd.Process.Kill()\n\t\t\t}\n\t\t}\n\t}()\n\n\tfor _, e := range request.extensions {\n\t\tvar pieces []string\n\t\tswitch request.action {\n\t\tcase \"clean\":\n\t\t\tpieces = strings.Split(e.Clean, \" \")\n\t\tcase \"smudge\":\n\t\t\tpieces = strings.Split(e.Smudge, \" \")\n\t\tdefault:\n\t\t\terr = fmt.Errorf(\"Invalid action: \" + request.action)\n\t\t\treturn\n\t\t}\n\t\tname := strings.Trim(pieces[0], \" \")\n\t\tvar args []string\n\t\tfor _, value := range pieces[1:] {\n\t\t\targ := strings.Replace(value, \"%f\", request.fileName, -1)\n\t\t\targs = append(args, arg)\n\t\t}\n\t\tcmd := subprocess.ExecCommand(name, args...)\n\t\tec := &extCommand{cmd: cmd, result: &pipeExtResult{name: e.Name}}\n\t\textcmds = append(extcmds, ec)\n\t}\n\n\thasher := sha256.New()\n\tpipeReader, pipeWriter := io.Pipe()\n\tmultiWriter := io.MultiWriter(hasher, pipeWriter)\n\n\tvar input io.Reader\n\tvar output io.WriteCloser\n\tinput = pipeReader\n\textcmds[0].cmd.Stdin = input\n\tif response.file, err = TempFile(cfg, \"\"); err != nil {\n\t\treturn\n\t}\n\tdefer response.file.Close()\n\toutput = response.file\n\n\tlast := len(extcmds) - 1\n\tfor i, ec := range extcmds {\n\t\tec.hasher = sha256.New()\n\n\t\tif i == last {\n\t\t\tec.cmd.Stdout = io.MultiWriter(ec.hasher, output)\n\t\t\tec.out = output\n\t\t\tcontinue\n\t\t}\n\n\t\tnextec := extcmds[i+1]\n\t\tvar nextStdin io.WriteCloser\n\t\tvar stdout io.ReadCloser\n\t\tif nextStdin, err = nextec.cmd.StdinPipe(); err != nil {\n\t\t\treturn\n\t\t}\n\t\tif stdout, err = ec.cmd.StdoutPipe(); err != nil {\n\t\t\treturn\n\t\t}\n\n\t\tec.cmd.Stdin = input\n\t\tec.cmd.Stdout = io.MultiWriter(ec.hasher, nextStdin)\n\t\tec.out = nextStdin\n\n\t\tinput = stdout\n\n\t\tvar errBuff bytes.Buffer\n\t\tec.err = &errBuff\n\t\tec.cmd.Stderr = ec.err\n\t}\n\n\tfor _, ec := range extcmds {\n\t\tif err = ec.cmd.Start(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\tif _, err = io.Copy(multiWriter, request.reader); err != nil {\n\t\treturn\n\t}\n\tif err = pipeWriter.Close(); err != nil {\n\t\treturn\n\t}\n\n\tfor _, ec := range extcmds {\n\t\tif err = ec.cmd.Wait(); err != nil {\n\t\t\tif ec.err != nil {\n\t\t\t\terrStr := ec.err.String()\n\t\t\t\terr = fmt.Errorf(\"extension '%s' failed with: %s\", ec.result.name, errStr)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif err = ec.out.Close(); err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\toid := hex.EncodeToString(hasher.Sum(nil))\n\tfor _, ec := range extcmds {\n\t\tec.result.oidIn = oid\n\t\toid = hex.EncodeToString(ec.hasher.Sum(nil))\n\t\tec.result.oidOut = oid\n\t\tresponse.results = append(response.results, ec.result)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func Pipe2(p []int, flags int) (err error) {\n\tif len(p) != 2 {\n\t\treturn EINVAL\n\t}\n\tvar pp [2]_C_int\n\terr = pipe2(&pp, flags)\n\tp[0] = int(pp[0])\n\tp[1] = int(pp[1])\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"must specify topic or subscriptionID\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"gcp-pubsub.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.PubSub)\n\n\tfor name, value := range eventSource.Spec.PubSub {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tPubSubEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) SetRequestedScopes(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"SetRequestedScopes\", reflect.TypeOf((*MockAuthorizeRequester)(nil).SetRequestedScopes), arg0)\n}", "is_vulnerable": 0}
{"code": "func TestWithDatastoreCursorInCursor(t *testing.T) {\n\tlimits, _ := newLimitTracker(context.Background(), 10)\n\trevision := revision.NewFromDecimal(decimal.NewFromInt(1))\n\n\tci, err := newCursorInformation(&v1.Cursor{\n\t\tAtRevision: revision.String(),\n\t\tSections:   []string{\"dsc\", \"document:firstdoc#viewer@user:tom\"},\n\t}, revision, limits)\n\trequire.NoError(t, err)\n\n\ti := 0\n\tcursors := []string{\n\t\t\"document:firstdoc#viewer@user:tom\",\n\t\t\"document:seconddoc#viewer@user:tom\",\n\t\t\"document:thirddoc#viewer@user:tom\",\n\t}\n\n\terr = withDatastoreCursorInCursor(ci, \"dsc\",\n\t\tfunc(queryCursor options.Cursor, ci cursorInformation) (options.Cursor, error) {\n\t\t\trequire.Equal(t, cursors[i], tuple.MustString(queryCursor))\n\t\t\ti++\n\t\t\tif i >= len(cursors) {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\n\t\t\treturn options.Cursor(tuple.MustParse(cursors[i])), nil\n\t\t})\n\trequire.NoError(t, err)\n\trequire.Equal(t, i, 3)\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(test.path, func(t *testing.T) {\n\t\t\tassert.Equal(t, test.wantVal, isRepositoryGitPath(test.path))\n\t\t})", "is_vulnerable": 0}
{"code": "func (p *CompactProtocol) ReadMapBegin() (keyType Type, valueType Type, size int, err error) {\n\tsize32, e := p.readVarint32()\n\tif e != nil {\n\t\terr = NewProtocolException(e)\n\t\treturn\n\t}\n\tif size32 < 0 {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tif uint64(size32*2) > p.trans.RemainingBytes() || p.trans.RemainingBytes() == UnknownRemaining {\n\t\terr = invalidDataLength\n\t\treturn\n\t}\n\tsize = int(size32)\n\n\tkeyAndValueType := byte(STOP)\n\tif size != 0 {\n\t\tkeyAndValueType, err = p.readByteDirect()\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\tkeyType, _ = p.getType(compactType(keyAndValueType >> 4))\n\tvalueType, _ = p.getType(compactType(keyAndValueType & 0xf))\n\treturn\n}", "is_vulnerable": 0}
{"code": "func isChunked(r *http.Request) bool {\n\t//RFC 7230 specifies that content length is to be ignored if Transfer-Encoding is chunked\n\tif strings.ToLower(r.Header.Get(\"Transfer-Encoding\")) == \"chunked\" {\n\t\treturn true\n\t}\n\tfor _, v := range r.TransferEncoding {\n\t\tif 0 == strings.Compare(strings.ToLower(v), \"chunked\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"access key can't be empty\", err.Error())\n\n\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"minio.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Minio)\n\n\tfor _, value := range eventSource.Spec.Minio {\n\t\tl := &EventListener{\n\t\t\tMinioEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestLookupResourcesOverSchemaWithCursors(t *testing.T) {\n\ttestCases := []struct {\n\t\tname                string\n\t\tschema              string\n\t\trelationships       []*core.RelationTuple\n\t\tpermission          *core.RelationReference\n\t\tsubject             *core.ObjectAndRelation\n\t\texpectedResourceIDs []string\n\t}{\n\t\t{\n\t\t\t\"basic union\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 1510),\n\t\t\t\tgenTuples(\"document\", \"editor\", \"user\", \"tom\", 1510),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 1510),\n\t\t},\n\t\t{\n\t\t\t\"basic exclusion\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation banned: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - banned\n  \t\t\t }`,\n\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 1010),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 1010),\n\t\t},\n\t\t{\n\t\t\t\"basic intersection\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer & editor\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 510),\n\t\t\t\tgenTuples(\"document\", \"editor\", \"user\", \"tom\", 510),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 510),\n\t\t},\n\t\t{\n\t\t\t\"union and exclused union\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\trelation banned: user\n\t\t\t\tpermission can_view = viewer - banned\n\t\t\t\tpermission view = can_view + editor\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 1310),\n\t\t\t\tgenTuplesWithOffset(\"document\", \"editor\", \"user\", \"tom\", 1250, 1200),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 2450),\n\t\t},\n\t\t{\n\t\t\t\"basic caveats\",\n\t\t\t`definition user {}\n\n \t\t\t caveat somecaveat(somecondition int) {\n\t\t\t\tsomecondition == 42\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation viewer: user with somecaveat\n\t\t\t\tpermission view = viewer\n  \t\t\t }`,\n\t\t\tgenTuplesWithCaveat(\"document\", \"viewer\", \"user\", \"tom\", \"somecaveat\", map[string]any{\"somecondition\": 42}, 0, 2450),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 2450),\n\t\t},\n\t\t{\n\t\t\t\"excluded items\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation banned: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer - banned\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 1310),\n\t\t\t\tgenTuplesWithOffset(\"document\", \"banned\", \"user\", \"tom\", 1210, 100),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 1210),\n\t\t},\n\t\t{\n\t\t\t\"basic caveats with missing field\",\n\t\t\t`definition user {}\n\n \t\t\t caveat somecaveat(somecondition int) {\n\t\t\t\tsomecondition == 42\n\t\t\t }\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation viewer: user with somecaveat\n\t\t\t\tpermission view = viewer\n  \t\t\t }`,\n\t\t\tgenTuplesWithCaveat(\"document\", \"viewer\", \"user\", \"tom\", \"somecaveat\", map[string]any{}, 0, 2450),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 2450),\n\t\t},\n\t\t{\n\t\t\t\"larger arrow dispatch\",\n\t\t\t`definition user {}\n\t\n\t\t\t definition folder {\n\t\t\t\trelation viewer: user\n\t\t\t }\n\n\t\t \t definition document {\n\t\t\t\trelation folder: folder\n\t\t\t\tpermission view = folder->viewer\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"folder\", \"viewer\", \"user\", \"tom\", 150),\n\t\t\t\tgenSubjectTuples(\"document\", \"folder\", \"folder\", \"...\", 150),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 150),\n\t\t},\n\t\t{\n\t\t\t\"big\",\n\t\t\t`definition user {}\n\t\t\n\t\t \t definition document {\n\t\t\t\trelation editor: user\n\t\t\t\trelation viewer: user\n\t\t\t\tpermission view = viewer + editor\n  \t\t\t }`,\n\t\t\tjoinTuples(\n\t\t\t\tgenTuples(\"document\", \"viewer\", \"user\", \"tom\", 15100),\n\t\t\t\tgenTuples(\"document\", \"editor\", \"user\", \"tom\", 15100),\n\t\t\t),\n\t\t\tRR(\"document\", \"view\"),\n\t\t\tONR(\"user\", \"tom\", \"...\"),\n\t\t\tgenResourceIds(\"document\", 15100),\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tfor _, pageSize := range []int{0, 104, 1023} {\n\t\t\t\tpageSize := pageSize\n\t\t\t\tt.Run(fmt.Sprintf(\"ps-%d_\", pageSize), func(t *testing.T) {\n\t\t\t\t\trequire := require.New(t)\n\n\t\t\t\t\tdispatcher := NewLocalOnlyDispatcher(10)\n\n\t\t\t\t\tds, err := memdb.NewMemdbDatastore(0, 0, memdb.DisableGC)\n\t\t\t\t\trequire.NoError(err)\n\n\t\t\t\t\tds, revision := testfixtures.DatastoreFromSchemaAndTestRelationships(ds, tc.schema, tc.relationships, require)\n\n\t\t\t\t\tctx := datastoremw.ContextWithHandle(context.Background())\n\t\t\t\t\trequire.NoError(datastoremw.SetInContext(ctx, ds))\n\n\t\t\t\t\tvar currentCursor *v1.Cursor\n\t\t\t\t\tfoundResourceIDs := util.NewSet[string]()\n\t\t\t\t\tfor {\n\t\t\t\t\t\tstream := dispatch.NewCollectingDispatchStream[*v1.DispatchLookupResourcesResponse](ctx)\n\t\t\t\t\t\terr = dispatcher.DispatchLookupResources(&v1.DispatchLookupResourcesRequest{\n\t\t\t\t\t\t\tObjectRelation: tc.permission,\n\t\t\t\t\t\t\tSubject:        tc.subject,\n\t\t\t\t\t\t\tMetadata: &v1.ResolverMeta{\n\t\t\t\t\t\t\t\tAtRevision:     revision.String(),\n\t\t\t\t\t\t\t\tDepthRemaining: 50,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tOptionalLimit:  uint32(pageSize),\n\t\t\t\t\t\t\tOptionalCursor: currentCursor,\n\t\t\t\t\t\t}, stream)\n\t\t\t\t\t\trequire.NoError(err)\n\n\t\t\t\t\t\tif pageSize > 0 {\n\t\t\t\t\t\t\trequire.LessOrEqual(len(stream.Results()), pageSize)\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tfor _, result := range stream.Results() {\n\t\t\t\t\t\t\tfoundResourceIDs.Add(result.ResolvedResource.ResourceId)\n\t\t\t\t\t\t\tcurrentCursor = result.AfterResponseCursor\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif pageSize == 0 || len(stream.Results()) < pageSize {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tfoundResourceIDsSlice := foundResourceIDs.AsSlice()\n\t\t\t\t\tsort.Strings(foundResourceIDsSlice)\n\t\t\t\t\tsort.Strings(tc.expectedResourceIDs)\n\n\t\t\t\t\trequire.Equal(tc.expectedResourceIDs, foundResourceIDsSlice)\n\t\t\t\t})\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func InstrumentRoundTripperDuration(obs prometheus.ObserverVec, next http.RoundTripper, opts ...Option) RoundTripperFunc {\n\trtOpts := &option{}\n\tfor _, o := range opts {\n\t\to(rtOpts)\n\t}\n\n\tcode, method := checkLabels(obs)\n\n\treturn RoundTripperFunc(func(r *http.Request) (*http.Response, error) {\n\t\tstart := time.Now()\n\t\tresp, err := next.RoundTrip(r)\n\t\tif err == nil {\n\t\t\tobs.With(labels(code, method, r.Method, resp.StatusCode, rtOpts.extraMethods...)).Observe(time.Since(start).Seconds())\n\t\t}\n\t\treturn resp, err\n\t})\n}", "is_vulnerable": 0}
{"code": "func (request *Request) Compile(options *protocols.ExecutorOptions) error {\n\trequest.options = options\n\n\tclient, err := networkclientpool.Get(options.Options, &networkclientpool.Configuration{})\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"could not get network client\")\n\t}\n\trequest.dialer = client\n\n\tif len(request.Payloads) > 0 {\n\t\trequest.generator, err = generators.New(request.Payloads, request.AttackType.Value, request.options.TemplatePath, request.options.Options.AllowLocalFileAccess, options.Catalog, options.Options.AttackType)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"could not parse payloads\")\n\t\t}\n\t}\n\n\tif len(request.Matchers) > 0 || len(request.Extractors) > 0 {\n\t\tcompiled := &request.Operators\n\t\tcompiled.ExcludeMatchers = options.ExcludeMatchers\n\t\tcompiled.TemplateID = options.TemplateID\n\t\tif err := compiled.Compile(); err != nil {\n\t\t\treturn errors.Wrap(err, \"could not compile operators\")\n\t\t}\n\t\trequest.CompiledOperators = compiled\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (n *selfnotoken) Run(t *testing.T, ctx context.Context) {\n\tn.daprd.WaitUntilRunning(t, ctx)\n\n\tdclient := n.daprd.GRPCClient(t, ctx)\n\t_, err := dclient.InvokeService(ctx, &runtimev1.InvokeServiceRequest{\n\t\tId: n.daprd.AppID(),\n\t\tMessage: &commonv1.InvokeRequest{\n\t\t\tMethod:        \"helloworld\",\n\t\t\tData:          new(anypb.Any),\n\t\t\tHttpExtension: &commonv1.HTTPExtension{Verb: commonv1.HTTPExtension_GET},\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase header := <-n.ch:\n\t\trequire.Empty(t, header.Values(\"dapr-api-token\"))\n\tcase <-time.After(5 * time.Second):\n\t\tassert.Fail(t, \"timed out waiting for header\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *NidOptStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidOptStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidOptStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.Field1 = float64(math.Float64frombits(v))\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.Field2 = float32(math.Float32frombits(v))\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Field3.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Field4.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tm.Field6 = 0\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tm.Field6 |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.Field7 = v\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Field8.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field13 = bool(v != 0)\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field14 = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Field15 == nil {\n\t\t\t\tm.Field15 = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func newstack() *Stack {\n\treturn stackPool.Get().(*Stack)\n}", "is_vulnerable": 0}
{"code": "func TestRouteActiveHandlerDeprecated(t *testing.T) {\n\tconvey.Convey(\"Given a route configuration\", t, func() {\n\t\troute := router.route\n\t\troute.DataCh = make(chan []byte)\n\n\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tDeprecatedOwner:      \"fake\",\n\t\t\t\tDeprecatedRepository: \"fake\",\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "func (mr *MockTokenEndpointHandlerMockRecorder) HandleTokenEndpointRequest(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"HandleTokenEndpointRequest\", reflect.TypeOf((*MockTokenEndpointHandler)(nil).HandleTokenEndpointRequest), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func (a *autoCodePgsql) GetTables(dbName string) (data []response.Table, err error) {\n\tvar entities []response.Table\n\tsql := `select table_name as table_name from information_schema.tables where table_catalog = ? and table_schema = ?`\n\tdb, _err := gorm.Open(postgres.Open(global.GVA_CONFIG.Pgsql.LinkDsn(dbName)), &gorm.Config{Logger: logger.Default.LogMode(logger.Info)})\n\tif _err != nil {\n\t\treturn nil, errors.Wrapf(err, \"[pgsql] \u8fde\u63a5 \u6570\u636e\u5e93(%s)\u7684\u8868\u5931\u8d25!\", dbName)\n\t}\n\terr = db.Raw(sql, dbName, \"public\").Scan(&entities).Error\n\treturn entities, err\n}", "is_vulnerable": 1}
{"code": "func (client TagsClient) listNextResults(lastResults TagsListResult) (result TagsListResult, err error) {\n\treq, err := lastResults.tagsListResultPreparer()\n\tif err != nil {\n\t\treturn result, autorest.NewErrorWithError(err, \"resources.TagsClient\", \"listNextResults\", nil, \"Failure preparing next results request\")\n\t}\n\tif req == nil {\n\t\treturn\n\t}\n\tresp, err := client.ListSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\treturn result, autorest.NewErrorWithError(err, \"resources.TagsClient\", \"listNextResults\", resp, \"Failure sending next results request\")\n\t}\n\tresult, err = client.ListResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.TagsClient\", \"listNextResults\", resp, \"Failure responding to next results request\")\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func (context *DatabaseContext) buildAccessQuery(username string) string {\n\tstatement := replaceSyncTokensQuery(QueryAccess.statement, context.UseXattrs())\n\n\t// SG usernames don't allow back tick, but guard username in select clause for additional safety\n\tusername = strings.Replace(username, \"`\", \"``\", -1)\n\tstatement = strings.Replace(statement, QuerySelectUserName, username, -1)\n\treturn statement\n}", "is_vulnerable": 0}
{"code": "func TestCleanFileName(t *testing.T) {\n\tfor _, x := range [][2]string{\n\t\t{`HELLO`, `hello.json`},\n\t\t{`hello`, `hello.json`},\n\t\t{`cisco-sa-20190513-secureboot.json`, `cisco-sa-20190513-secureboot.json`},\n\t\t{``, `.json`},\n\t\t{`..`, `_.json`},\n\t\t{`../..`, `_.json`},\n\t\t{`abc.html`, `abc_html.json`},\n\t\t{`abc_.htm__l`, `abc_htm_l.json`},\n\t\t{`foo+BAR`, `foo+bar.json`},\n\t} {\n\t\tif got := CleanFileName(x[0]); got != x[1] {\n\t\t\tt.Errorf(\"%q: Expected %q but got %q.\", x[0], x[1], got)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestIngressAnnotationServiceUpstreamEnabled(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(serviceUpstreamAnnotation)] = \"true\"\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\tenabled, ok := val.(bool)\n\tif !ok {\n\t\tt.Errorf(\"expected a bool type\")\n\t}\n\n\tif !enabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockClientMockRecorder) GetResponseTypes() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetResponseTypes\", reflect.TypeOf((*MockClient)(nil).GetResponseTypes))\n}", "is_vulnerable": 0}
{"code": "func NewMetaSyncerWithMetrics(logger log.Logger, metrics *SyncerMetrics, bkt objstore.Bucket, fetcher block.MetadataFetcher, duplicateBlocksFilter block.DeduplicateFilter, ignoreDeletionMarkFilter *block.IgnoreDeletionMarkFilter, blocksMarkedForDeletion, garbageCollectedBlocks prometheus.Counter) (*Syncer, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\treturn &Syncer{\n\t\tlogger:                   logger,\n\t\tbkt:                      bkt,\n\t\tfetcher:                  fetcher,\n\t\tblocks:                   map[ulid.ULID]*metadata.Meta{},\n\t\tmetrics:                  metrics,\n\t\tduplicateBlocksFilter:    duplicateBlocksFilter,\n\t\tignoreDeletionMarkFilter: ignoreDeletionMarkFilter,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (client Client) CreateOrUpdateSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func TestEmptyProtectedField(t *testing.T) {\n\t// MEMO: this was the only test case from the original report\n\t// This passes. It should produce an invalid JWS message, but\n\t// that's not `jws.Parse`'s problem.\n\t_, err := jws.Parse([]byte(`{\"signature\": \"\"}`))\n\trequire.NoError(t, err, `jws.Parse should fail`)\n\n\t// Also test that non-flattened serialization passes.\n\t_, err = jws.Parse([]byte(`{\"signatures\": [{}]}`))\n\trequire.NoError(t, err, `jws.Parse should fail`)\n\n\t// MEMO: rest of the cases are present to be extra pedantic about it\n\n\tprivKey, err := jwxtest.GenerateRsaJwk()\n\trequire.NoError(t, err, `jwxtest.GenerateRsaJwk should succeed`)\n\n\t// This fails. `jws.Parse` works, but the subsequent verification\n\t// workflow fails to verify anything without the presence of a signature or\n\t// a protected header.\n\t_, err = jws.Verify([]byte(`{\"signature\": \"\"}`), jwa.RS256, privKey)\n\trequire.Error(t, err, `jws.Parse should fail`)\n\n\t// Create a valid signatre.\n\tsigned, err := jws.Sign([]byte(\"Lorem Ipsum\"), jwa.RS256, privKey)\n\trequire.NoError(t, err, `jws.Sign should succeed`)\n\n\t_, payload, signature, err := jws.SplitCompact(signed)\n\trequire.NoError(t, err, `jws.SplitCompact should succeed`)\n\n\t// This fails as well. we have a valid signature and a valid\n\t// key to verify it, but no protected headers\n\t_, err = jws.Verify(\n\t\t[]byte(fmt.Sprintf(`{\"signature\": \"%s\"}`, signature)),\n\t\tjwa.RS256, privKey,\n\t)\n\trequire.Error(t, err, `jws.Verify should fail`)\n\n\t// Test for cases when we have an incomplete compact form JWS\n\tvar buf bytes.Buffer\n\tbuf.WriteRune('.')\n\tbuf.Write(payload)\n\tbuf.WriteRune('.')\n\tbuf.Write(signature)\n\tinvalidMessage := buf.Bytes()\n\n\t// This is an error because the format is simply wrong.\n\t// Whereas in the other JSON-based JWS's case the lack of protected field\n\t// is not a SYNTAX error, this one is, and therefore we barf.\n\t_, err = jws.Parse(invalidMessage)\n\trequire.Error(t, err, `jws.Parse should fail`)\n}", "is_vulnerable": 0}
{"code": "func (b *SystemBackend) raftStoragePaths() []*framework.Path {\n\treturn []*framework.Path{\n\t\t{\n\t\t\tPattern: \"storage/raft/bootstrap/answer\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"answer\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"cluster_addr\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"non_voter\": {\n\t\t\t\t\tType: framework.TypeBool,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftBootstrapAnswerWrite(),\n\t\t\t\t\tSummary:  \"Accepts an answer from the peer to be joined to the fact cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-answer\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-answer\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/bootstrap/challenge\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftBootstrapChallengeWrite(),\n\t\t\t\t\tSummary:  \"Creates a challenge for the new peer to be joined to the raft cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-challenge\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-challenge\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/remove-peer\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"dr_operation_token\": {\n\t\t\t\t\tType:        framework.TypeString,\n\t\t\t\t\tDescription: \"DR operation token used to authorize this request (if a DR secondary node).\",\n\t\t\t\t},\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: wrapHandleRaftRemovePeer(b),\n\t\t\t\t\tSummary:  \"Remove a peer from the raft cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-remove-peer\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-remove-peer\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/configuration\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"dr_operation_token\": {\n\t\t\t\t\tType:        framework.TypeString,\n\t\t\t\t\tDescription: \"DR operation token used to authorize this request (if a DR secondary node).\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.ReadOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftConfigurationGet(),\n\t\t\t\t\tSummary:  \"Returns the configuration of the raft cluster.\",\n\t\t\t\t},\n\t\t\t\t// Reading configuration on a DR secondary cluster is an update\n\t\t\t\t// operation to allow consuming the DR operation token for\n\t\t\t\t// authenticating the request.\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.verifyDROperationToken(b.handleRaftConfigurationGet(), false),\n\t\t\t\t\tSummary:  \"Returns the configuration of the raft cluster in a DR secondary cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-configuration\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-configuration\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/snapshot\",\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.ReadOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotRead(),\n\t\t\t\t\tSummary:  \"Returns a snapshot of the current state of vault.\",\n\t\t\t\t},\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotWrite(false),\n\t\t\t\t\tSummary:  \"Installs the provided snapshot, returning the cluster to the state defined in it.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-snapshot\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-snapshot\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/snapshot-force\",\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotWrite(true),\n\t\t\t\t\tSummary:  \"Installs the provided snapshot, returning the cluster to the state defined in it. This bypasses checks ensuring the current Autounseal or Shamir keys are consistent with the snapshot data.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-snapshot-force\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-snapshot-force\"][1]),\n\t\t},\n\t}\n}", "is_vulnerable": 1}
{"code": "func (proj AppProject) IsResourcePermitted(groupKind schema.GroupKind, namespace string, dest ApplicationDestination) bool {\n\tif !proj.IsGroupKindPermitted(groupKind, namespace != \"\") {\n\t\treturn false\n\t}\n\tif namespace != \"\" {\n\t\treturn proj.IsDestinationPermitted(ApplicationDestination{Server: dest.Server, Name: dest.Name, Namespace: namespace})\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func evalWorkloadWithContext(pCtx process.Context, wl *Workload, ns, appName, compName string) (*types.ComponentManifest, error) {\n\tcompManifest := &types.ComponentManifest{}\n\tworkload, err := makeWorkloadWithContext(pCtx, wl, ns, appName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcompManifest.StandardWorkload = workload\n\n\t_, assists := pCtx.Output()\n\tcompManifest.Traits = make([]*unstructured.Unstructured, len(assists))\n\tcommonLabels := definition.GetCommonLabels(pCtx.BaseContextLabels())\n\tfor i, assist := range assists {\n\t\ttr, err := assist.Ins.Unstructured()\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"evaluate trait=%s template for component=%s app=%s\", assist.Name, compName, appName)\n\t\t}\n\t\tlabels := util.MergeMapOverrideWithDst(commonLabels, map[string]string{oam.TraitTypeLabel: assist.Type})\n\t\tif assist.Name != \"\" {\n\t\t\tlabels[oam.TraitResource] = assist.Name\n\t\t}\n\t\tutil.AddLabels(tr, labels)\n\t\tcompManifest.Traits[i] = tr\n\t}\n\treturn compManifest, nil\n}", "is_vulnerable": 1}
{"code": "func (m *Foo5) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Foo5: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Foo5: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Bar1.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Bar2 == nil {\n\t\t\t\tm.Bar2 = &Bar1{}\n\t\t\t}\n\t\t\tif err := m.Bar2.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif err := m.Bar3.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Bar4 == nil {\n\t\t\t\tm.Bar4 = &Bar2{}\n\t\t\t}\n\t\t\tif err := m.Bar4.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars1 = append(m.Bars1, Bar1{})\n\t\t\tif err := m.Bars1[len(m.Bars1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars2 = append(m.Bars2, &Bar1{})\n\t\t\tif err := m.Bars2[len(m.Bars2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 7:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars3 = append(m.Bars3, Bar2{})\n\t\t\tif err := m.Bars3[len(m.Bars3)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars4 = append(m.Bars4, &Bar2{})\n\t\t\tif err := m.Bars4[len(m.Bars4)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 9:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Barrs1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Barrs1 = append(m.Barrs1, Bar3{})\n\t\t\tif err := m.Barrs1[len(m.Barrs1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Barrs2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Barrs2 = append(m.Barrs2, Bar5{})\n\t\t\tif err := m.Barrs2[len(m.Barrs2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 11:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Barmap1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Barmap1 == nil {\n\t\t\t\tm.Barmap1 = make(map[string]*Bar3)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue *Bar3\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Bar3{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Barmap1[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tcase 12:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Barmap2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Barmap2 == nil {\n\t\t\t\tm.Barmap2 = make(map[string]*Bar5)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue *Bar5\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapmsglen int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tmapmsglen |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif mapmsglen < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tpostmsgIndex := iNdEx + mapmsglen\n\t\t\t\t\tif postmsgIndex < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif postmsgIndex > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvalue = &Bar5{}\n\t\t\t\t\tif err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx = postmsgIndex\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Barmap2[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (ins *tenantInstrumentationMiddleware) NewHandler(handlerName string, next http.Handler) http.HandlerFunc {\n\ttenantWrapper := func(w http.ResponseWriter, r *http.Request) {\n\t\ttenant := r.Header.Get(ins.tenantHeaderName)\n\t\tif tenant == \"\" {\n\t\t\ttenant = ins.defaultTenant\n\t\t}\n\t\tbaseLabels := prometheus.Labels{\"handler\": handlerName, \"tenant\": tenant}\n\t\thandlerStack := httpInstrumentationHandler(baseLabels, ins.metrics, next)\n\t\thandlerStack.ServeHTTP(w, r)\n\t}\n\treturn tenantWrapper\n}", "is_vulnerable": 0}
{"code": "func TestSaveAndGetFullStateFromK8s_ClusterWithoutSecretOrCM(t *testing.T) {\n\t// Set up a fake cluster without a secret or configmap.\n\tctx, fullState, client := setup(t, false)\n\n\t// We should not be able to fetch and load the state from the secret or configmap.\n\tctx, cancel := context.WithTimeout(ctx, time.Millisecond*500)\n\tdefer cancel()\n\tfetchedFullState, err := GetFullStateFromK8s(ctx, client)\n\tassert.True(t, apierrors.IsNotFound(err))\n\n\t// Create the secret and delete the configmap.\n\terr = SaveFullStateToK8s(ctx, client, &fullState)\n\tassert.NoError(t, err)\n\n\t// There should be a secret containing the full state.\n\tcheckSecretMatches(t, ctx, client, fullState)\n\n\t// There should be no configmap.\n\tcheckConfigMapDeleted(t, ctx, client)\n\n\t// We should be able to fetch and load the state from the secret.\n\tfetchedFullState, err = GetFullStateFromK8s(ctx, client)\n\tassert.NoError(t, err)\n\tassert.True(t, reflect.DeepEqual(*fetchedFullState, fullState))\n}", "is_vulnerable": 0}
{"code": "func TestNullBytes(t *testing.T) {\n\tt.Run(\"element keys\", func(t *testing.T) {\n\t\tdoc := D{{\"a\\x00\", \"foobar\"}}\n\t\tres, err := Marshal(doc)\n\t\twant := errors.New(\"BSON element key cannot contain null bytes\")\n\t\tassert.Equal(t, want, err, \"expected Marshal error %v, got error %v with result %q\", want, err, Raw(res))\n\t})\n\n\tt.Run(\"regex values\", func(t *testing.T) {\n\t\twantErr := errors.New(\"BSON regex values cannot contain null bytes\")\n\n\t\ttestCases := []struct {\n\t\t\tname    string\n\t\t\tpattern string\n\t\t\toptions string\n\t\t}{\n\t\t\t{\"null bytes in pattern\", \"a\\x00\", \"i\"},\n\t\t\t{\"null bytes in options\", \"pattern\", \"i\\x00\"},\n\t\t}\n\t\tfor _, tc := range testCases {\n\t\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\t\tregex := primitive.Regex{\n\t\t\t\t\tPattern: tc.pattern,\n\t\t\t\t\tOptions: tc.options,\n\t\t\t\t}\n\t\t\t\tres, err := Marshal(D{{\"foo\", regex}})\n\t\t\t\tassert.Equal(t, wantErr, err, \"expected Marshal error %v, got error %v with result %q\", wantErr, err, Raw(res))\n\t\t\t})\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func render1(w writer, n *Node) error {\n\t// Render non-element nodes; these are the easy cases.\n\tswitch n.Type {\n\tcase ErrorNode:\n\t\treturn errors.New(\"html: cannot render an ErrorNode node\")\n\tcase TextNode:\n\t\treturn escape(w, n.Data)\n\tcase DocumentNode:\n\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n\t\t\tif err := render1(w, c); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\tcase ElementNode:\n\t\t// No-op.\n\tcase CommentNode:\n\t\tif _, err := w.WriteString(\"<!--\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := escapeComment(w, n.Data); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := w.WriteString(\"-->\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\tcase DoctypeNode:\n\t\tif _, err := w.WriteString(\"<!DOCTYPE \"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := escape(w, n.Data); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif n.Attr != nil {\n\t\t\tvar p, s string\n\t\t\tfor _, a := range n.Attr {\n\t\t\t\tswitch a.Key {\n\t\t\t\tcase \"public\":\n\t\t\t\t\tp = a.Val\n\t\t\t\tcase \"system\":\n\t\t\t\t\ts = a.Val\n\t\t\t\t}\n\t\t\t}\n\t\t\tif p != \"\" {\n\t\t\t\tif _, err := w.WriteString(\" PUBLIC \"); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := writeQuoted(w, p); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif s != \"\" {\n\t\t\t\t\tif err := w.WriteByte(' '); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif err := writeQuoted(w, s); err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if s != \"\" {\n\t\t\t\tif _, err := w.WriteString(\" SYSTEM \"); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif err := writeQuoted(w, s); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn w.WriteByte('>')\n\tcase RawNode:\n\t\t_, err := w.WriteString(n.Data)\n\t\treturn err\n\tdefault:\n\t\treturn errors.New(\"html: unknown node type\")\n\t}\n\n\t// Render the <xxx> opening tag.\n\tif err := w.WriteByte('<'); err != nil {\n\t\treturn err\n\t}\n\tif _, err := w.WriteString(n.Data); err != nil {\n\t\treturn err\n\t}\n\tfor _, a := range n.Attr {\n\t\tif err := w.WriteByte(' '); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif a.Namespace != \"\" {\n\t\t\tif _, err := w.WriteString(a.Namespace); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := w.WriteByte(':'); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif _, err := w.WriteString(a.Key); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif _, err := w.WriteString(`=\"`); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := escape(w, a.Val); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := w.WriteByte('\"'); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif voidElements[n.Data] {\n\t\tif n.FirstChild != nil {\n\t\t\treturn fmt.Errorf(\"html: void element <%s> has child nodes\", n.Data)\n\t\t}\n\t\t_, err := w.WriteString(\"/>\")\n\t\treturn err\n\t}\n\tif err := w.WriteByte('>'); err != nil {\n\t\treturn err\n\t}\n\n\t// Add initial newline where there is danger of a newline beging ignored.\n\tif c := n.FirstChild; c != nil && c.Type == TextNode && strings.HasPrefix(c.Data, \"\\n\") {\n\t\tswitch n.Data {\n\t\tcase \"pre\", \"listing\", \"textarea\":\n\t\t\tif err := w.WriteByte('\\n'); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// Render any child nodes\n\tif childTextNodesAreLiteral(n) {\n\t\tfor c := n.FirstChild; c != nil; c = c.NextSibling {\n\t\t\tif c.Type == TextNode {\n\t\t\t\tif _, err := w.WriteString(c.Data); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif err := render1(w, c); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif n.Data == \"plaintext\" {\n\t\t\t// Don't render anything else. <plaintext> must be the\n\t\t\t// last element in the file, with no closing tag.\n\t\t\treturn plaintextAbort\n\t\t}\n\t} else {", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) Symlink(oldpath, newpath string) error {\n\treturn fs.unixFS.Symlink(oldpath, newpath)\n}", "is_vulnerable": 0}
{"code": "func toolUploadHandler(\n\tconfig_obj *config_proto.Config) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Check for acls\n\t\tuserinfo := GetUserInfo(r.Context(), config_obj)\n\t\tpermissions := acls.ARTIFACT_WRITER\n\t\tperm, err := acls.CheckAccess(config_obj, userinfo.Name, permissions)\n\t\tif !perm || err != nil {\n\t\t\treturnError(w, http.StatusUnauthorized,\n\t\t\t\t\"User is not allowed to upload tools.\")\n\t\t\treturn\n\t\t}\n\n\t\t// Parse our multipart form, 10 << 20 specifies a maximum\n\t\t// upload of 10 MB files.\n\t\terr = r.ParseMultipartForm(10 << 20)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\t\tdefer r.MultipartForm.RemoveAll()\n\n\t\ttool := &artifacts_proto.Tool{}\n\t\tparams, pres := r.Form[\"_params_\"]\n\t\tif !pres || len(params) != 1 {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\n\t\terr = json.Unmarshal([]byte(params[0]), tool)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusBadRequest, \"Unsupported params\")\n\t\t\treturn\n\t\t}\n\n\t\t// FormFile returns the first file for the given key `myFile`\n\t\t// it also returns the FileHeader so we can get the Filename,\n\t\t// the Header and the size of the file\n\t\tfile, handler, err := r.FormFile(\"file\")\n\t\tif err != nil {\n\t\t\treturnError(w, 403, fmt.Sprintf(\"Unsupported params: %v\", err))\n\t\t\treturn\n\t\t}\n\t\tdefer file.Close()\n\n\t\ttool.Filename = path.Base(handler.Filename)\n\t\ttool.ServeLocally = true\n\n\t\tfile_store_factory := file_store.GetFileStore(config_obj)\n\t\tpath_manager := paths.NewInventoryPathManager(config_obj, tool)\n\t\twriter, err := file_store_factory.WriteFile(path_manager.Path())\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\t\tdefer writer.Close()\n\n\t\terr = writer.Truncate()\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\tsha_sum := sha256.New()\n\n\t\t_, err = io.Copy(writer, io.TeeReader(file, sha_sum))\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\ttool.Hash = hex.EncodeToString(sha_sum.Sum(nil))\n\n\t\terr = services.GetInventory().AddTool(config_obj, tool,\n\t\t\tservices.ToolOptions{\n\t\t\t\tAdminOverride: true,\n\t\t\t})\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\t// Now materialize the tool\n\t\ttool, err = services.GetInventory().GetToolInfo(\n\t\t\tr.Context(), config_obj, tool.Name)\n\t\tif err != nil {\n\t\t\treturnError(w, http.StatusInternalServerError,\n\t\t\t\tfmt.Sprintf(\"Error: %v\", err))\n\t\t\treturn\n\t\t}\n\n\t\tserialized, _ := json.Marshal(tool)\n\t\t_, err = w.Write(serialized)\n\t\tif err != nil {\n\t\t\tlogger := logging.GetLogger(config_obj, &logging.GUIComponent)\n\t\t\tlogger.Error(\"toolUploadHandler: %v\", err)\n\t\t}\n\t})\n}", "is_vulnerable": 0}
{"code": "func (m *Manager) buildEntryPointHandler(ctx context.Context, configs map[string]*runtime.TCPRouterInfo, configsHTTP map[string]*runtime.RouterInfo, handlerHTTP, handlerHTTPS http.Handler) (*Router, error) {\n\t// Build a new Router.\n\trouter, err := NewRouter()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trouter.SetHTTPHandler(handlerHTTP)\n\n\tdefaultTLSConf, err := m.tlsManager.Get(traefiktls.DefaultTLSStoreName, traefiktls.DefaultTLSConfigName)\n\tif err != nil {\n\t\tlog.FromContext(ctx).Errorf(\"Error during the build of the default TLS configuration: %v\", err)\n\t}\n\n\t// Keyed by domain. The source of truth for doing SNI checking, and for what TLS\n\t// options will actually be used for the connection.\n\t// As soon as there's (at least) two different tlsOptions found for the same domain,\n\t// we set the value to the default TLS conf.\n\ttlsOptionsForHost := map[string]string{}\n\n\t// Keyed by domain, then by options reference.\n\t// As opposed to tlsOptionsForHost, it keeps track of all the (different) TLS\n\t// options that occur for a given host name, so that later on we can set relevant\n\t// errors and logging for all the routers concerned (i.e. wrongly configured).\n\ttlsOptionsForHostSNI := map[string]map[string]nameAndConfig{}\n\n\tfor routerHTTPName, routerHTTPConfig := range configsHTTP {\n\t\tif routerHTTPConfig.TLS == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tctxRouter := log.With(provider.AddInContext(ctx, routerHTTPName), log.Str(log.RouterName, routerHTTPName))\n\t\tlogger := log.FromContext(ctxRouter)\n\n\t\ttlsOptionsName := traefiktls.DefaultTLSConfigName\n\t\tif len(routerHTTPConfig.TLS.Options) > 0 && routerHTTPConfig.TLS.Options != traefiktls.DefaultTLSConfigName {\n\t\t\ttlsOptionsName = provider.GetQualifiedName(ctxRouter, routerHTTPConfig.TLS.Options)\n\t\t}\n\n\t\tdomains, err := httpmuxer.ParseDomains(routerHTTPConfig.Rule)\n\t\tif err != nil {\n\t\t\trouterErr := fmt.Errorf(\"invalid rule %s, error: %w\", routerHTTPConfig.Rule, err)\n\t\t\trouterHTTPConfig.AddError(routerErr, true)\n\t\t\tlogger.Error(routerErr)\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(domains) == 0 {\n\t\t\t// Extra Host(*) rule, for HTTPS routers with no Host rule, and for requests for\n\t\t\t// which the SNI does not match _any_ of the other existing routers Host. This is\n\t\t\t// only about choosing the TLS configuration. The actual routing will be done\n\t\t\t// further on by the HTTPS handler. See examples below.\n\t\t\trouter.AddHTTPTLSConfig(\"*\", defaultTLSConf)\n\n\t\t\t// The server name (from a Host(SNI) rule) is the only parameter (available in\n\t\t\t// HTTP routing rules) on which we can map a TLS config, because it is the only one\n\t\t\t// accessible before decryption (we obtain it during the ClientHello). Therefore,\n\t\t\t// when a router has no Host rule, it does not make any sense to specify some TLS\n\t\t\t// options. Consequently, when it comes to deciding what TLS config will be used,\n\t\t\t// for a request that will match an HTTPS router with no Host rule, the result will\n\t\t\t// depend on the _others_ existing routers (their Host rule, to be precise), and\n\t\t\t// the TLS options associated with them, even though they don't match the incoming\n\t\t\t// request. Consider the following examples:\n\n\t\t\t//\t# conf1\n\t\t\t//\thttpRouter1:\n\t\t\t//\t\trule: PathPrefix(\"/foo\")\n\t\t\t//\t# Wherever the request comes from, the TLS config used will be the default one, because of the Host(*) fallback.\n\n\t\t\t//\t# conf2\n\t\t\t//\thttpRouter1:\n\t\t\t//\t\trule: PathPrefix(\"/foo\")\n\t\t\t//\n\t\t\t//\thttpRouter2:\n\t\t\t//\t\trule: Host(\"foo.com\") && PathPrefix(\"/bar\")\n\t\t\t//\t\ttlsoptions: myTLSOptions\n\t\t\t//\t# When a request for \"/foo\" comes, even though it won't be routed by\n\t\t\t//\thttpRouter2, if its SNI is set to foo.com, myTLSOptions will be used for the TLS\n\t\t\t//\tconnection. Otherwise, it will fallback to the default TLS config.\n\t\t\tlogger.Warnf(\"No domain found in rule %v, the TLS options applied for this router will depend on the SNI of each request\", routerHTTPConfig.Rule)\n\t\t}\n\n\t\ttlsConf, err := m.tlsManager.Get(traefiktls.DefaultTLSStoreName, tlsOptionsName)\n\t\tif err != nil {\n\t\t\trouterHTTPConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, domain := range domains {\n\t\t\t// domain is already in lower case thanks to the domain parsing\n\t\t\tif tlsOptionsForHostSNI[domain] == nil {\n\t\t\t\ttlsOptionsForHostSNI[domain] = make(map[string]nameAndConfig)\n\t\t\t}\n\t\t\ttlsOptionsForHostSNI[domain][tlsOptionsName] = nameAndConfig{\n\t\t\t\trouterName: routerHTTPName,\n\t\t\t\tTLSConfig:  tlsConf,\n\t\t\t}\n\n\t\t\tif name, ok := tlsOptionsForHost[domain]; ok && name != tlsOptionsName {\n\t\t\t\t// Different tlsOptions on the same domain, so fallback to default\n\t\t\t\ttlsOptionsForHost[domain] = traefiktls.DefaultTLSConfigName\n\t\t\t} else {\n\t\t\t\ttlsOptionsForHost[domain] = tlsOptionsName\n\t\t\t}\n\t\t}\n\t}\n\n\tsniCheck := snicheck.New(tlsOptionsForHost, handlerHTTPS)\n\n\trouter.SetHTTPSHandler(sniCheck, defaultTLSConf)\n\n\tlogger := log.FromContext(ctx)\n\tfor hostSNI, tlsConfigs := range tlsOptionsForHostSNI {\n\t\tif len(tlsConfigs) == 1 {\n\t\t\tvar optionsName string\n\t\t\tvar config *tls.Config\n\t\t\tfor k, v := range tlsConfigs {\n\t\t\t\toptionsName = k\n\t\t\t\tconfig = v.TLSConfig\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tlogger.Debugf(\"Adding route for %s with TLS options %s\", hostSNI, optionsName)\n\n\t\t\trouter.AddHTTPTLSConfig(hostSNI, config)\n\t\t} else {\n\t\t\trouters := make([]string, 0, len(tlsConfigs))\n\t\t\tfor _, v := range tlsConfigs {\n\t\t\t\tconfigsHTTP[v.routerName].AddError(fmt.Errorf(\"found different TLS options for routers on the same host %v, so using the default TLS options instead\", hostSNI), false)\n\t\t\t\trouters = append(routers, v.routerName)\n\t\t\t}\n\n\t\t\tlogger.Warnf(\"Found different TLS options for routers on the same host %v, so using the default TLS options instead for these routers: %#v\", hostSNI, routers)\n\n\t\t\trouter.AddHTTPTLSConfig(hostSNI, defaultTLSConf)\n\t\t}\n\t}\n\n\tfor routerName, routerConfig := range configs {\n\t\tctxRouter := log.With(provider.AddInContext(ctx, routerName), log.Str(log.RouterName, routerName))\n\t\tlogger := log.FromContext(ctxRouter)\n\n\t\tif routerConfig.Service == \"\" {\n\t\t\terr := errors.New(\"the service is missing on the router\")\n\t\t\trouterConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t\tcontinue\n\t\t}\n\n\t\tif routerConfig.Rule == \"\" {\n\t\t\terr := errors.New(\"router has no rule\")\n\t\t\trouterConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t\tcontinue\n\t\t}\n\n\t\thandler, err := m.buildTCPHandler(ctxRouter, routerConfig)\n\t\tif err != nil {\n\t\t\trouterConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t\tcontinue\n\t\t}\n\n\t\tdomains, err := tcpmuxer.ParseHostSNI(routerConfig.Rule)\n\t\tif err != nil {\n\t\t\trouterErr := fmt.Errorf(\"invalid rule: %q , %w\", routerConfig.Rule, err)\n\t\t\trouterConfig.AddError(routerErr, true)\n\t\t\tlogger.Error(routerErr)\n\t\t\tcontinue\n\t\t}\n\n\t\t// HostSNI Rule, but TLS not set on the router, which is an error.\n\t\t// However, we allow the HostSNI(*) exception.\n\t\tif len(domains) > 0 && routerConfig.TLS == nil && domains[0] != \"*\" {\n\t\t\trouterErr := fmt.Errorf(\"invalid rule: %q , has HostSNI matcher, but no TLS on router\", routerConfig.Rule)\n\t\t\trouterConfig.AddError(routerErr, true)\n\t\t\tlogger.Error(routerErr)\n\t\t}\n\n\t\tif routerConfig.TLS == nil {\n\t\t\tlogger.Debugf(\"Adding route for %q\", routerConfig.Rule)\n\t\t\tif err := router.AddRoute(routerConfig.Rule, routerConfig.Priority, handler); err != nil {\n\t\t\t\trouterConfig.AddError(err, true)\n\t\t\t\tlogger.Error(err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif routerConfig.TLS.Passthrough {\n\t\t\tlogger.Debugf(\"Adding Passthrough route for %q\", routerConfig.Rule)\n\t\t\tif err := router.AddRouteTLS(routerConfig.Rule, routerConfig.Priority, handler, nil); err != nil {\n\t\t\t\trouterConfig.AddError(err, true)\n\t\t\t\tlogger.Error(err)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, domain := range domains {\n\t\t\tif httpmuxer.IsASCII(domain) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tasciiError := fmt.Errorf(\"invalid domain name value %q, non-ASCII characters are not allowed\", domain)\n\t\t\trouterConfig.AddError(asciiError, true)\n\t\t\tlogger.Error(asciiError)\n\t\t}\n\n\t\ttlsOptionsName := routerConfig.TLS.Options\n\n\t\tif len(tlsOptionsName) == 0 {\n\t\t\ttlsOptionsName = traefiktls.DefaultTLSConfigName\n\t\t}\n\n\t\tif tlsOptionsName != traefiktls.DefaultTLSConfigName {\n\t\t\ttlsOptionsName = provider.GetQualifiedName(ctxRouter, tlsOptionsName)\n\t\t}\n\n\t\ttlsConf, err := m.tlsManager.Get(traefiktls.DefaultTLSStoreName, tlsOptionsName)\n\t\tif err != nil {\n\t\t\trouterConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Now that the Rule is not just about the Host, we could theoretically have a config like:\n\t\t//\trouter1:\n\t\t//\t\trule: HostSNI(foo.com) && ClientIP(IP1)\n\t\t//\t\ttlsOption: tlsOne\n\t\t//\trouter2:\n\t\t//\t\trule: HostSNI(foo.com) && ClientIP(IP2)\n\t\t//\t\ttlsOption: tlsTwo\n\t\t// i.e. same HostSNI but different tlsOptions\n\t\t// This is only applicable if the muxer can decide about the routing _before_\n\t\t// telling the client about the tlsConf (i.e. before the TLS HandShake). This seems\n\t\t// to be the case so far with the existing matchers (HostSNI, and ClientIP), so\n\t\t// it's all good. Otherwise, we would have to do as for HTTPS, i.e. disallow\n\t\t// different TLS configs for the same HostSNIs.\n\n\t\tlogger.Debugf(\"Adding TLS route for %q\", routerConfig.Rule)\n\t\tif err := router.AddRouteTLS(routerConfig.Rule, routerConfig.Priority, handler, tlsConf); err != nil {\n\t\t\trouterConfig.AddError(err, true)\n\t\t\tlogger.Error(err)\n\t\t}\n\t}\n\n\treturn router, nil\n}", "is_vulnerable": 1}
{"code": "func TestAnnotations(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"default-backend\")] = \"demo-service\"\n\ting.SetAnnotations(data)\n\n\tfakeService := &mockService{}\n\ti, err := NewParser(fakeService).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error %v\", err)\n\t}\n\n\tsvc, ok := i.(*api.Service)\n\tif !ok {\n\t\tt.Errorf(\"expected *api.Service but got %v\", svc)\n\t}\n\tif svc.Name != \"demo-service\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"demo-service\", svc.Name)\n\t}\n}", "is_vulnerable": 1}
{"code": "func MainnetConfig() Config {\n\tvar postPowDifficulty activation.PowDifficulty\n\tdifficulty := []byte(\"000dfb23b0979b4b000000000000000000000000000000000000000000000000\")\n\tif err := postPowDifficulty.UnmarshalText(difficulty); err != nil {\n\t\tpanic(err)\n\t}\n\tp2pconfig := p2p.DefaultConfig()\n\n\tp2pconfig.Bootnodes = []string{\n\t\t\"/dns4/mainnet-bootnode-0.spacemesh.network/tcp/5000/p2p/12D3KooWPStnitMbLyWAGr32gHmPr538mT658Thp6zTUujZt3LRf\",\n\t\t\"/dns4/mainnet-bootnode-2.spacemesh.network/tcp/5000/p2p/12D3KooWAsMgXLpyGdsRNjHBF3FaXwnXhyMEqWQYBXUpvCHNzFNK\",\n\t\t\"/dns4/mainnet-bootnode-4.spacemesh.network/tcp/5000/p2p/12D3KooWRcTWDHzptnhJn5h6CtwnokzzMaDLcXv6oM9CxQEXd5FL\",\n\t\t\"/dns4/mainnet-bootnode-6.spacemesh.network/tcp/5000/p2p/12D3KooWRS47KAs3ZLkBtE2AqjJCwxRYqZKmyLkvombJJdrca8Hz\",\n\t\t\"/dns4/mainnet-bootnode-8.spacemesh.network/tcp/5000/p2p/12D3KooWFYv99aGbtXnZQy6UZxyf72NpkWJp3K4HS8Py35WhKtzE\",\n\t\t\"/dns4/mainnet-bootnode-10.spacemesh.network/tcp/5000/p2p/12D3KooWHK5m83sNj2eNMJMGAngcS9gBja27ho83t79Q2CD4iRjQ\",\n\t\t\"/dns4/mainnet-bootnode-12.spacemesh.network/tcp/5000/p2p/12D3KooWG4gk8GtMsAjYxHtbNC7oEoBTMRLbLDpKgSQMQkYBFRsw\",\n\t\t\"/dns4/mainnet-bootnode-14.spacemesh.network/tcp/5000/p2p/12D3KooWRkZMjGNrQfRyeKQC9U58cUwAfyQMtjNsupixkBFag8AY\",\n\t\t\"/dns4/mainnet-bootnode-16.spacemesh.network/tcp/5000/p2p/12D3KooWDAFRuFrMNgVQMDy8cgD71GLtPyYyfQzFxMZr2yUBgjHK\",\n\t\t\"/dns4/mainnet-bootnode-18.spacemesh.network/tcp/5000/p2p/12D3KooWMJmdfwxDctuGGoTYJD8Wj9jubQBbPfrgrzzXaQ1RTKE6\",\n\t}\n\n\tsmeshing := DefaultSmeshingConfig()\n\tsmeshing.ProvingOpts.Nonces = 288\n\tsmeshing.ProvingOpts.Threads = uint(runtime.NumCPU() * 3 / 4)\n\tif smeshing.ProvingOpts.Threads < 1 {\n\t\tsmeshing.ProvingOpts.Threads = 1\n\t}\n\tlogging := DefaultLoggingConfig()\n\tlogging.TrtlLoggerLevel = zapcore.WarnLevel.String()\n\tlogging.AtxHandlerLevel = zapcore.WarnLevel.String()\n\tlogging.ProposalListenerLevel = zapcore.WarnLevel.String()\n\thare3conf := hare3.DefaultConfig()\n\thare3conf.Committee = 400\n\thare3conf.Enable = true\n\thare3conf.EnableLayer = 35117\n\treturn Config{\n\t\tBaseConfig: BaseConfig{\n\t\t\tDataDirParent:         defaultDataDir,\n\t\t\tFileLock:              filepath.Join(os.TempDir(), \"spacemesh.lock\"),\n\t\t\tMetricsPort:           1010,\n\t\t\tDatabaseConnections:   16,\n\t\t\tDatabasePruneInterval: 30 * time.Minute,\n\t\t\tDatabaseVacuumState:   15,\n\t\t\tPruneActivesetsFrom:   12,    // starting from epoch 13 activesets below 12 will be pruned\n\t\t\tScanMalfeasantATXs:    false, // opt-in\n\t\t\tNetworkHRP:            \"sm\",\n\n\t\t\tLayerDuration:  5 * time.Minute,\n\t\t\tLayerAvgSize:   50,\n\t\t\tLayersPerEpoch: 4032,\n\n\t\t\tTxsPerProposal: 700,       // https://github.com/spacemeshos/go-spacemesh/issues/4559\n\t\t\tBlockGasLimit:  100107000, // 3000 of spends\n\n\t\t\tOptFilterThreshold: 90,\n\n\t\t\tTickSize: 9331200,\n\t\t\tPoetServers: []types.PoetServer{\n\t\t\t\t{\n\t\t\t\t\tAddress: \"https://mainnet-poet-0.spacemesh.network\",\n\t\t\t\t\tPubkey:  types.MustBase64FromString(\"cFnqCS5oER7GOX576oPtahlxB/1y95aDibdK7RHQFVg=\"),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAddress: \"https://mainnet-poet-1.spacemesh.network\",\n\t\t\t\t\tPubkey:  types.MustBase64FromString(\"Qh1efxY4YhoYBEXKPTiHJ/a7n1GsllRSyweQKO3j7m0=\"),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAddress: \"https://poet-110.spacemesh.network\",\n\t\t\t\t\tPubkey:  types.MustBase64FromString(\"8Qqgid+37eyY7ik+EA47Nd5TrQjXolbv2Mdgir243No=\"),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAddress: \"https://poet-111.spacemesh.network\",\n\t\t\t\t\tPubkey:  types.MustBase64FromString(\"caIV0Ym59L3RqbVAL6UrCPwr+z+lwe2TBj57QWnAgtM=\"),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tAddress: \"https://poet-112.spacemesh.network\",\n\t\t\t\t\tPubkey:  types.MustBase64FromString(\"5p/mPvmqhwdvf8U0GVrNq/9IN/HmZj5hCkFLAN04g1E=\"),\n\t\t\t\t},\n\t\t\t},\n\t\t\tRegossipAtxInterval: 2 * time.Hour,\n\t\t\tATXGradeDelay:       30 * time.Minute,\n\t\t\tPostValidDelay:      time.Duration(math.MaxInt64),\n\t\t},\n\t\tGenesis: GenesisConfig{\n\t\t\tGenesisTime: \"2023-07-14T08:00:00Z\",\n\t\t\tExtraData:   \"00000000000000000001a6bc150307b5c1998045752b3c87eccf3c013036f3cc\",\n\t\t\tAccounts:    MainnetAccounts(),\n\t\t},\n\t\tTortoise: tortoise.Config{\n\t\t\tHdist:                    10,\n\t\t\tZdist:                    2,\n\t\t\tWindowSize:               4032,\n\t\t\tMaxExceptions:            1000,\n\t\t\tBadBeaconVoteDelayLayers: 4032,\n\t\t\tMinimalActiveSetWeight: []types.EpochMinimalActiveWeight{\n\t\t\t\t{Weight: 1_000_000},\n\t\t\t},\n\t\t\tHistoricalWindowSize: []tortoise.WindowSizeInterval{\n\t\t\t\t{End: 30_000, Window: 10_000},\n\t\t\t},\n\t\t},\n\t\tHARE3: hare3conf,\n\t\tHareEligibility: eligibility.Config{\n\t\t\tConfidenceParam: 200,\n\t\t},\n\t\tCertificate: blocks.CertConfig{\n\t\t\t// NOTE(dshulyak) this is intentional. we increased committee size with hare3 upgrade\n\t\t\t// but certifier continues to use 200 committee size.\n\t\t\t// this will be upgraded in future with scheduled upgrade.\n\t\t\tCommitteeSize: 200,\n\t\t},\n\t\tBeacon: beacon.Config{\n\t\t\tKappa:                    40,\n\t\t\tQ:                        *big.NewRat(1, 3),\n\t\t\tTheta:                    *big.NewRat(1, 4),\n\t\t\tGracePeriodDuration:      10 * time.Minute,\n\t\t\tProposalDuration:         4 * time.Minute,\n\t\t\tFirstVotingRoundDuration: 30 * time.Minute,\n\t\t\tRoundsNumber:             0,\n\t\t\tVotingRoundDuration:      4 * time.Minute,\n\t\t\tWeakCoinRoundDuration:    4 * time.Minute,\n\t\t\tVotesLimit:               100,\n\t\t\tBeaconSyncWeightUnits:    800,\n\t\t},\n\t\tPOET: activation.PoetConfig{\n\t\t\tPhaseShift:        240 * time.Hour,\n\t\t\tCycleGap:          12 * time.Hour,\n\t\t\tGracePeriod:       1 * time.Hour,\n\t\t\tRequestTimeout:    1100 * time.Second, // RequestRetryDelay * 2 * MaxRequestRetries*(MaxRequestRetries+1)/2\n\t\t\tRequestRetryDelay: 10 * time.Second,\n\t\t\tMaxRequestRetries: 10,\n\t\t},\n\t\tPOST: activation.PostConfig{\n\t\t\tMinNumUnits:   4,\n\t\t\tMaxNumUnits:   math.MaxUint32,\n\t\t\tLabelsPerUnit: 4294967296,\n\t\t\tK1:            26,\n\t\t\tK2:            37,\n\t\t\tK3:            1,\n\t\t\tPowDifficulty: postPowDifficulty,\n\t\t},\n\t\tBootstrap: bootstrap.Config{\n\t\t\tURL:      \"https://bootstrap.spacemesh.network/mainnet\",\n\t\t\tVersion:  \"https://spacemesh.io/bootstrap.schema.json.1.0\",\n\t\t\tDataDir:  os.TempDir(),\n\t\t\tInterval: 30 * time.Second,\n\t\t},\n\t\tP2P:         p2pconfig,\n\t\tAPI:         grpcserver.DefaultConfig(),\n\t\tTIME:        timeConfig.DefaultConfig(),\n\t\tSMESHING:    smeshing,\n\t\tPOSTService: activation.DefaultPostServiceConfig(),\n\t\tFETCH:       fetch.DefaultConfig(),\n\t\tLOGGING:     logging,\n\t\tSync: syncer.Config{\n\t\t\tInterval:                 time.Minute,\n\t\t\tEpochEndFraction:         0.8,\n\t\t\tMaxStaleDuration:         time.Hour,\n\t\t\tStandalone:               false,\n\t\t\tGossipDuration:           50 * time.Second,\n\t\t\tOutOfSyncThresholdLayers: 36, // 3h\n\t\t\tDisableMeshAgreement:     true,\n\t\t\tAtxSync:                  atxsync.DefaultConfig(),\n\t\t\tMalSync:                  malsync.DefaultConfig(),\n\t\t},\n\t\tRecovery: checkpoint.DefaultConfig(),\n\t\tCache:    datastore.DefaultConfig(),\n\t\tActiveSet: miner.ActiveSetPreparation{\n\t\t\tWindow:        60 * time.Minute,\n\t\t\tRetryInterval: time.Minute,\n\t\t\tTries:         20,\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestEscapeBashStr(t *testing.T) {\n\tcases := [][]string{\n\t\t{\"abc\", \"abc\"},\n\t\t{\"test-volume\", \"test-volume\"},\n\t\t{\"http://minio.kube-system:9000/minio/dynamic-ce\", \"http://minio.kube-system:9000/minio/dynamic-ce\"},\n\t\t{\"$(cat /proc/self/status | grep CapEff > /test.txt)\", \"$'$(cat /proc/self/status | grep CapEff > /test.txt)'\"},\n\t\t{\"hel`cat /proc/self/status`lo\", \"$'hel`cat /proc/self/status`lo'\"},\n\t\t{\"'h'el`cat /proc/self/status`lo\", \"$'\\\\'h\\\\'el`cat /proc/self/status`lo'\"},\n\t\t{\"\\\\'h\\\\'el`cat /proc/self/status`lo\", \"$'\\\\'h\\\\'el`cat /proc/self/status`lo'\"},\n\t\t{\"$'h'el`cat /proc/self/status`lo\", \"$'$\\\\'h\\\\'el`cat /proc/self/status`lo'\"},\n\t\t{\"hel\\\\`cat /proc/self/status`lo\", \"$'hel\\\\\\\\`cat /proc/self/status`lo'\"},\n\t\t{\"hel\\\\\\\\`cat /proc/self/status`lo\", \"$'hel\\\\\\\\`cat /proc/self/status`lo'\"},\n\t\t{\"hel\\\\'`cat /proc/self/status`lo\", \"$'hel\\\\'`cat /proc/self/status`lo'\"},\n\t}\n\tfor _, c := range cases {\n\t\tescaped := EscapeBashStr(c[0])\n\t\tif escaped != c[1] {\n\t\t\tt.Errorf(\"escapeBashVar(%s) = %s, want %s\", c[0], escaped, c[1])\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *ConnectionPool) Get(ctx context.Context, token auth.Token) (gitpod.APIInterface, error) {\n\torigin := origin.FromContext(ctx)\n\n\tcacheKey := p.cacheKey(token, origin)\n\tcached, found := p.cache.Get(cacheKey)\n\treportCacheOutcome(found)\n\tif found {\n\t\tconn, ok := cached.(*gitpod.APIoverJSONRPC)\n\t\tif ok {\n\t\t\treturn conn, nil\n\t\t}\n\t}\n\n\tconn, err := p.connConstructor(ctx, token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create new connection to server: %w\", err)\n\t}\n\n\tp.cache.Add(cacheKey, conn)\n\tconnectionPoolSize.Inc()\n\n\treturn conn, nil\n}", "is_vulnerable": 0}
{"code": "func (s *Server) getAppEnforceRBAC(ctx context.Context, action, project, namespace, name string, getApp func() (*appv1.Application, error)) (*appv1.Application, *appv1.AppProject, error) {\n\tuser := session.Username(ctx)\n\tif user == \"\" {\n\t\tuser = \"Unknown user\"\n\t}\n\tlogCtx := log.WithFields(map[string]interface{}{\n\t\t\"user\":        user,\n\t\t\"application\": name,\n\t\t\"namespace\":   namespace,\n\t})\n\tif project != \"\" {\n\t\t// The user has provided everything we need to perform an initial RBAC check.\n\t\tgivenRBACName := security.RBACName(s.ns, project, namespace, name)\n\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceApplications, action, givenRBACName); err != nil {\n\t\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\t\"project\":                project,\n\t\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t\t}).Warnf(\"user tried to %s application which they do not have access to: %s\", action, err)\n\t\t\t// Do a GET on the app. This ensures that the timing of a \"no access\" response is the same as a \"yes access,\n\t\t\t// but the app is in a different project\" response. We don't want the user inferring the existence of the\n\t\t\t// app from response time.\n\t\t\t_, _ = getApp()\n\t\t\treturn nil, nil, permissionDeniedErr\n\t\t}\n\t}\n\ta, err := getApp()\n\tif err != nil {\n\t\tif apierr.IsNotFound(err) {\n\t\t\tif project != \"\" {\n\t\t\t\t// We know that the user was allowed to get the Application, but the Application does not exist. Return 404.\n\t\t\t\treturn nil, nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t\t\t}\n\t\t\t// We don't know if the user was allowed to get the Application, and we don't want to leak information about\n\t\t\t// the Application's existence. Return 403.\n\t\t\tlogCtx.Warn(\"application does not exist\")\n\t\t\treturn nil, nil, permissionDeniedErr\n\t\t}\n\t\tlogCtx.Errorf(\"failed to get application: %s\", err)\n\t\treturn nil, nil, permissionDeniedErr\n\t}\n\t// Even if we performed an initial RBAC check (because the request was fully parameterized), we still need to\n\t// perform a second RBAC check to ensure that the user has access to the actual Application's project (not just the\n\t// project they specified in the request).\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceApplications, action, a.RBACName(s.ns)); err != nil {\n\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\"project\":                a.Spec.Project,\n\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t}).Warnf(\"user tried to %s application which they do not have access to: %s\", action, err)\n\t\tif project != \"\" {\n\t\t\t// The user specified a project. We would have returned a 404 if the user had access to the app, but the app\n\t\t\t// did not exist. So we have to return a 404 when the app does exist, but the user does not have access.\n\t\t\t// Otherwise, they could infer that the app exists based on the error code.\n\t\t\treturn nil, nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t\t}\n\t\t// The user didn't specify a project. We always return permission denied for both lack of access and lack of\n\t\t// existence.\n\t\treturn nil, nil, permissionDeniedErr\n\t}\n\teffectiveProject := \"default\"\n\tif a.Spec.Project != \"\" {\n\t\teffectiveProject = a.Spec.Project\n\t}\n\tif project != \"\" && effectiveProject != project {\n\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\"project\":                a.Spec.Project,\n\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t}).Warnf(\"user tried to %s application in project %s, but the application is in project %s\", action, project, effectiveProject)\n\t\t// The user has access to the app, but the app is in a different project. Return 404, meaning \"app doesn't\n\t\t// exist in that project\".\n\t\treturn nil, nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t}\n\t// Get the app's associated project, and make sure all project restrictions are enforced.\n\tproj, err := s.getAppProject(ctx, a, logCtx)\n\tif err != nil {\n\t\treturn a, nil, err\n\t}\n\treturn a, proj, nil\n}", "is_vulnerable": 0}
{"code": "func (self *Indexer) CheckSimpleIndex(\n\tconfig_obj *config_proto.Config,\n\tindex_urn api.DSPathSpec,\n\tentity string,\n\tkeywords []string) error {\n\n\tdb, err := datastore.GetDB(config_obj)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, keyword := range keywords {\n\t\tmessage := &emptypb.Empty{}\n\t\tkeyword = strings.ToLower(keyword)\n\t\tsubject := index_urn.AddUnsafeChild(keyword, entity)\n\t\treturn db.GetSubject(config_obj, subject, message)\n\t}\n\treturn errors.New(\"Client does not have label\")\n}", "is_vulnerable": 0}
{"code": "func (s *KeyAgentTestSuite) TestAddKey(c *check.C) {\n\t// make a new local agent\n\tlka, err := NewLocalAgent(s.keyDir, s.hostname, s.username, true)\n\tc.Assert(err, check.IsNil)\n\n\t// add the key to the local agent, this should write the key\n\t// to disk as well as load it in the agent\n\t_, err = lka.AddKey(s.key)\n\tc.Assert(err, check.IsNil)\n\n\t// check that the key has been written to disk\n\tfor _, ext := range []string{fileExtCert, \"\", fileExtPub} {\n\t\t_, err := os.Stat(fmt.Sprintf(\"%v/keys/%v/%v%v\", s.keyDir, s.hostname, s.username, ext))\n\t\tc.Assert(err, check.IsNil)\n\t}\n\n\t// get all agent keys from teleport agent and system agent\n\tteleportAgentKeys, err := lka.Agent.List()\n\tc.Assert(err, check.IsNil)\n\tsystemAgentKeys, err := lka.sshAgent.List()\n\tc.Assert(err, check.IsNil)\n\n\t// check that we've loaded a cert as well as a private key into the teleport agent\n\t// and it's for the user we expected to add a certificate for\n\tc.Assert(teleportAgentKeys, check.HasLen, 2)\n\tc.Assert(teleportAgentKeys[0].Type(), check.Equals, \"ssh-rsa-cert-v01@openssh.com\")\n\tc.Assert(teleportAgentKeys[0].Comment, check.Equals, \"teleport:\"+s.username)\n\tc.Assert(teleportAgentKeys[1].Type(), check.Equals, \"ssh-rsa\")\n\tc.Assert(teleportAgentKeys[1].Comment, check.Equals, \"teleport:\"+s.username)\n\n\t// check that we've loaded a cert as well as a private key into the system again\n\tfound := false\n\tfor _, sak := range systemAgentKeys {\n\t\tif sak.Comment == \"teleport:\"+s.username && sak.Type() == \"ssh-rsa\" {\n\t\t\tfound = true\n\t\t}\n\t}\n\tc.Assert(true, check.Equals, found)\n\tfound = false\n\tfor _, sak := range systemAgentKeys {\n\t\tif sak.Comment == \"teleport:\"+s.username && sak.Type() == \"ssh-rsa-cert-v01@openssh.com\" {\n\t\t\tfound = true\n\t\t}\n\t}\n\tc.Assert(true, check.Equals, found)\n\n\t// unload all keys for this user from the teleport agent and system agent\n\terr = lka.UnloadKey()\n\tc.Assert(err, check.IsNil)\n}", "is_vulnerable": 1}
{"code": "func NotEmpty(t TestingT, object interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotEmpty(t, object, msgAndArgs...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (e *Export) IsRevokedAt(pubKey string, timestamp time.Time) bool {\n\treturn e.Revocations.IsRevoked(pubKey, timestamp)\n}", "is_vulnerable": 1}
{"code": "func (s *store) Create(ctx context.Context, key string, obj, out runtime.Object, ttl uint64) error {\n\tpreparedKey, err := s.prepareKey(key)\n\tif err != nil {\n\t\treturn err\n\t}\n\tctx, span := tracing.Start(ctx, \"Create etcd3\",\n\t\tattribute.String(\"audit-id\", audit.GetAuditIDTruncated(ctx)),\n\t\tattribute.String(\"key\", key),\n\t\tattribute.String(\"type\", getTypeName(obj)),\n\t\tattribute.String(\"resource\", s.groupResourceString),\n\t)\n\tdefer span.End(500 * time.Millisecond)\n\tif version, err := s.versioner.ObjectResourceVersion(obj); err == nil && version != 0 {\n\t\treturn errors.New(\"resourceVersion should not be set on objects to be created\")\n\t}\n\tif err := s.versioner.PrepareObjectForStorage(obj); err != nil {\n\t\treturn fmt.Errorf(\"PrepareObjectForStorage failed: %v\", err)\n\t}\n\tspan.AddEvent(\"About to Encode\")\n\tdata, err := runtime.Encode(s.codec, obj)\n\tif err != nil {\n\t\tspan.AddEvent(\"Encode failed\", attribute.Int(\"len\", len(data)), attribute.String(\"err\", err.Error()))\n\t\treturn err\n\t}\n\tspan.AddEvent(\"Encode succeeded\", attribute.Int(\"len\", len(data)))\n\n\topts, err := s.ttlOpts(ctx, int64(ttl))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnewData, err := s.transformer.TransformToStorage(ctx, data, authenticatedDataString(preparedKey))\n\tif err != nil {\n\t\tspan.AddEvent(\"TransformToStorage failed\", attribute.String(\"err\", err.Error()))\n\t\treturn storage.NewInternalError(err.Error())\n\t}\n\tspan.AddEvent(\"TransformToStorage succeeded\")\n\n\tstartTime := time.Now()\n\ttxnResp, err := s.client.KV.Txn(ctx).If(\n\t\tnotFound(preparedKey),\n\t).Then(\n\t\tclientv3.OpPut(preparedKey, string(newData), opts...),\n\t).Commit()\n\tmetrics.RecordEtcdRequestLatency(\"create\", s.groupResourceString, startTime)\n\tif err != nil {\n\t\tspan.AddEvent(\"Txn call failed\", attribute.String(\"err\", err.Error()))\n\t\treturn err\n\t}\n\tspan.AddEvent(\"Txn call succeeded\")\n\n\tif !txnResp.Succeeded {\n\t\treturn storage.NewKeyExistsError(preparedKey, 0)\n\t}\n\n\tif out != nil {\n\t\tputResp := txnResp.Responses[0].GetResponsePut()\n\t\terr = decode(s.codec, s.versioner, data, out, putResp.Header.Revision)\n\t\tif err != nil {\n\t\t\tspan.AddEvent(\"decode failed\", attribute.Int(\"len\", len(data)), attribute.String(\"err\", err.Error()))\n\t\t\treturn err\n\t\t}\n\t\tspan.AddEvent(\"decode succeeded\", attribute.Int(\"len\", len(data)))\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestConstructor(t *testing.T) {\n\tkind := api.ServiceKindTerminatingGateway\n\tcases := map[string]struct {\n\t\textensionName      string\n\t\tarn                string\n\t\tpayloadPassthrough bool\n\t\tregion             string\n\t\texpected           awsLambda\n\t\tok                 bool\n\t}{\n\t\t\"no arguments\": {\n\t\t\tok: false,\n\t\t},\n\t\t\"a bad name\": {\n\t\t\tarn:           \"arn\",\n\t\t\tregion:        \"blah\",\n\t\t\textensionName: \"bad\",\n\t\t\tok:            false,\n\t\t},\n\t\t\"missing arn\": {\n\t\t\tregion: \"blah\",\n\t\t\tok:     false,\n\t\t},\n\t\t\"including payload passthrough\": {\n\t\t\tarn:                \"arn\",\n\t\t\tregion:             \"blah\",\n\t\t\tpayloadPassthrough: true,\n\t\t\texpected: awsLambda{\n\t\t\t\tARN:                \"arn\",\n\t\t\t\tPayloadPassthrough: true,\n\t\t\t},\n\t\t\tok: true,\n\t\t},\n\t}\n\n\tfor n, tc := range cases {\n\t\tt.Run(n, func(t *testing.T) {\n\t\t\textensionName := api.BuiltinAWSLambdaExtension\n\t\t\tif tc.extensionName != \"\" {\n\t\t\t\textensionName = tc.extensionName\n\t\t\t}\n\t\t\tsvc := api.CompoundServiceName{Name: \"svc\"}\n\t\t\text := extensioncommon.RuntimeConfig{\n\t\t\t\tServiceName: svc,\n\t\t\t\tUpstreams: map[api.CompoundServiceName]*extensioncommon.UpstreamData{\n\t\t\t\t\tsvc: {OutgoingProxyKind: kind},\n\t\t\t\t},\n\t\t\t\tEnvoyExtension: api.EnvoyExtension{\n\t\t\t\t\tName: extensionName,\n\t\t\t\t\tArguments: map[string]interface{}{\n\t\t\t\t\t\t\"ARN\":                tc.arn,\n\t\t\t\t\t\t\"PayloadPassthrough\": tc.payloadPassthrough,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\te, err := Constructor(ext.EnvoyExtension)\n\n\t\t\tif tc.ok {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t\trequire.Equal(t, &extensioncommon.UpstreamEnvoyExtender{Extension: &tc.expected}, e)\n\t\t\t} else {\n\t\t\t\trequire.Error(t, err)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s GetSecurityGroupsForVpcOutput) GoString() string {\n\treturn s.String()\n}", "is_vulnerable": 0}
{"code": "func shmget(key int, size int, flag int) (id int, err error) {\n\tr0, _, e1 := syscall_syscall(libc_shmget_trampoline_addr, uintptr(key), uintptr(size), uintptr(flag))\n\tid = int(r0)\n\tif e1 != 0 {\n\t\terr = errnoErr(e1)\n\t}\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (p *HTTPClient) ReadByte() (c byte, err error) {\n\treturn readByte(p.response.Body)\n}", "is_vulnerable": 1}
{"code": "func testInvalidRequestHandler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"invalid_request_handler\\n\")\n}", "is_vulnerable": 0}
{"code": "func readStatus(pid string) ([]string, error) {\n\tpath := fmt.Sprintf(\"/proc/%s/status\", pid)\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlines := []string{}\n\tscanner := bufio.NewScanner(f)\n\tfor scanner.Scan() {\n\t\tlines = append(lines, scanner.Text())\n\t}\n\treturn lines, nil\n}", "is_vulnerable": 0}
{"code": "func (client DeploymentsClient) DeleteSender(req *http.Request) (future DeploymentsDeleteFuture, err error) {\n\tvar resp *http.Response\n\tresp, err = autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n\tif err != nil {\n\t\treturn\n\t}\n\tfuture.Future, err = azure.NewFutureFromResponse(resp)\n\treturn\n}", "is_vulnerable": 1}
{"code": "func NewManagerFactory(staticConfiguration static.Configuration, routinesPool *safe.Pool, metricsRegistry metrics.Registry, roundTripperManager *RoundTripperManager, acmeHTTPHandler http.Handler) *ManagerFactory {\n\tfactory := &ManagerFactory{\n\t\tmetricsRegistry:     metricsRegistry,\n\t\troutinesPool:        routinesPool,\n\t\troundTripperManager: roundTripperManager,\n\t\tacmeHTTPHandler:     acmeHTTPHandler,\n\t}\n\n\tif staticConfiguration.API != nil {\n\t\tfactory.api = api.NewBuilder(staticConfiguration)\n\n\t\tif staticConfiguration.API.Dashboard {\n\t\t\tfactory.dashboardHandler = http.FileServer(staticConfiguration.API.DashboardAssets)\n\t\t}\n\t}\n\n\tif staticConfiguration.Providers != nil && staticConfiguration.Providers.Rest != nil {\n\t\tfactory.restHandler = staticConfiguration.Providers.Rest.CreateRouter()\n\t}\n\n\tif staticConfiguration.Metrics != nil && staticConfiguration.Metrics.Prometheus != nil {\n\t\tfactory.metricsHandler = metrics.PrometheusHandler()\n\t}\n\n\t// This check is necessary because even when staticConfiguration.Ping == nil ,\n\t// the affectation would make factory.pingHandle become a typed nil, which does not pass the nil test,\n\t// and would break things elsewhere.\n\tif staticConfiguration.Ping != nil {\n\t\tfactory.pingHandler = staticConfiguration.Ping\n\t}\n\n\treturn factory\n}", "is_vulnerable": 1}
{"code": "func TestConfigurator_ErrorPropagation(t *testing.T) {\n\ttype variant struct {\n\t\tconfig       Config\n\t\tshouldErr    bool\n\t\texcludeCheck bool\n\t}\n\tcafile := \"../test/ca/root.cer\"\n\tcapath := \"../test/ca_path\"\n\tcertfile := \"../test/key/ourdomain.cer\"\n\tkeyfile := \"../test/key/ourdomain.key\"\n\tvariants := []variant{\n\t\t{Config{}, false, false},                                              // 1\n\t\t{Config{TLSMinVersion: \"tls9\"}, true, false},                          // 1\n\t\t{Config{TLSMinVersion: \"\"}, false, false},                             // 2\n\t\t{Config{VerifyOutgoing: true, CAFile: \"\", CAPath: \"\"}, true, false},   // 6\n\t\t{Config{VerifyOutgoing: false, CAFile: \"\", CAPath: \"\"}, false, false}, // 7\n\t\t{Config{VerifyOutgoing: false, CAFile: cafile, CAPath: \"\"},\n\t\t\tfalse, false}, // 8\n\t\t{Config{VerifyOutgoing: false, CAFile: \"\", CAPath: capath},\n\t\t\tfalse, false}, // 9\n\t\t{Config{VerifyOutgoing: false, CAFile: cafile, CAPath: capath},\n\t\t\tfalse, false}, // 10\n\t\t{Config{VerifyOutgoing: true, CAFile: cafile, CAPath: \"\"},\n\t\t\tfalse, false}, // 11\n\t\t{Config{VerifyOutgoing: true, CAFile: \"\", CAPath: capath},\n\t\t\tfalse, false}, // 12\n\t\t{Config{VerifyOutgoing: true, CAFile: cafile, CAPath: capath},\n\t\t\tfalse, false}, // 13\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: \"\"}, true, false}, // 14\n\t\t{Config{VerifyIncomingRPC: true, CAFile: \"\", CAPath: \"\"},\n\t\t\ttrue, false}, // 15\n\t\t{Config{VerifyIncomingHTTPS: true, CAFile: \"\", CAPath: \"\"},\n\t\t\ttrue, false}, // 16\n\t\t{Config{VerifyIncoming: true, CAFile: cafile, CAPath: \"\"}, true, false}, // 17\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: capath}, true, false}, // 18\n\t\t{Config{VerifyIncoming: true, CAFile: \"\", CAPath: capath,\n\t\t\tCertFile: certfile, KeyFile: keyfile}, false, false}, // 19\n\t\t{Config{CertFile: \"bogus\", KeyFile: \"bogus\"}, true, true},                   // 20\n\t\t{Config{CAFile: \"bogus\"}, true, true},                                       // 21\n\t\t{Config{CAPath: \"bogus\"}, true, true},                                       // 22\n\t\t{Config{VerifyIncoming: true, CAFile: cafile, AutoTLS: true}, false, false}, // 22\n\t}\n\tfor _, v := range tlsVersions() {\n\t\tvariants = append(variants, variant{Config{TLSMinVersion: v}, false, false})\n\t}\n\n\tc := Configurator{autoTLS: &autoTLS{}, manual: &manual{}}\n\tfor i, v := range variants {\n\t\tinfo := fmt.Sprintf(\"case %d, config: %+v\", i, v.config)\n\t\t_, err1 := NewConfigurator(v.config, nil)\n\t\terr2 := c.Update(v.config)\n\n\t\tvar err3 error\n\t\tif !v.excludeCheck {\n\t\t\tcert, err := v.config.KeyPair()\n\t\t\trequire.NoError(t, err, info)\n\t\t\tpems, err := LoadCAs(v.config.CAFile, v.config.CAPath)\n\t\t\trequire.NoError(t, err, info)\n\t\t\tpool, err := newX509CertPool(pems)\n\t\t\trequire.NoError(t, err, info)\n\t\t\terr3 = c.check(v.config, pool, cert)\n\t\t}\n\t\tif v.shouldErr {\n\t\t\trequire.Error(t, err1, info)\n\t\t\trequire.Error(t, err2, info)\n\t\t\tif !v.excludeCheck {\n\t\t\t\trequire.Error(t, err3, info)\n\t\t\t}\n\t\t} else {\n\t\t\trequire.NoError(t, err1, info)\n\t\t\trequire.NoError(t, err2, info)\n\t\t\tif !v.excludeCheck {\n\t\t\t\trequire.NoError(t, err3, info)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tconf.App.Version = \"0.12.8\"\n}", "is_vulnerable": 0}
{"code": "func (m *NinRepPackedNativeUnsafe) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNativeUnsafe: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNativeUnsafe: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowPacked\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipPacked(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthPacked\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Context) KeyListNext() bool {\n\tc.Key = newKey()\n\terr := handleError(C.gpgme_op_keylist_next(c.ctx, &c.Key.k))\n\truntime.KeepAlive(c)\n\tif err != nil {\n\t\tif e, ok := err.(Error); ok && e.Code() == ErrorEOF {\n\t\t\tc.KeyError = nil\n\t\t} else {\n\t\t\tc.KeyError = err\n\t\t}\n\t\treturn false\n\t}\n\tc.KeyError = nil\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (src *GSSEncRequest) Encode(dst []byte) []byte {\n\tdst = pgio.AppendInt32(dst, 8)\n\tdst = pgio.AppendInt32(dst, gssEncReqNumber)\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func init() {\n\tconf.App.Version = \"0.12.7\"\n}", "is_vulnerable": 1}
{"code": "func (s *S2IBuilder) Build() error {\n\tif s.build.Spec.Strategy.SourceStrategy == nil {\n\t\treturn fmt.Errorf(\"the source to image builder must be used with the source strategy\")\n\t}\n\n\tvar push bool\n\n\tcontextDir := filepath.Clean(s.build.Spec.Source.ContextDir)\n\tif contextDir == \".\" || contextDir == \"/\" {\n\t\tcontextDir = \"\"\n\t}\n\tbuildDir, err := ioutil.TempDir(\"\", \"s2i-build\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tsrcDir := filepath.Join(buildDir, s2iapi.Source)\n\tif err := os.MkdirAll(srcDir, os.ModePerm); err != nil {\n\t\treturn err\n\t}\n\ttmpDir := filepath.Join(buildDir, \"tmp\")\n\tif err := os.MkdirAll(tmpDir, os.ModePerm); err != nil {\n\t\treturn err\n\t}\n\n\tdownload := &downloader{\n\t\ts:       s,\n\t\tin:      os.Stdin,\n\t\ttimeout: urlCheckTimeout,\n\n\t\tdir:        srcDir,\n\t\tcontextDir: contextDir,\n\t\ttmpDir:     tmpDir,\n\t}\n\t// if there is no output target, set one up so the docker build logic\n\t// (which requires a tag) will still work, but we won't push it at the end.\n\tif s.build.Spec.Output.To == nil || len(s.build.Spec.Output.To.Name) == 0 {\n\t\ts.build.Status.OutputDockerImageReference = s.build.Name\n\t} else {\n\t\tpush = true\n\t}\n\tpushTag := s.build.Status.OutputDockerImageReference\n\tgit := s.build.Spec.Source.Git\n\n\tvar ref string\n\tif s.build.Spec.Revision != nil && s.build.Spec.Revision.Git != nil &&\n\t\tlen(s.build.Spec.Revision.Git.Commit) != 0 {\n\t\tref = s.build.Spec.Revision.Git.Commit\n\t} else if git != nil && len(git.Ref) != 0 {\n\t\tref = git.Ref\n\t}\n\n\tsourceURI := &url.URL{\n\t\tScheme:   \"file\",\n\t\tPath:     srcDir,\n\t\tFragment: ref,\n\t}\n\n\tinjections := s2iapi.InjectionList{}\n\tfor _, s := range s.build.Spec.Source.Secrets {\n\t\tglog.V(3).Infof(\"Injecting secret %q into a build into %q\", s.Secret.Name, filepath.Clean(s.DestinationDir))\n\t\tsecretSourcePath := filepath.Join(strategy.SecretBuildSourceBaseMountPath, s.Secret.Name)\n\t\tinjections = append(injections, s2iapi.InjectPath{\n\t\t\tSourcePath:     secretSourcePath,\n\t\t\tDestinationDir: s.DestinationDir,\n\t\t})\n\t}\n\n\tbuildTag := randomBuildTag(s.build.Namespace, s.build.Name)\n\n\tconfig := &s2iapi.Config{\n\t\tWorkingDir:     buildDir,\n\t\tDockerConfig:   &s2iapi.DockerConfig{Endpoint: s.dockerSocket},\n\t\tDockerCfgPath:  os.Getenv(dockercfg.PullAuthType),\n\t\tLabelNamespace: api.DefaultDockerLabelNamespace,\n\n\t\tScriptsURL: s.build.Spec.Strategy.SourceStrategy.Scripts,\n\n\t\tBuilderImage:       s.build.Spec.Strategy.SourceStrategy.From.Name,\n\t\tIncremental:        s.build.Spec.Strategy.SourceStrategy.Incremental,\n\t\tIncrementalFromTag: pushTag,\n\n\t\tEnvironment:       buildEnvVars(s.build),\n\t\tDockerNetworkMode: getDockerNetworkMode(),\n\n\t\tSource:       sourceURI.String(),\n\t\tTag:          buildTag,\n\t\tContextDir:   s.build.Spec.Source.ContextDir,\n\t\tCGroupLimits: s.cgLimits,\n\t\tInjections:   injections,\n\t}\n\n\tif s.build.Spec.Strategy.SourceStrategy.ForcePull {\n\t\tglog.V(4).Infof(\"With force pull true, setting policies to %s\", s2iapi.PullAlways)\n\t\tconfig.BuilderPullPolicy = s2iapi.PullAlways\n\t} else {\n\t\tglog.V(4).Infof(\"With force pull false, setting policies to %s\", s2iapi.PullIfNotPresent)\n\t\tconfig.BuilderPullPolicy = s2iapi.PullIfNotPresent\n\t}\n\tconfig.PreviousImagePullPolicy = s2iapi.PullAlways\n\n\tallowedUIDs := os.Getenv(\"ALLOWED_UIDS\")\n\tglog.V(2).Infof(\"The value of ALLOWED_UIDS is [%s]\", allowedUIDs)\n\tif len(allowedUIDs) > 0 {\n\t\terr := config.AllowedUIDs.Set(allowedUIDs)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif errs := s.validator.ValidateConfig(config); len(errs) != 0 {\n\t\tvar buffer bytes.Buffer\n\t\tfor _, ve := range errs {\n\t\t\tbuffer.WriteString(ve.Error())\n\t\t\tbuffer.WriteString(\", \")\n\t\t}\n\t\treturn errors.New(buffer.String())\n\t}\n\n\t// If DockerCfgPath is provided in api.Config, then attempt to read the the\n\t// dockercfg file and get the authentication for pulling the builder image.\n\tconfig.PullAuthentication, _ = dockercfg.NewHelper().GetDockerAuth(config.BuilderImage, dockercfg.PullAuthType)\n\tconfig.IncrementalAuthentication, _ = dockercfg.NewHelper().GetDockerAuth(pushTag, dockercfg.PushAuthType)\n\n\tglog.V(2).Infof(\"Creating a new S2I builder with build config: %#v\\n\", describe.DescribeConfig(config))\n\tbuilder, err := s.builder.Builder(config, s2ibuild.Overrides{Downloader: download})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tglog.V(4).Infof(\"Starting S2I build from %s/%s BuildConfig ...\", s.build.Namespace, s.build.Name)\n\n\tif _, err = builder.Build(config); err != nil {\n\t\treturn err\n\t}\n\n\tcname := containerName(\"s2i\", s.build.Name, s.build.Namespace, \"post-commit\")\n\tif err := execPostCommitHook(s.dockerClient, s.build.Spec.PostCommit, buildTag, cname); err != nil {\n\t\treturn err\n\t}\n\n\tif push {\n\t\tif err := tagImage(s.dockerClient, buildTag, pushTag); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := removeImage(s.dockerClient, buildTag); err != nil {\n\t\tglog.Warningf(\"Failed to remove temporary build tag %v: %v\", buildTag, err)\n\t}\n\n\tif push {\n\t\t// Get the Docker push authentication\n\t\tpushAuthConfig, authPresent := dockercfg.NewHelper().GetDockerAuth(\n\t\t\tpushTag,\n\t\t\tdockercfg.PushAuthType,\n\t\t)\n\t\tif authPresent {\n\t\t\tglog.Infof(\"Using provided push secret for pushing %s image\", pushTag)\n\t\t} else {\n\t\t\tglog.Infof(\"No push secret provided\")\n\t\t}\n\t\tglog.Infof(\"Pushing %s image ...\", pushTag)\n\t\tif err := pushImage(s.dockerClient, pushTag, pushAuthConfig); err != nil {\n\t\t\t// write extended error message to assist in problem resolution\n\t\t\tmsg := fmt.Sprintf(\"Failed to push image. Response from registry is: %v\", err)\n\t\t\tif authPresent {\n\t\t\t\tglog.Infof(\"Registry server Address: %s\", pushAuthConfig.ServerAddress)\n\t\t\t\tglog.Infof(\"Registry server User Name: %s\", pushAuthConfig.Username)\n\t\t\t\tglog.Infof(\"Registry server Email: %s\", pushAuthConfig.Email)\n\t\t\t\tpasswordPresent := \"<<empty>>\"\n\t\t\t\tif len(pushAuthConfig.Password) > 0 {\n\t\t\t\t\tpasswordPresent = \"<<non-empty>>\"\n\t\t\t\t}\n\t\t\t\tglog.Infof(\"Registry server Password: %s\", passwordPresent)\n\t\t\t}\n\t\t\treturn errors.New(msg)\n\t\t}\n\t\tglog.Infof(\"Successfully pushed %s\", pushTag)\n\t\tglog.Flush()\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (vfs *VirtualFilesystem) UmountAt(ctx context.Context, creds *auth.Credentials, pop *PathOperation, opts *UmountOptions) error {\n\tif opts.Flags&^(linux.MNT_FORCE|linux.MNT_DETACH) != 0 {\n\t\treturn linuxerr.EINVAL\n\t}\n\n\t// MNT_FORCE is currently unimplemented except for the permission check.\n\t// Force unmounting specifically requires CAP_SYS_ADMIN in the root user\n\t// namespace, and not in the owner user namespace for the target mount. See\n\t// fs/namespace.c:SYSCALL_DEFINE2(umount, ...)\n\tif opts.Flags&linux.MNT_FORCE != 0 && creds.HasCapabilityIn(linux.CAP_SYS_ADMIN, creds.UserNamespace.Root()) {\n\t\treturn linuxerr.EPERM\n\t}\n\tvd, err := vfs.getMountpoint(ctx, creds, pop)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer vd.DecRef(ctx)\n\n\tvfs.lockMounts()\n\tdefer vfs.unlockMounts(ctx)\n\tif mntns := MountNamespaceFromContext(ctx); mntns != nil {\n\t\tvfs.delayDecRef(mntns)\n\t\tif mntns != vd.mount.ns {\n\t\t\treturn linuxerr.EINVAL\n\t\t}\n\n\t\tif vd.mount == vd.mount.ns.root {\n\t\t\treturn linuxerr.EINVAL\n\t\t}\n\t}\n\n\tif opts.Flags&linux.MNT_DETACH == 0 && vfs.arePropMountsBusy(vd.mount) {\n\t\treturn linuxerr.EBUSY\n\t}\n\n\t// TODO(gvisor.dev/issue/1035): Linux special-cases umount of the caller's\n\t// root, which we don't implement yet (we'll just fail it since the caller\n\t// holds a reference on it).\n\tvfs.umountTreeLocked(vd.mount, &umountRecursiveOptions{\n\t\teager:               opts.Flags&linux.MNT_DETACH == 0,\n\t\tdisconnectHierarchy: true,\n\t\tpropagate:           true,\n\t})\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (e errorTranslateQuerier) Select(sortSeries bool, hints *storage.SelectHints, matchers ...*labels.Matcher) storage.SeriesSet {\n\ts := e.q.Select(sortSeries, hints, matchers...)\n\treturn errorTranslateSeriesSet{s}\n}", "is_vulnerable": 1}
{"code": "func Test_buildPolicyTransportSocket(t *testing.T) {\n\tctx := context.Background()\n\tcacheDir, _ := os.UserCacheDir()\n\tcustomCA := filepath.Join(cacheDir, \"pomerium\", \"envoy\", \"files\", \"custom-ca-32484c314b584447463735303142374c31414145374650305a525539554938594d524855353757313942494d473847535231.pem\")\n\n\tb := New(\"local-grpc\", \"local-http\", filemgr.NewManager(), nil)\n\trootCABytes, _ := getCombinedCertificateAuthority(\"\", \"\")\n\trootCA := b.filemgr.BytesDataSource(\"ca.pem\", rootCABytes).GetFilename()\n\n\to1 := config.NewDefaultOptions()\n\to2 := config.NewDefaultOptions()\n\to2.CA = base64.StdEncoding.EncodeToString([]byte{0, 0, 0, 0})\n\n\tcombinedCABytes, _ := getCombinedCertificateAuthority(o2.CA, \"\")\n\tcombinedCA := b.filemgr.BytesDataSource(\"ca.pem\", combinedCABytes).GetFilename()\n\n\tt.Run(\"insecure\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo: mustParseWeightedURLs(t, \"http://example.com\"),\n\t\t}, *mustParseURL(t, \"http://example.com\"))\n\t\trequire.NoError(t, err)\n\t\tassert.Nil(t, ts)\n\t})\n\tt.Run(\"host as sni\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo: mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n            \t            \t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-RSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-RSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-RSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-ECDSA-AES128-SHA\",\n            \t            \t\"ECDHE-RSA-AES128-SHA\",\n            \t            \t\"AES128-GCM-SHA256\",\n            \t            \t\"AES128-SHA\",\n            \t            \t\"ECDHE-ECDSA-AES256-SHA\",\n            \t            \t\"ECDHE-RSA-AES256-SHA\",\n            \t            \t\"AES256-GCM-SHA384\",\n            \t            \t\"AES256-SHA\"\n            \t            ],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+rootCA+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n\tt.Run(\"tls_server_name as sni\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo:            mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t\tTLSServerName: \"use-this-name.example.com\",\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n            \t            \t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-RSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-RSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-RSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-ECDSA-AES128-SHA\",\n            \t            \t\"ECDHE-RSA-AES128-SHA\",\n            \t            \t\"AES128-GCM-SHA256\",\n            \t            \t\"AES128-SHA\",\n            \t            \t\"ECDHE-ECDSA-AES256-SHA\",\n            \t            \t\"ECDHE-RSA-AES256-SHA\",\n            \t            \t\"AES256-GCM-SHA384\",\n            \t            \t\"AES256-SHA\"\n            \t            ],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"use-this-name.example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+rootCA+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"use-this-name.example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n\tt.Run(\"tls_skip_verify\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo:            mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t\tTLSSkipVerify: true,\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n            \t            \t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-RSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-RSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-RSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-ECDSA-AES128-SHA\",\n            \t            \t\"ECDHE-RSA-AES128-SHA\",\n            \t            \t\"AES128-GCM-SHA256\",\n            \t            \t\"AES128-SHA\",\n            \t            \t\"ECDHE-ECDSA-AES256-SHA\",\n            \t            \t\"ECDHE-RSA-AES256-SHA\",\n            \t            \t\"AES256-GCM-SHA384\",\n            \t            \t\"AES256-SHA\"\n            \t            ],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+rootCA+`\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"trustChainVerification\": \"ACCEPT_UNTRUSTED\"\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n\tt.Run(\"custom ca\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo:          mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t\tTLSCustomCA: base64.StdEncoding.EncodeToString([]byte{0, 0, 0, 0}),\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-CHACHA20-POLY1305\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES128-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES128-SHA\",\n\t\t\t\t\t\t\t\t\"AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"AES128-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES256-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES256-SHA\",\n\t\t\t\t\t\t\t\t\"AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"AES256-SHA\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+customCA+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n\tt.Run(\"options custom ca\", func(t *testing.T) {\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o2, &config.Policy{\n\t\t\tTo: mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-CHACHA20-POLY1305\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES128-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES128-SHA\",\n\t\t\t\t\t\t\t\t\"AES128-GCM-SHA256\",\n\t\t\t\t\t\t\t\t\"AES128-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-ECDSA-AES256-SHA\",\n\t\t\t\t\t\t\t\t\"ECDHE-RSA-AES256-SHA\",\n\t\t\t\t\t\t\t\t\"AES256-GCM-SHA384\",\n\t\t\t\t\t\t\t\t\"AES256-SHA\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+combinedCA+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n\tt.Run(\"client certificate\", func(t *testing.T) {\n\t\tclientCert, _ := cryptutil.CertificateFromBase64(aExampleComCert, aExampleComKey)\n\t\tts, err := b.buildPolicyTransportSocket(ctx, o1, &config.Policy{\n\t\t\tTo:                mustParseWeightedURLs(t, \"https://example.com\"),\n\t\t\tClientCertificate: clientCert,\n\t\t}, *mustParseURL(t, \"https://example.com\"))\n\t\trequire.NoError(t, err)\n\t\ttestutil.AssertProtoJSONEqual(t, `\n\t\t\t{\n\t\t\t\t\"name\": \"tls\",\n\t\t\t\t\"typedConfig\": {\n\t\t\t\t\t\"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\",\n\t\t\t\t\t\"commonTlsContext\": {\n\t\t\t\t\t\t\"alpnProtocols\": [\"h2\", \"http/1.1\"],\n\t\t\t\t\t\t\"tlsParams\": {\n\t\t\t\t\t\t\t\"cipherSuites\": [\n            \t            \t\"ECDHE-ECDSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-RSA-AES256-GCM-SHA384\",\n            \t            \t\"ECDHE-ECDSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-RSA-AES128-GCM-SHA256\",\n            \t            \t\"ECDHE-ECDSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-RSA-CHACHA20-POLY1305\",\n            \t            \t\"ECDHE-ECDSA-AES128-SHA\",\n            \t            \t\"ECDHE-RSA-AES128-SHA\",\n            \t            \t\"AES128-GCM-SHA256\",\n            \t            \t\"AES128-SHA\",\n            \t            \t\"ECDHE-ECDSA-AES256-SHA\",\n            \t            \t\"ECDHE-RSA-AES256-SHA\",\n            \t            \t\"AES256-GCM-SHA384\",\n            \t            \t\"AES256-SHA\"\n            \t            ],\n\t\t\t\t\t\t\t\"ecdhCurves\": [\n\t\t\t\t\t\t\t\t\"X25519\",\n\t\t\t\t\t\t\t\t\"P-256\",\n\t\t\t\t\t\t\t\t\"P-384\",\n\t\t\t\t\t\t\t\t\"P-521\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"tlsCertificates\": [{\n\t\t\t\t\t\t\t\"certificateChain\":{\n\t\t\t\t\t\t\t\t\"filename\": \"`+filepath.Join(cacheDir, \"pomerium\", \"envoy\", \"files\", \"tls-crt-354e49305a5a39414a545530374e58454e48334148524c4e324258463837364355564c4e4532464b54355139495547514a38.pem\")+`\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"privateKey\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+filepath.Join(cacheDir, \"pomerium\", \"envoy\", \"files\", \"tls-key-3350415a38414e4e4a4655424e55393430474147324651433949384e485341334b5157364f424b4c5856365a545937383735.pem\")+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}],\n\t\t\t\t\t\t\"validationContext\": {\n\t\t\t\t\t\t\t\"matchTypedSubjectAltNames\": [{\n\t\t\t\t\t\t\t\t\"sanType\": \"DNS\",\n\t\t\t\t\t\t\t\t\"matcher\": {\n\t\t\t\t\t\t\t\t\t\"exact\": \"example.com\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t\t\"trustedCa\": {\n\t\t\t\t\t\t\t\t\"filename\": \"`+rootCA+`\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t\t\"sni\": \"example.com\"\n\t\t\t\t}\n\t\t\t}\n\t\t`, ts)\n\t})\n}", "is_vulnerable": 1}
{"code": "func (ctx *internalContext) activeBuildOrRecentBuildOrRebuild() BuildResult {\n\tctx.mutex.Lock()\n\n\t// If there's already an active build, wait for it and return that\n\tif build := ctx.activeBuild; build != nil {\n\t\tctx.mutex.Unlock()\n\t\tbuild.waitGroup.Wait()\n\t\treturn build.state.result\n\t}\n\n\t// Then try to return a recentl already-completed build\n\tif build := ctx.recentBuild; build != nil {\n\t\tctx.mutex.Unlock()\n\t\treturn *build\n\t}\n\n\t// Otherwise, fall back to rebuilding\n\tctx.mutex.Unlock()\n\treturn ctx.Rebuild()\n}", "is_vulnerable": 0}
{"code": "func (p *Pack) ExtraAuthz() (map[string]interface{}, error) {", "is_vulnerable": 0}
{"code": "func NewHandler(appLister applisters.ApplicationLister, namespace string, enabledNamespaces []string, db db.ArgoDB, enf *rbac.Enforcer, cache *servercache.Cache,\n\tappResourceTree AppResourceTreeFn, allowedShells []string, sessionManager *util_session.SessionManager) *terminalHandler {\n\treturn &terminalHandler{\n\t\tappLister:         appLister,\n\t\tdb:                db,\n\t\tenf:               enf,\n\t\tcache:             cache,\n\t\tappResourceTreeFn: appResourceTree,\n\t\tallowedShells:     allowedShells,\n\t\tnamespace:         namespace,\n\t\tenabledNamespaces: enabledNamespaces,\n\t\tsessionManager:    sessionManager,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (g *GitGetter) clone(ctx context.Context, dst, sshKeyFile string, u *url.URL, ref string, depth int) error {\n\targs := []string{\"clone\"}\n\n\toriginalRef := ref // we handle an unspecified ref differently than explicitly selecting the default branch below\n\tif ref == \"\" {\n\t\tref = findRemoteDefaultBranch(ctx, u)\n\t}\n\tif depth > 0 {\n\t\targs = append(args, \"--depth\", strconv.Itoa(depth))\n\t\targs = append(args, \"--branch\", ref)\n\t}\n\targs = append(args, \"--\", u.String(), dst)\n\n\tcmd := exec.CommandContext(ctx, \"git\", args...)\n\tsetupGitEnv(cmd, sshKeyFile)\n\terr := getRunCommand(cmd)\n\tif err != nil {\n\t\tif depth > 0 && originalRef != \"\" {\n\t\t\t// If we're creating a shallow clone then the given ref must be\n\t\t\t// a named ref (branch or tag) rather than a commit directly.\n\t\t\t// We can't accurately recognize the resulting error here without\n\t\t\t// hard-coding assumptions about git's human-readable output, but\n\t\t\t// we can at least try a heuristic.\n\t\t\tif gitCommitIDRegex.MatchString(originalRef) {\n\t\t\t\treturn fmt.Errorf(\"%w (note that setting 'depth' requires 'ref' to be a branch or tag name)\", err)\n\t\t\t}\n\t\t}\n\t\treturn err\n\t}\n\n\tif depth < 1 && originalRef != \"\" {\n\t\t// If we didn't add --depth and --branch above then we will now be\n\t\t// on the remote repository's default branch, rather than the selected\n\t\t// ref, so we'll need to fix that before we return.\n\t\treturn g.checkout(ctx, dst, originalRef)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tg.AfterEach(func() {\n\t\t\trfs.reset()\n\t\t\tatomic.StoreInt64(&fs.diskUsed, 0)\n\t\t\tatomic.StoreInt64(&fs.diskLimit, 0)\n\t\t})", "is_vulnerable": 1}
{"code": "\texpectInvalidKey := func(methodName string, err error) {\n\t\tif err == nil {\n\t\t\tt.Errorf(\"[%s] expected invalid key error; got nil\", methodName)\n\t\t} else if err.Error() != expectedError {\n\t\t\tt.Errorf(\"[%s] expected invalid key error; got %v\", methodName, err)\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "\treturn newServiceWithOpt(func(gitClient *gitmocks.Client) {\n\t\tgitClient.On(\"Init\").Return(nil)\n\t\tgitClient.On(\"Fetch\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"Checkout\", mock.Anything).Return(nil)\n\t\tgitClient.On(\"LsRemote\", mock.Anything).Return(mock.Anything, nil)\n\t\tgitClient.On(\"CommitSHA\").Return(mock.Anything, nil)\n\t\tgitClient.On(\"Root\").Return(root)\n\t\tif signed {\n\t\t\tgitClient.On(\"VerifyCommitSignature\", mock.Anything).Return(testSignature, nil)\n\t\t} else {\n\t\t\tgitClient.On(\"VerifyCommitSignature\", mock.Anything).Return(\"\", nil)\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func (h *TaskcafeHandler) LoginHandler(w http.ResponseWriter, r *http.Request) {\n\tvar requestData LoginRequestData\n\terr := json.NewDecoder(r.Body).Decode(&requestData)\n\tif err != nil {\n\t\tw.WriteHeader(http.StatusBadRequest)\n\t\tlog.Debug(\"bad request body\")\n\t\treturn\n\t}\n\n\tuser, err := h.repo.GetUserAccountByUsername(r.Context(), requestData.Username)\n\tif err != nil {\n\t\tlog.WithFields(log.Fields{\n\t\t\t\"username\": requestData.Username,\n\t\t}).Warn(\"user account not found\")\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\treturn\n\t}\n\n\terr = bcrypt.CompareHashAndPassword([]byte(user.PasswordHash), []byte(requestData.Password))\n\tif err != nil {\n\t\tlog.WithFields(log.Fields{\n            \"username\": requestData.Username,\n        }).Warn(\"password incorrect for user\")\n\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\treturn\n\t}\n\n\trefreshCreatedAt := time.Now().UTC()\n\trefreshExpiresAt := refreshCreatedAt.AddDate(0, 0, 1)\n\trefreshTokenString, err := h.repo.CreateRefreshToken(r.Context(), db.CreateRefreshTokenParams{user.UserID, refreshCreatedAt, refreshExpiresAt})\n\n\taccessTokenString, err := auth.NewAccessToken(user.UserID.String(), auth.Unrestricted, user.RoleCode)\n\tif err != nil {\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t}\n\n\tw.Header().Set(\"Content-type\", \"application/json\")\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     \"refreshToken\",\n\t\tValue:    refreshTokenString.TokenID.String(),\n\t\tExpires:  refreshExpiresAt,\n\t\tHttpOnly: true,\n\t})\n\tjson.NewEncoder(w).Encode(LoginResponseData{accessTokenString, false})\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"No signature\", func(t *testing.T) {\n\t\tsampleIDToken, err := jwt.NewWithClaims(jwt.SigningMethodRS512, jwt.RegisteredClaims{\n\t\t\tAudience:  r.allowedAudience,\n\t\t\tExpiresAt: jwt.NewNumericDate(time.Now().Add(time.Hour)),\n\t\t\tIssuedAt:  jwt.NewNumericDate(time.Now()),\n\t\t\tIssuer:    \"localhost\",\n\t\t\tSubject:   \"someone\",\n\t\t}).SignedString(sampleRSAKey)\n\t\tif !assert.NoError(t, err) {\n\t\t\tt.FailNow()\n\t\t}\n\n\t\tparts := strings.Split(sampleIDToken, \".\")\n\t\tsampleIDToken = strings.Join(parts[:len(parts)-1], \".\") + \".\"\n\n\t\t_, err = r.ValidateAccessToken(context.Background(), \"myserver\", sampleIDToken)\n\t\tif !assert.Error(t, err) {\n\t\t\tt.FailNow()\n\t\t}\n\n\t\tassert.Contains(t, err.Error(), \"failed to verify id token signature\")\n\t})", "is_vulnerable": 0}
{"code": "func (s *Stats) LoadFetchedChunkBytes() uint64 {\n\tif s == nil {\n\t\treturn 0\n\t}\n\n\treturn atomic.LoadUint64(&s.FetchedChunkBytes)\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) Eventually(condition func() bool, waitFor time.Duration, tick time.Duration, msgAndArgs ...interface{}) bool {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\treturn Eventually(a.t, condition, waitFor, tick, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func TestLoadPayloads(t *testing.T) {\n\ttempdir, err := os.MkdirTemp(\"\", \"templates-*\")\n\trequire.NoError(t, err, \"could not create temp dir\")\n\tdefer os.RemoveAll(tempdir)\n\n\tgenerator := &PayloadGenerator{catalog: disk.NewCatalog(tempdir)}\n\n\tfullpath := filepath.Join(tempdir, \"payloads.txt\")\n\terr = os.WriteFile(fullpath, []byte(\"test\\nanother\"), 0777)\n\trequire.NoError(t, err, \"could not write payload\")\n\n\t// Test sandbox\n\tt.Run(\"templates-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/test\", tempdir, true)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})\n\tt.Run(\"template-directory\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, filepath.Join(tempdir, \"test.yaml\"), \"/test\", true)\n\t\trequire.NoError(t, err, \"could not load payloads\")\n\t\trequire.Equal(t, map[string][]string{\"new\": {\"test\", \"another\"}}, values, \"could not get values\")\n\t})\n\tt.Run(\"no-sandbox-unix\", func(t *testing.T) {\n\t\tif osutils.IsWindows() {\n\t\t\treturn\n\t\t}\n\t\t_, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": \"/etc/passwd\",\n\t\t}, \"/random\", \"/test\", false)\n\t\trequire.NoError(t, err, \"could load payloads\")\n\t})\n\tt.Run(\"invalid\", func(t *testing.T) {\n\t\tvalues, err := generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": \"/etc/passwd\",\n\t\t}, \"/random\", \"/test\", true)\n\t\trequire.Error(t, err, \"could load payloads\")\n\t\trequire.Equal(t, 0, len(values), \"could get values\")\n\n\t\tvalues, err = generator.loadPayloads(map[string]interface{}{\n\t\t\t\"new\": fullpath,\n\t\t}, \"/random\", \"/test\", true)\n\t\trequire.Error(t, err, \"could load payloads\")\n\t\trequire.Equal(t, 0, len(values), \"could get values\")\n\t})\n}", "is_vulnerable": 1}
{"code": "func (EmptyEvidencePool) AddEvidence(types.Evidence) error                { return nil }", "is_vulnerable": 0}
{"code": "func (r *reconciler) ensureLoadBalancerService(ci *operatorv1.IngressController, deploymentRef metav1.OwnerReference, infraConfig *configv1.Infrastructure) (bool, *corev1.Service, error) {\n\tplatform, err := oputil.GetPlatformStatus(r.client, infraConfig)\n\tif err != nil {\n\t\treturn false, nil, fmt.Errorf(\"failed to determine infrastructure platform status for ingresscontroller %s/%s: %v\", ci.Namespace, ci.Name, err)\n\t}\n\tproxyNeeded, err := IsProxyProtocolNeeded(ci, platform)\n\tif err != nil {\n\t\treturn false, nil, fmt.Errorf(\"failed to determine if proxy protocol is proxyNeeded for ingresscontroller %q: %v\", ci.Name, err)\n\t}\n\twantLBS, desiredLBService, err := desiredLoadBalancerService(ci, deploymentRef, platform, proxyNeeded)\n\tif err != nil {\n\t\treturn false, nil, err\n\t}\n\n\thaveLBS, currentLBService, err := r.currentLoadBalancerService(ci)\n\tif err != nil {\n\t\treturn false, nil, err\n\t}\n\n\tswitch {\n\tcase !wantLBS && !haveLBS:\n\t\treturn false, nil, nil\n\tcase !wantLBS && haveLBS:\n\t\tif deletedFinalizer, err := r.deleteLoadBalancerServiceFinalizer(currentLBService); err != nil {\n\t\t\treturn true, currentLBService, fmt.Errorf(\"failed to remove finalizer from load balancer service: %v\", err)\n\t\t} else if deletedFinalizer {\n\t\t\thaveLBS, currentLBService, err = r.currentLoadBalancerService(ci)\n\t\t\tif err != nil {\n\t\t\t\treturn haveLBS, currentLBService, err\n\t\t\t}\n\t\t}\n\t\tif err := r.deleteLoadBalancerService(currentLBService, &crclient.DeleteOptions{}); err != nil {\n\t\t\treturn true, currentLBService, err\n\t\t}\n\t\treturn false, nil, nil\n\tcase wantLBS && !haveLBS:\n\t\tif err := r.createLoadBalancerService(desiredLBService); err != nil {\n\t\t\treturn false, nil, err\n\t\t}\n\t\treturn r.currentLoadBalancerService(ci)\n\tcase wantLBS && haveLBS:\n\t\tif deletedFinalizer, err := r.deleteLoadBalancerServiceFinalizer(currentLBService); err != nil {\n\t\t\treturn true, currentLBService, fmt.Errorf(\"failed to remove finalizer from load balancer service: %v\", err)\n\t\t} else if deletedFinalizer {\n\t\t\thaveLBS, currentLBService, err = r.currentLoadBalancerService(ci)\n\t\t\tif err != nil {\n\t\t\t\treturn haveLBS, currentLBService, err\n\t\t\t}\n\t\t}\n\t\tif updated, err := r.updateLoadBalancerService(currentLBService, desiredLBService, platform); err != nil {\n\t\t\treturn true, currentLBService, fmt.Errorf(\"failed to update load balancer service: %v\", err)\n\t\t} else if updated {\n\t\t\tlog.Info(\"updated load balancer service\", \"namespace\", desiredLBService.Namespace, \"name\", desiredLBService.Name)\n\t\t\treturn r.currentLoadBalancerService(ci)\n\t\t}\n\t}\n\n\treturn true, currentLBService, nil\n}", "is_vulnerable": 0}
{"code": "func (a adminAPIHandlers) UpdateServiceAccount(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\n\t// Get current object layer instance.\n\tobjectAPI := newObjectLayerFn()\n\tif objectAPI == nil || globalNotificationSys == nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL)\n\t\treturn\n\t}\n\n\tcred, owner, s3Err := validateAdminSignature(ctx, r, \"\")\n\tif s3Err != ErrNone {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(s3Err), r.URL)\n\t\treturn\n\t}\n\n\taccessKey := mux.Vars(r)[\"accessKey\"]\n\tif accessKey == \"\" {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrInvalidRequest), r.URL)\n\t\treturn\n\t}\n\n\tsvcAccount, _, err := globalIAMSys.GetServiceAccount(ctx, accessKey)\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\treturn\n\t}\n\n\tif !globalIAMSys.IsAllowed(policy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tGroups:          cred.Groups,\n\t\tAction:          policy.UpdateServiceAccountAdminAction,\n\t\tConditionValues: getConditionValues(r, \"\", cred),\n\t\tIsOwner:         owner,\n\t\tClaims:          cred.Claims,\n\t}) {\n\t\trequestUser := cred.AccessKey\n\t\tif cred.ParentUser != \"\" {\n\t\t\trequestUser = cred.ParentUser\n\t\t}\n\n\t\tif requestUser != svcAccount.ParentUser {\n\t\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrAccessDenied), r.URL)\n\t\t\treturn\n\t\t}\n\t}\n\n\tpassword := cred.SecretKey\n\treqBytes, err := madmin.DecryptData(password, io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErrWithErr(ErrAdminConfigBadJSON, err), r.URL)\n\t\treturn\n\t}\n\n\tvar updateReq madmin.UpdateServiceAccountReq\n\tif err = json.Unmarshal(reqBytes, &updateReq); err != nil {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErrWithErr(ErrAdminConfigBadJSON, err), r.URL)\n\t\treturn\n\t}\n\n\tif err := updateReq.Validate(); err != nil {\n\t\t// Since this validation would happen client side as well, we only send\n\t\t// a generic error message here.\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrAdminResourceInvalidArgument), r.URL)\n\t\treturn\n\t}\n\n\tvar sp *policy.Policy\n\tif len(updateReq.NewPolicy) > 0 {\n\t\tsp, err = policy.ParseConfig(bytes.NewReader(updateReq.NewPolicy))\n\t\tif err != nil {\n\t\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\t\treturn\n\t\t}\n\t\tif sp.Version == \"\" && len(sp.Statements) == 0 {\n\t\t\tsp = nil\n\t\t}\n\t}\n\topts := updateServiceAccountOpts{\n\t\tsecretKey:     updateReq.NewSecretKey,\n\t\tstatus:        updateReq.NewStatus,\n\t\tname:          updateReq.NewName,\n\t\tdescription:   updateReq.NewDescription,\n\t\texpiration:    updateReq.NewExpiration,\n\t\tsessionPolicy: sp,\n\t}\n\tupdatedAt, err := globalIAMSys.UpdateServiceAccount(ctx, accessKey, opts)\n\tif err != nil {\n\t\twriteErrorResponseJSON(ctx, w, toAdminAPIErr(ctx, err), r.URL)\n\t\treturn\n\t}\n\n\t// Call site replication hook - non-root user accounts are replicated.\n\tif svcAccount.ParentUser != globalActiveCred.AccessKey {\n\t\tlogger.LogIf(ctx, globalSiteReplicationSys.IAMChangeHook(ctx, madmin.SRIAMItem{\n\t\t\tType: madmin.SRIAMItemSvcAcc,\n\t\t\tSvcAccChange: &madmin.SRSvcAccChange{\n\t\t\t\tUpdate: &madmin.SRSvcAccUpdate{\n\t\t\t\t\tAccessKey:     accessKey,\n\t\t\t\t\tSecretKey:     opts.secretKey,\n\t\t\t\t\tStatus:        opts.status,\n\t\t\t\t\tName:          opts.name,\n\t\t\t\t\tDescription:   opts.description,\n\t\t\t\t\tSessionPolicy: updateReq.NewPolicy,\n\t\t\t\t\tExpiration:    updateReq.NewExpiration,\n\t\t\t\t},\n\t\t\t},\n\t\t\tUpdatedAt: updatedAt,\n\t\t}))\n\t}\n\n\twriteSuccessNoContent(w)\n}", "is_vulnerable": 1}
{"code": "func (s *TestServer) handleStartup(client *pgproto3.Backend) error {\n\tstartupMessageI, err := client.ReceiveStartupMessage()\n\tif err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tstartupMessage, ok := startupMessageI.(*pgproto3.StartupMessage)\n\tif !ok {\n\t\treturn trace.BadParameter(\"expected *pgproto3.StartupMessage, got: %#v\", startupMessage)\n\t}\n\ts.log.Debugf(\"Received %#v.\", startupMessage)\n\t// Push connect parameters into the channel so tests can consume them.\n\ts.parametersCh <- startupMessage.Parameters\n\t// If auth token is specified, used it for password authentication, this\n\t// simulates cloud provider IAM auth.\n\tif s.cfg.AuthToken != \"\" {\n\t\tif err := s.handlePasswordAuth(client); err != nil {\n\t\t\tif trace.IsAccessDenied(err) {\n\t\t\t\tif err := client.Send(&pgproto3.ErrorResponse{Code: pgerrcode.InvalidPassword, Message: err.Error()}); err != nil {\n\t\t\t\t\treturn trace.Wrap(err)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn trace.Wrap(err)\n\t\t}\n\t}\n\t// Accept auth and send ready for query.\n\tif err := client.Send(&pgproto3.AuthenticationOk{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\tif err := client.Send(&pgproto3.ReadyForQuery{}); err != nil {\n\t\treturn trace.Wrap(err)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (e Extractor) Extract(ing *networking.Ingress) (*Ingress, error) {\n\tpia := &Ingress{\n\t\tObjectMeta: ing.ObjectMeta,\n\t}\n\n\tdata := make(map[string]interface{})\n\tfor name, annotationParser := range e.annotations {\n\t\tif err := annotationParser.Validate(ing.GetAnnotations()); err != nil {\n\t\t\treturn nil, errors.NewRiskyAnnotations(name)\n\t\t}\n\t\tval, err := annotationParser.Parse(ing)\n\t\tklog.V(5).InfoS(\"Parsing Ingress annotation\", \"name\", name, \"ingress\", klog.KObj(ing), \"value\", val)\n\t\tif err != nil {\n\t\t\tif errors.IsValidationError(err) {\n\t\t\t\tklog.ErrorS(err, \"ingress contains invalid annotation value\")\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif errors.IsMissingAnnotations(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif !errors.IsLocationDenied(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif name == \"CertificateAuth\" && data[name] == nil {\n\t\t\t\tdata[name] = authtls.Config{\n\t\t\t\t\tAuthTLSError: err.Error(),\n\t\t\t\t}\n\t\t\t\t// avoid mapping the result from the annotation\n\t\t\t\tval = nil\n\t\t\t}\n\n\t\t\t_, alreadyDenied := data[DeniedKeyName]\n\t\t\tif !alreadyDenied {\n\t\t\t\terrString := err.Error()\n\t\t\t\tdata[DeniedKeyName] = &errString\n\t\t\t\tklog.ErrorS(err, \"error reading Ingress annotation\", \"name\", name, \"ingress\", klog.KObj(ing))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tklog.V(5).ErrorS(err, \"error reading Ingress annotation\", \"name\", name, \"ingress\", klog.KObj(ing))\n\t\t}\n\n\t\tif val != nil {\n\t\t\tdata[name] = val\n\t\t}\n\t}\n\n\terr := mergo.MapWithOverwrite(pia, data)\n\tif err != nil {\n\t\tklog.ErrorS(err, \"unexpected error merging extracted annotations\")\n\t}\n\n\treturn pia, nil\n}", "is_vulnerable": 0}
{"code": "func TestInitialAllocationMapCompactProtocol(t *testing.T) {\n\tvar m MyTestStruct\n\td := NewDeserializer()\n\tf := NewCompactProtocolFactory()\n\td.Protocol = f.GetProtocol(d.Transport)\n\t// attempts to allocate a map of 930M elements for a 9 byte message\n\tdata := []byte(\"%0\\x88\\x8a\\x97\\xb7\\xc4\\x030\")\n\terr := d.Read(&m, data)\n\tif err == nil {\n\t\tt.Fatalf(\"Parsed invalid message correctly\")\n\t} else if !strings.Contains(err.Error(), \"Invalid data length\") {\n\t\tt.Fatalf(\"Failed for reason besides Invalid data length\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Compiler) Compile(conf *yaml_types.Workflow) (*backend_types.Config, error) {\n\tconfig := new(backend_types.Config)\n\n\tif match, err := conf.When.Match(c.metadata, true, c.env); !match && err == nil {\n\t\t// This pipeline does not match the configured filter so return an empty config and stop further compilation.\n\t\t// An empty pipeline will just be skipped completely.\n\t\treturn config, nil\n\t} else if err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create a default volume\n\tconfig.Volumes = append(config.Volumes, &backend_types.Volume{\n\t\tName: fmt.Sprintf(\"%s_default\", c.prefix),\n\t})\n\n\t// create a default network\n\tconfig.Networks = append(config.Networks, &backend_types.Network{\n\t\tName: fmt.Sprintf(\"%s_default\", c.prefix),\n\t})\n\n\t// create secrets for mask\n\tfor _, sec := range c.secrets {\n\t\tconfig.Secrets = append(config.Secrets, &backend_types.Secret{\n\t\t\tName:  sec.Name,\n\t\t\tValue: sec.Value,\n\t\t})\n\t}\n\n\t// overrides the default workspace paths when specified\n\t// in the YAML file.\n\tif len(conf.Workspace.Base) != 0 {\n\t\tc.workspaceBase = path.Clean(conf.Workspace.Base)\n\t}\n\tif len(conf.Workspace.Path) != 0 {\n\t\tc.workspacePath = path.Clean(conf.Workspace.Path)\n\t}\n\n\tcloneImage := constant.DefaultCloneImage\n\tif len(c.defaultCloneImage) > 0 {\n\t\tcloneImage = c.defaultCloneImage\n\t}\n\n\t// add default clone step\n\tif !c.local && len(conf.Clone.ContainerList) == 0 && !conf.SkipClone {\n\t\tcloneSettings := map[string]any{\"depth\": \"0\"}\n\t\tif c.metadata.Curr.Event == metadata.EventTag {\n\t\t\tcloneSettings[\"tags\"] = \"true\"\n\t\t}\n\t\tcontainer := &yaml_types.Container{\n\t\t\tName:        defaultCloneName,\n\t\t\tImage:       cloneImage,\n\t\t\tSettings:    cloneSettings,\n\t\t\tEnvironment: make(map[string]any),\n\t\t}\n\t\tfor k, v := range c.cloneEnv {\n\t\t\tcontainer.Environment[k] = v\n\t\t}\n\t\tstep, err := c.createProcess(container, backend_types.StepTypeClone)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstage := new(backend_types.Stage)\n\t\tstage.Steps = append(stage.Steps, step)\n\n\t\tconfig.Stages = append(config.Stages, stage)\n\t} else if !c.local && !conf.SkipClone {\n\t\tfor _, container := range conf.Clone.ContainerList {\n\t\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstage := new(backend_types.Stage)\n\n\t\t\tstep, err := c.createProcess(container, backend_types.StepTypeClone)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// only inject netrc if it's a trusted repo or a trusted plugin\n\t\t\tif !c.netrcOnlyTrusted || c.trustedPipeline || (container.IsPlugin() && container.IsTrustedCloneImage()) {\n\t\t\t\tfor k, v := range c.cloneEnv {\n\t\t\t\t\tstep.Environment[k] = v\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tstage.Steps = append(stage.Steps, step)\n\n\t\t\tconfig.Stages = append(config.Stages, stage)\n\t\t}\n\t}\n\n\t// add services steps\n\tif len(conf.Services.ContainerList) != 0 {\n\t\tstage := new(backend_types.Stage)\n\n\t\tfor _, container := range conf.Services.ContainerList {\n\t\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstep, err := c.createProcess(container, backend_types.StepTypeService)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tstage.Steps = append(stage.Steps, step)\n\t\t}\n\t\tconfig.Stages = append(config.Stages, stage)\n\t}\n\n\t// add pipeline steps\n\tsteps := make([]*dagCompilerStep, 0, len(conf.Steps.ContainerList))\n\tfor pos, container := range conf.Steps.ContainerList {\n\t\t// Skip if local and should not run local\n\t\tif c.local && !container.When.IsLocal() {\n\t\t\tcontinue\n\t\t}\n\n\t\tif match, err := container.When.Match(c.metadata, false, c.env); !match && err == nil {\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tstepType := backend_types.StepTypeCommands\n\t\tif container.IsPlugin() {\n\t\t\tstepType = backend_types.StepTypePlugin\n\t\t}\n\t\tstep, err := c.createProcess(container, stepType)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// inject netrc if it's a trusted repo or a trusted clone-plugin\n\t\tif c.trustedPipeline || (container.IsPlugin() && container.IsTrustedCloneImage()) {\n\t\t\tfor k, v := range c.cloneEnv {\n\t\t\t\tstep.Environment[k] = v\n\t\t\t}\n\t\t}\n\n\t\tsteps = append(steps, &dagCompilerStep{\n\t\t\tstep:      step,\n\t\t\tposition:  pos,\n\t\t\tname:      container.Name,\n\t\t\tgroup:     container.Group,\n\t\t\tdependsOn: container.DependsOn,\n\t\t})\n\t}\n\n\t// generate stages out of steps\n\tstepStages, err := newDAGCompiler(steps).compile()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tconfig.Stages = append(config.Stages, stepStages...)\n\n\treturn config, nil\n}", "is_vulnerable": 0}
{"code": "func (p *printer) printExpr(expr js_ast.Expr, level js_ast.L, flags printExprFlags) {\n\t// If syntax compression is enabled, do a pre-pass over unary and binary\n\t// operators to inline bitwise operations of cross-module inlined constants.\n\t// This makes the output a little tighter if people construct bit masks in\n\t// other files. This is not a general-purpose constant folding pass. In\n\t// particular, it has no effect on tree shaking because that pass has already\n\t// been run.\n\t//\n\t// This sets a flag to avoid doing this when the parent is a unary or binary\n\t// operator so that we don't trigger O(n^2) behavior when traversing over a\n\t// large expression tree.\n\tif p.options.MinifySyntax && (flags&parentWasUnaryOrBinary) == 0 {\n\t\tswitch expr.Data.(type) {\n\t\tcase *js_ast.EUnary, *js_ast.EBinary:\n\t\t\texpr = p.lateConstantFoldUnaryOrBinaryExpr(expr)\n\t\t}\n\t}\n\n\tp.printExprCommentsAtLoc(expr.Loc)\n\n\tswitch e := expr.Data.(type) {\n\tcase *js_ast.EMissing:\n\t\tp.addSourceMapping(expr.Loc)\n\n\tcase *js_ast.EUndefined:\n\t\tp.printUndefined(expr.Loc, level)\n\n\tcase *js_ast.ESuper:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"super\")\n\n\tcase *js_ast.ENull:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"null\")\n\n\tcase *js_ast.EThis:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"this\")\n\n\tcase *js_ast.ESpread:\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"...\")\n\t\tp.printExpr(e.Value, js_ast.LComma, 0)\n\n\tcase *js_ast.ENewTarget:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"new.target\")\n\n\tcase *js_ast.EImportMeta:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"import.meta\")\n\n\tcase *js_ast.EMangledProp:\n\t\tname := p.mangledPropName(e.Ref)\n\t\tp.addSourceMappingForName(expr.Loc, name, e.Ref)\n\t\tp.printQuotedUTF8(name, true)\n\n\tcase *js_ast.EJSXElement:\n\t\t// Start the opening tag\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"<\")\n\t\tp.printJSXTag(e.TagOrNil)\n\t\tif !e.IsTagSingleLine {\n\t\t\tp.options.Indent++\n\t\t}\n\n\t\t// Print the attributes\n\t\tfor _, property := range e.Properties {\n\t\t\tif e.IsTagSingleLine {\n\t\t\t\tp.printSpace()\n\t\t\t} else {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printIndent()\n\t\t\t}\n\n\t\t\tif property.Kind == js_ast.PropertySpread {\n\t\t\t\tif p.willPrintExprCommentsAtLoc(property.Loc) {\n\t\t\t\t\tp.print(\"{\")\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.options.Indent++\n\t\t\t\t\tp.printIndent()\n\t\t\t\t\tp.printExprCommentsAtLoc(property.Loc)\n\t\t\t\t\tp.print(\"...\")\n\t\t\t\t\tp.printExpr(property.ValueOrNil, js_ast.LComma, 0)\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.options.Indent--\n\t\t\t\t\tp.printIndent()\n\t\t\t\t\tp.print(\"}\")\n\t\t\t\t} else {\n\t\t\t\t\tp.print(\"{...\")\n\t\t\t\t\tp.printExpr(property.ValueOrNil, js_ast.LComma, 0)\n\t\t\t\t\tp.print(\"}\")\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tif mangled, ok := property.Key.Data.(*js_ast.EMangledProp); ok {\n\t\t\t\tname := p.mangledPropName(mangled.Ref)\n\t\t\t\tp.addSourceMappingForName(property.Key.Loc, name, mangled.Ref)\n\t\t\t\tp.printIdentifier(name)\n\t\t\t} else if str, ok := property.Key.Data.(*js_ast.EString); ok {\n\t\t\t\tp.addSourceMapping(property.Key.Loc)\n\t\t\t\tp.print(helpers.UTF16ToString(str.Value))\n\t\t\t} else {\n\t\t\t\tp.print(\"{...{\")\n\t\t\t\tp.printSpace()\n\t\t\t\tp.print(\"[\")\n\t\t\t\tp.printExpr(property.Key, js_ast.LComma, 0)\n\t\t\t\tp.print(\"]:\")\n\t\t\t\tp.printSpace()\n\t\t\t\tp.printExpr(property.ValueOrNil, js_ast.LComma, 0)\n\t\t\t\tp.printSpace()\n\t\t\t\tp.print(\"}}\")\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tisMultiLine := p.willPrintExprCommentsAtLoc(property.ValueOrNil.Loc)\n\n\t\t\t// Don't use shorthand syntax if it would discard comments\n\t\t\tif !isMultiLine {\n\t\t\t\t// Special-case string values\n\t\t\t\tif str, ok := property.ValueOrNil.Data.(*js_ast.EString); ok {\n\t\t\t\t\tif quote, ok := p.canPrintTextAsJSXAttribute(str.Value); ok {\n\t\t\t\t\t\tp.print(\"=\")\n\t\t\t\t\t\tp.addSourceMapping(property.ValueOrNil.Loc)\n\t\t\t\t\t\tp.print(quote)\n\t\t\t\t\t\tp.print(helpers.UTF16ToString(str.Value))\n\t\t\t\t\t\tp.print(quote)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Implicit \"true\" value\n\t\t\t\tif boolean, ok := property.ValueOrNil.Data.(*js_ast.EBoolean); ok && boolean.Value && property.Flags.Has(js_ast.PropertyWasShorthand) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Generic JS value\n\t\t\tp.print(\"={\")\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.options.Indent++\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tp.printExpr(property.ValueOrNil, js_ast.LComma, 0)\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.options.Indent--\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tp.print(\"}\")\n\t\t}\n\n\t\t// End the opening tag\n\t\tif !e.IsTagSingleLine {\n\t\t\tp.options.Indent--\n\t\t\tif len(e.Properties) > 0 {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t}\n\t\tif e.TagOrNil.Data != nil && len(e.Children) == 0 {\n\t\t\tif e.IsTagSingleLine || len(e.Properties) == 0 {\n\t\t\t\tp.printSpace()\n\t\t\t}\n\t\t\tp.addSourceMapping(e.CloseLoc)\n\t\t\tp.print(\"/>\")\n\t\t\tbreak\n\t\t}\n\t\tp.print(\">\")\n\n\t\tisSingleLine := true\n\t\tif !p.options.MinifyWhitespace {\n\t\t\tisSingleLine = len(e.Children) < 2\n\t\t\tif len(e.Children) == 1 {\n\t\t\t\tif _, ok := e.Children[0].Data.(*js_ast.EJSXElement); !ok {\n\t\t\t\t\tisSingleLine = true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !isSingleLine {\n\t\t\tp.options.Indent++\n\t\t}\n\n\t\t// Print the children\n\t\tfor _, child := range e.Children {\n\t\t\tif !isSingleLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tif _, ok := child.Data.(*js_ast.EJSXElement); ok {\n\t\t\t\tp.printExpr(child, js_ast.LLowest, 0)\n\t\t\t} else if str, ok := child.Data.(*js_ast.EString); ok && isSingleLine && p.canPrintTextAsJSXChild(str.Value) {\n\t\t\t\tp.addSourceMapping(child.Loc)\n\t\t\t\tp.print(helpers.UTF16ToString(str.Value))\n\t\t\t} else {\n\t\t\t\tisMultiLine := p.willPrintExprCommentsAtLoc(child.Loc)\n\t\t\t\tp.print(\"{\")\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.options.Indent++\n\t\t\t\t\tp.printIndent()\n\t\t\t\t}\n\t\t\t\tp.printExpr(child, js_ast.LComma, 0)\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.options.Indent--\n\t\t\t\t\tp.printIndent()\n\t\t\t\t}\n\t\t\t\tp.print(\"}\")\n\t\t\t}\n\t\t}\n\n\t\t// Print the closing tag\n\t\tif !isSingleLine {\n\t\t\tp.options.Indent--\n\t\t\tp.printNewline()\n\t\t\tp.printIndent()\n\t\t}\n\t\tp.addSourceMapping(e.CloseLoc)\n\t\tp.print(\"</\")\n\t\tp.printJSXTag(e.TagOrNil)\n\t\tp.print(\">\")\n\n\tcase *js_ast.ENew:\n\t\twrap := level >= js_ast.LCall\n\n\t\thasPureComment := !p.options.MinifyWhitespace && e.CanBeUnwrappedIfUnused\n\t\tif hasPureComment && level >= js_ast.LPostfix {\n\t\t\twrap = true\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tif hasPureComment {\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\tp.print(\"/* @__PURE__ */ \")\n\t\t}\n\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"new\")\n\t\tp.printSpace()\n\t\tp.printExpr(e.Target, js_ast.LNew, forbidCall)\n\n\t\t// Omit the \"()\" when minifying, but only when safe to do so\n\t\tisMultiLine := !p.options.MinifyWhitespace && ((e.IsMultiLine && len(e.Args) > 0) ||\n\t\t\tp.willPrintExprCommentsForAnyOf(e.Args) ||\n\t\t\tp.willPrintExprCommentsAtLoc(e.CloseParenLoc))\n\t\tif !p.options.MinifyWhitespace || len(e.Args) > 0 || level >= js_ast.LPostfix || isMultiLine {\n\t\t\tneedsNewline := true\n\t\t\tp.print(\"(\")\n\t\t\tif isMultiLine {\n\t\t\t\tp.options.Indent++\n\t\t\t}\n\t\t\tfor i, arg := range e.Args {\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tif i != 0 {\n\t\t\t\t\t\tp.print(\",\")\n\t\t\t\t\t}\n\t\t\t\t\tif needsNewline {\n\t\t\t\t\t\tp.printNewline()\n\t\t\t\t\t}\n\t\t\t\t\tp.printIndent()\n\t\t\t\t} else if i != 0 {\n\t\t\t\t\tp.print(\",\")\n\t\t\t\t\tp.printSpace()\n\t\t\t\t}\n\t\t\t\tp.printExpr(arg, js_ast.LComma, 0)\n\t\t\t\tneedsNewline = true\n\t\t\t}\n\t\t\tif isMultiLine {\n\t\t\t\tif needsNewline || p.willPrintExprCommentsAtLoc(e.CloseParenLoc) {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t}\n\t\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseParenLoc)\n\t\t\t\tp.options.Indent--\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tif e.CloseParenLoc.Start > expr.Loc.Start {\n\t\t\t\tp.addSourceMapping(e.CloseParenLoc)\n\t\t\t}\n\t\t\tp.print(\")\")\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.ECall:\n\t\tif p.options.MinifySyntax {\n\t\t\tvar symbolFlags js_ast.SymbolFlags\n\t\t\tswitch target := e.Target.Data.(type) {\n\t\t\tcase *js_ast.EIdentifier:\n\t\t\t\tsymbolFlags = p.symbols.Get(target.Ref).Flags\n\t\t\tcase *js_ast.EImportIdentifier:\n\t\t\t\tref := js_ast.FollowSymbols(p.symbols, target.Ref)\n\t\t\t\tsymbolFlags = p.symbols.Get(ref).Flags\n\t\t\t}\n\n\t\t\t// Replace non-mutated empty functions with their arguments at print time\n\t\t\tif (symbolFlags & (js_ast.IsEmptyFunction | js_ast.CouldPotentiallyBeMutated)) == js_ast.IsEmptyFunction {\n\t\t\t\tvar replacement js_ast.Expr\n\t\t\t\tfor _, arg := range e.Args {\n\t\t\t\t\tif _, ok := arg.Data.(*js_ast.ESpread); ok {\n\t\t\t\t\t\targ.Data = &js_ast.EArray{Items: []js_ast.Expr{arg}, IsSingleLine: true}\n\t\t\t\t\t}\n\t\t\t\t\treplacement = js_ast.JoinWithComma(replacement, js_ast.SimplifyUnusedExpr(arg, p.options.UnsupportedFeatures, p.isUnbound))\n\t\t\t\t}\n\t\t\t\tif replacement.Data == nil || (flags&exprResultIsUnused) == 0 {\n\t\t\t\t\treplacement = js_ast.JoinWithComma(replacement, js_ast.Expr{Loc: expr.Loc, Data: js_ast.EUndefinedShared})\n\t\t\t\t}\n\t\t\t\tp.printExpr(p.guardAgainstBehaviorChangeDueToSubstitution(replacement, flags), level, flags)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Inline non-mutated identity functions at print time\n\t\t\tif (symbolFlags&(js_ast.IsIdentityFunction|js_ast.CouldPotentiallyBeMutated)) == js_ast.IsIdentityFunction && len(e.Args) == 1 {\n\t\t\t\targ := e.Args[0]\n\t\t\t\tif _, ok := arg.Data.(*js_ast.ESpread); !ok {\n\t\t\t\t\tif (flags & exprResultIsUnused) != 0 {\n\t\t\t\t\t\targ = js_ast.SimplifyUnusedExpr(arg, p.options.UnsupportedFeatures, p.isUnbound)\n\t\t\t\t\t}\n\t\t\t\t\tp.printExpr(p.guardAgainstBehaviorChangeDueToSubstitution(arg, flags), level, flags)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n\t\tvar targetFlags printExprFlags\n\t\tif e.OptionalChain == js_ast.OptionalChainNone {\n\t\t\ttargetFlags = hasNonOptionalChainParent\n\t\t} else if (flags & hasNonOptionalChainParent) != 0 {\n\t\t\twrap = true\n\t\t}\n\n\t\thasPureComment := !p.options.MinifyWhitespace && e.CanBeUnwrappedIfUnused\n\t\tif hasPureComment && level >= js_ast.LPostfix {\n\t\t\twrap = true\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tif hasPureComment {\n\t\t\tflags := p.saveExprStartFlags()\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\tp.print(\"/* @__PURE__ */ \")\n\t\t\tp.restoreExprStartFlags(flags)\n\t\t}\n\n\t\t// We don't ever want to accidentally generate a direct eval expression here\n\t\tp.callTarget = e.Target.Data\n\t\tif (e.Kind != js_ast.DirectEval && p.isUnboundEvalIdentifier(e.Target) && e.OptionalChain == js_ast.OptionalChainNone) ||\n\t\t\t(e.Kind != js_ast.TargetWasOriginallyPropertyAccess && js_ast.IsPropertyAccess(e.Target)) {\n\t\t\tp.print(\"(0,\")\n\t\t\tp.printSpace()\n\t\t\tp.printExpr(e.Target, js_ast.LPostfix, isCallTargetOrTemplateTag)\n\t\t\tp.print(\")\")\n\t\t} else {\n\t\t\tp.printExpr(e.Target, js_ast.LPostfix, isCallTargetOrTemplateTag|targetFlags)\n\t\t}\n\n\t\tif e.OptionalChain == js_ast.OptionalChainStart {\n\t\t\tp.print(\"?.\")\n\t\t}\n\n\t\tisMultiLine := !p.options.MinifyWhitespace && ((e.IsMultiLine && len(e.Args) > 0) ||\n\t\t\tp.willPrintExprCommentsForAnyOf(e.Args) ||\n\t\t\tp.willPrintExprCommentsAtLoc(e.CloseParenLoc))\n\t\tp.print(\"(\")\n\t\tif isMultiLine {\n\t\t\tp.options.Indent++\n\t\t}\n\t\tfor i, arg := range e.Args {\n\t\t\tif isMultiLine {\n\t\t\t\tif i != 0 {\n\t\t\t\t\tp.print(\",\")\n\t\t\t\t}\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printIndent()\n\t\t\t} else if i != 0 {\n\t\t\t\tp.print(\",\")\n\t\t\t\tp.printSpace()\n\t\t\t}\n\t\t\tp.printExpr(arg, js_ast.LComma, 0)\n\t\t}\n\t\tif isMultiLine {\n\t\t\tp.printNewline()\n\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseParenLoc)\n\t\t\tp.options.Indent--\n\t\t\tp.printIndent()\n\t\t}\n\t\tif e.CloseParenLoc.Start > expr.Loc.Start {\n\t\t\tp.addSourceMapping(e.CloseParenLoc)\n\t\t}\n\t\tp.print(\")\")\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.ERequireString:\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.printRequireOrImportExpr(e.ImportRecordIndex, level, flags, e.CloseParenLoc)\n\n\tcase *js_ast.ERequireResolveString:\n\t\trecordLoc := p.importRecords[e.ImportRecordIndex].Range.Loc\n\t\tisMultiLine := p.willPrintExprCommentsAtLoc(recordLoc) || p.willPrintExprCommentsAtLoc(e.CloseParenLoc)\n\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"require.resolve(\")\n\t\tif isMultiLine {\n\t\t\tp.printNewline()\n\t\t\tp.options.Indent++\n\t\t\tp.printIndent()\n\t\t\tp.printExprCommentsAtLoc(recordLoc)\n\t\t}\n\t\tp.printPath(e.ImportRecordIndex, ast.ImportRequireResolve)\n\t\tif isMultiLine {\n\t\t\tp.printNewline()\n\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseParenLoc)\n\t\t\tp.options.Indent--\n\t\t\tp.printIndent()\n\t\t}\n\t\tif e.CloseParenLoc.Start > expr.Loc.Start {\n\t\t\tp.addSourceMapping(e.CloseParenLoc)\n\t\t}\n\t\tp.print(\")\")\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EImportString:\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.printRequireOrImportExpr(e.ImportRecordIndex, level, flags, e.CloseParenLoc)\n\n\tcase *js_ast.EImportCall:\n\t\t// Just omit import assertions if they aren't supported\n\t\tprintImportAssertions := e.OptionsOrNil.Data != nil && !p.options.UnsupportedFeatures.Has(compat.ImportAssertions)\n\t\tisMultiLine := !p.options.MinifyWhitespace &&\n\t\t\t(p.willPrintExprCommentsAtLoc(e.Expr.Loc) ||\n\t\t\t\t(printImportAssertions && p.willPrintExprCommentsAtLoc(e.OptionsOrNil.Loc)) ||\n\t\t\t\tp.willPrintExprCommentsAtLoc(e.CloseParenLoc))\n\t\twrap := level >= js_ast.LNew || (flags&forbidCall) != 0\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"import(\")\n\t\tif isMultiLine {\n\t\t\tp.printNewline()\n\t\t\tp.options.Indent++\n\t\t\tp.printIndent()\n\t\t}\n\t\tp.printExpr(e.Expr, js_ast.LComma, 0)\n\n\t\tif printImportAssertions {\n\t\t\tp.print(\",\")\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printIndent()\n\t\t\t} else {\n\t\t\t\tp.printSpace()\n\t\t\t}\n\t\t\tp.printExpr(e.OptionsOrNil, js_ast.LComma, 0)\n\t\t}\n\n\t\tif isMultiLine {\n\t\t\tp.printNewline()\n\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseParenLoc)\n\t\t\tp.options.Indent--\n\t\t\tp.printIndent()\n\t\t}\n\t\tp.print(\")\")\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EDot:\n\t\twrap := false\n\t\tif e.OptionalChain == js_ast.OptionalChainNone {\n\t\t\tflags |= hasNonOptionalChainParent\n\n\t\t\t// Inline cross-module TypeScript enum references here\n\t\t\tif id, ok := e.Target.Data.(*js_ast.EImportIdentifier); ok {\n\t\t\t\tref := js_ast.FollowSymbols(p.symbols, id.Ref)\n\t\t\t\tif symbol := p.symbols.Get(ref); symbol.Kind == js_ast.SymbolTSEnum {\n\t\t\t\t\tif enum, ok := p.options.TSEnums[ref]; ok {\n\t\t\t\t\t\tif value, ok := enum[e.Name]; ok {\n\t\t\t\t\t\t\tif value.String != nil {\n\t\t\t\t\t\t\t\tp.printQuotedUTF16(value.String, true /* allowBacktick */)\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tp.printNumber(value.Number, level)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif !p.options.MinifyWhitespace && !p.options.MinifyIdentifiers && !strings.Contains(e.Name, \"*/\") {\n\t\t\t\t\t\t\t\tp.print(\" /* \")\n\t\t\t\t\t\t\t\tp.print(e.Name)\n\t\t\t\t\t\t\t\tp.print(\" */\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (flags & hasNonOptionalChainParent) != 0 {\n\t\t\t\twrap = true\n\t\t\t\tp.print(\"(\")\n\t\t\t}\n\t\t\tflags &= ^hasNonOptionalChainParent\n\t\t}\n\t\tp.printExpr(e.Target, js_ast.LPostfix, flags&(forbidCall|hasNonOptionalChainParent))\n\t\tif p.canPrintIdentifier(e.Name) {\n\t\t\tif e.OptionalChain != js_ast.OptionalChainStart && p.prevNumEnd == len(p.js) {\n\t\t\t\t// \"1.toString\" is a syntax error, so print \"1 .toString\" instead\n\t\t\t\tp.print(\" \")\n\t\t\t}\n\t\t\tif e.OptionalChain == js_ast.OptionalChainStart {\n\t\t\t\tp.print(\"?.\")\n\t\t\t} else {\n\t\t\t\tp.print(\".\")\n\t\t\t}\n\t\t\tp.addSourceMapping(e.NameLoc)\n\t\t\tp.printIdentifier(e.Name)\n\t\t} else {\n\t\t\tif e.OptionalChain == js_ast.OptionalChainStart {\n\t\t\t\tp.print(\"?.\")\n\t\t\t}\n\t\t\tp.print(\"[\")\n\t\t\tp.addSourceMapping(e.NameLoc)\n\t\t\tp.printQuotedUTF8(e.Name, true /* allowBacktick */)\n\t\t\tp.print(\"]\")\n\t\t}\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EIndex:\n\t\twrap := false\n\t\tif e.OptionalChain == js_ast.OptionalChainNone {\n\t\t\tflags |= hasNonOptionalChainParent\n\n\t\t\t// Inline cross-module TypeScript enum references here\n\t\t\tif index, ok := e.Index.Data.(*js_ast.EString); ok {\n\t\t\t\tif id, ok := e.Target.Data.(*js_ast.EImportIdentifier); ok {\n\t\t\t\t\tref := js_ast.FollowSymbols(p.symbols, id.Ref)\n\t\t\t\t\tif symbol := p.symbols.Get(ref); symbol.Kind == js_ast.SymbolTSEnum {\n\t\t\t\t\t\tif enum, ok := p.options.TSEnums[ref]; ok {\n\t\t\t\t\t\t\tname := helpers.UTF16ToString(index.Value)\n\t\t\t\t\t\t\tif value, ok := enum[name]; ok {\n\t\t\t\t\t\t\t\tif value.String != nil {\n\t\t\t\t\t\t\t\t\tp.printQuotedUTF16(value.String, true /* allowBacktick */)\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tp.printNumber(value.Number, level)\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif !p.options.MinifyWhitespace && !p.options.MinifyIdentifiers && !strings.Contains(name, \"*/\") {\n\t\t\t\t\t\t\t\t\tp.print(\" /* \")\n\t\t\t\t\t\t\t\t\tp.print(name)\n\t\t\t\t\t\t\t\t\tp.print(\" */\")\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (flags & hasNonOptionalChainParent) != 0 {\n\t\t\t\twrap = true\n\t\t\t\tp.print(\"(\")\n\t\t\t}\n\t\t\tflags &= ^hasNonOptionalChainParent\n\t\t}\n\t\tp.printExpr(e.Target, js_ast.LPostfix, flags&(forbidCall|hasNonOptionalChainParent))\n\t\tif e.OptionalChain == js_ast.OptionalChainStart {\n\t\t\tp.print(\"?.\")\n\t\t}\n\n\t\tswitch index := e.Index.Data.(type) {\n\t\tcase *js_ast.EPrivateIdentifier:\n\t\t\tif e.OptionalChain != js_ast.OptionalChainStart {\n\t\t\t\tp.print(\".\")\n\t\t\t}\n\t\t\tname := p.renamer.NameForSymbol(index.Ref)\n\t\t\tp.addSourceMappingForName(e.Index.Loc, name, index.Ref)\n\t\t\tp.printIdentifier(name)\n\n\t\tcase *js_ast.EMangledProp:\n\t\t\tif name := p.mangledPropName(index.Ref); p.canPrintIdentifier(name) {\n\t\t\t\tif e.OptionalChain != js_ast.OptionalChainStart {\n\t\t\t\t\tp.print(\".\")\n\t\t\t\t}\n\t\t\t\tp.addSourceMappingForName(e.Index.Loc, name, index.Ref)\n\t\t\t\tp.printIdentifier(name)\n\t\t\t} else {\n\t\t\t\tisMultiLine := p.willPrintExprCommentsAtLoc(e.Index.Loc) || p.willPrintExprCommentsAtLoc(e.CloseBracketLoc)\n\t\t\t\tp.print(\"[\")\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.options.Indent++\n\t\t\t\t\tp.printIndent()\n\t\t\t\t}\n\t\t\t\tp.printExprCommentsAtLoc(e.Index.Loc)\n\t\t\t\tp.addSourceMapping(e.Index.Loc)\n\t\t\t\tp.printQuotedUTF8(name, true /* allowBacktick */)\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseBracketLoc)\n\t\t\t\t\tp.options.Indent--\n\t\t\t\t\tp.printIndent()\n\t\t\t\t}\n\t\t\t\tif e.CloseBracketLoc.Start > expr.Loc.Start {\n\t\t\t\t\tp.addSourceMapping(e.CloseBracketLoc)\n\t\t\t\t}\n\t\t\t\tp.print(\"]\")\n\t\t\t}\n\n\t\tdefault:\n\t\t\tisMultiLine := p.willPrintExprCommentsAtLoc(e.Index.Loc) || p.willPrintExprCommentsAtLoc(e.CloseBracketLoc)\n\t\t\tp.print(\"[\")\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.options.Indent++\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tp.printExpr(e.Index, js_ast.LLowest, 0)\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseBracketLoc)\n\t\t\t\tp.options.Indent--\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t\tif e.CloseBracketLoc.Start > expr.Loc.Start {\n\t\t\t\tp.addSourceMapping(e.CloseBracketLoc)\n\t\t\t}\n\t\t\tp.print(\"]\")\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EIf:\n\t\twrap := level >= js_ast.LConditional\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t\tflags &= ^forbidIn\n\t\t}\n\t\tp.printExpr(e.Test, js_ast.LConditional, flags&forbidIn)\n\t\tp.printSpace()\n\t\tp.print(\"?\")\n\t\tp.printSpace()\n\t\tp.printExprWithoutLeadingNewline(e.Yes, js_ast.LYield, 0)\n\t\tp.printSpace()\n\t\tp.print(\":\")\n\t\tp.printSpace()\n\t\tp.printExprWithoutLeadingNewline(e.No, js_ast.LYield, flags&forbidIn)\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EArrow:\n\t\twrap := level >= js_ast.LAssign\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tif e.IsAsync {\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tp.print(\"async\")\n\t\t\tp.printSpace()\n\t\t}\n\n\t\tp.printFnArgs(e.Args, fnArgsOpts{\n\t\t\topenParenLoc:              expr.Loc,\n\t\t\taddMappingForOpenParenLoc: !e.IsAsync,\n\t\t\thasRestArg:                e.HasRestArg,\n\t\t\tisArrow:                   true,\n\t\t})\n\t\tp.printSpace()\n\t\tp.print(\"=>\")\n\t\tp.printSpace()\n\n\t\twasPrinted := false\n\t\tif len(e.Body.Block.Stmts) == 1 && e.PreferExpr {\n\t\t\tif s, ok := e.Body.Block.Stmts[0].Data.(*js_ast.SReturn); ok && s.ValueOrNil.Data != nil {\n\t\t\t\tp.arrowExprStart = len(p.js)\n\t\t\t\tp.printExprWithoutLeadingNewline(s.ValueOrNil, js_ast.LComma, flags&forbidIn)\n\t\t\t\twasPrinted = true\n\t\t\t}\n\t\t}\n\t\tif !wasPrinted {\n\t\t\tp.printBlock(e.Body.Loc, e.Body.Block)\n\t\t}\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EFunction:\n\t\tn := len(p.js)\n\t\twrap := p.stmtStart == n || p.exportDefaultStart == n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tif e.Fn.IsAsync {\n\t\t\tp.print(\"async \")\n\t\t}\n\t\tp.print(\"function\")\n\t\tif e.Fn.IsGenerator {\n\t\t\tp.print(\"*\")\n\t\t\tp.printSpace()\n\t\t}\n\t\tif e.Fn.Name != nil {\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tname := p.renamer.NameForSymbol(e.Fn.Name.Ref)\n\t\t\tp.addSourceMappingForName(e.Fn.Name.Loc, name, e.Fn.Name.Ref)\n\t\t\tp.printIdentifier(name)\n\t\t}\n\t\tp.printFn(e.Fn)\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EClass:\n\t\tn := len(p.js)\n\t\twrap := p.stmtStart == n || p.exportDefaultStart == n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"class\")\n\t\tif e.Class.Name != nil {\n\t\t\tp.print(\" \")\n\t\t\tname := p.renamer.NameForSymbol(e.Class.Name.Ref)\n\t\t\tp.addSourceMappingForName(e.Class.Name.Loc, name, e.Class.Name.Ref)\n\t\t\tp.printIdentifier(name)\n\t\t}\n\t\tp.printClass(e.Class)\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EArray:\n\t\tisMultiLine := (len(e.Items) > 0 && !e.IsSingleLine) || p.willPrintExprCommentsForAnyOf(e.Items) || p.willPrintExprCommentsAtLoc(e.CloseBracketLoc)\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"[\")\n\t\tif len(e.Items) > 0 || isMultiLine {\n\t\t\tif isMultiLine {\n\t\t\t\tp.options.Indent++\n\t\t\t}\n\n\t\t\tfor i, item := range e.Items {\n\t\t\t\tif i != 0 {\n\t\t\t\t\tp.print(\",\")\n\t\t\t\t\tif !isMultiLine {\n\t\t\t\t\t\tp.printSpace()\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.printIndent()\n\t\t\t\t}\n\t\t\t\tp.printExpr(item, js_ast.LComma, 0)\n\n\t\t\t\t// Make sure there's a comma after trailing missing items\n\t\t\t\t_, ok := item.Data.(*js_ast.EMissing)\n\t\t\t\tif ok && i == len(e.Items)-1 {\n\t\t\t\t\tp.print(\",\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseBracketLoc)\n\t\t\t\tp.options.Indent--\n\t\t\t\tp.printIndent()\n\t\t\t}\n\t\t}\n\t\tif e.CloseBracketLoc.Start > expr.Loc.Start {\n\t\t\tp.addSourceMapping(e.CloseBracketLoc)\n\t\t}\n\t\tp.print(\"]\")\n\n\tcase *js_ast.EObject:\n\t\tisMultiLine := (len(e.Properties) > 0 && !e.IsSingleLine) || p.willPrintExprCommentsAtLoc(e.CloseBraceLoc)\n\t\tif !p.options.MinifyWhitespace && !isMultiLine {\n\t\t\tfor _, property := range e.Properties {\n\t\t\t\tif p.willPrintExprCommentsAtLoc(property.Loc) {\n\t\t\t\t\tisMultiLine = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tn := len(p.js)\n\t\twrap := p.stmtStart == n || p.arrowExprStart == n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"{\")\n\t\tif len(e.Properties) > 0 || isMultiLine {\n\t\t\tif isMultiLine {\n\t\t\t\tp.options.Indent++\n\t\t\t}\n\n\t\t\tfor i, item := range e.Properties {\n\t\t\t\tif i != 0 {\n\t\t\t\t\tp.print(\",\")\n\t\t\t\t}\n\t\t\t\tif isMultiLine {\n\t\t\t\t\tp.printNewline()\n\t\t\t\t\tp.printIndent()\n\t\t\t\t} else {\n\t\t\t\t\tp.printSpace()\n\t\t\t\t}\n\t\t\t\tp.printProperty(item)\n\t\t\t}\n\n\t\t\tif isMultiLine {\n\t\t\t\tp.printNewline()\n\t\t\t\tp.printExprCommentsAfterCloseTokenAtLoc(e.CloseBraceLoc)\n\t\t\t\tp.options.Indent--\n\t\t\t\tp.printIndent()\n\t\t\t} else if len(e.Properties) > 0 {\n\t\t\t\tp.printSpace()\n\t\t\t}\n\t\t}\n\t\tif e.CloseBraceLoc.Start > expr.Loc.Start {\n\t\t\tp.addSourceMapping(e.CloseBraceLoc)\n\t\t}\n\t\tp.print(\"}\")\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EBoolean:\n\t\tp.addSourceMapping(expr.Loc)\n\t\tif p.options.MinifySyntax {\n\t\t\tif level >= js_ast.LPrefix {\n\t\t\t\tif e.Value {\n\t\t\t\t\tp.print(\"(!0)\")\n\t\t\t\t} else {\n\t\t\t\t\tp.print(\"(!1)\")\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif e.Value {\n\t\t\t\t\tp.print(\"!0\")\n\t\t\t\t} else {\n\t\t\t\t\tp.print(\"!1\")\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tif e.Value {\n\t\t\t\tp.print(\"true\")\n\t\t\t} else {\n\t\t\t\tp.print(\"false\")\n\t\t\t}\n\t\t}\n\n\tcase *js_ast.EString:\n\t\tp.addSourceMapping(expr.Loc)\n\n\t\t// If this was originally a template literal, print it as one as long as we're not minifying\n\t\tif e.PreferTemplate && !p.options.MinifySyntax && !p.options.UnsupportedFeatures.Has(compat.TemplateLiteral) {\n\t\t\tp.print(\"`\")\n\t\t\tp.printUnquotedUTF16(e.Value, '`')\n\t\t\tp.print(\"`\")\n\t\t\treturn\n\t\t}\n\n\t\tp.printQuotedUTF16(e.Value, true /* allowBacktick */)\n\n\tcase *js_ast.ETemplate:\n\t\t// Convert no-substitution template literals into strings if it's smaller\n\t\tif p.options.MinifySyntax && e.TagOrNil.Data == nil && len(e.Parts) == 0 {\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\tp.printQuotedUTF16(e.HeadCooked, true /* allowBacktick */)\n\t\t\treturn\n\t\t}\n\n\t\tif e.TagOrNil.Data != nil {\n\t\t\ttagIsPropertyAccess := false\n\t\t\tswitch e.TagOrNil.Data.(type) {\n\t\t\tcase *js_ast.EDot, *js_ast.EIndex:\n\t\t\t\ttagIsPropertyAccess = true\n\t\t\t}\n\t\t\tif !e.TagWasOriginallyPropertyAccess && tagIsPropertyAccess {\n\t\t\t\t// Prevent \"x``\" from becoming \"y.z``\"\n\t\t\t\tp.print(\"(0,\")\n\t\t\t\tp.printSpace()\n\t\t\t\tp.printExpr(e.TagOrNil, js_ast.LLowest, isCallTargetOrTemplateTag)\n\t\t\t\tp.print(\")\")\n\t\t\t} else if js_ast.IsOptionalChain(e.TagOrNil) {\n\t\t\t\t// Optional chains are forbidden in template tags\n\t\t\t\tp.print(\"(\")\n\t\t\t\tp.printExpr(e.TagOrNil, js_ast.LLowest, isCallTargetOrTemplateTag)\n\t\t\t\tp.print(\")\")\n\t\t\t} else {\n\t\t\t\tp.printExpr(e.TagOrNil, js_ast.LPostfix, isCallTargetOrTemplateTag)\n\t\t\t}\n\t\t} else {\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t}\n\t\tp.print(\"`\")\n\t\tif e.TagOrNil.Data != nil {\n\t\t\tp.print(e.HeadRaw)\n\t\t} else {\n\t\t\tp.printUnquotedUTF16(e.HeadCooked, '`')\n\t\t}\n\t\tfor _, part := range e.Parts {\n\t\t\tp.print(\"${\")\n\t\t\tp.printExpr(part.Value, js_ast.LLowest, 0)\n\t\t\tp.print(\"}\")\n\t\t\tif e.TagOrNil.Data != nil {\n\t\t\t\tp.print(part.TailRaw)\n\t\t\t} else {\n\t\t\t\tp.printUnquotedUTF16(part.TailCooked, '`')\n\t\t\t}\n\t\t}\n\t\tp.print(\"`\")\n\n\tcase *js_ast.ERegExp:\n\t\tbuffer := p.js\n\t\tn := len(buffer)\n\n\t\t// Avoid forming a single-line comment or \"</script\" sequence\n\t\tif !p.options.UnsupportedFeatures.Has(compat.InlineScript) && n > 0 {\n\t\t\tif last := buffer[n-1]; last == '/' || (last == '<' && len(e.Value) >= 7 && strings.EqualFold(e.Value[:7], \"/script\")) {\n\t\t\t\tp.print(\" \")\n\t\t\t}\n\t\t}\n\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(e.Value)\n\n\t\t// Need a space before the next identifier to avoid it turning into flags\n\t\tp.prevRegExpEnd = len(p.js)\n\n\tcase *js_ast.EInlinedEnum:\n\t\tp.printExpr(e.Value, level, flags)\n\n\t\tif !p.options.MinifyWhitespace && !p.options.MinifyIdentifiers {\n\t\t\tp.print(\" /* \")\n\t\t\tp.print(e.Comment)\n\t\t\tp.print(\" */\")\n\t\t}\n\n\tcase *js_ast.EBigInt:\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(e.Value)\n\t\tp.print(\"n\")\n\n\tcase *js_ast.ENumber:\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.printNumber(e.Value, level)\n\n\tcase *js_ast.EIdentifier:\n\t\tname := p.renamer.NameForSymbol(e.Ref)\n\t\twrap := len(p.js) == p.forOfInitStart && (name == \"let\" ||\n\t\t\t((flags&isFollowedByOf) != 0 && (flags&isInsideForAwait) == 0 && name == \"async\"))\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMappingForName(expr.Loc, name, e.Ref)\n\t\tp.printIdentifier(name)\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EImportIdentifier:\n\t\t// Potentially use a property access instead of an identifier\n\t\tref := js_ast.FollowSymbols(p.symbols, e.Ref)\n\t\tsymbol := p.symbols.Get(ref)\n\n\t\tif symbol.ImportItemStatus == js_ast.ImportItemMissing {\n\t\t\tp.printUndefined(expr.Loc, level)\n\t\t} else if symbol.NamespaceAlias != nil {\n\t\t\twrap := p.callTarget == e && e.WasOriginallyIdentifier\n\t\t\tif wrap {\n\t\t\t\tif p.options.MinifyWhitespace {\n\t\t\t\t\tp.print(\"(0,\")\n\t\t\t\t} else {\n\t\t\t\t\tp.print(\"(0, \")\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\tp.printIdentifier(p.renamer.NameForSymbol(symbol.NamespaceAlias.NamespaceRef))\n\t\t\talias := symbol.NamespaceAlias.Alias\n\t\t\tif !e.PreferQuotedKey && p.canPrintIdentifier(alias) {\n\t\t\t\tp.print(\".\")\n\t\t\t\tp.addSourceMappingForName(expr.Loc, alias, ref)\n\t\t\t\tp.printIdentifier(alias)\n\t\t\t} else {\n\t\t\t\tp.print(\"[\")\n\t\t\t\tp.addSourceMappingForName(expr.Loc, alias, ref)\n\t\t\t\tp.printQuotedUTF8(alias, true /* allowBacktick */)\n\t\t\t\tp.print(\"]\")\n\t\t\t}\n\t\t\tif wrap {\n\t\t\t\tp.print(\")\")\n\t\t\t}\n\t\t} else if value := p.options.ConstValues[ref]; value.Kind != js_ast.ConstValueNone {\n\t\t\t// Handle inlined constants\n\t\t\tp.printExpr(js_ast.ConstValueToExpr(expr.Loc, value), level, flags)\n\t\t} else {\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tname := p.renamer.NameForSymbol(ref)\n\t\t\tp.addSourceMappingForName(expr.Loc, name, ref)\n\t\t\tp.printIdentifier(name)\n\t\t}\n\n\tcase *js_ast.EAwait:\n\t\twrap := level >= js_ast.LPrefix\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"await\")\n\t\tp.printSpace()\n\t\tp.printExpr(e.Value, js_ast.LPrefix-1, 0)\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EYield:\n\t\twrap := level >= js_ast.LAssign\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tp.printSpaceBeforeIdentifier()\n\t\tp.addSourceMapping(expr.Loc)\n\t\tp.print(\"yield\")\n\n\t\tif e.ValueOrNil.Data != nil {\n\t\t\tif e.IsStar {\n\t\t\t\tp.print(\"*\")\n\t\t\t}\n\t\t\tp.printSpace()\n\t\t\tp.printExprWithoutLeadingNewline(e.ValueOrNil, js_ast.LYield, 0)\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EUnary:\n\t\tentry := js_ast.OpTable[e.Op]\n\t\twrap := level >= entry.Level\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t}\n\n\t\tif !e.Op.IsPrefix() {\n\t\t\tp.printExpr(e.Value, js_ast.LPostfix-1, parentWasUnaryOrBinary)\n\t\t}\n\n\t\tif entry.IsKeyword {\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tif e.Op.IsPrefix() {\n\t\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\t}\n\t\t\tp.print(entry.Text)\n\t\t\tp.printSpace()\n\t\t} else {\n\t\t\tp.printSpaceBeforeOperator(e.Op)\n\t\t\tif e.Op.IsPrefix() {\n\t\t\t\tp.addSourceMapping(expr.Loc)\n\t\t\t}\n\t\t\tp.print(entry.Text)\n\t\t\tp.prevOp = e.Op\n\t\t\tp.prevOpEnd = len(p.js)\n\t\t}\n\n\t\tif e.Op.IsPrefix() {\n\t\t\tvalueFlags := parentWasUnaryOrBinary\n\t\t\tif e.Op == js_ast.UnOpDelete {\n\t\t\t\tvalueFlags |= isDeleteTarget\n\t\t\t}\n\n\t\t\t// Never turn \"typeof (0, x)\" into \"typeof x\" or \"delete (0, x)\" into \"delete x\"\n\t\t\tif (e.Op == js_ast.UnOpTypeof && !e.WasOriginallyTypeofIdentifier && p.isUnboundIdentifier(e.Value)) ||\n\t\t\t\t(e.Op == js_ast.UnOpDelete && !e.WasOriginallyDeleteOfIdentifierOrPropertyAccess && p.isIdentifierOrNumericConstantOrPropertyAccess(e.Value)) {\n\t\t\t\tp.print(\"(0,\")\n\t\t\t\tp.printSpace()\n\t\t\t\tp.printExpr(e.Value, js_ast.LPrefix-1, valueFlags)\n\t\t\t\tp.print(\")\")\n\t\t\t} else {\n\t\t\t\tp.printExpr(e.Value, js_ast.LPrefix-1, valueFlags)\n\t\t\t}\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tcase *js_ast.EBinary:\n\t\t// If this is a comma operator then either the result is unused (and we\n\t\t// should have already simplified unused expressions), or the result is used\n\t\t// (and we can still simplify unused expressions inside the left operand)\n\t\tif e.Op == js_ast.BinOpComma {\n\t\t\tif (flags & didAlreadySimplifyUnusedExprs) == 0 {\n\t\t\t\tleft := p.simplifyUnusedExpr(e.Left)\n\t\t\t\tright := e.Right\n\t\t\t\tif (flags & exprResultIsUnused) != 0 {\n\t\t\t\t\tright = p.simplifyUnusedExpr(right)\n\t\t\t\t}\n\t\t\t\tif left.Data != e.Left.Data || right.Data != e.Right.Data {\n\t\t\t\t\t// Pass a flag so we don't needlessly re-simplify the same expression\n\t\t\t\t\tp.printExpr(p.guardAgainstBehaviorChangeDueToSubstitution(js_ast.JoinWithComma(left, right), flags), level, flags|didAlreadySimplifyUnusedExprs)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Pass a flag so we don't needlessly re-simplify the same expression\n\t\t\t\tflags |= didAlreadySimplifyUnusedExprs\n\t\t\t}\n\t\t}\n\n\t\tentry := js_ast.OpTable[e.Op]\n\t\twrap := level >= entry.Level || (e.Op == js_ast.BinOpIn && (flags&forbidIn) != 0)\n\n\t\t// Destructuring assignments must be parenthesized\n\t\tif n := len(p.js); p.stmtStart == n || p.arrowExprStart == n {\n\t\t\tif _, ok := e.Left.Data.(*js_ast.EObject); ok {\n\t\t\t\twrap = true\n\t\t\t}\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\"(\")\n\t\t\tflags &= ^forbidIn\n\t\t}\n\n\t\tleftLevel := entry.Level - 1\n\t\trightLevel := entry.Level - 1\n\n\t\tif e.Op.IsRightAssociative() {\n\t\t\tleftLevel = entry.Level\n\t\t}\n\t\tif e.Op.IsLeftAssociative() {\n\t\t\trightLevel = entry.Level\n\t\t}\n\n\t\tswitch e.Op {\n\t\tcase js_ast.BinOpNullishCoalescing:\n\t\t\t// \"??\" can't directly contain \"||\" or \"&&\" without being wrapped in parentheses\n\t\t\tif left, ok := e.Left.Data.(*js_ast.EBinary); ok && (left.Op == js_ast.BinOpLogicalOr || left.Op == js_ast.BinOpLogicalAnd) {\n\t\t\t\tleftLevel = js_ast.LPrefix\n\t\t\t}\n\t\t\tif right, ok := e.Right.Data.(*js_ast.EBinary); ok && (right.Op == js_ast.BinOpLogicalOr || right.Op == js_ast.BinOpLogicalAnd) {\n\t\t\t\trightLevel = js_ast.LPrefix\n\t\t\t}\n\n\t\tcase js_ast.BinOpPow:\n\t\t\t// \"**\" can't contain certain unary expressions\n\t\t\tif left, ok := e.Left.Data.(*js_ast.EUnary); ok && left.Op.UnaryAssignTarget() == js_ast.AssignTargetNone {\n\t\t\t\tleftLevel = js_ast.LCall\n\t\t\t} else if _, ok := e.Left.Data.(*js_ast.EAwait); ok {\n\t\t\t\tleftLevel = js_ast.LCall\n\t\t\t} else if _, ok := e.Left.Data.(*js_ast.EUndefined); ok {\n\t\t\t\t// Undefined is printed as \"void 0\"\n\t\t\t\tleftLevel = js_ast.LCall\n\t\t\t} else if _, ok := e.Left.Data.(*js_ast.ENumber); ok {\n\t\t\t\t// Negative numbers are printed using a unary operator\n\t\t\t\tleftLevel = js_ast.LCall\n\t\t\t} else if p.options.MinifySyntax {\n\t\t\t\t// When minifying, booleans are printed as \"!0 and \"!1\"\n\t\t\t\tif _, ok := e.Left.Data.(*js_ast.EBoolean); ok {\n\t\t\t\t\tleftLevel = js_ast.LCall\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Special-case \"#foo in bar\"\n\t\tif private, ok := e.Left.Data.(*js_ast.EPrivateIdentifier); ok && e.Op == js_ast.BinOpIn {\n\t\t\tname := p.renamer.NameForSymbol(private.Ref)\n\t\t\tp.addSourceMappingForName(e.Left.Loc, name, private.Ref)\n\t\t\tp.printIdentifier(name)\n\t\t} else if e.Op == js_ast.BinOpComma {\n\t\t\t// The result of the left operand of the comma operator is unused\n\t\t\tp.printExpr(e.Left, leftLevel, (flags&forbidIn)|exprResultIsUnused|parentWasUnaryOrBinary)\n\t\t} else {\n\t\t\tp.printExpr(e.Left, leftLevel, (flags&forbidIn)|parentWasUnaryOrBinary)\n\t\t}\n\n\t\tif e.Op != js_ast.BinOpComma {\n\t\t\tp.printSpace()\n\t\t}\n\n\t\tif entry.IsKeyword {\n\t\t\tp.printSpaceBeforeIdentifier()\n\t\t\tp.print(entry.Text)\n\t\t} else {\n\t\t\tp.printSpaceBeforeOperator(e.Op)\n\t\t\tp.print(entry.Text)\n\t\t\tp.prevOp = e.Op\n\t\t\tp.prevOpEnd = len(p.js)\n\t\t}\n\n\t\tp.printSpace()\n\n\t\tif e.Op == js_ast.BinOpComma {\n\t\t\t// The result of the right operand of the comma operator is unused if the caller doesn't use it\n\t\t\tp.printExpr(e.Right, rightLevel, (flags&(forbidIn|exprResultIsUnused))|parentWasUnaryOrBinary)\n\t\t} else {\n\t\t\tp.printExpr(e.Right, rightLevel, (flags&forbidIn)|parentWasUnaryOrBinary)\n\t\t}\n\n\t\tif wrap {\n\t\t\tp.print(\")\")\n\t\t}\n\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"Unexpected expression of type %T\", expr.Data))\n\t}\n}", "is_vulnerable": 0}
{"code": "func inSelectIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase ErrorToken:\n\t\t// Stop parsing.\n\t\treturn true\n\tcase TextToken:\n\t\tp.addText(strings.Replace(p.tok.Data, \"\\x00\", \"\", -1))\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\treturn inBodyIM(p)\n\t\tcase a.Option:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Optgroup:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tif p.top().DataAtom == a.Optgroup {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\t\tp.addElement()\n\t\tcase a.Select:\n\t\t\tp.tok.Type = EndTagToken\n\t\t\treturn false\n\t\tcase a.Input, a.Keygen, a.Textarea:\n\t\t\tif p.elementInScope(selectScope, a.Select) {\n\t\t\t\tp.parseImpliedToken(EndTagToken, a.Select, a.Select.String())\n\t\t\t\treturn false\n\t\t\t}\n\t\t\t// In order to properly ignore <textarea>, we need to change the tokenizer mode.\n\t\t\tp.tokenizer.NextIsNotRawText()\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\tcase a.Script, a.Template:\n\t\t\treturn inHeadIM(p)\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Option:\n\t\t\tif p.top().DataAtom == a.Option {\n\t\t\t\tp.oe.pop()\n\t\t\t}\n\t\tcase a.Optgroup:\n\t\t\ti := len(p.oe) - 1\n\t\t\tif p.oe[i].DataAtom == a.Option {\n\t\t\t\ti--\n\t\t\t}\n\t\t\tif p.oe[i].DataAtom == a.Optgroup {\n\t\t\t\tp.oe = p.oe[:i]\n\t\t\t}\n\t\tcase a.Select:\n\t\t\tif p.popUntil(selectScope, a.Select) {\n\t\t\t\tp.resetInsertionMode()\n\t\t\t}\n\t\tcase a.Template:\n\t\t\treturn inHeadIM(p)\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\tcase DoctypeToken:\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (s *connectionState) writePacket(w *bufio.Writer, rand io.Reader, packet []byte, strictMode bool) error {\n\tchangeKeys := len(packet) > 0 && packet[0] == msgNewKeys\n\n\terr := s.packetCipher.writeCipherPacket(s.seqNum, w, rand, packet)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif err = w.Flush(); err != nil {\n\t\treturn err\n\t}\n\ts.seqNum++\n\tif changeKeys {\n\t\tselect {\n\t\tcase cipher := <-s.pendingKeyChange:\n\t\t\ts.packetCipher = cipher\n\t\t\tif strictMode {\n\t\t\t\ts.seqNum = 0\n\t\t\t}\n\t\tdefault:\n\t\t\tpanic(\"ssh: no key material for msgNewKeys\")\n\t\t}\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func WorkspaceDidChangeConfiguration(srv *jrpc2.Server) jrpc2.Handler {\n\treturn handler.New(func(ctx context.Context, params lsp.DidChangeConfigurationParams) (bool, error) {\n\t\tlog.Info().Str(\"method\", \"WorkspaceDidChangeConfiguration\").Interface(\"params\", params).Msg(\"RECEIVED\")\n\t\tdefer log.Info().Str(\"method\", \"WorkspaceDidChangeConfiguration\").Interface(\"params\", params).Msg(\"DONE\")\n\n\t\temptySettings := lsp.Settings{}\n\t\tif params.Settings != emptySettings {\n\t\t\t// client used settings push\n\t\t\tUpdateSettings(ctx, params.Settings)\n\t\t\treturn true, nil\n\t\t}\n\n\t\t// client expects settings pull. E.g. VS Code uses pull model & sends empty settings when configuration is updated.\n\t\tif !config.CurrentConfig().ClientCapabilities().Workspace.Configuration {\n\t\t\tlog.Info().Msg(\"Pull model for workspace configuration not supported, ignoring workspace/didChangeConfiguration notification.\")\n\t\t\treturn false, nil\n\t\t}\n\n\t\tconfigRequestParams := lsp.ConfigurationParams{\n\t\t\tItems: []lsp.ConfigurationItem{\n\t\t\t\t{Section: \"snyk\"},\n\t\t\t},\n\t\t}\n\t\tres, err := srv.Callback(ctx, \"workspace/configuration\", configRequestParams)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tvar fetchedSettings []lsp.Settings\n\t\terr = res.UnmarshalResult(&fetchedSettings)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\n\t\tif fetchedSettings[0] != emptySettings {\n\t\t\tUpdateSettings(ctx, fetchedSettings[0])\n\t\t\treturn true, nil\n\t\t}\n\n\t\treturn false, nil\n\t})\n}", "is_vulnerable": 1}
{"code": "func isServiceInternal(service *corev1.Service) bool {\n\tfor dk, dv := range service.Annotations {\n\t\tfor _, annotations := range ingresscontroller.InternalLBAnnotations {\n\t\t\tfor ik, iv := range annotations {\n\t\t\t\tif dk == ik && dv == iv {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (t *Teler) checkBadReferrer(r *http.Request) error {\n\t// Parse the request referer URL\n\tref, err := url.Parse(r.Referer())\n\tif err != nil {\n\t\t// If there is an error parsing the URL, return nil\n\t\t// TODO: What should we do so as not to stop the threat analysis chain from analyzeRequest?\n\t\treturn nil\n\t}\n\n\t// Extract the effective top-level domain plus one from the hostname of the referer URL\n\teTLD1, err := publicsuffix.EffectiveTLDPlusOne(ref.Hostname())\n\tif err != nil {\n\t\t// If there is an error extracting the effective top-level domain plus one, return nil\n\t\t// TODO: What should we do so as not to stop the threat analysis chain from analyzeRequest?\n\t\treturn nil\n\t}\n\n\t// Check if the referrer request is in cache\n\tif err, ok := t.getCache(eTLD1); ok {\n\t\treturn err\n\t}\n\n\t// Check if the root domain of request referer header is in the BadReferrer index\n\tif t.inThreatIndex(threat.BadReferrer, eTLD1) {\n\t\t// If the domain is found in the index, cache the referrer\n\t\t// request and return an error indicating a bad HTTP referer\n\t\tt.setCache(eTLD1, errBadIPAddress)\n\t\treturn errors.New(errBadReferer)\n\t}\n\n\t// Cache the referrer of the request\n\tt.setCache(eTLD1, \"\")\n\n\t// Return nil if no match is found in the BadReferrer index\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func XMLToMap(r io.Reader) (map[string]string, error) {\n\tm := make(map[string]string)\n\tdec := xml.NewDecoder(r)\n\tvar tagName string\n\tfor {\n\t\tt, err := dec.Token()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\n\t\tswitch v := t.(type) {\n\t\tcase xml.StartElement:\n\t\t\ttagName = string(v.Name.Local)\n\t\tcase xml.CharData:\n\t\t\tm[tagName] = string(v)\n\t\t}\n\t}\n\treturn m, nil\n}", "is_vulnerable": 1}
{"code": "\tusers, err := ParsePasswdFilter(passwd, func(u User) bool {\n\t\tif userArg == \"\" {\n\t\t\treturn u.Uid == user.Uid\n\t\t}\n\n\t\tif uidErr == nil {\n\t\t\t// If the userArg is numeric, always treat it as a UID.\n\t\t\treturn uidArg == u.Uid\n\t\t}\n\n\t\treturn u.Name == userArg\n\t})", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) ExecuteAssembly(ctx context.Context, in *sliverpb.ExecuteAssemblyReq, opts ...grpc.CallOption) (*sliverpb.ExecuteAssembly, error) {\n\tout := new(sliverpb.ExecuteAssembly)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/ExecuteAssembly\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func clusterToSecret(c *appv1.Cluster, secret *apiv1.Secret) error {\n\tdata := make(map[string][]byte)\n\tdata[\"server\"] = []byte(strings.TrimRight(c.Server, \"/\"))\n\tif c.Name == \"\" {\n\t\tdata[\"name\"] = []byte(c.Server)\n\t} else {\n\t\tdata[\"name\"] = []byte(c.Name)\n\t}\n\tif len(c.Namespaces) != 0 {\n\t\tdata[\"namespaces\"] = []byte(strings.Join(c.Namespaces, \",\"))\n\t}\n\tconfigBytes, err := json.Marshal(c.Config)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdata[\"config\"] = configBytes\n\tif c.Shard != nil {\n\t\tdata[\"shard\"] = []byte(strconv.Itoa(int(*c.Shard)))\n\t}\n\tif c.ClusterResources {\n\t\tdata[\"clusterResources\"] = []byte(\"true\")\n\t}\n\tif c.Project != \"\" {\n\t\tdata[\"project\"] = []byte(c.Project)\n\t}\n\tsecret.Data = data\n\n\tsecret.Labels = c.Labels\n\tif c.Annotations != nil && c.Annotations[apiv1.LastAppliedConfigAnnotation] != \"\" {\n\t\treturn status.Errorf(codes.InvalidArgument, \"annotation %s cannot be set\", apiv1.LastAppliedConfigAnnotation)\n\t}\n\tsecret.Annotations = c.Annotations\n\n\tif secret.Annotations == nil {\n\t\tsecret.Annotations = make(map[string]string)\n\t}\n\n\tif c.RefreshRequestedAt != nil {\n\t\tsecret.Annotations[appv1.AnnotationKeyRefresh] = c.RefreshRequestedAt.Format(time.RFC3339)\n\t} else {\n\t\tdelete(secret.Annotations, appv1.AnnotationKeyRefresh)\n\t}\n\taddSecretMetadata(secret, common.LabelValueSecretTypeCluster)\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (f *writableMapFile) Write(data []byte) (int, error) {\n\tf.Data = data\n\treturn len(data), nil\n}", "is_vulnerable": 0}
{"code": "func (e errorTranslateSeriesSet) Err() error {\n\treturn TranslateToPromqlAPIError(e.s.Err())\n}", "is_vulnerable": 1}
{"code": "func TestDoErr(t *testing.T) {\n\tt.Skip(\"singleflight tests not stable\")\n\tvar g Group\n\tsomeErr := errors.New(\"Some error\")\n\tv, err, _ := g.Do(\"key\", func() (interface{}, error) {\n\t\treturn nil, someErr\n\t})\n\tif err != someErr {\n\t\tt.Errorf(\"Do error = %v; want someErr %v\", err, someErr)\n\t}\n\tif v != nil {\n\t\tt.Errorf(\"unexpected non-nil value %#v\", v)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *UpgradesTestSuite) TestUpdateMigrateNativeMultisigs() {\n\ts.SetupTest()\n\n\tamountPremint, ok := math.NewIntFromString(\"64699999994000000000000000\")\n\ts.Require().True(ok, \"failed to parse premint amount\")\n\tamount1, ok := math.NewIntFromString(\"13824747333293928482487986\")\n\ts.Require().True(ok, \"failed to parse amount1\")\n\tamount1IBC, ok := math.NewIntFromString(\"421720500000000000000\")\n\ts.Require().True(ok, \"failed to parse amount2\")\n\tamount2, ok := math.NewIntFromString(\"494000000000000000\")\n\ts.Require().True(ok, \"failed to parse amount3\")\n\tamount3 := amount2\n\tamount4 := amount2\n\tamount5, ok := math.NewIntFromString(\"1013699976000000000000000\")\n\ts.Require().True(ok, \"failed to parse amount6\")\n\n\tvar (\n\t\toldPremintCoin     = sdk.Coin{Denom: s.bondDenom, Amount: amountPremint}\n\t\tstratRes1EvmosCoin = sdk.Coin{Denom: s.bondDenom, Amount: amount1}\n\t\tstratRes1IBCCoin   = sdk.Coin{Denom: \"someIBCdenom\", Amount: amount1IBC}\n\t\tstratRes2Coin      = sdk.Coin{Denom: s.bondDenom, Amount: amount2}\n\t\tstratRes3Coin      = sdk.Coin{Denom: s.bondDenom, Amount: amount3}\n\t\tstratRes4Coin      = sdk.Coin{Denom: s.bondDenom, Amount: amount4}\n\t\tstratRes5Coin      = sdk.Coin{Denom: s.bondDenom, Amount: amount5}\n\n\t\t// We are delegating one token to each of the validators in the test setup\n\t\tdelegateAmount = int64(1)\n\t\t// One delegated token equals to 1e-18 share issued for the delegator\n\t\tdelegateShares = math.LegacyNewDecWithPrec(1, 18)\n\t)\n\n\toldStrategicReserves := make([]MigrationTestAccount, 0, 5)\n\tfor idx := 0; idx < 5; idx++ {\n\t\toldStrategicReserves = append(oldStrategicReserves, GenerateMigrationTestAccount())\n\t\ts.T().Logf(\"Old Strategic Reserve %d: %q\\n\", idx+1, oldStrategicReserves[idx].Addr.String())\n\t}\n\t// assign pre-balances\n\toldStrategicReserves[0].BalancePre = sdk.NewCoins(stratRes1EvmosCoin, stratRes1IBCCoin)\n\toldStrategicReserves[1].BalancePre = sdk.NewCoins(stratRes2Coin)\n\toldStrategicReserves[2].BalancePre = sdk.NewCoins(stratRes3Coin)\n\toldStrategicReserves[3].BalancePre = sdk.NewCoins(stratRes4Coin)\n\toldStrategicReserves[4].BalancePre = sdk.NewCoins(stratRes5Coin)\n\n\t// the new strategic reserve should hold the sum of all old strategic reserves\n\tnewStrategicReserve := GenerateMigrationTestAccount()\n\ts.T().Logf(\"New Strategic Reserve: %q\\n\", newStrategicReserve.Addr.String())\n\tnewStrategicReserve.BalancePost = sdk.NewCoins(\n\t\tstratRes1IBCCoin,\n\t\tstratRes1EvmosCoin.Add(stratRes2Coin).Add(stratRes3Coin).Add(stratRes4Coin).Add(stratRes5Coin),\n\t)\n\t// NOTE: after the migration the delegation that returns zero tokens should be removed / not newly delegated to\n\tnewStrategicReserve.DelegationsPost = stakingtypes.Delegations{\n\t\tstakingtypes.Delegation{\n\t\t\tDelegatorAddress: newStrategicReserve.Addr.String(),\n\t\t\tValidatorAddress: s.validators[1].OperatorAddress,\n\t\t\tShares:           delegateShares,\n\t\t},\n\t}\n\n\t// premint wallets\n\toldPremintWallet := GenerateMigrationTestAccount()\n\ts.T().Logf(\"Old Premint Wallet: %q\\n\", oldPremintWallet.Addr.String())\n\toldPremintWallet.BalancePre = sdk.Coins{oldPremintCoin}\n\n\t// the new premint wallet should have the same balance as the old premint wallet before the migration\n\tnewPremintWallet := GenerateMigrationTestAccount()\n\ts.T().Logf(\"New Premint Wallet: %q\\n\", newPremintWallet.Addr.String())\n\tnewPremintWallet.BalancePost = sdk.Coins{oldPremintCoin}\n\n\t// Fund the accounts to be migrated\n\taffectedAccounts := oldStrategicReserves\n\taffectedAccounts = append(affectedAccounts, oldPremintWallet)\n\tfor _, affectedAccount := range affectedAccounts {\n\t\terr := testutil.FundAccount(s.ctx, s.app.BankKeeper, affectedAccount.Addr, affectedAccount.BalancePre)\n\t\ts.Require().NoError(err, \"failed to fund account %s\", affectedAccount.Addr.String())\n\t}\n\n\t// delegation to validator 0 with zero tokens being returned because of the slashing\n\t_, err := CreateDelegationWithZeroTokens(\n\t\ts.ctx,\n\t\ts.app,\n\t\toldStrategicReserves[0].PrivKey,\n\t\toldStrategicReserves[0].Addr,\n\t\ts.validators[0],\n\t\tdelegateAmount,\n\t)\n\ts.Require().NoError(err, \"failed to create delegation with zero tokens\")\n\n\t// delegation to validator 1\n\t_, err = Delegate(\n\t\ts.ctx,\n\t\ts.app,\n\t\toldStrategicReserves[0].PrivKey,\n\t\toldStrategicReserves[0].Addr,\n\t\ts.validators[1],\n\t\tdelegateAmount,\n\t)\n\ts.Require().NoError(err, \"failed to create delegation\")\n\n\t// NOTE: We send twice the delegate amount to the old strategic reserve here, because that is\n\t// the amount that was just spent on delegations and thus removed from the balance. We need to fill it up again,\n\t// because the expected post-migration balance does not include the delegated amount.\n\terr = testutil.FundAccountWithBaseDenom(s.ctx, s.app.BankKeeper, oldStrategicReserves[0].Addr, 2*delegateAmount)\n\ts.Require().NoError(err, \"failed to fund account %s to even out delegated amount\", oldStrategicReserves[0].Addr.String())\n\t// Additionally, we need to send twice the default fee that is charged for the delegation transaction.\n\tfeeAmt := testutiltx.DefaultFee.Amount.MulRaw(2)\n\terr = testutil.FundAccountWithBaseDenom(s.ctx, s.app.BankKeeper, oldStrategicReserves[0].Addr, feeAmt.Int64())\n\ts.Require().NoError(err, \"failed to fund account %s to account for delegation fees\", oldStrategicReserves[0].Addr.String())\n\n\t// Store addresses in a slice\n\toldStrategicReservesAddrs := make([]string, 0, len(oldStrategicReserves))\n\tfor _, oldStrategicReserve := range oldStrategicReserves {\n\t\toldStrategicReservesAddrs = append(oldStrategicReservesAddrs, oldStrategicReserve.Addr.String())\n\t}\n\n\t// Check validator shares before migration, which are stored as the expected shares map.\n\t//\n\t// NOTE: There is a minor difference expected between the pre- and post-migration shares. This is because\n\t// the zero-token delegation is being unbonded and the corresponding shares are removed. Since zero tokens\n\t// would be delegated to the validator after the migration, the shares are not added again, creating a reduction\n\t// in the total shares of s.validators[0] of 1e-18.\n\texpectedSharesMap := s.getDelegationSharesMap()\n\texpectedSharesMap[s.validators[0].OperatorAddress] = expectedSharesMap[s.validators[0].OperatorAddress].Sub(delegateShares)\n\n\t// Migrate strategic reserves\n\terr = v14.MigrateNativeMultisigs(s.ctx, s.app.BankKeeper, s.app.StakingKeeper, newStrategicReserve.Addr, oldStrategicReservesAddrs...)\n\ts.Require().NoError(err, \"failed to migrate strategic reserves\")\n\n\t// Migrate premint wallet\n\terr = v14.MigrateNativeMultisigs(s.ctx, s.app.BankKeeper, s.app.StakingKeeper, newPremintWallet.Addr, oldPremintWallet.Addr.String())\n\ts.Require().NoError(err, \"failed to migrate premint wallet\")\n\n\t// Check that the multisigs have been updated\n\texpectedAccounts := oldStrategicReserves\n\texpectedAccounts = append(expectedAccounts, newStrategicReserve, oldPremintWallet, newPremintWallet)\n\tfor _, account := range expectedAccounts {\n\t\ts.requireMigratedAccount(account)\n\t}\n\n\t// Check validator shares after migration.\n\tsharesMap := s.getDelegationSharesMap()\n\ts.Require().Equal(expectedSharesMap, sharesMap, \"expected different validator shares after migration\")\n}", "is_vulnerable": 1}
{"code": "func getDirs(usrName string) []Directory {\n\t// Ignition has a bug/feature? where if you make a series of dirs\n\t// in one swoop, then the leading dirs are creates as root.\n\tnewDirs := []string{\n\t\t\"/home/\" + usrName + \"/.config\",\n\t\t\"/home/\" + usrName + \"/.config/containers\",\n\t\t\"/home/\" + usrName + \"/.config/systemd\",\n\t\t\"/home/\" + usrName + \"/.config/systemd/user\",\n\t\t\"/home/\" + usrName + \"/.config/systemd/user/default.target.wants\",\n\t}\n\tvar (\n\t\tdirs = make([]Directory, len(newDirs))\n\t)\n\tfor i, d := range newDirs {\n\t\tnewDir := Directory{\n\t\t\tNode: Node{\n\t\t\t\tGroup: getNodeGrp(usrName),\n\t\t\t\tPath:  d,\n\t\t\t\tUser:  getNodeUsr(usrName),\n\t\t\t},\n\t\t\tDirectoryEmbedded1: DirectoryEmbedded1{Mode: intToPtr(493)},\n\t\t}\n\t\tdirs[i] = newDir\n\t}\n\treturn dirs\n}", "is_vulnerable": 0}
{"code": "func ValidateStorageHostname(value interface{}) error {\n\ts, _ := value.(sort.StringSlice)\n\tfor _, ip := range s {\n\t\terr := validation.Validate(ip, validation.Required, is.Host)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Storage hostname should be valid IP\")\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (pt *pollingTrackerBase) pollForStatus(ctx context.Context, sender autorest.Sender) error {\n\treq, err := http.NewRequest(http.MethodGet, pt.URI, nil)\n\tif err != nil {\n\t\treturn autorest.NewErrorWithError(err, \"pollingTrackerBase\", \"pollForStatus\", nil, \"failed to create HTTP request\")\n\t}\n\n\treq = req.WithContext(ctx)\n\tpreparer := autorest.CreatePreparer(autorest.GetPrepareDecorators(ctx)...)\n\treq, err = preparer.Prepare(req)\n\tif err != nil {\n\t\treturn autorest.NewErrorWithError(err, \"pollingTrackerBase\", \"pollForStatus\", nil, \"failed preparing HTTP request\")\n\t}\n\tpt.resp, err = sender.Do(req)\n\tif err != nil {\n\t\treturn autorest.NewErrorWithError(err, \"pollingTrackerBase\", \"pollForStatus\", nil, \"failed to send HTTP request\")\n\t}\n\tif autorest.ResponseHasStatusCode(pt.resp, pollingCodes[:]...) {\n\t\t// reset the service error on success case\n\t\tpt.Err = nil\n\t\terr = pt.updateRawBody()\n\t} else {\n\t\t// check response body for error content\n\t\tpt.updateErrorFromResponse()\n\t\terr = pt.pollingError()\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "\t\tfunc(queryCursor options.Cursor) ([]itemAndPostCursor[dispatchableResourcesSubjectMap], error) {\n\t\t\tit, err := config.reader.ReverseQueryRelationships(\n\t\t\t\tctx,\n\t\t\t\tconfig.subjectsFilter,\n\t\t\t\toptions.WithResRelation(&options.ResourceRelation{\n\t\t\t\t\tNamespace: config.sourceResourceType.Namespace,\n\t\t\t\t\tRelation:  config.sourceResourceType.Relation,\n\t\t\t\t}),\n\t\t\t\toptions.WithSortForReverse(options.BySubject),\n\t\t\t\toptions.WithAfterForReverse(queryCursor),\n\t\t\t)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tdefer it.Close()\n\n\t\t\t// Chunk based on the FilterMaximumIDCount, to ensure we never send more than that amount of\n\t\t\t// results to a downstream dispatch.\n\t\t\trsm := newResourcesSubjectMapWithCapacity(config.sourceResourceType, uint32(datastore.FilterMaximumIDCount))\n\t\t\ttoBeHandled := make([]itemAndPostCursor[dispatchableResourcesSubjectMap], 0)\n\t\t\tcurrentCursor := queryCursor\n\n\t\t\tfor tpl := it.Next(); tpl != nil; tpl = it.Next() {\n\t\t\t\tif it.Err() != nil {\n\t\t\t\t\treturn nil, it.Err()\n\t\t\t\t}\n\n\t\t\t\tif err := rsm.addRelationship(tpl); err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\tif rsm.len() == int(datastore.FilterMaximumIDCount) {\n\t\t\t\t\ttoBeHandled = append(toBeHandled, itemAndPostCursor[dispatchableResourcesSubjectMap]{\n\t\t\t\t\t\titem:   rsm.asReadOnly(),\n\t\t\t\t\t\tcursor: currentCursor,\n\t\t\t\t\t})\n\t\t\t\t\trsm = newResourcesSubjectMapWithCapacity(config.sourceResourceType, uint32(datastore.FilterMaximumIDCount))\n\t\t\t\t\tcurrentCursor = tpl\n\t\t\t\t}\n\t\t\t}\n\t\t\tit.Close()\n\n\t\t\tif rsm.len() > 0 {\n\t\t\t\ttoBeHandled = append(toBeHandled, itemAndPostCursor[dispatchableResourcesSubjectMap]{\n\t\t\t\t\titem:   rsm.asReadOnly(),\n\t\t\t\t\tcursor: currentCursor,\n\t\t\t\t})\n\t\t\t}\n\n\t\t\treturn toBeHandled, nil\n\t\t},", "is_vulnerable": 0}
{"code": "func TestMissingAccountInImport(t *testing.T) {\n\ti := &Import{Subject: \"foo\", To: \"bar\", Type: Stream}\n\n\tvr := CreateValidationResults()\n\ti.Validate(\"\", vr)\n\n\tif len(vr.Issues) != 1 {\n\t\tt.Errorf(\"expected only one issue\")\n\t}\n\n\tif vr.IsBlocking(true) {\n\t\tt.Errorf(\"Missing Account is not blocking, must import failures are warnings\")\n\t}\n}", "is_vulnerable": 1}
{"code": "\tnb.GlobalRPC.Handler = func(req *nb.RPCMessage) (interface{}, error) {\n\t\tlogrus.Infof(\"RPC Handle: %+v\", req)\n\t\tnotificationSource.Queue.AddRateLimited(reconcile.Request{NamespacedName: types.NamespacedName{\n\t\t\tName:      options.SystemName,\n\t\t\tNamespace: options.Namespace,\n\t\t}})\n\t\treturn nil, nil\n\t}", "is_vulnerable": 1}
{"code": "func TestAES_GCM_KATS(t *testing.T) {\n\tfileContents, err := ioutil.ReadFile(\"testdata/aes_gcm.json\")\n\tif err != nil {\n\t\tt.Fatalf(\"failed to read KAT file: %v\", err)\n\t}\n\n\tvar kats []KAT\n\terr = json.Unmarshal(fileContents, &kats)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to unmarshal KAT json file: %v\", err)\n\t}\n\n\tfor i, kat := range kats {\n\t\tt.Run(fmt.Sprintf(\"Case%d\", i), func(t *testing.T) {\n\t\t\tif len(kat.AAD) > 0 {\n\t\t\t\tt.Skip(\"Skipping... SDK implementation does not expose additional authenticated data\")\n\t\t\t}\n\t\t\tiv, err := hex.DecodeString(kat.IV)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode iv: %v\", err)\n\t\t\t}\n\t\t\tkey, err := hex.DecodeString(kat.Key)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode key: %v\", err)\n\t\t\t}\n\t\t\tplaintext, err := hex.DecodeString(kat.Plaintext)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode plaintext: %v\", err)\n\t\t\t}\n\t\t\tciphertext, err := hex.DecodeString(kat.CipherText)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode ciphertext: %v\", err)\n\t\t\t}\n\t\t\ttag, err := hex.DecodeString(kat.Tag)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode tag: %v\", err)\n\t\t\t}\n\t\t\taesgcmTest(t, iv, key, plaintext, ciphertext, tag)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (s *AuthSuite) TestSAMLConnectorCRUDEventsEmitted(c *C) {\n\tctx := context.Background()\n\t// generate a certificate that makes ParseCertificatePEM happy, copied from ca_test.go\n\tca, err := tlsca.FromKeys([]byte(fixtures.SigningCertPEM), []byte(fixtures.SigningKeyPEM))\n\tc.Assert(err, IsNil)\n\n\tprivateKey, err := rsa.GenerateKey(rand.Reader, constants.RSAKeySize)\n\tc.Assert(err, IsNil)\n\n\ttestClock := clockwork.NewFakeClock()\n\tcertBytes, err := ca.GenerateCertificate(tlsca.CertificateRequest{\n\t\tClock:     testClock,\n\t\tPublicKey: privateKey.Public(),\n\t\tSubject:   pkix.Name{CommonName: \"test\"},\n\t\tNotAfter:  testClock.Now().Add(time.Hour),\n\t})\n\tc.Assert(err, IsNil)\n\n\t// test saml create\n\tsaml := services.NewSAMLConnector(\"test\", services.SAMLConnectorSpecV2{\n\t\tAssertionConsumerService: \"a\",\n\t\tIssuer:                   \"b\",\n\t\tSSO:                      \"c\",\n\t\tCert:                     string(certBytes),\n\t})\n\n\terr = s.a.UpsertSAMLConnector(ctx, saml)\n\tc.Assert(err, IsNil)\n\tc.Assert(s.mockEmitter.LastEvent().GetType(), DeepEquals, events.SAMLConnectorCreatedEvent)\n\ts.mockEmitter.Reset()\n\n\t// test saml update event\n\terr = s.a.UpsertSAMLConnector(ctx, saml)\n\tc.Assert(err, IsNil)\n\tc.Assert(s.mockEmitter.LastEvent().GetType(), DeepEquals, events.SAMLConnectorCreatedEvent)\n\ts.mockEmitter.Reset()\n\n\t// test saml delete event\n\terr = s.a.DeleteSAMLConnector(ctx, \"test\")\n\tc.Assert(err, IsNil)\n\tc.Assert(s.mockEmitter.LastEvent().GetType(), DeepEquals, events.SAMLConnectorDeletedEvent)\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_ServerNameOrNodeName(t *testing.T) {\n\tc := Configurator{base: &Config{}}\n\ttype variant struct {\n\t\tserver, node, expected string\n\t}\n\tvariants := []variant{\n\t\t{\"\", \"\", \"\"},\n\t\t{\"a\", \"\", \"a\"},\n\t\t{\"\", \"b\", \"b\"},\n\t\t{\"a\", \"b\", \"a\"},\n\t}\n\tfor _, v := range variants {\n\t\tc.base.ServerName = v.server\n\t\tc.base.NodeName = v.node\n\t\trequire.Equal(t, v.expected, c.serverNameOrNodeName())\n\t}\n}", "is_vulnerable": 0}
{"code": "func initFlags() {\n\tappFlags.InitializeDB = flag.Bool(\"initialize_db\", false, \"initialize the database and create all tables\")\n\tappFlags.CreateConfigDB = flag.Bool(\"create-config-db\", false, \"create config db\")\n\tappFlags.CreateDataDB = flag.Bool(\"create-data-db\", false, \"create data db\")\n\tappFlags.CreateTableConfigDB = flag.Bool(\"create-table-db-config\", false, \"create table in db config\")\n\tappFlags.UpgradeTableConfigDB = flag.Bool(\"upgrade-table-db-config\", false, \"upgrade table in db config\")\n\n\tappFlags.PopulateTableConfigDB = flag.Bool(\"populate-table-db-config\", false, \"populate table in db config\")\n\n\tappFlags.CreateHomerUser = flag.Bool(\"create-homer-user\", false, \"create homer user\")\n\tappFlags.DeleteHomerUser = flag.Bool(\"delete-homer-user\", false, \"delete homer user\")\n\tappFlags.ShowDbUsers = flag.Bool(\"show-db-users\", false, \"show db users\")\n\n\tappFlags.ForcePopulate = flag.Bool(\"force-populate\", false, \"force populate all records to config\")\n\tappFlags.ForcePasswordDB = flag.String(\"force-password\", \"\", \"force password for AWS setups\")\n\n\tappFlags.UpdateUIUser = flag.String(\"update-ui-user\", \"\", \"update user ui\")\n\tappFlags.UpdateUIPassword = flag.String(\"update-ui-password\", \"\", \"update password for user\")\n\n\tflag.Var(&appFlags.TablesPopulate, \"populate-table\", \"force to populate only current tables\")\n\n\tappFlags.ShowVersion = flag.Bool(\"version\", false, \"show version\")\n\n\tappFlags.CreateHomerRole = flag.Bool(\"create-homer-role\", false, \"create homer role\")\n\tappFlags.RevokeHomerRole = flag.Bool(\"revoke-homer-role\", false, \"revoke homer user\")\n\n\tappFlags.SaveHomerDbConfigToConfig = flag.Bool(\"save-homer-db-config-settings\", false, \"save homer db-config to configs\")\n\tappFlags.SaveHomerDbDataToConfig = flag.Bool(\"save-homer-db-data-settings\", false, \"save homer db-data settings to configs\")\n\n\tappFlags.ShowHelpMessage = flag.Bool(\"help\", false, \"show help\")\n\tappFlags.DatabaseRootUser = flag.String(\"database-root-user\", \"postgres\", \"database-root-user\")\n\tappFlags.DatabaseRootPassword = flag.String(\"database-root-password\", \"\", \"database-root-password\")\n\tappFlags.DatabaseHost = flag.String(\"database-host\", \"localhost\", \"database-host\")\n\tappFlags.DatabasePort = flag.Int(\"database-port\", 5432, \"database-port\")\n\tappFlags.DatabaseSSLMode = flag.String(\"database-ssl-mode\", \"disable\", \"database-ssl-mode\")\n\tappFlags.DatabaseRootDB = flag.String(\"database-root-db\", \"postgres\", \"database-root-db\")\n\tappFlags.DatabaseHomerNode = flag.String(\"database-homer-node\", \"localnode\", \"database-homer-node\")\n\tappFlags.DatabaseHomerUser = flag.String(\"database-homer-user\", \"homer_user\", \"database-homer-user\")\n\tappFlags.DatabaseHomerPassword = flag.String(\"database-homer-password\", \"homer_password\", \"database-homer-password\")\n\tappFlags.DatabaseHomerConfig = flag.String(\"database-homer-config\", \"homer_config\", \"database-homer-config\")\n\tappFlags.DatabaseHomerData = flag.String(\"database-homer-data\", \"homer_data\", \"database-homer-data\")\n\tappFlags.PathWebAppConfig = flag.String(\"webapp-config-path\", \"/usr/local/homer/etc\", \"the path to the webapp config file\")\n\tappFlags.LogName = flag.String(\"webapp-log-name\", \"\", \"the name prefix of the log file.\")\n\tappFlags.LogPathWebApp = flag.String(\"webapp-log-path\", \"\", \"the path for the log file.\")\n\tappFlags.APIPrefix = flag.String(\"webapp-api-prefix\", \"\", \"API prefix.\")\n\tappFlags.WatchConfig = flag.Bool(\"watch-config\", false, \"Watch the configuration for changes\")\n\tappFlags.ShowCurrentConfig = flag.Bool(\"show-current-config\", false, \"print out the current config and exit\")\n\n\t//Jwt\n\tappFlags.GenerateJwtSecret = flag.Bool(\"generate-jwt-secret\", false, \"generate jwt secret\")\n\n\tflag.Parse()\n}", "is_vulnerable": 0}
{"code": "func NotPanics(t TestingT, f assert.PanicTestFunc, msgAndArgs ...interface{}) {\n\tif assert.NotPanics(t, f, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "\t\treturn SenderFunc(func(r *http.Request) (*http.Response, error) {\n\t\t\treturn doRetryForStatusCodesImpl(s, r, false, attempts, backoff, 0, codes...)\n\t\t})", "is_vulnerable": 0}
{"code": "func ReadHeaderRange(db ethdb.Reader, number uint64, count uint64) []rlp.RawValue {\n\tvar rlpHeaders []rlp.RawValue\n\tif count == 0 {\n\t\treturn rlpHeaders\n\t}\n\ti := number\n\tif count-1 > number {\n\t\t// It's ok to request block 0, 1 item\n\t\tcount = number + 1\n\t}\n\tlimit, _ := db.Ancients()\n\t// First read live blocks\n\tif i >= limit {\n\t\t// If we need to read live blocks, we need to figure out the hash first\n\t\thash := ReadCanonicalHash(db, number)\n\t\tfor ; i >= limit && count > 0; i-- {\n\t\t\tif data, _ := db.Get(headerKey(i, hash)); len(data) > 0 {\n\t\t\t\trlpHeaders = append(rlpHeaders, data)\n\t\t\t\t// Get the parent hash for next query\n\t\t\t\thash = types.HeaderParentHashFromRLP(data)\n\t\t\t} else {\n\t\t\t\tbreak // Maybe got moved to ancients\n\t\t\t}\n\t\t\tcount--\n\t\t}\n\t}\n\tif count == 0 {\n\t\treturn rlpHeaders\n\t}\n\t// read remaining from ancients, cap at 2M\n\tdata, err := db.AncientRange(ChainFreezerHeaderTable, i+1-count, count, 2*1024*1024)\n\tif err != nil {\n\t\tlog.Error(\"Failed to read headers from freezer\", \"err\", err)\n\t\treturn rlpHeaders\n\t}\n\tif uint64(len(data)) != count {\n\t\tlog.Warn(\"Incomplete read of headers from freezer\", \"wanted\", count, \"read\", len(data))\n\t\treturn rlpHeaders\n\t}\n\t// The data is on the order [h, h+1, .., n] -- reordering needed\n\tfor i := range data {\n\t\trlpHeaders = append(rlpHeaders, data[len(data)-1-i])\n\t}\n\treturn rlpHeaders\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) checkDoublePublish(\n\tctx context.Context,\n\ttx sql.Executor,\n\tatx *types.VerifiedActivationTx,\n) (*mwire.MalfeasanceProof, error) {\n\tprev, err := atxs.GetByEpochAndNodeID(tx, atx.PublishEpoch, atx.SmesherID)\n\tif err != nil && !errors.Is(err, sql.ErrNotFound) {\n\t\treturn nil, err\n\t}\n\n\t// do ID check to be absolutely sure.\n\tif prev == nil || prev.ID() == atx.ID() {\n\t\treturn nil, nil\n\t}\n\tif _, ok := h.signers[atx.SmesherID]; ok {\n\t\t// if we land here we tried to publish 2 ATXs in the same epoch\n\t\t// don't punish ourselves but fail validation and thereby the handling of the incoming ATX\n\t\treturn nil, fmt.Errorf(\"%s already published an ATX in epoch %d\", atx.SmesherID.ShortString(), atx.PublishEpoch)\n\t}\n\n\tvar atxProof mwire.AtxProof\n\tfor i, a := range []*types.VerifiedActivationTx{prev, atx} {\n\t\tatxProof.Messages[i] = mwire.AtxProofMsg{\n\t\t\tInnerMsg: types.ATXMetadata{\n\t\t\t\tPublishEpoch: a.PublishEpoch,\n\t\t\t\tMsgHash:      wire.ActivationTxToWireV1(a.ActivationTx).HashInnerBytes(),\n\t\t\t},\n\t\t\tSmesherID: a.SmesherID,\n\t\t\tSignature: a.Signature,\n\t\t}\n\t}\n\tproof := &mwire.MalfeasanceProof{\n\t\tLayer: atx.PublishEpoch.FirstLayer(),\n\t\tProof: mwire.Proof{\n\t\t\tType: mwire.MultipleATXs,\n\t\t\tData: &atxProof,\n\t\t},\n\t}\n\tencoded, err := codec.Encode(proof)\n\tif err != nil {\n\t\th.log.With().Panic(\"failed to encode malfeasance proof\", log.Err(err))\n\t}\n\tif err := identities.SetMalicious(tx, atx.SmesherID, encoded, time.Now()); err != nil {\n\t\treturn nil, fmt.Errorf(\"add malfeasance proof: %w\", err)\n\t}\n\n\th.log.WithContext(ctx).With().Warning(\"smesher produced more than one atx in the same epoch\",\n\t\tlog.Stringer(\"smesher\", atx.SmesherID),\n\t\tlog.Object(\"prev\", prev),\n\t\tlog.Object(\"curr\", atx),\n\t)\n\n\treturn proof, nil\n}", "is_vulnerable": 0}
{"code": "func findObjectStorage(ctx context.Context, dataStore *store.Store) (*s3.Client, error) {\n\tsystemSettingStorageServiceID, err := dataStore.GetWorkspaceSetting(ctx, &store.FindWorkspaceSetting{Name: apiv1.SystemSettingStorageServiceIDName.String()})\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Failed to find SystemSettingStorageServiceIDName\")\n\t}\n\n\tstorageServiceID := apiv1.DefaultStorage\n\tif systemSettingStorageServiceID != nil {\n\t\terr = json.Unmarshal([]byte(systemSettingStorageServiceID.Value), &storageServiceID)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"Failed to unmarshal storage service id\")\n\t\t}\n\t}\n\tstorage, err := dataStore.GetStorage(ctx, &store.FindStorage{ID: &storageServiceID})\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Failed to find StorageServiceID\")\n\t}\n\n\tif storage == nil {\n\t\treturn nil, nil // storage not configured - not an error, just return empty ref\n\t}\n\tstorageMessage, err := apiv1.ConvertStorageFromStore(storage)\n\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Failed to ConvertStorageFromStore\")\n\t}\n\tif storageMessage.Type != apiv1.StorageS3 {\n\t\treturn nil, nil\n\t}\n\n\ts3Config := storageMessage.Config.S3Config\n\treturn s3.NewClient(ctx, &s3.Config{\n\t\tAccessKey: s3Config.AccessKey,\n\t\tSecretKey: s3Config.SecretKey,\n\t\tEndPoint:  s3Config.EndPoint,\n\t\tRegion:    s3Config.Region,\n\t\tBucket:    s3Config.Bucket,\n\t\tURLPrefix: s3Config.URLPrefix,\n\t\tURLSuffix: s3Config.URLSuffix,\n\t\tPreSign:   s3Config.PreSign,\n\t})\n}", "is_vulnerable": 1}
{"code": "func (f *ConfigurationFile) parseJsonFile(file ufs.File) error {\n\tb, err := io.ReadAll(file)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdata, err := f.IterateOverJson(b)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err := file.Seek(0, io.SeekStart); err != nil {\n\t\treturn err\n\t}\n\tif err := file.Truncate(0); err != nil {\n\t\treturn err\n\t}\n\n\t// Write the data to the file.\n\tif _, err := io.Copy(file, bytes.NewReader(data.BytesIndent(\"\", \"    \"))); err != nil {\n\t\treturn errors.Wrap(err, \"parser: failed to write properties file to disk\")\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestContains(t *testing.T) {\n\ttestCasesStr := []struct {\n\t\tname     string\n\t\tslice    []string\n\t\titem     string\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []string{},\n\t\t\titem:     \"foo\",\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []string{\"foo\"},\n\t\t\titem:     \"foo\",\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []string{\"bar\"},\n\t\t\titem:     \"foo\",\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []string{\"foo\", \"bar\"},\n\t\t\titem:     \"foo\",\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []string{\"foo\", \"bar\"},\n\t\t\titem:     \"baz\",\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesStr {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesInt := []struct {\n\t\tname     string\n\t\tslice    []int\n\t\titem     int\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []int{},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []int{1},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []int{2},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []int{1, 2},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []int{1, 2},\n\t\t\titem:     3,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesInt {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesFloat := []struct {\n\t\tname     string\n\t\tslice    []float64\n\t\titem     float64\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []float64{},\n\t\t\titem:     1.0,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []float64{1.0},\n\t\t\titem:     1.0,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []float64{2.0},\n\t\t\titem:     1.0,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []float64{1.0, 2.0},\n\t\t\titem:     1.0,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []float64{1.0, 2.0},\n\t\t\titem:     3.0,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesFloat {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesBool := []struct {\n\t\tname     string\n\t\tslice    []bool\n\t\titem     bool\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []bool{},\n\t\t\titem:     true,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []bool{true},\n\t\t\titem:     true,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []bool{false},\n\t\t\titem:     true,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []bool{true, false},\n\t\t\titem:     true,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []bool{true, false},\n\t\t\titem:     false,\n\t\t\texpected: true,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesBool {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesByte := []struct {\n\t\tname     string\n\t\tslice    []byte\n\t\titem     byte\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []byte{},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []byte{1},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []byte{2},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []byte{1, 2},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []byte{1, 2},\n\t\t\titem:     3,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesByte {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesRune := []struct {\n\t\tname     string\n\t\tslice    []rune\n\t\titem     rune\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []rune{},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []rune{1},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []rune{2},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []rune{1, 2},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []rune{1, 2},\n\t\t\titem:     3,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesRune {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesComplex := []struct {\n\t\tname     string\n\t\tslice    []complex128\n\t\titem     complex128\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []complex128{},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []complex128{1},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []complex128{2},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []complex128{1, 2},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []complex128{1, 2},\n\t\t\titem:     3,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesComplex {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n\n\ttestCasesUint := []struct {\n\t\tname     string\n\t\tslice    []uint\n\t\titem     uint\n\t\texpected bool\n\t}{\n\t\t{\n\t\t\tname:     \"empty slice\",\n\t\t\tslice:    []uint{},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with item\",\n\t\t\tslice:    []uint{1},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice without item\",\n\t\t\tslice:    []uint{2},\n\t\t\titem:     1,\n\t\t\texpected: false,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items\",\n\t\t\tslice:    []uint{1, 2},\n\t\t\titem:     1,\n\t\t\texpected: true,\n\t\t},\n\t\t{\n\t\t\tname:     \"slice with multiple items without item\",\n\t\t\tslice:    []uint{1, 2},\n\t\t\titem:     3,\n\t\t\texpected: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCasesUint {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tactual := utils.Contains(tc.slice, tc.item)\n\t\t\tif actual != tc.expected {\n\t\t\t\tt.Errorf(\"Expected Contains(%v, %v) to be %v, but got %v\", tc.slice, tc.item, tc.expected, actual)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestRedirectLocation(t *testing.T) {\n\texpected := \"https://mattermost.com/wp-content/themes/mattermostv2/img/logo-light.svg\"\n\n\ttestServer := httptest.NewServer(http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) {\n\t\tres.Header().Set(\"Location\", expected)\n\t\tres.WriteHeader(http.StatusFound)\n\t\tres.Write([]byte(\"body\"))\n\t}))\n\tdefer func() { testServer.Close() }()\n\n\tmockBitlyLink := testServer.URL\n\n\tth := Setup(t)\n\tdefer th.TearDown()\n\tclient := th.Client\n\tenableLinkPreviews := *th.App.Config().ServiceSettings.EnableLinkPreviews\n\tdefer func() {\n\t\tth.App.UpdateConfig(func(cfg *model.Config) { *cfg.ServiceSettings.EnableLinkPreviews = enableLinkPreviews })\n\t}()\n\n\t*th.App.Config().ServiceSettings.EnableLinkPreviews = true\n\t*th.App.Config().ServiceSettings.AllowedUntrustedInternalConnections = \"127.0.0.1\"\n\n\t_, _, err := th.SystemAdminClient.GetRedirectLocation(context.Background(), \"https://mattermost.com/\", \"\")\n\trequire.NoError(t, err)\n\n\t_, resp, err := th.SystemAdminClient.GetRedirectLocation(context.Background(), \"\", \"\")\n\trequire.Error(t, err)\n\tCheckBadRequestStatus(t, resp)\n\n\tactual, _, err := th.SystemAdminClient.GetRedirectLocation(context.Background(), mockBitlyLink, \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, expected, actual)\n\n\t// Check cached value\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), mockBitlyLink, \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, expected, actual)\n\n\t*th.App.Config().ServiceSettings.EnableLinkPreviews = false\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), \"https://mattermost.com/\", \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, actual, \"\")\n\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), \"\", \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, actual, \"\")\n\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), mockBitlyLink, \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, actual, \"\")\n\n\tclient.Logout(context.Background())\n\t_, resp, err = client.GetRedirectLocation(context.Background(), \"\", \"\")\n\trequire.Error(t, err)\n\tCheckUnauthorizedStatus(t, resp)\n\n\t// Check that too-long redirect locations are ignored\n\t*th.App.Config().ServiceSettings.EnableLinkPreviews = true\n\turlPrefix := \"https://example.co\"\n\talmostTooLongUrl := urlPrefix + strings.Repeat(\"a\", 2100-len(urlPrefix))\n\ttestServer2 := httptest.NewServer(http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) {\n\t\tres.Header().Set(\"Location\", almostTooLongUrl)\n\t\tres.WriteHeader(http.StatusFound)\n\t\tres.Write([]byte(\"body\"))\n\t}))\n\tdefer func() { testServer2.Close() }()\n\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), testServer2.URL, \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, almostTooLongUrl, actual)\n\n\ttooLongUrl := urlPrefix + strings.Repeat(\"a\", 2101-len(urlPrefix))\n\ttestServer3 := httptest.NewServer(http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) {\n\t\tres.Header().Set(\"Location\", tooLongUrl)\n\t\tres.WriteHeader(http.StatusFound)\n\t\tres.Write([]byte(\"body\"))\n\t}))\n\tdefer func() { testServer3.Close() }()\n\n\tactual, _, err = th.SystemAdminClient.GetRedirectLocation(context.Background(), testServer3.URL, \"\")\n\trequire.NoError(t, err)\n\tassert.Equal(t, \"\", actual)\n}", "is_vulnerable": 0}
{"code": "\t\t\t\tbootstrapContainer.MessagingClientName: func(get di.Get) interface{} {\n\t\t\t\t\treturn msgClient\n\t\t\t\t},\n\t\t\t})\n\n\t\t\tlc.Infof(\n\t\t\t\t\"Connected to %s Message Bus @ %s://%s:%d publishing on '%s' prefix topic with AuthMode='%s'\",\n\t\t\t\tmessageBusInfo.Type,\n\t\t\t\tmessageBusInfo.Protocol,\n\t\t\t\tmessageBusInfo.Host,\n\t\t\t\tmessageBusInfo.Port,\n\t\t\t\tmessageBusInfo.PublishTopicPrefix,\n\t\t\t\tmessageBusInfo.AuthMode)\n\n\t\t\t// Make sure the MessageBus password is not leaked into the Service Config that can be retrieved via the /config endpoint\n\t\t\tdelete(messageBusInfo.Optional, bootstrapMessaging.OptionsPasswordKey)\n\n\t\t\treturn true\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "\t\t\tchangeRole := func(role string) string {\n\t\t\t\tswitch role {\n\t\t\t\tcase fleet.RoleMaintainer:\n\t\t\t\t\treturn fleet.RoleAdmin // promote\n\t\t\t\tcase fleet.RoleAdmin:\n\t\t\t\t\treturn fleet.RoleMaintainer // demote\n\t\t\t\tcase fleet.RoleObserver:\n\t\t\t\t\treturn fleet.RoleAdmin // promote\n\t\t\t\tdefault:\n\t\t\t\t\tt.Fatalf(\"unknown role: %s\", role)\n\t\t\t\t\treturn \"\"\n\t\t\t\t}\n\t\t\t}", "is_vulnerable": 0}
{"code": "func (m mockConfigMap) GetConfigMap(name string) (*api.ConfigMap, error) {\n\tif name != \"default/demo-configmap\" && name != \"otherns/demo-configmap\" {\n\t\treturn nil, fmt.Errorf(\"there is no configmap with name %v\", name)\n\t}\n\n\tcmns, cmn, err := cache.SplitMetaNamespaceKey(name)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"invalid configmap name\")\n\t}\n\n\treturn &api.ConfigMap{\n\t\tObjectMeta: meta_v1.ObjectMeta{\n\t\t\tNamespace: cmns,\n\t\t\tName:      cmn,\n\t\t},\n\t\tData: map[string]string{\"REDIRECT_STATUS\": \"200\", \"SERVER_NAME\": \"$server_name\"},\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (r *resourceConfigScope) FindVersion(v atc.Version) (ResourceConfigVersion, bool, error) {\n\trcv := &resourceConfigVersion{\n\t\tresourceConfigScope: r,\n\t\tconn:                r.conn,\n\t}\n\n\tversionByte, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn nil, false, err\n\t}\n\n\trow := resourceConfigVersionQuery.\n\t\tWhere(sq.Eq{\n\t\t\t\"v.resource_config_scope_id\": r.id,\n\t\t}).\n\t\tWhere(sq.Expr(fmt.Sprintf(\"v.version_md5 = md5('%s')\", versionByte))).\n\t\tRunWith(r.conn).\n\t\tQueryRow()\n\n\terr = scanResourceConfigVersion(rcv, row)\n\tif err != nil {\n\t\tif err == sql.ErrNoRows {\n\t\t\treturn nil, false, nil\n\t\t}\n\t\treturn nil, false, err\n\t}\n\n\treturn rcv, true, nil\n}", "is_vulnerable": 1}
{"code": "func (v *VM) assignSandbox(s *Sandbox) error {\n\t// add vm symlinks\n\t// - link vm socket from sandbox dir (/run/vc/vm/sbid/<kata.sock>) to vm dir (/run/vc/vm/vmid/<kata.sock>)\n\t// - link 9pfs share path from sandbox dir (/run/kata-containers/shared/sandboxes/sbid/) to vm dir (/run/vc/vm/vmid/shared/)\n\n\tvmSharePath := buildVMSharePath(v.id, v.store.RunVMStoragePath())\n\tvmSockDir := filepath.Join(v.store.RunVMStoragePath(), v.id)\n\tsbSharePath := s.agent.getSharePath(s.id)\n\tsbSockDir := filepath.Join(v.store.RunVMStoragePath(), s.id)\n\n\tv.logger().WithFields(logrus.Fields{\n\t\t\"vmSharePath\": vmSharePath,\n\t\t\"vmSockDir\":   vmSockDir,\n\t\t\"sbSharePath\": sbSharePath,\n\t\t\"sbSockDir\":   sbSockDir,\n\t\t\"proxy-pid\":   v.proxyPid,\n\t\t\"proxy-url\":   v.proxyURL,\n\t}).Infof(\"assign vm to sandbox %s\", s.id)\n\n\tif err := s.agent.setProxy(s, v.proxy, v.proxyPid, v.proxyURL); err != nil {\n\t\treturn err\n\t}\n\n\tif err := s.agent.reuseAgent(v.agent); err != nil {\n\t\treturn err\n\t}\n\n\t// First make sure the symlinks do not exist\n\tos.RemoveAll(sbSharePath)\n\tos.RemoveAll(sbSockDir)\n\n\tif err := os.Symlink(vmSharePath, sbSharePath); err != nil {\n\t\treturn err\n\t}\n\n\tif err := os.Symlink(vmSockDir, sbSockDir); err != nil {\n\t\tos.Remove(sbSharePath)\n\t\treturn err\n\t}\n\n\ts.hypervisor = v.hypervisor\n\ts.config.HypervisorConfig.VMid = v.id\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) UpdateAutoTLS(manualCAPems, connectCAPems []string, pub, priv string, verifyServerHostname bool) error {\n\t// order of defers matters because log acquires a RLock()\n\tdefer c.log(\"UpdateAutoEncrypt\")\n\tcert, err := tls.X509KeyPair([]byte(pub), []byte(priv))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to load cert/key pair: %v\", err)\n\t}\n\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tpool, err := newX509CertPool(c.manual.caPems, manualCAPems, connectCAPems)\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.autoTLS.extraCAPems = manualCAPems\n\tc.autoTLS.connectCAPems = connectCAPems\n\tc.autoTLS.cert = &cert\n\tc.caPool = pool\n\tc.autoTLS.verifyServerHostname = verifyServerHostname\n\tc.version++\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tgo func() {\n\t\t\tdefer GinkgoRecover()\n\t\t\tcryptoSetup.EXPECT().StartHandshake()\n\t\t\tcryptoSetup.EXPECT().NextEvent().Return(handshake.Event{Kind: handshake.EventHandshakeComplete})\n\t\t\tcryptoSetup.EXPECT().NextEvent().Return(handshake.Event{Kind: handshake.EventNoEvent})\n\t\t\tcryptoSetup.EXPECT().SetHandshakeConfirmed()\n\t\t\tcryptoSetup.EXPECT().GetSessionTicket()\n\t\t\tmconn.EXPECT().Write(gomock.Any(), gomock.Any())\n\t\t\tExpect(conn.handleHandshakeComplete()).To(Succeed())\n\t\t\tconn.run()\n\t\t}()", "is_vulnerable": 0}
{"code": "func ConsumeEnvelope(data []byte, domain string) (envelope *Envelope, rec Record, err error) {\n\te, err := UnmarshalEnvelope(data)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed when unmarshalling the envelope: %w\", err)\n\t}\n\n\terr = e.validate(domain)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to validate envelope: %w\", err)\n\t}\n\n\trec, err = e.Record()\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to unmarshal envelope payload: %w\", err)\n\t}\n\treturn e, rec, nil\n}", "is_vulnerable": 0}
{"code": "func validateRelationRewrites(model *openfgapb.AuthorizationModel) error {\n\ttypeDefinitions := model.GetTypeDefinitions()\n\n\tallRelations := map[string]struct{}{}\n\ttypeToRelations := map[string]map[string]struct{}{}\n\tfor _, td := range typeDefinitions {\n\t\tobjectType := td.GetType()\n\t\ttypeToRelations[objectType] = map[string]struct{}{}\n\t\tfor relation := range td.GetRelations() {\n\t\t\ttypeToRelations[objectType][relation] = struct{}{}\n\t\t\tallRelations[relation] = struct{}{}\n\t\t}\n\t}\n\n\tfor _, td := range typeDefinitions {\n\t\tobjectType := td.GetType()\n\t\tfor relation, rewrite := range td.GetRelations() {\n\t\t\terr := isUsersetRewriteValid(allRelations, typeToRelations[objectType], objectType, relation, rewrite)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"Clear cookie header should clear Cookie header\", func(t *testing.T) {\n\t\treq, err := http.NewRequest(http.MethodGet, \"/\", nil)\n\t\trequire.NoError(t, err)\n\t\treq.AddCookie(&http.Cookie{Name: \"cookie\"})\n\n\t\tClearCookieHeader(req, nil, nil)\n\t\trequire.NotContains(t, req.Header, \"Cookie\")\n\t})", "is_vulnerable": 0}
{"code": "func (sg *SecureGet) Do(ctx context.Context) error {\n\tref, err := name.ParseReference(sg.ImageRef)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\topts := []remote.Option{\n\t\tremote.WithAuthFromKeychain(authn.DefaultKeychain),\n\t\tremote.WithContext(ctx),\n\t}\n\n\tco := &cosign.CheckOpts{\n\t\tClaimVerifier:      cosign.SimpleClaimVerifier,\n\t\tRegistryClientOpts: []ociremote.Option{ociremote.WithRemoteOptions(opts...)},\n\t}\n\tif _, ok := ref.(name.Tag); ok {\n\t\tif sg.KeyRef == \"\" && !options.EnableExperimental() {\n\t\t\treturn errors.New(\"public key must be specified when fetching by tag, you must fetch by digest or supply a public key\")\n\t\t}\n\t}\n\t// Overwrite \"ref\" with a digest to avoid a race where we verify the tag,\n\t// and then access the file through the tag.  This has a race where we\n\t// might download content that isn't what we verified.\n\tref, err = ociremote.ResolveDigest(ref, co.RegistryClientOpts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif sg.KeyRef != \"\" {\n\t\tpub, err := sigs.LoadPublicKey(ctx, sg.KeyRef)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tco.SigVerifier = pub\n\t}\n\n\tif co.SigVerifier != nil || options.EnableExperimental() {\n\t\t// NB: There are only 2 kinds of verification right now:\n\t\t// 1. You gave us the public key explicitly to verify against so co.SigVerifier is non-nil or,\n\t\t// 2. We're going to find an x509 certificate on the signature and verify against Fulcio root trust\n\t\t// TODO(nsmith5): Refactor this verification logic to pass back _how_ verification\n\t\t// was performed so we don't need to use this fragile logic here.\n\t\tfulcioVerified := (co.SigVerifier == nil)\n\n\t\tco.RootCerts = fulcio.GetRoots()\n\n\t\tsp, bundleVerified, err := cosign.VerifyImageSignatures(ctx, ref, co)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tverify.PrintVerificationHeader(sg.ImageRef, co, bundleVerified, fulcioVerified)\n\t\tverify.PrintVerification(sg.ImageRef, sp, \"text\")\n\t}\n\n\t// TODO(mattmoor): Depending on what this is, use the higher-level stuff.\n\timg, err := remote.Image(ref, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlayers, err := img.Layers()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif len(layers) != 1 {\n\t\treturn errors.New(\"invalid artifact\")\n\t}\n\trc, err := layers[0].Compressed()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.Copy(sg.Out, rc)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (iter *ListResultIterator) Next() error {\n\titer.i++\n\tif iter.i < len(iter.page.Values()) {\n\t\treturn nil\n\t}\n\terr := iter.page.Next()\n\tif err != nil {\n\t\titer.i--\n\t\treturn err\n\t}\n\titer.i = 0\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func createAccount(t *testing.T, s *server.Server) (acc *server.Account, akp nkeys.KeyPair) {\n\tt.Helper()\n\takp = createAccountForOperatorKey(t, s, oSeed)\n\tif pub, err := akp.PublicKey(); err != nil {\n\t\tt.Fatalf(\"Expected this to pass, got %v\", err)\n\t} else if acc, err = s.LookupAccount(pub); err != nil {\n\t\tt.Fatalf(\"Error looking up account: %v\", err)\n\t}\n\treturn acc, akp\n}", "is_vulnerable": 0}
{"code": "func setupEncryption(localIP, advIP, remoteIP net.IP, em *encrMap, keys []*key) error {\n\tlogrus.Debugf(\"Programming encryption between %s and %s\", localIP, remoteIP)\n\trIPs := remoteIP.String()\n\n\tindices := make([]*spi, 0, len(keys))\n\n\tfor i, k := range keys {\n\t\tspis := &spi{buildSPI(advIP, remoteIP, k.tag), buildSPI(remoteIP, advIP, k.tag)}\n\t\tdir := reverse\n\t\tif i == 0 {\n\t\t\tdir = bidir\n\t\t}\n\t\tfSA, rSA, err := programSA(localIP, remoteIP, spis, k, dir, true)\n\t\tif err != nil {\n\t\t\tlogrus.Warn(err)\n\t\t}\n\t\tindices = append(indices, spis)\n\t\tif i != 0 {\n\t\t\tcontinue\n\t\t}\n\t\terr = programSP(fSA, rSA, true)\n\t\tif err != nil {\n\t\t\tlogrus.Warn(err)\n\t\t}\n\t}\n\n\tem.Lock()\n\tem.nodes[rIPs] = indices\n\tem.Unlock()\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (f *framerI) QueueControlFrame(frame wire.Frame) {\n\tf.controlFrameMutex.Lock()\n\tdefer f.controlFrameMutex.Unlock()\n\n\tif pr, ok := frame.(*wire.PathResponseFrame); ok {\n\t\t// Only queue up to maxPathResponses PATH_RESPONSE frames.\n\t\t// This limit should be high enough to never be hit in practice,\n\t\t// unless the peer is doing something malicious.\n\t\tif len(f.pathResponses) >= maxPathResponses {\n\t\t\treturn\n\t\t}\n\t\tf.pathResponses = append(f.pathResponses, pr)\n\t\treturn\n\t}\n\t// This is a hack.\n\tif len(f.controlFrames) >= maxControlFrames {\n\t\tf.queuedTooManyControlFrames = true\n\t\treturn\n\t}\n\tf.controlFrames = append(f.controlFrames, frame)\n}", "is_vulnerable": 0}
{"code": "func NewMediaFileRepository(ctx context.Context, db dbx.Builder) *mediaFileRepository {\n\tr := &mediaFileRepository{}\n\tr.ctx = ctx\n\tr.db = db\n\tr.tableName = \"media_file\"\n\tr.filterMappings = map[string]filterFunc{\n\t\t\"id\":      idFilter(r.tableName),\n\t\t\"title\":   fullTextFilter,\n\t\t\"starred\": booleanFilter,\n\t}\n\tif conf.Server.PreferSortTags {\n\t\tr.sortMappings = map[string]string{\n\t\t\t\"title\":     \"COALESCE(NULLIF(sort_title,''),title)\",\n\t\t\t\"artist\":    \"COALESCE(NULLIF(sort_artist_name,''),order_artist_name) asc, COALESCE(NULLIF(sort_album_name,''),order_album_name) asc, release_date asc, disc_number asc, track_number asc\",\n\t\t\t\"album\":     \"COALESCE(NULLIF(sort_album_name,''),order_album_name) asc, release_date asc, disc_number asc, track_number asc, COALESCE(NULLIF(sort_artist_name,''),order_artist_name) asc, COALESCE(NULLIF(sort_title,''),title) asc\",\n\t\t\t\"random\":    r.seededRandomSort(),\n\t\t\t\"createdAt\": \"media_file.created_at\",\n\t\t}\n\t} else {\n\t\tr.sortMappings = map[string]string{\n\t\t\t\"title\":     \"order_title\",\n\t\t\t\"artist\":    \"order_artist_name asc, order_album_name asc, release_date asc, disc_number asc, track_number asc\",\n\t\t\t\"album\":     \"order_album_name asc, release_date asc, disc_number asc, track_number asc, order_artist_name asc, title asc\",\n\t\t\t\"random\":    r.seededRandomSort(),\n\t\t\t\"createdAt\": \"media_file.created_at\",\n\t\t}\n\t}\n\treturn r\n}", "is_vulnerable": 1}
{"code": "\t\tsuite.Run(fmt.Sprintf(\"Case %s\", tc.name), func() {\n\t\t\tsuite.SetupTest(tc.chainID)\n\t\t\tsuite.fundTestnetRewardsAcc(balance)\n\t\t\ttc.malleate()\n\n\t\t\t// create validators\n\t\t\tsuite.setValidators(validatorAddresses)\n\n\t\t\t// check no delegations for validators initially\n\t\t\tinitialDel := suite.getDelegatedTokens(validatorAddresses...)\n\t\t\tsuite.Require().Equal(math.ZeroInt(), initialDel)\n\n\t\t\tif utils.IsMainnet(tc.chainID) {\n\t\t\t\tv11.HandleRewardDistribution(suite.ctx, suite.app.Logger(), suite.app.BankKeeper, *suite.app.StakingKeeper.Keeper, suite.app.DistrKeeper)\n\t\t\t}\n\n\t\t\t// account not in list should NOT get rewards\n\t\t\t// balance should be 0\n\t\t\tbalance := suite.app.BankKeeper.GetBalance(suite.ctx, noRewardAddr, utils.BaseDenom)\n\t\t\tsuite.Require().Equal(math.ZeroInt(), balance.Amount)\n\n\t\t\t// get staked (delegated) tokens - no delegations expected\n\t\t\tdelegated := suite.app.StakingKeeper.GetAllDelegatorDelegations(suite.ctx, noRewardAddr)\n\t\t\tsuite.Require().Empty(delegated)\n\n\t\t\tcommPoolFinalBalance := suite.app.BankKeeper.GetBalance(suite.ctx, communityPool, utils.BaseDenom)\n\t\t\tsuite.Require().Equal(tc.expCommPoolBalance, commPoolFinalBalance.Amount)\n\n\t\t\t// do allocations\n\t\t\tfor i := range v11.Allocations {\n\t\t\t\taddr := sdk.MustAccAddressFromBech32(v11.Allocations[i][0])\n\t\t\t\tvalShare, _ := math.NewIntFromString(v11.Allocations[i][1])\n\n\t\t\t\tbalance := suite.app.BankKeeper.GetBalance(suite.ctx, addr, utils.BaseDenom)\n\t\t\t\tsuite.Require().Equal(math.ZeroInt(), balance.Amount)\n\n\t\t\t\t// get staked (delegated) tokens\n\t\t\t\tdelegated := suite.app.StakingKeeper.GetAllDelegatorDelegations(suite.ctx, addr)\n\t\t\t\tif tc.expectedSuccess {\n\t\t\t\t\t// sum of all delegations should be equal to rewards\n\t\t\t\t\tdelegatedAmt := suite.sumDelegatorDelegations(delegated...)\n\t\t\t\t\tsuite.Require().Equal(valShare, delegatedAmt)\n\t\t\t\t} else {\n\t\t\t\t\tsuite.Require().Empty(delegated)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// check delegation for each validator\n\t\t\ttotalDelegations := math.ZeroInt()\n\t\t\tfor _, v := range validatorAddresses {\n\t\t\t\tdelTokens := suite.getDelegatedTokens(v)\n\t\t\t\tif tc.expectedSuccess {\n\t\t\t\t\t// amount delegated should be equal to sums calculated pre-tests\n\t\t\t\t\tsuite.Require().Equal(validatorDelegations[v], delTokens)\n\t\t\t\t} else {\n\t\t\t\t\tsuite.Require().Equal(math.ZeroInt(), delTokens)\n\t\t\t\t}\n\t\t\t\ttotalDelegations = totalDelegations.Add(delTokens)\n\t\t\t}\n\n\t\t\tif tc.expectedSuccess {\n\t\t\t\t// sum of all delegations should be equal to rewards\n\t\t\t\tsuite.Require().Equal(expRewards, totalDelegations)\n\t\t\t\t// Funding acc balance should be 0 after the rewards distribution\n\t\t\t\tfinalFundingAccBalance := suite.app.BankKeeper.GetBalance(suite.ctx, fundingAcc, utils.BaseDenom)\n\t\t\t\tsuite.Require().Equal(math.NewInt(0), finalFundingAccBalance.Amount)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func TestStrategyLoginAuthentication(t *testing.T) {\n\tcfg := config.NewConfig()\n\tcfg.Auth.Strategy = config.AuthStrategyLogin\n\tcfg.Server.Credentials.Username = \"foo\"\n\tcfg.Server.Credentials.Passphrase = \"bar\"\n\tconfig.Set(cfg)\n\n\tclockTime := time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC)\n\tutil.Clock = util.ClockMock{Time: clockTime}\n\n\trequest := httptest.NewRequest(\"GET\", \"http://kiali/api/authenticate\", nil)\n\trequest.SetBasicAuth(\"foo\", \"bar\")\n\n\tresponseRecorder := httptest.NewRecorder()\n\tAuthenticate(responseRecorder, request)\n\tresponse := responseRecorder.Result()\n\n\tassert.Equal(t, http.StatusOK, response.StatusCode)\n\tassert.Len(t, response.Cookies(), 1)\n\n\tcookie := response.Cookies()[0]\n\tassert.Equal(t, config.TokenCookieName, cookie.Name)\n\tassert.True(t, cookie.HttpOnly)\n\t// assert.Equal(t,, http.SameSiteStrictMode, cookie.SameSite) ** Commented out because unsupported in go < 1.11\n\n\tassert.NotEmpty(t, cookie.Value)\n\tassert.Equal(t, clockTime.Add(time.Second*time.Duration(cfg.LoginToken.ExpirationSeconds)), cookie.Expires)\n}", "is_vulnerable": 1}
{"code": "func getKubernetesSwagger(kubeSwaggerPath string) spec.Definitions {\n\tdata, err := ioutil.ReadFile(kubeSwaggerPath)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tswagger := &spec.Swagger{}\n\terr = json.Unmarshal(data, swagger)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn swagger.Definitions\n}", "is_vulnerable": 1}
{"code": "func createChaincodeProposalWithTxIDNonceAndTransient(txid string, typ common.HeaderType, channelID string, cis *peer.ChaincodeInvocationSpec, nonce, creator []byte, transientMap map[string][]byte, needTime *timestamppb.Timestamp) (*peer.Proposal, string, error) {\n\tccHdrExt := &peer.ChaincodeHeaderExtension{ChaincodeId: cis.ChaincodeSpec.ChaincodeId}\n\tccHdrExtBytes, err := proto.Marshal(ccHdrExt)\n\tif err != nil {\n\t\treturn nil, \"\", errors.Wrap(err, \"error marshaling ChaincodeHeaderExtension\")\n\t}\n\n\tcisBytes, err := proto.Marshal(cis)\n\tif err != nil {\n\t\treturn nil, \"\", errors.Wrap(err, \"error marshaling ChaincodeInvocationSpec\")\n\t}\n\n\tccPropPayload := &peer.ChaincodeProposalPayload{Input: cisBytes, TransientMap: transientMap}\n\tccPropPayloadBytes, err := proto.Marshal(ccPropPayload)\n\tif err != nil {\n\t\treturn nil, \"\", errors.Wrap(err, \"error marshaling ChaincodeProposalPayload\")\n\t}\n\n\thdr := &common.Header{\n\t\tChannelHeader: protoutil.MarshalOrPanic(\n\t\t\t&common.ChannelHeader{\n\t\t\t\tType:      int32(typ),\n\t\t\t\tTxId:      txid,\n\t\t\t\tTimestamp: needTime,\n\t\t\t\tChannelId: channelID,\n\t\t\t\tExtension: ccHdrExtBytes,\n\t\t\t\tEpoch:     0,\n\t\t\t},\n\t\t),\n\t\tSignatureHeader: protoutil.MarshalOrPanic(\n\t\t\t&common.SignatureHeader{\n\t\t\t\tNonce:   nonce,\n\t\t\t\tCreator: creator,\n\t\t\t},\n\t\t),\n\t}\n\n\thdrBytes, err := proto.Marshal(hdr)\n\tif err != nil {\n\t\treturn nil, \"\", err\n\t}\n\n\tprop := &peer.Proposal{\n\t\tHeader:  hdrBytes,\n\t\tPayload: ccPropPayloadBytes,\n\t}\n\treturn prop, txid, nil\n}", "is_vulnerable": 0}
{"code": "func (s *Server) getAppEnforceRBAC(ctx context.Context, action, project, namespace, name string, getApp func() (*appv1.Application, error)) (*appv1.Application, error) {\n\tlogCtx := log.WithFields(map[string]interface{}{\n\t\t\"application\": name,\n\t\t\"namespace\":   namespace,\n\t})\n\tif project != \"\" {\n\t\t// The user has provided everything we need to perform an initial RBAC check.\n\t\tgivenRBACName := security.RBACName(s.ns, project, namespace, name)\n\t\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceApplications, action, givenRBACName); err != nil {\n\t\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\t\"project\":                project,\n\t\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t\t}).Warnf(\"user tried to %s application which they do not have access to: %s\", action, err)\n\t\t\t// Do a GET on the app. This ensures that the timing of a \"no access\" response is the same as a \"yes access,\n\t\t\t// but the app is in a different project\" response. We don't want the user inferring the existence of the\n\t\t\t// app from response time.\n\t\t\t_, _ = getApp()\n\t\t\treturn nil, permissionDeniedErr\n\t\t}\n\t}\n\ta, err := getApp()\n\tif err != nil {\n\t\tif apierr.IsNotFound(err) {\n\t\t\tif project != \"\" {\n\t\t\t\t// We know that the user was allowed to get the Application, but the Application does not exist. Return 404.\n\t\t\t\treturn nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t\t\t}\n\t\t\t// We don't know if the user was allowed to get the Application, and we don't want to leak information about\n\t\t\t// the Application's existence. Return 403.\n\t\t\tlogCtx.Warn(\"application does not exist\")\n\t\t\treturn nil, permissionDeniedErr\n\t\t}\n\t\tlogCtx.Errorf(\"failed to get application: %s\", err)\n\t\treturn nil, permissionDeniedErr\n\t}\n\t// Even if we performed an initial RBAC check (because the request was fully parameterized), we still need to\n\t// perform a second RBAC check to ensure that the user has access to the actual Application's project (not just the\n\t// project they specified in the request).\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceApplications, action, a.RBACName(s.ns)); err != nil {\n\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\"project\":                a.Spec.Project,\n\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t}).Warnf(\"user tried to %s application which they do not have access to: %s\", action, err)\n\t\tif project != \"\" {\n\t\t\t// The user specified a project. We would have returned a 404 if the user had access to the app, but the app\n\t\t\t// did not exist. So we have to return a 404 when the app does exist, but the user does not have access.\n\t\t\t// Otherwise, they could infer that the app exists based on the error code.\n\t\t\treturn nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t\t}\n\t\t// The user didn't specify a project. We always return permission denied for both lack of access and lack of\n\t\t// existence.\n\t\treturn nil, permissionDeniedErr\n\t}\n\teffectiveProject := \"default\"\n\tif a.Spec.Project != \"\" {\n\t\teffectiveProject = a.Spec.Project\n\t}\n\tif project != \"\" && effectiveProject != project {\n\t\tlogCtx.WithFields(map[string]interface{}{\n\t\t\t\"project\":                a.Spec.Project,\n\t\t\targocommon.SecurityField: argocommon.SecurityMedium,\n\t\t}).Warnf(\"user tried to %s application in project %s, but the application is in project %s\", action, project, effectiveProject)\n\t\t// The user has access to the app, but the app is in a different project. Return 404, meaning \"app doesn't\n\t\t// exist in that project\".\n\t\treturn nil, status.Errorf(codes.NotFound, apierr.NewNotFound(schema.GroupResource{Group: \"argoproj.io\", Resource: \"applications\"}, name).Error())\n\t}\n\treturn a, nil\n}", "is_vulnerable": 1}
{"code": "func (b *FakeBackups) Create(\n\tmeta *backups.Metadata,\n\tpaths *backups.Paths,\n\tdbInfo *backups.DBInfo,\n) (string, error) {\n\tb.Calls = append(b.Calls, \"Create\")\n\n\tb.PathsArg = paths\n\tb.DBInfoArg = dbInfo\n\tb.MetaArg = meta\n\n\tif b.Meta != nil {\n\t\t*meta = *b.Meta\n\t}\n\n\treturn b.Filename, b.Error\n}", "is_vulnerable": 1}
{"code": "func isEmpty(object interface{}) bool {\n\n\t// get nil case out of the way\n\tif object == nil {\n\t\treturn true\n\t}\n\n\tobjValue := reflect.ValueOf(object)\n\n\tswitch objValue.Kind() {\n\t// collection types are empty when they have no element\n\tcase reflect.Array, reflect.Chan, reflect.Map, reflect.Slice:\n\t\treturn objValue.Len() == 0\n\t\t// pointers are empty if nil or if the value they point to is empty\n\tcase reflect.Ptr:\n\t\tif objValue.IsNil() {\n\t\t\treturn true\n\t\t}\n\t\tderef := objValue.Elem().Interface()\n\t\treturn isEmpty(deref)\n\t\t// for all other types, compare against the zero value\n\tdefault:\n\t\tzero := reflect.Zero(objValue.Type())\n\t\treturn reflect.DeepEqual(object, zero.Interface())\n\t}\n}", "is_vulnerable": 0}
{"code": "func forwardToProxy(incoming, outgoing *http.Request) {\n\tproxyURL := &url.URL{\n\t\tScheme: outgoing.URL.Scheme,\n\t\tHost:   outgoing.URL.Host,\n\t}\n\n\toutgoing.URL.Host = incoming.Host\n\toutgoing.URL.Scheme = schemeFromRequest(incoming)\n\n\toutgoing.Header.Set(backendIsProxyHeader, proxyURL.String())\n}", "is_vulnerable": 1}
{"code": "func newDiffNormalizer(ignore []v1alpha1.ResourceIgnoreDifferences, overrides map[string]v1alpha1.ResourceOverride, opts normalizers.IgnoreNormalizerOpts) (diff.Normalizer, error) {\n\tignoreNormalizer, err := normalizers.NewIgnoreNormalizer(ignore, overrides, opts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tknownTypesNorm, err := normalizers.NewKnownTypesNormalizer(overrides)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &composableNormalizer{normalizers: []diff.Normalizer{ignoreNormalizer, knownTypesNorm}}, nil\n}", "is_vulnerable": 0}
{"code": "func (fs *Filesystem) CompressFiles(dir string, paths []string) (os.FileInfo, error) {\n\tcleanedRootDir, err := fs.SafePath(dir)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Take all the paths passed in and merge them together with the root directory we've gotten.\n\tfor i, p := range paths {\n\t\tpaths[i] = filepath.Join(cleanedRootDir, p)\n\t}\n\n\tcleaned, err := fs.ParallelSafePath(paths)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ta := &Archive{BasePath: cleanedRootDir, Files: cleaned}\n\td := path.Join(\n\t\tcleanedRootDir,\n\t\tfmt.Sprintf(\"archive-%s.tar.gz\", strings.ReplaceAll(time.Now().Format(time.RFC3339), \":\", \"\")),\n\t)\n\n\tif err := a.Create(context.Background(), d); err != nil {\n\t\treturn nil, err\n\t}\n\n\tf, err := os.Stat(d)\n\tif err != nil {\n\t\t_ = os.Remove(d)\n\t\treturn nil, err\n\t}\n\n\tif err := fs.HasSpaceFor(f.Size()); err != nil {\n\t\t_ = os.Remove(d)\n\t\treturn nil, err\n\t}\n\n\tfs.addDisk(f.Size())\n\n\treturn f, nil\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) WebsiteRemove(ctx context.Context, in *clientpb.Website, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/WebsiteRemove\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (f *Framework) newIngressController(namespace string, namespaceOverlay string) error {\n\t// Creates an nginx deployment\n\tisChroot, ok := os.LookupEnv(\"IS_CHROOT\")\n\tif !ok {\n\t\tisChroot = \"false\"\n\t}\n\tcmd := exec.Command(\"./wait-for-nginx.sh\", namespace, namespaceOverlay, isChroot)\n\tout, err := cmd.CombinedOutput()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unexpected error waiting for ingress controller deployment: %v.\\nLogs:\\n%v\", err, string(out))\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (mr *MockRequesterMockRecorder) GetGrantedAudience() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetGrantedAudience\", reflect.TypeOf((*MockRequester)(nil).GetGrantedAudience))\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn sslpt{r: r,\n\t\tannotationConfig: sslPassthroughAnnotations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func setTA(h RR_Header, c chan lex, o, f string) (RR, *ParseError, string) {\n\trr := new(TA)\n\trr.Hdr = h\n\n\tl := <-c\n\tif l.length == 0 { // dynamic update rr.\n\t\treturn rr, nil, l.comment\n\t}\n\n\ti, e := strconv.ParseUint(l.token, 10, 16)\n\tif e != nil || l.err {\n\t\treturn nil, &ParseError{f, \"bad TA KeyTag\", l}, \"\"\n\t}\n\trr.KeyTag = uint16(i)\n\t<-c // zBlank\n\tl = <-c\n\tif i, e := strconv.ParseUint(l.token, 10, 8); e != nil {\n\t\ti, ok := StringToAlgorithm[l.tokenUpper]\n\t\tif !ok || l.err {\n\t\t\treturn nil, &ParseError{f, \"bad TA Algorithm\", l}, \"\"\n\t\t}\n\t\trr.Algorithm = i\n\t} else {\n\t\trr.Algorithm = uint8(i)\n\t}\n\t<-c // zBlank\n\tl = <-c\n\ti, e = strconv.ParseUint(l.token, 10, 8)\n\tif e != nil || l.err {\n\t\treturn nil, &ParseError{f, \"bad TA DigestType\", l}, \"\"\n\t}\n\trr.DigestType = uint8(i)\n\ts, e, c1 := endingToString(c, \"bad TA Digest\", f)\n\tif e != nil {\n\t\treturn nil, e.(*ParseError), c1\n\t}\n\trr.Digest = s\n\treturn rr, nil, c1\n}", "is_vulnerable": 1}
{"code": "func (l fnlogger) Error(err error, msg string, kvList ...interface{}) {\n\tprefix, args := l.FormatError(err, msg, kvList)\n\tl.write(prefix, args)\n}", "is_vulnerable": 1}
{"code": "func VerifyGet(cfg schema.AuthenticationBackendConfiguration) middlewares.RequestHandler {\n\trefreshProfile, refreshProfileInterval := getProfileRefreshSettings(cfg)\n\n\treturn func(ctx *middlewares.AutheliaCtx) {\n\t\tctx.Logger.Tracef(\"Headers=%s\", ctx.Request.Header.String())\n\t\ttargetURL, err := ctx.GetOriginalURL()\n\n\t\tif err != nil {\n\t\t\tctx.Error(fmt.Errorf(\"Unable to parse target URL: %s\", err), operationFailedMessage)\n\t\t\treturn\n\t\t}\n\n\t\tif !isSchemeHTTPS(targetURL) && !isSchemeWSS(targetURL) {\n\t\t\tctx.Logger.Error(fmt.Errorf(\"Scheme of target URL %s must be secure since cookies are \"+\n\t\t\t\t\"only transported over a secure connection for security reasons\", targetURL.String()))\n\t\t\tctx.ReplyUnauthorized()\n\n\t\t\treturn\n\t\t}\n\n\t\tif !isURLUnderProtectedDomain(targetURL, ctx.Configuration.Session.Domain) {\n\t\t\tctx.Logger.Error(fmt.Errorf(\"The target URL %s is not under the protected domain %s\",\n\t\t\t\ttargetURL.String(), ctx.Configuration.Session.Domain))\n\t\t\tctx.ReplyUnauthorized()\n\n\t\t\treturn\n\t\t}\n\n\t\tisBasicAuth, username, name, groups, emails, authLevel, err := verifyAuth(ctx, targetURL, refreshProfile, refreshProfileInterval)\n\n\t\tmethod := ctx.XForwardedMethod()\n\n\t\tif err != nil {\n\t\t\tctx.Logger.Error(fmt.Sprintf(\"Error caught when verifying user authorization: %s\", err))\n\n\t\t\tif err := updateActivityTimestamp(ctx, isBasicAuth, username); err != nil {\n\t\t\t\tctx.Error(fmt.Errorf(\"Unable to update last activity: %s\", err), operationFailedMessage)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\thandleUnauthorized(ctx, targetURL, isBasicAuth, username, method)\n\n\t\t\treturn\n\t\t}\n\n\t\tauthorized := isTargetURLAuthorized(ctx.Providers.Authorizer, *targetURL, username,\n\t\t\tgroups, ctx.RemoteIP(), method, authLevel)\n\n\t\tswitch authorized {\n\t\tcase Forbidden:\n\t\t\tctx.Logger.Infof(\"Access to %s is forbidden to user %s\", targetURL.String(), username)\n\t\t\tctx.ReplyForbidden()\n\t\tcase NotAuthorized:\n\t\t\thandleUnauthorized(ctx, targetURL, isBasicAuth, username, method)\n\t\tcase Authorized:\n\t\t\tsetForwardedHeaders(&ctx.Response.Header, username, name, groups, emails)\n\t\t}\n\n\t\tif err := updateActivityTimestamp(ctx, isBasicAuth, username); err != nil {\n\t\t\tctx.Error(fmt.Errorf(\"Unable to update last activity: %s\", err), operationFailedMessage)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestLoadBalancerServiceChangedScopeNeedsRecreate(t *testing.T) {\n\ttestCases := []struct {\n\t\tplatform configv1.PlatformType\n\t\texpect   bool\n\t}{\n\t\t{platform: configv1.AWSPlatformType, expect: true},\n\t\t{platform: configv1.AzurePlatformType, expect: false},\n\t\t{platform: configv1.GCPPlatformType, expect: false},\n\t\t{platform: configv1.IBMCloudPlatformType, expect: true},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tplatformStatus := &configv1.PlatformStatus{Type: tc.platform}\n\t\toriginal := corev1.Service{\n\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\tAnnotations: map[string]string{},\n\t\t\t\tNamespace:   \"openshift-ingress\",\n\t\t\t\tName:        \"router-original\",\n\t\t\t},\n\t\t}\n\t\tinternal := original.DeepCopy()\n\t\textAnnotations := externalLBAnnotations[platformStatus.Type]\n\t\tfor name, value := range extAnnotations {\n\t\t\toriginal.Annotations[name] = value\n\t\t}\n\t\tintAnnotations := InternalLBAnnotations[platformStatus.Type]\n\t\tfor name, value := range intAnnotations {\n\t\t\tinternal.Annotations[name] = value\n\t\t}\n\t\tif changed, updated, needsRecreate := loadBalancerServiceChanged(&original, internal, platformStatus); needsRecreate != tc.expect {\n\t\t\tt.Errorf(\"on platform %s, when setting internal scope, expected loadBalancerServiceChanged to return needsRecreate=%t, got %t\", tc.platform, tc.expect, needsRecreate)\n\t\t} else if !changed {\n\t\t\tt.Errorf(\"on platform %s, when setting internal scope, expected loadBalancerServiceChanged to return changed=%t, got %t\", tc.platform, true, changed)\n\t\t} else {\n\t\t\tfor name, value := range intAnnotations {\n\t\t\t\tif err := checkServiceHasAnnotation(updated, name, true, value); err != nil {\n\t\t\t\t\tt.Errorf(\"on platform %s, when setting internal scope, %v\", tc.platform, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif changed, updated, needsRecreate := loadBalancerServiceChanged(internal, &original, platformStatus); needsRecreate != tc.expect {\n\t\t\tt.Errorf(\"on platform %s, when setting external scope, expected loadBalancerServiceChanged to return needsRecreate=%t, got %t\", tc.platform, tc.expect, needsRecreate)\n\t\t} else if !changed {\n\t\t\tt.Errorf(\"on platform %s, when setting external scope, expected loadBalancerServiceChanged to return changed=%t, got %t\", tc.platform, true, changed)\n\t\t} else {\n\t\t\tfor name, value := range extAnnotations {\n\t\t\t\tif err := checkServiceHasAnnotation(updated, name, true, value); err != nil {\n\t\t\t\t\tt.Errorf(\"on platform %s, when setting external scope, %v\", tc.platform, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e *Entity) UnmarshalJSON(data []byte) error {\n\terrorTemplate := \"Deserializing error: %v\"\n\n\tprops := map[string]interface{}{}\n\terr := json.Unmarshal(data, &props)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// deselialize metadata\n\te.OdataMetadata = stringFromMap(props, \"odata.metadata\")\n\te.OdataType = stringFromMap(props, \"odata.type\")\n\te.OdataID = stringFromMap(props, \"odata.id\")\n\te.OdataEtag = stringFromMap(props, \"odata.etag\")\n\te.OdataEditLink = stringFromMap(props, \"odata.editLink\")\n\te.PartitionKey = stringFromMap(props, partitionKeyNode)\n\te.RowKey = stringFromMap(props, rowKeyNode)\n\n\t// deserialize timestamp\n\ttimeStamp, ok := props[\"Timestamp\"]\n\tif ok {\n\t\tstr, ok := timeStamp.(string)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(errorTemplate, \"Timestamp casting error\")\n\t\t}\n\t\tt, err := time.Parse(time.RFC3339Nano, str)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(errorTemplate, err)\n\t\t}\n\t\te.TimeStamp = t\n\t}\n\tdelete(props, \"Timestamp\")\n\tdelete(props, \"Timestamp@odata.type\")\n\n\t// deserialize entity (user defined fields)\n\tfor k, v := range props {\n\t\tif strings.HasSuffix(k, OdataTypeSuffix) {\n\t\t\tvalueKey := strings.TrimSuffix(k, OdataTypeSuffix)\n\t\t\tstr, ok := props[valueKey].(string)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(errorTemplate, fmt.Sprintf(\"%v casting error\", v))\n\t\t\t}\n\t\t\tswitch v {\n\t\t\tcase OdataBinary:\n\t\t\t\tprops[valueKey], err = base64.StdEncoding.DecodeString(str)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(errorTemplate, err)\n\t\t\t\t}\n\t\t\tcase OdataDateTime:\n\t\t\t\tt, err := time.Parse(\"2006-01-02T15:04:05Z\", str)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(errorTemplate, err)\n\t\t\t\t}\n\t\t\t\tprops[valueKey] = t\n\t\t\tcase OdataGUID:\n\t\t\t\tprops[valueKey] = uuid.FromStringOrNil(str)\n\t\t\tcase OdataInt64:\n\t\t\t\ti, err := strconv.ParseInt(str, 10, 64)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(errorTemplate, err)\n\t\t\t\t}\n\t\t\t\tprops[valueKey] = i\n\t\t\tcase OdataDouble:\n\t\t\t\tf, err := strconv.ParseFloat(str, 64)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(errorTemplate, err)\n\t\t\t\t}\n\t\t\t\tprops[valueKey] = f\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(errorTemplate, fmt.Sprintf(\"%v is not supported\", v))\n\t\t\t}\n\t\t\tdelete(props, k)\n\t\t}\n\t}\n\n\te.Properties = props\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (r *playlistRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\treturn r.CountAll(r.parseRestOptions(r.ctx, options...))\n}", "is_vulnerable": 0}
{"code": "func (e errorTranslateSampleAndChunkQueryable) Querier(ctx context.Context, mint, maxt int64) (storage.Querier, error) {\n\tq, err := e.q.Querier(ctx, mint, maxt)\n\treturn errorTranslateQuerier{q: q, fn: e.fn}, e.fn(err)\n}", "is_vulnerable": 0}
{"code": "func (m *ContainsNestedMap_NestedMap) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMap: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NestedMap: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NestedMapField\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.NestedMapField == nil {\n\t\t\t\tm.NestedMapField = make(map[string]float64)\n\t\t\t}\n\t\t\tvar mapkey string\n\t\t\tvar mapvalue float64\n\t\t\tfor iNdEx < postIndex {\n\t\t\t\tentryPreIndex := iNdEx\n\t\t\t\tvar wire uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfieldNum := int32(wire >> 3)\n\t\t\t\tif fieldNum == 1 {\n\t\t\t\t\tvar stringLenmapkey uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowTheproto3\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tstringLenmapkey |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tintStringLenmapkey := int(stringLenmapkey)\n\t\t\t\t\tif intStringLenmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tpostStringIndexmapkey := iNdEx + intStringLenmapkey\n\t\t\t\t\tif postStringIndexmapkey < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif postStringIndexmapkey > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapkey = string(dAtA[iNdEx:postStringIndexmapkey])\n\t\t\t\t\tiNdEx = postStringIndexmapkey\n\t\t\t\t} else if fieldNum == 2 {\n\t\t\t\t\tvar mapvaluetemp uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tmapvaluetemp = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tmapvalue = math.Float64frombits(mapvaluetemp)\n\t\t\t\t} else {\n\t\t\t\t\tiNdEx = entryPreIndex\n\t\t\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif skippy < 0 {\n\t\t\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t\t\t}\n\t\t\t\t\tif (iNdEx + skippy) > postIndex {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tiNdEx += skippy\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.NestedMapField[mapkey] = mapvalue\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipTheproto3(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthTheproto3\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (c *VerifyCommand) Exec(ctx context.Context, images []string) (err error) {\n\tif len(images) == 0 {\n\t\treturn flag.ErrHelp\n\t}\n\n\tswitch c.Attachment {\n\tcase \"sbom\", \"\":\n\t\tbreak\n\tdefault:\n\t\treturn flag.ErrHelp\n\t}\n\n\t// always default to sha256 if the algorithm hasn't been explicitly set\n\tif c.HashAlgorithm == 0 {\n\t\tc.HashAlgorithm = crypto.SHA256\n\t}\n\n\tif !options.OneOf(c.KeyRef, c.CertRef, c.Sk) && !options.EnableExperimental() {\n\t\treturn &options.KeyParseError{}\n\t}\n\tociremoteOpts, err := c.ClientOpts(ctx)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"constructing client options\")\n\t}\n\tco := &cosign.CheckOpts{\n\t\tAnnotations:        c.Annotations.Annotations,\n\t\tRegistryClientOpts: ociremoteOpts,\n\t\tCertEmail:          c.CertEmail,\n\t\tCertOidcIssuer:     c.CertOidcIssuer,\n\t\tSignatureRef:       c.SignatureRef,\n\t}\n\tif c.CheckClaims {\n\t\tco.ClaimVerifier = cosign.SimpleClaimVerifier\n\t}\n\tif options.EnableExperimental() {\n\t\tif c.RekorURL != \"\" {\n\t\t\trekorClient, err := rekor.NewClient(c.RekorURL)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"creating Rekor client\")\n\t\t\t}\n\t\t\tco.RekorClient = rekorClient\n\t\t}\n\t\tco.RootCerts = fulcio.GetRoots()\n\t}\n\tkeyRef := c.KeyRef\n\tcertRef := c.CertRef\n\n\t// Keys are optional!\n\tvar pubKey signature.Verifier\n\tswitch {\n\tcase keyRef != \"\":\n\t\tpubKey, err = sigs.PublicKeyFromKeyRefWithHashAlgo(ctx, keyRef, c.HashAlgorithm)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"loading public key\")\n\t\t}\n\t\tpkcs11Key, ok := pubKey.(*pkcs11key.Key)\n\t\tif ok {\n\t\t\tdefer pkcs11Key.Close()\n\t\t}\n\tcase c.Sk:\n\t\tsk, err := pivkey.GetKeyWithSlot(c.Slot)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"opening piv token\")\n\t\t}\n\t\tdefer sk.Close()\n\t\tpubKey, err = sk.Verifier()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"initializing piv token verifier\")\n\t\t}\n\tcase certRef != \"\":\n\t\tcert, err := loadCertFromFileOrURL(c.CertRef)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpubKey, err = signature.LoadECDSAVerifier(cert.PublicKey.(*ecdsa.PublicKey), crypto.SHA256)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tco.SigVerifier = pubKey\n\n\t// NB: There are only 2 kinds of verification right now:\n\t// 1. You gave us the public key explicitly to verify against so co.SigVerifier is non-nil or,\n\t// 2. We're going to find an x509 certificate on the signature and verify against Fulcio root trust\n\t// TODO(nsmith5): Refactor this verification logic to pass back _how_ verification\n\t// was performed so we don't need to use this fragile logic here.\n\tfulcioVerified := (co.SigVerifier == nil)\n\n\tfor _, img := range images {\n\t\tif c.LocalImage {\n\t\t\tverified, bundleVerified, err := cosign.VerifyLocalImageSignatures(ctx, img, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tPrintVerificationHeader(img, co, bundleVerified, fulcioVerified)\n\t\t\tPrintVerification(img, verified, c.Output)\n\t\t} else {\n\t\t\tref, err := name.ParseReference(img)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"parsing reference\")\n\t\t\t}\n\t\t\tref, err = sign.GetAttachedImageRef(ref, c.Attachment, ociremoteOpts...)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrapf(err, \"resolving attachment type %s for image %s\", c.Attachment, img)\n\t\t\t}\n\n\t\t\tverified, bundleVerified, err := cosign.VerifyImageSignatures(ctx, ref, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tPrintVerificationHeader(ref.Name(), co, bundleVerified, fulcioVerified)\n\t\t\tPrintVerification(ref.Name(), verified, c.Output)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func PushTag(dir, tagName string) error {\n\tr, err := git.PlainOpen(dir)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// force remote URL to be https, using git@ requires ssh keys and we default to using basic auth\n\tremote, err := r.Remote(\"origin\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tgitURL, err := ParseGitURL(remote.Config().URLs[0])\n\tif err != nil {\n\t\treturn err\n\t}\n\tremoteURL := fmt.Sprintf(\"https://github.com/%s/%s.git\", gitURL.Organisation, gitURL.Name)\n\n\tpo := &git.PushOptions{\n\t\tRemoteName: \"origin\",\n\t\tRemoteURL:  remoteURL,\n\t\tRefSpecs:   []config.RefSpec{config.RefSpec(fmt.Sprintf(\"refs/tags/%s:refs/tags/%s\", tagName, tagName))},\n\t\tAuth:       GetGitAuth(),\n\t}\n\n\terr = r.Push(po)\n\n\tif err != nil {\n\t\tif err == git.NoErrAlreadyUpToDate {\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"failed to push tag: %w\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *MockAuthorizeRequester) GetGrantedAudience() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetGrantedAudience\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func validateInvalidPostIndex(\n\tctx context.Context,\n\tlogger log.Log,\n\tdb sql.Executor,\n\tedVerifier SigVerifier,\n\tpostVerifier postVerifier,\n\tproof *wire.InvalidPostIndexProof,\n) (types.NodeID, error) {\n\tatx := &proof.Atx\n\tif !edVerifier.Verify(signing.ATX, atx.SmesherID, atx.SignedBytes(), atx.Signature) {\n\t\treturn types.EmptyNodeID, errors.New(\"invalid signature\")\n\t}\n\tcommitmentAtx := atx.CommitmentATX\n\tif commitmentAtx == nil {\n\t\tatx, err := atxs.CommitmentATX(db, atx.SmesherID)\n\t\tif err != nil {\n\t\t\treturn types.EmptyNodeID, fmt.Errorf(\"getting commitment ATX: %w\", err)\n\t\t}\n\t\tcommitmentAtx = &atx\n\t}\n\tpost := (*shared.Proof)(atx.NIPost.Post)\n\tmeta := &shared.ProofMetadata{\n\t\tNodeId:          atx.SmesherID[:],\n\t\tCommitmentAtxId: commitmentAtx[:],\n\t\tNumUnits:        atx.NumUnits,\n\t\tChallenge:       atx.NIPost.PostMetadata.Challenge,\n\t\tLabelsPerUnit:   atx.NIPost.PostMetadata.LabelsPerUnit,\n\t}\n\tif err := postVerifier.Verify(\n\t\tctx,\n\t\tpost,\n\t\tmeta,\n\t\tverifying.SelectedIndex(int(proof.InvalidIdx)),\n\t); err != nil {\n\t\treturn atx.SmesherID, nil\n\t}\n\tnumInvalidProofsPostIndex.Inc()\n\treturn types.EmptyNodeID, errors.New(\"invalid post index malfeasance proof - POST is valid\")\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Rename(ctx context.Context, in *clientpb.RenameReq, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_Rename_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (n *selfnotoken) Run(t *testing.T, ctx context.Context) {\n\tn.daprd.WaitUntilRunning(t, ctx)\n\n\tclient := testpb.NewTestServiceClient(n.daprd.GRPCConn(t, ctx))\n\tctx = metadata.AppendToOutgoingContext(ctx, \"dapr-app-id\", n.daprd.AppID())\n\t_, err := client.Ping(ctx, new(testpb.PingRequest))\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase md := <-n.ch:\n\t\trequire.Empty(t, md.Get(\"dapr-api-token\"))\n\tcase <-time.After(5 * time.Second):\n\t\tassert.Fail(t, \"timed out waiting for metadata\")\n\t}\n\n\tdclient := n.daprd.GRPCClient(t, ctx)\n\t_, err = dclient.InvokeService(ctx, &runtimev1.InvokeServiceRequest{\n\t\tId: n.daprd.AppID(),\n\t\tMessage: &commonv1.InvokeRequest{\n\t\t\tMethod:        \"helloworld\",\n\t\t\tData:          new(anypb.Any),\n\t\t\tHttpExtension: &commonv1.HTTPExtension{Verb: commonv1.HTTPExtension_GET},\n\t\t},\n\t})\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase md := <-n.ch:\n\t\trequire.Empty(t, md.Get(\"dapr-api-token\"))\n\tcase <-time.After(5 * time.Second):\n\t\tassert.Fail(t, \"timed out waiting for metadata\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAppNamespaceRestrictions(t *testing.T) {\n\tt.Run(\"List applications in controller namespace\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\tappServer := newTestAppServer(t, testApp)\n\t\tapps, err := appServer.List(context.TODO(), &application.ApplicationQuery{})\n\t\trequire.NoError(t, err)\n\t\trequire.Len(t, apps.Items, 1)\n\t})\n\n\tt.Run(\"List applications with non-allowed apps existing\", func(t *testing.T) {\n\t\ttestApp1 := newTestApp()\n\t\ttestApp1.Namespace = \"argocd-1\"\n\t\tappServer := newTestAppServer(t, testApp1)\n\t\tapps, err := appServer.List(context.TODO(), &application.ApplicationQuery{})\n\t\trequire.NoError(t, err)\n\t\trequire.Len(t, apps.Items, 0)\n\t})\n\n\tt.Run(\"List applications with non-allowed apps existing and explicit ns request\", func(t *testing.T) {\n\t\ttestApp1 := newTestApp()\n\t\ttestApp2 := newTestApp()\n\t\ttestApp2.Namespace = \"argocd-1\"\n\t\tappServer := newTestAppServer(t, testApp1, testApp2)\n\t\tapps, err := appServer.List(context.TODO(), &application.ApplicationQuery{AppNamespace: pointer.String(\"argocd-1\")})\n\t\trequire.NoError(t, err)\n\t\trequire.Len(t, apps.Items, 0)\n\t})\n\n\tt.Run(\"List applications with allowed apps in other namespaces\", func(t *testing.T) {\n\t\ttestApp1 := newTestApp()\n\t\ttestApp1.Namespace = \"argocd-1\"\n\t\tappServer := newTestAppServer(t, testApp1)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tapps, err := appServer.List(context.TODO(), &application.ApplicationQuery{})\n\t\trequire.NoError(t, err)\n\t\trequire.Len(t, apps.Items, 1)\n\t})\n\n\tt.Run(\"Get application in control plane namespace\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\tappServer := newTestAppServer(t, testApp)\n\t\tapp, err := appServer.Get(context.TODO(), &application.ApplicationQuery{\n\t\t\tName: pointer.String(\"test-app\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tassert.Equal(t, \"test-app\", app.GetName())\n\t})\n\tt.Run(\"Get application in other namespace when forbidden\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\tappServer := newTestAppServer(t, testApp)\n\t\tapp, err := appServer.Get(context.TODO(), &application.ApplicationQuery{\n\t\t\tName:         pointer.String(\"test-app\"),\n\t\t\tAppNamespace: pointer.String(\"argocd-1\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\trequire.ErrorContains(t, err, \"permission denied\")\n\t\trequire.Nil(t, app)\n\t})\n\tt.Run(\"Get application in other namespace when allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-1\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tapp, err := appServer.Get(context.TODO(), &application.ApplicationQuery{\n\t\t\tName:         pointer.String(\"test-app\"),\n\t\t\tAppNamespace: pointer.String(\"argocd-1\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, app)\n\t\trequire.Equal(t, \"argocd-1\", app.Namespace)\n\t\trequire.Equal(t, \"test-app\", app.Name)\n\t})\n\tt.Run(\"Get application in other namespace when project is not allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-2\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tapp, err := appServer.Get(context.TODO(), &application.ApplicationQuery{\n\t\t\tName:         pointer.String(\"test-app\"),\n\t\t\tAppNamespace: pointer.String(\"argocd-1\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\trequire.Nil(t, app)\n\t\trequire.ErrorContains(t, err, \"app is not allowed in project\")\n\t})\n\tt.Run(\"Create application in other namespace when allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-1\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tapp, err := appServer.Create(context.TODO(), &application.ApplicationCreateRequest{\n\t\t\tApplication: testApp,\n\t\t})\n\t\trequire.NoError(t, err)\n\t\trequire.NotNil(t, app)\n\t\tassert.Equal(t, \"test-app\", app.Name)\n\t\tassert.Equal(t, \"argocd-1\", app.Namespace)\n\t})\n\n\tt.Run(\"Create application in other namespace when not allowed by project\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tapp, err := appServer.Create(context.TODO(), &application.ApplicationCreateRequest{\n\t\t\tApplication: testApp,\n\t\t})\n\t\trequire.Error(t, err)\n\t\trequire.Nil(t, app)\n\t\trequire.ErrorContains(t, err, \"app is not allowed in project\")\n\t})\n\n\tt.Run(\"Create application in other namespace when not allowed by configuration\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-1\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-2\"}\n\t\tapp, err := appServer.Create(context.TODO(), &application.ApplicationCreateRequest{\n\t\t\tApplication: testApp,\n\t\t})\n\t\trequire.Error(t, err)\n\t\trequire.Nil(t, app)\n\t\trequire.ErrorContains(t, err, \"namespace 'argocd-1' is not permitted\")\n\t})\n\tt.Run(\"Get application sync window in other namespace when project is allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-1\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tactive, err := appServer.GetApplicationSyncWindows(context.TODO(), &application.ApplicationSyncWindowsQuery{Name: &testApp.Name, AppNamespace: &testApp.Namespace})\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, 0, len(active.ActiveWindows))\n\t})\n\tt.Run(\"Get application sync window in other namespace when project is not allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-2\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tactive, err := appServer.GetApplicationSyncWindows(context.TODO(), &application.ApplicationSyncWindowsQuery{Name: &testApp.Name, AppNamespace: &testApp.Namespace})\n\t\trequire.Error(t, err)\n\t\trequire.Nil(t, active)\n\t\trequire.ErrorContains(t, err, \"app is not allowed in project\")\n\t})\n\tt.Run(\"Get list of links in other namespace when project is not allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-2\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tlinks, err := appServer.ListLinks(context.TODO(), &application.ListAppLinksRequest{\n\t\t\tName:      pointer.String(\"test-app\"),\n\t\t\tNamespace: pointer.String(\"argocd-1\"),\n\t\t})\n\t\trequire.Error(t, err)\n\t\trequire.Nil(t, links)\n\t\trequire.ErrorContains(t, err, \"app is not allowed in project\")\n\t})\n\tt.Run(\"Get list of links in other namespace when project is allowed\", func(t *testing.T) {\n\t\ttestApp := newTestApp()\n\t\ttestApp.Namespace = \"argocd-1\"\n\t\ttestApp.Spec.Project = \"other-ns\"\n\t\totherNsProj := &appsv1.AppProject{\n\t\t\tObjectMeta: metav1.ObjectMeta{Name: \"other-ns\", Namespace: \"default\"},\n\t\t\tSpec: appsv1.AppProjectSpec{\n\t\t\t\tSourceRepos:      []string{\"*\"},\n\t\t\t\tDestinations:     []appsv1.ApplicationDestination{{Server: \"*\", Namespace: \"*\"}},\n\t\t\t\tSourceNamespaces: []string{\"argocd-1\"},\n\t\t\t},\n\t\t}\n\t\tappServer := newTestAppServer(t, testApp, otherNsProj)\n\t\tappServer.enabledNamespaces = []string{\"argocd-1\"}\n\t\tlinks, err := appServer.ListLinks(context.TODO(), &application.ListAppLinksRequest{\n\t\t\tName:      pointer.String(\"test-app\"),\n\t\t\tNamespace: pointer.String(\"argocd-1\"),\n\t\t})\n\t\trequire.NoError(t, err)\n\t\tassert.Equal(t, 0, len(links.Items))\n\t})\n}", "is_vulnerable": 0}
{"code": "func GetTokenStringFromRequest(r *http.Request) string {\n\ttokenString := \"\" // Default to no token.\n\n\t// Token can be provided by a browser in a Cookie or\n\t// in an authorization HTTP header.\n\t// The token in the cookie has priority.\n\tif authCookie, err := r.Cookie(config.TokenCookieName); err == nil && authCookie != nil {\n\t\ttokenString = authCookie.Value\n\t} else if headerValue := r.Header.Get(\"Authorization\"); strings.Contains(headerValue, \"Bearer\") {\n\t\ttokenString = strings.TrimPrefix(headerValue, \"Bearer \")\n\t}\n\n\treturn tokenString\n}", "is_vulnerable": 1}
{"code": "func (m *NodeExecutionManager) listNodeExecutions(\n\tctx context.Context, identifierFilters []common.InlineFilter,\n\trequestFilters string, limit uint32, requestToken string, sortBy *admin.Sort, mapFilters []common.MapFilter) (\n\t*admin.NodeExecutionList, error) {\n\n\tfilters, err := util.AddRequestFilters(requestFilters, common.NodeExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif sortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*sortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(requestToken)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListNodeExecutions\", requestToken)\n\t}\n\tlistInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\tlistInput.MapFilters = mapFilters\n\toutput, err := m.db.NodeExecutionRepo().List(ctx, listInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list node executions for request with err %v\", err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.NodeExecutions) == int(limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.NodeExecutions))\n\t}\n\tnodeExecutionList, err := m.transformNodeExecutionModelList(ctx, output.NodeExecutions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution models for request with err: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn &admin.NodeExecutionList{\n\t\tNodeExecutions: nodeExecutionList,\n\t\tToken:          token,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func TestParseAnnotationsOverridesDefaultConfig(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"service-upstream\")] = \"false\"\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(mockBackend{}).Parse(ing)\n\tenabled, ok := val.(bool)\n\n\tif !ok {\n\t\tt.Errorf(\"expected a bool type\")\n\t}\n\n\tif enabled {\n\t\tt.Errorf(\"expected annotation value to be false, got true\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func fetchArgs(remoteURL string, ref string) []string {\n\targs := []string{\"fetch\"}\n\n\tif supportsShallowClone(remoteURL) {\n\t\targs = append(args, \"--depth\", \"1\")\n\t}\n\n\treturn append(args, \"origin\", \"--\", ref)\n}", "is_vulnerable": 0}
{"code": "func nomadDefaultCaps() []string {\n\treturn []string{\n\t\t\"AUDIT_WRITE\",\n\t\t\"CHOWN\",\n\t\t\"DAC_OVERRIDE\",\n\t\t\"FOWNER\",\n\t\t\"FSETID\",\n\t\t\"KILL\",\n\t\t\"MKNOD\",\n\t\t\"NET_BIND_SERVICE\",\n\t\t\"SETFCAP\",\n\t\t\"SETGID\",\n\t\t\"SETPCAP\",\n\t\t\"SETUID\",\n\t\t\"SYS_CHROOT\",\n\t}\n}", "is_vulnerable": 0}
{"code": "func (f Formatter) pretty(value interface{}) string {\n\treturn f.prettyWithFlags(value, 0, 0)\n}", "is_vulnerable": 1}
{"code": "\t\t\tvar uv = func() error {\n\t\t\t\tif err := v.Unmarshal(it); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tif !tt.wantErr {\n\t\t\t\t\tif ok, err := v.Insertable(); !ok || err != nil {\n\t\t\t\t\t\tt.Errorf(\"unexpected error calling insertable on valid proposed entry: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\twant := []string{}\n\t\t\t\tfor _, sig := range v.IntotoObj.Content.Envelope.Signatures {\n\t\t\t\t\tkeyHash := sha256.Sum256(*sig.PublicKey)\n\t\t\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(keyHash[:]))\n\t\t\t\t}\n\t\t\t\tdecodedPayload, err := base64.StdEncoding.DecodeString(tt.env.Payload)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"could not decode envelope payload: %w\", err)\n\t\t\t\t}\n\t\t\t\th := sha256.Sum256(decodedPayload)\n\t\t\t\twant = append(want, \"sha256:\"+hex.EncodeToString(h[:]))\n\n\t\t\t\tif !reflect.DeepEqual(v.AttestationKey(), \"sha256:\"+hex.EncodeToString(h[:])) {\n\t\t\t\t\tt.Errorf(\"V002Entry.AttestationKey() = %v, want %v\", v.AttestationKey(), \"sha256:\"+hex.EncodeToString(h[:]))\n\t\t\t\t}\n\n\t\t\t\tgot, _ := v.IndexKeys()\n\t\t\t\tsort.Strings(got)\n\t\t\t\tsort.Strings(want)\n\t\t\t\tif !reflect.DeepEqual(got, want) {\n\t\t\t\t\tt.Errorf(\"V002Entry.IndexKeys() = %v, want %v\", got, want)\n\t\t\t\t}\n\t\t\t\tpayloadBytes, _ := v.env.DecodeB64Payload()\n\t\t\t\tpayloadSha := sha256.Sum256(payloadBytes)\n\t\t\t\tpayloadHash := hex.EncodeToString(payloadSha[:])\n\n\t\t\t\tcanonicalBytes, err := v.Canonicalize(context.Background())\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"error canonicalizing entry: %v\", err)\n\t\t\t\t}\n\n\t\t\t\tpe, err := models.UnmarshalProposedEntry(bytes.NewReader(canonicalBytes), runtime.JSONConsumer())\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"unexpected err from Unmarshalling canonicalized entry for '%v': %v\", tt.name, err)\n\t\t\t\t}\n\t\t\t\tcanonicalEntry, err := types.UnmarshalEntry(pe)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"unexpected err from type-specific unmarshalling for '%v': %v\", tt.name, err)\n\t\t\t\t}\n\t\t\t\tif ok, err := canonicalEntry.Insertable(); ok || err == nil {\n\t\t\t\t\tt.Errorf(\"unexpected success calling Insertable on entry created from canonicalized content\")\n\t\t\t\t}\n\t\t\t\tcanonicalV002 := canonicalEntry.(*V002Entry)\n\t\t\t\tfmt.Printf(\"%v\", canonicalV002.IntotoObj.Content)\n\t\t\t\tif *canonicalV002.IntotoObj.Content.Hash.Value != *tt.it.Content.Hash.Value {\n\t\t\t\t\tt.Errorf(\"envelope hashes do not match post canonicalization: %v %v\", *canonicalV002.IntotoObj.Content.Hash.Value, *tt.it.Content.Hash.Value)\n\t\t\t\t}\n\t\t\t\tif canonicalV002.AttestationKey() != \"\" && *canonicalV002.IntotoObj.Content.PayloadHash.Value != payloadHash {\n\t\t\t\t\tt.Errorf(\"payload hashes do not match post canonicalization: %v %v\", canonicalV002.IntotoObj.Content.PayloadHash.Value, payloadHash)\n\t\t\t\t}\n\t\t\t\tcanonicalIndexKeys, _ := canonicalV002.IndexKeys()\n\t\t\t\tif !cmp.Equal(got, canonicalIndexKeys, cmpopts.SortSlices(func(x, y string) bool { return x < y })) {\n\t\t\t\t\tt.Errorf(\"index keys from hydrated object do not match those generated from canonicalized (and re-hydrated) object: %v %v\", got, canonicalIndexKeys)\n\t\t\t\t}\n\n\t\t\t\tverifier, err := v.Verifier()\n\t\t\t\tif !tt.wantVerifierErr {\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tt.Errorf(\"%v: unexpected error, got %v\", tt.name, err)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpubV, _ := verifier.CanonicalValue()\n\t\t\t\t\t\tif !reflect.DeepEqual(pubV, pub) && !reflect.DeepEqual(pubV, pemBytes) {\n\t\t\t\t\t\t\tt.Errorf(\"verifier and public keys do not match: %v, %v\", string(pubV), string(pub))\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\ts, _ := verifier.CanonicalValue()\n\t\t\t\t\t\tt.Errorf(\"%v: expected error for %v, got %v\", tt.name, string(s), err)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := uv(); (err != nil) != tt.wantErr {\n\t\t\t\tt.Errorf(\"V002Entry.Unmarshal() error = %v, wantErr %v\", err, tt.wantErr)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "func makeBenchBlock() *Block {\n\tvar (\n\t\tkey, _   = crypto.GenerateKey()\n\t\ttxs      = make([]*Transaction, 70)\n\t\treceipts = make([]*Receipt, len(txs))\n\t\tsigner   = NewEIP155Signer(params.TestChainConfig.ChainID)\n\t\tuncles   = make([]*Header, 3)\n\t)\n\theader := &Header{\n\t\tDifficulty: math.BigPow(11, 11),\n\t\tNumber:     math.BigPow(2, 9),\n\t\tGasLimit:   12345678,\n\t\tGasUsed:    1476322,\n\t\tTime:       9876543,\n\t\tExtra:      []byte(\"coolest block on chain\"),\n\t}\n\tfor i := range txs {\n\t\tamount := math.BigPow(2, int64(i))\n\t\tprice := big.NewInt(300000)\n\t\tdata := make([]byte, 100)\n\t\ttx := NewTransaction(uint64(i), common.Address{}, amount, 123457, price, data)\n\t\tsignedTx, err := SignTx(tx, signer, key)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\ttxs[i] = signedTx\n\t\treceipts[i] = NewReceipt(make([]byte, 32), false, tx.Gas())\n\t}\n\tfor i := range uncles {\n\t\tuncles[i] = &Header{\n\t\t\tDifficulty: math.BigPow(11, 11),\n\t\t\tNumber:     math.BigPow(2, 9),\n\t\t\tGasLimit:   12345678,\n\t\t\tGasUsed:    1476322,\n\t\t\tTime:       9876543,\n\t\t\tExtra:      []byte(\"benchmark uncle\"),\n\t\t}\n\t}\n\treturn NewBlock(header, txs, uncles, receipts)\n}", "is_vulnerable": 1}
{"code": "func (c *Configurator) AddCheck(id string, skipVerify bool) {\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.checks[id] = skipVerify\n}", "is_vulnerable": 1}
{"code": "\terr = filepath.Walk(cacheDir, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif info.IsDir() {\n\t\t\tassert.Equal(os.FileMode(0750), info.Mode().Perm())\n\t\t} else {\n\t\t\tassert.Equal(os.FileMode(0660), info.Mode().Perm())\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (autoCodeService *AutoCodeService) Database(businessDB string) Database {\n\n\tif businessDB == \"\" {\n\t\tswitch global.GVA_CONFIG.System.DbType {\n\t\tcase \"mysql\":\n\t\t\treturn AutoCodeMysql\n\t\tcase \"pgsql\":\n\t\t\treturn AutoCodePgsql\n\t\tdefault:\n\t\t\treturn AutoCodeMysql\n\t\t}\n\t} else {\n\t\tfor _, info := range global.GVA_CONFIG.DBList {\n\t\t\tif info.AliasName == businessDB {\n\n\t\t\t\tswitch info.Type {\n\t\t\t\tcase \"mysql\":\n\t\t\t\t\treturn AutoCodeMysql\n\t\t\t\tcase \"pgsql\":\n\t\t\t\t\treturn AutoCodePgsql\n\t\t\t\tcase \"oracle\":\n\t\t\t\t\treturn AutoCodeOracle\n\t\t\t\tdefault:\n\t\t\t\t\treturn AutoCodeMysql\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn AutoCodeMysql\n\t}\n\n}", "is_vulnerable": 0}
{"code": "func CsrfFromForm(param string) func(c *fiber.Ctx) (string, error) {\n\treturn func(c *fiber.Ctx) (string, error) {\n\t\ttoken := c.FormValue(param)\n\t\tif token == \"\" {\n\t\t\treturn \"\", errMissingForm\n\t\t}\n\t\treturn token, nil\n\t}\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) ListSender(req *http.Request) (*http.Response, error) {\n\treturn autorest.SendWithSender(client, req,\n\t\tazure.DoRetryWithRegistration(client.Client))\n}", "is_vulnerable": 1}
{"code": "func (h *UpgradeAwareHandler) tryUpgrade(w http.ResponseWriter, req *http.Request) bool {\n\tif !httpstream.IsUpgradeRequest(req) {\n\t\tklog.V(6).Infof(\"Request was not an upgrade\")\n\t\treturn false\n\t}\n\n\tvar (\n\t\tbackendConn net.Conn\n\t\trawResponse []byte\n\t\terr         error\n\t)\n\n\tlocation := *h.Location\n\tif h.UseRequestLocation {\n\t\tlocation = *req.URL\n\t\tlocation.Scheme = h.Location.Scheme\n\t\tlocation.Host = h.Location.Host\n\t}\n\n\tclone := utilnet.CloneRequest(req)\n\t// Only append X-Forwarded-For in the upgrade path, since httputil.NewSingleHostReverseProxy\n\t// handles this in the non-upgrade path.\n\tutilnet.AppendForwardedForHeader(clone)\n\tif h.InterceptRedirects {\n\t\tklog.V(6).Infof(\"Connecting to backend proxy (intercepting redirects) %s\\n  Headers: %v\", &location, clone.Header)\n\t\tbackendConn, rawResponse, err = utilnet.ConnectWithRedirects(req.Method, &location, clone.Header, req.Body, utilnet.DialerFunc(h.DialForUpgrade), h.RequireSameHostRedirects)\n\t} else {\n\t\tklog.V(6).Infof(\"Connecting to backend proxy (direct dial) %s\\n  Headers: %v\", &location, clone.Header)\n\t\tclone.URL = &location\n\t\tbackendConn, err = h.DialForUpgrade(clone)\n\t}\n\tif err != nil {\n\t\tklog.V(6).Infof(\"Proxy connection error: %v\", err)\n\t\th.Responder.Error(w, req, err)\n\t\treturn true\n\t}\n\tdefer backendConn.Close()\n\n\t// determine the http response code from the backend by reading from rawResponse+backendConn\n\tbackendHTTPResponse, headerBytes, err := getResponse(io.MultiReader(bytes.NewReader(rawResponse), backendConn))\n\tif err != nil {\n\t\tklog.V(6).Infof(\"Proxy connection error: %v\", err)\n\t\th.Responder.Error(w, req, err)\n\t\treturn true\n\t}\n\tif len(headerBytes) > len(rawResponse) {\n\t\t// we read beyond the bytes stored in rawResponse, update rawResponse to the full set of bytes read from the backend\n\t\trawResponse = headerBytes\n\t}\n\n\t// If the backend did not upgrade the request, return an error to the client. If the response was\n\t// an error, the error is forwarded directly after the connection is hijacked. Otherwise, just\n\t// return a generic error here.\n\tif backendHTTPResponse.StatusCode != http.StatusSwitchingProtocols && backendHTTPResponse.StatusCode < 400 {\n\t\terr := fmt.Errorf(\"invalid upgrade response: status code %d\", backendHTTPResponse.StatusCode)\n\t\tklog.Errorf(\"Proxy upgrade error: %v\", err)\n\t\th.Responder.Error(w, req, err)\n\t\treturn true\n\t}\n\n\t// Once the connection is hijacked, the ErrorResponder will no longer work, so\n\t// hijacking should be the last step in the upgrade.\n\trequestHijacker, ok := w.(http.Hijacker)\n\tif !ok {\n\t\tklog.V(6).Infof(\"Unable to hijack response writer: %T\", w)\n\t\th.Responder.Error(w, req, fmt.Errorf(\"request connection cannot be hijacked: %T\", w))\n\t\treturn true\n\t}\n\trequestHijackedConn, _, err := requestHijacker.Hijack()\n\tif err != nil {\n\t\tklog.V(6).Infof(\"Unable to hijack response: %v\", err)\n\t\th.Responder.Error(w, req, fmt.Errorf(\"error hijacking connection: %v\", err))\n\t\treturn true\n\t}\n\tdefer requestHijackedConn.Close()\n\n\tif backendHTTPResponse.StatusCode != http.StatusSwitchingProtocols {\n\t\t// If the backend did not upgrade the request, echo the response from the backend to the client and return, closing the connection.\n\t\tklog.V(6).Infof(\"Proxy upgrade error, status code %d\", backendHTTPResponse.StatusCode)\n\t\t// set read/write deadlines\n\t\tdeadline := time.Now().Add(10 * time.Second)\n\t\tbackendConn.SetReadDeadline(deadline)\n\t\trequestHijackedConn.SetWriteDeadline(deadline)\n\t\t// write the response to the client\n\t\terr := backendHTTPResponse.Write(requestHijackedConn)\n\t\tif err != nil && !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\tklog.Errorf(\"Error proxying data from backend to client: %v\", err)\n\t\t}\n\t\t// Indicate we handled the request\n\t\treturn true\n\t}\n\n\t// Forward raw response bytes back to client.\n\tif len(rawResponse) > 0 {\n\t\tklog.V(6).Infof(\"Writing %d bytes to hijacked connection\", len(rawResponse))\n\t\tif _, err = requestHijackedConn.Write(rawResponse); err != nil {\n\t\t\tutilruntime.HandleError(fmt.Errorf(\"Error proxying response from backend to client: %v\", err))\n\t\t}\n\t}\n\n\t// Proxy the connection. This is bidirectional, so we need a goroutine\n\t// to copy in each direction. Once one side of the connection exits, we\n\t// exit the function which performs cleanup and in the process closes\n\t// the other half of the connection in the defer.\n\twriterComplete := make(chan struct{})\n\treaderComplete := make(chan struct{})\n\n\tgo func() {\n\t\tvar writer io.WriteCloser\n\t\tif h.MaxBytesPerSec > 0 {\n\t\t\twriter = flowrate.NewWriter(backendConn, h.MaxBytesPerSec)\n\t\t} else {\n\t\t\twriter = backendConn\n\t\t}\n\t\t_, err := io.Copy(writer, requestHijackedConn)\n\t\tif err != nil && !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\tklog.Errorf(\"Error proxying data from client to backend: %v\", err)\n\t\t}\n\t\tclose(writerComplete)\n\t}()\n\n\tgo func() {\n\t\tvar reader io.ReadCloser\n\t\tif h.MaxBytesPerSec > 0 {\n\t\t\treader = flowrate.NewReader(backendConn, h.MaxBytesPerSec)\n\t\t} else {\n\t\t\treader = backendConn\n\t\t}\n\t\t_, err := io.Copy(requestHijackedConn, reader)\n\t\tif err != nil && !strings.Contains(err.Error(), \"use of closed network connection\") {\n\t\t\tklog.Errorf(\"Error proxying data from backend to client: %v\", err)\n\t\t}\n\t\tclose(readerComplete)\n\t}()\n\n\t// Wait for one half the connection to exit. Once it does the defer will\n\t// clean up the other half of the connection.\n\tselect {\n\tcase <-writerComplete:\n\tcase <-readerComplete:\n\t}\n\tklog.V(6).Infof(\"Disconnecting from backend proxy %s\\n  Headers: %v\", &location, clone.Header)\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func (c *Catalog) Register(args *structs.RegisterRequest, reply *struct{}) error {\n\tif done, err := c.srv.ForwardRPC(\"Catalog.Register\", args, args, reply); done {\n\t\treturn err\n\t}\n\tdefer metrics.MeasureSince([]string{\"catalog\", \"register\"}, time.Now())\n\n\t// Fetch the ACL token, if any.\n\tauthz, err := c.srv.ResolveTokenAndDefaultMeta(args.Token, &args.EnterpriseMeta, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.srv.validateEnterpriseRequest(args.GetEnterpriseMeta(), true); err != nil {\n\t\treturn err\n\t}\n\n\t// This needs to happen before the other preapply checks as it will fixup some of the\n\t// internal enterprise metas on the services and checks\n\tstate := c.srv.fsm.State()\n\tentMeta, err := state.ValidateRegisterRequest(args)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Verify the args.\n\tif err := nodePreApply(args.Node, string(args.ID)); err != nil {\n\t\treturn err\n\t}\n\tif args.Address == \"\" && !args.SkipNodeUpdate {\n\t\treturn fmt.Errorf(\"Must provide address if SkipNodeUpdate is not set\")\n\t}\n\n\t// Handle a service registration.\n\tif args.Service != nil {\n\t\tif err := servicePreApply(args.Service, authz, args.Service.FillAuthzContext); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Move the old format single check into the slice, and fixup IDs.\n\tif args.Check != nil {\n\t\targs.Checks = append(args.Checks, args.Check)\n\t\targs.Check = nil\n\t}\n\tfor _, check := range args.Checks {\n\t\tif check.Node == \"\" {\n\t\t\tcheck.Node = args.Node\n\t\t}\n\t\tcheckPreApply(check)\n\n\t\t// Populate check type for cases when a check is registered in the catalog directly\n\t\t// and not via anti-entropy\n\t\tif check.Type == \"\" {\n\t\t\tchkType := check.CheckType()\n\t\t\tcheck.Type = chkType.Type()\n\t\t}\n\t}\n\n\t// Check the complete register request against the given ACL policy.\n\tif authz != nil {\n\t\tstate := c.srv.fsm.State()\n\t\t_, ns, err := state.NodeServices(nil, args.Node, entMeta)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Node lookup failed: %v\", err)\n\t\t}\n\t\tif err := vetRegisterWithACL(authz, args, ns); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tresp, err := c.srv.raftApply(structs.RegisterRequestType, args)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif respErr, ok := resp.(error); ok {\n\t\treturn respErr\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func PrepareAccountsForDelegationRewards(t *testing.T, ctx sdk.Context, app *app.Evmos, addr sdk.AccAddress, balance math.Int, rewards ...math.Int) (sdk.Context, error) {\n\t// Calculate the necessary amount of tokens to fund the account in order for the desired residual balance to\n\t// be left after creating validators and delegating to them.\n\ttotalRewards := math.ZeroInt()\n\tfor _, reward := range rewards {\n\t\ttotalRewards = totalRewards.Add(reward)\n\t}\n\ttotalNeededBalance := balance.Add(totalRewards)\n\n\tif totalNeededBalance.IsZero() {\n\t\tapp.AccountKeeper.SetAccount(ctx, app.AccountKeeper.NewAccountWithAddress(ctx, addr))\n\t} else {\n\t\t// Fund account with enough tokens to stake them\n\t\terr := FundAccountWithBaseDenom(ctx, app.BankKeeper, addr, totalNeededBalance.Int64())\n\t\tif err != nil {\n\t\t\treturn sdk.Context{}, fmt.Errorf(\"failed to fund account: %s\", err.Error())\n\t\t}\n\t}\n\n\tif totalRewards.IsZero() {\n\t\treturn ctx, nil\n\t}\n\n\t// reset historical count in distribution keeper which is necessary\n\t// for the delegation rewards to be calculated correctly\n\tapp.DistrKeeper.DeleteAllValidatorHistoricalRewards(ctx)\n\n\t// set distribution module account balance which pays out the rewards\n\tdistrAcc := app.DistrKeeper.GetDistributionAccount(ctx)\n\terr := FundModuleAccount(ctx, app.BankKeeper, distrAcc.GetName(), sdk.NewCoins(sdk.NewCoin(utils.BaseDenom, totalRewards)))\n\tif err != nil {\n\t\treturn sdk.Context{}, fmt.Errorf(\"failed to fund distribution module account: %s\", err.Error())\n\t}\n\tapp.AccountKeeper.SetModuleAccount(ctx, distrAcc)\n\n\tfor _, reward := range rewards {\n\t\tif reward.IsZero() {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Set up validator and delegate to it\n\t\tprivKey := ed25519.GenPrivKey()\n\t\taddr2, _ := testutiltx.NewAccAddressAndKey()\n\t\terr := FundAccountWithBaseDenom(ctx, app.BankKeeper, addr2, reward.Int64())\n\t\tif err != nil {\n\t\t\treturn sdk.Context{}, fmt.Errorf(\"failed to fund validator account: %s\", err.Error())\n\t\t}\n\n\t\tzeroDec := math.LegacyZeroDec()\n\t\tstakingParams := app.StakingKeeper.GetParams(ctx)\n\t\tstakingParams.BondDenom = utils.BaseDenom\n\t\tstakingParams.MinCommissionRate = zeroDec\n\t\terr = app.StakingKeeper.SetParams(ctx, stakingParams)\n\t\trequire.NoError(t, err)\n\n\t\tstakingHelper := teststaking.NewHelper(t, ctx, app.StakingKeeper.Keeper)\n\t\tstakingHelper.Commission = stakingtypes.NewCommissionRates(zeroDec, zeroDec, zeroDec)\n\t\tstakingHelper.Denom = utils.BaseDenom\n\n\t\tvalAddr := sdk.ValAddress(addr2.Bytes())\n\t\t// self-delegate the same amount of tokens as the delegate address also stakes\n\t\t// this ensures, that the delegation rewards are 50% of the total rewards\n\t\tstakingHelper.CreateValidator(valAddr, privKey.PubKey(), reward, true)\n\t\tstakingHelper.Delegate(addr, valAddr, reward)\n\n\t\t// end block to bond validator and increase block height\n\t\t// Not using Commit() here because code panics due to invalid block height\n\t\tstaking.EndBlocker(ctx, app.StakingKeeper.Keeper)\n\n\t\t// allocate rewards to validator (of these 50% will be paid out to the delegator)\n\t\tvalidator := app.StakingKeeper.Validator(ctx, valAddr)\n\t\tallocatedRewards := sdk.NewDecCoins(sdk.NewDecCoin(utils.BaseDenom, reward.Mul(math.NewInt(2))))\n\t\tapp.DistrKeeper.AllocateTokensToValidator(ctx, validator, allocatedRewards)\n\t}\n\n\treturn ctx, nil\n}", "is_vulnerable": 0}
{"code": "func (f Formatter) FormatError(err error, msg string, kvList []any) (prefix, argsStr string) {\n\targs := make([]any, 0, 64) // using a constant here impacts perf\n\tprefix = f.prefix\n\tif f.outputFormat == outputJSON {\n\t\targs = append(args, \"logger\", prefix)\n\t\tprefix = \"\"\n\t}\n\tif f.opts.LogTimestamp {\n\t\targs = append(args, \"ts\", time.Now().Format(f.opts.TimestampFormat))\n\t}\n\tif policy := f.opts.LogCaller; policy == All || policy == Error {\n\t\targs = append(args, \"caller\", f.caller())\n\t}\n\targs = append(args, \"msg\", msg)\n\tvar loggableErr any\n\tif err != nil {\n\t\tloggableErr = err.Error()\n\t}\n\targs = append(args, \"error\", loggableErr)\n\treturn prefix, f.render(args, kvList)\n}", "is_vulnerable": 0}
{"code": "func (k *Key) IssuerName() string {\n\tres := C.GoString(k.k.issuer_name)\n\truntime.KeepAlive(k)\n\treturn res\n}", "is_vulnerable": 0}
{"code": "func TestGenerateYamlManifestInDir(t *testing.T) {\n\tservice := newService(\"../../manifests/base\")\n\n\tsrc := argoappv1.ApplicationSource{Path: \".\"}\n\tq := apiclient.ManifestRequest{\n\t\tRepo:              &argoappv1.Repository{},\n\t\tApplicationSource: &src,\n\t}\n\n\t// update this value if we add/remove manifests\n\tconst countOfManifests = 50\n\n\tres1, err := service.GenerateManifest(context.Background(), &q)\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, countOfManifests, len(res1.Manifests))\n\n\t// this will test concatenated manifests to verify we split YAMLs correctly\n\tres2, err := GenerateManifests(context.Background(), \"./testdata/concatenated\", \"/\", \"\", &q, false, &git.NoopCredsStore{}, resource.MustParse(\"0\"), nil)\n\tassert.NoError(t, err)\n\tassert.Equal(t, 3, len(res2.Manifests))\n}", "is_vulnerable": 0}
{"code": "\tdir1, s1 := testServerWithConfig(t, func(c *Config) {\n\t\tc.RPCHandshakeTimeout = 10 * time.Millisecond\n\t})", "is_vulnerable": 0}
{"code": "func (pt *pollingTrackerPatch) updatePollingMethod() error {\n\t// by default we can use the original URL for polling and final GET\n\tif pt.URI == \"\" {\n\t\tpt.URI = pt.resp.Request.URL.String()\n\t}\n\tif pt.FinalGetURI == \"\" {\n\t\tpt.FinalGetURI = pt.resp.Request.URL.String()\n\t}\n\tif pt.Pm == PollingUnknown {\n\t\tpt.Pm = PollingRequestURI\n\t}\n\t// for 201 it's permissible for no headers to be returned\n\tif pt.resp.StatusCode == http.StatusCreated {\n\t\tif ao, err := getURLFromAsyncOpHeader(pt.resp); err != nil {\n\t\t\treturn err\n\t\t} else if ao != \"\" {\n\t\t\tpt.URI = ao\n\t\t\tpt.Pm = PollingAsyncOperation\n\t\t}\n\t}\n\t// for 202 prefer the Azure-AsyncOperation header but fall back to Location if necessary\n\t// note the absence of the \"final GET\" mechanism for PATCH\n\tif pt.resp.StatusCode == http.StatusAccepted {\n\t\tao, err := getURLFromAsyncOpHeader(pt.resp)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t} else if ao != \"\" {\n\t\t\tpt.URI = ao\n\t\t\tpt.Pm = PollingAsyncOperation\n\t\t}\n\t\tif ao == \"\" {\n\t\t\tif lh, err := getURLFromLocationHeader(pt.resp); err != nil {\n\t\t\t\treturn err\n\t\t\t} else if lh == \"\" {\n\t\t\t\treturn autorest.NewError(\"pollingTrackerPatch\", \"updateHeaders\", \"didn't get any suitable polling URLs in 202 response\")\n\t\t\t} else {\n\t\t\t\tpt.URI = lh\n\t\t\t\tpt.Pm = PollingLocation\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func Upload(c *gin.Context) {\n\t//\u83b7\u53d6\u6587\u4ef6\u8def\u5f84\n\tpath := c.PostForm(\"path\")\n\t//\u5982\u679c\u4e0a\u4f20\u8def\u5f84\u4e3a\u7a7a\n\tif path == \"\" {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"code\": -1000,\n\t\t\t\"msg\":  \"\u4e0a\u4f20\u8def\u5f84\u4e0d\u80fd\u4e3a\u7a7a\uff01\",\n\t\t\t\"data\": \"\",\n\t\t})\n\t\tc.Abort()\n\t\treturn\n\t}\n\t//\u5982\u679c\u4e0a\u4f20\u8def\u5f84\u4e0d\u5408\u6cd5\n\t//\u5224\u65ad\u7528\u6237\u4f20\u9012\u7684\u8def\u5f84\u662f\u5426\u5408\u6cd5\n\tv_re := V_fpath(path)\n\tif !v_re {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"code\": -1000,\n\t\t\t\"msg\":  \"\u6587\u4ef6\u5939\u540d\u79f0\u4e0d\u5408\u6cd5\uff01\",\n\t\t\t\"data\": \"\",\n\t\t})\n\t\tc.Abort()\n\t\treturn\n\t}\n\n\t//\u5224\u65ad\u4e0a\u4f20\u8def\u5f84\u662f\u5426\u5e26\u6709/\n\tend_path_str := string(path[len(path)-1])\n\tif end_path_str != \"/\" {\n\t\tpath = path + \"/\"\n\t}\n\n\t//\u7ec4\u5408\u516c\u5171\u6587\u4ef6\u5b8c\u6574\u8def\u5f84\n\tpublic_dir := config.Public_path()\n\tfull_path := public_dir + path\n\n\t//\u5224\u65ad\u6587\u4ef6\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5219\u7ec8\u6b62\u6267\u884c\n\t_, err := os.Stat(full_path)\n\tif os.IsNotExist(err) {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"code\": -1000,\n\t\t\t\"msg\":  \"\u6587\u4ef6\u5939\u4e0d\u5b58\u5728\uff01\",\n\t\t\t\"data\": \"\",\n\t\t})\n\t\tc.Abort()\n\t\treturn\n\t}\n\n\t// \u5355\u6587\u4ef6\n\tfile, _ := c.FormFile(\"file\")\n\tfile_name := file.Filename\n\t//\u9a8c\u8bc1\u6587\u4ef6\u540d\u662f\u5426\u5408\u6cd5\n\tif !V_fname(file_name) {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"code\": -1000,\n\t\t\t\"msg\":  \"\u6587\u4ef6\u540d\u4e0d\u5408\u6cd5\uff01\",\n\t\t\t\"data\": \"\",\n\t\t})\n\t\treturn\n\t}\n\n\tdst := full_path + file_name\n\t// \u4e0a\u4f20\u6587\u4ef6\u81f3\u6307\u5b9a\u7684\u5b8c\u6574\u6587\u4ef6\u8def\u5f84\n\tc.SaveUploadedFile(file, dst)\n\t//\u8fd4\u56de\u4e0a\u4f20\u6210\u529f\n\tc.JSON(200, gin.H{\n\t\t\"code\": 200,\n\t\t\"msg\":  \"success\",\n\t\t\"data\": \"\",\n\t})\n}", "is_vulnerable": 0}
{"code": "func InstrumentRoundTripperCounter(counter *prometheus.CounterVec, next http.RoundTripper, opts ...Option) RoundTripperFunc {\n\trtOpts := &option{}\n\tfor _, o := range opts {\n\t\to(rtOpts)\n\t}\n\n\tcode, method := checkLabels(counter)\n\n\treturn RoundTripperFunc(func(r *http.Request) (*http.Response, error) {\n\t\tresp, err := next.RoundTrip(r)\n\t\tif err == nil {\n\t\t\tcounter.With(labels(code, method, r.Method, resp.StatusCode, rtOpts.extraMethods...)).Inc()\n\t\t}\n\t\treturn resp, err\n\t})\n}", "is_vulnerable": 0}
{"code": "func NewClientLogger(config *Config, logger *log.Logger, tlsConfigurator *tlsutil.Configurator) (*Client, error) {\n\t// Check the protocol version\n\tif err := config.CheckProtocolVersion(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check for a data directory!\n\tif config.DataDir == \"\" {\n\t\treturn nil, fmt.Errorf(\"Config must provide a DataDir\")\n\t}\n\n\t// Sanity check the ACLs\n\tif err := config.CheckACL(); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Ensure we have a log output\n\tif config.LogOutput == nil {\n\t\tconfig.LogOutput = os.Stderr\n\t}\n\n\t// Create the tls Wrapper\n\ttlsWrap, err := tlsConfigurator.OutgoingRPCWrapper()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create a logger\n\tif logger == nil {\n\t\tlogger = log.New(config.LogOutput, \"\", log.LstdFlags)\n\t}\n\n\tconnPool := &pool.ConnPool{\n\t\tSrcAddr:    config.RPCSrcAddr,\n\t\tLogOutput:  config.LogOutput,\n\t\tMaxTime:    clientRPCConnMaxIdle,\n\t\tMaxStreams: clientMaxStreams,\n\t\tTLSWrapper: tlsWrap,\n\t\tForceTLS:   config.VerifyOutgoing,\n\t}\n\n\t// Create client\n\tc := &Client{\n\t\tconfig:     config,\n\t\tconnPool:   connPool,\n\t\teventCh:    make(chan serf.Event, serfEventBacklog),\n\t\tlogger:     logger,\n\t\tshutdownCh: make(chan struct{}),\n\t}\n\n\tc.rpcLimiter.Store(rate.NewLimiter(config.RPCRate, config.RPCMaxBurst))\n\n\tif err := c.initEnterprise(); err != nil {\n\t\tc.Shutdown()\n\t\treturn nil, err\n\t}\n\n\tc.useNewACLs = 0\n\taclConfig := ACLResolverConfig{\n\t\tConfig:      config,\n\t\tDelegate:    c,\n\t\tLogger:      logger,\n\t\tAutoDisable: true,\n\t\tCacheConfig: clientACLCacheConfig,\n\t\tSentinel:    nil,\n\t}\n\tif c.acls, err = NewACLResolver(&aclConfig); err != nil {\n\t\tc.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to create ACL resolver: %v\", err)\n\t}\n\n\t// Initialize the LAN Serf\n\tc.serf, err = c.setupSerf(config.SerfLANConfig,\n\t\tc.eventCh, serfLANSnapshot)\n\tif err != nil {\n\t\tc.Shutdown()\n\t\treturn nil, fmt.Errorf(\"Failed to start lan serf: %v\", err)\n\t}\n\n\tif c.acls.ACLsEnabled() {\n\t\tgo c.monitorACLMode()\n\t}\n\n\t// Start maintenance task for servers\n\tc.routers = router.New(c.logger, c.shutdownCh, c.serf, c.connPool)\n\tgo c.routers.Start()\n\n\t// Start LAN event handlers after the router is complete since the event\n\t// handlers depend on the router and the router depends on Serf.\n\tgo c.lanEventHandler()\n\n\tif err := c.startEnterprise(); err != nil {\n\t\tc.Shutdown()\n\t\treturn nil, err\n\t}\n\n\treturn c, nil\n}", "is_vulnerable": 1}
{"code": "func convertLegacy(legacy legacyProgress) SyncProgress {\n\tvar progress SyncProgress\n\tfor i, task := range legacy.Tasks {\n\t\tsubTasks := make(map[common.Hash][]*storageTask)\n\t\tfor owner, list := range task.SubTasks {\n\t\t\tvar cpy []*storageTask\n\t\t\tfor i := 0; i < len(list); i++ {\n\t\t\t\tcpy = append(cpy, &storageTask{\n\t\t\t\t\tNext: list[i].Next,\n\t\t\t\t\tLast: list[i].Last,\n\t\t\t\t})\n\t\t\t}\n\t\t\tsubTasks[owner] = cpy\n\t\t}\n\t\taccountTask := &accountTask{\n\t\t\tNext:     task.Next,\n\t\t\tLast:     task.Last,\n\t\t\tSubTasks: subTasks,\n\t\t}\n\t\tif i == 0 {\n\t\t\taccountTask.StorageCompleted = []common.Hash{{0xaa}, {0xbb}} // fulfill new fields\n\t\t}\n\t\tprogress.Tasks = append(progress.Tasks, accountTask)\n\t}\n\treturn progress\n}", "is_vulnerable": 0}
{"code": "func TestConfigMap(t *testing.T) {\n\ttype Expectation struct {\n\t\tEnableLocalApp                    bool\n\t\tRunDbDeleter                      bool\n\t\tDisableDynamicAuthProviderLogin   bool\n\t\tDisableWorkspaceGarbageCollection bool\n\t\tDefaultBaseImageRegistryWhiteList []string\n\t\tWorkspaceImage                    string\n\t\tJWTSecret                         string\n\t\tSessionSecret                     string\n\t\tGitHubApp                         experimental.GithubApp\n\t\tAuth                              auth.Config\n\t\tRedis                             redis.Configuration\n\t}\n\n\texpectation := Expectation{\n\t\tEnableLocalApp:                    true,\n\t\tDisableDynamicAuthProviderLogin:   true,\n\t\tRunDbDeleter:                      false,\n\t\tDisableWorkspaceGarbageCollection: true,\n\t\tDefaultBaseImageRegistryWhiteList: []string{\"some-registry\"},\n\t\tWorkspaceImage:                    \"some-workspace-image\",\n\t\tJWTSecret:                         \"some-jwt-secret\",\n\t\tSessionSecret:                     \"some-session-secret\",\n\t\tGitHubApp: experimental.GithubApp{\n\t\t\tAppId:           123,\n\t\t\tAuthProviderId:  \"some-auth-provider-id\",\n\t\t\tBaseUrl:         \"some-base-url\",\n\t\t\tCertPath:        \"some-cert-path\",\n\t\t\tEnabled:         true,\n\t\t\tLogLevel:        \"some-log-level\",\n\t\t\tMarketplaceName: \"some-marketplace-name\",\n\t\t\tWebhookSecret:   \"some-webhook-secret\",\n\t\t\tCertSecretName:  \"some-cert-secret-name\",\n\t\t},\n\t\tAuth: auth.Config{\n\t\t\tPKI: auth.PKIConfig{\n\t\t\t\tSigning: auth.KeyPair{\n\t\t\t\t\tID:             \"0001\",\n\t\t\t\t\tPrivateKeyPath: \"/secrets/auth-pki/signing/tls.key\",\n\t\t\t\t\tPublicKeyPath:  \"/secrets/auth-pki/signing/tls.crt\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tSession: auth.SessionConfig{\n\t\t\t\tLifetimeSeconds: int64((7 * 24 * time.Hour).Seconds()),\n\t\t\t\tIssuer:          \"https://awesome.domain\",\n\t\t\t\tCookie: auth.CookieConfig{\n\t\t\t\t\tName:     \"__Host-_awesome_domain_jwt2_\",\n\t\t\t\t\tMaxAge:   int64((7 * 24 * time.Hour).Seconds()),\n\t\t\t\t\tSameSite: \"lax\",\n\t\t\t\t\tSecure:   true,\n\t\t\t\t\tHTTPOnly: true,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tRedis: redis.Configuration{\n\t\t\tAddress: \"redis.test_namespace.svc.cluster.local:6379\",\n\t\t},\n\t}\n\n\tctx, err := common.NewRenderContext(config.Config{\n\t\tDomain: \"awesome.domain\",\n\t\tWorkspace: config.Workspace{\n\t\t\tWorkspaceImage: expectation.WorkspaceImage,\n\t\t},\n\t\tContainerRegistry: config.ContainerRegistry{\n\t\t\tPrivateBaseImageAllowList: expectation.DefaultBaseImageRegistryWhiteList,\n\t\t},\n\t\tExperimental: &experimental.Config{\n\t\t\tWebApp: &experimental.WebAppConfig{\n\t\t\t\tServer: &experimental.ServerConfig{\n\t\t\t\t\tDisableDynamicAuthProviderLogin:   expectation.DisableDynamicAuthProviderLogin,\n\t\t\t\t\tEnableLocalApp:                    pointer.Bool(expectation.EnableLocalApp),\n\t\t\t\t\tRunDbDeleter:                      pointer.Bool(expectation.RunDbDeleter),\n\t\t\t\t\tDisableWorkspaceGarbageCollection: expectation.DisableWorkspaceGarbageCollection,\n\t\t\t\t\tOAuthServer: experimental.OAuthServer{\n\t\t\t\t\t\tJWTSecret: expectation.JWTSecret,\n\t\t\t\t\t},\n\t\t\t\t\tSession: experimental.Session{\n\t\t\t\t\t\tSecret: expectation.SessionSecret,\n\t\t\t\t\t},\n\t\t\t\t\tGithubApp: &expectation.GitHubApp,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}, versions.Manifest{}, \"test_namespace\")\n\n\trequire.NoError(t, err)\n\tobjs, err := configmap(ctx)\n\tif err != nil {\n\t\tt.Errorf(\"failed to generate configmap: %s\\n\", err)\n\t}\n\n\tconfigmap, ok := objs[0].(*corev1.ConfigMap)\n\tif !ok {\n\t\tt.Fatalf(\"rendering configmap did not return a configMap\")\n\t\treturn\n\t}\n\n\tconfigJson, ok := configmap.Data[\"config.json\"]\n\tif ok == false {\n\t\tt.Errorf(\"no %q key found in configmap data\", \"config.json\")\n\t}\n\n\tvar config ConfigSerialized\n\tif err := json.Unmarshal([]byte(configJson), &config); err != nil {\n\t\tt.Errorf(\"failed to unmarshal config json: %s\", err)\n\t}\n\n\tactual := Expectation{\n\t\tDisableDynamicAuthProviderLogin:   config.DisableDynamicAuthProviderLogin,\n\t\tEnableLocalApp:                    config.EnableLocalApp,\n\t\tRunDbDeleter:                      config.RunDbDeleter,\n\t\tDisableWorkspaceGarbageCollection: config.WorkspaceGarbageCollection.Disabled,\n\t\tDefaultBaseImageRegistryWhiteList: config.DefaultBaseImageRegistryWhitelist,\n\t\tWorkspaceImage:                    config.WorkspaceDefaults.WorkspaceImage,\n\t\tJWTSecret:                         config.OAuthServer.JWTSecret,\n\t\tSessionSecret:                     config.Session.Secret,\n\t\tGitHubApp: experimental.GithubApp{\n\t\t\tAppId:           config.GitHubApp.AppId,\n\t\t\tAuthProviderId:  config.GitHubApp.AuthProviderId,\n\t\t\tBaseUrl:         config.GitHubApp.BaseUrl,\n\t\t\tCertPath:        config.GitHubApp.CertPath,\n\t\t\tEnabled:         config.GitHubApp.Enabled,\n\t\t\tLogLevel:        config.GitHubApp.LogLevel,\n\t\t\tMarketplaceName: config.GitHubApp.MarketplaceName,\n\t\t\tWebhookSecret:   config.GitHubApp.WebhookSecret,\n\t\t\tCertSecretName:  config.GitHubApp.CertSecretName,\n\t\t},\n\t\tAuth:  config.Auth,\n\t\tRedis: config.Redis,\n\t}\n\n\tassert.Equal(t, expectation, actual)\n}", "is_vulnerable": 0}
{"code": "func inHeadIM(p *parser) bool {\n\tswitch p.tok.Type {\n\tcase TextToken:\n\t\ts := strings.TrimLeft(p.tok.Data, whitespace)\n\t\tif len(s) < len(p.tok.Data) {\n\t\t\t// Add the initial whitespace to the current node.\n\t\t\tp.addText(p.tok.Data[:len(p.tok.Data)-len(s)])\n\t\t\tif s == \"\" {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tp.tok.Data = s\n\t\t}\n\tcase StartTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Html:\n\t\t\treturn inBodyIM(p)\n\t\tcase a.Base, a.Basefont, a.Bgsound, a.Link, a.Meta:\n\t\t\tp.addElement()\n\t\t\tp.oe.pop()\n\t\t\tp.acknowledgeSelfClosingTag()\n\t\t\treturn true\n\t\tcase a.Noscript:\n\t\t\tif p.scripting {\n\t\t\t\tp.parseGenericRawTextElement()\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tp.addElement()\n\t\t\tp.im = inHeadNoscriptIM\n\t\t\t// Don't let the tokenizer go into raw text mode when scripting is disabled.\n\t\t\tp.tokenizer.NextIsNotRawText()\n\t\t\treturn true\n\t\tcase a.Script, a.Title:\n\t\t\tp.addElement()\n\t\t\tp.setOriginalIM()\n\t\t\tp.im = textIM\n\t\t\treturn true\n\t\tcase a.Noframes, a.Style:\n\t\t\tp.parseGenericRawTextElement()\n\t\t\treturn true\n\t\tcase a.Head:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\tcase a.Template:\n\t\t\tp.addElement()\n\t\t\tp.afe = append(p.afe, &scopeMarker)\n\t\t\tp.framesetOK = false\n\t\t\tp.im = inTemplateIM\n\t\t\tp.templateStack = append(p.templateStack, inTemplateIM)\n\t\t\treturn true\n\t\t}\n\tcase EndTagToken:\n\t\tswitch p.tok.DataAtom {\n\t\tcase a.Head:\n\t\t\tp.oe.pop()\n\t\t\tp.im = afterHeadIM\n\t\t\treturn true\n\t\tcase a.Body, a.Html, a.Br:\n\t\t\tp.parseImpliedToken(EndTagToken, a.Head, a.Head.String())\n\t\t\treturn false\n\t\tcase a.Template:\n\t\t\tif !p.oe.contains(a.Template) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\t// TODO: remove this divergence from the HTML5 spec.\n\t\t\t//\n\t\t\t// See https://bugs.chromium.org/p/chromium/issues/detail?id=829668\n\t\t\tp.generateImpliedEndTags()\n\t\t\tfor i := len(p.oe) - 1; i >= 0; i-- {\n\t\t\t\tif n := p.oe[i]; n.Namespace == \"\" && n.DataAtom == a.Template {\n\t\t\t\t\tp.oe = p.oe[:i]\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tp.clearActiveFormattingElements()\n\t\t\tp.templateStack.pop()\n\t\t\tp.resetInsertionMode()\n\t\t\treturn true\n\t\tdefault:\n\t\t\t// Ignore the token.\n\t\t\treturn true\n\t\t}\n\tcase CommentToken:\n\t\tp.addChild(&Node{\n\t\t\tType: CommentNode,\n\t\t\tData: p.tok.Data,\n\t\t})\n\t\treturn true\n\tcase DoctypeToken:\n\t\t// Ignore the token.\n\t\treturn true\n\t}\n\n\tp.parseImpliedToken(EndTagToken, a.Head, a.Head.String())\n\treturn false\n}", "is_vulnerable": 1}
{"code": "\tgo func() {\n\t\treverseExpandQuery := NewReverseExpandQuery(mockDatastore, typeSystem)\n\t\tt.Logf(\"before execute reverse expand\")\n\t\terr := reverseExpandQuery.Execute(ctx, &ReverseExpandRequest{\n\t\t\tStoreID:    store,\n\t\t\tObjectType: \"document\",\n\t\t\tRelation:   \"viewer\",\n\t\t\tUser: &UserRefObject{\n\t\t\t\tObject: &openfgav1.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"maria\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tContextualTuples: []*openfgav1.TupleKey{},\n\t\t}, resultChan, NewResolutionMetadata())\n\t\tt.Logf(\"after execute reverse expand\")\n\n\t\tif err != nil {\n\t\t\terrChan <- err\n\t\t}\n\t}()", "is_vulnerable": 0}
{"code": "func TestServer_DeltaAggregatedResources_v3_CapacityReached(t *testing.T) {\n\taclResolve := func(id string) (acl.Authorizer, error) { return acl.ManageAll(), nil }\n\n\tscenario := newTestServerDeltaScenario(t, aclResolve, \"web-sidecar-proxy\", \"\", 0)\n\tmgr, errCh, envoy := scenario.mgr, scenario.errCh, scenario.envoy\n\n\tsid := structs.NewServiceID(\"web-sidecar-proxy\", nil)\n\n\tmgr.RegisterProxy(t, sid)\n\tmgr.DrainStreams(sid)\n\n\tsnap := newTestSnapshot(t, nil, \"\", nil)\n\n\tenvoy.SendDeltaReq(t, xdscommon.ClusterType, &envoy_discovery_v3.DeltaDiscoveryRequest{\n\t\tInitialResourceVersions: mustMakeVersionMap(t,\n\t\t\tmakeTestCluster(t, snap, \"tcp:geo-cache\"),\n\t\t),\n\t})\n\n\tselect {\n\tcase err := <-errCh:\n\t\trequire.Error(t, err)\n\t\trequire.Equal(t, codes.ResourceExhausted.String(), status.Code(err).String())\n\tcase <-time.After(50 * time.Millisecond):\n\t\tt.Fatalf(\"timed out waiting for handler to finish\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func PanicsWithValue(t TestingT, expected interface{}, f assert.PanicTestFunc, msgAndArgs ...interface{}) {\n\tif assert.PanicsWithValue(t, expected, f, msgAndArgs...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "func TestVerifyDigestNotMatchResolve(t *testing.T) {\n\tpolicyDocument := dummyPolicyDocument()\n\trepo := mock.NewRepository()\n\trepo.MissMatchDigest = true\n\tverifier := dummyVerifier{&policyDocument, mock.PluginManager{}, false, *trustpolicy.LevelStrict}\n\n\terrorMessage := fmt.Sprintf(\"user input digest %s does not match the resolved digest %s\", mock.SampleDigest, mock.ZeroDigest)\n\texpectedErr := ErrorSignatureRetrievalFailed{Msg: errorMessage}\n\n\t// mock the repository\n\topts := VerifyOptions{ArtifactReference: mock.SampleArtifactUri, MaxSignatureAttempts: 50}\n\t_, _, err := Verify(context.Background(), &verifier, repo, opts)\n\tif err == nil || err.Error() != errorMessage {\n\t\tt.Fatalf(\"VerifyTagReference expected: %v got: %v\", expectedErr, err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (p *provider) RenderComponent(ctx wfContext.Context, v *value.Value, act wfTypes.Action) error {\n\tcomp, patcher, clusterName, overrideNamespace, env, err := lookUpCompInfo(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tworkload, traits, err := p.render(*comp, patcher, clusterName, overrideNamespace, env)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif workload != nil {\n\t\tif err := v.FillObject(workload.Object, \"output\"); err != nil {\n\t\t\treturn errors.WithMessage(err, \"FillOutput\")\n\t\t}\n\t}\n\n\tfor _, trait := range traits {\n\t\tname := trait.GetLabels()[oam.TraitResource]\n\t\tif name != \"\" {\n\t\t\tif err := v.FillObject(trait.Object, \"outputs\", name); err != nil {\n\t\t\t\treturn errors.WithMessage(err, \"FillOutputs\")\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (cli *VanClient) RouterCreate(ctx context.Context, options types.SiteConfig) error {\n\t// todo return error\n\tif options.Spec.IsIngressRoute() && cli.RouteClient == nil {\n\t\treturn fmt.Errorf(\"OpenShift cluster not detected for --ingress type route\")\n\t}\n\n\tif options.Spec.EnableFlowCollector || options.Spec.EnableRestAPI {\n\t\tif options.Spec.AuthMode == string(types.ConsoleAuthModeInternal) || options.Spec.AuthMode == \"\" {\n\t\t\toptions.Spec.AuthMode = string(types.ConsoleAuthModeInternal)\n\t\t\tif options.Spec.User == \"\" {\n\t\t\t\toptions.Spec.User = \"admin\"\n\t\t\t}\n\t\t\tif options.Spec.Password == \"\" {\n\t\t\t\toptions.Spec.Password = utils.RandomId(10)\n\t\t\t}\n\t\t} else {\n\t\t\tif options.Spec.User != \"\" {\n\t\t\t\tfmt.Println(\"--router-console-user only valid when --router-console-auth=internal\")\n\t\t\t}\n\t\t\tif options.Spec.Password != \"\" {\n\t\t\t\tfmt.Println(\"--router-console-password only valid when --router-console-auth=internal\")\n\t\t\t}\n\t\t}\n\t}\n\n\tsiteId := options.Reference.UID\n\tif siteId == \"\" {\n\t\tsiteId = utils.RandomId(10)\n\t}\n\tvan := cli.GetRouterSpecFromOpts(options.Spec, siteId)\n\tsiteOwnerRef := asOwnerReference(options.Reference)\n\tvar ownerRefs []metav1.OwnerReference\n\tif siteOwnerRef != nil {\n\t\townerRefs = []metav1.OwnerReference{*siteOwnerRef}\n\t}\n\tvar err error\n\thostAliases, err := cli.GetRouterHostAliasesSpecFromTokens(ctx, cli.GetNamespace())\n\tif err != nil {\n\t\treturn err\n\t}\n\tvan.Transport.HostAliases = hostAliases\n\tif options.Spec.AuthMode == string(types.ConsoleAuthModeInternal) {\n\t\tconfig := `\npwcheck_method: auxprop\nauxprop_plugin: sasldb\nsasldb_path: /tmp/skrouterd.sasldb\n`\n\t\tsaslData := &map[string]string{\n\t\t\t\"skrouterd.conf\": config,\n\t\t}\n\t\tkube.NewConfigMap(\"skupper-sasl-config\", saslData, &options.Spec.Labels, nil, siteOwnerRef, van.Namespace, cli.KubeClient)\n\t}\n\tfor _, sa := range van.Transport.ServiceAccounts {\n\t\tsa.ObjectMeta.OwnerReferences = ownerRefs\n\t\t_, err = kube.CreateServiceAccount(van.Namespace, sa, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, role := range van.Transport.Roles {\n\t\trole.ObjectMeta.OwnerReferences = ownerRefs\n\t\t_, err = kube.CreateRole(van.Namespace, role, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, roleBinding := range van.Transport.RoleBindings {\n\t\troleBinding.ObjectMeta.OwnerReferences = ownerRefs\n\t\t_, err = kube.CreateRoleBinding(van.Namespace, roleBinding, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, ca := range van.CertAuthoritys {\n\t\t_, err = kube.NewCertAuthority(ca, siteOwnerRef, van.Namespace, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, cred := range van.TransportCredentials {\n\t\tif !cred.Post {\n\t\t\t_, err = kube.NewSecret(cred, siteOwnerRef, van.Namespace, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\tfor _, svc := range van.Transport.Services {\n\t\tsvc.ObjectMeta.OwnerReferences = ownerRefs\n\t\t_, err = kube.CreateService(svc, van.Namespace, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\tif options.Spec.IsIngressRoute() {\n\t\tfor _, rte := range van.Transport.Routes {\n\t\t\trte.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateRoute(rte, van.Namespace, cli.RouteClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\tdep, err := kube.NewTransportDeployment(van, siteOwnerRef, cli.KubeClient)\n\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\treturn err\n\t}\n\n\tkube.NewConfigMap(types.ServiceInterfaceConfigMap, nil, &options.Spec.Labels, nil, siteOwnerRef, van.Namespace, cli.KubeClient)\n\tinitialConfig := qdr.AsConfigMapData(van.RouterConfig)\n\tkube.NewConfigMap(types.TransportConfigMapName, &initialConfig, &options.Spec.Labels, nil, siteOwnerRef, van.Namespace, cli.KubeClient)\n\n\tcurrentContext, cn := getCurrentContextOrDefault(ctx)\n\tif cn != nil {\n\t\tdefer cn()\n\t}\n\n\tif options.Spec.RouterMode == string(types.TransportModeInterior) {\n\t\tif options.Spec.IsIngressNginxIngress() || options.Spec.IsIngressKubernetes() {\n\t\t\terr = cli.createIngress(options)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else if options.Spec.IsIngressContourHttpProxy() {\n\t\t\terr = cli.createContourProxies(options)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tfor _, cred := range van.TransportCredentials {\n\t\t\tif cred.Post {\n\t\t\t\tdeadlineExceeded := false\n\t\t\t\trslvr, err := resolver.NewResolver(cli, van.Namespace, &options.Spec)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\thosts, err := rslvr.GetAllHosts()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\tvar spin *spinner.Spinner\n\t\t\t\tif len(hosts) == 0 {\n\t\t\t\t\twaitingFor := \"Waiting to try and resolve SANs for router...\"\n\n\t\t\t\t\tif options.Spec.IsIngressLoadBalancer() {\n\t\t\t\t\t\twaitingFor = \"Waiting for LoadBalancer IP or hostname...\"\n\t\t\t\t\t}\n\n\t\t\t\t\tspin = spinner.New(spinner.CharSets[9], 100*time.Millisecond)\n\t\t\t\t\tspin.Prefix = waitingFor\n\t\t\t\t\tspin.FinalMSG = waitingFor + \"\\n\"\n\t\t\t\t}\n\n\t\t\t\tfor len(hosts) == 0 && !deadlineExceeded {\n\t\t\t\t\tspin.Start()\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\tfmt.Println(\"context deadline exceeded\")\n\t\t\t\t\t\tdeadlineExceeded = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\tdefault:\n\t\t\t\t\t\ttime.Sleep(time.Second)\n\t\t\t\t\t\thosts, err = rslvr.GetAllHosts()\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif spin != nil {\n\t\t\t\t\tspin.Stop()\n\t\t\t\t}\n\n\t\t\t\tif len(hosts) == 0 {\n\t\t\t\t\tif options.Spec.IsIngressLoadBalancer() {\n\t\t\t\t\t\treturn fmt.Errorf(\"Failed to get LoadBalancer IP or Hostname for service %s\", types.TransportServiceName)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn fmt.Errorf(\"Failed to resolve SANs for %s\", cred.Name)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfor _, host := range hosts {\n\t\t\t\t\t\tcred.Hosts = append(cred.Hosts, host)\n\t\t\t\t\t\tif len(host) < 64 {\n\t\t\t\t\t\t\tcred.Subject = host\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tkube.NewSecret(cred, siteOwnerRef, van.Namespace, cli.KubeClient)\n\t\t\t}\n\t\t}\n\t}\n\n\tif options.Spec.EnableController {\n\t\tcli.GetVanControllerSpec(options.Spec, van, dep, siteId)\n\t\terr := configureDeployment(&van.Controller, &options.Spec.Controller.Tuning)\n\t\tif err != nil {\n\t\t\tfmt.Println(\"Error configuring controller:\", err)\n\t\t}\n\t\tfor _, sa := range van.Controller.ServiceAccounts {\n\t\t\tsa.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateServiceAccount(van.Namespace, sa, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tfor _, role := range van.Controller.Roles {\n\t\t\trole.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateRole(van.Namespace, role, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tfor _, roleBinding := range van.Controller.RoleBindings {\n\t\t\troleBinding.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateRoleBinding(van.Namespace, roleBinding, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tpolicyValidator := NewClusterPolicyValidator(cli)\n\t\tfor _, clusterRole := range van.Controller.ClusterRoles {\n\t\t\t// optional (in case of failure, cluster admin can add necessary cluster roles manually)\n\t\t\tkube.CreateClusterRole(clusterRole, cli.KubeClient)\n\t\t}\n\t\tfor _, clusterRoleBinding := range van.Controller.ClusterRoleBindings {\n\t\t\tclusterRoleBinding.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateClusterRoleBinding(clusterRoleBinding, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\tif policyValidator.Enabled() {\n\t\t\t\t\tlog.Printf(\"unable to define cluster role binding - %v\", err)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, svc := range van.Controller.Services {\n\t\t\tsvc.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t_, err = kube.CreateService(svc, van.Namespace, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif options.Spec.IsConsoleIngressRoute() {\n\t\t\tfor _, rte := range van.Controller.Routes {\n\t\t\t\trte.ObjectMeta.OwnerReferences = ownerRefs\n\t\t\t\t_, err = kube.CreateRoute(rte, van.Namespace, cli.RouteClient)\n\t\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, cred := range van.ControllerCredentials {\n\t\t\tif options.Spec.IsConsoleIngressRoute() {\n\t\t\t\trte, err := kube.GetRoute(types.ClaimRedemptionRouteName, van.Namespace, cli.RouteClient)\n\t\t\t\tif err == nil {\n\t\t\t\t\tcred.Hosts = append(cred.Hosts, rte.Spec.Host)\n\t\t\t\t} else {\n\t\t\t\t\tlog.Printf(\"Failed to retrieve route %q: %s\", types.ClaimRedemptionRouteName, err.Error())\n\t\t\t\t}\n\t\t\t} else if options.Spec.IsConsoleIngressLoadBalancer() {\n\t\t\t\terr = cli.appendLoadBalancerHostOrIp(currentContext, types.ControllerServiceName, van.Namespace, &cred)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else if options.Spec.IsConsoleIngressNginxIngress() && cred.Post {\n\t\t\t\terr = cli.appendIngressHost([]string{\"claims\", \"console\"}, van.Namespace, &cred)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\t_, err = kube.NewSecret(cred, siteOwnerRef, van.Namespace, cli.KubeClient)\n\t\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\t_, err = kube.NewControllerDeployment(van, siteOwnerRef, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif options.Spec.EnableFlowCollector && options.Spec.PrometheusServer.ExternalServer == \"\" {\n\t\t//\tStand up local prometheus server for metric aggregation\n\t\tcli.GetVanPrometheusServerSpec(options.Spec, van)\n\t\terr := configureDeployment(&van.PrometheusServer, &options.Spec.Controller.Tuning)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = cli.createPrometheus(ctx, &options, *van)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif options.Spec.CreateNetworkPolicy {\n\t\terr = kube.CreateNetworkPolicy(ownerRefs, van.Namespace, cli.KubeClient)\n\t\tif err != nil && !errors.IsAlreadyExists(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif options.Spec.EnableSkupperEvents {\n\t\terr = kube.AddEventRecorderPermissions(van.Namespace, ownerRefs, cli.KubeClient, types.ControllerServiceAccountName)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Failed to add permissions for the event recorder: %s\\n\", err)\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestSHA512_256iOne(t *testing.T) {\n\tinput := new(big.Int).SetBytes([]byte(\"abc\"))\n\tinput2 := new(big.Int).SetBytes([]byte(\"ab\"))\n\tinput3 := new(big.Int).SetBytes([]byte(\"cd\"))\n\ttype args struct {\n\t\tin *big.Int\n\t}\n\ttests := []struct {\n\t\tname     string\n\t\targs     args\n\t\twant     *big.Int\n\t\twantDiff bool\n\t}{{\n\t\tname: \"same inputs produce the same hash\",\n\t\targs: args{input},\n\t\twant: SHA512_256iOne(input),\n\t}, {\n\t\tname:     \"different inputs produce a differing hash\",\n\t\targs:     args{input2},\n\t\twant:     SHA512_256iOne(input),\n\t\twantDiff: true,\n\t}, {\n\t\tname:     \"different inputs produce a differing hash: Hash(-a) != Hash(a)\",\n\t\targs:     args{new(big.Int).Neg(input3)},\n\t\twant:     SHA512_256i(input3),\n\t\twantDiff: true,\n\t}}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot := SHA512_256iOne(tt.args.in)\n\t\t\tif tt.wantDiff {\n\t\t\t\tif !assert.NotEqualf(t, tt.want, got, \"SHA512_256iOne(%v)\", tt.args.in) {\n\t\t\t\t\tt.Errorf(\"SHA512_256iOne() = %v, do not want %v\", got, tt.want)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif !assert.Equalf(t, tt.want, got, \"SHA512_256iOne(%v)\", tt.args.in) {\n\t\t\t\t\tt.Errorf(\"SHA512_256iOne() = %v, want %v\", got, tt.want)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func Truef(t TestingT, value bool, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.Truef(t, value, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func (iter *ProviderListResultIterator) Next() error {\n\titer.i++\n\tif iter.i < len(iter.page.Values()) {\n\t\treturn nil\n\t}\n\terr := iter.page.Next()\n\tif err != nil {\n\t\titer.i--\n\t\treturn err\n\t}\n\titer.i = 0\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func New(cfg *setting.Cfg, tracer tracing.Tracer) *sdkhttpclient.Provider {\n\tlogger := log.New(\"httpclient\")\n\tuserAgent := fmt.Sprintf(\"Grafana/%s\", cfg.BuildVersion)\n\n\tmiddlewares := []sdkhttpclient.Middleware{\n\t\tTracingMiddleware(logger, tracer),\n\t\tDataSourceMetricsMiddleware(),\n\t\tSetUserAgentMiddleware(userAgent),\n\t\tsdkhttpclient.BasicAuthenticationMiddleware(),\n\t\tsdkhttpclient.CustomHeadersMiddleware(),\n\t\tResponseLimitMiddleware(cfg.ResponseLimit),\n\t}\n\n\tif cfg.SigV4AuthEnabled {\n\t\tmiddlewares = append(middlewares, SigV4Middleware(cfg.SigV4VerboseLogging))\n\t}\n\n\tsetDefaultTimeoutOptions(cfg)\n\n\treturn newProviderFunc(sdkhttpclient.ProviderOptions{\n\t\tMiddlewares: middlewares,\n\t\tConfigureTransport: func(opts sdkhttpclient.Options, transport *http.Transport) {\n\t\t\tdatasourceName, exists := opts.Labels[\"datasource_name\"]\n\t\t\tif !exists {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tdatasourceLabelName, err := metricutil.SanitizeLabelName(datasourceName)\n\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tnewConntrackRoundTripper(datasourceLabelName, transport)\n\t\t},\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestValidateSensor(t *testing.T) {\n\tdir := \"../../examples/sensors\"\n\tdirEntries, err := os.ReadDir(dir)\n\tassert.Nil(t, err)\n\n\ttestBus := fakeBus.DeepCopy()\n\ttestBus.Status.MarkDeployed(\"test\", \"test\")\n\ttestBus.Status.MarkConfigured()\n\t_, err = fakeEventBusClient.ArgoprojV1alpha1().EventBus(testNamespace).Create(context.TODO(), testBus, metav1.CreateOptions{})\n\tassert.Nil(t, err)\n\n\tfor _, entry := range dirEntries {\n\t\tif entry.IsDir() {\n\t\t\tcontinue\n\t\t}\n\t\tcontent, err := os.ReadFile(fmt.Sprintf(\"%s/%s\", dir, entry.Name()))\n\t\tassert.Nil(t, err)\n\t\tvar sensor *v1alpha1.Sensor\n\t\terr = yaml.Unmarshal(content, &sensor)\n\t\tassert.Nil(t, err)\n\t\tsensor.Namespace = testNamespace\n\t\tnewSensor := sensor.DeepCopy()\n\t\tnewSensor.Generation++\n\t\tv := NewSensorValidator(fakeK8sClient, fakeEventBusClient, fakeEventSourceClient, fakeSensorClient, sensor, newSensor)\n\t\tr := v.ValidateCreate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t\tr = v.ValidateUpdate(contextWithLogger(t))\n\t\tassert.True(t, r.Allowed)\n\t}\n}", "is_vulnerable": 0}
{"code": "func runList(ctx context.Context, opts *listOpts) error {\n\t// set log level\n\tctx = opts.LoggingFlagOpts.SetLoggerLevel(ctx)\n\n\t// initialize\n\treference := opts.reference\n\tsigRepo, err := getRepository(ctx, opts.inputType, reference, &opts.SecureFlagOpts, opts.allowReferrersAPI)\n\tif err != nil {\n\t\treturn err\n\t}\n\ttargetDesc, resolvedRef, err := resolveReferenceWithWarning(ctx, opts.inputType, reference, sigRepo, \"list\")\n\tif err != nil {\n\t\treturn err\n\t}\n\t// print all signature manifest digests\n\treturn printSignatureManifestDigests(ctx, targetDesc, sigRepo, resolvedRef, opts.maxSignatures)\n}", "is_vulnerable": 0}
{"code": "func (r *P256Point) ScalarBaseMult(scalar []byte) (*P256Point, error) {\n\tif len(scalar) != 32 {\n\t\treturn nil, errors.New(\"invalid scalar length\")\n\t}\n\tscalarReversed := new(p256OrdElement)\n\tp256OrdBigToLittle(scalarReversed, (*[32]byte)(scalar))\n\tp256OrdReduce(scalarReversed)\n\n\tr.p256BaseMult(scalarReversed)\n\treturn r, nil\n}", "is_vulnerable": 0}
{"code": "func TestIngressAnnotationOpentelemetryTrustSetTrue(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\topName := \"foo-op\"\n\tdata[parser.GetAnnotationWithPrefix(\"enable-opentelemetry\")] = \"true\"\n\tdata[parser.GetAnnotationWithPrefix(\"opentelemetry-trust-incoming-span\")] = \"true\"\n\tdata[parser.GetAnnotationWithPrefix(\"opentelemetry-operation-name\")] = opName\n\ting.SetAnnotations(data)\n\n\tval, _ := NewParser(&resolver.Mock{}).Parse(ing)\n\topenTelemetry, ok := val.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected a Config type\")\n\t}\n\n\tif !openTelemetry.Enabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif !openTelemetry.Set {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif !openTelemetry.TrustEnabled {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif !openTelemetry.TrustSet {\n\t\tt.Errorf(\"expected annotation value to be true, got false\")\n\t}\n\n\tif openTelemetry.OperationName != opName {\n\t\tt.Errorf(\"expected annotation value to be %v, got %v\", opName, openTelemetry.OperationName)\n\t}\n}", "is_vulnerable": 1}
{"code": "func WithExistingCache(cache *ccache.Cache[*ResolveCheckResponse]) CachedCheckResolverOpt {\n\treturn func(ccr *CachedCheckResolver) {\n\t\tccr.cache = cache\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestEventBroker_handleACLUpdates_tokenExpiry(t *testing.T) {\n\tci.Parallel(t)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tt.Cleanup(cancel)\n\n\tcases := []struct {\n\t\tname         string\n\t\tinputToken   *structs.ACLToken\n\t\tshouldExpire bool\n\t}{\n\t\t{\n\t\t\tname: \"token does not expire\",\n\t\t\tinputToken: &structs.ACLToken{\n\t\t\t\tAccessorID:     uuid.Generate(),\n\t\t\t\tSecretID:       uuid.Generate(),\n\t\t\t\tExpirationTime: pointer.Of(time.Now().Add(100000 * time.Hour).UTC()),\n\t\t\t\tType:           structs.ACLManagementToken,\n\t\t\t},\n\t\t\tshouldExpire: false,\n\t\t},\n\t\t{\n\t\t\tname: \"token does expire\",\n\t\t\tinputToken: &structs.ACLToken{\n\t\t\t\tAccessorID:     uuid.Generate(),\n\t\t\t\tSecretID:       uuid.Generate(),\n\t\t\t\tExpirationTime: pointer.Of(time.Now().Add(100000 * time.Hour).UTC()),\n\t\t\t\tType:           structs.ACLManagementToken,\n\t\t\t},\n\t\t\tshouldExpire: true,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\n\t\t\t// Build our fake token provider containing the relevant state\n\t\t\t// objects and add this to our new delegate. Keeping the token\n\t\t\t// provider setup separate means we can easily update its state.\n\t\t\ttokenProvider := &fakeACLTokenProvider{token: tc.inputToken}\n\t\t\taclDelegate := &fakeACLDelegate{tokenProvider: tokenProvider}\n\n\t\t\tpublisher, err := NewEventBroker(ctx, aclDelegate, EventBrokerCfg{})\n\t\t\trequire.NoError(t, err)\n\n\t\t\tfakeNodeEvent := structs.Event{\n\t\t\t\tTopic:   structs.TopicNode,\n\t\t\t\tType:    structs.TypeNodeRegistration,\n\t\t\t\tPayload: structs.NodeStreamEvent{Node: &structs.Node{}},\n\t\t\t}\n\n\t\t\tfakeTokenEvent := structs.Event{\n\t\t\t\tTopic:   structs.TopicACLToken,\n\t\t\t\tType:    structs.TypeACLTokenUpserted,\n\t\t\t\tPayload: structs.NewACLTokenEvent(&structs.ACLToken{SecretID: tc.inputToken.SecretID}),\n\t\t\t}\n\n\t\t\tsub, err := publisher.SubscribeWithACLCheck(&SubscribeRequest{\n\t\t\t\tTopics: map[structs.Topic][]string{structs.TopicAll: {\"*\"}},\n\t\t\t\tToken:  tc.inputToken.SecretID,\n\t\t\t})\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NotNil(t, sub)\n\n\t\t\t// Publish an event and check that there is a new item in the\n\t\t\t// subscription queue.\n\t\t\tpublisher.Publish(&structs.Events{Index: 100, Events: []structs.Event{fakeNodeEvent}})\n\n\t\t\tctx, cancel := context.WithDeadline(ctx, time.Now().Add(100*time.Millisecond))\n\t\t\tdefer cancel()\n\t\t\t_, err = sub.Next(ctx)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// If the test states the token should expire, set the expiration\n\t\t\t// time to a previous time.\n\t\t\tif tc.shouldExpire {\n\t\t\t\ttokenProvider.token.ExpirationTime = pointer.Of(\n\t\t\t\t\ttime.Date(1987, time.April, 13, 8, 3, 0, 0, time.UTC),\n\t\t\t\t)\n\t\t\t}\n\n\t\t\t// Publish some events to trigger re-evaluation of the subscription.\n\t\t\tpublisher.Publish(&structs.Events{Index: 101, Events: []structs.Event{fakeTokenEvent}})\n\t\t\tpublisher.Publish(&structs.Events{Index: 102, Events: []structs.Event{fakeNodeEvent}})\n\n\t\t\t// If we are expecting to unsubscribe consume the subscription\n\t\t\t// until the expected error occurs.\n\t\t\tctx, cancel = context.WithDeadline(ctx, time.Now().Add(100*time.Millisecond))\n\t\t\tdefer cancel()\n\n\t\t\tif tc.shouldExpire {\n\t\t\t\tfor {\n\t\t\t\t\tif _, err = sub.Next(ctx); err != nil {\n\t\t\t\t\t\tif err == context.DeadlineExceeded {\n\t\t\t\t\t\t\trequire.Fail(t, err.Error())\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif err == ErrSubscriptionClosed {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t_, err = sub.Next(ctx)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *RoleBindingReflector) GetUserNamespacesFromRequest(req request.Request) ([]string, error) {\n\tvar err error\n\n\tusername, groups, _ := req.GetUserAndGroups()\n\n\tnamespaces := sets.NewString()\n\n\tuserOwnerKind := capsulev1beta2.UserOwner\n\n\tvar userRoleBindings []interface{}\n\n\tif strings.HasPrefix(username, serviceaccount.ServiceAccountUsernamePrefix) {\n\t\tuserOwnerKind = capsulev1beta2.ServiceAccountOwner\n\n\t\tnamespace, name, splitErr := serviceaccount.SplitUsername(username)\n\t\tif splitErr != nil {\n\t\t\treturn nil, errors.Wrap(splitErr, \"Unable to parse serviceAccount name\")\n\t\t}\n\n\t\tusername = fmt.Sprintf(\"%s-%s\", namespace, name)\n\t}\n\n\tuserRoleBindings, err = r.store.ByIndex(subjectIndex, fmt.Sprintf(\"%s-%s\", userOwnerKind, username))\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"Unable to find rolebindings in index for user\")\n\t}\n\n\tfor _, rb := range userRoleBindings {\n\t\trb := rb.(*rbacv1.RoleBinding)\n\t\tnamespaces.Insert(rb.GetNamespace())\n\t}\n\n\tfor _, group := range groups {\n\t\tgroupRoleBindings, err := r.store.ByIndex(subjectIndex, fmt.Sprintf(\"%s-%s\", capsulev1beta2.GroupOwner, group))\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"Unable to find rolebindings in index for groups\")\n\t\t}\n\n\t\tfor _, rb := range groupRoleBindings {\n\t\t\trb := rb.(*rbacv1.RoleBinding)\n\t\t\tnamespaces.Insert(rb.GetNamespace())\n\t\t}\n\t}\n\n\treturn namespaces.List(), nil\n}", "is_vulnerable": 0}
{"code": "func (h *AuthHandlers) UserKeyAuth(conn ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\tfingerprint := fmt.Sprintf(\"%v %v\", key.Type(), sshutils.Fingerprint(key))\n\n\t// create a new logging entry with info specific to this login attempt\n\tlog := h.Entry.WithField(trace.ComponentFields, log.Fields{\n\t\t\"local\":       conn.LocalAddr(),\n\t\t\"remote\":      conn.RemoteAddr(),\n\t\t\"user\":        conn.User(),\n\t\t\"fingerprint\": fingerprint,\n\t})\n\n\tcid := fmt.Sprintf(\"conn(%v->%v, user=%v)\", conn.RemoteAddr(), conn.LocalAddr(), conn.User())\n\tlog.Debugf(\"%v auth attempt\", cid)\n\n\tcert, ok := key.(*ssh.Certificate)\n\tlog.Debugf(\"%v auth attempt with key %v, %#v\", cid, fingerprint, cert)\n\tif !ok {\n\t\tlog.Debugf(\"auth attempt, unsupported key type\")\n\t\treturn nil, trace.BadParameter(\"unsupported key type: %v\", fingerprint)\n\t}\n\tif len(cert.ValidPrincipals) == 0 {\n\t\tlog.Debugf(\"need a valid principal for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid principal for key %v\", fingerprint)\n\t}\n\tif len(cert.KeyId) == 0 {\n\t\tlog.Debugf(\"need a valid key ID for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid key for key %v\", fingerprint)\n\t}\n\tteleportUser := cert.KeyId\n\n\t// only failed attempts are logged right now\n\trecordFailedLogin := func(err error) {\n\t\tif err := h.Emitter.EmitAuditEvent(h.Server.Context(), &events.AuthAttempt{\n\t\t\tMetadata: events.Metadata{\n\t\t\t\tType: events.AuthAttemptEvent,\n\t\t\t\tCode: events.AuthAttemptFailureCode,\n\t\t\t},\n\t\t\tUserMetadata: events.UserMetadata{\n\t\t\t\tLogin: conn.User(),\n\t\t\t\tUser:  teleportUser,\n\t\t\t},\n\t\t\tConnectionMetadata: events.ConnectionMetadata{\n\t\t\t\tLocalAddr:  conn.LocalAddr().String(),\n\t\t\t\tRemoteAddr: conn.RemoteAddr().String(),\n\t\t\t},\n\t\t\tStatus: events.Status{\n\t\t\t\tSuccess: false,\n\t\t\t\tError:   err.Error(),\n\t\t\t},\n\t\t}); err != nil {\n\t\t\th.WithError(err).Warn(\"Failed to emit failed login audit event.\")\n\t\t}\n\t}\n\n\t// Check that the user certificate uses supported public key algorithms, was\n\t// issued by Teleport, and check the certificate metadata (principals,\n\t// timestamp, etc). Fallback to keys is not supported.\n\tclock := time.Now\n\tif h.Clock != nil {\n\t\tclock = h.Clock.Now\n\t}\n\tcertChecker := sshutils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsUserAuthority: h.IsUserAuthority,\n\t\t\tClock:           clock,\n\t\t},\n\t\tFIPS: h.FIPS,\n\t}\n\tpermissions, err := certChecker.Authenticate(conn, key)\n\tif err != nil {\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tlog.Debugf(\"Successfully authenticated\")\n\n\tclusterName, err := h.AccessPoint.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// this is the only way we know of to pass valid additional data about the\n\t// connection to the handlers\n\tpermissions.Extensions[utils.CertTeleportUser] = teleportUser\n\tpermissions.Extensions[utils.CertTeleportClusterName] = clusterName.GetClusterName()\n\tpermissions.Extensions[utils.CertTeleportUserCertificate] = string(ssh.MarshalAuthorizedKey(cert))\n\n\tif h.isProxy() {\n\t\treturn permissions, nil\n\t}\n\n\t// check if the user has permission to log into the node.\n\tswitch {\n\tcase h.Component == teleport.ComponentForwardingNode:\n\t\terr = h.canLoginWithoutRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\tdefault:\n\t\terr = h.canLoginWithRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\t}\n\tif err != nil {\n\t\tlog.Errorf(\"Permission denied: %v\", err)\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn permissions, nil\n}", "is_vulnerable": 0}
{"code": "\t\t\tIt(\"packs PATH_CHALLENGE and PATH_RESPONSE frames\", func() {\n\t\t\t\tpnManager.EXPECT().PeekPacketNumber(protocol.Encryption1RTT).Return(protocol.PacketNumber(0x42), protocol.PacketNumberLen2)\n\t\t\t\tpnManager.EXPECT().PopPacketNumber(protocol.Encryption1RTT).Return(protocol.PacketNumber(0x42))\n\t\t\t\tsealingManager.EXPECT().Get1RTTSealer().Return(getSealer(), nil)\n\t\t\t\tframer.EXPECT().HasData().Return(true)\n\t\t\t\tackFramer.EXPECT().GetAckFrame(protocol.Encryption1RTT, false)\n\t\t\t\tframes := []ackhandler.Frame{\n\t\t\t\t\t{Frame: &wire.PathChallengeFrame{}},\n\t\t\t\t\t{Frame: &wire.PathResponseFrame{}},\n\t\t\t\t\t{Frame: &wire.DataBlockedFrame{}},\n\t\t\t\t}\n\t\t\t\texpectAppendControlFrames(frames...)\n\t\t\t\texpectAppendStreamFrames()\n\t\t\t\tbuffer := getPacketBuffer()\n\t\t\t\tp, err := packer.AppendPacket(buffer, maxPacketSize, protocol.Version1)\n\t\t\t\tExpect(p).ToNot(BeNil())\n\t\t\t\tExpect(err).ToNot(HaveOccurred())\n\t\t\t\tExpect(p.Frames).To(HaveLen(3))\n\t\t\t\tfor i, f := range p.Frames {\n\t\t\t\t\tExpect(f).To(BeAssignableToTypeOf(frames[i]))\n\t\t\t\t\tswitch f.Frame.(type) {\n\t\t\t\t\tcase *wire.PathChallengeFrame, *wire.PathResponseFrame:\n\t\t\t\t\t\t// This means that the frame won't be retransmitted.\n\t\t\t\t\t\tExpect(f.Handler).To(BeNil())\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tExpect(f.Handler).ToNot(BeNil())\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tExpect(buffer.Len()).ToNot(BeZero())\n\t\t\t})", "is_vulnerable": 0}
{"code": "func Test_DeleteExecutionsWorkflow_ManyExecutions_ContinueAsNew(t *testing.T) {\n\ttestSuite := &testsuite.WorkflowTestSuite{}\n\tenv := testSuite.NewTestWorkflowEnvironment()\n\n\tvar a *Activities\n\n\tenv.OnActivity(a.GetNextPageTokenActivity, mock.Anything, mock.Anything).Return([]byte{3, 22, 83}, nil).Times(78)\n\tenv.OnActivity(a.DeleteExecutionsActivity, mock.Anything, mock.Anything).Return(DeleteExecutionsActivityResult{SuccessCount: 1}, nil).Times(78)\n\n\tenv.ExecuteWorkflow(DeleteExecutionsWorkflow, DeleteExecutionsParams{\n\t\tNamespaceID: \"namespace-id\",\n\t\tNamespace:   \"namespace\",\n\t\tConfig: DeleteExecutionsConfig{\n\t\t\tPageSize:          3,\n\t\t\tPagesPerExecution: 78,\n\t\t},\n\t})\n\n\trequire.True(t, env.IsWorkflowCompleted())\n\twfErr := env.GetWorkflowError()\n\trequire.Error(t, wfErr)\n\tvar errContinueAsNew *workflow.ContinueAsNewError\n\trequire.ErrorAs(t, wfErr, &errContinueAsNew)\n\n\trequire.NotNil(t, errContinueAsNew.Input)\n\tvar newWfParams DeleteExecutionsParams\n\terr := payloads.Decode(errContinueAsNew.Input, &newWfParams)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 78, newWfParams.PreviousSuccessCount)\n\trequire.Equal(t, 0, newWfParams.PreviousErrorCount)\n\trequire.Equal(t, []byte{3, 22, 83}, newWfParams.NextPageToken)\n}", "is_vulnerable": 1}
{"code": "func (f *timewindowCheckFilter) ProcessProposal(ctx context.Context, signedProp *peer.SignedProposal) (*peer.ProposalResponse, error) {\n\tif err := validateTimewindowProposal(signedProp, f.timeWindow); err != nil {\n\t\treturn nil, err\n\t}\n\treturn f.next.ProcessProposal(ctx, signedProp)\n}", "is_vulnerable": 0}
{"code": "func (m *Bar5) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Bar5: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Bar5: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars2\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars2 = append(m.Bars2, &Bar2{})\n\t\t\tif err := m.Bars2[len(m.Bars2)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bars1\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowIssue530\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bars1 = append(m.Bars1, &Bar1{})\n\t\t\tif err := m.Bars1[len(m.Bars1)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipIssue530(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthIssue530\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (s *CustomColumnsPrinter) printOneObject(obj runtime.Object, parsers []*jsonpath.JSONPath, out io.Writer) error {\n\tcolumns := make([]string, len(parsers))\n\tswitch u := obj.(type) {\n\tcase *metav1.WatchEvent:\n\t\tif printers.InternalObjectPreventer.IsForbidden(reflect.Indirect(reflect.ValueOf(u.Object.Object)).Type().PkgPath()) {\n\t\t\treturn fmt.Errorf(printers.InternalObjectPrinterErr)\n\t\t}\n\t\tunstructuredObject, err := runtime.DefaultUnstructuredConverter.ToUnstructured(u.Object.Object)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tobj = &unstructured.Unstructured{\n\t\t\tObject: map[string]interface{}{\n\t\t\t\t\"type\":   u.Type,\n\t\t\t\t\"object\": unstructuredObject,\n\t\t\t},\n\t\t}\n\n\tcase *runtime.Unknown:\n\t\tif len(u.Raw) > 0 {\n\t\t\tvar err error\n\t\t\tif obj, err = runtime.Decode(s.Decoder, u.Raw); err != nil {\n\t\t\t\treturn fmt.Errorf(\"can't decode object for printing: %v (%s)\", err, u.Raw)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor ix := range parsers {\n\t\tparser := parsers[ix]\n\n\t\tvar values [][]reflect.Value\n\t\tvar err error\n\t\tif unstructured, ok := obj.(runtime.Unstructured); ok {\n\t\t\tvalues, err = parser.FindResults(unstructured.UnstructuredContent())\n\t\t} else {\n\t\t\tvalues, err = parser.FindResults(reflect.ValueOf(obj).Elem().Interface())\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvalueStrings := []string{}\n\t\tif len(values) == 0 || len(values[0]) == 0 {\n\t\t\tvalueStrings = append(valueStrings, \"<none>\")\n\t\t}\n\t\tfor arrIx := range values {\n\t\t\tfor valIx := range values[arrIx] {\n\t\t\t\tvalueStrings = append(valueStrings, fmt.Sprintf(\"%v\", values[arrIx][valIx].Interface()))\n\t\t\t}\n\t\t}\n\t\tcolumns[ix] = strings.Join(valueStrings, \",\")\n\t}\n\tfmt.Fprintln(out, strings.Join(columns, \"\\t\"))\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func newTerminalSession(w http.ResponseWriter, r *http.Request, responseHeader http.Header, sessionManager *util_session.SessionManager) (*terminalSession, error) {\n\ttoken, err := getToken(r)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tconn, err := upgrader.Upgrade(w, r, responseHeader)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsession := &terminalSession{\n\t\twsConn:         conn,\n\t\ttty:            true,\n\t\tsizeChan:       make(chan remotecommand.TerminalSize),\n\t\tdoneChan:       make(chan struct{}),\n\t\tsessionManager: sessionManager,\n\t\ttoken:          &token,\n\t}\n\treturn session, nil\n}", "is_vulnerable": 0}
{"code": "func (s *Sync) AddRawEntry(hash common.Hash, depth int, parent common.Hash) {\n\t// Short circuit if the entry is empty or already known\n\tif hash == emptyState {\n\t\treturn\n\t}\n\tif _, ok := s.membatch.batch[hash]; ok {\n\t\treturn\n\t}\n\tif s.bloom == nil || s.bloom.Contains(hash[:]) {\n\t\t// Bloom filter says this might be a duplicate, double check\n\t\tif ok, _ := s.database.Has(hash[:]); ok {\n\t\t\treturn\n\t\t}\n\t\t// False positive, bump fault meter\n\t\tbloomFaultMeter.Mark(1)\n\t}\n\t// Assemble the new sub-trie sync request\n\treq := &request{\n\t\thash:  hash,\n\t\traw:   true,\n\t\tdepth: depth,\n\t}\n\t// If this sub-trie has a designated parent, link them together\n\tif parent != (common.Hash{}) {\n\t\tancestor := s.requests[parent]\n\t\tif ancestor == nil {\n\t\t\tpanic(fmt.Sprintf(\"raw-entry ancestor not found: %x\", parent))\n\t\t}\n\t\tancestor.deps++\n\t\treq.parents = append(req.parents, ancestor)\n\t}\n\ts.schedule(req)\n}", "is_vulnerable": 1}
{"code": "func (a *Agent) connect() (conn *ssh.Client, err error) {\n\tfor _, authMethod := range a.authMethods {\n\t\t// Create a dialer (that respects HTTP proxies) and connect to remote host.\n\t\tdialer := proxy.DialerFromEnvironment(a.Addr.Addr)\n\t\tpconn, err := dialer.DialTimeout(a.Addr.AddrNetwork, a.Addr.Addr, defaults.DefaultDialTimeout)\n\t\tif err != nil {\n\t\t\ta.log.Debugf(\"Dial to %v failed: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Build a new client connection. This is done to get access to incoming\n\t\t// global requests which dialer.Dial would not provide.\n\t\tconn, chans, reqs, err := ssh.NewClientConn(pconn, a.Addr.Addr, &ssh.ClientConfig{\n\t\t\tUser:            a.Username,\n\t\t\tAuth:            []ssh.AuthMethod{authMethod},\n\t\t\tHostKeyCallback: a.checkHostSignature,\n\t\t\tTimeout:         defaults.DefaultDialTimeout,\n\t\t})\n\t\tif err != nil {\n\t\t\ta.log.Debugf(\"Failed to create client to %v: %v.\", a.Addr.Addr, err)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create an empty channel and close it right away. This will prevent\n\t\t// ssh.NewClient from attempting to process any incoming requests.\n\t\temptyCh := make(chan *ssh.Request)\n\t\tclose(emptyCh)\n\n\t\tclient := ssh.NewClient(conn, chans, emptyCh)\n\n\t\t// Start a goroutine to process global requests from the server.\n\t\tgo a.handleGlobalRequests(a.ctx, reqs)\n\n\t\treturn client, nil\n\t}\n\treturn nil, trace.BadParameter(\"failed to dial: all auth methods failed\")\n}", "is_vulnerable": 1}
{"code": "func (vfs *VirtualFilesystem) attachTreeLocked(ctx context.Context, mnt *Mount, mp VirtualDentry) error {\n\tcleanup := cleanup.Make(func() {\n\t\tvfs.cleanupGroupIDs(mnt.submountsLocked()) // +checklocksforce\n\t\tmp.dentry.mu.Unlock()\n\t\tvfs.delayDecRef(mp)\n\t})\n\tdefer cleanup.Clean()\n\t// This is equivalent to checking for SB_NOUSER in Linux, which is set on all\n\t// anon mounts and sentry-internal filesystems like pipefs.\n\tif mp.mount.neverConnected() {\n\t\treturn linuxerr.EINVAL\n\t}\n\tdefer func() { mp.mount.ns.pending = 0 }()\n\tif err := mp.mount.ns.checkMountCount(ctx, mnt); err != nil {\n\t\treturn err\n\t}\n\n\tvar (\n\t\tpropMnts map[*Mount]struct{}\n\t\terr      error\n\t)\n\tif mp.mount.isShared {\n\t\tif err := vfs.allocMountGroupIDs(mnt, true); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpropMnts, err = vfs.doPropagation(ctx, mnt, mp)\n\t\tif err != nil {\n\t\t\tfor pmnt := range propMnts {\n\t\t\t\tif !pmnt.parent().neverConnected() {\n\t\t\t\t\tpmnt.parent().ns.pending -= pmnt.countSubmountsLocked()\n\t\t\t\t}\n\t\t\t\tvfs.abortUncommitedMount(ctx, pmnt)\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t}\n\tcleanup.Release()\n\n\tif mp.mount.isShared {\n\t\tfor _, m := range mnt.submountsLocked() {\n\t\t\tm.isShared = true\n\t\t}\n\t}\n\tvfs.mounts.seq.BeginWrite()\n\tvfs.connectLocked(mnt, mp, mp.mount.ns)\n\tvfs.mounts.seq.EndWrite()\n\tmp.dentry.mu.Unlock()\n\tvfs.commitChildren(ctx, mnt)\n\tfor pmnt := range propMnts {\n\t\tvfs.commitMount(ctx, pmnt)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func syscallMode(i FileMode) (o FileMode) {\n\to |= i.Perm()\n\tif i&ModeSetuid != 0 {\n\t\to |= unix.S_ISUID\n\t}\n\tif i&ModeSetgid != 0 {\n\t\to |= unix.S_ISGID\n\t}\n\tif i&ModeSticky != 0 {\n\t\to |= unix.S_ISVTX\n\t}\n\t// No mapping for Go's ModeTemporary (plan9 only).\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (err error) {\n\tif len(images) == 0 {\n\t\treturn flag.ErrHelp\n\t}\n\n\tif !options.OneOf(c.KeyRef, c.Sk, c.CertRef) && !options.EnableExperimental() {\n\t\treturn &options.PubKeyParseError{}\n\t}\n\n\tociremoteOpts, err := c.ClientOpts(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"constructing client options: %w\", err)\n\t}\n\tco := &cosign.CheckOpts{\n\t\tRegistryClientOpts:           ociremoteOpts,\n\t\tCertEmail:                    c.CertEmail,\n\t\tCertOidcIssuer:               c.CertOidcIssuer,\n\t\tCertGithubWorkflowTrigger:    c.CertGithubWorkflowTrigger,\n\t\tCertGithubWorkflowSha:        c.CertGithubWorkflowSha,\n\t\tCertGithubWorkflowName:       c.CertGithubWorkflowName,\n\t\tCertGithubWorkflowRepository: c.CertGithubWorkflowRepository,\n\t\tCertGithubWorkflowRef:        c.CertGithubWorkflowRef,\n\t\tEnforceSCT:                   c.EnforceSCT,\n\t}\n\tif c.CheckClaims {\n\t\tco.ClaimVerifier = cosign.IntotoSubjectClaimVerifier\n\t}\n\tif options.EnableExperimental() {\n\t\tif c.RekorURL != \"\" {\n\t\t\trekorClient, err := rekor.NewClient(c.RekorURL)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating Rekor client: %w\", err)\n\t\t\t}\n\t\t\tco.RekorClient = rekorClient\n\t\t}\n\t\tco.RootCerts, err = fulcio.GetRoots()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"getting Fulcio roots: %w\", err)\n\t\t}\n\t\tco.IntermediateCerts, err = fulcio.GetIntermediates()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"getting Fulcio intermediates: %w\", err)\n\t\t}\n\t}\n\tkeyRef := c.KeyRef\n\n\t// Keys are optional!\n\tswitch {\n\tcase keyRef != \"\":\n\t\tco.SigVerifier, err = sigs.PublicKeyFromKeyRef(ctx, keyRef)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading public key: %w\", err)\n\t\t}\n\t\tpkcs11Key, ok := co.SigVerifier.(*pkcs11key.Key)\n\t\tif ok {\n\t\t\tdefer pkcs11Key.Close()\n\t\t}\n\tcase c.Sk:\n\t\tsk, err := pivkey.GetKeyWithSlot(c.Slot)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"opening piv token: %w\", err)\n\t\t}\n\t\tdefer sk.Close()\n\t\tco.SigVerifier, err = sk.Verifier()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"initializing piv token verifier: %w\", err)\n\t\t}\n\tcase c.CertRef != \"\":\n\t\tcert, err := loadCertFromFileOrURL(c.CertRef)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading certificate from reference: %w\", err)\n\t\t}\n\t\tif c.CertChain == \"\" {\n\t\t\terr = cosign.CheckCertificatePolicy(cert, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tco.SigVerifier, err = signature.LoadVerifier(cert.PublicKey, crypto.SHA256)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating certificate verifier: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\t// Verify certificate with chain\n\t\t\tchain, err := loadCertChainFromFileOrURL(c.CertChain)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tco.SigVerifier, err = cosign.ValidateAndUnpackCertWithChain(cert, chain, co)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating certificate verifier: %w\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// NB: There are only 2 kinds of verification right now:\n\t// 1. You gave us the public key explicitly to verify against so co.SigVerifier is non-nil or,\n\t// 2. We're going to find an x509 certificate on the signature and verify against Fulcio root trust\n\t// TODO(nsmith5): Refactor this verification logic to pass back _how_ verification\n\t// was performed so we don't need to use this fragile logic here.\n\tfulcioVerified := (co.SigVerifier == nil)\n\n\tfor _, imageRef := range images {\n\t\tvar verified []oci.Signature\n\t\tvar bundleVerified bool\n\n\t\tif c.LocalImage {\n\t\t\tverified, bundleVerified, err = cosign.VerifyLocalImageAttestations(ctx, imageRef, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tref, err := name.ParseReference(imageRef)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tverified, bundleVerified, err = cosign.VerifyImageAttestations(ctx, ref, co)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tvar cuePolicies, regoPolicies []string\n\n\t\tfor _, policy := range c.Policies {\n\t\t\tswitch filepath.Ext(policy) {\n\t\t\tcase \".rego\":\n\t\t\t\tregoPolicies = append(regoPolicies, policy)\n\t\t\tcase \".cue\":\n\t\t\t\tcuePolicies = append(cuePolicies, policy)\n\t\t\tdefault:\n\t\t\t\treturn errors.New(\"invalid policy format, expected .cue or .rego\")\n\t\t\t}\n\t\t}\n\n\t\tvar checked []oci.Signature\n\t\tvar validationErrors []error\n\t\tfor _, vp := range verified {\n\t\t\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"converting to consumable policy validation: %w\", err)\n\t\t\t}\n\t\t\tif len(payload) == 0 {\n\t\t\t\t// This is not the predicate type we're looking for.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif len(cuePolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against CUE policies: %v\\n\", cuePolicies)\n\t\t\t\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\n\t\t\t\tif cueValidationErr != nil {\n\t\t\t\t\tvalidationErrors = append(validationErrors, cueValidationErr)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif len(regoPolicies) > 0 {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"will be validating against Rego policies: %v\\n\", regoPolicies)\n\t\t\t\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\n\t\t\t\tif len(regoValidationErrs) > 0 {\n\t\t\t\t\tvalidationErrors = append(validationErrors, regoValidationErrs...)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tchecked = append(checked, vp)\n\t\t}\n\n\t\tif len(validationErrors) > 0 {\n\t\t\tfmt.Fprintf(os.Stderr, \"There are %d number of errors occurred during the validation:\\n\", len(validationErrors))\n\t\t\tfor _, v := range validationErrors {\n\t\t\t\t_, _ = fmt.Fprintf(os.Stderr, \"- %v\\n\", v)\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\n\t\t}\n\n\t\tif len(checked) == 0 {\n\t\t\treturn fmt.Errorf(\"none of the attestations matched the predicate type: %s\", c.PredicateType)\n\t\t}\n\n\t\t// TODO: add CUE validation report to `PrintVerificationHeader`.\n\t\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\n\t\t// The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\n\t\tPrintVerification(imageRef, checked, \"text\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.desc, func(t *testing.T) {\n\n\t\t\tpolicy := &structs.ACLPolicy{\n\t\t\t\tName:  \"some-policy\",\n\t\t\t\tRules: tc.policyBeforeRules,\n\t\t\t}\n\t\t\tpolicy.SetHash()\n\n\t\t\ttokenProvider := &fakeACLTokenProvider{\n\t\t\t\tpolicy: policy,\n\t\t\t\ttoken: &structs.ACLToken{\n\t\t\t\t\tSecretID: secretID,\n\t\t\t\t\tPolicies: []string{policy.Name},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\taclDelegate := &fakeACLDelegate{\n\t\t\t\ttokenProvider: tokenProvider,\n\t\t\t}\n\n\t\t\tpublisher, err := NewEventBroker(ctx, aclDelegate, EventBrokerCfg{})\n\t\t\trequire.NoError(t, err)\n\n\t\t\tvar ns string\n\t\t\tif tc.event.Namespace != \"\" {\n\t\t\t\tns = tc.event.Namespace\n\t\t\t} else {\n\t\t\t\tns = structs.DefaultNamespace\n\t\t\t}\n\n\t\t\tsub, expiryTime, err := publisher.SubscribeWithACLCheck(&SubscribeRequest{\n\t\t\t\tTopics: map[structs.Topic][]string{\n\t\t\t\t\ttc.event.Topic: {\"*\"},\n\t\t\t\t},\n\t\t\t\tNamespace: ns,\n\t\t\t\tToken:     secretID,\n\t\t\t})\n\t\t\trequire.Nil(t, expiryTime)\n\n\t\t\tif tc.initialSubErr {\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.Nil(t, sub)\n\t\t\t\treturn\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t\tpublisher.Publish(&structs.Events{Index: 100, Events: []structs.Event{tc.event}})\n\n\t\t\tctx, cancel := context.WithDeadline(ctx, time.Now().Add(100*time.Millisecond))\n\t\t\tdefer cancel()\n\t\t\t_, err = sub.Next(ctx)\n\t\t\trequire.NoError(t, err)\n\n\t\t\t// Update the mock provider to use the after rules\n\t\t\tpolicyAfter := &structs.ACLPolicy{\n\t\t\t\tName:        \"some-new-policy\",\n\t\t\t\tRules:       tc.policyAfterRules,\n\t\t\t\tModifyIndex: 101, // The ModifyIndex is used to caclulate the acl cache key\n\t\t\t}\n\t\t\tpolicyAfter.SetHash()\n\n\t\t\ttokenProvider.policy = policyAfter\n\n\t\t\t// Publish ACL event triggering subscription re-evaluation\n\t\t\tpublisher.Publish(&structs.Events{Index: 101, Events: []structs.Event{tc.policyEvent}})\n\t\t\t// Publish another event\n\t\t\tpublisher.Publish(&structs.Events{Index: 102, Events: []structs.Event{tc.event}})\n\n\t\t\t// If we are expecting to unsubscribe consume the subscription\n\t\t\t// until the expected error occurs.\n\t\t\tctx, cancel = context.WithDeadline(ctx, time.Now().Add(100*time.Millisecond))\n\t\t\tdefer cancel()\n\t\t\tif tc.shouldUnsubscribe {\n\t\t\t\tfor {\n\t\t\t\t\t_, err = sub.Next(ctx)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif err == context.DeadlineExceeded {\n\t\t\t\t\t\t\trequire.Fail(t, err.Error())\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif err == ErrSubscriptionClosed {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t_, err = sub.Next(ctx)\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\n\t\t\tpublisher.Publish(&structs.Events{Index: 103, Events: []structs.Event{tc.event}})\n\n\t\t\tctx, cancel = context.WithDeadline(ctx, time.Now().Add(100*time.Millisecond))\n\t\t\tdefer cancel()\n\t\t\t_, err = sub.Next(ctx)\n\t\t\tif tc.shouldUnsubscribe {\n\t\t\t\trequire.Equal(t, ErrSubscriptionClosed, err)\n\t\t\t} else {\n\t\t\t\trequire.NoError(t, err)\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "\terr = b.Restore(s.Context(), reader, func(file string, info fs.FileInfo, r io.ReadCloser) error {\n\t\tdefer r.Close()\n\t\ts.Events().Publish(DaemonMessageEvent, \"(restoring): \"+file)\n\n\t\tif err := s.Filesystem().Writefile(file, r); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := s.Filesystem().Chmod(file, info.Mode()); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tatime := info.ModTime()\n\t\tmtime := atime\n\t\treturn s.Filesystem().Chtimes(file, atime, mtime)\n\t})", "is_vulnerable": 1}
{"code": "\tcyclicErrorHandler = func(context.Context) (*ResolveCheckResponse, error) {\n\t\treturn nil, ErrCycleDetected\n\t}", "is_vulnerable": 1}
{"code": "func (h *AuthHandlers) UserKeyAuth(conn ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\tfingerprint := fmt.Sprintf(\"%v %v\", key.Type(), sshutils.Fingerprint(key))\n\n\t// create a new logging entry with info specific to this login attempt\n\tlog := h.Entry.WithField(trace.ComponentFields, log.Fields{\n\t\t\"local\":       conn.LocalAddr(),\n\t\t\"remote\":      conn.RemoteAddr(),\n\t\t\"user\":        conn.User(),\n\t\t\"fingerprint\": fingerprint,\n\t})\n\n\tcid := fmt.Sprintf(\"conn(%v->%v, user=%v)\", conn.RemoteAddr(), conn.LocalAddr(), conn.User())\n\tlog.Debugf(\"%v auth attempt\", cid)\n\n\tcert, ok := key.(*ssh.Certificate)\n\tlog.Debugf(\"%v auth attempt with key %v, %#v\", cid, fingerprint, cert)\n\tif !ok {\n\t\tlog.Debugf(\"auth attempt, unsupported key type\")\n\t\treturn nil, trace.BadParameter(\"unsupported key type: %v\", fingerprint)\n\t}\n\tif len(cert.ValidPrincipals) == 0 {\n\t\tlog.Debugf(\"need a valid principal for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid principal for key %v\", fingerprint)\n\t}\n\tif len(cert.KeyId) == 0 {\n\t\tlog.Debugf(\"need a valid key ID for key\")\n\t\treturn nil, trace.BadParameter(\"need a valid key for key %v\", fingerprint)\n\t}\n\tteleportUser := cert.KeyId\n\n\t// only failed attempts are logged right now\n\trecordFailedLogin := func(err error) {\n\t\tfailedLoginCount.Inc()\n\t\tif err := h.Emitter.EmitAuditEvent(h.Server.Context(), &events.AuthAttempt{\n\t\t\tMetadata: events.Metadata{\n\t\t\t\tType: events.AuthAttemptEvent,\n\t\t\t\tCode: events.AuthAttemptFailureCode,\n\t\t\t},\n\t\t\tUserMetadata: events.UserMetadata{\n\t\t\t\tLogin: conn.User(),\n\t\t\t\tUser:  teleportUser,\n\t\t\t},\n\t\t\tConnectionMetadata: events.ConnectionMetadata{\n\t\t\t\tLocalAddr:  conn.LocalAddr().String(),\n\t\t\t\tRemoteAddr: conn.RemoteAddr().String(),\n\t\t\t},\n\t\t\tStatus: events.Status{\n\t\t\t\tSuccess: false,\n\t\t\t\tError:   err.Error(),\n\t\t\t},\n\t\t}); err != nil {\n\t\t\th.WithError(err).Warn(\"Failed to emit failed login audit event.\")\n\t\t}\n\t}\n\n\t// Check that the user certificate uses supported public key algorithms, was\n\t// issued by Teleport, and check the certificate metadata (principals,\n\t// timestamp, etc). Fallback to keys is not supported.\n\tclock := time.Now\n\tif h.Clock != nil {\n\t\tclock = h.Clock.Now\n\t}\n\tcertChecker := apisshutils.CertChecker{\n\t\tCertChecker: ssh.CertChecker{\n\t\t\tIsUserAuthority: h.IsUserAuthority,\n\t\t\tClock:           clock,\n\t\t},\n\t\tFIPS: h.FIPS,\n\t}\n\tpermissions, err := certChecker.Authenticate(conn, key)\n\tif err != nil {\n\t\tcertificateMismatchCount.Inc()\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\tlog.Debugf(\"Successfully authenticated\")\n\n\tclusterName, err := h.AccessPoint.GetClusterName()\n\tif err != nil {\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\t// this is the only way we know of to pass valid additional data about the\n\t// connection to the handlers\n\tpermissions.Extensions[utils.CertTeleportUser] = teleportUser\n\tpermissions.Extensions[utils.CertTeleportClusterName] = clusterName.GetClusterName()\n\tpermissions.Extensions[utils.CertTeleportUserCertificate] = string(ssh.MarshalAuthorizedKey(cert))\n\n\tif h.isProxy() {\n\t\treturn permissions, nil\n\t}\n\n\t// check if the user has permission to log into the node.\n\tswitch {\n\tcase h.Component == teleport.ComponentForwardingNode:\n\t\terr = h.canLoginWithoutRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\tdefault:\n\t\terr = h.canLoginWithRBAC(cert, clusterName.GetClusterName(), teleportUser, conn.User())\n\t}\n\tif err != nil {\n\t\tlog.Errorf(\"Permission denied: %v\", err)\n\t\trecordFailedLogin(err)\n\t\treturn nil, trace.Wrap(err)\n\t}\n\n\treturn permissions, nil\n}", "is_vulnerable": 0}
{"code": "func (t *handshakeTransport) readLoop() {\n\tfirst := true\n\tfor {\n\t\tp, err := t.readOnePacket(first)\n\t\tfirst = false\n\t\tif err != nil {\n\t\t\tt.readError = err\n\t\t\tclose(t.incoming)\n\t\t\tbreak\n\t\t}\n\t\t// If this is the first kex, and strict KEX mode is enabled,\n\t\t// we don't ignore any messages, as they may be used to manipulate\n\t\t// the packet sequence numbers.\n\t\tif !(t.sessionID == nil && t.strictMode) && (p[0] == msgIgnore || p[0] == msgDebug) {\n\t\t\tcontinue\n\t\t}\n\t\tt.incoming <- p\n\t}\n\n\t// Stop writers too.\n\tt.recordWriteError(t.readError)\n\n\t// Unblock the writer should it wait for this.\n\tclose(t.startKex)\n\n\t// Don't close t.requestKex; it's also written to from writePacket.\n}", "is_vulnerable": 0}
{"code": "func (s *SmartTransactionParser) Action(in *InToCxt, out *OutCtx) (err error) {\n\tvar res string\n\tdefer func() {\n\t\tif len(res) > 255 {\n\t\t\tres = res[:252] + \"...\"\n\t\t}\n\t\tret := &pbgo.TxResult{\n\t\t\tResult: res,\n\t\t\tHash:   out.TxResult.Hash,\n\t\t}\n\t\tif s.Penalty {\n\t\t\tret.Code = pbgo.TxInvokeStatusCode_PENALTY\n\t\t\tret.BlockId = s.BlockHeader.BlockId\n\t\t}\n\t\tout.Apply(\n\t\t\tWithOutCtxTxResult(ret),\n\t\t\tWithOutCtxRollBackTx(s.RollBackTx),\n\t\t)\n\t\tif err != nil || s.Penalty {\n\t\t\tif s.FlushRollback != nil {\n\t\t\t\tflush := s.FlushRollback\n\t\t\t\tfor i := len(flush) - 1; i >= 0; i-- {\n\t\t\t\t\tflush[i].FlushVM()\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tret.Code = pbgo.TxInvokeStatusCode_SUCCESS\n\t\tret.BlockId = s.BlockHeader.BlockId\n\t\tout.Apply(\n\t\t\tWithOutCtxTxResult(ret),\n\t\t\tWithOutCtxSysUpdate(s.SysUpdate),\n\t\t\tWithOutCtxTxOutputs(s.TxOutputsMap),\n\t\t\tWithOutCtxTxInputs(s.TxInputsMap),\n\t\t)\n\t\t//in.DbTransaction.BinLogSql = s.DbTransaction.BinLogSql\n\t}()\n\n\t_transferSelf := s.TxSmart.TransferSelf\n\tif _transferSelf != nil {\n\t\t_, err = smart.TransferSelf(s.SmartContract, _transferSelf.Value, _transferSelf.Source, _transferSelf.Target)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = in.TxCheckLimits.CheckLimit(s)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\t_utxo := s.TxSmart.UTXO\n\tif _utxo != nil {\n\t\t_, err = smart.UtxoToken(s.SmartContract, _utxo.ToID, _utxo.Value)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = in.TxCheckLimits.CheckLimit(s)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\tres, err = s.CallContract(in.SqlDbSavePoint)\n\tif err == nil && s.TxSmart != nil {\n\t\terr = in.TxCheckLimits.CheckLimit(s)\n\t}\n\tif err != nil {\n\t\treturn\n\t}\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestSignaturesBundle(t *testing.T) {\n\ttd := t.TempDir()\n\tfp := filepath.Join(td, \"file\")\n\n\tsig := \"a==\"\n\tb64sig := \"YT09\"\n\n\t// save as a LocalSignedPayload to the file\n\tlsp := cosign.LocalSignedPayload{\n\t\tBase64Signature: b64sig,\n\t}\n\tcontents, err := json.Marshal(lsp)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif err := os.WriteFile(fp, contents, 0644); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tgotSig, err := signatures(\"\", fp)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif gotSig != sig {\n\t\tt.Fatalf(\"unexpected signature, expected: %s got: %s\", sig, gotSig)\n\t}\n}", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn upstreamhashby{r}\n}", "is_vulnerable": 1}
{"code": "func (lt *limitTracker) clone(ctx context.Context) (*limitTracker, context.Context) {\n\twithCancel, cancel := context.WithCancel(ctx)\n\treturn &limitTracker{\n\t\tcurrentLimit: lt.currentLimit,\n\t\thasLimit:     lt.hasLimit,\n\t\tcancel:       cancel,\n\t}, withCancel\n}", "is_vulnerable": 1}
{"code": "func TestConfig_ParseCiphers(t *testing.T) {\n\ttestOk := strings.Join([]string{\n\t\t\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_128_GCM_SHA256\",\n\t\t\"TLS_RSA_WITH_AES_256_GCM_SHA384\",\n\t\t\"TLS_RSA_WITH_AES_128_CBC_SHA256\",\n\t\t\"TLS_RSA_WITH_AES_128_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_AES_256_CBC_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_3DES_EDE_CBC_SHA\",\n\t\t\"TLS_RSA_WITH_RC4_128_SHA\",\n\t\t\"TLS_ECDHE_RSA_WITH_RC4_128_SHA\",\n\t\t\"TLS_ECDHE_ECDSA_WITH_RC4_128_SHA\",\n\t}, \",\")\n\tciphers := []uint16{\n\t\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_AES_128_GCM_SHA256,\n\t\ttls.TLS_RSA_WITH_AES_256_GCM_SHA384,\n\t\ttls.TLS_RSA_WITH_AES_128_CBC_SHA256,\n\t\ttls.TLS_RSA_WITH_AES_128_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_AES_256_CBC_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_3DES_EDE_CBC_SHA,\n\t\ttls.TLS_RSA_WITH_RC4_128_SHA,\n\t\ttls.TLS_ECDHE_RSA_WITH_RC4_128_SHA,\n\t\ttls.TLS_ECDHE_ECDSA_WITH_RC4_128_SHA,\n\t}\n\tv, err := ParseCiphers(testOk)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif got, want := v, ciphers; !reflect.DeepEqual(got, want) {\n\t\tt.Fatalf(\"got ciphers %#v want %#v\", got, want)\n\t}\n\n\ttestBad := \"TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,cipherX\"\n\tif _, err := ParseCiphers(testBad); err == nil {\n\t\tt.Fatal(\"should fail on unsupported cipherX\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (g *GSSResponse) Encode(dst []byte) []byte {\n\tdst = append(dst, 'p')\n\tdst = pgio.AppendInt32(dst, int32(4+len(g.Data)))\n\tdst = append(dst, g.Data...)\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func TestWithoutAnnotations(t *testing.T) {\n\ting := buildIngress()\n\t_, err := NewParser(mockBackend{}).Parse(ing)\n\tif err != nil && !errors.IsMissingAnnotations(err) {\n\t\tt.Errorf(\"unexpected error with ingress without annotations: %s\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestGenerateBytes(t *testing.T) {\n\tb := generateBytes(5)\n\tif e, a := 5, len(b); e != a {\n\t\tt.Errorf(\"expected %d, but received %d\", e, a)\n\t}\n\tb = generateBytes(0)\n\tif e, a := 0, len(b); e != a {\n\t\tt.Errorf(\"expected %d, but received %d\", e, a)\n\t}\n\tb = generateBytes(1024)\n\tif e, a := 1024, len(b); e != a {\n\t\tt.Errorf(\"expected %d, but received %d\", e, a)\n\t}\n}", "is_vulnerable": 1}
{"code": "\twrapper := func(dc string, conn net.Conn) (net.Conn, error) {\n\t\tif c.base.VerifyServerHostname {\n\t\t\t// Strip the trailing '.' from the domain if any\n\t\t\tdomain := strings.TrimSuffix(c.base.Domain, \".\")\n\t\t\ttlsConfig = tlsConfig.Clone()\n\t\t\ttlsConfig.ServerName = \"server.\" + dc + \".\" + domain\n\t\t}\n\t\treturn c.base.wrapTLSClient(conn, tlsConfig)\n\t}", "is_vulnerable": 1}
{"code": "\tDescribe(\"creating a json payload\", func() {\n\t\tlimits := types.MessageLimit{\n\t\t\tChunkSize:      2000,\n\t\t\tTotalChunkSize: 6000,\n\t\t\tChunkCount:     10,\n\t\t}\n\t\tWhen(\"given a message that exceeds the max length\", func() {\n\t\t\tWhen(\"not splitting by lines\", func() {\n\t\t\t\tIt(\"should return a payload with chunked messages\", func() {\n\n\t\t\t\t\titems, _ := testPartitionMessage(42, limits, 100)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(1994))\n\t\t\t\t\tExpect(len(items[1].Text)).To(Equal(1999))\n\t\t\t\t\tExpect(len(items[2].Text)).To(Equal(205))\n\t\t\t\t})\n\t\t\t\tIt(\"omit characters above total max\", func() {\n\t\t\t\t\titems, _ := testPartitionMessage(62, limits, 100)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(1994))\n\t\t\t\t\tExpect(len(items[1].Text)).To(Equal(1999))\n\t\t\t\t\tExpect(len(items[2].Text)).To(Equal(1999))\n\t\t\t\t\tExpect(len(items[3].Text)).To(Equal(5))\n\t\t\t\t})\n\t\t\t})\n\t\t\tWhen(\"splitting by lines\", func() {\n\t\t\t\tIt(\"should return a payload with chunked messages\", func() {\n\t\t\t\t\titems, omitted := testMessageItemsFromLines(18, limits, 2)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(200))\n\t\t\t\t\tExpect(len(items[8].Text)).To(Equal(200))\n\n\t\t\t\t\tExpect(omitted).To(Equal(0))\n\t\t\t\t})\n\t\t\t\tIt(\"omit characters above total max\", func() {\n\t\t\t\t\titems, omitted := testMessageItemsFromLines(19, limits, 2)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(200))\n\t\t\t\t\tExpect(len(items[8].Text)).To(Equal(200))\n\n\t\t\t\t\tExpect(omitted).To(Equal(100))\n\t\t\t\t})\n\t\t\t\tIt(\"should trim characters above chunk size\", func() {\n\t\t\t\t\thundreds := 42\n\t\t\t\t\trepeat := 21\n\t\t\t\t\titems, omitted := testMessageItemsFromLines(hundreds, limits, repeat)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(limits.ChunkSize))\n\t\t\t\t\tExpect(len(items[1].Text)).To(Equal(limits.ChunkSize))\n\n\t\t\t\t\t// Trimmed characters do not count towards the total omitted count\n\t\t\t\t\tExpect(omitted).To(Equal(0))\n\t\t\t\t})\n\n\t\t\t\tIt(\"omit characters above total chunk size\", func() {\n\t\t\t\t\thundreds := 100\n\t\t\t\t\trepeat := 20\n\t\t\t\t\titems, omitted := testMessageItemsFromLines(hundreds, limits, repeat)\n\n\t\t\t\t\tExpect(len(items[0].Text)).To(Equal(limits.ChunkSize))\n\t\t\t\t\tExpect(len(items[1].Text)).To(Equal(limits.ChunkSize))\n\t\t\t\t\tExpect(len(items[2].Text)).To(Equal(limits.ChunkSize))\n\n\t\t\t\t\tmaxRunes := hundreds * 100\n\t\t\t\t\texpectedOmitted := maxRunes - limits.TotalChunkSize\n\n\t\t\t\t\tExpect(omitted).To(Equal(expectedOmitted))\n\t\t\t\t})\n\n\t\t\t})\n\n\t\t})\n\t})", "is_vulnerable": 1}
{"code": "func (m *Nil) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Nil: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (src *FunctionCall) Encode(dst []byte) []byte {\n\tdst = append(dst, 'F')\n\tsp := len(dst)\n\tdst = pgio.AppendUint32(dst, 0) // Unknown length, set it at the end\n\tdst = pgio.AppendUint32(dst, src.Function)\n\tdst = pgio.AppendUint16(dst, uint16(len(src.ArgFormatCodes)))\n\tfor _, argFormatCode := range src.ArgFormatCodes {\n\t\tdst = pgio.AppendUint16(dst, argFormatCode)\n\t}\n\tdst = pgio.AppendUint16(dst, uint16(len(src.Arguments)))\n\tfor _, argument := range src.Arguments {\n\t\tif argument == nil {\n\t\t\tdst = pgio.AppendInt32(dst, -1)\n\t\t} else {\n\t\t\tdst = pgio.AppendInt32(dst, int32(len(argument)))\n\t\t\tdst = append(dst, argument...)\n\t\t}\n\t}\n\tdst = pgio.AppendUint16(dst, src.ResultFormatCode)\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (v *View) UserByLoginName(ctx context.Context, loginName, instanceID string) (*model.UserView, error) {\n\tqueriedUser, err := v.query.GetNotifyUserByLoginName(ctx, true, loginName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//nolint: contextcheck // no lint was added because refactor would change too much code\n\treturn view.UserByID(v.Db, userTable, queriedUser.ID, instanceID)\n}", "is_vulnerable": 1}
{"code": "var arcKeyDirectory = func() (string, error) {\n\tswitch runtime.GOOS {\n\tcase \"linux\":\n\t\treturn \"/var/opt/azcmagent/tokens\", nil\n\tcase \"windows\":\n\t\treturn filepath.Join(os.Getenv(\"ProgramData\"), \"AzureConnectedMachineAgent\", \"Tokens\"), nil\n\tdefault:\n\t\treturn \"\", fmt.Errorf(\"unsupported OS %q\", runtime.GOOS)\n\t}\n}", "is_vulnerable": 0}
{"code": "func CopyConfig(config *Config) *Config {\n\treturn &Config{\n\t\tHost:          config.Host,\n\t\tAPIPath:       config.APIPath,\n\t\tContentConfig: config.ContentConfig,\n\t\tUsername:      config.Username,\n\t\tPassword:      config.Password,\n\t\tBearerToken:   config.BearerToken,\n\t\tImpersonate: ImpersonationConfig{\n\t\t\tGroups:   config.Impersonate.Groups,\n\t\t\tExtra:    config.Impersonate.Extra,\n\t\t\tUserName: config.Impersonate.UserName,\n\t\t},\n\t\tAuthProvider:        config.AuthProvider,\n\t\tAuthConfigPersister: config.AuthConfigPersister,\n\t\tExecProvider:        config.ExecProvider,\n\t\tTLSClientConfig: TLSClientConfig{\n\t\t\tInsecure:   config.TLSClientConfig.Insecure,\n\t\t\tServerName: config.TLSClientConfig.ServerName,\n\t\t\tCertFile:   config.TLSClientConfig.CertFile,\n\t\t\tKeyFile:    config.TLSClientConfig.KeyFile,\n\t\t\tCAFile:     config.TLSClientConfig.CAFile,\n\t\t\tCertData:   config.TLSClientConfig.CertData,\n\t\t\tKeyData:    config.TLSClientConfig.KeyData,\n\t\t\tCAData:     config.TLSClientConfig.CAData,\n\t\t},\n\t\tUserAgent:     config.UserAgent,\n\t\tTransport:     config.Transport,\n\t\tWrapTransport: config.WrapTransport,\n\t\tQPS:           config.QPS,\n\t\tBurst:         config.Burst,\n\t\tRateLimiter:   config.RateLimiter,\n\t\tTimeout:       config.Timeout,\n\t\tDial:          config.Dial,\n\t}\n}", "is_vulnerable": 1}
{"code": "func (h *Handler) DefaultErrorHandler(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {\n\th.L.Warnln(\"A client requested the default error URL, environment variable OAUTH2_ERROR_URL is probably not set.\")\n\n\tt, err := template.New(\"consent\").Parse(`\n<html>\n<head>\n\t<title>An OAuth 2.0 Error Occurred</title>\n</head>\n<body>\n<h1>\n\tThe OAuth2 request resulted in an error.\n</h1>\n<ul>\n\t<li>Error: {{ .Name }}</li>\n\t<li>Description: {{ .Description }}</li>\n\t<li>Hint: {{ .Hint }}</li>\n\t<li>Debug: {{ .Debug }}</li>\n</ul>\n<p>\n\tYou are seeing this default error page because the administrator has not set a dedicated error URL (environment variable <code>OAUTH2_ERROR_URL</code> is not set). \n\tIf you are an administrator, please read <a href=\"https://www.ory.sh/docs\">the guide</a> to understand what you\n\tneed to do. If you are a user, please contact the administrator.\n</p>\n</body>\n</html>\n`)\n\tif err != nil {\n\t\th.H.WriteError(w, r, err)\n\t\treturn\n\t}\n\n\tif err := t.Execute(w, struct {\n\t\tName        string\n\t\tDescription string\n\t\tHint        string\n\t\tDebug       string\n\t}{\n\t\tName:        r.URL.Query().Get(\"error\"),\n\t\tDescription: r.URL.Query().Get(\"error_description\"),\n\t\tHint:        r.URL.Query().Get(\"error_hint\"),\n\t\tDebug:       r.URL.Query().Get(\"error_debug\"),\n\t}); err != nil {\n\t\th.H.WriteError(w, r, err)\n\t\treturn\n\t}\n}", "is_vulnerable": 0}
{"code": "func connectClient(t *testing.T, s1 *Server, mb pool.RPCType, useTLS, wantOpen bool, message string) net.Conn {\n\tt.Helper()\n\n\taddr := s1.config.RPCAdvertise\n\ttlsWrap := s1.tlsConfigurator.OutgoingRPCWrapper()\n\n\tconn, err := net.DialTimeout(\"tcp\", addr.String(), time.Second)\n\trequire.NoError(t, err)\n\n\t// Write magic byte so we aren't timed out\n\touterByte := mb\n\tif useTLS {\n\t\touterByte = pool.RPCTLS\n\t}\n\t_, err = conn.Write([]byte{byte(outerByte)})\n\trequire.NoError(t, err)\n\n\tif useTLS {\n\t\ttlsConn, err := tlsWrap(s1.config.Datacenter, conn)\n\t\t// Subtly, tlsWrap will NOT actually do a handshake in this case - it only\n\t\t// does so for some configs, so even if the server closed the conn before\n\t\t// handshake this won't fail and it's only when we attempt to read or write\n\t\t// that we'll see the broken pipe.\n\t\trequire.NoError(t, err, \"%s: wanted open conn, failed TLS handshake: %s\",\n\t\t\tmessage, err)\n\t\tconn = tlsConn\n\n\t\t// Write Inner magic byte\n\t\t_, err = conn.Write([]byte{byte(mb)})\n\t\tif !wantOpen {\n\t\t\t// TLS Handshake will be done on this attempt to write and should fail\n\t\t\trequire.Error(t, err, \"%s: wanted closed conn, TLS Handshake succeeded\", message)\n\t\t} else {\n\t\t\trequire.NoError(t, err, \"%s: wanted open conn, failed writing inner magic byte: %s\",\n\t\t\t\tmessage, err)\n\t\t}\n\t}\n\n\t// Check if the conn is in the state we want.\n\tretry.Run(t, func(r *retry.R) {\n\t\t// Don't wait around as server won't be sending data but the read will fail\n\t\t// immediately if the conn is closed.\n\t\tconn.SetReadDeadline(time.Now().Add(1 * time.Millisecond))\n\t\tbuf := make([]byte, 10)\n\t\t_, err := conn.Read(buf)\n\t\trequire.Error(r, err)\n\t\tif wantOpen {\n\t\t\trequire.Contains(r, err.Error(), \"i/o timeout\",\n\t\t\t\t\"%s: wanted an open conn (read timeout)\", message)\n\t\t} else {\n\t\t\tif useTLS {\n\t\t\t\trequire.Error(r, err)\n\t\t\t\t// TLS may fail during either read or write of the handshake so there\n\t\t\t\t// are a few different errors that come up.\n\t\t\t\tif !strings.Contains(err.Error(), \"read: connection reset by peer\") &&\n\t\t\t\t\t!strings.Contains(err.Error(), \"write: connection reset by peer\") &&\n\t\t\t\t\t!strings.Contains(err.Error(), \"write: broken pipe\") {\n\t\t\t\t\tr.Fatalf(\"%s: wanted closed conn got err: %s\", message, err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trequire.Contains(r, err.Error(), \"EOF\", \"%s: wanted a closed conn\",\n\t\t\t\t\tmessage)\n\t\t\t}\n\t\t}\n\t})\n\n\treturn conn\n}", "is_vulnerable": 0}
{"code": "\trequireServiceHealthName := func(t *testing.T, serviceName, expected string, shouldExist bool) {\n\t\tmsg := fmt.Sprintf(\"service name:%s, shouldExist:%v, expectedStatus:%s : bad %%s\", serviceName, shouldExist, expected)\n\n\t\tstate, outs, err := agent.AgentHealthServiceByName(serviceName)\n\t\trequire.Nil(t, err, msg, \"err\")\n\t\trequire.Equal(t, expected, state, msg, \"state\")\n\t\tif !shouldExist {\n\t\t\trequire.Equal(t, 0, len(outs), msg, \"output\")\n\t\t} else {\n\t\t\trequire.True(t, len(outs) > 0, msg, \"output\")\n\t\t\tfor _, o := range outs {\n\t\t\t\trequire.Equal(t, serviceName, o.Service.Service, msg, \"output\")\n\t\t\t}\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func testV3AuthWithLeaseRevokeWithRoot(t *testing.T, ccfg integration.ClusterConfig) {\n\tintegration.BeforeTest(t)\n\n\tclus := integration.NewCluster(t, &ccfg)\n\tdefer clus.Terminate(t)\n\n\tapi := integration.ToGRPC(clus.Client(0))\n\tauthSetupRoot(t, api.Auth)\n\n\trootc, cerr := integration.NewClient(t, clientv3.Config{\n\t\tEndpoints: clus.Client(0).Endpoints(),\n\t\tUsername:  \"root\",\n\t\tPassword:  \"123\",\n\t})\n\tif cerr != nil {\n\t\tt.Fatal(cerr)\n\t}\n\tdefer rootc.Close()\n\n\tleaseResp, err := rootc.Grant(context.TODO(), 2)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tleaseID := leaseResp.ID\n\n\tif _, err = rootc.Put(context.TODO(), \"foo\", \"bar\", clientv3.WithLease(leaseID)); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// wait for lease expire\n\ttime.Sleep(3 * time.Second)\n\n\ttresp, terr := api.Lease.LeaseTimeToLive(\n\t\tcontext.TODO(),\n\t\t&pb.LeaseTimeToLiveRequest{\n\t\t\tID:   int64(leaseID),\n\t\t\tKeys: true,\n\t\t},\n\t)\n\tif terr != nil {\n\t\tt.Error(terr)\n\t}\n\tif len(tresp.Keys) > 0 || tresp.GrantedTTL != 0 {\n\t\tt.Errorf(\"lease %016x should have been revoked, got %+v\", leaseID, tresp)\n\t}\n\tif tresp.TTL != -1 {\n\t\tt.Errorf(\"lease %016x should have been expired, got %+v\", leaseID, tresp)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (p *parser) markExprAsParenthesized(value js_ast.Expr) {\n\tswitch e := value.Data.(type) {\n\tcase *js_ast.EArray:\n\t\te.IsParenthesized = true\n\tcase *js_ast.EObject:\n\t\te.IsParenthesized = true\n\t}\n}", "is_vulnerable": 1}
{"code": "func (r *transcodingRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\treturn r.count(Select(), r.parseRestOptions(options...))\n}", "is_vulnerable": 1}
{"code": "func TestStartupMessage(t *testing.T) {\n\tt.Parallel()\n\n\tt.Run(\"valid StartupMessage\", func(t *testing.T) {\n\t\twant := &pgproto3.StartupMessage{\n\t\t\tProtocolVersion: pgproto3.ProtocolVersionNumber,\n\t\t\tParameters: map[string]string{\n\t\t\t\t\"username\": \"tester\",\n\t\t\t},\n\t\t}\n\t\tdst := []byte{}\n\t\tdst = want.Encode(dst)\n\n\t\tserver := &interruptReader{}\n\t\tserver.push(dst)\n\n\t\tbackend := pgproto3.NewBackend(pgproto3.NewChunkReader(server), nil)\n\n\t\tmsg, err := backend.ReceiveStartupMessage()\n\t\trequire.NoError(t, err)\n\t\trequire.Equal(t, want, msg)\n\t})\n\n\tt.Run(\"invalid packet length\", func(t *testing.T) {\n\t\twantErr := \"invalid length of startup packet\"\n\t\ttests := []struct {\n\t\t\tname      string\n\t\t\tpacketLen uint32\n\t\t}{\n\t\t\t{\n\t\t\t\tname: \"large packet length\",\n\t\t\t\t// Since the StartupMessage contains the \"Length of message contents\n\t\t\t\t//  in bytes, including self\", the max startup packet length is actually\n\t\t\t\t//  10000+4. Therefore, let's go past the limit with 10005\n\t\t\t\tpacketLen: 10005,\n\t\t\t},\n\t\t\t{\n\t\t\t\tname:      \"short packet length\",\n\t\t\t\tpacketLen: 3,\n\t\t\t},\n\t\t}\n\t\tfor _, tt := range tests {\n\t\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\t\tserver := &interruptReader{}\n\t\t\t\tdst := []byte{}\n\t\t\t\tdst = pgio.AppendUint32(dst, tt.packetLen)\n\t\t\t\tdst = pgio.AppendUint32(dst, pgproto3.ProtocolVersionNumber)\n\t\t\t\tserver.push(dst)\n\n\t\t\t\tbackend := pgproto3.NewBackend(pgproto3.NewChunkReader(server), nil)\n\n\t\t\t\tmsg, err := backend.ReceiveStartupMessage()\n\t\t\t\trequire.Error(t, err)\n\t\t\t\trequire.Nil(t, msg)\n\t\t\t\trequire.Contains(t, err.Error(), wantErr)\n\t\t\t})\n\t\t}\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestCheckMountDestFalsePositive(t *testing.T) {\n\tdest := \"/rootfs/sysfiles/fs/cgroup\"\n\terr := checkProcMount(\"/rootfs\", dest, \"\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockERC20BridgeViewMockRecorder) FindAssetLimitsUpdated(arg0, arg1, arg2, arg3, arg4 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"FindAssetLimitsUpdated\", reflect.TypeOf((*MockERC20BridgeView)(nil).FindAssetLimitsUpdated), arg0, arg1, arg2, arg3, arg4)\n}", "is_vulnerable": 0}
{"code": "func (p *Proxy) Connect(ctx context.Context, state request.Request, opts Options) (*dns.Msg, error) {\n\tstart := time.Now()\n\n\tproto := \"\"\n\tswitch {\n\tcase opts.ForceTCP: // TCP flag has precedence over UDP flag\n\t\tproto = \"tcp\"\n\tcase opts.PreferUDP:\n\t\tproto = \"udp\"\n\tdefault:\n\t\tproto = state.Proto()\n\t}\n\n\tpc, cached, err := p.transport.Dial(proto)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Set buffer size correctly for this client.\n\tpc.c.UDPSize = uint16(state.Size())\n\tif pc.c.UDPSize < 512 {\n\t\tpc.c.UDPSize = 512\n\t}\n\n\tpc.c.SetWriteDeadline(time.Now().Add(maxTimeout))\n\t// records the origin Id before upstream.\n\toriginId := state.Req.Id\n\tstate.Req.Id = dns.Id()\n\tdefer func() {\n\t\tstate.Req.Id = originId\n\t}()\n\n\tif err := pc.c.WriteMsg(state.Req); err != nil {\n\t\tpc.c.Close() // not giving it back\n\t\tif err == io.EOF && cached {\n\t\t\treturn nil, ErrCachedClosed\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tvar ret *dns.Msg\n\tpc.c.SetReadDeadline(time.Now().Add(p.readTimeout))\n\tfor {\n\t\tret, err = pc.c.ReadMsg()\n\t\tif err != nil {\n\t\t\t// For UDP, if the error is not a network error keep waiting for a valid response to prevent malformed\n\t\t\t// spoofs from blocking the upstream response.\n\t\t\t// In the case this is a legitimate malformed response from the upstream, this will result in a timeout.\n\t\t\tif proto == \"udp\" {\n\t\t\t\tif _, ok := err.(net.Error); !ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tpc.c.Close() // connection closed by peer, close the persistent connection\n\t\t\tif err == io.EOF && cached {\n\t\t\t\treturn nil, ErrCachedClosed\n\t\t\t}\n\n\t\t\t// recover the origin Id after upstream.\n\t\t\tif ret != nil {\n\t\t\t\tret.Id = originId\n\t\t\t}\n\t\t\treturn ret, err\n\t\t}\n\t\t// drop out-of-order responses\n\t\tif state.Req.Id == ret.Id {\n\t\t\tbreak\n\t\t}\n\t}\n\t// recovery the origin Id after upstream.\n\tret.Id = originId\n\n\tp.transport.Yield(pc)\n\n\trc, ok := dns.RcodeToString[ret.Rcode]\n\tif !ok {\n\t\trc = strconv.Itoa(ret.Rcode)\n\t}\n\n\tRequestCount.WithLabelValues(p.addr).Add(1)\n\tRcodeCount.WithLabelValues(rc, p.addr).Add(1)\n\tRequestDuration.WithLabelValues(p.addr, rc).Observe(time.Since(start).Seconds())\n\n\treturn ret, nil\n}", "is_vulnerable": 0}
{"code": "func (a upstreamhashby) Validate(anns map[string]string) error {\n\tmaxrisk := parser.StringRiskToRisk(a.r.GetSecurityConfiguration().AnnotationsRiskLevel)\n\treturn parser.CheckAnnotationRisk(anns, maxrisk, upstreamHashByAnnotations.Annotations)\n}", "is_vulnerable": 0}
{"code": "func (u *webHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tc, err := getConfig(u.tlsConfigPath)\n\tif err != nil {\n\t\tu.logger.Log(\"msg\", \"Unable to parse configuration\", \"err\", err)\n\t\thttp.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Configure http headers.\n\tfor k, v := range c.HTTPConfig.Header {\n\t\tw.Header().Set(k, v)\n\t}\n\n\tif len(c.Users) == 0 {\n\t\tu.handler.ServeHTTP(w, r)\n\t\treturn\n\t}\n\n\tuser, pass, auth := r.BasicAuth()\n\tif auth {\n\t\thashedPassword, validUser := c.Users[user]\n\n\t\tif !validUser {\n\t\t\t// The user is not found. Use a fixed password hash to\n\t\t\t// prevent user enumeration by timing requests.\n\t\t\t// This is a bcrypt-hashed version of \"fakepassword\".\n\t\t\thashedPassword = \"$2y$10$QOauhQNbBCuQDKes6eFzPeMqBSjb7Mr5DUmpZ/VcEd00UAV/LDeSi\"\n\t\t}\n\n\t\tcacheKey := hex.EncodeToString(append(append([]byte(user), []byte(hashedPassword)...), []byte(pass)...))\n\t\tauthOk, ok := u.cache.get(cacheKey)\n\n\t\tif !ok {\n\t\t\t// This user, hashedPassword, password is not cached.\n\t\t\tu.bcryptMtx.Lock()\n\t\t\terr := bcrypt.CompareHashAndPassword([]byte(hashedPassword), []byte(pass))\n\t\t\tu.bcryptMtx.Unlock()\n\n\t\t\tauthOk = err == nil\n\t\t\tu.cache.set(cacheKey, authOk)\n\t\t}\n\n\t\tif authOk && validUser {\n\t\t\tu.handler.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t}\n\n\tw.Header().Set(\"WWW-Authenticate\", \"Basic\")\n\thttp.Error(w, http.StatusText(http.StatusUnauthorized), http.StatusUnauthorized)\n}", "is_vulnerable": 1}
{"code": "\t\tgo func(idx int, f os.FileInfo) {\n\t\t\tdefer wg.Done()\n\n\t\t\tvar m *mimetype.MIME\n\t\t\td := \"inode/directory\"\n\t\t\tif !f.IsDir() {\n\t\t\t\tcleanedp := filepath.Join(cleaned, f.Name())\n\t\t\t\tif f.Mode()&os.ModeSymlink != 0 {\n\t\t\t\t\tcleanedp, _ = fs.SafePath(filepath.Join(cleaned, f.Name()))\n\t\t\t\t}\n\n\t\t\t\t// Don't try to detect the type on a pipe \u2014 this will just hang the application and\n\t\t\t\t// you'll never get a response back.\n\t\t\t\t//\n\t\t\t\t// @see https://github.com/pterodactyl/panel/issues/4059\n\t\t\t\tif cleanedp != \"\" && f.Mode()&os.ModeNamedPipe == 0 {\n\t\t\t\t\tm, _ = mimetype.DetectFile(filepath.Join(cleaned, f.Name()))\n\t\t\t\t} else {\n\t\t\t\t\t// Just pass this for an unknown type because the file could not safely be resolved within\n\t\t\t\t\t// the server data path.\n\t\t\t\t\td = \"application/octet-stream\"\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tst := Stat{FileInfo: f, Mimetype: d}\n\t\t\tif m != nil {\n\t\t\t\tst.Mimetype = m.String()\n\t\t\t}\n\t\t\tout[idx] = st\n\t\t}(i, file)", "is_vulnerable": 1}
{"code": "func hostMatchesGlob(host string, domainGlob string) bool {\n\tif domainGlob != \"\" && domainGlob[0] == '*' {\n\t\tsuffix := domainGlob[1:]\n\t\tif strings.HasSuffix(host, suffix) {\n\t\t\treturn true\n\t\t}\n\t} else if domainGlob == host {\n\t\treturn true\n\t}\n\treturn false\n}", "is_vulnerable": 1}
{"code": "func (mgr *SessionManager) getFailureCount(username string) LoginAttempts {\n\tmgr.failedLock.RLock()\n\tdefer mgr.failedLock.RUnlock()\n\tfailures := mgr.GetLoginFailures()\n\tattempt, ok := failures[username]\n\tif !ok {\n\t\tattempt = LoginAttempts{FailCount: 0}\n\t}\n\treturn attempt\n}", "is_vulnerable": 0}
{"code": "func (p *Parser) parseEvery() *Expr {\n\tqb := &Every{}\n\tqb.SetLoc(p.s.Loc())\n\n\t// TODO(sr): We'd get more accurate error messages if we didn't rely on\n\t// parseTermInfixCall here, but parsed \"var [, var] in term\" manually.\n\tp.scan()\n\tterm := p.parseTermInfixCall()\n\tif term == nil {\n\t\treturn nil\n\t}\n\tcall, ok := term.Value.(Call)\n\tif !ok {\n\t\tp.illegal(\"expected `x[, y] in xs { ... }` expression\")\n\t\treturn nil\n\t}\n\tswitch call[0].String() {\n\tcase Member.Name: // x in xs\n\t\tif len(call) != 3 {\n\t\t\tp.illegal(\"illegal domain\")\n\t\t\treturn nil\n\t\t}\n\t\tqb.Value = call[1]\n\t\tqb.Domain = call[2]\n\tcase MemberWithKey.Name: // k, v in xs\n\t\tif len(call) != 4 {\n\t\t\tp.illegal(\"illegal domain\")\n\t\t\treturn nil\n\t\t}\n\t\tqb.Key = call[1]\n\t\tqb.Value = call[2]\n\t\tqb.Domain = call[3]\n\t\tif _, ok := qb.Key.Value.(Var); !ok {\n\t\t\tp.illegal(\"expected key to be a variable\")\n\t\t\treturn nil\n\t\t}\n\tdefault:\n\t\tp.illegal(\"expected `x[, y] in xs { ... }` expression\")\n\t\treturn nil\n\t}\n\tif _, ok := qb.Value.Value.(Var); !ok {\n\t\tp.illegal(\"expected value to be a variable\")\n\t\treturn nil\n\t}\n\tif p.s.tok == tokens.LBrace { // every x in xs { ... }\n\t\tp.scan()\n\t\tbody := p.parseBody(tokens.RBrace)\n\t\tif body == nil {\n\t\t\treturn nil\n\t\t}\n\t\tp.scan()\n\t\tqb.Body = body\n\t\texpr := NewExpr(qb).SetLocation(qb.Location)\n\n\t\tif p.s.tok == tokens.With {\n\t\t\tif expr.With = p.parseWith(); expr.With == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\treturn expr\n\t}\n\n\tp.illegal(\"missing body\")\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestDecodeColonsInLocalNames(t *testing.T) {\n\t_, _, err := parseResponse([]byte(`<x::Root/>`))\n\trequire.Error(t, err)\n}", "is_vulnerable": 0}
{"code": "func GetPubKey(rw io.ReadWriter, keyHandle tpmutil.Handle, srkAuth []byte) ([]byte, error) {\n\t// Run OSAP for the handle, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a response.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etKeyHandle, keyHandle, srkAuth)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\tauthIn := []interface{}{ordGetPubKey}\n\tca, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpk, ra, ret, err := getPubKey(rw, keyHandle, ca)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check response authentication for TPM_GetPubKey.\n\traIn := []interface{}{ret, ordGetPubKey, pk}\n\tif err := ra.verify(ca.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn nil, err\n\t}\n\n\tb, err := tpmutil.Pack(*pk)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn b, err\n}", "is_vulnerable": 1}
{"code": "func InstrumentHandlerResponseSize(obs prometheus.ObserverVec, next http.Handler, opts ...Option) http.Handler {\n\tmwOpts := &option{}\n\tfor _, o := range opts {\n\t\to(mwOpts)\n\t}\n\n\tcode, method := checkLabels(obs)\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\td := newDelegator(w, nil)\n\t\tnext.ServeHTTP(d, r)\n\t\tobs.With(labels(code, method, r.Method, d.Status(), mwOpts.extraMethods...)).Observe(float64(d.Written()))\n\t})\n}", "is_vulnerable": 0}
{"code": "func (f *file) Payload() ([]byte, error) {\n\tsize, err := f.layer.Size()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = payloadsize.CheckSize(uint64(size))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\trc, err := f.layer.Uncompressed()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rc.Close()\n\treturn io.ReadAll(rc)\n}", "is_vulnerable": 0}
{"code": "func InstrumentHandlerCounter(counter *prometheus.CounterVec, next http.Handler) http.HandlerFunc {\n\tcode, method := checkLabels(counter)\n\n\tif code {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\td := newDelegator(w, nil)\n\t\t\tnext.ServeHTTP(d, r)\n\t\t\tcounter.With(labels(code, method, r.Method, d.Status())).Inc()\n\t\t})\n\t}\n\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tnext.ServeHTTP(w, r)\n\t\tcounter.With(labels(code, method, r.Method, 0)).Inc()\n\t})\n}", "is_vulnerable": 1}
{"code": "func TestHttpGetter_subdirLink(t *testing.T) {\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tln := testHttpServerSubDir(t)\n\tdefer ln.Close()\n\n\tdst, err := ioutil.TempDir(\"\", \"tf\")\n\tif err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n\n\tt.Logf(\"dst: %q\", dst)\n\n\tvar u url.URL\n\tu.Scheme = \"http\"\n\tu.Host = ln.Addr().String()\n\tu.Path = \"/regular-subdir//meta-subdir\"\n\n\tg := new(HttpGetter)\n\tclient := &Client{\n\t\tGetters: []Getter{g},\n\t}\n\n\tt.Logf(\"url: %q\", u.String())\n\n\treq := Request{\n\t\tDst:     dst,\n\t\tSrc:     u.String(),\n\t\tGetMode: ModeAny,\n\t}\n\n\t_, err = client.Get(ctx, &req)\n\tif err != nil {\n\t\tt.Fatalf(\"get err: %v\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func Register(mgr manager.Manager, cfg config.Config) error {\n\tcsiDriver := NewDriver(cfg.NodeId, cfg.Endpoint, mgr.GetClient(), mgr.GetAPIReader())\n\n\tif err := mgr.Add(csiDriver); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (msg *MsgTx) BtcDecode(r io.Reader, pver uint32, enc MessageEncoding) error {\n\tversion, err := binarySerializer.Uint32(r, littleEndian)\n\tif err != nil {\n\t\treturn err\n\t}\n\tmsg.Version = int32(version)\n\n\tcount, err := ReadVarInt(r, pver)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// A count of zero (meaning no TxIn's to the uninitiated) means that the\n\t// value is a TxFlagMarker, and hence indicates the presence of a flag.\n\tvar flag [1]TxFlag\n\tif count == TxFlagMarker && enc == WitnessEncoding {\n\t\t// The count varint was in fact the flag marker byte. Next, we need to\n\t\t// read the flag value, which is a single byte.\n\t\tif _, err = io.ReadFull(r, flag[:]); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// At the moment, the flag MUST be WitnessFlag (0x01). In the future\n\t\t// other flag types may be supported.\n\t\tif flag[0] != WitnessFlag {\n\t\t\tstr := fmt.Sprintf(\"witness tx but flag byte is %x\", flag)\n\t\t\treturn messageError(\"MsgTx.BtcDecode\", str)\n\t\t}\n\n\t\t// With the Segregated Witness specific fields decoded, we can\n\t\t// now read in the actual txin count.\n\t\tcount, err = ReadVarInt(r, pver)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Prevent more input transactions than could possibly fit into a\n\t// message.  It would be possible to cause memory exhaustion and panics\n\t// without a sane upper bound on this count.\n\tif count > uint64(maxTxInPerMessage) {\n\t\tstr := fmt.Sprintf(\"too many input transactions to fit into \"+\n\t\t\t\"max message size [count %d, max %d]\", count,\n\t\t\tmaxTxInPerMessage)\n\t\treturn messageError(\"MsgTx.BtcDecode\", str)\n\t}\n\n\t// returnScriptBuffers is a closure that returns any script buffers that\n\t// were borrowed from the pool when there are any deserialization\n\t// errors.  This is only valid to call before the final step which\n\t// replaces the scripts with the location in a contiguous buffer and\n\t// returns them.\n\treturnScriptBuffers := func() {\n\t\tfor _, txIn := range msg.TxIn {\n\t\t\tif txIn == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif txIn.SignatureScript != nil {\n\t\t\t\tscriptPool.Return(txIn.SignatureScript)\n\t\t\t}\n\n\t\t\tfor _, witnessElem := range txIn.Witness {\n\t\t\t\tif witnessElem != nil {\n\t\t\t\t\tscriptPool.Return(witnessElem)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, txOut := range msg.TxOut {\n\t\t\tif txOut == nil || txOut.PkScript == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tscriptPool.Return(txOut.PkScript)\n\t\t}\n\t}\n\n\t// Deserialize the inputs.\n\tvar totalScriptSize uint64\n\ttxIns := make([]TxIn, count)\n\tmsg.TxIn = make([]*TxIn, count)\n\tfor i := uint64(0); i < count; i++ {\n\t\t// The pointer is set now in case a script buffer is borrowed\n\t\t// and needs to be returned to the pool on error.\n\t\tti := &txIns[i]\n\t\tmsg.TxIn[i] = ti\n\t\terr = readTxIn(r, pver, msg.Version, ti)\n\t\tif err != nil {\n\t\t\treturnScriptBuffers()\n\t\t\treturn err\n\t\t}\n\t\ttotalScriptSize += uint64(len(ti.SignatureScript))\n\t}\n\n\tcount, err = ReadVarInt(r, pver)\n\tif err != nil {\n\t\treturnScriptBuffers()\n\t\treturn err\n\t}\n\n\t// Prevent more output transactions than could possibly fit into a\n\t// message.  It would be possible to cause memory exhaustion and panics\n\t// without a sane upper bound on this count.\n\tif count > uint64(maxTxOutPerMessage) {\n\t\treturnScriptBuffers()\n\t\tstr := fmt.Sprintf(\"too many output transactions to fit into \"+\n\t\t\t\"max message size [count %d, max %d]\", count,\n\t\t\tmaxTxOutPerMessage)\n\t\treturn messageError(\"MsgTx.BtcDecode\", str)\n\t}\n\n\t// Deserialize the outputs.\n\ttxOuts := make([]TxOut, count)\n\tmsg.TxOut = make([]*TxOut, count)\n\tfor i := uint64(0); i < count; i++ {\n\t\t// The pointer is set now in case a script buffer is borrowed\n\t\t// and needs to be returned to the pool on error.\n\t\tto := &txOuts[i]\n\t\tmsg.TxOut[i] = to\n\t\terr = ReadTxOut(r, pver, msg.Version, to)\n\t\tif err != nil {\n\t\t\treturnScriptBuffers()\n\t\t\treturn err\n\t\t}\n\t\ttotalScriptSize += uint64(len(to.PkScript))\n\t}\n\n\t// If the transaction's flag byte isn't 0x00 at this point, then one or\n\t// more of its inputs has accompanying witness data.\n\tif flag[0] != 0 && enc == WitnessEncoding {\n\t\tfor _, txin := range msg.TxIn {\n\t\t\t// For each input, the witness is encoded as a stack\n\t\t\t// with one or more items. Therefore, we first read a\n\t\t\t// varint which encodes the number of stack items.\n\t\t\twitCount, err := ReadVarInt(r, pver)\n\t\t\tif err != nil {\n\t\t\t\treturnScriptBuffers()\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// Prevent a possible memory exhaustion attack by\n\t\t\t// limiting the witCount value to a sane upper bound.\n\t\t\tif witCount > maxWitnessItemsPerInput {\n\t\t\t\treturnScriptBuffers()\n\t\t\t\tstr := fmt.Sprintf(\"too many witness items to fit \"+\n\t\t\t\t\t\"into max message size [count %d, max %d]\",\n\t\t\t\t\twitCount, maxWitnessItemsPerInput)\n\t\t\t\treturn messageError(\"MsgTx.BtcDecode\", str)\n\t\t\t}\n\n\t\t\t// Then for witCount number of stack items, each item\n\t\t\t// has a varint length prefix, followed by the witness\n\t\t\t// item itself.\n\t\t\ttxin.Witness = make([][]byte, witCount)\n\t\t\tfor j := uint64(0); j < witCount; j++ {\n\t\t\t\ttxin.Witness[j], err = readScript(\n\t\t\t\t\tr, pver, maxWitnessItemSize, \"script witness item\",\n\t\t\t\t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturnScriptBuffers()\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\ttotalScriptSize += uint64(len(txin.Witness[j]))\n\t\t\t}\n\t\t}\n\t}\n\n\tmsg.LockTime, err = binarySerializer.Uint32(r, littleEndian)\n\tif err != nil {\n\t\treturnScriptBuffers()\n\t\treturn err\n\t}\n\n\t// Create a single allocation to house all of the scripts and set each\n\t// input signature script and output public key script to the\n\t// appropriate subslice of the overall contiguous buffer.  Then, return\n\t// each individual script buffer back to the pool so they can be reused\n\t// for future deserializations.  This is done because it significantly\n\t// reduces the number of allocations the garbage collector needs to\n\t// track, which in turn improves performance and drastically reduces the\n\t// amount of runtime overhead that would otherwise be needed to keep\n\t// track of millions of small allocations.\n\t//\n\t// NOTE: It is no longer valid to call the returnScriptBuffers closure\n\t// after these blocks of code run because it is already done and the\n\t// scripts in the transaction inputs and outputs no longer point to the\n\t// buffers.\n\tvar offset uint64\n\tscripts := make([]byte, totalScriptSize)\n\tfor i := 0; i < len(msg.TxIn); i++ {\n\t\t// Copy the signature script into the contiguous buffer at the\n\t\t// appropriate offset.\n\t\tsignatureScript := msg.TxIn[i].SignatureScript\n\t\tcopy(scripts[offset:], signatureScript)\n\n\t\t// Reset the signature script of the transaction input to the\n\t\t// slice of the contiguous buffer where the script lives.\n\t\tscriptSize := uint64(len(signatureScript))\n\t\tend := offset + scriptSize\n\t\tmsg.TxIn[i].SignatureScript = scripts[offset:end:end]\n\t\toffset += scriptSize\n\n\t\t// Return the temporary script buffer to the pool.\n\t\tscriptPool.Return(signatureScript)\n\n\t\tfor j := 0; j < len(msg.TxIn[i].Witness); j++ {\n\t\t\t// Copy each item within the witness stack for this\n\t\t\t// input into the contiguous buffer at the appropriate\n\t\t\t// offset.\n\t\t\twitnessElem := msg.TxIn[i].Witness[j]\n\t\t\tcopy(scripts[offset:], witnessElem)\n\n\t\t\t// Reset the witness item within the stack to the slice\n\t\t\t// of the contiguous buffer where the witness lives.\n\t\t\twitnessElemSize := uint64(len(witnessElem))\n\t\t\tend := offset + witnessElemSize\n\t\t\tmsg.TxIn[i].Witness[j] = scripts[offset:end:end]\n\t\t\toffset += witnessElemSize\n\n\t\t\t// Return the temporary buffer used for the witness stack\n\t\t\t// item to the pool.\n\t\t\tscriptPool.Return(witnessElem)\n\t\t}\n\t}\n\tfor i := 0; i < len(msg.TxOut); i++ {\n\t\t// Copy the public key script into the contiguous buffer at the\n\t\t// appropriate offset.\n\t\tpkScript := msg.TxOut[i].PkScript\n\t\tcopy(scripts[offset:], pkScript)\n\n\t\t// Reset the public key script of the transaction output to the\n\t\t// slice of the contiguous buffer where the script lives.\n\t\tscriptSize := uint64(len(pkScript))\n\t\tend := offset + scriptSize\n\t\tmsg.TxOut[i].PkScript = scripts[offset:end:end]\n\t\toffset += scriptSize\n\n\t\t// Return the temporary script buffer to the pool.\n\t\tscriptPool.Return(pkScript)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (mgr *MetricsManager) updateInfo(ctx context.Context, cfg *Config) {\n\tserviceName := telemetry.ServiceName(cfg.Options.Services)\n\tif serviceName == mgr.serviceName {\n\t\treturn\n\t}\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\tlog.Error(ctx).Err(err).Msg(\"telemetry/metrics: failed to get OS hostname\")\n\t\thostname = \"__unknown__\"\n\t}\n\n\tmetrics.SetBuildInfo(serviceName, hostname, cfg.EnvoyVersion)\n\tmgr.serviceName = serviceName\n}", "is_vulnerable": 0}
{"code": "func (h *Handler) GetSystemDatabase(w http.ResponseWriter, r *http.Request, _ *models.Preference, _ *models.User, provider models.Provider) {\n\tvar tables []*models.SqliteSchema\n\tvar recordCount int\n\tvar totalTables int64\n\n\tlimitstr := r.URL.Query().Get(\"pagesize\")\n\tvar limit int\n\tif limitstr != \"all\" {\n\t\tlimit, _ = strconv.Atoi(limitstr)\n\t\tif limit <= 0 {\n\t\t\tlimit = defaultPageSize\n\t\t}\n\t}\n\tpagestr := r.URL.Query().Get(\"page\")\n\tpage, _ := strconv.Atoi(pagestr)\n\n\tif page <= 0 {\n\t\tpage = 1\n\t}\n\n\toffset := (page - 1) * limit\n\torder := r.URL.Query().Get(\"order\")\n\tsort := r.URL.Query().Get(\"sort\")\n\tsearch := r.URL.Query().Get(\"search\")\n\n\ttableFinder := h.dbHandler.DB.Table(\"sqlite_schema\").\n\t\tWhere(\"type = ?\", \"table\")\n\n\tif search != \"\" {\n\t\ttableFinder = tableFinder.Where(\"name LIKE ?\", \"%\"+search+\"%\")\n\t}\n\n\ttableFinder.Count(&totalTables)\n\n\tif limit != 0 {\n\t\ttableFinder = tableFinder.Limit(limit)\n\t}\n\tif offset != 0 {\n\t\ttableFinder = tableFinder.Offset(offset)\n\t}\n\torder = models.SanitizeOrderInput(order, []string{\"created_at\", \"updated_at\", \"name\"})\n\tif order != \"\" {\n\t\tif sort == \"desc\" {\n\t\t\ttableFinder = tableFinder.Order(clause.OrderByColumn{Column: clause.Column{Name: order}, Desc: true})\n\t\t} else {\n\t\t\ttableFinder = tableFinder.Order(order)\n\t\t}\n\t}\n\n\ttableFinder.Find(&tables)\n\n\tfor _, table := range tables {\n\t\th.dbHandler.DB.Table(table.Name).Count(&table.Count)\n\t\trecordCount += int(table.Count)\n\t}\n\n\tdatabaseSummary := &models.DatabaseSummary{\n\t\tPage:        page,\n\t\tPageSize:    limit,\n\t\tTotalTables: int(totalTables),\n\t\tRecordCount: recordCount,\n\t\tTables:      tables,\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\n\tval, err := json.Marshal(databaseSummary)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\tfmt.Fprint(w, string(val))\n}", "is_vulnerable": 0}
{"code": "func (r *remotereceiverhastoken) Setup(t *testing.T) []framework.Option {\n\tfn, ch := newServer()\n\tr.ch = ch\n\tapp := app.New(t,\n\t\tapp.WithRegister(fn),\n\t\tapp.WithOnInvokeFn(func(ctx context.Context, _ *commonv1.InvokeRequest) (*commonv1.InvokeResponse, error) {\n\t\t\tmd, ok := metadata.FromIncomingContext(ctx)\n\t\t\trequire.True(t, ok)\n\t\t\tr.ch <- md\n\t\t\treturn new(commonv1.InvokeResponse), nil\n\t\t}),\n\t)\n\n\tr.daprd1 = daprd.New(t)\n\tr.daprd2 = daprd.New(t,\n\t\tdaprd.WithAppProtocol(\"grpc\"),\n\t\tdaprd.WithAppAPIToken(t, \"abc\"),\n\t\tdaprd.WithAppPort(app.Port(t)),\n\t)\n\n\treturn []framework.Option{\n\t\tframework.WithProcesses(app, r.daprd1, r.daprd2),\n\t}\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(name, func(t *testing.T) {\n\t\t\tif sc.ok {\n\t\t\t\tgotCode, gotMethod := checkLabels(sc.varLabels)\n\t\t\t\tgotLabels := labels(gotCode, gotMethod, sc.reqMethod, sc.respStatus, sc.extraMethods...)\n\t\t\t\tif !equalLabels(gotLabels, sc.wantLabels) {\n\t\t\t\t\tt.Errorf(\"wanted labels=%v for counter, got code=%v\", sc.wantLabels, gotLabels)\n\t\t\t\t}\n\t\t\t}\n\t\t})", "is_vulnerable": 0}
{"code": "\t\t\tmutate: func(service *corev1.Service) {\n\t\t\t\tservice.Spec.SessionAffinity = corev1.ServiceAffinityNone\n\t\t\t},", "is_vulnerable": 0}
{"code": "func (e errorTranslateChunkQuerier) Select(sortSeries bool, hints *storage.SelectHints, matchers ...*labels.Matcher) storage.ChunkSeriesSet {\n\ts := e.q.Select(sortSeries, hints, matchers...)\n\treturn errorTranslateChunkSeriesSet{s: s, fn: e.fn}\n}", "is_vulnerable": 0}
{"code": "func TestCheckSize(t *testing.T) {\n\ttests := []struct {\n\t\tname    string\n\t\tinput   uint64\n\t\tsetting string\n\t\twantErr bool\n\t}{\n\t\t{\n\t\t\tname:    \"size is within default limit\",\n\t\t\tinput:   1000,\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"size exceeds default limit\",\n\t\t\tinput:   200000000,\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is within overridden limit (bytes)\",\n\t\t\tinput:   1000,\n\t\t\tsetting: \"1024\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is exceeds overridden limit (bytes)\",\n\t\t\tinput:   2000,\n\t\t\tsetting: \"1024\",\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is within overridden limit (megabytes, short form)\",\n\t\t\tinput:   1999999,\n\t\t\tsetting: \"2M\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"size exceeds overridden limit (megabytes, short form)\",\n\t\t\tinput:   2000001,\n\t\t\tsetting: \"2M\",\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is within overridden limit (megabytes, long form)\",\n\t\t\tinput:   1999999,\n\t\t\tsetting: \"2MB\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"size exceeds overridden limit (megabytes, long form)\",\n\t\t\tinput:   2000001,\n\t\t\tsetting: \"2MB\",\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is within overridden limit (mebibytes)\",\n\t\t\tinput:   2097151,\n\t\t\tsetting: \"2MiB\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"size exceeds overridden limit (mebibytes)\",\n\t\t\tinput:   2097153,\n\t\t\tsetting: \"2MiB\",\n\t\t\twantErr: true,\n\t\t},\n\t\t{\n\t\t\tname:    \"size is negative results in default\",\n\t\t\tinput:   5121,\n\t\t\tsetting: \"-5KiB\",\n\t\t\twantErr: false,\n\t\t},\n\t\t{\n\t\t\tname:    \"invalid setting results in default\",\n\t\t\tinput:   5121,\n\t\t\tsetting: \"five kilobytes\",\n\t\t\twantErr: false,\n\t\t},\n\t}\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tif test.setting != \"\" {\n\t\t\t\tt.Setenv(\"COSIGN_MAX_ATTACHMENT_SIZE\", test.setting)\n\t\t\t}\n\t\t\tgot := CheckSize(test.input)\n\t\t\tif (got != nil) != (test.wantErr) {\n\t\t\t\tt.Errorf(\"CheckSize() = %v, expected %v\", got, test.wantErr)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *Context) DecryptVerify(ciphertext, plaintext *Data) error {\n\treturn handleError(C.gpgme_op_decrypt_verify(c.ctx, ciphertext.dh, plaintext.dh))\n}", "is_vulnerable": 1}
{"code": "func TestNodeIteratorCoverage(t *testing.T) {\n\t// Create some arbitrary test state to iterate\n\tdb, root, _ := makeTestState()\n\tdb.TrieDB().Commit(root, false, nil)\n\n\tstate, err := New(root, db, nil)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create state trie at %x: %v\", root, err)\n\t}\n\t// Gather all the node hashes found by the iterator\n\thashes := make(map[common.Hash]struct{})\n\tfor it := NewNodeIterator(state); it.Next(); {\n\t\tif it.Hash != (common.Hash{}) {\n\t\t\thashes[it.Hash] = struct{}{}\n\t\t}\n\t}\n\t// Cross check the iterated hashes and the database/nodepool content\n\tfor hash := range hashes {\n\t\tif _, err = db.TrieDB().Node(hash); err != nil {\n\t\t\t_, err = db.ContractCode(common.Hash{}, hash)\n\t\t}\n\t\tif err != nil {\n\t\t\tt.Errorf(\"failed to retrieve reported node %x\", hash)\n\t\t}\n\t}\n\tfor _, hash := range db.TrieDB().Nodes() {\n\t\tif _, ok := hashes[hash]; !ok {\n\t\t\tt.Errorf(\"state entry not reported %x\", hash)\n\t\t}\n\t}\n\tit := db.TrieDB().DiskDB().(ethdb.Database).NewIterator(nil, nil)\n\tfor it.Next() {\n\t\tkey := it.Key()\n\t\tif bytes.HasPrefix(key, []byte(\"secure-key-\")) {\n\t\t\tcontinue\n\t\t}\n\t\tif _, ok := hashes[common.BytesToHash(key)]; !ok {\n\t\t\tt.Errorf(\"state entry not reported %x\", key)\n\t\t}\n\t}\n\tit.Release()\n}", "is_vulnerable": 0}
{"code": "\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 3)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Len(t, input.MapFilters, 1)\n\t\t\tfilter := input.MapFilters[0].GetFilter()\n\t\t\tassert.Equal(t, map[string]interface{}{\n\t\t\t\t\"parent_id\":                nil,\n\t\t\t\t\"parent_task_execution_id\": nil,\n\t\t\t}, filter)\n\n\t\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})", "is_vulnerable": 0}
{"code": "func TestSortParameter_Nil(t *testing.T) {\n\tsortParameter, err := NewSortParameter(nil, nil)\n\n\tassert.NoError(t, err)\n\tassert.Nil(t, sortParameter)\n}", "is_vulnerable": 0}
{"code": "func CreateRepo(c *gin.Context) {\n\t// capture middleware values\n\tu := user.Retrieve(c)\n\tallowlist := c.Value(\"allowlist\").([]string)\n\tdefaultBuildLimit := c.Value(\"defaultBuildLimit\").(int64)\n\tdefaultTimeout := c.Value(\"defaultTimeout\").(int64)\n\tmaxBuildLimit := c.Value(\"maxBuildLimit\").(int64)\n\n\t// capture body from API request\n\tinput := new(library.Repo)\n\n\terr := c.Bind(input)\n\tif err != nil {\n\t\tretErr := fmt.Errorf(\"unable to decode JSON for new repo: %w\", err)\n\n\t\tutil.HandleError(c, http.StatusBadRequest, retErr)\n\n\t\treturn\n\t}\n\n\t// update engine logger with API metadata\n\t//\n\t// https://pkg.go.dev/github.com/sirupsen/logrus?tab=doc#Entry.WithFields\n\tlogrus.WithFields(logrus.Fields{\n\t\t\"org\":  input.GetOrg(),\n\t\t\"repo\": input.GetName(),\n\t\t\"user\": u.GetName(),\n\t}).Infof(\"creating new repo %s\", input.GetFullName())\n\n\t// get repo information from the source\n\tr, err := scm.FromContext(c).GetRepo(u, input)\n\tif err != nil {\n\t\tretErr := fmt.Errorf(\"unable to retrieve repo info for %s from source: %w\", r.GetFullName(), err)\n\n\t\tutil.HandleError(c, http.StatusBadRequest, retErr)\n\n\t\treturn\n\t}\n\n\t// update fields in repo object\n\tr.SetUserID(u.GetID())\n\n\t// set the active field based off the input provided\n\tif input.Active == nil {\n\t\t// default active field to true\n\t\tr.SetActive(true)\n\t} else {\n\t\tr.SetActive(input.GetActive())\n\t}\n\n\t// set the build limit field based off the input provided\n\tif input.GetBuildLimit() == 0 {\n\t\t// default build limit to value configured by server\n\t\tr.SetBuildLimit(defaultBuildLimit)\n\t} else if input.GetBuildLimit() > maxBuildLimit {\n\t\t// set build limit to value configured by server to prevent limit from exceeding max\n\t\tr.SetBuildLimit(maxBuildLimit)\n\t} else {\n\t\tr.SetBuildLimit(input.GetBuildLimit())\n\t}\n\n\t// set the timeout field based off the input provided\n\tif input.GetTimeout() == 0 && defaultTimeout == 0 {\n\t\t// default build timeout to 30m\n\t\tr.SetTimeout(constants.BuildTimeoutDefault)\n\t} else if input.GetTimeout() == 0 {\n\t\tr.SetTimeout(defaultTimeout)\n\t} else {\n\t\tr.SetTimeout(input.GetTimeout())\n\t}\n\n\t// set the visibility field based off the input provided\n\tif len(input.GetVisibility()) == 0 {\n\t\t// default visibility field to public\n\t\tr.SetVisibility(constants.VisibilityPublic)\n\t} else {\n\t\tr.SetVisibility(input.GetVisibility())\n\t}\n\n\t// set default events if no events are passed in\n\tif !input.GetAllowPull() && !input.GetAllowPush() &&\n\t\t!input.GetAllowDeploy() && !input.GetAllowTag() &&\n\t\t!input.GetAllowComment() {\n\t\t// default events to push and pull_request\n\t\tr.SetAllowPull(true)\n\t\tr.SetAllowPush(true)\n\t} else {\n\t\tr.SetAllowComment(input.GetAllowComment())\n\t\tr.SetAllowDeploy(input.GetAllowDeploy())\n\t\tr.SetAllowPull(input.GetAllowPull())\n\t\tr.SetAllowPush(input.GetAllowPush())\n\t\tr.SetAllowTag(input.GetAllowTag())\n\t}\n\n\tif len(input.GetPipelineType()) == 0 {\n\t\tr.SetPipelineType(constants.PipelineTypeYAML)\n\t} else {\n\t\t// ensure the pipeline type matches one of the expected values\n\t\tif input.GetPipelineType() != constants.PipelineTypeYAML &&\n\t\t\tinput.GetPipelineType() != constants.PipelineTypeGo &&\n\t\t\tinput.GetPipelineType() != constants.PipelineTypeStarlark {\n\t\t\tretErr := fmt.Errorf(\"unable to create new repo %s: invalid pipeline_type provided %s\", r.GetFullName(), input.GetPipelineType())\n\n\t\t\tutil.HandleError(c, http.StatusBadRequest, retErr)\n\n\t\t\treturn\n\t\t}\n\t\tr.SetPipelineType(input.GetPipelineType())\n\t}\n\n\t// create unique id for the repo\n\tuid, err := uuid.NewRandom()\n\tif err != nil {\n\t\tretErr := fmt.Errorf(\"unable to create UID for repo %s: %w\", r.GetFullName(), err)\n\n\t\tutil.HandleError(c, http.StatusServiceUnavailable, retErr)\n\n\t\treturn\n\t}\n\n\tr.SetHash(\n\t\tbase64.StdEncoding.EncodeToString(\n\t\t\t[]byte(strings.TrimSpace(uid.String())),\n\t\t),\n\t)\n\n\t// ensure repo is allowed to be activated\n\tif !checkAllowlist(r, allowlist) {\n\t\tretErr := fmt.Errorf(\"unable to activate repo: %s is not on allowlist\", r.GetFullName())\n\n\t\tutil.HandleError(c, http.StatusForbidden, retErr)\n\n\t\treturn\n\t}\n\n\t// send API call to capture the repo from the database\n\tdbRepo, err := database.FromContext(c).GetRepoForOrg(r.GetOrg(), r.GetName())\n\tif err == nil && dbRepo.GetActive() {\n\t\tretErr := fmt.Errorf(\"unable to activate repo: %s is already active\", r.GetFullName())\n\n\t\tutil.HandleError(c, http.StatusConflict, retErr)\n\n\t\treturn\n\t}\n\n\t// check if the repo already has a hash created\n\tif len(dbRepo.GetHash()) > 0 {\n\t\t// overwrite the new repo hash with the existing repo hash\n\t\tr.SetHash(dbRepo.GetHash())\n\t}\n\n\t// send API call to create the webhook\n\tif c.Value(\"webhookvalidation\").(bool) {\n\t\t_, err = scm.FromContext(c).Enable(u, r.GetOrg(), r.GetName(), r.GetHash())\n\t\tif err != nil {\n\t\t\tretErr := fmt.Errorf(\"unable to create webhook for %s: %w\", r.GetFullName(), err)\n\n\t\t\tswitch err.Error() {\n\t\t\tcase \"repo already enabled\":\n\t\t\t\tutil.HandleError(c, http.StatusConflict, retErr)\n\t\t\t\treturn\n\t\t\tcase \"repo not found\":\n\t\t\t\tutil.HandleError(c, http.StatusNotFound, retErr)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tutil.HandleError(c, http.StatusInternalServerError, retErr)\n\n\t\t\treturn\n\t\t}\n\t}\n\n\t// if the repo exists but is inactive\n\tif len(dbRepo.GetOrg()) > 0 && !dbRepo.GetActive() {\n\t\t// update the repo owner\n\t\tdbRepo.SetUserID(u.GetID())\n\t\t// update the default branch\n\t\tdbRepo.SetBranch(r.GetBranch())\n\t\t// activate the repo\n\t\tdbRepo.SetActive(true)\n\n\t\t// send API call to update the repo\n\t\terr = database.FromContext(c).UpdateRepo(dbRepo)\n\t\tif err != nil {\n\t\t\tretErr := fmt.Errorf(\"unable to set repo %s to active: %w\", dbRepo.GetFullName(), err)\n\n\t\t\tutil.HandleError(c, http.StatusInternalServerError, retErr)\n\n\t\t\treturn\n\t\t}\n\n\t\t// send API call to capture the updated repo\n\t\tr, _ = database.FromContext(c).GetRepoForOrg(dbRepo.GetOrg(), dbRepo.GetName())\n\t} else {\n\t\t// send API call to create the repo\n\t\terr = database.FromContext(c).CreateRepo(r)\n\t\tif err != nil {\n\t\t\tretErr := fmt.Errorf(\"unable to create new repo %s: %w\", r.GetFullName(), err)\n\n\t\t\tutil.HandleError(c, http.StatusInternalServerError, retErr)\n\n\t\t\treturn\n\t\t}\n\n\t\t// send API call to capture the created repo\n\t\tr, _ = database.FromContext(c).GetRepoForOrg(r.GetOrg(), r.GetName())\n\t}\n\n\tc.JSON(http.StatusCreated, r)\n}", "is_vulnerable": 1}
{"code": "func (l Logger) Info(msg string, keysAndValues ...any) {\n\tif l.sink == nil {\n\t\treturn\n\t}\n\tif l.sink.Enabled(l.level) { // see comment in Enabled\n\t\tif withHelper, ok := l.sink.(CallStackHelperLogSink); ok {\n\t\t\twithHelper.GetCallStackHelper()()\n\t\t}\n\t\tl.sink.Info(l.level, msg, keysAndValues...)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (d webpGenerator) GetOriginDimensions(b []byte, contentType string, ctx rcontext.RequestContext) (bool, int, int, error) {\n\ti, err := webp.DecodeConfig(bytes.NewBuffer(b))\n\tif err != nil {\n\t\treturn false, 0, 0, err\n\t}\n\treturn true, i.Width, i.Height, nil\n}", "is_vulnerable": 0}
{"code": "func NewIdpAuthnRequest(idp *IdentityProvider, r *http.Request) (*IdpAuthnRequest, error) {\n\treq := &IdpAuthnRequest{\n\t\tIDP:         idp,\n\t\tHTTPRequest: r,\n\t\tNow:         TimeNow(),\n\t}\n\n\tswitch r.Method {\n\tcase \"GET\":\n\t\tcompressedRequest, err := base64.StdEncoding.DecodeString(r.URL.Query().Get(\"SAMLRequest\"))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot decode request: %s\", err)\n\t\t}\n\t\treq.RequestBuffer, err = ioutil.ReadAll(flate.NewReader(bytes.NewReader(compressedRequest)))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot decompress request: %s\", err)\n\t\t}\n\t\treq.RelayState = r.URL.Query().Get(\"RelayState\")\n\tcase \"POST\":\n\t\tif err := r.ParseForm(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tvar err error\n\t\treq.RequestBuffer, err = base64.StdEncoding.DecodeString(r.PostForm.Get(\"SAMLRequest\"))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treq.RelayState = r.PostForm.Get(\"RelayState\")\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"method not allowed\")\n\t}\n\n\treturn req, nil\n}", "is_vulnerable": 0}
{"code": "func indirect(v reflect.Value, decodingNull bool) (json.Unmarshaler, encoding.TextUnmarshaler, reflect.Value) {\n\t// If v is a named type and is addressable,\n\t// start with its address, so that if the type has pointer methods,\n\t// we find them.\n\tif v.Kind() != reflect.Ptr && v.Type().Name() != \"\" && v.CanAddr() {\n\t\tv = v.Addr()\n\t}\n\tfor {\n\t\t// Load value from interface, but only if the result will be\n\t\t// usefully addressable.\n\t\tif v.Kind() == reflect.Interface && !v.IsNil() {\n\t\t\te := v.Elem()\n\t\t\tif e.Kind() == reflect.Ptr && !e.IsNil() && (!decodingNull || e.Elem().Kind() == reflect.Ptr) {\n\t\t\t\tv = e\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif v.Kind() != reflect.Ptr {\n\t\t\tbreak\n\t\t}\n\n\t\tif v.Elem().Kind() != reflect.Ptr && decodingNull && v.CanSet() {\n\t\t\tbreak\n\t\t}\n\t\tif v.IsNil() {\n\t\t\tif v.CanSet() {\n\t\t\t\tv.Set(reflect.New(v.Type().Elem()))\n\t\t\t} else {\n\t\t\t\tv = reflect.New(v.Type().Elem())\n\t\t\t}\n\t\t}\n\t\tif v.Type().NumMethod() > 0 {\n\t\t\tif u, ok := v.Interface().(json.Unmarshaler); ok {\n\t\t\t\treturn u, nil, reflect.Value{}\n\t\t\t}\n\t\t\tif u, ok := v.Interface().(encoding.TextUnmarshaler); ok {\n\t\t\t\treturn nil, u, reflect.Value{}\n\t\t\t}\n\t\t}\n\t\tv = v.Elem()\n\t}\n\treturn nil, nil, v\n}", "is_vulnerable": 1}
{"code": "func main() {\n\tif len(os.Args) < 3 {\n\t\tfatal(usage)\n\t}\n\n\tcmd, filename := os.Args[1], os.Args[2]\n\n\tff := archiver.MatchingFormat(filename)\n\tif ff == nil {\n\t\tfatalf(\"%s: Unsupported file extension\", filename)\n\t}\n\n\tvar err error\n\tswitch cmd {\n\tcase \"make\":\n\t\tif len(os.Args) < 4 {\n\t\t\tfatal(usage)\n\t\t}\n\t\terr = ff.Make(filename, os.Args[3:])\n\tcase \"open\":\n\t\tdest, osErr := os.Getwd()\n\t\tif osErr != nil {\n\t\t\tfatal(err)\n\t\t}\n\t\tif len(os.Args) == 4 {\n\t\t\tdest = os.Args[3]\n\t\t} else if len(os.Args) > 4 {\n\t\t\tfatal(usage)\n\t\t}\n\t\terr = ff.Open(filename, dest)\n\tdefault:\n\t\tfatal(usage)\n\t}\n\tif err != nil {\n\t\tfatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func InitializeHandler(srv *jrpc2.Server) handler.Func {\n\treturn handler.New(func(ctx context.Context, params lsp.InitializeParams) (interface{}, error) {\n\t\tmethod := \"InitializeHandler\"\n\t\tlog.Info().Str(\"method\", method).Interface(\"params\", params).Msg(\"RECEIVING\")\n\t\tInitializeSettings(ctx, params.InitializationOptions)\n\t\tconfig.CurrentConfig().SetClientCapabilities(params.Capabilities)\n\t\tsetClientInformation(params)\n\t\tdi.Analytics().Initialise()\n\t\tw := workspace.New(di.Instrumentor(), di.Scanner(), di.HoverService())\n\t\tworkspace.Set(w)\n\n\t\t// async processing listener\n\t\tgo createProgressListener(progress.Channel, srv)\n\t\tregisterNotifier(srv)\n\t\tgo func() {\n\t\t\tif params.ProcessID == 0 {\n\t\t\t\t// if started on its own, no need to exit or to monitor\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tmonitorClientProcess(params.ProcessID)\n\t\t\tlog.Info().Msgf(\"Shutting down as client pid %d not running anymore.\", params.ProcessID)\n\t\t\tos.Exit(0)\n\t\t}()\n\n\t\taddWorkspaceFolders(params, w)\n\n\t\treturn lsp.InitializeResult{\n\t\t\tServerInfo: lsp.ServerInfo{\n\t\t\t\tName:    \"snyk-ls\",\n\t\t\t\tVersion: config.LsProtocolVersion,\n\t\t\t},\n\t\t\tCapabilities: lsp.ServerCapabilities{\n\t\t\t\tTextDocumentSync: &sglsp.TextDocumentSyncOptionsOrKind{\n\t\t\t\t\tOptions: &sglsp.TextDocumentSyncOptions{\n\t\t\t\t\t\tOpenClose:         true,\n\t\t\t\t\t\tWillSave:          true,\n\t\t\t\t\t\tWillSaveWaitUntil: true,\n\t\t\t\t\t\tSave:              &sglsp.SaveOptions{IncludeText: true},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWorkspace: &lsp.Workspace{\n\t\t\t\t\tWorkspaceFolders: &lsp.WorkspaceFoldersServerCapabilities{\n\t\t\t\t\t\tSupported:           true,\n\t\t\t\t\t\tChangeNotifications: \"snyk-ls\",\n\t\t\t\t\t}},\n\t\t\t\tHoverProvider:      true,\n\t\t\t\tCodeActionProvider: true,\n\t\t\t\tCodeLensProvider:   &sglsp.CodeLensOptions{ResolveProvider: false},\n\t\t\t\tExecuteCommandProvider: &sglsp.ExecuteCommandOptions{\n\t\t\t\t\tCommands: []string{\n\t\t\t\t\t\tsnyk.NavigateToRangeCommand,\n\t\t\t\t\t\tsnyk.WorkspaceScanCommand,\n\t\t\t\t\t\tsnyk.OpenBrowserCommand,\n\t\t\t\t\t\tsnyk.LoginCommand,\n\t\t\t\t\t\tsnyk.CopyAuthLinkCommand,\n\t\t\t\t\t\tsnyk.LogoutCommand,\n\t\t\t\t\t\tsnyk.TrustWorkspaceFoldersCommand,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t})\n}", "is_vulnerable": 0}
{"code": "func (t *transport) setInitialKEXDone() {\n\tt.initialKEXDone = true\n}", "is_vulnerable": 0}
{"code": "func HTTPRedirectf(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.HTTPRedirectf(t, handler, method, url, values, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func fieldSeccompProfile(scmp *v1.SeccompProfile, profileRootPath string, fallbackToRuntimeDefault bool) (*runtimeapi.SecurityProfile, error) {\n\tif scmp == nil {\n\t\tif fallbackToRuntimeDefault {\n\t\t\treturn &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t\t}, nil\n\t\t}\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t\t}, nil\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeRuntimeDefault {\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t}, nil\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeLocalhost {\n\t\tif scmp.LocalhostProfile != nil && len(*scmp.LocalhostProfile) > 0 {\n\t\t\tfname := filepath.Join(profileRootPath, *scmp.LocalhostProfile)\n\t\t\treturn &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType:  runtimeapi.SecurityProfile_Localhost,\n\t\t\t\tLocalhostRef: fname,\n\t\t\t}, nil\n\t\t} else {\n\t\t\treturn nil, fmt.Errorf(\"localhostProfile must be set if seccompProfile type is Localhost.\")\n\t\t}\n\t}\n\treturn &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func Install(version string) error {\n\t// Make sure the RNG is seeded.\n\tseedrng.EnsureSeeded()\n\n\t// Configure logging before anything else.\n\tlogrus.SetFormatter(&logutils.Formatter{Component: \"cni-installer\"})\n\n\t// Clean up any existing binaries / config / assets.\n\tif err := os.RemoveAll(winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls\")); err != nil && !os.IsNotExist(err) {\n\t\tlogrus.WithError(err).Warnf(\"Error removing old TLS directory\")\n\t}\n\n\t// Load config.\n\tc := loadConfig()\n\n\t// Determine if we're running as a Kubernetes pod.\n\tvar kubecfg *rest.Config\n\n\tserviceAccountTokenFile := winutils.GetHostPath(\"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n\tc.ServiceAccountToken = make([]byte, 0)\n\tvar err error\n\tif fileExists(serviceAccountTokenFile) {\n\t\tlogrus.Info(\"Running as a Kubernetes pod\")\n\t\t// FIXME: get rid of this and call rest.InClusterConfig() directly when containerd v1.6 is EOL'd\n\t\tkubecfg, err = winutils.GetInClusterConfig()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = rest.LoadTLSFiles(kubecfg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tc.ServiceAccountToken, err = os.ReadFile(serviceAccountTokenFile)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Copy over any TLS assets from the SECRETS_MOUNT_DIR to the host.\n\t// First check if the dir exists and has anything in it.\n\tif directoryExists(c.TLSAssetsDir) {\n\t\t// Only install TLS assets if at least one of them exists in the dir.\n\t\tetcdCaPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-ca\")\n\t\tetcdCertPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-cert\")\n\t\tetcdKeyPath := fmt.Sprintf(\"%s/%s\", c.TLSAssetsDir, \"etcd-key\")\n\t\tif !fileExists(etcdCaPath) && !fileExists(etcdCertPath) && !fileExists(etcdKeyPath) {\n\t\t\tlogrus.Infof(\"No TLS assets found in %s, skipping\", c.TLSAssetsDir)\n\t\t} else {\n\t\t\tlogrus.Info(\"Installing any TLS assets\")\n\t\t\tmkdir(winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls\"))\n\t\t\tif err := copyFileAndPermissions(etcdCaPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-ca\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-ca\")\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(etcdCertPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-cert\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-cert\")\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(etcdKeyPath, winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/etcd-key\")); err != nil {\n\t\t\t\tlogrus.Warnf(\"Missing etcd-key\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Place the new binaries if the directory is writeable.\n\tdirs := []string{winutils.GetHostPath(\"/host/opt/cni/bin\"), winutils.GetHostPath(\"/host/secondary-bin-dir\")}\n\tbinsWritten := false\n\tfor _, d := range dirs {\n\t\tif err := fileutil.IsDirWriteable(d); err != nil {\n\t\t\tlogrus.Infof(\"%s is not writeable, skipping\", d)\n\t\t\tcontinue\n\t\t}\n\n\t\t// The binaries dir in the container needs to be prepended by the CONTAINER_SANDBOX_MOUNT_POINT env var on Windows Host Process Containers\n\t\t// see https://kubernetes.io/docs/tasks/configure-pod-container/create-hostprocess-pod/#containerd-v1-7-and-greater\n\t\tcontainerBinDir := winutils.GetHostPath(\"/opt/cni/bin\")\n\t\t// Iterate through each binary we might want to install.\n\t\tfiles, err := os.ReadDir(containerBinDir)\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\t\tfor _, binary := range files {\n\t\t\ttarget := fmt.Sprintf(\"%s/%s\", d, binary.Name())\n\t\t\tsource := fmt.Sprintf(\"%s/%s\", containerBinDir, binary.Name())\n\t\t\t// Skip the 'install' binary as it is not needed on the host\n\t\t\tif binary.Name() == \"install\" || binary.Name() == \"install.exe\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif c.skipBinary(binary.Name()) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif fileExists(target) && !c.UpdateCNIBinaries {\n\t\t\t\tlogrus.Infof(\"Skipping installation of %s\", target)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := copyFileAndPermissions(source, target); err != nil {\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed to install %s\", target)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tlogrus.Infof(\"Installed %s\", target)\n\t\t}\n\n\t\t// Binaries were placed into at least one directory\n\t\tlogrus.Infof(\"Wrote Calico CNI binaries to %s\\n\", d)\n\t\tbinsWritten = true\n\n\t\t// Instead of executing 'calico -v', check if the calico binary was copied successfully\n\t\tcalicoBinaryName := \"calico\"\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tcalicoBinaryName = \"calico.exe\"\n\t\t}\n\t\tcalicoBinaryOK, err := destinationUptoDate(containerBinDir+\"/\"+calicoBinaryName, d+\"/\"+calicoBinaryName)\n\t\tif err != nil {\n\t\t\tlogrus.WithError(err).Warnf(\"Failed verifying installed binary, exiting\")\n\t\t\treturn err\n\t\t}\n\t\t// Print version number successful\n\t\tif calicoBinaryOK {\n\t\t\tlogrus.Infof(\"CNI plugin version: %s\", version)\n\t\t}\n\t}\n\n\t// If binaries were not placed, exit\n\tif !binsWritten {\n\t\tlogrus.WithError(err).Fatalf(\"found no writeable directory, exiting\")\n\t}\n\n\tif kubecfg != nil {\n\t\t// If running as a Kubernetes pod, then write out a kubeconfig for the\n\t\t// CNI plugin to use.\n\t\twriteKubeconfig(kubecfg)\n\t}\n\n\t// Write a CNI config file.\n\twriteCNIConfig(c)\n\n\t// Unless told otherwise, sleep forever.\n\t// This prevents Kubernetes from restarting the pod repeatedly.\n\tlogrus.Infof(\"Done configuring CNI.  Sleep= %v\", c.ShouldSleep)\n\tfor c.ShouldSleep {\n\t\t// Kubernetes Secrets can be updated.  If so, we need to install the updated\n\t\t// version to the host. Just check the timestamp on the certificate to see if it\n\t\t// has been updated.  A bit hokey, but likely good enough.\n\t\tfilename := c.TLSAssetsDir + \"/etcd-cert\"\n\n\t\twatcher, err := fsnotify.NewWatcher()\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\n\t\tdone := make(chan bool)\n\n\t\t// Process events\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-watcher.Events:\n\t\t\t\t\tlogrus.Infoln(\"Updating installed secrets at:\", time.Now().String())\n\t\t\t\t\tfiles, err := os.ReadDir(c.TLSAssetsDir)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlogrus.Warn(err)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, f := range files {\n\t\t\t\t\t\tif err = copyFileAndPermissions(winutils.GetHostPath(c.TLSAssetsDir+\"/\"+f.Name()), winutils.GetHostPath(\"/host/etc/cni/net.d/calico-tls/\"+f.Name())); err != nil {\n\t\t\t\t\t\t\tlogrus.Warn(err)\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase err := <-watcher.Errors:\n\t\t\t\t\tlogrus.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\terr = watcher.Add(filename)\n\t\tif err != nil {\n\t\t\tlogrus.Fatal(err)\n\t\t}\n\n\t\t<-done\n\n\t\twatcher.Close()\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (a *jwtAuthorizer) Authorize(req *pbautoconf.AutoConfigRequest) (AutoConfigOptions, error) {\n\t// perform basic JWT Authorization\n\tidentity, err := a.validator.ValidateLogin(context.Background(), req.JWT)\n\tif err != nil {\n\t\t// TODO (autoconf) maybe we should add a more generic permission denied error not tied to the ACL package?\n\t\treturn AutoConfigOptions{}, acl.PermissionDenied(\"Failed JWT authorization: %v\", err)\n\t}\n\n\t// Ensure provided data cannot escape the RHS of a bexpr for security.\n\t// This is not the cleanest way to prevent this behavior. Ideally, the bexpr would allow us to\n\t// inject a variable on the RHS for comparison as well, but it would be a complex change to implement\n\t// that would likely break backwards-compatibility in certain circumstances.\n\tif dns.InvalidNameRe.MatchString(req.Node) {\n\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Invalid request field. %v = `%v`\", \"node\", req.Node)\n\t}\n\tif invalidSegmentName.MatchString(req.Segment) {\n\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Invalid request field. %v = `%v`\", \"segment\", req.Segment)\n\t}\n\tif req.Partition != \"\" && !dns.IsValidLabel(req.Partition) {\n\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Invalid request field. %v = `%v`\", \"partition\", req.Partition)\n\t}\n\n\t// Ensure that every value in this mapping is safe to interpolate before using it.\n\tvarMap := map[string]string{\n\t\t\"node\":      req.Node,\n\t\t\"segment\":   req.Segment,\n\t\t\"partition\": req.PartitionOrDefault(),\n\t}\n\n\tfor _, raw := range a.claimAssertions {\n\t\t// validate and fill any HIL\n\t\tfilled, err := template.InterpolateHIL(raw, varMap, true)\n\t\tif err != nil {\n\t\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Failed to render claim assertion template %q: %w\", raw, err)\n\t\t}\n\n\t\tevaluator, err := bexpr.CreateEvaluatorForType(filled, nil, identity.SelectableFields)\n\t\tif err != nil {\n\t\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Failed to create evaluator for claim assertion %q: %w\", filled, err)\n\t\t}\n\n\t\tok, err := evaluator.Evaluate(identity.SelectableFields)\n\t\tif err != nil {\n\t\t\treturn AutoConfigOptions{}, fmt.Errorf(\"Failed to execute claim assertion %q: %w\", filled, err)\n\t\t}\n\n\t\tif !ok {\n\t\t\treturn AutoConfigOptions{}, acl.PermissionDenied(\"Failed JWT claim assertion\")\n\t\t}\n\t}\n\n\topts := AutoConfigOptions{\n\t\tNodeName:    req.Node,\n\t\tSegmentName: req.Segment,\n\t\tPartition:   req.Partition,\n\t}\n\n\tif req.CSR != \"\" {\n\t\tcsr, id, err := parseAutoConfigCSR(req.CSR)\n\t\tif err != nil {\n\t\t\treturn AutoConfigOptions{}, err\n\t\t}\n\n\t\tif id.Agent != req.Node || !structs.EqualPartitions(id.Partition, req.Partition) {\n\t\t\treturn AutoConfigOptions{},\n\t\t\t\tfmt.Errorf(\"Spiffe ID agent name (%s) of the certificate signing request is not for the correct node (%s)\",\n\t\t\t\t\tprintNodeName(id.Agent, id.Partition),\n\t\t\t\t\tprintNodeName(req.Node, req.Partition),\n\t\t\t\t)\n\t\t}\n\n\t\topts.CSR = csr\n\t\topts.SpiffeID = id\n\t}\n\n\treturn opts, nil\n}", "is_vulnerable": 0}
{"code": "func (f Formatter) FormatInfo(level int, msg string, kvList []interface{}) (prefix, argsStr string) {\n\targs := make([]interface{}, 0, 64) // using a constant here impacts perf\n\tprefix = f.prefix\n\tif f.outputFormat == outputJSON {\n\t\targs = append(args, \"logger\", prefix)\n\t\tprefix = \"\"\n\t}\n\tif f.opts.LogTimestamp {\n\t\targs = append(args, \"ts\", time.Now().Format(f.opts.TimestampFormat))\n\t}\n\tif policy := f.opts.LogCaller; policy == All || policy == Info {\n\t\targs = append(args, \"caller\", f.caller())\n\t}\n\targs = append(args, \"level\", level, \"msg\", msg)\n\treturn prefix, f.render(args, kvList)\n}", "is_vulnerable": 1}
{"code": "func newResourcesSubjectMapWithCapacity(resourceType *core.RelationReference, capacity uint32) resourcesSubjectMap {\n\treturn resourcesSubjectMap{\n\t\tresourceType:         resourceType,\n\t\tresourcesAndSubjects: util.NewMultiMapWithCapacity[string, subjectInfo](capacity),\n\t}\n}", "is_vulnerable": 0}
{"code": "func (client AccountsClient) CheckNameAvailabilitySender(req *http.Request) (*http.Response, error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\treturn autorest.SendWithSender(client, req, sd...)\n}", "is_vulnerable": 0}
{"code": "func TestUpstreamHashBy(t *testing.T) {\n\tec := NewAnnotationExtractor(mockCfg{})\n\ting := buildIngress()\n\n\tfooAnns := []struct {\n\t\tannotations map[string]string\n\t\ter          string\n\t}{\n\t\t{map[string]string{annotationUpstreamHashBy: \"$request_uri\"}, \"$request_uri\"},\n\t\t{map[string]string{annotationUpstreamHashBy: \"false\"}, \"false\"},\n\t\t{map[string]string{annotationUpstreamHashBy + \"_no\": \"true\"}, \"\"},\n\t\t{map[string]string{}, \"\"},\n\t\t{nil, \"\"},\n\t}\n\n\tfor _, foo := range fooAnns {\n\t\ting.SetAnnotations(foo.annotations)\n\t\tr, err := ec.Extract(ing)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"error should be null: %v\", err)\n\t\t}\n\t\tif r.UpstreamHashBy.UpstreamHashBy != foo.er {\n\t\t\tt.Errorf(\"Returned %v but expected %v\", r, foo.er)\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func (t *Template) Validate() error {\n\tvar mErr multierror.Error\n\n\t// Verify we have something to render\n\tif t.SourcePath == \"\" && t.EmbeddedTmpl == \"\" {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify a source path or have an embedded template\"))\n\t}\n\n\t// Verify we can render somewhere\n\tif t.DestPath == \"\" {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify a destination for the template\"))\n\t}\n\n\t// Verify the destination doesn't escape\n\tescaped, err := PathEscapesAllocDir(\"task\", t.DestPath)\n\tif err != nil {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"invalid destination path: %v\", err))\n\t} else if escaped {\n\t\tmErr.Errors = append(mErr.Errors, fmt.Errorf(\"destination escapes allocation directory\"))\n\t}\n\n\t// Verify a proper change mode\n\tswitch t.ChangeMode {\n\tcase TemplateChangeModeNoop, TemplateChangeModeRestart:\n\tcase TemplateChangeModeSignal:\n\t\tif t.ChangeSignal == \"\" {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify signal value when change mode is signal\"))\n\t\t}\n\t\tif t.Envvars {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"cannot use signals with env var templates\"))\n\t\t}\n\tdefault:\n\t\t_ = multierror.Append(&mErr, TemplateChangeModeInvalidError)\n\t}\n\n\t// Verify the splay is positive\n\tif t.Splay < 0 {\n\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Must specify positive splay value\"))\n\t}\n\n\t// Verify the permissions\n\tif t.Perms != \"\" {\n\t\tif _, err := strconv.ParseUint(t.Perms, 8, 12); err != nil {\n\t\t\t_ = multierror.Append(&mErr, fmt.Errorf(\"Failed to parse %q as octal: %v\", t.Perms, err))\n\t\t}\n\t}\n\n\treturn mErr.ErrorOrNil()\n}", "is_vulnerable": 1}
{"code": "\tif err := fs.unixFS.WalkDirat(dirfd, name, func(dirfd int, name, _ string, info ufs.DirEntry, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := fs.unixFS.Lchownat(dirfd, name, uid, gid); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t}); err != nil {", "is_vulnerable": 0}
{"code": "\t\tt.Run(fmt.Sprintf(\"Case%d\", i), func(t *testing.T) {\n\t\t\tif len(kat.AAD) > 0 {\n\t\t\t\tt.Skip(\"Skipping... SDK implementation does not expose additional authenticated data\")\n\t\t\t}\n\t\t\tiv, err := hex.DecodeString(kat.IV)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode iv: %v\", err)\n\t\t\t}\n\t\t\tkey, err := hex.DecodeString(kat.Key)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode key: %v\", err)\n\t\t\t}\n\t\t\tplaintext, err := hex.DecodeString(kat.Plaintext)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode plaintext: %v\", err)\n\t\t\t}\n\t\t\tciphertext, err := hex.DecodeString(kat.CipherText)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode ciphertext: %v\", err)\n\t\t\t}\n\t\t\ttag, err := hex.DecodeString(kat.Tag)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to decode tag: %v\", err)\n\t\t\t}\n\t\t\taesgcmTest(t, iv, key, plaintext, ciphertext, tag)\n\t\t})", "is_vulnerable": 0}
{"code": "func TestFetchPCRValues(t *testing.T) {\n\trwc := openTPMOrSkip(t)\n\tdefer rwc.Close()\n\n\tvar mask pcrMask\n\tif err := mask.setPCR(17); err != nil {\n\t\tt.Fatal(\"Couldn't set PCR 17:\", err)\n\t}\n\n\tpcrs, err := FetchPCRValues(rwc, []int{17})\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't get PCRs 17:\", err)\n\t}\n\n\tcomp, err := createPCRComposite(mask, pcrs)\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't create PCR composite\")\n\t}\n\n\tif len(comp) != int(20) {\n\t\tt.Fatal(\"Invalid PCR composite\")\n\t}\n\n\tvar loc Locality\n\t_, err = createPCRInfoLong(loc, mask, pcrs)\n\tif err != nil {\n\t\tt.Fatal(\"Couldn't create a pcrInfoLong structure for these PCRs\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *autoCodeMysql) GetTables(businessDB string, dbName string) (data []response.Table, err error) {\n\tvar entities []response.Table\n\tsql := `select table_name as table_name from information_schema.tables where table_schema = ?`\n\tif businessDB == \"\" {\n\t\terr = global.GVA_DB.Raw(sql, dbName).Scan(&entities).Error\n\t} else {\n\t\terr = global.GVA_DBList[businessDB].Raw(sql, dbName).Scan(&entities).Error\n\t}\n\n\treturn entities, err\n}", "is_vulnerable": 0}
{"code": "func WriteTextPlainDeprecated(w http.ResponseWriter, r *http.Request) (isPlainText bool) {\n\tif r.Header.Get(HdrNameContentType) != HdrValTextPlain {\n\t\treturn false\n\t}\n\n\tError(r, w, http.StatusUnsupportedMediaType, textPlainDeprMsg)\n\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func TestConfigurator_VerifyIncomingHTTPS(t *testing.T) {\n\tc := Configurator{base: &Config{\n\t\tVerifyIncomingHTTPS: true,\n\t}}\n\tverify := c.verifyIncomingHTTPS()\n\trequire.Equal(t, c.base.VerifyIncomingHTTPS, verify)\n}", "is_vulnerable": 0}
{"code": "func (s *Stat) CTime() time.Time {\n\tst := s.Sys().(*syscall.Stat_t)\n\n\t// Do not remove these \"redundant\" type-casts, they are required for 32-bit builds to work.\n\treturn time.Unix(int64(st.Ctim.Sec), int64(st.Ctim.Nsec))\n}", "is_vulnerable": 1}
{"code": "func New(payloads map[string]interface{}, attackType AttackType, templatePath string, allowLocalFileAccess bool, catalog catalog.Catalog, customAttackType string) (*PayloadGenerator, error) {\n\tif attackType.String() == \"\" {\n\t\tattackType = BatteringRamAttack\n\t}\n\n\t// Resolve payload paths if they are files.\n\tpayloadsFinal := make(map[string]interface{})\n\tfor name, payload := range payloads {\n\t\tpayloadsFinal[name] = payload\n\t}\n\tfor name, payload := range payloads {\n\t\tpayloadStr, ok := payload.(string)\n\t\tif ok {\n\t\t\tfinal, resolveErr := catalog.ResolvePath(payloadStr, templatePath)\n\t\t\tif resolveErr != nil {\n\t\t\t\treturn nil, errors.Wrap(resolveErr, \"could not read payload file\")\n\t\t\t}\n\t\t\tpayloadsFinal[name] = final\n\t\t}\n\t}\n\n\tgenerator := &PayloadGenerator{catalog: catalog}\n\tif err := generator.validate(payloadsFinal, templatePath); err != nil {\n\t\treturn nil, err\n\t}\n\n\tcompiled, err := generator.loadPayloads(payloadsFinal, templatePath, config.DefaultConfig.TemplatesDirectory, allowLocalFileAccess)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tgenerator.Type = attackType\n\tgenerator.payloads = compiled\n\n\tif customAttackType != \"\" {\n\t\tattackTypeNew, err := toAttackType(customAttackType)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"could not parse custom attack-type\")\n\t\t}\n\t\tgenerator.Type = attackTypeNew\n\t}\n\t// Validate the batteringram payload set\n\tif attackType == BatteringRamAttack {\n\t\tif len(payloads) != 1 {\n\t\t\treturn nil, errors.New(\"batteringram must have single payload set\")\n\t\t}\n\t}\n\treturn generator, nil\n}", "is_vulnerable": 0}
{"code": "func NewWebServer(g *gounicorn.GoUnicorn) *WebServer {\n\tl := log.WithField(\"logger\", \"authentik.router\")\n\tmainHandler := mux.NewRouter()\n\tmainHandler.Use(web.ProxyHeaders())\n\tmainHandler.Use(handlers.CompressHandler)\n\tloggingHandler := mainHandler.NewRoute().Subrouter()\n\tloggingHandler.Use(web.NewLoggingHandler(l, nil))\n\n\tws := &WebServer{\n\t\tm:   mainHandler,\n\t\tlh:  loggingHandler,\n\t\tlog: l,\n\t\tp:   g,\n\t}\n\tws.configureStatic()\n\tws.configureProxy()\n\treturn ws\n}", "is_vulnerable": 0}
{"code": "func (c *LocalChecker) ResolveCheck(\n\tctx context.Context,\n\treq *ResolveCheckRequest,\n) (*ResolveCheckResponse, error) {\n\tif ctx.Err() != nil {\n\t\treturn nil, ctx.Err()\n\t}\n\n\tctx, span := tracer.Start(ctx, \"ResolveCheck\")\n\tdefer span.End()\n\tspan.SetAttributes(attribute.String(\"resolver_type\", \"LocalChecker\"))\n\tspan.SetAttributes(attribute.String(\"tuple_key\", req.GetTupleKey().String()))\n\n\tif req.GetRequestMetadata().Depth == 0 {\n\t\treturn nil, ErrResolutionDepthExceeded\n\t}\n\n\ttypesys, ok := typesystem.TypesystemFromContext(ctx)\n\tif !ok {\n\t\tpanic(\"typesystem missing in context\")\n\t}\n\n\ttupleKey := req.GetTupleKey()\n\tobject := tupleKey.GetObject()\n\trelation := tupleKey.GetRelation()\n\n\tobjectType, _ := tuple.SplitObject(object)\n\trel, err := typesys.GetRelation(objectType, relation)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"relation '%s' undefined for object type '%s'\", relation, objectType)\n\t}\n\n\tresp, err := c.checkRewrite(ctx, req, rel.GetRewrite())(ctx)\n\tif err != nil {\n\t\ttelemetry.TraceError(span, err)\n\t\treturn nil, err\n\t}\n\n\treturn resp, nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CredsUpdate(ctx context.Context, in *clientpb.Credentials, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/CredsUpdate\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (src *DataRow) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'D')\n\n\tdst = pgio.AppendUint16(dst, uint16(len(src.Values)))\n\tfor _, v := range src.Values {\n\t\tif v == nil {\n\t\t\tdst = pgio.AppendInt32(dst, -1)\n\t\t\tcontinue\n\t\t}\n\n\t\tdst = pgio.AppendInt32(dst, int32(len(v)))\n\t\tdst = append(dst, v...)\n\t}\n\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func DefaultEnvVariables() map[string]string {\n\treturn map[string]string{\n\t\t\"PATH\": \"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n\t\t\"TERM\": \"xterm\",\n\t}\n}", "is_vulnerable": 0}
{"code": "func (ch *cors) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\torigin := r.Header.Get(corsOriginHeader)\n\tif !ch.isOriginAllowed(origin) {\n\t\tch.h.ServeHTTP(w, r)\n\t\treturn\n\t}\n\n\tif r.Method == corsOptionMethod {\n\t\tif ch.ignoreOptions {\n\t\t\tch.h.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\n\t\tif _, ok := r.Header[corsRequestMethodHeader]; !ok {\n\t\t\tw.WriteHeader(http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\n\t\tmethod := r.Header.Get(corsRequestMethodHeader)\n\t\tif !ch.isMatch(method, ch.allowedMethods) {\n\t\t\tw.WriteHeader(http.StatusMethodNotAllowed)\n\t\t\treturn\n\t\t}\n\n\t\trequestHeaders := strings.Split(r.Header.Get(corsRequestHeadersHeader), \",\")\n\t\tallowedHeaders := []string{}\n\t\tfor _, v := range requestHeaders {\n\t\t\tcanonicalHeader := http.CanonicalHeaderKey(strings.TrimSpace(v))\n\t\t\tif canonicalHeader == \"\" || ch.isMatch(canonicalHeader, defaultCorsHeaders) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif !ch.isMatch(canonicalHeader, ch.allowedHeaders) {\n\t\t\t\tw.WriteHeader(http.StatusForbidden)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tallowedHeaders = append(allowedHeaders, canonicalHeader)\n\t\t}\n\n\t\tif len(allowedHeaders) > 0 {\n\t\t\tw.Header().Set(corsAllowHeadersHeader, strings.Join(allowedHeaders, \",\"))\n\t\t}\n\n\t\tif ch.maxAge > 0 {\n\t\t\tw.Header().Set(corsMaxAgeHeader, strconv.Itoa(ch.maxAge))\n\t\t}\n\n\t\tif !ch.isMatch(method, defaultCorsMethods) {\n\t\t\tw.Header().Set(corsAllowMethodsHeader, method)\n\t\t}\n\t} else {\n\t\tif len(ch.exposedHeaders) > 0 {\n\t\t\tw.Header().Set(corsExposeHeadersHeader, strings.Join(ch.exposedHeaders, \",\"))\n\t\t}\n\t}\n\n\tif ch.allowCredentials {\n\t\tw.Header().Set(corsAllowCredentialsHeader, \"true\")\n\t}\n\n\tif len(ch.allowedOrigins) > 1 {\n\t\tw.Header().Set(corsVaryHeader, corsOriginHeader)\n\t}\n\n\tw.Header().Set(corsAllowOriginHeader, origin)\n\n\tif r.Method == corsOptionMethod {\n\t\treturn\n\t}\n\tch.h.ServeHTTP(w, r)\n}", "is_vulnerable": 1}
{"code": "func (c *Client) Update() (data.TargetFiles, error) {\n\tif err := c.UpdateRoots(); err != nil {\n\t\tif _, ok := err.(verify.ErrExpired); ok {\n\t\t\t// For backward compatibility, we wrap the ErrExpired inside\n\t\t\t// ErrDecodeFailed.\n\t\t\treturn nil, ErrDecodeFailed{\"root.json\", err}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// Get timestamp.json, extract snapshot.json file meta and save the\n\t// timestamp.json locally\n\ttimestampJSON, err := c.downloadMetaUnsafe(\"timestamp.json\", defaultTimestampDownloadLimit)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsnapshotMeta, err := c.decodeTimestamp(timestampJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := c.local.SetMeta(\"timestamp.json\", timestampJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Get snapshot.json, then extract file metas.\n\t// root.json meta should not be stored in the snapshot, if it is,\n\t// the root will be checked, re-downloaded\n\tsnapshotJSON, err := c.downloadMetaFromTimestamp(\"snapshot.json\", snapshotMeta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsnapshotMetas, err := c.decodeSnapshot(snapshotJSON)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Save the snapshot.json\n\tif err := c.local.SetMeta(\"snapshot.json\", snapshotJSON); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// If we don't have the targets.json, download it, determine updated\n\t// targets and save targets.json in local storage\n\tvar updatedTargets data.TargetFiles\n\ttargetsMeta := snapshotMetas[\"targets.json\"]\n\tif !c.hasMetaFromSnapshot(\"targets.json\", targetsMeta) {\n\t\ttargetsJSON, err := c.downloadMetaFromSnapshot(\"targets.json\", targetsMeta)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tupdatedTargets, err = c.decodeTargets(targetsJSON)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif err := c.local.SetMeta(\"targets.json\", targetsJSON); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn updatedTargets, nil\n}", "is_vulnerable": 1}
{"code": "func parseWorkflowTemplate(workflow *workflows.WorkflowTemplate, preprocessor Preprocessor, options *protocols.ExecutorOptions, loader model.WorkflowLoader, noValidate bool) error {\n\tvar paths []string\n\n\tsubTemplateTags := workflow.Tags\n\tif !subTemplateTags.IsEmpty() {\n\t\tpaths = loader.GetTemplatePathsByTags(subTemplateTags.ToSlice())\n\t} else {\n\t\tpaths = loader.GetTemplatePaths([]string{workflow.Template}, noValidate)\n\t}\n\tif len(paths) == 0 {\n\t\treturn nil\n\t}\n\n\tvar workflowTemplates []*Template\n\n\tfor _, path := range paths {\n\t\ttemplate, err := Parse(path, preprocessor, options.Copy())\n\t\tif err != nil {\n\t\t\tgologger.Warning().Msgf(\"Could not parse workflow template %s: %v\\n\", path, err)\n\t\t\tcontinue\n\t\t}\n\t\tif template.Executer == nil {\n\t\t\tgologger.Warning().Msgf(\"Could not parse workflow template %s: no executer found\\n\", path)\n\t\t\tcontinue\n\t\t}\n\t\tif len(template.RequestsCode) > 0 {\n\t\t\tif !options.Options.EnableCodeTemplates {\n\t\t\t\tgologger.Warning().Msgf(\"`-code` flag not found, skipping code template from workflow: %v\\n\", path)\n\t\t\t\tcontinue\n\t\t\t} else if !template.Verified {\n\t\t\t\t// unverfied code templates are not allowed in workflows\n\t\t\t\tgologger.Warning().Msgf(\"skipping unverified code template from workflow: %v\\n\", path)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tworkflowTemplates = append(workflowTemplates, template)\n\t}\n\n\tfinalTemplates, _ := ClusterTemplates(workflowTemplates, options.Copy())\n\tfor _, template := range finalTemplates {\n\t\tworkflow.Executers = append(workflow.Executers, &workflows.ProtocolExecuterPair{\n\t\t\tExecuter:     template.Executer,\n\t\t\tOptions:      options,\n\t\t\tTemplateType: template.Type(),\n\t\t})\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\t\tNewRequest: func() (*request.Request, error) {\n\t\t\tvar inCpy *GetSecurityGroupsForVpcInput\n\t\t\tif input != nil {\n\t\t\t\ttmp := *input\n\t\t\t\tinCpy = &tmp\n\t\t\t}\n\t\t\treq, _ := c.GetSecurityGroupsForVpcRequest(inCpy)\n\t\t\treq.SetContext(ctx)\n\t\t\treq.ApplyOptions(opts...)\n\t\t\treturn req, nil\n\t\t},", "is_vulnerable": 0}
{"code": "func (s *submounts) subMount(m mount.Mount, subPath string) (mount.Mount, error) {\n\tif path.Join(\"/\", subPath) == \"/\" {\n\t\treturn m, nil\n\t}\n\tif s.m == nil {\n\t\ts.m = map[uint64]mountRef{}\n\t}\n\th, err := hashstructure.Hash(m, hashstructure.FormatV2, nil)\n\tif err != nil {\n\t\treturn mount.Mount{}, err\n\t}\n\tif mr, ok := s.m[h]; ok {\n\t\tif sm, ok := mr.subRefs[subPath]; ok {\n\t\t\treturn sm.mount, nil\n\t\t}\n\t\tsm, unmount, err := sub(mr.mount, subPath)\n\t\tif err != nil {\n\t\t\treturn mount.Mount{}, err\n\t\t}\n\t\tmr.subRefs[subPath] = mountRef{\n\t\t\tmount:   sm,\n\t\t\tunmount: unmount,\n\t\t}\n\t\treturn sm, nil\n\t}\n\n\tlm := snapshot.LocalMounterWithMounts([]mount.Mount{m})\n\n\tmp, err := lm.Mount()\n\tif err != nil {\n\t\treturn mount.Mount{}, err\n\t}\n\n\tvar mntType string\n\topts := []string{}\n\tif m.ReadOnly() {\n\t\topts = append(opts, \"ro\")\n\t}\n\n\tif runtime.GOOS != \"windows\" {\n\t\t// Windows uses a mechanism similar to bind mounts, but will err out if we request\n\t\t// a mount type it does not understand. Leaving the mount type empty on Windows will\n\t\t// yield the same result.\n\t\tmntType = \"bind\"\n\t\topts = append(opts, \"rbind\")\n\t}\n\n\ts.m[h] = mountRef{\n\t\tmount: mount.Mount{\n\t\t\tSource:  mp,\n\t\t\tType:    mntType,\n\t\t\tOptions: opts,\n\t\t},\n\t\tunmount: lm.Unmount,\n\t\tsubRefs: map[string]mountRef{},\n\t}\n\n\tsm, unmount, err := sub(s.m[h].mount, subPath)\n\tif err != nil {\n\t\treturn mount.Mount{}, err\n\t}\n\ts.m[h].subRefs[subPath] = mountRef{\n\t\tmount:   sm,\n\t\tunmount: unmount,\n\t}\n\treturn sm, nil\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"no language\", func(t *testing.T) {\n\t\tdefer func() {\n\t\t\tassert.Equal(t, \"no language is specified\", recover())\n\t\t}()\n\n\t\tm := macaron.New()\n\t\tm.Use(I18n(Options{}))\n\t})", "is_vulnerable": 0}
{"code": "func (f *EntryFormatter) Process(ctx context.Context, e *eventlogger.Event) (*eventlogger.Event, error) {\n\tconst op = \"audit.(EntryFormatter).Process\"\n\n\tselect {\n\tcase <-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\tif e == nil {\n\t\treturn nil, fmt.Errorf(\"%s: event is nil: %w\", op, event.ErrInvalidParameter)\n\t}\n\n\ta, ok := e.Payload.(*auditEvent)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"%s: cannot parse event payload: %w\", op, event.ErrInvalidParameter)\n\t}\n\n\tif a.Data == nil {\n\t\treturn nil, fmt.Errorf(\"%s: cannot audit event (%s) with no data: %w\", op, a.Subtype, event.ErrInvalidParameter)\n\t}\n\n\t// Take a copy of the event data before we modify anything.\n\tdata, err := a.Data.Clone()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: unable to copy audit event data: %w\", op, err)\n\t}\n\n\tvar headers map[string][]string\n\tif data.Request != nil && data.Request.Headers != nil {\n\t\theaders = data.Request.Headers\n\t}\n\n\tif f.headerFormatter != nil {\n\t\tadjustedHeaders, err := f.headerFormatter.ApplyConfig(ctx, headers, f.salter)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to transform headers for auditing: %w\", op, err)\n\t\t}\n\n\t\tdata.Request.Headers = adjustedHeaders\n\t}\n\n\tvar result []byte\n\n\tswitch a.Subtype {\n\tcase RequestType:\n\t\tentry, err := f.FormatRequest(ctx, data)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to parse request from audit event: %w\", op, err)\n\t\t}\n\n\t\tresult, err = jsonutil.EncodeJSON(entry)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to format request: %w\", op, err)\n\t\t}\n\tcase ResponseType:\n\t\tentry, err := f.FormatResponse(ctx, data)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to parse response from audit event: %w\", op, err)\n\t\t}\n\n\t\tresult, err = jsonutil.EncodeJSON(entry)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to format response: %w\", op, err)\n\t\t}\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"%s: unknown audit event subtype: %q\", op, a.Subtype)\n\t}\n\n\tif f.config.RequiredFormat == JSONxFormat {\n\t\tvar err error\n\t\tresult, err = jsonx.EncodeJSONBytes(result)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: unable to encode JSONx using JSON data: %w\", op, err)\n\t\t}\n\t\tif result == nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: encoded JSONx was nil: %w\", op, err)\n\t\t}\n\t}\n\n\t// This makes a bit of a mess of the 'format' since both JSON and XML (JSONx)\n\t// don't support a prefix just sitting there.\n\t// However, this would be a breaking change to how Vault currently works to\n\t// include the prefix as part of the JSON object or XML document.\n\tif f.prefix != \"\" {\n\t\tresult = append([]byte(f.prefix), result...)\n\t}\n\n\t// Store the final format.\n\te.FormattedAs(f.config.RequiredFormat.String(), result)\n\n\treturn e, nil\n}", "is_vulnerable": 1}
{"code": "func (v *View) userByID(ctx context.Context, instanceID string, queries ...query.SearchQuery) (*model.UserView, error) {\n\tqueriedUser, err := v.query.GetNotifyUser(ctx, true, queries...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// always load the latest sequence first, so in case the user was not found by id,\n\t// the sequence will be equal or lower than the actual projection and no events are lost\n\tsequence, err := v.GetLatestUserSequence(ctx, instanceID)\n\tlogging.WithFields(\"instanceID\", instanceID).\n\t\tOnError(err).\n\t\tErrorf(\"could not get current sequence for userByID\")\n\n\tuser, err := view.UserByID(ctx, v.Db, queriedUser.ID, instanceID)\n\tif err != nil && !zerrors.IsNotFound(err) {\n\t\treturn nil, err\n\t}\n\n\tif err != nil {\n\t\tuser = new(model.UserView)\n\t\tif sequence != nil {\n\t\t\tuser.ChangeDate = sequence.EventCreatedAt\n\t\t}\n\t}\n\n\tquery, err := view.UserByIDQuery(queriedUser.ID, instanceID, user.ChangeDate, user.EventTypes())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tevents, err := v.es.Filter(ctx, query)\n\tif err != nil && user.Sequence == 0 {\n\t\treturn nil, err\n\t} else if err != nil {\n\t\treturn user, nil\n\t}\n\n\tuserCopy := *user\n\n\tfor _, event := range events {\n\t\tif err := user.AppendEvent(event); err != nil {\n\t\t\treturn &userCopy, nil\n\t\t}\n\t}\n\n\tif user.State == int32(usr_model.UserStateDeleted) {\n\t\treturn nil, zerrors.ThrowNotFound(nil, \"VIEW-r4y8r\", \"Errors.User.NotFound\")\n\t}\n\n\treturn user, nil\n}", "is_vulnerable": 0}
{"code": "func extractTarArchiveFile(header *tar.Header, dest string, input io.Reader) error {\n\tfilePath := filepath.Join(dest, header.Name)\n\tfileInfo := header.FileInfo()\n\n\tif fileInfo.IsDir() {\n\t\treturn os.MkdirAll(filePath, fileInfo.Mode())\n\t}\n\n\terr := os.MkdirAll(filepath.Dir(filePath), 0755)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif fileInfo.Mode()&os.ModeSymlink != 0 {\n\t\treturn os.Symlink(header.Linkname, filePath)\n\t}\n\n\tfileCopy, err := os.OpenFile(filePath, os.O_RDWR|os.O_CREATE|os.O_TRUNC, fileInfo.Mode())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer fileCopy.Close()\n\n\t_, err = io.Copy(fileCopy, input)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func (m *NestedDefinition_NestedMessage_NestedNestedMsg) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NestedNestedMsg: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NestedNestedMsg: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 10:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field NestedNestedField1\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.NestedNestedField1 = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(\"\", func(t *testing.T) {\n\t\t\tassert.Equal(t, test.want, isLocalHostname(test.hostname))\n\t\t})", "is_vulnerable": 1}
{"code": "func (lt *limitTracker) clone() *limitTracker {\n\treturn &limitTracker{\n\t\tcurrentLimit: lt.currentLimit,\n\t\thasLimit:     lt.hasLimit,\n\t}\n}", "is_vulnerable": 0}
{"code": "func generateEnvEntries(name string, options *ipfailover.IPFailoverConfigCmdOptions) app.Environment {\n\twatchPort := strconv.Itoa(options.WatchPort)\n\treplicas := strconv.FormatInt(int64(options.Replicas), 10)\n\tinterval := strconv.Itoa(options.CheckInterval)\n\tVRRPIDOffset := strconv.Itoa(options.VRRPIDOffset)\n\tenv := app.Environment{}\n\n\tenv.Add(app.Environment{\n\n\t\t\"OPENSHIFT_HA_CONFIG_NAME\":       name,\n\t\t\"OPENSHIFT_HA_VIRTUAL_IPS\":       options.VirtualIPs,\n\t\t\"OPENSHIFT_HA_NETWORK_INTERFACE\": options.NetworkInterface,\n\t\t\"OPENSHIFT_HA_MONITOR_PORT\":      watchPort,\n\t\t\"OPENSHIFT_HA_VRRP_ID_OFFSET\":    VRRPIDOffset,\n\t\t\"OPENSHIFT_HA_REPLICA_COUNT\":     replicas,\n\t\t\"OPENSHIFT_HA_USE_UNICAST\":       \"false\",\n\t\t\"OPENSHIFT_HA_IPTABLES_CHAIN\":    options.IptablesChain,\n\t\t\"OPENSHIFT_HA_NOTIFY_SCRIPT\":     options.NotifyScript,\n\t\t\"OPENSHIFT_HA_CHECK_SCRIPT\":      options.CheckScript,\n\t\t\"OPENSHIFT_HA_CHECK_INTERVAL\":    interval,\n\t\t// \"OPENSHIFT_HA_UNICAST_PEERS\":     \"127.0.0.1\",\n\t})\n\treturn env\n}", "is_vulnerable": 0}
{"code": "func (w *WriteAuthorizationModelCommand) Execute(ctx context.Context, req *openfgapb.WriteAuthorizationModelRequest) (*openfgapb.WriteAuthorizationModelResponse, error) {\n\t// Until this is solved: https://github.com/envoyproxy/protoc-gen-validate/issues/74\n\tif len(req.GetTypeDefinitions()) > w.backend.MaxTypesPerAuthorizationModel() {\n\t\treturn nil, serverErrors.ExceededEntityLimit(\"type definitions in an authorization model\", w.backend.MaxTypesPerAuthorizationModel())\n\t}\n\n\t// Fill in the schema version for old requests, which don't contain it, while we migrate to the new schema version.\n\tif req.SchemaVersion == \"\" {\n\t\treq.SchemaVersion = typesystem.SchemaVersion1_1\n\t}\n\n\tmodel := &openfgapb.AuthorizationModel{\n\t\tId:              ulid.Make().String(),\n\t\tSchemaVersion:   req.GetSchemaVersion(),\n\t\tTypeDefinitions: req.GetTypeDefinitions(),\n\t}\n\n\t_, err := typesystem.NewAndValidate(ctx, model)\n\tif err != nil {\n\t\treturn nil, serverErrors.InvalidAuthorizationModelInput(err)\n\t}\n\n\terr = w.backend.WriteAuthorizationModel(ctx, req.GetStoreId(), model)\n\tif err != nil {\n\t\treturn nil, serverErrors.NewInternalError(\"Error writing authorization model configuration\", err)\n\t}\n\n\treturn &openfgapb.WriteAuthorizationModelResponse{\n\t\tAuthorizationModelId: model.Id,\n\t}, nil\n}", "is_vulnerable": 0}
{"code": "func (param *MySQLConnectParam) ToDSN() string {\n\thostPort := net.JoinHostPort(param.Host, strconv.Itoa(param.Port))\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(%s)/?charset=utf8mb4&sql_mode='%s'&maxAllowedPacket=%d&tls=%s\",\n\t\tparam.User, param.Password, hostPort,\n\t\tparam.SQLMode, param.MaxAllowedPacket, param.TLS)\n\n\tfor k, v := range param.Vars {\n\t\tdsn += fmt.Sprintf(\"&%s='%s'\", k, url.QueryEscape(v))\n\t}\n\n\treturn dsn\n}", "is_vulnerable": 1}
{"code": "func (m Map) Copy() Map {\n\tcopied := Map{}\n\tfor k, v := range m {\n\t\tcopied[k] = v\n\t}\n\treturn copied\n}", "is_vulnerable": 0}
{"code": "func (d *DescriptionEntityManager) ListDescriptionEntity(ctx context.Context, request admin.DescriptionEntityListRequest) (*admin.DescriptionEntityList, error) {\n\t// Check required fields\n\tif err := validation.ValidateDescriptionEntityListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\tif request.ResourceType == core.ResourceType_WORKFLOW {\n\t\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\t} else {\n\t\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\t}\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.ResourceTypeToEntity[request.ResourceType])\n\tif err != nil {\n\t\tlogger.Error(ctx, \"failed to get database filter\")\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistDescriptionEntitiesInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := d.db.DescriptionEntityRepo().List(ctx, listDescriptionEntitiesInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tdescriptionEntityList, err := transformers.FromDescriptionEntityModels(output.Entities)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Entities, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\treturn &admin.DescriptionEntityList{\n\t\tDescriptionEntities: descriptionEntityList,\n\t\tToken:               token,\n\t}, nil\n}", "is_vulnerable": 1}
{"code": "func (args *FilterCriteria) UnmarshalJSON(data []byte) error {\n\ttype input struct {\n\t\tBlockHash *common.Hash     `json:\"blockHash\"`\n\t\tFromBlock *rpc.BlockNumber `json:\"fromBlock\"`\n\t\tToBlock   *rpc.BlockNumber `json:\"toBlock\"`\n\t\tAddresses interface{}      `json:\"address\"`\n\t\tTopics    []interface{}    `json:\"topics\"`\n\t}\n\n\tvar raw input\n\tif err := json.Unmarshal(data, &raw); err != nil {\n\t\treturn err\n\t}\n\n\tif raw.BlockHash != nil {\n\t\tif raw.FromBlock != nil || raw.ToBlock != nil {\n\t\t\t// BlockHash is mutually exclusive with FromBlock/ToBlock criteria\n\t\t\treturn errors.New(\"cannot specify both BlockHash and FromBlock/ToBlock, choose one or the other\")\n\t\t}\n\t\targs.BlockHash = raw.BlockHash\n\t} else {\n\t\tif raw.FromBlock != nil {\n\t\t\targs.FromBlock = big.NewInt(raw.FromBlock.Int64())\n\t\t}\n\n\t\tif raw.ToBlock != nil {\n\t\t\targs.ToBlock = big.NewInt(raw.ToBlock.Int64())\n\t\t}\n\t}\n\n\targs.Addresses = []common.Address{}\n\n\tif raw.Addresses != nil {\n\t\t// raw.Address can contain a single address or an array of addresses\n\t\tswitch rawAddr := raw.Addresses.(type) {\n\t\tcase []interface{}:\n\t\t\tfor i, addr := range rawAddr {\n\t\t\t\tif strAddr, ok := addr.(string); ok {\n\t\t\t\t\taddr, err := decodeAddress(strAddr)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid address at index %d: %v\", i, err)\n\t\t\t\t\t}\n\t\t\t\t\targs.Addresses = append(args.Addresses, addr)\n\t\t\t\t} else {\n\t\t\t\t\treturn fmt.Errorf(\"non-string address at index %d\", i)\n\t\t\t\t}\n\t\t\t}\n\t\tcase string:\n\t\t\taddr, err := decodeAddress(rawAddr)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"invalid address: %v\", err)\n\t\t\t}\n\t\t\targs.Addresses = []common.Address{addr}\n\t\tdefault:\n\t\t\treturn errors.New(\"invalid addresses in query\")\n\t\t}\n\t}\n\tif len(raw.Topics) > maxTopics {\n\t\treturn errExceedMaxTopics\n\t}\n\n\t// topics is an array consisting of strings and/or arrays of strings.\n\t// JSON null values are converted to common.Hash{} and ignored by the filter manager.\n\tif len(raw.Topics) > 0 {\n\t\targs.Topics = make([][]common.Hash, len(raw.Topics))\n\t\tfor i, t := range raw.Topics {\n\t\t\tswitch topic := t.(type) {\n\t\t\tcase nil:\n\t\t\t\t// ignore topic when matching logs\n\n\t\t\tcase string:\n\t\t\t\t// match specific topic\n\t\t\t\ttop, err := decodeTopic(topic)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\targs.Topics[i] = []common.Hash{top}\n\n\t\t\tcase []interface{}:\n\t\t\t\t// or case e.g. [null, \"topic0\", \"topic1\"]\n\t\t\t\tif len(topic) > maxSubTopics {\n\t\t\t\t\treturn errExceedMaxTopics\n\t\t\t\t}\n\t\t\t\tfor _, rawTopic := range topic {\n\t\t\t\t\tif rawTopic == nil {\n\t\t\t\t\t\t// null component, match all\n\t\t\t\t\t\targs.Topics[i] = nil\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t\tif topic, ok := rawTopic.(string); ok {\n\t\t\t\t\t\tparsed, err := decodeTopic(topic)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t\targs.Topics[i] = append(args.Topics[i], parsed)\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn errInvalidTopic\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn errInvalidTopic\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestGetBlobsPath(t *testing.T) {\n\t// GetBlobsPath expects an actual directory to exist\n\tdir, err := os.MkdirTemp(\"\", \"ollama-test\")\n\tassert.Nil(t, err)\n\tdefer os.RemoveAll(dir)\n\n\ttests := []struct {\n\t\tname     string\n\t\tdigest   string\n\t\texpected string\n\t\terr      error\n\t}{\n\t\t{\n\t\t\t\"empty digest\",\n\t\t\t\"\",\n\t\t\tfilepath.Join(dir, \"blobs\"),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"valid with colon\",\n\t\t\t\"sha256:456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7aad9\",\n\t\t\tfilepath.Join(dir, \"blobs\", \"sha256-456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7aad9\"),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"valid with dash\",\n\t\t\t\"sha256-456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7aad9\",\n\t\t\tfilepath.Join(dir, \"blobs\", \"sha256-456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7aad9\"),\n\t\t\tnil,\n\t\t},\n\t\t{\n\t\t\t\"digest too short\",\n\t\t\t\"sha256-45640291\",\n\t\t\t\"\",\n\t\t\tErrInvalidDigestFormat,\n\t\t},\n\t\t{\n\t\t\t\"digest too long\",\n\t\t\t\"sha256-456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7aad9aaaaaaaaaa\",\n\t\t\t\"\",\n\t\t\tErrInvalidDigestFormat,\n\t\t},\n\t\t{\n\t\t\t\"digest invalid chars\",\n\t\t\t\"../sha256-456402914e838a953e0cf80caa6adbe75383d9e63584a964f504a7bbb8f7a\",\n\t\t\t\"\",\n\t\t\tErrInvalidDigestFormat,\n\t\t},\n\t}\n\tfor _, tc := range tests {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tt.Setenv(\"OLLAMA_MODELS\", dir)\n\n\t\t\tgot, err := GetBlobsPath(tc.digest)\n\n\t\t\tassert.ErrorIs(t, tc.err, err, tc.name)\n\t\t\tassert.Equal(t, tc.expected, got, tc.name)\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func handleNodeFromMetaManager(content []byte) (*api.Node, error) {\n\tvar node *api.Node\n\terr := json.Unmarshal(content, &node)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unmarshal message to node failed, err: %v\", err)\n\t}\n\treturn node, nil\n}", "is_vulnerable": 1}
{"code": "func (c *nativeHelmChart) GetIndex(noCache bool) (*Index, error) {", "is_vulnerable": 1}
{"code": "func (g *rfc4122Generator) getHardwareAddr() ([]byte, error) {\n\tvar err error\n\tg.hardwareAddrOnce.Do(func() {\n\t\tif hwAddr, err := g.hwAddrFunc(); err == nil {\n\t\t\tcopy(g.hardwareAddr[:], hwAddr)\n\t\t\treturn\n\t\t}\n\n\t\t// Initialize hardwareAddr randomly in case\n\t\t// of real network interfaces absence.\n\t\tif _, err = g.rand.Read(g.hardwareAddr[:]); err != nil {\n\t\t\treturn\n\t\t}\n\t\t// Set multicast bit as recommended by RFC 4122\n\t\tg.hardwareAddr[0] |= 0x01\n\t})\n\tif err != nil {\n\t\treturn []byte{}, err\n\t}\n\treturn g.hardwareAddr[:], nil\n}", "is_vulnerable": 1}
{"code": "func Test_DeleteExecutionsWorkflow_ManyExecutions_ContinueAsNew(t *testing.T) {\n\ttestSuite := &testsuite.WorkflowTestSuite{}\n\tenv := testSuite.NewTestWorkflowEnvironment()\n\n\tvar a *Activities\n\n\tenv.OnActivity(a.GetNextPageTokenActivity, mock.Anything, mock.Anything).Return([]byte{3, 22, 83}, nil).Times(78)\n\tenv.OnActivity(a.DeleteExecutionsActivity, mock.Anything, mock.Anything).Return(DeleteExecutionsActivityResult{SuccessCount: 1, ErrorCount: 0}, nil).Times(78)\n\n\tenv.ExecuteWorkflow(DeleteExecutionsWorkflow, DeleteExecutionsParams{\n\t\tNamespaceID: \"namespace-id\",\n\t\tNamespace:   \"namespace\",\n\t\tConfig: DeleteExecutionsConfig{\n\t\t\tPageSize:          3,\n\t\t\tPagesPerExecution: 78,\n\t\t},\n\t})\n\n\trequire.True(t, env.IsWorkflowCompleted())\n\twfErr := env.GetWorkflowError()\n\trequire.Error(t, wfErr)\n\tvar errContinueAsNew *workflow.ContinueAsNewError\n\trequire.ErrorAs(t, wfErr, &errContinueAsNew)\n\n\trequire.NotNil(t, errContinueAsNew.Input)\n\tvar newWfParams DeleteExecutionsParams\n\terr := payloads.Decode(errContinueAsNew.Input, &newWfParams)\n\trequire.NoError(t, err)\n\trequire.Equal(t, 78, newWfParams.PreviousSuccessCount)\n\trequire.Equal(t, 0, newWfParams.PreviousErrorCount)\n\trequire.Equal(t, []byte{3, 22, 83}, newWfParams.NextPageToken)\n}", "is_vulnerable": 0}
{"code": "func TestFieldProfileDefaultSeccomp(t *testing.T) {\n\ttests := []struct {\n\t\tdescription     string\n\t\tscmpProfile     *v1.SeccompProfile\n\t\trootPath        string\n\t\texpectedProfile string\n\t}{\n\t\t{\n\t\t\tdescription:     \"no seccompProfile should return runtime/default\",\n\t\t\texpectedProfile: v1.SeccompProfileRuntimeDefault,\n\t\t},\n\t\t{\n\t\t\tdescription: \"type localhost without profile should return runtime/default\",\n\t\t\tscmpProfile: &v1.SeccompProfile{\n\t\t\t\tType: v1.SeccompProfileTypeLocalhost,\n\t\t\t},\n\t\t\texpectedProfile: v1.SeccompProfileRuntimeDefault,\n\t\t},\n\t\t{\n\t\t\tdescription: \"unknown type should return runtime/default\",\n\t\t\tscmpProfile: &v1.SeccompProfile{\n\t\t\t\tType: \"\",\n\t\t\t},\n\t\t\texpectedProfile: v1.SeccompProfileRuntimeDefault,\n\t\t},\n\t\t{\n\t\t\tdescription: \"SeccompProfileTypeRuntimeDefault should return runtime/default\",\n\t\t\tscmpProfile: &v1.SeccompProfile{\n\t\t\t\tType: v1.SeccompProfileTypeRuntimeDefault,\n\t\t\t},\n\t\t\texpectedProfile: \"runtime/default\",\n\t\t},\n\t\t{\n\t\t\tdescription: \"SeccompProfileTypeUnconfined should return unconfined\",\n\t\t\tscmpProfile: &v1.SeccompProfile{\n\t\t\t\tType: v1.SeccompProfileTypeUnconfined,\n\t\t\t},\n\t\t\texpectedProfile: \"unconfined\",\n\t\t},\n\t\t{\n\t\t\tdescription: \"SeccompProfileTypeLocalhost should return localhost\",\n\t\t\tscmpProfile: &v1.SeccompProfile{\n\t\t\t\tType:             v1.SeccompProfileTypeLocalhost,\n\t\t\t\tLocalhostProfile: utilpointer.StringPtr(\"profile.json\"),\n\t\t\t},\n\t\t\trootPath:        \"/test/\",\n\t\t\texpectedProfile: \"localhost//test/profile.json\",\n\t\t},\n\t}\n\n\tfor i, test := range tests {\n\t\tseccompProfile := fieldProfile(test.scmpProfile, test.rootPath, true)\n\t\tassert.Equal(t, test.expectedProfile, seccompProfile, \"TestCase[%d]: %s\", i, test.description)\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestNormalizeNoMatchedGroupKinds(t *testing.T) {\n\tnormalizer, err := NewIgnoreNormalizer([]v1alpha1.ResourceIgnoreDifferences{{\n\t\tGroup:        \"\",\n\t\tKind:         \"Service\",\n\t\tJSONPointers: []string{\"/spec\"},\n\t}}, make(map[string]v1alpha1.ResourceOverride), IgnoreNormalizerOpts{})\n\n\tassert.Nil(t, err)\n\n\tdeployment := test.NewDeployment()\n\n\terr = normalizer.Normalize(deployment)\n\tassert.Nil(t, err)\n\n\t_, hasSpec, err := unstructured.NestedMap(deployment.Object, \"spec\")\n\tassert.Nil(t, err)\n\tassert.True(t, hasSpec)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CloseTunnel(ctx context.Context, in *sliverpb.Tunnel, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_CloseTunnel_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (hs *HTTPServer) checkDatasourceHealth(c *models.ReqContext, ds *datasources.DataSource) response.Response {\n\tplugin, exists := hs.pluginStore.Plugin(c.Req.Context(), ds.Type)\n\tif !exists {\n\t\treturn response.Error(http.StatusInternalServerError, \"Unable to find datasource plugin\", nil)\n\t}\n\n\tdsInstanceSettings, err := adapters.ModelToInstanceSettings(ds, hs.decryptSecureJsonDataFn(c.Req.Context()))\n\tif err != nil {\n\t\treturn response.Error(http.StatusInternalServerError, \"Unable to get datasource model\", err)\n\t}\n\treq := &backend.CheckHealthRequest{\n\t\tPluginContext: backend.PluginContext{\n\t\t\tUser:                       adapters.BackendUserFromSignedInUser(c.SignedInUser),\n\t\t\tOrgID:                      c.OrgId,\n\t\t\tPluginID:                   plugin.ID,\n\t\t\tDataSourceInstanceSettings: dsInstanceSettings,\n\t\t},\n\t\tHeaders: map[string]string{},\n\t}\n\n\tvar dsURL string\n\tif req.PluginContext.DataSourceInstanceSettings != nil {\n\t\tdsURL = req.PluginContext.DataSourceInstanceSettings.URL\n\t}\n\n\terr = hs.PluginRequestValidator.Validate(dsURL, c.Req)\n\tif err != nil {\n\t\treturn response.Error(http.StatusForbidden, \"Access denied\", err)\n\t}\n\n\tif hs.DataProxy.OAuthTokenService.IsOAuthPassThruEnabled(ds) {\n\t\tif token := hs.DataProxy.OAuthTokenService.GetCurrentOAuthToken(c.Req.Context(), c.SignedInUser); token != nil {\n\t\t\treq.Headers[\"Authorization\"] = fmt.Sprintf(\"%s %s\", token.Type(), token.AccessToken)\n\t\t\tidToken, ok := token.Extra(\"id_token\").(string)\n\t\t\tif ok && idToken != \"\" {\n\t\t\t\treq.Headers[\"X-ID-Token\"] = idToken\n\t\t\t}\n\t\t}\n\t}\n\n\tproxyutil.ClearCookieHeader(c.Req, ds.AllowedCookies())\n\tif cookieStr := c.Req.Header.Get(\"Cookie\"); cookieStr != \"\" {\n\t\treq.Headers[\"Cookie\"] = cookieStr\n\t}\n\n\tresp, err := hs.pluginClient.CheckHealth(c.Req.Context(), req)\n\tif err != nil {\n\t\treturn translatePluginRequestErrorToAPIError(err)\n\t}\n\n\tpayload := map[string]interface{}{\n\t\t\"status\":  resp.Status.String(),\n\t\t\"message\": resp.Message,\n\t}\n\n\t// Unmarshal JSONDetails if it's not empty.\n\tif len(resp.JSONDetails) > 0 {\n\t\tvar jsonDetails map[string]interface{}\n\t\terr = json.Unmarshal(resp.JSONDetails, &jsonDetails)\n\t\tif err != nil {\n\t\t\treturn response.Error(http.StatusInternalServerError, \"Failed to unmarshal detailed response from backend plugin\", err)\n\t\t}\n\n\t\tpayload[\"details\"] = jsonDetails\n\t}\n\n\tif resp.Status != backend.HealthStatusOk {\n\t\treturn response.JSON(http.StatusBadRequest, payload)\n\t}\n\n\treturn response.JSON(http.StatusOK, payload)\n}", "is_vulnerable": 1}
{"code": "func TestFilesystem_Delete(t *testing.T) {\n\tg := Goblin(t)\n\tfs, rfs := NewFs()\n\n\tg.Describe(\"Delete\", func() {\n\t\tg.BeforeEach(func() {\n\t\t\tif err := rfs.CreateServerFileFromString(\"source.txt\", \"test content\"); err != nil {\n\t\t\t\tpanic(err)\n\t\t\t}\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, int64(utf8.RuneCountInString(\"test content\")))\n\t\t})\n\n\t\tg.It(\"does not delete files outside the root directory\", func() {\n\t\t\terr := rfs.CreateServerFileFromString(\"/../ext-source.txt\", \"external content\")\n\n\t\t\terr = fs.Delete(\"../ext-source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.It(\"does not allow the deletion of the root directory\", func() {\n\t\t\terr := fs.Delete(\"/\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(err.Error()).Equal(\"cannot delete root server directory\")\n\t\t})\n\n\t\tg.It(\"does not return an error if the target does not exist\", func() {\n\t\t\terr := fs.Delete(\"missing.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tst, err := rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(st.Name()).Equal(\"source.txt\")\n\t\t})\n\n\t\tg.It(\"deletes files and subtracts their size from the disk usage\", func() {\n\t\t\terr := fs.Delete(\"source.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t_, err = rfs.StatServerFile(\"source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(errors.Is(err, os.ErrNotExist)).IsTrue()\n\n\t\t\tg.Assert(atomic.LoadInt64(&fs.diskUsed)).Equal(int64(0))\n\t\t})\n\n\t\tg.It(\"deletes all items inside a directory if the directory is deleted\", func() {\n\t\t\tsources := []string{\n\t\t\t\t\"foo/source.txt\",\n\t\t\t\t\"foo/bar/source.txt\",\n\t\t\t\t\"foo/bar/baz/source.txt\",\n\t\t\t}\n\n\t\t\terr := os.MkdirAll(filepath.Join(rfs.root, \"/server/foo/bar/baz\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\tfor _, s := range sources {\n\t\t\t\terr = rfs.CreateServerFileFromString(s, \"test content\")\n\t\t\t\tg.Assert(err).IsNil()\n\t\t\t}\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, int64(utf8.RuneCountInString(\"test content\")*3))\n\n\t\t\terr = fs.Delete(\"foo\")\n\t\t\tg.Assert(err).IsNil()\n\t\t\tg.Assert(atomic.LoadInt64(&fs.diskUsed)).Equal(int64(0))\n\n\t\t\tfor _, s := range sources {\n\t\t\t\t_, err = rfs.StatServerFile(s)\n\t\t\t\tg.Assert(err).IsNotNil()\n\t\t\t\tg.Assert(errors.Is(err, os.ErrNotExist)).IsTrue()\n\t\t\t}\n\t\t})\n\n\t\tg.It(\"deletes a symlink but not it's target within the root directory\", func() {\n\t\t\t// Symlink to a file inside the root directory.\n\t\t\terr := os.Symlink(filepath.Join(rfs.root, \"server/source.txt\"), filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink itself.\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the symlink was deleted.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNotNil()\n\n\t\t\t// Ensure the symlink target still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"server/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked outside of the root directory\", func() {\n\t\t\t// Create a file outside the root directory.\n\t\t\terr := rfs.CreateServerFileFromString(\"/../source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a symlink to the file outside the root directory.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"source.txt\"), filepath.Join(rfs.root, \"/server/symlink.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete the symlink. (This should pass as we will delete the symlink itself, not it's target)\n\t\t\terr = fs.Delete(\"symlink.txt\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"does not delete files symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Create a file inside the directory that is outside the root.\n\t\t\terr = rfs.CreateServerFileFromString(\"/../foo/source.txt\", \"test content\")\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\n\t\t\t// Ensure the file outside the root directory still exists.\n\t\t\t_, err = os.Lstat(filepath.Join(rfs.root, \"foo/source.txt\"))\n\t\t\tg.Assert(err).IsNil()\n\t\t})\n\n\t\tg.It(\"returns an error when trying to delete a non-existent file symlinked through a directory outside of the root directory\", func() {\n\t\t\t// Create a directory outside the root directory.\n\t\t\terr := os.Mkdir(filepath.Join(rfs.root, \"foo2\"), 0o755)\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Symlink the directory that is outside the root to a file inside the root.\n\t\t\terr = os.Symlink(filepath.Join(rfs.root, \"foo2\"), filepath.Join(rfs.root, \"server/symlink\"))\n\t\t\tg.Assert(err).IsNil()\n\n\t\t\t// Delete a file inside the symlinked directory.\n\t\t\terr = fs.Delete(\"symlink/source.txt\")\n\t\t\tg.Assert(err).IsNotNil()\n\t\t\tg.Assert(IsErrorCode(err, ErrCodePathResolution)).IsTrue()\n\t\t})\n\n\t\tg.AfterEach(func() {\n\t\t\trfs.reset()\n\n\t\t\tatomic.StoreInt64(&fs.diskUsed, 0)\n\t\t\tatomic.StoreInt64(&fs.diskLimit, 0)\n\t\t})\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) CloseSocks(ctx context.Context, in *sliverpb.Socks, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/CloseSocks\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func init() {\n\tRegisterJwa(NewPbse2HmacAesKWAlg(128, 310000, 0))\n\tRegisterJwa(NewPbse2HmacAesKWAlg(192, 250000, 0))\n\tRegisterJwa(NewPbse2HmacAesKWAlg(256, 120000, 0))\n}", "is_vulnerable": 0}
{"code": "func CreateMigrationBlob(rw io.ReadWriter, srkAuth Digest, migrationAuth Digest, keyBlob []byte, migrationKeyBlob []byte) ([]byte, error) {\n\t// Run OSAP for the SRK, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a handle.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etSRK, khSRK, srkAuth[:])\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\t// The createMigrationBlob command needs an OIAP session in addition to the\n\t// OSAP session.\n\toiapr, err := oiap(rw)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer oiapr.Close(rw)\n\n\tencData := tpmutil.U32Bytes(keyBlob)\n\n\t// The digest for auth1 and auth2 for the createMigrationBlob command is\n\t// SHA1(ordCreateMigrationBlob || migrationScheme || migrationKeyBlob || encData)\n\tauthIn := []interface{}{ordCreateMigrationBlob, msRewrap, migrationKeyBlob, encData}\n\n\t// The first commandAuth uses the shared secret as an HMAC key.\n\tca1, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, nil, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The second commandAuth is based on OIAP instead of OSAP and uses the\n\t// migration auth as the HMAC key.\n\tca2, err := newCommandAuth(oiapr.AuthHandle, oiapr.NonceEven, nil, migrationAuth[:], authIn)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, outData, _, _, _, err := createMigrationBlob(rw, khSRK, msRewrap, migrationKeyBlob, encData, ca1, ca2)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// For now, ignore the response authenticatino.\n\treturn outData, nil\n}", "is_vulnerable": 0}
{"code": "func (z *ZipArchive) Open(name string, flag int, perm os.FileMode) error {\n\t// Create a new archive if it's specified and not exist.\n\tif flag&os.O_CREATE != 0 {\n\t\tf, err := os.Create(name)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tzw := zip.NewWriter(f)\n\t\tif err = zw.Close(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\trc, err := zip.OpenReader(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tz.ReadCloser = rc\n\tz.FileName = name\n\tz.Comment = rc.Comment\n\tz.NumFiles = len(rc.File)\n\tz.Flag = flag\n\tz.Permission = perm\n\tz.isHasChanged = false\n\n\tz.files = make([]*File, z.NumFiles)\n\tfor i, f := range rc.File {\n\t\tz.files[i] = &File{}\n\t\tz.files[i].FileHeader, err = zip.FileInfoHeader(f.FileInfo())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tz.files[i].Name = strings.Replace(f.Name, \"\\\\\", \"/\", -1)\n\t\tif f.FileInfo().IsDir() && !strings.HasSuffix(z.files[i].Name, \"/\") {\n\t\t\tz.files[i].Name += \"/\"\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestParse(t *testing.T) {\n\tannotation := parser.GetAnnotationWithPrefix(\"configuration-snippet\")\n\n\tap := NewParser(&resolver.Mock{})\n\tif ap == nil {\n\t\tt.Fatalf(\"expected a parser.IngressAnnotation but returned nil\")\n\t}\n\n\ttestCases := []struct {\n\t\tannotations map[string]string\n\t\texpected    string\n\t}{\n\t\t{map[string]string{annotation: \"more_headers\"}, \"more_headers\"},\n\t\t{map[string]string{annotation: \"false\"}, \"false\"},\n\t\t{map[string]string{}, \"\"},\n\t\t{nil, \"\"},\n\t}\n\n\ting := &networking.Ingress{\n\t\tObjectMeta: meta_v1.ObjectMeta{\n\t\t\tName:      \"foo\",\n\t\t\tNamespace: api.NamespaceDefault,\n\t\t},\n\t\tSpec: networking.IngressSpec{},\n\t}\n\n\tfor _, testCase := range testCases {\n\t\ting.SetAnnotations(testCase.annotations)\n\t\tresult, _ := ap.Parse(ing)\n\t\tif result != testCase.expected {\n\t\t\tt.Errorf(\"expected %v but returned %v, annotations: %s\", testCase.expected, result, testCase.annotations)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (src *Close) Encode(dst []byte) []byte {\n\tdst = append(dst, 'C')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\n\tdst = append(dst, src.ObjectType)\n\tdst = append(dst, src.Name...)\n\tdst = append(dst, 0)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func (k msgServer) CreateValidator(goCtx context.Context, msg *types.MsgCreateValidator) (*types.MsgCreateValidatorResponse, error) {\n\tif err := k.validateDelegationAmountNotUnvested(goCtx, msg.DelegatorAddress, msg.Value.Amount); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn k.MsgServer.CreateValidator(goCtx, msg)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) TrafficEncoderRm(ctx context.Context, in *clientpb.TrafficEncoder, opts ...grpc.CallOption) (*commonpb.Empty, error) {\n\tout := new(commonpb.Empty)\n\terr := c.cc.Invoke(ctx, SliverRPC_TrafficEncoderRm_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (s *validateSuite) TestValidateContainerSymlinksOK(c *C) {\n\tconst yaml = `name: empty-snap\nversion: 1\napps:\n foo:\n  command: foo\n`\n\td := emptyContainer(c)\n\tfn := filepath.Join(d.Path(), \"foo\")\n\tc.Assert(os.WriteFile(fn+\".real\", nil, 0555), IsNil)\n\tc.Assert(os.Symlink(fn+\".real\", fn), IsNil)\n\n\t// snapdir contains a command that's a symlink to a file that's world-rx\n\n\tinfo, err := snap.InfoFromSnapYaml([]byte(yaml))\n\tc.Assert(err, IsNil)\n\n\terr = snap.ValidateSnapContainer(d, info, discard)\n\tc.Check(err, IsNil)\n}", "is_vulnerable": 1}
{"code": "func TestShortestPathToSolutionWins(t *testing.T) {\n\tctx := context.Background()\n\n\tstoreID := ulid.Make().String()\n\tmodelID := ulid.Make().String()\n\n\ttypedefs := parser.MustParse(`\n\ttype user\n\n\ttype repo\n\t  relations\n\t    define reader: [user:*] as self\n\t`)\n\n\ttk := tuple.NewTupleKey(\"repo:openfga\", \"reader\", \"user:*\")\n\ttuple := &openfgapb.Tuple{Key: tk}\n\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tmockDatastore := mockstorage.NewMockOpenFGADatastore(mockController)\n\n\tmockDatastore.EXPECT().\n\t\tReadAuthorizationModel(gomock.Any(), storeID, modelID).\n\t\tAnyTimes().\n\t\tReturn(&openfgapb.AuthorizationModel{\n\t\t\tSchemaVersion:   typesystem.SchemaVersion1_1,\n\t\t\tTypeDefinitions: typedefs,\n\t\t}, nil)\n\n\t// it could happen that one of the following two mocks won't be necessary because the goroutine will be short-circuited\n\tmockDatastore.EXPECT().\n\t\tReadUserTuple(gomock.Any(), storeID, gomock.Any()).\n\t\tAnyTimes().\n\t\tDoAndReturn(\n\t\t\tfunc(ctx context.Context, _ string, _ *openfgapb.TupleKey) (storage.TupleIterator, error) {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\treturn nil, ctx.Err()\n\t\t\t\tcase <-time.After(500 * time.Millisecond):\n\t\t\t\t\treturn nil, storage.ErrNotFound\n\t\t\t\t}\n\t\t\t})\n\n\tmockDatastore.EXPECT().\n\t\tReadUsersetTuples(gomock.Any(), storeID, gomock.Any()).\n\t\tAnyTimes().\n\t\tDoAndReturn(\n\t\t\tfunc(_ context.Context, _ string, _ storage.ReadUsersetTuplesFilter) (storage.TupleIterator, error) {\n\t\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t\t\treturn storage.NewStaticTupleIterator([]*openfgapb.Tuple{tuple}), nil\n\t\t\t})\n\n\ts := New(&Dependencies{\n\t\tDatastore: mockDatastore,\n\t\tLogger:    logger.NewNoopLogger(),\n\t\tTransport: gateway.NewNoopTransport(),\n\t}, &Config{\n\t\tResolveNodeLimit: 25,\n\t})\n\n\tstart := time.Now()\n\tcheckResponse, err := s.Check(ctx, &openfgapb.CheckRequest{\n\t\tStoreId:              storeID,\n\t\tTupleKey:             tk,\n\t\tAuthorizationModelId: modelID,\n\t})\n\tend := time.Since(start)\n\n\t// we expect the Check call to be short-circuited after ReadUsersetTuples runs\n\trequire.Truef(t, end < 200*time.Millisecond, fmt.Sprintf(\"end was %s\", end))\n\trequire.NoError(t, err)\n\trequire.Equal(t, true, checkResponse.Allowed)\n}", "is_vulnerable": 1}
{"code": "func GetDirUnprivileged(name string, subDir string) (string, error) {\n\treturn getDir(false, name, subDir)\n}", "is_vulnerable": 1}
{"code": "func NewWithBaseURI(baseURI string, subscriptionID string) BaseClient {\n\treturn original.NewWithBaseURI(baseURI, subscriptionID)\n}", "is_vulnerable": 0}
{"code": "func generateSigningContent() (ocispec.Descriptor, notation.SignOptions) {\n\tcontent := \"hello world\"\n\tdesc := ocispec.Descriptor{\n\t\tMediaType: \"test media type\",\n\t\tDigest:    digest.Canonical.FromString(content),\n\t\tSize:      int64(len(content)),\n\t\tAnnotations: map[string]string{\n\t\t\t\"identity\": \"test.registry.io/test:example\",\n\t\t\t\"foo\":      \"bar\",\n\t\t},\n\t}\n\tsOpts := notation.SignOptions{ExpiryDuration: 24 * time.Hour}\n\n\treturn desc, sOpts\n}", "is_vulnerable": 0}
{"code": "func (crs *checkingResourceStream) publishResourcesIfPossible() error {\n\tfor {\n\t\ttoPublish := crs.rq.resourcesToPossiblyPublish()\n\t\tif len(toPublish) == 0 {\n\t\t\treturn nil\n\t\t}\n\n\t\tfor {\n\t\t\tif len(toPublish) == 0 {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Sort to ensure they are in the publishable order.\n\t\t\tsort.Sort(byOrderingIndex(toPublish))\n\n\t\t\t// Ensure that the next resource to be published is the next in the order. If not,\n\t\t\t// we're still waiting on a resource to be checked.\n\t\t\tcurrent := toPublish[0]\n\t\t\tif current.orderingIndex != crs.orderingIndexToBePublished {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\ttoPublish = toPublish[1:]\n\t\t\tcrs.orderingIndexToBePublished++\n\n\t\t\t// NOTE: lookupResult will be `nil` if the Check for the resource found that the resource is\n\t\t\t// not actually accessible. The entry is kept in `toPublish` to ensure proper ordering is maintained\n\t\t\t// on the parent stream.\n\t\t\tif current.lookupResult != nil {\n\t\t\t\tok, done := crs.limits.prepareForPublishing()\n\t\t\t\tdefer done()\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\terr := crs.parentStream.Publish(current.lookupResult)\n\t\t\t\tif err != nil {\n\t\t\t\t\tcrs.setError(err)\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcrs.rq.markResourceCompleted(current)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *sliverRPCClient) WGStartSocks(ctx context.Context, in *sliverpb.WGSocksStartReq, opts ...grpc.CallOption) (*sliverpb.WGSocks, error) {\n\tout := new(sliverpb.WGSocks)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/WGStartSocks\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func run(cmd *cobra.Command, args []string) error {\n\tvar err error\n\tcliVals.Net, err = common.NetFlagsToNetOptions(cmd, cliVals.Pod == \"\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// TODO: Breaking change should be made fatal in next major Release\n\tif cliVals.TTY && cliVals.Interactive && !terminal.IsTerminal(int(os.Stdin.Fd())) {\n\t\tlogrus.Warnf(\"The input device is not a TTY. The --tty and --interactive flags might not work properly\")\n\t}\n\n\tif af := cliVals.Authfile; len(af) > 0 {\n\t\tif _, err := os.Stat(af); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\trunOpts.CIDFile = cliVals.CIDFile\n\trunOpts.Rm = cliVals.Rm\n\tif err := createInit(cmd); err != nil {\n\t\treturn err\n\t}\n\tfor fd := 3; fd < int(3+runOpts.PreserveFDs); fd++ {\n\t\tif !rootless.IsFdInherited(fd) {\n\t\t\treturn errors.Errorf(\"file descriptor %d is not available - the preserve-fds option requires that file descriptors must be passed\", fd)\n\t\t}\n\t}\n\n\timageName := args[0]\n\trawImageName := \"\"\n\tif !cliVals.RootFS {\n\t\trawImageName = args[0]\n\t\tname, err := pullImage(args[0])\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\timageName = name\n\t}\n\n\tif cliVals.Replace {\n\t\tif err := replaceContainer(cliVals.Name); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// If -i is not set, clear stdin\n\tif !cliVals.Interactive {\n\t\trunOpts.InputStream = nil\n\t}\n\n\t// If attach is set, clear stdin/stdout/stderr and only attach requested\n\tif cmd.Flag(\"attach\").Changed {\n\t\trunOpts.OutputStream = nil\n\t\trunOpts.ErrorStream = nil\n\t\tif !cliVals.Interactive {\n\t\t\trunOpts.InputStream = nil\n\t\t}\n\n\t\tfor _, stream := range cliVals.Attach {\n\t\t\tswitch strings.ToLower(stream) {\n\t\t\tcase \"stdout\":\n\t\t\t\trunOpts.OutputStream = os.Stdout\n\t\t\tcase \"stderr\":\n\t\t\t\trunOpts.ErrorStream = os.Stderr\n\t\t\tcase \"stdin\":\n\t\t\t\trunOpts.InputStream = os.Stdin\n\t\t\tdefault:\n\t\t\t\treturn errors.Wrapf(define.ErrInvalidArg, \"invalid stream %q for --attach - must be one of stdin, stdout, or stderr\", stream)\n\t\t\t}\n\t\t}\n\t}\n\tcliVals.PreserveFDs = runOpts.PreserveFDs\n\ts := specgen.NewSpecGenerator(imageName, cliVals.RootFS)\n\tif err := common.FillOutSpecGen(s, &cliVals, args); err != nil {\n\t\treturn err\n\t}\n\ts.RawImageName = rawImageName\n\trunOpts.Spec = s\n\n\tif _, err := createPodIfNecessary(s, cliVals.Net); err != nil {\n\t\treturn err\n\t}\n\n\treport, err := registry.ContainerEngine().ContainerRun(registry.GetContext(), runOpts)\n\t// report.ExitCode is set by ContainerRun even it it returns an error\n\tif report != nil {\n\t\tregistry.SetExitCode(report.ExitCode)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif runOpts.Detach {\n\t\tfmt.Println(report.Id)\n\t\treturn nil\n\t}\n\tif runRmi {\n\t\t_, rmErrors := registry.ImageEngine().Remove(registry.GetContext(), []string{imageName}, entities.ImageRemoveOptions{})\n\t\tif len(rmErrors) > 0 {\n\t\t\tlogrus.Errorf(\"%s\", errorhandling.JoinErrors(rmErrors))\n\t\t}\n\t}\n\tif cmd.Flag(\"gpus\").Changed {\n\t\tlogrus.Info(\"--gpus is a Docker specific option and is a NOOP\")\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (b *Builder) buildControlPlanePathRoute(path string, protected bool) *envoy_config_route_v3.Route {\n\tr := &envoy_config_route_v3.Route{\n\t\tName: \"pomerium-path-\" + path,\n\t\tMatch: &envoy_config_route_v3.RouteMatch{\n\t\t\tPathSpecifier: &envoy_config_route_v3.RouteMatch_Path{Path: path},\n\t\t},\n\t\tAction: &envoy_config_route_v3.Route_Route{\n\t\t\tRoute: &envoy_config_route_v3.RouteAction{\n\t\t\t\tClusterSpecifier: &envoy_config_route_v3.RouteAction_Cluster{\n\t\t\t\t\tCluster: httpCluster,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tif !protected {\n\t\tr.TypedPerFilterConfig = map[string]*any.Any{\n\t\t\t\"envoy.filters.http.ext_authz\": disableExtAuthz,\n\t\t}\n\t}\n\treturn r\n}", "is_vulnerable": 0}
{"code": "func (r *Registrator) Certificate(ctx context.Context, in *securityapi.CertificateRequest) (resp *securityapi.CertificateResponse, err error) {\n\tremotePeer, ok := peer.FromContext(ctx)\n\tif !ok {\n\t\treturn nil, status.Error(codes.PermissionDenied, \"peer not found\")\n\t}\n\n\tosRoot, err := safe.StateGet[*secrets.OSRoot](ctx, r.Resources, resource.NewMetadata(secrets.NamespaceName, secrets.OSRootType, secrets.OSRootID, resource.VersionUndefined))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// decode and validate CSR\n\tcsrPemBlock, _ := pem.Decode(in.Csr)\n\tif csrPemBlock == nil {\n\t\treturn nil, status.Errorf(codes.InvalidArgument, \"failed to decode CSR\")\n\t}\n\n\trequest, err := stdx509.ParseCertificateRequest(csrPemBlock.Bytes)\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.InvalidArgument, \"failed to parse CSR: %s\", err)\n\t}\n\n\tlog.Printf(\"received CSR signing request from %s: subject %s dns names %s addresses %s\", remotePeer.Addr, request.Subject, request.DNSNames, request.IPAddresses)\n\n\t// allow only server auth certificates\n\tx509Opts := []x509.Option{\n\t\tx509.KeyUsage(stdx509.KeyUsageDigitalSignature),\n\t\tx509.ExtKeyUsage([]stdx509.ExtKeyUsage{stdx509.ExtKeyUsageServerAuth}),\n\t}\n\n\t// don't allow any certificates which can be used for client authentication\n\t//\n\t// we don't return an error here, as otherwise workers running old versions of Talos\n\t// will fail to provision client certificate and will never launch apid\n\t//\n\t// instead, the returned certificate will be rejected when being used\n\tif len(request.Subject.Organization) > 0 {\n\t\tlog.Printf(\"removing client auth organization from CSR: %s\", request.Subject.Organization)\n\n\t\tx509Opts = append(x509Opts, x509.OverrideSubject(func(subject *pkix.Name) {\n\t\t\tsubject.Organization = nil\n\t\t}))\n\t}\n\n\t// TODO: Verify that the request is coming from the IP address declared in\n\t// the CSR.\n\tsigned, err := x509.NewCertificateFromCSRBytes(\n\t\tosRoot.TypedSpec().CA.Crt,\n\t\tosRoot.TypedSpec().CA.Key,\n\t\tin.Csr,\n\t\tx509Opts...,\n\t)\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.Internal, \"failed to sign CSR: %s\", err)\n\t}\n\n\tresp = &securityapi.CertificateResponse{\n\t\tCa:  osRoot.TypedSpec().CA.Crt,\n\t\tCrt: signed.X509CertificatePEM,\n\t}\n\n\treturn resp, nil\n}", "is_vulnerable": 0}
{"code": "func (r *ACLResolver) fetchAndCacheIdentityFromToken(token string, cached *structs.IdentityCacheEntry) (structs.ACLIdentity, error) {\n\tcacheID := tokenSecretCacheID(token)\n\n\treq := structs.ACLTokenGetRequest{\n\t\tDatacenter:  r.delegate.ACLDatacenter(false),\n\t\tTokenID:     token,\n\t\tTokenIDType: structs.ACLTokenSecret,\n\t\tQueryOptions: structs.QueryOptions{\n\t\t\tToken:      token,\n\t\t\tAllowStale: true,\n\t\t},\n\t}\n\n\tvar resp structs.ACLTokenResponse\n\terr := r.delegate.RPC(\"ACL.TokenRead\", &req, &resp)\n\tif err == nil {\n\t\tif resp.Token == nil {\n\t\t\tr.cache.PutIdentity(cacheID, nil)\n\t\t\treturn nil, acl.ErrNotFound\n\t\t} else if resp.Token.Local && r.config.Datacenter != resp.SourceDatacenter {\n\t\t\tr.cache.PutIdentity(cacheID, nil)\n\t\t\treturn nil, acl.PermissionDeniedError{Cause: fmt.Sprintf(\"This is a local token in datacenter %q\", resp.SourceDatacenter)}\n\t\t} else {\n\t\t\tr.cache.PutIdentity(cacheID, resp.Token)\n\t\t\treturn resp.Token, nil\n\t\t}\n\t}\n\n\tif acl.IsErrNotFound(err) {\n\t\t// Make sure to remove from the cache if it was deleted\n\t\tr.cache.PutIdentity(cacheID, nil)\n\t\treturn nil, acl.ErrNotFound\n\n\t}\n\n\t// some other RPC error\n\tif cached != nil && (r.config.ACLDownPolicy == \"extend-cache\" || r.config.ACLDownPolicy == \"async-cache\") {\n\t\t// extend the cache\n\t\tr.cache.PutIdentity(cacheID, cached.Identity)\n\t\treturn cached.Identity, nil\n\t}\n\n\tr.cache.PutIdentity(cacheID, nil)\n\treturn nil, err\n}", "is_vulnerable": 0}
{"code": "\t\t\tmutate: func(svc *corev1.Service) {\n\t\t\t\tsvc.UID = \"2\"\n\t\t\t},", "is_vulnerable": 0}
{"code": "func TestRPC_RPCMaxConnsPerClient(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"too slow for testing.Short\")\n\t}\n\n\tt.Parallel()\n\n\tcases := []struct {\n\t\tname       string\n\t\tmagicByte  pool.RPCType\n\t\ttlsEnabled bool\n\t}{\n\t\t{\"RPC\", pool.RPCMultiplexV2, false},\n\t\t{\"RPC TLS\", pool.RPCMultiplexV2, true},\n\t\t{\"Raft\", pool.RPCRaft, false},\n\t\t{\"Raft TLS\", pool.RPCRaft, true},\n\t}\n\n\tfor _, tc := range cases {\n\t\ttc := tc\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdir1, s1 := testServerWithConfig(t, func(c *Config) {\n\t\t\t\tc.RPCMaxConnsPerClient = 2\n\t\t\t\tif tc.tlsEnabled {\n\t\t\t\t\tc.UseTLS = true\n\t\t\t\t\tc.CAFile = \"../../test/hostname/CertAuth.crt\"\n\t\t\t\t\tc.CertFile = \"../../test/hostname/Alice.crt\"\n\t\t\t\t\tc.KeyFile = \"../../test/hostname/Alice.key\"\n\t\t\t\t\tc.VerifyServerHostname = true\n\t\t\t\t\tc.VerifyOutgoing = true\n\t\t\t\t\tc.VerifyIncoming = false // saves us getting client cert setup\n\t\t\t\t\tc.Domain = \"consul\"\n\t\t\t\t}\n\t\t\t})\n\t\t\tdefer os.RemoveAll(dir1)\n\t\t\tdefer s1.Shutdown()\n\n\t\t\t// Connect to the server with bare TCP\n\t\t\tconn1 := connectClient(t, s1, tc.magicByte, tc.tlsEnabled, true, \"conn1\")\n\t\t\tdefer conn1.Close()\n\n\t\t\t// Two conns should succeed\n\t\t\tconn2 := connectClient(t, s1, tc.magicByte, tc.tlsEnabled, true, \"conn2\")\n\t\t\tdefer conn2.Close()\n\n\t\t\t// Third should be closed byt the limiter\n\t\t\tconn3 := connectClient(t, s1, tc.magicByte, tc.tlsEnabled, false, \"conn3\")\n\t\t\tdefer conn3.Close()\n\n\t\t\t// If we close one of the earlier ones, we should be able to open another\n\t\t\taddr := conn1.RemoteAddr()\n\t\t\tconn1.Close()\n\t\t\tretry.Run(t, func(r *retry.R) {\n\t\t\t\tif n := s1.rpcConnLimiter.NumOpen(addr); n >= 2 {\n\t\t\t\t\tr.Fatal(\"waiting for open conns to drop\")\n\t\t\t\t}\n\t\t\t})\n\t\t\tconn4 := connectClient(t, s1, tc.magicByte, tc.tlsEnabled, true, \"conn4\")\n\t\t\tdefer conn4.Close()\n\n\t\t\t// Reload config with higher limit\n\t\t\trc := ReloadableConfig{\n\t\t\t\tRPCRateLimit:         s1.config.RPCRateLimit,\n\t\t\t\tRPCMaxBurst:          s1.config.RPCMaxBurst,\n\t\t\t\tRPCMaxConnsPerClient: 10,\n\t\t\t}\n\t\t\trequire.NoError(t, s1.ReloadConfig(rc))\n\n\t\t\t// Now another conn should be allowed\n\t\t\tconn5 := connectClient(t, s1, tc.magicByte, tc.tlsEnabled, true, \"conn5\")\n\t\t\tdefer conn5.Close()\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestIsReqAuthenticated(t *testing.T) {\n\tpath, err := newTestConfig(globalMinioDefaultRegion)\n\tif err != nil {\n\t\tt.Fatalf(\"unable initialize config file, %s\", err)\n\t}\n\tdefer os.RemoveAll(path)\n\n\tcreds, err := auth.CreateCredentials(\"myuser\", \"mypassword\")\n\tif err != nil {\n\t\tt.Fatalf(\"unable create credential, %s\", err)\n\t}\n\n\tglobalServerConfig.SetCredential(creds)\n\n\t// List of test cases for validating http request authentication.\n\ttestCases := []struct {\n\t\treq     *http.Request\n\t\ts3Error APIErrorCode\n\t}{\n\t\t// When request is nil, internal error is returned.\n\t\t{nil, ErrInternalError},\n\t\t// When request is unsigned, access denied is returned.\n\t\t{mustNewRequest(\"GET\", \"http://127.0.0.1:9000\", 0, nil, t), ErrAccessDenied},\n\t\t// Empty Content-Md5 header.\n\t\t{mustNewSignedEmptyMD5Request(\"PUT\", \"http://127.0.0.1:9000/\", 5, bytes.NewReader([]byte(\"hello\")), t), ErrInvalidDigest},\n\t\t// Short Content-Md5 header.\n\t\t{mustNewSignedShortMD5Request(\"PUT\", \"http://127.0.0.1:9000/\", 5, bytes.NewReader([]byte(\"hello\")), t), ErrInvalidDigest},\n\t\t// When request is properly signed, but has bad Content-MD5 header.\n\t\t{mustNewSignedBadMD5Request(\"PUT\", \"http://127.0.0.1:9000/\", 5, bytes.NewReader([]byte(\"hello\")), t), ErrBadDigest},\n\t\t// When request is properly signed, error is none.\n\t\t{mustNewSignedRequest(\"GET\", \"http://127.0.0.1:9000\", 0, nil, t), ErrNone},\n\t}\n\n\t// Validates all testcases.\n\tfor _, testCase := range testCases {\n\t\tif s3Error := isReqAuthenticated(testCase.req, globalServerConfig.GetRegion()); s3Error != testCase.s3Error {\n\t\t\tt.Fatalf(\"Unexpected s3error returned wanted %d, got %d\", testCase.s3Error, s3Error)\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (g *Given) readResource(text string, v metav1.Object) {\n\tg.t.Helper()\n\tvar file string\n\tif strings.HasPrefix(text, \"@\") {\n\t\tfile = strings.TrimPrefix(text, \"@\")\n\t} else {\n\t\tf, err := ioutil.TempFile(\"\", \"argo-events-e2e\")\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\t_, err = f.Write([]byte(text))\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\terr = f.Close()\n\t\tif err != nil {\n\t\t\tg.t.Fatal(err)\n\t\t}\n\t\tfile = f.Name()\n\t}\n\n\tf, err := ioutil.ReadFile(file)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n\terr = yaml.Unmarshal(f, v)\n\tif err != nil {\n\t\tg.t.Fatal(err)\n\t}\n}", "is_vulnerable": 1}
{"code": "\terr := listSignatures(ctx, sigRepo, targetDesc, maxSigs, func(sigManifestDesc ocispec.Descriptor) error {\n\t\t// print the previous signature digest\n\t\tif prevDigest != \"\" {\n\t\t\tprintTitle()\n\t\t\tfmt.Printf(\"    \u251c\u2500\u2500 %s\\n\", prevDigest)\n\t\t}\n\t\tprevDigest = sigManifestDesc.Digest\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "\t\t\tPublicKey: func(conn ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\t\t\t\tcertChecker := apisshutils.CertChecker{\n\t\t\t\t\tCertChecker: ssh.CertChecker{\n\t\t\t\t\t\tIsUserAuthority: func(cert ssh.PublicKey) bool {\n\t\t\t\t\t\t\t// Makes sure that user presented key signed by or with trusted authority.\n\t\t\t\t\t\t\treturn apisshutils.KeysEqual(caPub, cert)\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\treturn certChecker.Authenticate(conn, key)\n\t\t\t},\n\t\t},", "is_vulnerable": 0}
{"code": "func TestKMSContextDecrypt(t *testing.T) {\n\tkey, _ := hex.DecodeString(\"31bdadd96698c204aa9ce1448ea94ae1fb4a9a0b3c9d773b51bb1822666b8f22\")\n\tkeyB64 := base64.URLEncoding.EncodeToString(key)\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tbodyBytes, err := ioutil.ReadAll(r.Body)\n\t\tif err != nil {\n\t\t\tw.WriteHeader(500)\n\t\t\treturn\n\t\t}\n\t\tvar body map[string]interface{}\n\t\terr = json.Unmarshal(bodyBytes, &body)\n\t\tif err != nil {\n\t\t\tw.WriteHeader(500)\n\t\t\treturn\n\t\t}\n\n\t\tmd, ok := body[\"EncryptionContext\"].(map[string]interface{})\n\t\tif !ok {\n\t\t\tw.WriteHeader(500)\n\t\t\treturn\n\t\t}\n\n\t\texEncContext := map[string]interface{}{\n\t\t\t\"aws:\" + cekAlgorithmHeader: \"cekAlgValue\",\n\t\t}\n\n\t\tif e, a := exEncContext, md; !reflect.DeepEqual(e, a) {\n\t\t\tw.WriteHeader(500)\n\t\t\tt.Errorf(\"expected %v, got %v\", e, a)\n\t\t\treturn\n\t\t}\n\n\t\tfmt.Fprintln(w, fmt.Sprintf(\"%s%s%s\", `{\"KeyId\":\"test-key-id\",\"Plaintext\":\"`, keyB64, `\"}`))\n\t}))\n\tdefer ts.Close()\n\n\tsess := unit.Session.Copy(&aws.Config{\n\t\tMaxRetries:       aws.Int(0),\n\t\tEndpoint:         aws.String(ts.URL),\n\t\tDisableSSL:       aws.Bool(true),\n\t\tS3ForcePathStyle: aws.Bool(true),\n\t\tRegion:           aws.String(\"us-west-2\"),\n\t})\n\thandler, err := NewKMSContextWrapEntry(kms.New(sess))(Envelope{MatDesc: `{\"aws:x-amz-cek-alg\": \"cekAlgValue\"}`})\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\n\tplaintextKey, err := handler.DecryptKey([]byte{1, 2, 3, 4})\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\n\tif !bytes.Equal(key, plaintextKey) {\n\t\tt.Errorf(\"expected %v, but received %v\", key, plaintextKey)\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestInsertable(t *testing.T) {\n\ttype TestCase struct {\n\t\tcaseDesc      string\n\t\tentry         V002Entry\n\t\texpectSuccess bool\n\t}\n\n\tkey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tenv := envelope(t, key, []byte(\"payload\"))\n\tkeyBytes := strfmt.Base64([]byte(\"key\"))\n\tsigBytes := strfmt.Base64([]byte(\"sig\"))\n\n\ttestCases := []TestCase{\n\t\t{\n\t\t\tcaseDesc: \"valid entry\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tPublicKey: &keyBytes,\n\t\t\t\t\t\t\t\t\tSig:       &sigBytes,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: true,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"valid entry but hasn't been parsed\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tPublicKey: &keyBytes,\n\t\t\t\t\t\t\t\t\tSig:       &sigBytes,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: dsse.Envelope{},\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing sig\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tPublicKey: &keyBytes,\n\t\t\t\t\t\t\t\t\t//Sig:       strfmt.Base64([]byte(\"sig\")),\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing key\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t//PublicKey: strfmt.Base64([]byte(\"key\")),\n\t\t\t\t\t\t\t\t\tSig: &sigBytes,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"empty signatures\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures:  []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{},\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tPublicKey: strfmt.Base64([]byte(\"key\")),\n\t\t\t\t\t\t\t\t\t\tSig:       strfmt.Base64([]byte(\"sig\")),\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t*/\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing payloadType\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\tPayload: strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\t//PayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tPublicKey: &keyBytes,\n\t\t\t\t\t\t\t\t\tSig:       &sigBytes,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing payload\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\t//Payload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tPublicKey: &keyBytes,\n\t\t\t\t\t\t\t\t\tSig:       &sigBytes,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing envelope\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tPublicKey: strfmt.Base64([]byte(\"key\")),\n\t\t\t\t\t\t\t\t\t\tSig:       strfmt.Base64([]byte(\"sig\")),\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t*/\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"missing content\",\n\t\t\tentry: V002Entry{\n\t\t\t\tIntotoObj: models.IntotoV002Schema{\n\t\t\t\t\t/*\n\t\t\t\t\t\tContent: &models.IntotoV002SchemaContent{\n\t\t\t\t\t\t\tEnvelope: &models.IntotoV002SchemaContentEnvelope{\n\t\t\t\t\t\t\t\tPayload:     strfmt.Base64(\"payload\"),\n\t\t\t\t\t\t\t\tPayloadType: swag.String(\"payloadType\"),\n\t\t\t\t\t\t\t\tSignatures: []*models.IntotoV002SchemaContentEnvelopeSignaturesItems0{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tPublicKey: strfmt.Base64([]byte(\"key\")),\n\t\t\t\t\t\t\t\t\t\tSig:       strfmt.Base64([]byte(\"sig\")),\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t*/\n\t\t\t\t},\n\t\t\t\tenv: *env,\n\t\t\t},\n\t\t\texpectSuccess: false,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tt.Run(tc.caseDesc, func(t *testing.T) {\n\t\t\tif ok, err := tc.entry.Insertable(); ok != tc.expectSuccess {\n\t\t\t\tt.Errorf(\"unexpected result calling Insertable: %v\", err)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (k *K8sClusterMesh) generateDeployment(clustermeshApiserverArgs []string) *appsv1.Deployment {\n\n\tdeployment := &appsv1.Deployment{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:   defaults.ClusterMeshDeploymentName,\n\t\t\tLabels: defaults.ClusterMeshDeploymentLabels,\n\t\t},\n\t\tSpec: appsv1.DeploymentSpec{\n\t\t\tReplicas: &replicas,\n\t\t\tSelector: &metav1.LabelSelector{\n\t\t\t\tMatchLabels: defaults.ClusterMeshDeploymentLabels,\n\t\t\t},\n\t\t\tStrategy: appsv1.DeploymentStrategy{\n\t\t\t\tType: appsv1.RollingUpdateDeploymentStrategyType,\n\t\t\t\tRollingUpdate: &appsv1.RollingUpdateDeployment{\n\t\t\t\t\tMaxUnavailable: &deploymentMaxUnavailable,\n\t\t\t\t\tMaxSurge:       &deploymentMaxSurge,\n\t\t\t\t},\n\t\t\t},\n\t\t\tTemplate: corev1.PodTemplateSpec{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tName:   defaults.ClusterMeshDeploymentName,\n\t\t\t\t\tLabels: defaults.ClusterMeshDeploymentLabels,\n\t\t\t\t},\n\t\t\t\tSpec: corev1.PodSpec{\n\t\t\t\t\tRestartPolicy:      corev1.RestartPolicyAlways,\n\t\t\t\t\tServiceAccountName: defaults.ClusterMeshServiceAccountName,\n\t\t\t\t\tContainers: []corev1.Container{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:    \"etcd\",\n\t\t\t\t\t\t\tCommand: []string{\"/usr/local/bin/etcd\"},\n\t\t\t\t\t\t\tArgs: []string{\n\t\t\t\t\t\t\t\t\"--data-dir=/var/run/etcd\",\n\t\t\t\t\t\t\t\t\"--name=clustermesh-apiserver\",\n\t\t\t\t\t\t\t\t\"--client-cert-auth\",\n\t\t\t\t\t\t\t\t\"--trusted-ca-file=/var/lib/etcd-secrets/ca.crt\",\n\t\t\t\t\t\t\t\t\"--cert-file=/var/lib/etcd-secrets/tls.crt\",\n\t\t\t\t\t\t\t\t\"--key-file=/var/lib/etcd-secrets/tls.key\",\n\t\t\t\t\t\t\t\t// Surrounding the IPv4 address with brackets works in this case, since etcd\n\t\t\t\t\t\t\t\t// uses net.SplitHostPort() internally and it accepts that format.\n\t\t\t\t\t\t\t\t\"--listen-client-urls=https://127.0.0.1:2379,https://[$(HOSTNAME_IP)]:2379\",\n\t\t\t\t\t\t\t\t\"--advertise-client-urls=https://[$(HOSTNAME_IP)]:2379\",\n\t\t\t\t\t\t\t\t\"--initial-cluster-token=clustermesh-apiserver\",\n\t\t\t\t\t\t\t\t\"--auto-compaction-retention=1\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tImage:           k.etcdImage(),\n\t\t\t\t\t\t\tImagePullPolicy: corev1.PullIfNotPresent,\n\t\t\t\t\t\t\tEnv:             k.etcdEnvs(),\n\t\t\t\t\t\t\tVolumeMounts: []corev1.VolumeMount{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName:      \"etcd-server-secrets\",\n\t\t\t\t\t\t\t\t\tMountPath: \"/var/lib/etcd-secrets\",\n\t\t\t\t\t\t\t\t\tReadOnly:  true,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName:      \"etcd-data-dir\",\n\t\t\t\t\t\t\t\t\tMountPath: \"/var/run/etcd\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:    \"apiserver\",\n\t\t\t\t\t\t\tCommand: []string{\"/usr/bin/clustermesh-apiserver\"},\n\t\t\t\t\t\t\tArgs: append(clustermeshApiserverArgs,\n\t\t\t\t\t\t\t\t\"--cluster-name=\"+k.clusterName,\n\t\t\t\t\t\t\t\t\"--cluster-id=\"+k.clusterID,\n\t\t\t\t\t\t\t\t\"--kvstore-opt\",\n\t\t\t\t\t\t\t\t\"etcd.config=/var/lib/cilium/etcd-config.yaml\",\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\tImage:           k.apiserverImage(utils.ImagePathIncludeDigest),\n\t\t\t\t\t\t\tImagePullPolicy: corev1.PullIfNotPresent,\n\t\t\t\t\t\t\tEnv: []corev1.EnvVar{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName: \"CILIUM_CLUSTER_NAME\",\n\t\t\t\t\t\t\t\t\tValueFrom: &corev1.EnvVarSource{\n\t\t\t\t\t\t\t\t\t\tConfigMapKeyRef: &corev1.ConfigMapKeySelector{\n\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.ConfigMapName,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tKey: configNameClusterName,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName: \"CILIUM_CLUSTER_ID\",\n\t\t\t\t\t\t\t\t\tValueFrom: &corev1.EnvVarSource{\n\t\t\t\t\t\t\t\t\t\tConfigMapKeyRef: &corev1.ConfigMapKeySelector{\n\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.ConfigMapName,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tKey: configNameClusterID,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName: \"CILIUM_IDENTITY_ALLOCATION_MODE\",\n\t\t\t\t\t\t\t\t\tValueFrom: &corev1.EnvVarSource{\n\t\t\t\t\t\t\t\t\t\tConfigMapKeyRef: &corev1.ConfigMapKeySelector{\n\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.ConfigMapName,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\tKey: \"identity-allocation-mode\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tVolumeMounts: []corev1.VolumeMount{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName:      \"etcd-admin-client\",\n\t\t\t\t\t\t\t\t\tMountPath: \"/var/lib/cilium/etcd-secrets\",\n\t\t\t\t\t\t\t\t\tReadOnly:  true,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tInitContainers: []corev1.Container{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:            \"etcd-init\",\n\t\t\t\t\t\t\tCommand:         []string{\"/bin/sh\", \"-c\"},\n\t\t\t\t\t\t\tArgs:            initContainerArgs,\n\t\t\t\t\t\t\tImage:           k.etcdImage(),\n\t\t\t\t\t\t\tImagePullPolicy: corev1.PullIfNotPresent,\n\t\t\t\t\t\t\tEnv:             k.etcdEnvs(),\n\t\t\t\t\t\t\tVolumeMounts: []corev1.VolumeMount{\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tName:      \"etcd-data-dir\",\n\t\t\t\t\t\t\t\t\tMountPath: \"etcd-data-dir\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tVolumes: []corev1.Volume{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"etcd-data-dir\",\n\t\t\t\t\t\t\tVolumeSource: corev1.VolumeSource{\n\t\t\t\t\t\t\t\tEmptyDir: &corev1.EmptyDirVolumeSource{},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"etcd-server-secrets\",\n\t\t\t\t\t\t\tVolumeSource: corev1.VolumeSource{\n\t\t\t\t\t\t\t\tProjected: &corev1.ProjectedVolumeSource{\n\t\t\t\t\t\t\t\t\tDefaultMode: &secretDefaultMode,\n\t\t\t\t\t\t\t\t\tSources: []corev1.VolumeProjection{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tSecret: &corev1.SecretProjection{\n\t\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.CASecretName,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tItems: []corev1.KeyToPath{\n\t\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tKey:  defaults.CASecretCertName,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tPath: \"ca.crt\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tSecret: &corev1.SecretProjection{\n\t\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.ClusterMeshServerSecretName,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName: \"etcd-admin-client\",\n\t\t\t\t\t\t\tVolumeSource: corev1.VolumeSource{\n\t\t\t\t\t\t\t\tProjected: &corev1.ProjectedVolumeSource{\n\t\t\t\t\t\t\t\t\tDefaultMode: &secretDefaultMode,\n\t\t\t\t\t\t\t\t\tSources: []corev1.VolumeProjection{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tSecret: &corev1.SecretProjection{\n\t\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.CASecretName,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\tItems: []corev1.KeyToPath{\n\t\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tKey:  defaults.CASecretCertName,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tPath: \"ca.crt\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tSecret: &corev1.SecretProjection{\n\t\t\t\t\t\t\t\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: defaults.ClusterMeshAdminSecretName,\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\treturn deployment\n}", "is_vulnerable": 1}
{"code": "func (s *Server) CreateToken(ctx context.Context, q *project.ProjectTokenCreateRequest) (*project.ProjectTokenResponse, error) {\n\tprj, err := s.appclientset.ArgoprojV1alpha1().AppProjects(s.ns).Get(ctx, q.Project, metav1.GetOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = validateProject(prj)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ts.projectLock.Lock(q.Project)\n\tdefer s.projectLock.Unlock(q.Project)\n\n\trole, _, err := prj.GetRoleByName(q.Role)\n\tif err != nil {\n\t\treturn nil, status.Errorf(codes.NotFound, \"project '%s' does not have role '%s'\", q.Project, q.Role)\n\t}\n\tif err := s.enf.EnforceErr(ctx.Value(\"claims\"), rbacpolicy.ResourceProjects, rbacpolicy.ActionUpdate, q.Project); err != nil {\n\t\tif !jwtutil.IsMember(jwtutil.Claims(ctx.Value(\"claims\")), role.Groups, s.policyEnf.GetScopes()) {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tid := q.Id\n\tif err := prj.ValidateJWTTokenID(q.Role, q.Id); err != nil {\n\t\treturn nil, status.Errorf(codes.InvalidArgument, err.Error())\n\t}\n\tif id == \"\" {\n\t\tuniqueId, _ := uuid.NewRandom()\n\t\tid = uniqueId.String()\n\t}\n\tsubject := fmt.Sprintf(JWTTokenSubFormat, q.Project, q.Role)\n\tjwtToken, err := s.sessionMgr.Create(subject, q.ExpiresIn, id)\n\tif err != nil {\n\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n\t}\n\tparser := &jwt.Parser{\n\t\tValidationHelper: jwt.NewValidationHelper(jwt.WithoutClaimsValidation(), jwt.WithoutAudienceValidation()),\n\t}\n\tclaims := jwt.StandardClaims{}\n\t_, _, err = parser.ParseUnverified(jwtToken, &claims)\n\tif err != nil {\n\t\treturn nil, status.Error(codes.InvalidArgument, err.Error())\n\t}\n\tvar issuedAt, expiresAt int64\n\tif claims.IssuedAt != nil {\n\t\tissuedAt = claims.IssuedAt.Unix()\n\t}\n\tif claims.ExpiresAt != nil {\n\t\texpiresAt = claims.ExpiresAt.Unix()\n\t}\n\tid = claims.ID\n\n\titems := append(prj.Status.JWTTokensByRole[q.Role].Items, v1alpha1.JWTToken{IssuedAt: issuedAt, ExpiresAt: expiresAt, ID: id})\n\tif _, found := prj.Status.JWTTokensByRole[q.Role]; found {\n\t\tprj.Status.JWTTokensByRole[q.Role] = v1alpha1.JWTTokens{Items: items}\n\t} else {\n\t\ttokensMap := make(map[string]v1alpha1.JWTTokens)\n\t\ttokensMap[q.Role] = v1alpha1.JWTTokens{Items: items}\n\t\tprj.Status.JWTTokensByRole = tokensMap\n\t}\n\n\tprj.NormalizeJWTTokens()\n\n\t_, err = s.appclientset.ArgoprojV1alpha1().AppProjects(s.ns).Update(ctx, prj, metav1.UpdateOptions{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ts.logEvent(prj, ctx, argo.EventReasonResourceCreated, \"created token\")\n\treturn &project.ProjectTokenResponse{Token: jwtToken}, nil\n\n}", "is_vulnerable": 0}
{"code": "func NewResourceIgnoreResourceUpdatesCommand(cmdCtx commandContext) *cobra.Command {\n\tvar command = &cobra.Command{\n\t\tUse:   \"ignore-resource-updates RESOURCE_YAML_PATH\",\n\t\tShort: \"Renders fields excluded from resource updates\",\n\t\tLong:  \"Renders ignored fields using the 'ignoreResourceUpdates' setting specified in the 'resource.customizations' field of 'argocd-cm' ConfigMap\",\n\t\tExample: `\nargocd admin settings resource-overrides ignore-resource-updates ./deploy.yaml --argocd-cm-path ./argocd-cm.yaml`,\n\t\tRun: func(c *cobra.Command, args []string) {\n\t\t\tctx := c.Context()\n\n\t\t\tif len(args) < 1 {\n\t\t\t\tc.HelpFunc()(c, args)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\n\t\t\texecuteIgnoreResourceUpdatesOverrideCommand(ctx, cmdCtx, args, func(res unstructured.Unstructured, override v1alpha1.ResourceOverride, overrides map[string]v1alpha1.ResourceOverride) {\n\t\t\t\tgvk := res.GroupVersionKind()\n\t\t\t\tif len(override.IgnoreResourceUpdates.JSONPointers) == 0 && len(override.IgnoreResourceUpdates.JQPathExpressions) == 0 {\n\t\t\t\t\t_, _ = fmt.Printf(\"Ignore resource updates are not configured for '%s/%s'\\n\", gvk.Group, gvk.Kind)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tnormalizer, err := normalizers.NewIgnoreNormalizer(nil, overrides)\n\t\t\t\terrors.CheckError(err)\n\n\t\t\t\tnormalizedRes := res.DeepCopy()\n\t\t\t\tlogs := collectLogs(func() {\n\t\t\t\t\terrors.CheckError(normalizer.Normalize(normalizedRes))\n\t\t\t\t})\n\t\t\t\tif logs != \"\" {\n\t\t\t\t\t_, _ = fmt.Println(logs)\n\t\t\t\t}\n\n\t\t\t\tif reflect.DeepEqual(&res, normalizedRes) {\n\t\t\t\t\t_, _ = fmt.Printf(\"No fields are ignored by ignoreResourceUpdates settings: \\n%s\\n\", override.IgnoreResourceUpdates)\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t_, _ = fmt.Printf(\"Following fields are ignored:\\n\\n\")\n\t\t\t\t_ = cli.PrintDiff(res.GetName(), &res, normalizedRes)\n\t\t\t})\n\t\t},\n\t}\n\treturn command\n}", "is_vulnerable": 1}
{"code": "func (e *EgressDNS) Run(defaultInterval time.Duration) {\n\tvar dnsName string\n\tvar ttl time.Time\n\tvar timeSet bool\n\t// initially the next DNS Query happens at the default interval\n\tdurationTillNextQuery := defaultInterval\n\tgo func() {\n\t\tfor {\n\t\t\t// Wait for the given duration or until something gets added\n\t\t\tselect {\n\t\t\tcase dnsName := <-e.added:\n\t\t\t\tif err := e.dns.Add(dnsName); err != nil {\n\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t}\n\t\t\t\tif err := e.updateEntryForName(dnsName); err != nil {\n\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t}\n\t\t\tcase <-time.After(durationTillNextQuery):\n\t\t\t\tif len(dnsName) > 0 {\n\t\t\t\t\tif _, err := e.Update(dnsName); err != nil {\n\t\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t\t}\n\t\t\t\t\tif err := e.updateEntryForName(dnsName); err != nil {\n\t\t\t\t\t\tutilruntime.HandleError(err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase <-e.stopChan:\n\t\t\t\treturn\n\t\t\tcase <-e.controllerStop:\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// before waiting on the signals get the next time this thread needs to wake up\n\t\t\tttl, dnsName, timeSet = e.dns.GetNextQueryTime()\n\t\t\tif time.Until(ttl) > defaultInterval || !timeSet {\n\t\t\t\tdurationTillNextQuery = defaultInterval\n\t\t\t} else {\n\t\t\t\tdurationTillNextQuery = time.Until(ttl)\n\t\t\t}\n\t\t}\n\t}()\n\n}", "is_vulnerable": 1}
{"code": "func TestCreateProposalBlock(t *testing.T) {\n\tconfig := cfg.ResetTestRoot(\"node_create_proposal\")\n\tdefer os.RemoveAll(config.RootDir)\n\tcc := proxy.NewLocalClientCreator(kvstore.NewApplication())\n\tproxyApp := proxy.NewAppConns(cc)\n\terr := proxyApp.Start()\n\trequire.Nil(t, err)\n\tdefer proxyApp.Stop() //nolint:errcheck // ignore for tests\n\n\tlogger := log.TestingLogger()\n\n\tvar height int64 = 1\n\tstate, stateDB, privVals := state(1, height)\n\tstateStore := sm.NewStore(stateDB)\n\tmaxBytes := 16384\n\tvar partSize uint32 = 256\n\tmaxEvidenceBytes := int64(maxBytes / 2)\n\tstate.ConsensusParams.Block.MaxBytes = int64(maxBytes)\n\tstate.ConsensusParams.Evidence.MaxBytes = maxEvidenceBytes\n\tproposerAddr, _ := state.Validators.GetByIndex(0)\n\n\t// Make Mempool\n\tmemplMetrics := mempl.PrometheusMetrics(\"node_test_1\")\n\tmempool := mempl.NewCListMempool(\n\t\tconfig.Mempool,\n\t\tproxyApp.Mempool(),\n\t\tstate.LastBlockHeight,\n\t\tmempl.WithMetrics(memplMetrics),\n\t\tmempl.WithPreCheck(sm.TxPreCheck(state)),\n\t\tmempl.WithPostCheck(sm.TxPostCheck(state)),\n\t)\n\tmempool.SetLogger(logger)\n\n\t// Make EvidencePool\n\tevidenceDB := dbm.NewMemDB()\n\tblockStore := store.NewBlockStore(dbm.NewMemDB())\n\tevidencePool, err := evidence.NewPool(evidenceDB, stateStore, blockStore)\n\trequire.NoError(t, err)\n\tevidencePool.SetLogger(logger)\n\n\t// fill the evidence pool with more evidence\n\t// than can fit in a block\n\tvar currentBytes int64 = 0\n\tfor currentBytes <= maxEvidenceBytes {\n\t\tev := types.NewMockDuplicateVoteEvidenceWithValidator(height, time.Now(), privVals[0], \"test-chain\")\n\t\tcurrentBytes += int64(len(ev.Bytes()))\n\t\terr := evidencePool.AddEvidenceFromConsensus(ev)\n\t\trequire.NoError(t, err)\n\t}\n\n\tevList, size := evidencePool.PendingEvidence(state.ConsensusParams.Evidence.MaxBytes)\n\trequire.Less(t, size, state.ConsensusParams.Evidence.MaxBytes+1)\n\tevData := &types.EvidenceData{Evidence: evList}\n\trequire.EqualValues(t, size, evData.ByteSize())\n\n\t// fill the mempool with more txs\n\t// than can fit in a block\n\ttxLength := 100\n\tfor i := 0; i <= maxBytes/txLength; i++ {\n\t\ttx := tmrand.Bytes(txLength)\n\t\terr := mempool.CheckTx(tx, nil, mempl.TxInfo{})\n\t\tassert.NoError(t, err)\n\t}\n\n\tblockExec := sm.NewBlockExecutor(\n\t\tstateStore,\n\t\tlogger,\n\t\tproxyApp.Consensus(),\n\t\tmempool,\n\t\tevidencePool,\n\t)\n\n\tcommit := types.NewCommit(height-1, 0, types.BlockID{}, nil)\n\tblock, _ := blockExec.CreateProposalBlock(\n\t\theight,\n\t\tstate, commit,\n\t\tproposerAddr,\n\t)\n\n\t// check that the part set does not exceed the maximum block size\n\tpartSet := block.MakePartSet(partSize)\n\tassert.Less(t, partSet.ByteSize(), int64(maxBytes))\n\n\tpartSetFromHeader := types.NewPartSetFromHeader(partSet.Header())\n\tfor partSetFromHeader.Count() < partSetFromHeader.Total() {\n\t\tadded, err := partSetFromHeader.AddPart(partSet.GetPart(int(partSetFromHeader.Count())))\n\t\trequire.NoError(t, err)\n\t\trequire.True(t, added)\n\t}\n\tassert.EqualValues(t, partSetFromHeader.ByteSize(), partSet.ByteSize())\n\n\terr = blockExec.ValidateBlock(state, block)\n\tassert.NoError(t, err)\n}", "is_vulnerable": 1}
{"code": "func TestInitialAllocationSetBinaryProtocol(t *testing.T) {\n\tvar m MyTestStruct\n\td := NewDeserializer()\n\tf := NewBinaryProtocolFactoryDefault()\n\td.Protocol = f.GetProtocol(d.Transport)\n\t// attempts to allocate a set with 1.8B elements for a 20 byte message\n\tdata := []byte(\"\\n\\x12\\rO\\t6\\x03\\n\\n\\n\\x10\\x0e\\n\\tslice\\x00\")\n\terr := d.Read(&m, data)\n\tif err == nil {\n\t\tt.Fatalf(\"Parsed invalid message correctly\")\n\t} else if !strings.Contains(err.Error(), \"Invalid data length\") {\n\t\tfmt.Printf(\"Got %+v\", err)\n\t\tt.Fatalf(\"Failed for reason besides Invalid data length\")\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *SessionContext) GetSSHCertificate() (*ssh.Certificate, error) {\n\treturn apisshutils.ParseCertificate(c.session.GetPub())\n}", "is_vulnerable": 0}
{"code": "func (acl *ACL) ValidateDomains(domains []string) error {\n\tfor _, d := range domains {\n\t\tif d == \"\" {\n\t\t\treturn fmt.Errorf(\"glob cannot be empty\")\n\t\t}\n\n\t\tif !strings.HasPrefix(d, \"*.\") && strings.HasPrefix(d, \"*\") {\n\t\t\treturn fmt.Errorf(\"%v: domain glob must represent a full prefix (sub)domain\", d)\n\t\t}\n\n\t\tdomainToCheck := strings.TrimPrefix(d, \"*\")\n\t\tif strings.Contains(domainToCheck, \"*\") {\n\t\t\treturn fmt.Errorf(\"%v: domain globs are only supported as prefix\", d)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func defaultLocation(x ast.Node) *ast.Location {\n\treturn ast.NewLocation([]byte(x.String()), defaultLocationFile, 1, 1)\n}", "is_vulnerable": 0}
{"code": "\treturn s.getAppEnforceRBAC(ctx, action, namespaceOrDefault, name, func() (*appv1.Application, error) {\n\t\treturn s.appLister.Applications(namespaceOrDefault).Get(name)\n\t})", "is_vulnerable": 0}
{"code": "func registerNotifier(srv *jrpc2.Server) {\n\tcallbackFunction := func(params interface{}) {\n\t\tswitch params := params.(type) {\n\t\tcase lsp.AuthenticationParams:\n\t\t\tnotifier(srv, \"$/snyk.hasAuthenticated\", params)\n\t\t\tlog.Info().Str(\"method\", \"registerNotifier\").\n\t\t\t\tMsg(\"sending token\")\n\t\tcase lsp.SnykIsAvailableCli:\n\t\t\tnotifier(srv, \"$/snyk.isAvailableCli\", params)\n\t\t\tlog.Info().Str(\"method\", \"registerNotifier\").\n\t\t\t\tMsg(\"sending cli path\")\n\t\tcase sglsp.ShowMessageParams:\n\t\t\tnotifier(srv, \"window/showMessage\", params)\n\t\t\tlog.Info().\n\t\t\t\tStr(\"method\", \"registerNotifier\").\n\t\t\t\tInterface(\"message\", params).\n\t\t\t\tMsg(\"showing message\")\n\t\tcase lsp.PublishDiagnosticsParams:\n\t\t\tnotifier(srv, \"textDocument/publishDiagnostics\", params)\n\t\t\tsource := \"LSP\"\n\t\t\tif len(params.Diagnostics) > 0 {\n\t\t\t\tsource = params.Diagnostics[0].Source\n\t\t\t}\n\t\t\tlog.Info().\n\t\t\t\tStr(\"method\", \"registerNotifier\").\n\t\t\t\tInterface(\"documentURI\", params.URI).\n\t\t\t\tInterface(\"source\", source).\n\t\t\t\tInterface(\"diagnosticCount\", len(params.Diagnostics)).\n\t\t\t\tMsg(\"publishing diagnostics\")\n\t\tcase lsp.SnykTrustedFoldersParams:\n\t\t\tnotifier(srv, \"$/snyk.addTrustedFolders\", params)\n\t\t\tlog.Info().\n\t\t\t\tStr(\"method\", \"registerNotifier\").\n\t\t\t\tInterface(\"trustedPaths\", params.TrustedFolders).\n\t\t\t\tMsg(\"sending trusted Folders to client\")\n\t\tdefault:\n\t\t\tlog.Warn().\n\t\t\t\tStr(\"method\", \"registerNotifier\").\n\t\t\t\tInterface(\"params\", params).\n\t\t\t\tMsg(\"received unconfigured notification object\")\n\t\t}\n\t}\n\tnotification.CreateListener(callbackFunction)\n\tlog.Info().Str(\"method\", \"registerNotifier\").Msg(\"registered notifier\")\n}", "is_vulnerable": 0}
{"code": "func (fs *UnixFS) ReadDir(path string) ([]DirEntry, error) {\n\tdirfd, name, closeFd, err := fs.safePath(path)\n\tdefer closeFd()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfd, err := fs.openat(dirfd, name, O_DIRECTORY|O_RDONLY, 0)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer unix.Close(fd)\n\treturn fs.readDir(fd, name, nil)\n}", "is_vulnerable": 0}
{"code": "func LoadKey2(rw io.ReadWriter, keyBlob []byte, srkAuth []byte) (tpmutil.Handle, error) {\n\t// Deserialize the keyBlob as a key\n\tvar k key\n\tif _, err := tpmutil.Unpack(keyBlob, &k); err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run OSAP for the SRK, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a handle. LoadKey2 needs an\n\t// OSAP session for the SRK because the private part of a TPM_KEY or\n\t// TPM_KEY12 is sealed against the SRK.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etSRK, khSRK, srkAuth)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\tauthIn := []interface{}{ordLoadKey2, k}\n\tca, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\thandle, ra, ret, err := loadKey2(rw, &k, ca)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Check the response authentication.\n\traIn := []interface{}{ret, ordLoadKey2}\n\tif err := ra.verify(ca.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn handle, nil\n}", "is_vulnerable": 1}
{"code": "func (m *NinOptStruct) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptStruct: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinOptStruct: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\tm.Field1 = &v2\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\tm.Field2 = &v2\n\t\tcase 3:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field3 == nil {\n\t\t\t\tm.Field3 = &NidOptNative{}\n\t\t\t}\n\t\t\tif err := m.Field3.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 4:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field4 == nil {\n\t\t\t\tm.Field4 = &NinOptNative{}\n\t\t\t}\n\t\t\tif err := m.Field4.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field6 = &v\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.Field7 = &v\n\t\tcase 8:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.Field8 == nil {\n\t\t\t\tm.Field8 = &NidOptNative{}\n\t\t\t}\n\t\t\tif err := m.Field8.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.Field13 = &b\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Field14 = &s\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Field15 = append(m.Field15[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Field15 == nil {\n\t\t\t\tm.Field15 = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func labels(code, method bool, reqMethod string, status int) prometheus.Labels {\n\tif !(code || method) {\n\t\treturn emptyLabels\n\t}\n\tlabels := prometheus.Labels{}\n\n\tif code {\n\t\tlabels[\"code\"] = sanitizeCode(status)\n\t}\n\tif method {\n\t\tlabels[\"method\"] = sanitizeMethod(reqMethod)\n\t}\n\n\treturn labels\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot, err := setInstance(tt.args.ctx, tt.args.req, tt.args.info, tt.args.handler, tt.args.verifier, tt.args.headerName, nil)\n\t\t\tif (err != nil) != tt.res.err {\n\t\t\t\tt.Errorf(\"setInstance() error = %v, wantErr %v\", err, tt.res.err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(got, tt.res.want) {\n\t\t\t\tt.Errorf(\"setInstance() got = %v, want %v\", got, tt.res.want)\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (p *HTTPClient) Read(buf []byte) (int, error) {\n\tif p.response == nil {\n\t\treturn 0, NewTransportException(NOT_OPEN, \"Response buffer is empty, no request.\")\n\t}\n\tn, err := p.response.Body.Read(buf)\n\tif n > 0 && (err == nil || err == io.EOF) {\n\t\treturn n, nil\n\t}\n\treturn n, NewTransportExceptionFromError(err)\n}", "is_vulnerable": 1}
{"code": "func handleNodeFromMetaManager(content []byte) (*api.Node, error) {\n\tvar node api.Node\n\terr := json.Unmarshal(content, &node)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"unmarshal message to node failed, err: %v\", err)\n\t}\n\treturn &node, nil\n}", "is_vulnerable": 0}
{"code": "func TestFSM_BadSnapshot_NilCAConfig(t *testing.T) {\n\tt.Parallel()\n\n\trequire := require.New(t)\n\n\t// Create an FSM with no config entry.\n\tlogger := testutil.Logger(t)\n\tfsm, err := New(nil, logger)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Snapshot\n\tsnap, err := fsm.Snapshot()\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\tdefer snap.Release()\n\n\t// Persist\n\tbuf := bytes.NewBuffer(nil)\n\tsink := &MockSink{buf, false}\n\tif err := snap.Persist(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Try to restore on a new FSM\n\tfsm2, err := New(nil, logger)\n\tif err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Do a restore\n\tif err := fsm2.Restore(sink); err != nil {\n\t\tt.Fatalf(\"err: %v\", err)\n\t}\n\n\t// Make sure there's no entry in the CA config table.\n\tstate := fsm2.State()\n\tidx, config, err := state.CAConfig(nil)\n\trequire.NoError(err)\n\trequire.Equal(uint64(0), idx)\n\tif config != nil {\n\t\tt.Fatalf(\"config should be nil\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (c *Context) KeyListStart(pattern string, secretOnly bool) error {\n\tcpattern := C.CString(pattern)\n\tdefer C.free(unsafe.Pointer(cpattern))\n\terr := C.gpgme_op_keylist_start(c.ctx, cpattern, cbool(secretOnly))\n\treturn handleError(err)\n}", "is_vulnerable": 1}
{"code": "func (hostadd HostAddresses) Validate() error {\n\treturn validation.ValidateStruct(&hostadd,\n\t\tvalidation.Field(&hostadd.Manage, validation.Required, validation.By(ValidateManagementHostname)),\n\t\tvalidation.Field(&hostadd.Storage, validation.Required, validation.By(ValidateStorageHostname)),\n\t)\n}", "is_vulnerable": 0}
{"code": "func (as *argoServer) newHTTPServer(ctx context.Context, port int, artifactServer *artifacts.ArtifactServer) *http.Server {\n\tendpoint := fmt.Sprintf(\"localhost:%d\", port)\n\n\tmux := http.NewServeMux()\n\thttpServer := http.Server{\n\t\tAddr:      endpoint,\n\t\tHandler:   accesslog.Interceptor(mux),\n\t\tTLSConfig: as.tlsConfig,\n\t}\n\tdialOpts := []grpc.DialOption{\n\t\tgrpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(MaxGRPCMessageSize)),\n\t}\n\tif as.tlsConfig != nil {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(credentials.NewTLS(as.tlsConfig)))\n\t} else {\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\t}\n\n\twebhookInterceptor := webhook.Interceptor(as.clients.Kubernetes)\n\n\t// HTTP 1.1+JSON Server\n\t// grpc-ecosystem/grpc-gateway is used to proxy HTTP requests to the corresponding gRPC call\n\t// NOTE: if a marshaller option is not supplied, grpc-gateway will default to the jsonpb from\n\t// golang/protobuf. Which does not support types such as time.Time. gogo/protobuf does support\n\t// time.Time, but does not support custom UnmarshalJSON() and MarshalJSON() methods. Therefore\n\t// we use our own Marshaler\n\tgwMuxOpts := runtime.WithMarshalerOption(runtime.MIMEWildcard, new(json.JSONMarshaler))\n\tgwmux := runtime.NewServeMux(gwMuxOpts,\n\t\truntime.WithIncomingHeaderMatcher(func(key string) (string, bool) { return key, true }),\n\t\truntime.WithProtoErrorHandler(runtime.DefaultHTTPProtoErrorHandler),\n\t)\n\tmustRegisterGWHandler(infopkg.RegisterInfoServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventpkg.RegisterEventServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(eventsourcepkg.RegisterEventSourceServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(sensorpkg.RegisterSensorServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(pipelinepkg.RegisterPipelineServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowpkg.RegisterWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowtemplatepkg.RegisterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(cronworkflowpkg.RegisterCronWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(workflowarchivepkg.RegisterArchivedWorkflowServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\tmustRegisterGWHandler(clusterwftemplatepkg.RegisterClusterWorkflowTemplateServiceHandlerFromEndpoint, ctx, gwmux, endpoint, dialOpts)\n\n\tmux.HandleFunc(\"/api/\", func(w http.ResponseWriter, r *http.Request) {\n\t\t// we must delete this header for API request to prevent \"stream terminated by RST_STREAM with error code: PROTOCOL_ERROR\" error\n\t\tr.Header.Del(\"Connection\")\n\t\twebhookInterceptor(w, r, gwmux)\n\t})\n\n\t// emergency environment variable that allows you to disable the artifact service in case of problems\n\tif os.Getenv(\"ARGO_ARTIFACT_SERVER\") != \"false\" {\n\t\tmux.HandleFunc(\"/artifacts/\", artifactServer.GetOutputArtifact)\n\t\tmux.HandleFunc(\"/input-artifacts/\", artifactServer.GetInputArtifact)\n\t\tmux.HandleFunc(\"/artifacts-by-uid/\", artifactServer.GetOutputArtifactByUID)\n\t\tmux.HandleFunc(\"/input-artifacts-by-uid/\", artifactServer.GetInputArtifactByUID)\n\t\tmux.HandleFunc(\"/artifact-files/\", artifactServer.GetArtifactFile)\n\t}\n\tmux.Handle(\"/oauth2/redirect\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleRedirect)))\n\tmux.Handle(\"/oauth2/callback\", handlers.ProxyHeaders(http.HandlerFunc(as.oAuth2Service.HandleCallback)))\n\tmux.HandleFunc(\"/metrics\", func(w http.ResponseWriter, r *http.Request) {\n\t\tif os.Getenv(\"ARGO_SERVER_METRICS_AUTH\") != \"false\" {\n\t\t\theader := metadata.New(map[string]string{\"authorization\": r.Header.Get(\"Authorization\")})\n\t\t\tctx := metadata.NewIncomingContext(context.Background(), header)\n\t\t\tif _, err := as.gatekeeper.Context(ctx); err != nil {\n\t\t\t\tlog.WithError(err).Error(\"failed to authenticate /metrics endpoint\")\n\t\t\t\tw.WriteHeader(403)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tpromhttp.Handler().ServeHTTP(w, r)\n\n\t})\n\t// we only enable HTST if we are secure mode, otherwise you would never be able access the UI\n\tmux.HandleFunc(\"/\", static.NewFilesServer(as.baseHRef, as.tlsConfig != nil && as.hsts, as.xframeOptions, as.accessControlAllowOrigin).ServerFiles)\n\treturn &httpServer\n}", "is_vulnerable": 0}
{"code": "func tokenFromRequest(ctx context.Context, req connect.AnyRequest) (Token, error) {\n\theaders := req.Header()\n\n\tbearerToken, err := BearerTokenFromHeaders(headers)\n\tif err == nil {\n\t\treturn NewAccessToken(bearerToken), nil\n\t}\n\n\tcookie := req.Header().Get(\"Cookie\")\n\torigin := req.Header().Get(\"Origin\")\n\tif cookie != \"\" {\n\t\treturn NewCookieToken(cookie, origin), nil\n\t}\n\n\treturn Token{}, connect.NewError(connect.CodeUnauthenticated, fmt.Errorf(\"No access token or cookie credentials available on request.\"))\n}", "is_vulnerable": 1}
{"code": "func getAccAddrsFromBalances(balances []banktypes.Balance) []sdktypes.AccAddress {\n\tnumberOfBalances := len(balances)\n\tgenAccounts := make([]sdktypes.AccAddress, 0, numberOfBalances)\n\tfor _, balance := range balances {\n\t\tgenAccounts = append(genAccounts, balance.GetAddress())\n\t}\n\treturn genAccounts\n}", "is_vulnerable": 0}
{"code": "func (va ClawbackVestingAccount) ComputeClawback(\n\tclawbackTime int64,\n) (ClawbackVestingAccount, sdk.Coins) {\n\ttotalVested := va.GetVestedOnly(time.Unix(clawbackTime, 0))\n\ttotalUnvested := va.GetUnvestedOnly(time.Unix(clawbackTime, 0))\n\n\t// Remove all unvested periods from the schedule\n\tpassedPeriodID := va.GetPassedPeriodCount(time.Unix(clawbackTime, 0))\n\tnewVestingPeriods := va.VestingPeriods[:passedPeriodID]\n\tnewVestingEnd := va.GetStartTime() + newVestingPeriods.TotalLength()\n\n\t// Cap the unlocking schedule to the new total vested.\n\t//  - If lockup has already passed, all vested coins are unlocked.\n\t//  - If lockup has not passed, the vested coins, are still locked.\n\tcapPeriods := sdkvesting.Periods{\n\t\t{\n\t\t\tLength: 0,\n\t\t\tAmount: totalVested,\n\t\t},\n\t}\n\n\t// minimum of the 2 periods\n\t_, newLockingEnd, newLockupPeriods := ConjunctPeriods(va.GetStartTime(), va.GetStartTime(), va.LockupPeriods, capPeriods)\n\n\t// Now construct the new account state\n\tva.OriginalVesting = totalVested\n\tva.EndTime = Max64(newVestingEnd, newLockingEnd)\n\tva.LockupPeriods = newLockupPeriods\n\tva.VestingPeriods = newVestingPeriods\n\n\treturn va, totalUnvested\n}", "is_vulnerable": 1}
{"code": "func TestNormalizeGlobMatch(t *testing.T) {\n\tnormalizer, err := NewIgnoreNormalizer([]v1alpha1.ResourceIgnoreDifferences{}, map[string]v1alpha1.ResourceOverride{\n\t\t\"*/*\": {\n\t\t\tIgnoreDifferences: v1alpha1.OverrideIgnoreDiff{JSONPointers: []string{\"/spec/template/spec/containers\"}},\n\t\t},\n\t}, IgnoreNormalizerOpts{})\n\n\tassert.Nil(t, err)\n\n\tdeployment := test.NewDeployment()\n\n\t_, has, err := unstructured.NestedSlice(deployment.Object, \"spec\", \"template\", \"spec\", \"containers\")\n\tassert.Nil(t, err)\n\tassert.True(t, has)\n\n\terr = normalizer.Normalize(deployment)\n\tassert.Nil(t, err)\n\t_, has, err = unstructured.NestedSlice(deployment.Object, \"spec\", \"template\", \"spec\", \"containers\")\n\tassert.Nil(t, err)\n\tassert.False(t, has)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.desc, func(t *testing.T) {\n\t\t\tctx := &testContext{}\n\t\t\tfinalRoundTripper := ctx.createRoundTripper()\n\t\t\tforwarded := []*http.Cookie{\n\t\t\t\t{Name: \"c1\", Value: \"1\"},\n\t\t\t\t{Name: \"c2\", Value: \"2\"},\n\t\t\t\t{Name: \"c3\", Value: \"3\"},\n\t\t\t}\n\t\t\tmw := httpclientprovider.ForwardedCookiesMiddleware(forwarded, tc.allowedCookies, tc.disallowedCookies)\n\t\t\topts := httpclient.Options{}\n\t\t\trt := mw.CreateMiddleware(opts, finalRoundTripper)\n\t\t\trequire.NotNil(t, rt)\n\t\t\tmiddlewareName, ok := mw.(httpclient.MiddlewareName)\n\t\t\trequire.True(t, ok)\n\t\t\trequire.Equal(t, \"forwarded-cookies\", middlewareName.MiddlewareName())\n\n\t\t\treq, err := http.NewRequest(http.MethodGet, \"http://\", nil)\n\t\t\trequire.NoError(t, err)\n\t\t\tres, err := rt.RoundTrip(req)\n\t\t\trequire.NoError(t, err)\n\t\t\trequire.NotNil(t, res)\n\t\t\tif res.Body != nil {\n\t\t\t\trequire.NoError(t, res.Body.Close())\n\t\t\t}\n\t\t\trequire.Len(t, ctx.callChain, 1)\n\t\t\trequire.ElementsMatch(t, []string{\"final\"}, ctx.callChain)\n\t\t\trequire.Equal(t, tc.expectedCookieHeader, ctx.req.Header.Get(\"Cookie\"))\n\t\t})", "is_vulnerable": 0}
{"code": "\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tfield, msg, ok := validateWebhook(l, test.webhook)\n\t\t\tassert.Equal(t, test.expOK, ok)\n\t\t\tassert.Equal(t, test.expMsg, msg)\n\t\t\tassert.Equal(t, test.expField, field)\n\t\t})", "is_vulnerable": 0}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn mirror{\n\t\tr:                r,\n\t\tannotationConfig: mirrorAnnotation,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m mockAuth) AuthPlain(username, _ string) ([]string, error) {\n\tids, ok := m.db[username]\n\tif !ok {\n\t\treturn nil, errors.New(\"invalid creds\")\n\t}\n\treturn ids, nil\n}", "is_vulnerable": 1}
{"code": "func (client AccountsClient) CreateSender(req *http.Request) (future AccountsCreateFuture, err error) {\n\tsd := autorest.GetSendDecorators(req.Context(), azure.DoRetryWithRegistration(client.Client))\n\tvar resp *http.Response\n\tresp, err = autorest.SendWithSender(client, req, sd...)\n\tif err != nil {\n\t\treturn\n\t}\n\tfuture.Future, err = azure.NewFutureFromResponse(resp)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func reconnect(w http.ResponseWriter, r *http.Request) {\n\tts := newTestTerminalSession(w, r)\n\t_, _ = ts.reconnect()\n}", "is_vulnerable": 0}
{"code": "func TestValidateEventSource(t *testing.T) {\n\tlistener := &EventListener{}\n\n\terr := listener.ValidateEventSource(context.Background())\n\tassert.Error(t, err)\n\tassert.Equal(t, \"token not provided\", err.Error())\n\n\tcontent, err := ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", sources.EventSourceDir, \"slack.yaml\"))\n\tassert.Nil(t, err)\n\n\tvar eventSource *v1alpha1.EventSource\n\terr = yaml.Unmarshal(content, &eventSource)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, eventSource.Spec.Slack)\n\n\tfor name, value := range eventSource.Spec.Slack {\n\t\tfmt.Println(name)\n\t\tl := &EventListener{\n\t\t\tSlackEventSource: value,\n\t\t}\n\t\terr := l.ValidateEventSource(context.Background())\n\t\tassert.NoError(t, err)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (e errorTranslateQuerier) Select(sortSeries bool, hints *storage.SelectHints, matchers ...*labels.Matcher) storage.SeriesSet {\n\ts := e.q.Select(sortSeries, hints, matchers...)\n\treturn errorTranslateSeriesSet{s: s, fn: e.fn}\n}", "is_vulnerable": 0}
{"code": "func (client Client) CreateOrUpdate(ctx context.Context, resourceGroupName string, resourceProviderNamespace string, parentResourcePath string, resourceType string, resourceName string, parameters GenericResource) (result GenericResource, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/Client.CreateOrUpdate\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.Client\", \"CreateOrUpdate\", err.Error())\n\t}\n\n\treq, err := client.CreateOrUpdatePreparer(ctx, resourceGroupName, resourceProviderNamespace, parentResourcePath, resourceType, resourceName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"CreateOrUpdate\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.CreateOrUpdateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"CreateOrUpdate\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.CreateOrUpdateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.Client\", \"CreateOrUpdate\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration,\n\tkubeDeps *Dependencies,\n\tcrOptions *config.ContainerRuntimeOptions,\n\tcontainerRuntime string,\n\thostnameOverride string,\n\tnodeIP string,\n\tproviderID string,\n\tcloudProvider string,\n\tcertDirectory string,\n\trootDirectory string,\n\tregisterNode bool,\n\tregisterWithTaints []api.Taint,\n\tallowedUnsafeSysctls []string,\n\texperimentalMounterPath string,\n\texperimentalKernelMemcgNotification bool,\n\texperimentalCheckNodeCapabilitiesBeforeMount bool,\n\texperimentalNodeAllocatableIgnoreEvictionThreshold bool,\n\tminimumGCAge metav1.Duration,\n\tmaxPerPodContainerCount int32,\n\tmaxContainerCount int32,\n\tmasterServiceNamespace string,\n\tregisterSchedulable bool,\n\tkeepTerminatedPodVolumes bool,\n\tnodeLabels map[string]string,\n\tseccompProfileRoot string,\n\tbootstrapCheckpointPath string,\n\tnodeStatusMaxImages int32) (*Kubelet, error) {\n\tif rootDirectory == \"\" {\n\t\treturn nil, fmt.Errorf(\"invalid root directory %q\", rootDirectory)\n\t}\n\tif kubeCfg.SyncFrequency.Duration <= 0 {\n\t\treturn nil, fmt.Errorf(\"invalid sync frequency %d\", kubeCfg.SyncFrequency.Duration)\n\t}\n\n\tif kubeCfg.MakeIPTablesUtilChains {\n\t\tif kubeCfg.IPTablesMasqueradeBit > 31 || kubeCfg.IPTablesMasqueradeBit < 0 {\n\t\t\treturn nil, fmt.Errorf(\"iptables-masquerade-bit is not valid. Must be within [0, 31]\")\n\t\t}\n\t\tif kubeCfg.IPTablesDropBit > 31 || kubeCfg.IPTablesDropBit < 0 {\n\t\t\treturn nil, fmt.Errorf(\"iptables-drop-bit is not valid. Must be within [0, 31]\")\n\t\t}\n\t\tif kubeCfg.IPTablesDropBit == kubeCfg.IPTablesMasqueradeBit {\n\t\t\treturn nil, fmt.Errorf(\"iptables-masquerade-bit and iptables-drop-bit must be different\")\n\t\t}\n\t}\n\n\thostname, err := nodeutil.GetHostname(hostnameOverride)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Query the cloud provider for our node name, default to hostname\n\tnodeName := types.NodeName(hostname)\n\tif kubeDeps.Cloud != nil {\n\t\tvar err error\n\t\tinstances, ok := kubeDeps.Cloud.Instances()\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"failed to get instances from cloud provider\")\n\t\t}\n\n\t\tnodeName, err = instances.CurrentNodeName(context.TODO(), hostname)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error fetching current instance name from cloud provider: %v\", err)\n\t\t}\n\n\t\tklog.V(2).Infof(\"cloud provider determined current node name to be %s\", nodeName)\n\t}\n\n\tif kubeDeps.PodConfig == nil {\n\t\tvar err error\n\t\tkubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName, bootstrapCheckpointPath)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tcontainerGCPolicy := kubecontainer.ContainerGCPolicy{\n\t\tMinAge:             minimumGCAge.Duration,\n\t\tMaxPerPodContainer: int(maxPerPodContainerCount),\n\t\tMaxContainers:      int(maxContainerCount),\n\t}\n\n\tdaemonEndpoints := &v1.NodeDaemonEndpoints{\n\t\tKubeletEndpoint: v1.DaemonEndpoint{Port: kubeCfg.Port},\n\t}\n\n\timageGCPolicy := images.ImageGCPolicy{\n\t\tMinAge:               kubeCfg.ImageMinimumGCAge.Duration,\n\t\tHighThresholdPercent: int(kubeCfg.ImageGCHighThresholdPercent),\n\t\tLowThresholdPercent:  int(kubeCfg.ImageGCLowThresholdPercent),\n\t}\n\n\tenforceNodeAllocatable := kubeCfg.EnforceNodeAllocatable\n\tif experimentalNodeAllocatableIgnoreEvictionThreshold {\n\t\t// Do not provide kubeCfg.EnforceNodeAllocatable to eviction threshold parsing if we are not enforcing Evictions\n\t\tenforceNodeAllocatable = []string{}\n\t}\n\tthresholds, err := eviction.ParseThresholdConfig(enforceNodeAllocatable, kubeCfg.EvictionHard, kubeCfg.EvictionSoft, kubeCfg.EvictionSoftGracePeriod, kubeCfg.EvictionMinimumReclaim)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tevictionConfig := eviction.Config{\n\t\tPressureTransitionPeriod: kubeCfg.EvictionPressureTransitionPeriod.Duration,\n\t\tMaxPodGracePeriodSeconds: int64(kubeCfg.EvictionMaxPodGracePeriod),\n\t\tThresholds:               thresholds,\n\t\tKernelMemcgNotification:  experimentalKernelMemcgNotification,\n\t\tPodCgroupRoot:            kubeDeps.ContainerManager.GetPodCgroupRoot(),\n\t}\n\n\tserviceIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc})\n\tif kubeDeps.KubeClient != nil {\n\t\tserviceLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"services\", metav1.NamespaceAll, fields.Everything())\n\t\tr := cache.NewReflector(serviceLW, &v1.Service{}, serviceIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tserviceLister := corelisters.NewServiceLister(serviceIndexer)\n\n\tnodeIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{})\n\tif kubeDeps.KubeClient != nil {\n\t\tfieldSelector := fields.Set{api.ObjectNameField: string(nodeName)}.AsSelector()\n\t\tnodeLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"nodes\", metav1.NamespaceAll, fieldSelector)\n\t\tr := cache.NewReflector(nodeLW, &v1.Node{}, nodeIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tnodeLister := corelisters.NewNodeLister(nodeIndexer)\n\n\t// TODO: get the real node object of ourself,\n\t// and use the real node name and UID.\n\t// TODO: what is namespace for node?\n\tnodeRef := &v1.ObjectReference{\n\t\tKind:      \"Node\",\n\t\tName:      string(nodeName),\n\t\tUID:       types.UID(nodeName),\n\t\tNamespace: \"\",\n\t}\n\n\tcontainerRefManager := kubecontainer.NewRefManager()\n\n\toomWatcher, err := oomwatcher.NewWatcher(kubeDeps.Recorder)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tclusterDNS := make([]net.IP, 0, len(kubeCfg.ClusterDNS))\n\tfor _, ipEntry := range kubeCfg.ClusterDNS {\n\t\tip := net.ParseIP(ipEntry)\n\t\tif ip == nil {\n\t\t\tklog.Warningf(\"Invalid clusterDNS ip '%q'\", ipEntry)\n\t\t} else {\n\t\t\tclusterDNS = append(clusterDNS, ip)\n\t\t}\n\t}\n\thttpClient := &http.Client{}\n\tparsedNodeIP := net.ParseIP(nodeIP)\n\tprotocol := utilipt.ProtocolIpv4\n\tif utilnet.IsIPv6(parsedNodeIP) {\n\t\tklog.V(0).Infof(\"IPv6 node IP (%s), assume IPv6 operation\", nodeIP)\n\t\tprotocol = utilipt.ProtocolIpv6\n\t}\n\n\tklet := &Kubelet{\n\t\thostname:                                hostname,\n\t\thostnameOverridden:                      len(hostnameOverride) > 0,\n\t\tnodeName:                                nodeName,\n\t\tkubeClient:                              kubeDeps.KubeClient,\n\t\theartbeatClient:                         kubeDeps.HeartbeatClient,\n\t\tonRepeatedHeartbeatFailure:              kubeDeps.OnHeartbeatFailure,\n\t\trootDirectory:                           rootDirectory,\n\t\tresyncInterval:                          kubeCfg.SyncFrequency.Duration,\n\t\tsourcesReady:                            config.NewSourcesReady(kubeDeps.PodConfig.SeenAllSources),\n\t\tregisterNode:                            registerNode,\n\t\tregisterWithTaints:                      registerWithTaints,\n\t\tregisterSchedulable:                     registerSchedulable,\n\t\tdnsConfigurer:                           dns.NewConfigurer(kubeDeps.Recorder, nodeRef, parsedNodeIP, clusterDNS, kubeCfg.ClusterDomain, kubeCfg.ResolverConfig),\n\t\tserviceLister:                           serviceLister,\n\t\tnodeLister:                              nodeLister,\n\t\tmasterServiceNamespace:                  masterServiceNamespace,\n\t\tstreamingConnectionIdleTimeout:          kubeCfg.StreamingConnectionIdleTimeout.Duration,\n\t\trecorder:                                kubeDeps.Recorder,\n\t\tcadvisor:                                kubeDeps.CAdvisorInterface,\n\t\tcloud:                                   kubeDeps.Cloud,\n\t\texternalCloudProvider:                   cloudprovider.IsExternal(cloudProvider),\n\t\tproviderID:                              providerID,\n\t\tnodeRef:                                 nodeRef,\n\t\tnodeLabels:                              nodeLabels,\n\t\tnodeStatusUpdateFrequency:               kubeCfg.NodeStatusUpdateFrequency.Duration,\n\t\tnodeStatusReportFrequency:               kubeCfg.NodeStatusReportFrequency.Duration,\n\t\tos:                                      kubeDeps.OSInterface,\n\t\toomWatcher:                              oomWatcher,\n\t\tcgroupsPerQOS:                           kubeCfg.CgroupsPerQOS,\n\t\tcgroupRoot:                              kubeCfg.CgroupRoot,\n\t\tmounter:                                 kubeDeps.Mounter,\n\t\thostutil:                                kubeDeps.HostUtil,\n\t\tsubpather:                               kubeDeps.Subpather,\n\t\tmaxPods:                                 int(kubeCfg.MaxPods),\n\t\tpodsPerCore:                             int(kubeCfg.PodsPerCore),\n\t\tsyncLoopMonitor:                         atomic.Value{},\n\t\tdaemonEndpoints:                         daemonEndpoints,\n\t\tcontainerManager:                        kubeDeps.ContainerManager,\n\t\tcontainerRuntimeName:                    containerRuntime,\n\t\tredirectContainerStreaming:              crOptions.RedirectContainerStreaming,\n\t\tnodeIP:                                  parsedNodeIP,\n\t\tnodeIPValidator:                         validateNodeIP,\n\t\tclock:                                   clock.RealClock{},\n\t\tenableControllerAttachDetach:            kubeCfg.EnableControllerAttachDetach,\n\t\tiptClient:                               utilipt.New(utilexec.New(), protocol),\n\t\tmakeIPTablesUtilChains:                  kubeCfg.MakeIPTablesUtilChains,\n\t\tiptablesMasqueradeBit:                   int(kubeCfg.IPTablesMasqueradeBit),\n\t\tiptablesDropBit:                         int(kubeCfg.IPTablesDropBit),\n\t\texperimentalHostUserNamespaceDefaulting: utilfeature.DefaultFeatureGate.Enabled(features.ExperimentalHostUserNamespaceDefaultingGate),\n\t\tkeepTerminatedPodVolumes:                keepTerminatedPodVolumes,\n\t\tnodeStatusMaxImages:                     nodeStatusMaxImages,\n\t}\n\n\tif klet.cloud != nil {\n\t\tklet.cloudResourceSyncManager = cloudresource.NewSyncManager(klet.cloud, nodeName, klet.nodeStatusUpdateFrequency)\n\t}\n\n\tvar secretManager secret.Manager\n\tvar configMapManager configmap.Manager\n\tswitch kubeCfg.ConfigMapAndSecretChangeDetectionStrategy {\n\tcase kubeletconfiginternal.WatchChangeDetectionStrategy:\n\t\tsecretManager = secret.NewWatchingSecretManager(kubeDeps.KubeClient)\n\t\tconfigMapManager = configmap.NewWatchingConfigMapManager(kubeDeps.KubeClient)\n\tcase kubeletconfiginternal.TTLCacheChangeDetectionStrategy:\n\t\tsecretManager = secret.NewCachingSecretManager(\n\t\t\tkubeDeps.KubeClient, manager.GetObjectTTLFromNodeFunc(klet.GetNode))\n\t\tconfigMapManager = configmap.NewCachingConfigMapManager(\n\t\t\tkubeDeps.KubeClient, manager.GetObjectTTLFromNodeFunc(klet.GetNode))\n\tcase kubeletconfiginternal.GetChangeDetectionStrategy:\n\t\tsecretManager = secret.NewSimpleSecretManager(kubeDeps.KubeClient)\n\t\tconfigMapManager = configmap.NewSimpleConfigMapManager(kubeDeps.KubeClient)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unknown configmap and secret manager mode: %v\", kubeCfg.ConfigMapAndSecretChangeDetectionStrategy)\n\t}\n\n\tklet.secretManager = secretManager\n\tklet.configMapManager = configMapManager\n\n\tif klet.experimentalHostUserNamespaceDefaulting {\n\t\tklog.Infof(\"Experimental host user namespace defaulting is enabled.\")\n\t}\n\n\tmachineInfo, err := klet.cadvisor.MachineInfo()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.machineInfo = machineInfo\n\n\timageBackOff := flowcontrol.NewBackOff(backOffPeriod, MaxContainerBackOff)\n\n\tklet.livenessManager = proberesults.NewManager()\n\tklet.startupManager = proberesults.NewManager()\n\n\tklet.podCache = kubecontainer.NewCache()\n\tvar checkpointManager checkpointmanager.CheckpointManager\n\tif bootstrapCheckpointPath != \"\" {\n\t\tcheckpointManager, err = checkpointmanager.NewCheckpointManager(bootstrapCheckpointPath)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to initialize checkpoint manager: %+v\", err)\n\t\t}\n\t}\n\t// podManager is also responsible for keeping secretManager and configMapManager contents up-to-date.\n\tmirrorPodClient := kubepod.NewBasicMirrorClient(klet.kubeClient, string(nodeName), nodeLister)\n\tklet.podManager = kubepod.NewBasicPodManager(mirrorPodClient, secretManager, configMapManager, checkpointManager)\n\n\tklet.statusManager = status.NewManager(klet.kubeClient, klet.podManager, klet)\n\n\tklet.resourceAnalyzer = serverstats.NewResourceAnalyzer(klet, kubeCfg.VolumeStatsAggPeriod.Duration)\n\n\tklet.dockerLegacyService = kubeDeps.dockerLegacyService\n\tklet.criHandler = kubeDeps.criHandler\n\tklet.runtimeService = kubeDeps.RemoteRuntimeService\n\n\tif utilfeature.DefaultFeatureGate.Enabled(features.RuntimeClass) && kubeDeps.KubeClient != nil {\n\t\tklet.runtimeClassManager = runtimeclass.NewManager(kubeDeps.KubeClient)\n\t}\n\n\truntime, err := kuberuntime.NewKubeGenericRuntimeManager(\n\t\tkubecontainer.FilterEventRecorder(kubeDeps.Recorder),\n\t\tklet.livenessManager,\n\t\tklet.startupManager,\n\t\tseccompProfileRoot,\n\t\tcontainerRefManager,\n\t\tmachineInfo,\n\t\tklet,\n\t\tkubeDeps.OSInterface,\n\t\tklet,\n\t\thttpClient,\n\t\timageBackOff,\n\t\tkubeCfg.SerializeImagePulls,\n\t\tfloat32(kubeCfg.RegistryPullQPS),\n\t\tint(kubeCfg.RegistryBurst),\n\t\tkubeCfg.CPUCFSQuota,\n\t\tkubeCfg.CPUCFSQuotaPeriod,\n\t\tkubeDeps.RemoteRuntimeService,\n\t\tkubeDeps.RemoteImageService,\n\t\tkubeDeps.ContainerManager.InternalContainerLifecycle(),\n\t\tkubeDeps.dockerLegacyService,\n\t\tklet.runtimeClassManager,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.containerRuntime = runtime\n\tklet.streamingRuntime = runtime\n\tklet.runner = runtime\n\n\truntimeCache, err := kubecontainer.NewRuntimeCache(klet.containerRuntime)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.runtimeCache = runtimeCache\n\n\tif kubeDeps.useLegacyCadvisorStats {\n\t\tklet.StatsProvider = stats.NewCadvisorStatsProvider(\n\t\t\tklet.cadvisor,\n\t\t\tklet.resourceAnalyzer,\n\t\t\tklet.podManager,\n\t\t\tklet.runtimeCache,\n\t\t\tklet.containerRuntime,\n\t\t\tklet.statusManager)\n\t} else {\n\t\tklet.StatsProvider = stats.NewCRIStatsProvider(\n\t\t\tklet.cadvisor,\n\t\t\tklet.resourceAnalyzer,\n\t\t\tklet.podManager,\n\t\t\tklet.runtimeCache,\n\t\t\tkubeDeps.RemoteRuntimeService,\n\t\t\tkubeDeps.RemoteImageService,\n\t\t\tstats.NewLogMetricsService(),\n\t\t\tkubecontainer.RealOS{})\n\t}\n\n\tklet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{})\n\tklet.runtimeState = newRuntimeState(maxWaitForContainerRuntime)\n\tklet.runtimeState.addHealthCheck(\"PLEG\", klet.pleg.Healthy)\n\tif _, err := klet.updatePodCIDR(kubeCfg.PodCIDR); err != nil {\n\t\tklog.Errorf(\"Pod CIDR update failed %v\", err)\n\t}\n\n\t// setup containerGC\n\tcontainerGC, err := kubecontainer.NewContainerGC(klet.containerRuntime, containerGCPolicy, klet.sourcesReady)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.containerGC = containerGC\n\tklet.containerDeletor = newPodContainerDeletor(klet.containerRuntime, integer.IntMax(containerGCPolicy.MaxPerPodContainer, minDeadContainerInPod))\n\n\t// setup imageManager\n\timageManager, err := images.NewImageGCManager(klet.containerRuntime, klet.StatsProvider, kubeDeps.Recorder, nodeRef, imageGCPolicy, crOptions.PodSandboxImage)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to initialize image manager: %v\", err)\n\t}\n\tklet.imageManager = imageManager\n\n\tif containerRuntime == kubetypes.RemoteContainerRuntime && utilfeature.DefaultFeatureGate.Enabled(features.CRIContainerLogRotation) {\n\t\t// setup containerLogManager for CRI container runtime\n\t\tcontainerLogManager, err := logs.NewContainerLogManager(\n\t\t\tklet.runtimeService,\n\t\t\tkubeCfg.ContainerLogMaxSize,\n\t\t\tint(kubeCfg.ContainerLogMaxFiles),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to initialize container log manager: %v\", err)\n\t\t}\n\t\tklet.containerLogManager = containerLogManager\n\t} else {\n\t\tklet.containerLogManager = logs.NewStubContainerLogManager()\n\t}\n\n\tif kubeCfg.ServerTLSBootstrap && kubeDeps.TLSOptions != nil && utilfeature.DefaultFeatureGate.Enabled(features.RotateKubeletServerCertificate) {\n\t\tklet.serverCertificateManager, err = kubeletcertificate.NewKubeletServerCertificateManager(klet.kubeClient, kubeCfg, klet.nodeName, klet.getLastObservedNodeAddresses, certDirectory)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to initialize certificate manager: %v\", err)\n\t\t}\n\t\tkubeDeps.TLSOptions.Config.GetCertificate = func(*tls.ClientHelloInfo) (*tls.Certificate, error) {\n\t\t\tcert := klet.serverCertificateManager.Current()\n\t\t\tif cert == nil {\n\t\t\t\treturn nil, fmt.Errorf(\"no serving certificate available for the kubelet\")\n\t\t\t}\n\t\t\treturn cert, nil\n\t\t}\n\t}\n\n\tklet.probeManager = prober.NewManager(\n\t\tklet.statusManager,\n\t\tklet.livenessManager,\n\t\tklet.startupManager,\n\t\tklet.runner,\n\t\tcontainerRefManager,\n\t\tkubeDeps.Recorder)\n\n\ttokenManager := token.NewManager(kubeDeps.KubeClient)\n\n\t// NewInitializedVolumePluginMgr initializes some storageErrors on the Kubelet runtimeState (in csi_plugin.go init)\n\t// which affects node ready status. This function must be called before Kubelet is initialized so that the Node\n\t// ReadyState is accurate with the storage state.\n\tklet.volumePluginMgr, err =\n\t\tNewInitializedVolumePluginMgr(klet, secretManager, configMapManager, tokenManager, kubeDeps.VolumePlugins, kubeDeps.DynamicPluginProber)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.pluginManager = pluginmanager.NewPluginManager(\n\t\tklet.getPluginsRegistrationDir(), /* sockDir */\n\t\tkubeDeps.Recorder,\n\t)\n\n\t// If the experimentalMounterPathFlag is set, we do not want to\n\t// check node capabilities since the mount path is not the default\n\tif len(experimentalMounterPath) != 0 {\n\t\texperimentalCheckNodeCapabilitiesBeforeMount = false\n\t\t// Replace the nameserver in containerized-mounter's rootfs/etc/resolve.conf with kubelet.ClusterDNS\n\t\t// so that service name could be resolved\n\t\tklet.dnsConfigurer.SetupDNSinContainerizedMounter(experimentalMounterPath)\n\t}\n\n\t// setup volumeManager\n\tklet.volumeManager = volumemanager.NewVolumeManager(\n\t\tkubeCfg.EnableControllerAttachDetach,\n\t\tnodeName,\n\t\tklet.podManager,\n\t\tklet.statusManager,\n\t\tklet.kubeClient,\n\t\tklet.volumePluginMgr,\n\t\tklet.containerRuntime,\n\t\tkubeDeps.Mounter,\n\t\tkubeDeps.HostUtil,\n\t\tklet.getPodsDir(),\n\t\tkubeDeps.Recorder,\n\t\texperimentalCheckNodeCapabilitiesBeforeMount,\n\t\tkeepTerminatedPodVolumes,\n\t\tvolumepathhandler.NewBlockVolumePathHandler())\n\n\tklet.reasonCache = NewReasonCache()\n\tklet.workQueue = queue.NewBasicWorkQueue(klet.clock)\n\tklet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue, klet.resyncInterval, backOffPeriod, klet.podCache)\n\n\tklet.backOff = flowcontrol.NewBackOff(backOffPeriod, MaxContainerBackOff)\n\tklet.podKillingCh = make(chan *kubecontainer.PodPair, podKillingChannelCapacity)\n\n\t// setup eviction manager\n\tevictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.podManager.GetMirrorPodByPod, klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock)\n\n\tklet.evictionManager = evictionManager\n\tklet.admitHandlers.AddPodAdmitHandler(evictionAdmitHandler)\n\n\tif utilfeature.DefaultFeatureGate.Enabled(features.Sysctls) {\n\t\t// Safe, whitelisted sysctls can always be used as unsafe sysctls in the spec.\n\t\t// Hence, we concatenate those two lists.\n\t\tsafeAndUnsafeSysctls := append(sysctlwhitelist.SafeSysctlWhitelist(), allowedUnsafeSysctls...)\n\t\tsysctlsWhitelist, err := sysctl.NewWhitelist(safeAndUnsafeSysctls)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tklet.admitHandlers.AddPodAdmitHandler(sysctlsWhitelist)\n\t}\n\n\t// enable active deadline handler\n\tactiveDeadlineHandler, err := newActiveDeadlineHandler(klet.statusManager, kubeDeps.Recorder, klet.clock)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tklet.AddPodSyncLoopHandler(activeDeadlineHandler)\n\tklet.AddPodSyncHandler(activeDeadlineHandler)\n\n\tklet.admitHandlers.AddPodAdmitHandler(klet.containerManager.GetAllocateResourcesPodAdmitHandler())\n\n\tcriticalPodAdmissionHandler := preemption.NewCriticalPodAdmissionHandler(klet.GetActivePods, killPodNow(klet.podWorkers, kubeDeps.Recorder), kubeDeps.Recorder)\n\tklet.admitHandlers.AddPodAdmitHandler(lifecycle.NewPredicateAdmitHandler(klet.getNodeAnyWay, criticalPodAdmissionHandler, klet.containerManager.UpdatePluginResources))\n\t// apply functional Option's\n\tfor _, opt := range kubeDeps.Options {\n\t\topt(klet)\n\t}\n\n\tklet.appArmorValidator = apparmor.NewValidator(containerRuntime)\n\tklet.softAdmitHandlers.AddPodAdmitHandler(lifecycle.NewAppArmorAdmitHandler(klet.appArmorValidator))\n\tklet.softAdmitHandlers.AddPodAdmitHandler(lifecycle.NewNoNewPrivsAdmitHandler(klet.containerRuntime))\n\tklet.softAdmitHandlers.AddPodAdmitHandler(lifecycle.NewProcMountAdmitHandler(klet.containerRuntime))\n\n\tklet.nodeLeaseController = nodelease.NewController(klet.clock, klet.heartbeatClient, string(klet.nodeName), kubeCfg.NodeLeaseDurationSeconds, klet.onRepeatedHeartbeatFailure)\n\n\t// Finally, put the most recent version of the config on the Kubelet, so\n\t// people can see how it was configured.\n\tklet.kubeletConfiguration = *kubeCfg\n\n\t// Generating the status funcs should be the last thing we do,\n\t// since this relies on the rest of the Kubelet having been constructed.\n\tklet.setNodeStatusFuncs = klet.defaultNodeStatusFuncs()\n\n\treturn klet, nil\n}", "is_vulnerable": 1}
{"code": "func TestHttpGetter__XTerraformGetConfiguredGettersBypass(t *testing.T) {\n\ttc := []struct {\n\t\tname              string\n\t\tconfiguredGetters []Getter\n\t\terrExpected       bool\n\t}{\n\t\t{name: \"configured getter for git protocol switch\", configuredGetters: []Getter{new(GitGetter)}, errExpected: false},\n\t\t{name: \"configured getter for multiple protocol switch\", configuredGetters: []Getter{new(GitGetter), new(HgGetter), new(FileGetter)}, errExpected: false},\n\t\t{name: \"configured getter for file protocol switch\", configuredGetters: []Getter{new(FileGetter)}, errExpected: true},\n\t}\n\n\tfor _, tt := range tc {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tctx, cancel := context.WithCancel(context.Background())\n\t\t\tdefer cancel()\n\n\t\t\tln := testHttpServerWithXTerraformGetConfiguredGettersBypass(t)\n\n\t\t\tvar u url.URL\n\t\t\tu.Scheme = \"http\"\n\t\t\tu.Host = ln.Addr().String()\n\t\t\tu.Path = \"/start\"\n\n\t\t\tdst := testing_helper.TempDir(t)\n\n\t\t\trt := hookableHTTPRoundTripper{\n\t\t\t\tbefore: func(req *http.Request) {\n\t\t\t\t\tt.Logf(\"making request\")\n\t\t\t\t},\n\t\t\t\tRoundTripper: http.DefaultTransport,\n\t\t\t}\n\n\t\t\tg := new(HttpGetter)\n\t\t\tg.XTerraformGetLimit = 10\n\t\t\tg.Client = &http.Client{\n\t\t\t\tTransport: &rt,\n\t\t\t}\n\n\t\t\tclient := &Client{\n\t\t\t\tGetters: []Getter{g},\n\t\t\t}\n\t\t\tclient.Getters = append(client.Getters, tt.configuredGetters...)\n\n\t\t\tt.Logf(\"%v\", u.String())\n\n\t\t\treq := Request{\n\t\t\t\tDst:     dst,\n\t\t\t\tSrc:     u.String(),\n\t\t\t\tGetMode: ModeDir,\n\t\t\t}\n\n\t\t\t_, err := client.Get(ctx, &req)\n\t\t\t// For configured getters that support git, the git repository doesn't exist so error will not be nil.\n\t\t\t// If we get a nil error when we expect one other than the git error git exited with -1 we should fail.\n\t\t\tif tt.errExpected && err == nil {\n\t\t\t\tt.Fatalf(\"error expected\")\n\t\t\t}\n\t\t\t// We only care about the error messages that indicate that we can download the git header URL\n\t\t\tif tt.errExpected && err != nil {\n\t\t\t\tif !strings.Contains(err.Error(), \"download not supported for scheme\") {\n\t\t\t\t\tt.Fatalf(\"expected download not supported for scheme, got: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockRequester) GetGrantedScopes() fosite.Arguments {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetGrantedScopes\")\n\tret0, _ := ret[0].(fosite.Arguments)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (j *JuiceFSEngine) transformFuse(runtime *datav1alpha1.JuiceFSRuntime, dataset *datav1alpha1.Dataset, value *JuiceFS) (err error) {\n\tif len(dataset.Spec.Mounts) <= 0 {\n\t\treturn errors.New(\"do not assign mount point\")\n\t}\n\tmount := dataset.Spec.Mounts[0]\n\n\tvalue.Configs.Name = security.EscapeBashStr(mount.Name)\n\n\t// transform image\n\timage := runtime.Spec.Fuse.Image\n\ttag := runtime.Spec.Fuse.ImageTag\n\timagePullPolicy := runtime.Spec.Fuse.ImagePullPolicy\n\tvalue.Fuse.Image, value.Fuse.ImageTag, value.Fuse.ImagePullPolicy = j.parseFuseImage(image, tag, imagePullPolicy)\n\n\t// transform envs\n\tvalue.Fuse.Envs = runtime.Spec.Fuse.Env\n\n\t// transform options\n\tvar tiredStoreLevel *datav1alpha1.Level\n\tif len(runtime.Spec.TieredStore.Levels) != 0 {\n\t\ttiredStoreLevel = &runtime.Spec.TieredStore.Levels[0]\n\t}\n\toption, err := j.genValue(mount, tiredStoreLevel, value, dataset.Spec.SharedOptions, dataset.Spec.SharedEncryptOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform format cmd\n\tj.genFormatCmd(value, runtime.Spec.Configs)\n\n\t// transform quota cmd\n\terr = j.genQuotaCmd(value, mount)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform mount cmd & stat cmd\n\terr = j.genMount(value, runtime, option)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// transform nodeSelector\n\tj.transformFuseNodeSelector(runtime, value)\n\tvalue.Fuse.Enabled = true\n\n\t// transform resource\n\terr = j.transformResourcesForFuse(runtime, value)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// transform volumes for fuse\n\terr = j.transformFuseVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform volumes for fuse\")\n\t\treturn err\n\t}\n\t// transform cache volumes for fuse\n\terr = j.transformFuseCacheVolumes(runtime, value)\n\tif err != nil {\n\t\tj.Log.Error(err, \"failed to transform cache volumes for fuse\")\n\t\treturn err\n\t}\n\n\t// set critical fuse pod to avoid eviction\n\tvalue.Fuse.CriticalPod = common.CriticalFusePodEnabled()\n\n\t// parse fuse container network mode\n\tvalue.Fuse.HostNetwork = datav1alpha1.IsHostNetwork(runtime.Spec.Fuse.NetworkMode)\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (m *mockSignableTemplate) GetFileImports() []string {\n\treturn m.imports\n}", "is_vulnerable": 0}
{"code": "func ProfilePath() (string, error) {\n\tif cfgDir := os.Getenv(\"AZURE_CONFIG_DIR\"); cfgDir != \"\" {\n\t\treturn filepath.Join(cfgDir, azureProfileJSON), nil\n\t}\n\treturn homedir.Expand(\"~/.azure/\" + azureProfileJSON)\n}", "is_vulnerable": 0}
{"code": "func NotEmptyf(t TestingT, object interface{}, msg string, args ...interface{}) {\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tif assert.NotEmptyf(t, object, msg, args...) {\n\t\treturn\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 0}
{"code": "func TestSignWithTimestamp(t *testing.T) {\n\tt.Skip(\"Skipping testing as we dont have timestamping hooked up\")\n\t// prepare signer\n\tfor _, envelopeType := range signature.RegisteredEnvelopeTypes() {\n\t\tfor _, keyCert := range keyCertPairCollections {\n\t\t\tt.Run(fmt.Sprintf(\"envelopeType=%v_keySpec=%v\", envelopeType, keyCert.keySpecName), func(t *testing.T) {\n\t\t\t\ts, err := New(keyCert.key, keyCert.certs)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"NewSigner() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// configure TSA\n\t\t\t\ttsa, err := timestamptest.NewTSA()\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"timestamptest.NewTSA() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// sign content\n\t\t\t\tctx := context.Background()\n\t\t\t\tdesc, sOpts := generateSigningContent(tsa)\n\t\t\t\tsOpts.SignatureMediaType = envelopeType\n\t\t\t\tsig, _, err := s.Sign(ctx, desc, sOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Sign() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// basic verification\n\t\t\t\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], &validMetadata)\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func HTTPSuccessf(t TestingT, handler http.HandlerFunc, method string, url string, values url.Values, msg string, args ...interface{}) {\n\tif assert.HTTPSuccessf(t, handler, method, url, values, msg, args...) {\n\t\treturn\n\t}\n\tif h, ok := t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tt.FailNow()\n}", "is_vulnerable": 1}
{"code": "\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tRepositories: []v1alpha1.OwnedRepositories{\n\t\t\t\t\t{\n\t\t\t\t\t\tOwner: \"fake\",\n\t\t\t\t\t\tNames: []string{\n\t\t\t\t\t\t\t\"fake0\", \"fake1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: io.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})", "is_vulnerable": 0}
{"code": "func (m *Wilson) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Wilson: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Wilson: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Int64\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowCasttype\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Int64 = &v\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipCasttype(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthCasttype\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func TestCustomField(t *testing.T) {\n\t// XXX has global effect!!!\n\tjws.RegisterCustomField(`x-birthday`, time.Time{})\n\tdefer jws.RegisterCustomField(`x-birthday`, nil)\n\n\texpected := time.Date(2015, 11, 4, 5, 12, 52, 0, time.UTC)\n\tbdaybytes, _ := expected.MarshalText() // RFC3339\n\n\tpayload := \"Hello, World!\"\n\tprivkey, err := jwxtest.GenerateRsaJwk()\n\trequire.NoError(t, err, `jwxtest.GenerateRsaJwk() should succeed`)\n\n\thdrs := jws.NewHeaders()\n\thdrs.Set(`x-birthday`, string(bdaybytes))\n\n\tsigned, err := jws.Sign([]byte(payload), jws.WithKey(jwa.RS256, privkey, jws.WithProtectedHeaders(hdrs)))\n\trequire.NoError(t, err, `jws.Sign should succeed`)\n\n\tt.Run(\"jws.Parse + json.Unmarshal\", func(t *testing.T) {\n\t\tmsg, err := jws.Parse(signed)\n\t\trequire.NoError(t, err, `jws.Parse should succeed`)\n\n\t\tv, ok := msg.Signatures()[0].ProtectedHeaders().Get(`x-birthday`)\n\t\trequire.True(t, ok, `msg.Signatures()[0].ProtectedHeaders().Get(\"x-birthday\") should succeed`)\n\t\trequire.Equal(t, expected, v, `values should match`)\n\n\t\t// Create JSON from jws.Message\n\t\tbuf, err := json.Marshal(msg)\n\t\trequire.NoError(t, err, `json.Marshal should succeed`)\n\n\t\tvar msg2 jws.Message\n\t\trequire.NoError(t, json.Unmarshal(buf, &msg2), `json.Unmarshal should succeed`)\n\n\t\tv, ok = msg2.Signatures()[0].ProtectedHeaders().Get(`x-birthday`)\n\t\trequire.True(t, ok, `msg2.Signatures()[0].ProtectedHeaders().Get(\"x-birthday\") should succeed`)\n\t\trequire.Equal(t, expected, v, `values should match`)\n\t})\n}", "is_vulnerable": 0}
{"code": "func (p *Permissions) Validate(vr *ValidationResults) {\n\tp.Pub.Validate(vr)\n\tp.Sub.Validate(vr)\n\tif p.Resp != nil {\n\t\tp.Resp.Validate(vr)\n\t}\n}", "is_vulnerable": 1}
{"code": "func extractZipArchiveFile(file *zip.File, dest string, input io.Reader) error {\n\tfilePath := filepath.Join(dest, file.Name)\n\tfileInfo := file.FileInfo()\n\n\tif fileInfo.IsDir() {\n\t\terr := os.MkdirAll(filePath, fileInfo.Mode())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\terr := os.MkdirAll(filepath.Dir(filePath), 0755)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif fileInfo.Mode()&os.ModeSymlink != 0 {\n\t\t\tlinkName, err := ioutil.ReadAll(input)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn os.Symlink(string(linkName), filePath)\n\t\t}\n\n\t\tfileCopy, err := os.OpenFile(filePath, os.O_RDWR|os.O_CREATE|os.O_TRUNC, fileInfo.Mode())\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer fileCopy.Close()\n\n\t\t_, err = io.Copy(fileCopy, input)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func newTestCache(ttl time.Duration) (*Cache, *ResponseWriter) {\n\tc := New()\n\tc.pttl = ttl\n\tc.nttl = ttl\n\n\tcrr := &ResponseWriter{ResponseWriter: nil, Cache: c}\n\tcrr.nexcept = []string{\"neg-disabled.example.org.\"}\n\tcrr.pexcept = []string{\"pos-disabled.example.org.\"}\n\n\treturn c, crr\n}", "is_vulnerable": 0}
{"code": "func ParseMetadata(data []byte) (*saml.EntityDescriptor, error) {\n\tentity := &saml.EntityDescriptor{}\n\n\tif err := xrv.Validate(bytes.NewBuffer(data)); err != nil {\n\t\treturn nil, err\n\t}\n\n\terr := xml.Unmarshal(data, entity)\n\n\t// this comparison is ugly, but it is how the error is generated in encoding/xml\n\tif err != nil && err.Error() == \"expected element type <EntityDescriptor> but have <EntitiesDescriptor>\" {\n\t\tentities := &saml.EntitiesDescriptor{}\n\t\tif err := xml.Unmarshal(data, entities); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tfor i, e := range entities.EntityDescriptors {\n\t\t\tif len(e.IDPSSODescriptors) > 0 {\n\t\t\t\treturn &entities.EntityDescriptors[i], nil\n\t\t\t}\n\t\t}\n\t\treturn nil, errors.New(\"no entity found with IDPSSODescriptor\")\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn entity, nil\n}", "is_vulnerable": 0}
{"code": "func (s *nodeStack) contains(a atom.Atom) bool {\n\tfor _, n := range *s {\n\t\tif n.DataAtom == a {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "is_vulnerable": 0}
{"code": "func (ns *nodeServer) NodeUnstageVolume(ctx context.Context, req *csi.NodeUnstageVolumeRequest) (*csi.NodeUnstageVolumeResponse, error) {\n\t// The lock is to ensure CSI plugin labels the node in correct order\n\tns.mutex.Lock()\n\tdefer ns.mutex.Unlock()\n\n\t// 1. get runtime namespace and name\n\t// A nil volumeContext is passed because unlike csi.NodeStageVolumeRequest, csi.NodeUnstageVolumeRequest has\n\t// no volume context attribute.\n\tnamespace, name, err := ns.getRuntimeNamespacedName(nil, req.GetVolumeId())\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: can't get runtime namespace and name given (volumeContext: nil, volumeId: %s): %v\", req.GetVolumeId(), err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: can't get namespace and name by volume id %s\", req.GetVolumeId())\n\t}\n\n\t// 2. Check fuse clean policy. If clean policy is set to OnRuntimeDeleted, there is no\n\t// need to clean fuse eagerly.\n\truntimeInfo, err := base.GetRuntimeInfo(ns.client, name, namespace)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"NodeUnstageVolume: can't get fuse clean policy\")\n\t}\n\n\tvar shouldCleanFuse bool\n\tcleanPolicy := runtimeInfo.GetFuseCleanPolicy()\n\tglog.Infof(\"Using %s clean policy for runtime %s in namespace %s\", cleanPolicy, runtimeInfo.GetName(), runtimeInfo.GetNamespace())\n\tswitch cleanPolicy {\n\tcase v1alpha1.OnDemandCleanPolicy:\n\t\tshouldCleanFuse = true\n\tcase v1alpha1.OnRuntimeDeletedCleanPolicy:\n\t\tshouldCleanFuse = false\n\tdefault:\n\t\treturn nil, errors.Errorf(\"Unknown Fuse clean policy: %s\", cleanPolicy)\n\t}\n\n\tif !shouldCleanFuse {\n\t\treturn &csi.NodeUnstageVolumeResponse{}, nil\n\t}\n\n\t// 3. check if the path is mounted\n\tinUse, err := checkMountInUse(req.GetVolumeId())\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"NodeUnstageVolume: can't check mount in use\")\n\t}\n\tif inUse {\n\t\treturn nil, fmt.Errorf(\"NodeUnstageVolume: can't stop fuse cause it's in use\")\n\t}\n\n\t// 4. remove label on node\n\t// Once the label is removed, fuse pod on corresponding node will be terminated\n\t// since node selector in the fuse daemonSet no longer matches.\n\t// TODO: move all the label keys into a util func\n\tfuseLabelKey := common.LabelAnnotationFusePrefix + namespace + \"-\" + name\n\tvar labelsToModify common.LabelsToModify\n\tlabelsToModify.Delete(fuseLabelKey)\n\n\tnode, err := ns.getNode()\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: can't get node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: can't get node %s\", ns.nodeId)\n\t}\n\n\t// _, err = utils.ChangeNodeLabelWithPatchMode(ns.client, node, labelsToModify)\n\terr = ns.patchNodeWithLabel(node, labelsToModify)\n\tif err != nil {\n\t\tglog.Errorf(\"NodeUnstageVolume: error when patching labels on node %s: %v\", ns.nodeId, err)\n\t\treturn nil, errors.Wrapf(err, \"NodeUnstageVolume: error when patching labels on node %s\", ns.nodeId)\n\t}\n\n\treturn &csi.NodeUnstageVolumeResponse{}, nil\n}", "is_vulnerable": 0}
{"code": "func TestSignWithoutExpiry(t *testing.T) {\n\t// sign with key\n\tfor _, envelopeType := range signature.RegisteredEnvelopeTypes() {\n\t\tfor _, keyCert := range keyCertPairCollections {\n\t\t\tt.Run(fmt.Sprintf(\"envelopeType=%v_keySpec=%v\", envelopeType, keyCert.keySpecName), func(t *testing.T) {\n\t\t\t\ts, err := New(keyCert.key, keyCert.certs)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"NewSigner() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\tctx := context.Background()\n\t\t\t\tdesc, sOpts := generateSigningContent(nil)\n\t\t\t\tsOpts.ExpiryDuration = 0 // reset expiry\n\t\t\t\tsOpts.SignatureMediaType = envelopeType\n\t\t\t\tsig, _, err := s.Sign(ctx, desc, sOpts)\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(\"Sign() error = %v\", err)\n\t\t\t\t}\n\n\t\t\t\t// basic verification\n\t\t\t\tbasicVerification(t, sig, envelopeType, keyCert.certs[len(keyCert.certs)-1], nil)\n\t\t\t})\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func TestIngressAuthInvalidSecretKey(t *testing.T) {\n\ting := buildIngress()\n\n\tdata := map[string]string{}\n\tdata[parser.GetAnnotationWithPrefix(\"auth-type\")] = \"basic\"\n\tdata[parser.GetAnnotationWithPrefix(\"auth-secret\")] = \"demo-secret\"\n\tdata[parser.GetAnnotationWithPrefix(\"auth-secret-type\")] = \"invalid-type\"\n\tdata[parser.GetAnnotationWithPrefix(\"auth-realm\")] = \"-realm-\"\n\ting.SetAnnotations(data)\n\n\t_, dir, _ := dummySecretContent(t)\n\tdefer os.RemoveAll(dir)\n\n\t_, err := NewParser(dir, mockSecret{}).Parse(ing)\n\tif err == nil {\n\t\tt.Errorf(\"expected an error with invalid secret name\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func RunDashboard() {\n\tdashboardVersion := flag.Bool(\"version\", false, \"Prints the dashboard version\")\n\tport := flag.Int(\"port\", 8080, \"Port to listen to\")\n\n\tflag.Parse()\n\n\tif *dashboardVersion {\n\t\tfmt.Println(version.GetVersion())\n\t\tos.Exit(0)\n\t} else {\n\t\tRunWebServer(*port)\n\t}\n}", "is_vulnerable": 1}
{"code": "\tdoStart = func() {\n\t\tmlog.Debug(\"Hub is starting\", mlog.Int(\"index\", h.connectionIndex))\n\n\t\tticker := time.NewTicker(inactiveConnReaperInterval)\n\t\tdefer ticker.Stop()\n\n\t\tconnIndex := newHubConnectionIndex(inactiveConnReaperInterval)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase webSessionMessage := <-h.checkRegistered:\n\t\t\t\tconns := connIndex.ForUser(webSessionMessage.userID)\n\t\t\t\tvar isRegistered bool\n\t\t\t\tfor _, conn := range conns {\n\t\t\t\t\tif !conn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif conn.GetSessionToken() == webSessionMessage.sessionToken {\n\t\t\t\t\t\tisRegistered = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\twebSessionMessage.isRegistered <- isRegistered\n\t\t\tcase req := <-h.checkConn:\n\t\t\t\tvar res *CheckConnResult\n\t\t\t\tconn := connIndex.RemoveInactiveByConnectionID(req.userID, req.connectionID)\n\t\t\t\tif conn != nil {\n\t\t\t\t\tres = &CheckConnResult{\n\t\t\t\t\t\tConnectionID:     req.connectionID,\n\t\t\t\t\t\tUserID:           req.userID,\n\t\t\t\t\t\tActiveQueue:      conn.send,\n\t\t\t\t\t\tDeadQueue:        conn.deadQueue,\n\t\t\t\t\t\tDeadQueuePointer: conn.deadQueuePointer,\n\t\t\t\t\t\tReuseCount:       conn.reuseCount + 1,\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treq.result <- res\n\t\t\tcase <-ticker.C:\n\t\t\t\tconnIndex.RemoveInactiveConnections()\n\t\t\tcase webConn := <-h.register:\n\t\t\t\t// Mark the current one as active.\n\t\t\t\t// There is no need to check if it was inactive or not,\n\t\t\t\t// we will anyways need to make it active.\n\t\t\t\twebConn.active.Store(true)\n\n\t\t\t\tconnIndex.Add(webConn)\n\t\t\t\tatomic.StoreInt64(&h.connectionCount, int64(connIndex.AllActive()))\n\n\t\t\t\tif webConn.IsAuthenticated() && webConn.reuseCount == 0 {\n\t\t\t\t\t// The hello message should only be sent when the reuseCount is 0.\n\t\t\t\t\t// i.e in server restart, or long timeout, or fresh connection case.\n\t\t\t\t\t// In case of seq number not found in dead queue, it is handled by\n\t\t\t\t\t// the webconn write pump.\n\t\t\t\t\twebConn.send <- webConn.createHelloMessage()\n\t\t\t\t}\n\t\t\tcase webConn := <-h.unregister:\n\t\t\t\t// If already removed (via queue full), then removing again becomes a noop.\n\t\t\t\t// But if not removed, mark inactive.\n\t\t\t\twebConn.active.Store(false)\n\n\t\t\t\tatomic.StoreInt64(&h.connectionCount, int64(connIndex.AllActive()))\n\n\t\t\t\tif webConn.UserId == \"\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tconns := connIndex.ForUser(webConn.UserId)\n\t\t\t\tif len(conns) == 0 || areAllInactive(conns) {\n\t\t\t\t\tuserID := webConn.UserId\n\t\t\t\t\th.platform.Go(func() {\n\t\t\t\t\t\th.platform.SetStatusOffline(userID, false)\n\t\t\t\t\t})\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tvar latestActivity int64\n\t\t\t\tfor _, conn := range conns {\n\t\t\t\t\tif !conn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif conn.lastUserActivityAt > latestActivity {\n\t\t\t\t\t\tlatestActivity = conn.lastUserActivityAt\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif h.platform.isUserAway(latestActivity) {\n\t\t\t\t\tuserID := webConn.UserId\n\t\t\t\t\th.platform.Go(func() {\n\t\t\t\t\t\th.platform.SetStatusLastActivityAt(userID, latestActivity)\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\tcase userID := <-h.invalidateUser:\n\t\t\t\tfor _, webConn := range connIndex.ForUser(userID) {\n\t\t\t\t\twebConn.InvalidateCache()\n\t\t\t\t}\n\t\t\tcase activity := <-h.activity:\n\t\t\t\tfor _, webConn := range connIndex.ForUser(activity.userID) {\n\t\t\t\t\tif !webConn.active.Load() {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif webConn.GetSessionToken() == activity.sessionToken {\n\t\t\t\t\t\twebConn.lastUserActivityAt = activity.activityAt\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase directMsg := <-h.directMsg:\n\t\t\t\tif !connIndex.Has(directMsg.conn) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tselect {\n\t\t\t\tcase directMsg.conn.send <- directMsg.msg:\n\t\t\t\tdefault:\n\t\t\t\t\t// Don't log the warning if it's an inactive connection.\n\t\t\t\t\tif directMsg.conn.active.Load() {\n\t\t\t\t\t\tmlog.Error(\"webhub.broadcast: cannot send, closing websocket for user\",\n\t\t\t\t\t\t\tmlog.String(\"user_id\", directMsg.conn.UserId),\n\t\t\t\t\t\t\tmlog.String(\"conn_id\", directMsg.conn.GetConnectionID()))\n\t\t\t\t\t}\n\t\t\t\t\tclose(directMsg.conn.send)\n\t\t\t\t\tconnIndex.Remove(directMsg.conn)\n\t\t\t\t}\n\t\t\tcase msg := <-h.broadcast:\n\t\t\t\tif metrics := h.platform.metricsIFace; metrics != nil {\n\t\t\t\t\tmetrics.DecrementWebSocketBroadcastBufferSize(strconv.Itoa(h.connectionIndex), 1)\n\t\t\t\t}\n\n\t\t\t\t// Remove the broadcast hook information before precomputing the JSON so that those aren't included in it\n\t\t\t\tmsg, broadcastHooks, broadcastHookArgs := msg.WithoutBroadcastHooks()\n\n\t\t\t\tmsg = msg.PrecomputeJSON()\n\n\t\t\t\tbroadcast := func(webConn *WebConn) {\n\t\t\t\t\tif !connIndex.Has(webConn) {\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tif webConn.ShouldSendEvent(msg) {\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase webConn.send <- h.runBroadcastHooks(msg, webConn, broadcastHooks, broadcastHookArgs):\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t// Don't log the warning if it's an inactive connection.\n\t\t\t\t\t\t\tif webConn.active.Load() {\n\t\t\t\t\t\t\t\tmlog.Error(\"webhub.broadcast: cannot send, closing websocket for user\",\n\t\t\t\t\t\t\t\t\tmlog.String(\"user_id\", webConn.UserId),\n\t\t\t\t\t\t\t\t\tmlog.String(\"conn_id\", webConn.GetConnectionID()))\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tclose(webConn.send)\n\t\t\t\t\t\t\tconnIndex.Remove(webConn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif connID := msg.GetBroadcast().ConnectionId; connID != \"\" {\n\t\t\t\t\tif webConn := connIndex.byConnectionId[connID]; webConn != nil {\n\t\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t} else if msg.GetBroadcast().UserId != \"\" {\n\t\t\t\t\tcandidates := connIndex.ForUser(msg.GetBroadcast().UserId)\n\t\t\t\t\tfor _, webConn := range candidates {\n\t\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tcandidates := connIndex.All()\n\t\t\t\tfor webConn := range candidates {\n\t\t\t\t\tbroadcast(webConn)\n\t\t\t\t}\n\t\t\tcase <-h.stop:\n\t\t\t\tfor webConn := range connIndex.All() {\n\t\t\t\t\twebConn.Close()\n\t\t\t\t\th.platform.SetStatusOffline(webConn.UserId, false)\n\t\t\t\t}\n\n\t\t\t\th.explicitStop = true\n\t\t\t\tclose(h.didStop)\n\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}", "is_vulnerable": 0}
{"code": "func runUpdateSnapshotClassTests(t *testing.T, tests []controllerTest, snapshotClasses []*crdv1.VolumeSnapshotClass) {\n\tsnapshotscheme.AddToScheme(scheme.Scheme)\n\tfor _, test := range tests {\n\t\tklog.V(4).Infof(\"starting test %q\", test.name)\n\n\t\t// Initialize the controller\n\t\tkubeClient := &kubefake.Clientset{}\n\t\tclient := &fake.Clientset{}\n\n\t\tctrl, err := newTestController(kubeClient, client, nil, t, test)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Test %q construct test controller failed: %v\", test.name, err)\n\t\t}\n\n\t\treactor := newSnapshotReactor(kubeClient, client, ctrl, nil, nil, test.errors)\n\t\tfor _, snapshot := range test.initialSnapshots {\n\t\t\tctrl.snapshotStore.Add(snapshot)\n\t\t\treactor.snapshots[snapshot.Name] = snapshot\n\t\t}\n\t\tfor _, content := range test.initialContents {\n\t\t\tctrl.contentStore.Add(content)\n\t\t\treactor.contents[content.Name] = content\n\t\t}\n\n\t\tpvcIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{})\n\t\tfor _, claim := range test.initialClaims {\n\t\t\treactor.claims[claim.Name] = claim\n\t\t\tpvcIndexer.Add(claim)\n\t\t}\n\t\tctrl.pvcLister = corelisters.NewPersistentVolumeClaimLister(pvcIndexer)\n\n\t\tfor _, volume := range test.initialVolumes {\n\t\t\treactor.volumes[volume.Name] = volume\n\t\t}\n\t\tfor _, storageClass := range test.initialStorageClasses {\n\t\t\treactor.storageClasses[storageClass.Name] = storageClass\n\t\t}\n\t\tfor _, secret := range test.initialSecrets {\n\t\t\treactor.secrets[secret.Name] = secret\n\t\t}\n\n\t\t// Inject classes into controller via a custom lister.\n\t\tindexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{})\n\t\tfor _, class := range snapshotClasses {\n\t\t\tindexer.Add(class)\n\t\t\treactor.snapshotClasses[class.Name] = class\n\n\t\t}\n\t\tctrl.classLister = storagelisters.NewVolumeSnapshotClassLister(indexer)\n\n\t\t// Run the tested functions\n\t\terr = test.test(ctrl, reactor, test)\n\t\tif err != nil && isTestError(err) {\n\t\t\tt.Errorf(\"Test %q failed: %v\", test.name, err)\n\t\t}\n\t\tif test.expectSuccess && err != nil {\n\t\t\tt.Errorf(\"Test %q failed: %v\", test.name, err)\n\t\t}\n\n\t\t// Verify UpdateSnapshotClass tests results\n\t\tevaluateTestResults(ctrl, reactor, test, t)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *MockAccessRequester) GetSession() fosite.Session {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"GetSession\")\n\tret0, _ := ret[0].(fosite.Session)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func returnStack(s *Stack) {\n\ts.data = s.data[:0]\n\tstackPool.Put(s)\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetEngineInfo(proto Protocol, fileName, homeDir string) error {\n\tvar cfn, chome *C.char\n\tif fileName != \"\" {\n\t\tcfn = C.CString(fileName)\n\t\tdefer C.free(unsafe.Pointer(cfn))\n\t}\n\tif homeDir != \"\" {\n\t\tchome = C.CString(homeDir)\n\t\tdefer C.free(unsafe.Pointer(chome))\n\t}\n\terr := handleError(C.gpgme_ctx_set_engine_info(c.ctx, C.gpgme_protocol_t(proto), cfn, chome))\n\truntime.KeepAlive(c)\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func (src *AuthenticationSASLContinue) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'R')\n\tdst = pgio.AppendUint32(dst, AuthTypeSASLContinue)\n\tdst = append(dst, src.Data...)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func buildPartial(owner common.Hash, db ethdb.KeyValueReader, batch ethdb.Batch, entries []*kv, first, last int) *replayer {\n\ttr := newPathTrie(owner, first != 0, db, batch)\n\tfor i := first; i <= last; i++ {\n\t\ttr.update(entries[i].k, entries[i].v)\n\t}\n\ttr.commit(last == len(entries)-1)\n\n\treplay := newBatchReplay()\n\tbatch.Replay(replay)\n\n\treturn replay\n}", "is_vulnerable": 0}
{"code": "func TestMetadataValidatesUrlSchemeForProtocolBinding(t *testing.T) {\n\tbuf := golden.Get(t, \"TestMetadataValidatesUrlSchemeForProtocolBinding_metadata.xml\")\n\n\tmetadata := EntityDescriptor{}\n\terr := xml.Unmarshal(buf, &metadata)\n\tassert.Error(t, err, \"invalid url scheme \\\"javascript\\\" for binding \\\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\\\"\")\n}", "is_vulnerable": 0}
{"code": "func (a *ActivationClaims) Validate(vr *ValidationResults) {\n\ta.ClaimsData.Validate(vr)\n\ta.Activation.Validate(vr)\n\tif a.IssuerAccount != \"\" && !nkeys.IsValidPublicAccountKey(a.IssuerAccount) {\n\t\tvr.AddError(\"account_id is not an account public key\")\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\treturn autorest.SenderFunc(func(r *http.Request) (*http.Response, error) {\n\t\t\tresp, err := s.Do(r)\n\t\t\tif err != nil {\n\t\t\t\treturn resp, err\n\t\t\t}\n\t\t\tif !autorest.ResponseHasStatusCode(resp, pollingCodes[:]...) {\n\t\t\t\treturn resp, nil\n\t\t\t}\n\t\t\tfuture, err := NewFutureFromResponse(resp)\n\t\t\tif err != nil {\n\t\t\t\treturn resp, err\n\t\t\t}\n\t\t\t// retry until either the LRO completes or we receive an error\n\t\t\tvar done bool\n\t\t\tfor done, err = future.Done(s); !done && err == nil; done, err = future.Done(s) {\n\t\t\t\t// check for Retry-After delay, if not present use the specified polling delay\n\t\t\t\tif pd, ok := future.GetPollingDelay(); ok {\n\t\t\t\t\tdelay = pd\n\t\t\t\t}\n\t\t\t\t// wait until the delay elapses or the context is cancelled\n\t\t\t\tif delayElapsed := autorest.DelayForBackoff(delay, 0, r.Context().Done()); !delayElapsed {\n\t\t\t\t\treturn future.Response(),\n\t\t\t\t\t\tautorest.NewErrorWithError(r.Context().Err(), \"azure\", \"DoPollForAsynchronous\", future.Response(), \"context has been cancelled\")\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn future.Response(), err\n\t\t})", "is_vulnerable": 1}
{"code": "func (p Precompile) Validators(\n\tctx sdk.Context,\n\tmethod *abi.Method,\n\t_ *vm.Contract,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewValidatorsRequest(method, args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: &p.stakingKeeper}\n\n\tres, err := queryServer.Validators(sdk.WrapSDKContext(ctx), req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := new(ValidatorsOutput).FromResponse(res)\n\n\treturn out.Pack(method.Outputs)\n}", "is_vulnerable": 1}
{"code": "func (f *Frontend) SendBind(msg *Bind) {\n\tif f.encodeError != nil {\n\t\treturn\n\t}\n\n\tprevLen := len(f.wbuf)\n\tnewBuf, err := msg.Encode(f.wbuf)\n\tif err != nil {\n\t\tf.encodeError = err\n\t\treturn\n\t}\n\tf.wbuf = newBuf\n\n\tif f.tracer != nil {\n\t\tf.tracer.traceBind('F', int32(len(f.wbuf)-prevLen), msg)\n\t}\n}", "is_vulnerable": 0}
{"code": "func MkdirAllInRootOpen(root, unsafePath string, mode uint32) (_ *os.File, Err error) {\n\t// If the path is already \"within\" the root, use it verbatim.\n\tfullPath := unsafePath\n\tif !IsLexicallyInRoot(root, unsafePath) {\n\t\tvar err error\n\t\tfullPath, err = securejoin.SecureJoin(root, unsafePath)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tsubPath, err := filepath.Rel(root, fullPath)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Check for any silly mode bits.\n\tif mode&^0o7777 != 0 {\n\t\treturn nil, fmt.Errorf(\"tried to include non-mode bits in MkdirAll mode: 0o%.3o\", mode)\n\t}\n\n\tcurrentDir, err := os.OpenFile(root, unix.O_DIRECTORY|unix.O_CLOEXEC, 0)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"open root handle: %w\", err)\n\t}\n\tdefer func() {\n\t\tif Err != nil {\n\t\t\tcurrentDir.Close()\n\t\t}\n\t}()\n\n\tfor _, part := range strings.Split(subPath, string(filepath.Separator)) {\n\t\tswitch part {\n\t\tcase \"\", \".\":\n\t\t\t// Skip over no-op components.\n\t\t\tcontinue\n\t\tcase \"..\":\n\t\t\treturn nil, fmt.Errorf(\"possible breakout detected: found %q component in SecureJoin subpath %s\", part, subPath)\n\t\t}\n\n\t\tnextDir, err := system.Openat(currentDir, part, unix.O_DIRECTORY|unix.O_NOFOLLOW|unix.O_CLOEXEC, 0)\n\t\tswitch {\n\t\tcase err == nil:\n\t\t\t// Update the currentDir.\n\t\t\t_ = currentDir.Close()\n\t\t\tcurrentDir = nextDir\n\n\t\tcase errors.Is(err, unix.ENOTDIR):\n\t\t\t// This might be a symlink or some other random file. Either way,\n\t\t\t// error out.\n\t\t\treturn nil, fmt.Errorf(\"cannot mkdir in %s/%s: %w\", currentDir.Name(), part, unix.ENOTDIR)\n\n\t\tcase errors.Is(err, os.ErrNotExist):\n\t\t\t// Luckily, mkdirat will not follow trailing symlinks, so this is\n\t\t\t// safe to do as-is.\n\t\t\tif err := system.Mkdirat(currentDir, part, mode); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\t// Open the new directory. There is a race here where an attacker\n\t\t\t// could swap the directory with a different directory, but\n\t\t\t// MkdirAll's fuzzy semantics mean we don't care about that.\n\t\t\tnextDir, err := system.Openat(currentDir, part, unix.O_DIRECTORY|unix.O_NOFOLLOW|unix.O_CLOEXEC, 0)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"open newly created directory: %w\", err)\n\t\t\t}\n\t\t\t// Update the currentDir.\n\t\t\t_ = currentDir.Close()\n\t\t\tcurrentDir = nextDir\n\n\t\tdefault:\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn currentDir, nil\n}", "is_vulnerable": 0}
{"code": "func TestGitGetter_gitVersion(t *testing.T) {\n\tif !testHasGit {\n\t\tt.Skip(\"git not found, skipping\")\n\t}\n\tif runtime.GOOS == \"windows\" {\n\t\tt.Skip(\"skipping on windows since the test requires sh\")\n\t}\n\tdir, err := ioutil.TempDir(\"\", \"go-getter\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(dir)\n\n\tscript := filepath.Join(dir, \"git\")\n\terr = ioutil.WriteFile(\n\t\tscript,\n\t\t[]byte(\"#!/bin/sh\\necho \\\"git version 2.0 (Some Metadata Here)\\n\\\"\"),\n\t\t0700)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tdefer func(v string) {\n\t\tos.Setenv(\"PATH\", v)\n\t}(os.Getenv(\"PATH\"))\n\n\tos.Setenv(\"PATH\", dir)\n\n\t// Asking for a higher version throws an error\n\tctx := context.Background()\n\tif err := checkGitVersion(ctx, \"2.3\"); err == nil {\n\t\tt.Fatal(\"expect git version error\")\n\t}\n\n\t// Passes when version is satisfied\n\tif err := checkGitVersion(ctx, \"1.9\"); err != nil {\n\t\tt.Fatal(err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (c *repositoryClient) getReferenceFromDescriptor(desc ocispec.Descriptor) string {\n\treturn GetReferenceFromDescriptor(desc, c.ref)\n}", "is_vulnerable": 0}
{"code": "func releaseSession(s *Session) {\n\ts.mu.Lock()\n\ts.id = \"\"\n\ts.exp = 0\n\ts.ctx = nil\n\ts.config = nil\n\tif s.data != nil {\n\t\ts.data.Reset()\n\t}\n\tif s.byteBuffer != nil {\n\t\ts.byteBuffer.Reset()\n\t}\n\ts.mu.Unlock()\n\tsessionPool.Put(s)\n}", "is_vulnerable": 0}
{"code": "func (r *crdHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\tctx := req.Context()\n\trequestInfo, ok := apirequest.RequestInfoFrom(ctx)\n\tif !ok {\n\t\tresponsewriters.InternalError(w, req, fmt.Errorf(\"no RequestInfo found in the context\"))\n\t\treturn\n\t}\n\tif !requestInfo.IsResourceRequest {\n\t\tpathParts := splitPath(requestInfo.Path)\n\t\t// only match /apis/<group>/<version>\n\t\t// only registered under /apis\n\t\tif len(pathParts) == 3 {\n\t\t\tr.versionDiscoveryHandler.ServeHTTP(w, req)\n\t\t\treturn\n\t\t}\n\t\t// only match /apis/<group>\n\t\tif len(pathParts) == 2 {\n\t\t\tr.groupDiscoveryHandler.ServeHTTP(w, req)\n\t\t\treturn\n\t\t}\n\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\n\tcrdName := requestInfo.Resource + \".\" + requestInfo.APIGroup\n\tcrd, err := r.crdLister.Get(crdName)\n\tif apierrors.IsNotFound(err) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// if the scope in the CRD and the scope in request differ (with exception of the verbs in possiblyAcrossAllNamespacesVerbs\n\t// for namespaced resources), pass request to the delegate, which is supposed to lead to a 404.\n\tnamespacedCRD, namespacedReq := crd.Spec.Scope == apiextensions.NamespaceScoped, len(requestInfo.Namespace) > 0\n\tif !namespacedCRD && namespacedReq {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\tif namespacedCRD && !namespacedReq && !possiblyAcrossAllNamespacesVerbs.Has(requestInfo.Verb) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\n\tif !apiextensions.HasServedCRDVersion(crd, requestInfo.APIVersion) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\n\t// There is a small chance that a CRD is being served because NamesAccepted condition is true,\n\t// but it becomes \"unserved\" because another names update leads to a conflict\n\t// and EstablishingController wasn't fast enough to put the CRD into the Established condition.\n\t// We accept this as the problem is small and self-healing.\n\tif !apiextensions.IsCRDConditionTrue(crd, apiextensions.NamesAccepted) &&\n\t\t!apiextensions.IsCRDConditionTrue(crd, apiextensions.Established) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\n\tterminating := apiextensions.IsCRDConditionTrue(crd, apiextensions.Terminating)\n\n\tcrdInfo, err := r.getOrCreateServingInfoFor(crd.UID, crd.Name)\n\tif apierrors.IsNotFound(err) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n\tif !hasServedCRDVersion(crdInfo.spec, requestInfo.APIVersion) {\n\t\tr.delegate.ServeHTTP(w, req)\n\t\treturn\n\t}\n\n\tverb := strings.ToUpper(requestInfo.Verb)\n\tresource := requestInfo.Resource\n\tsubresource := requestInfo.Subresource\n\tscope := metrics.CleanScope(requestInfo)\n\tsupportedTypes := []string{\n\t\tstring(types.JSONPatchType),\n\t\tstring(types.MergePatchType),\n\t}\n\tif utilfeature.DefaultFeatureGate.Enabled(features.ServerSideApply) {\n\t\tsupportedTypes = append(supportedTypes, string(types.ApplyPatchType))\n\t}\n\n\tvar handlerFunc http.HandlerFunc\n\tsubresources, err := apiextensions.GetSubresourcesForVersion(crd, requestInfo.APIVersion)\n\tif err != nil {\n\t\tutilruntime.HandleError(err)\n\t\thttp.Error(w, \"the server could not properly serve the CR subresources\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\tswitch {\n\tcase subresource == \"status\" && subresources != nil && subresources.Status != nil:\n\t\thandlerFunc = r.serveStatus(w, req, requestInfo, crdInfo, terminating, supportedTypes)\n\tcase subresource == \"scale\" && subresources != nil && subresources.Scale != nil:\n\t\thandlerFunc = r.serveScale(w, req, requestInfo, crdInfo, terminating, supportedTypes)\n\tcase len(subresource) == 0:\n\t\thandlerFunc = r.serveResource(w, req, requestInfo, crdInfo, terminating, supportedTypes)\n\tdefault:\n\t\thttp.Error(w, \"the server could not find the requested resource\", http.StatusNotFound)\n\t}\n\n\tif handlerFunc != nil {\n\t\thandlerFunc = metrics.InstrumentHandlerFunc(verb, requestInfo.APIGroup, requestInfo.APIVersion, resource, subresource, scope, metrics.APIServerComponent, handlerFunc)\n\t\thandler := genericfilters.WithWaitGroup(handlerFunc, longRunningFilter, crdInfo.waitGroup)\n\t\thandler.ServeHTTP(w, req)\n\t\treturn\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestAnnotations(t *testing.T) {\n\ting := buildIngress()\n\tdata := map[string]string{}\n\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSSecret)] = \"default/demo-secret\"\n\n\ting.SetAnnotations(data)\n\n\tfakeSecret := &mockSecret{}\n\ti, err := NewParser(fakeSecret).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error with ingress: %v\", err)\n\t}\n\n\tu, ok := i.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected *Config but got %v\", u)\n\t}\n\n\tsecret, err := fakeSecret.GetAuthCertificate(\"default/demo-secret\")\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error getting secret %v\", err)\n\t}\n\n\tif u.AuthSSLCert.Secret != secret.Secret {\n\t\tt.Errorf(\"expected %v but got %v\", secret.Secret, u.AuthSSLCert.Secret)\n\t}\n\tif u.VerifyClient != \"on\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"on\", u.VerifyClient)\n\t}\n\tif u.ValidationDepth != 1 {\n\t\tt.Errorf(\"expected %v but got %v\", 1, u.ValidationDepth)\n\t}\n\tif u.ErrorPage != \"\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"\", u.ErrorPage)\n\t}\n\tif u.PassCertToUpstream != false {\n\t\tt.Errorf(\"expected %v but got %v\", false, u.PassCertToUpstream)\n\t}\n\tif u.MatchCN != \"\" {\n\t\tt.Errorf(\"expected empty string, but got %v\", u.MatchCN)\n\t}\n\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSVerifyClient)] = \"off\"\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSVerifyDepth)] = \"2\"\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSErrorPage)] = \"ok.com/error\"\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSPassCertToUpstream)] = \"true\"\n\tdata[parser.GetAnnotationWithPrefix(annotationAuthTLSMatchCN)] = \"CN=(hello-app|ok|goodbye)\"\n\n\ting.SetAnnotations(data)\n\n\ti, err = NewParser(fakeSecret).Parse(ing)\n\tif err != nil {\n\t\tt.Errorf(\"Unexpected error with ingress: %v\", err)\n\t}\n\n\tu, ok = i.(*Config)\n\tif !ok {\n\t\tt.Errorf(\"expected *Config but got %v\", u)\n\t}\n\n\tif u.AuthSSLCert.Secret != secret.Secret {\n\t\tt.Errorf(\"expected %v but got %v\", secret.Secret, u.AuthSSLCert.Secret)\n\t}\n\tif u.VerifyClient != \"off\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"off\", u.VerifyClient)\n\t}\n\tif u.ValidationDepth != 2 {\n\t\tt.Errorf(\"expected %v but got %v\", 2, u.ValidationDepth)\n\t}\n\tif u.ErrorPage != \"ok.com/error\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"ok.com/error\", u.ErrorPage)\n\t}\n\tif u.PassCertToUpstream != true {\n\t\tt.Errorf(\"expected %v but got %v\", true, u.PassCertToUpstream)\n\t}\n\tif u.MatchCN != \"CN=(hello-app|ok|goodbye)\" {\n\t\tt.Errorf(\"expected %v but got %v\", \"CN=(hello-app|ok|goodbye)\", u.MatchCN)\n\t}\n}", "is_vulnerable": 0}
{"code": "func yaml_parser_roll_indent(parser *yaml_parser_t, column, number int, typ yaml_token_type_t, mark yaml_mark_t) bool {\n\t// In the flow context, do nothing.\n\tif parser.flow_level > 0 {\n\t\treturn true\n\t}\n\n\tif parser.indent < column {\n\t\t// Push the current indentation level to the stack and set the new\n\t\t// indentation level.\n\t\tparser.indents = append(parser.indents, parser.indent)\n\t\tparser.indent = column\n\t\tif len(parser.indents) > max_indents {\n\t\t\treturn yaml_parser_set_scanner_error(parser,\n\t\t\t\t\"while increasing indent level\", parser.simple_keys[len(parser.simple_keys)-1].mark,\n\t\t\t\tfmt.Sprintf(\"exceeded max depth of %d\", max_indents))\n\t\t}\n\n\t\t// Create a token and insert it into the queue.\n\t\ttoken := yaml_token_t{\n\t\t\ttyp:        typ,\n\t\t\tstart_mark: mark,\n\t\t\tend_mark:   mark,\n\t\t}\n\t\tif number > -1 {\n\t\t\tnumber -= parser.tokens_parsed\n\t\t}\n\t\tyaml_insert_token(parser, number, &token)\n\t}\n\treturn true\n}", "is_vulnerable": 0}
{"code": "func TestCatalogConnectServiceNodes_good(t *testing.T) {\n\tt.Parallel()\n\n\tassert := assert.New(t)\n\ta := NewTestAgent(t.Name(), \"\")\n\tdefer a.Shutdown()\n\ttestrpc.WaitForLeader(t, a.RPC, \"dc1\")\n\n\t// Register\n\targs := structs.TestRegisterRequestProxy(t)\n\targs.Service.Address = \"127.0.0.55\"\n\tvar out struct{}\n\tassert.Nil(a.RPC(\"Catalog.Register\", args, &out))\n\n\treq, _ := http.NewRequest(\"GET\", fmt.Sprintf(\n\t\t\"/v1/catalog/connect/%s\", args.Service.Proxy.DestinationServiceName), nil)\n\tresp := httptest.NewRecorder()\n\tobj, err := a.srv.CatalogConnectServiceNodes(resp, req)\n\tassert.Nil(err)\n\tassertIndex(t, resp)\n\n\tnodes := obj.(structs.ServiceNodes)\n\tassert.Len(nodes, 1)\n\tassert.Equal(structs.ServiceKindConnectProxy, nodes[0].ServiceKind)\n\tassert.Equal(args.Service.Address, nodes[0].ServiceAddress)\n\tassert.Equal(args.Service.Proxy, nodes[0].ServiceProxy)\n}", "is_vulnerable": 0}
{"code": "func (t *FileStorageTests) TestSetDangerousName(c *C) {\n\tr := t.testReader()\n\tfor _, id := range dangerousNames {\n\t\terr := t.storage.Set(id, r)\n\t\tc.Assert(err, NotNil)\n\t}\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"check media type\", func(t *testing.T) {\n\t\twantMT := types.MediaType(\"foo\")\n\t\tgotMT, err := f.FileMediaType()\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"MediaType() = %v\", err)\n\t\t}\n\t\tif gotMT != wantMT {\n\t\t\tt.Errorf(\"MediaType() = %s, wanted %s\", gotMT, wantMT)\n\t\t}\n\t})", "is_vulnerable": 0}
{"code": "func (p *OAuthProxy) SetCookie(rw http.ResponseWriter, req *http.Request, val string) {\n\thttp.SetCookie(rw, p.MakeCookie(req, val, p.CookieExpire, time.Now()))\n}", "is_vulnerable": 1}
{"code": "func I18n(options ...Options) macaron.Handler {\n\topt := prepareOptions(options)\n\tm := initLocales(opt)\n\treturn func(ctx *macaron.Context) {\n\t\tisNeedRedir := false\n\t\thasCookie := false\n\n\t\t// 1. Check URL arguments.\n\t\tlang := ctx.Query(opt.Parameter)\n\n\t\t// 2. Get language information from cookies.\n\t\tif len(lang) == 0 {\n\t\t\tlang = ctx.GetCookie(\"lang\")\n\t\t\thasCookie = true\n\t\t} else {\n\t\t\tisNeedRedir = true\n\t\t}\n\n\t\t// Check again in case someone modify by purpose.\n\t\tif !i18n.IsExist(lang) {\n\t\t\tlang = \"\"\n\t\t\tisNeedRedir = false\n\t\t\thasCookie = false\n\t\t}\n\n\t\t// 3. Get language information from 'Accept-Language'.\n\t\t// The first element in the list is chosen to be the default language automatically.\n\t\tif len(lang) == 0 {\n\t\t\ttags, _, _ := language.ParseAcceptLanguage(ctx.Req.Header.Get(\"Accept-Language\"))\n\t\t\ttag, _, _ := m.Match(tags...)\n\t\t\tlang = tag.String()\n\t\t\tisNeedRedir = false\n\t\t}\n\n\t\tcurLang := LangType{\n\t\t\tLang: lang,\n\t\t}\n\n\t\t// Save language information in cookies.\n\t\tif !hasCookie {\n\t\t\tctx.SetCookie(\"lang\", curLang.Lang, 1<<31-1, \"/\"+strings.TrimPrefix(opt.SubURL, \"/\"), opt.CookieDomain)\n\t\t}\n\n\t\trestLangs := make([]LangType, 0, i18n.Count()-1)\n\t\tlangs := i18n.ListLangs()\n\t\tnames := i18n.ListLangDescs()\n\t\tfor i, v := range langs {\n\t\t\tif lang != v {\n\t\t\t\trestLangs = append(restLangs, LangType{v, names[i]})\n\t\t\t} else {\n\t\t\t\tcurLang.Name = names[i]\n\t\t\t}\n\t\t}\n\n\t\t// Set language properties.\n\t\tlocale := Locale{i18n.Locale{lang}}\n\t\tctx.Map(locale)\n\t\tctx.Locale = locale\n\t\tctx.Data[opt.TmplName] = locale\n\t\tctx.Data[\"Tr\"] = i18n.Tr\n\t\tctx.Data[\"Lang\"] = locale.Lang\n\t\tctx.Data[\"LangName\"] = curLang.Name\n\t\tctx.Data[\"AllLangs\"] = append([]LangType{curLang}, restLangs...)\n\t\tctx.Data[\"RestLangs\"] = restLangs\n\n\t\tif opt.Redirect && isNeedRedir {\n\t\t\tctx.Redirect(opt.SubURL + path.Clean(ctx.Req.RequestURI[:strings.Index(ctx.Req.RequestURI, \"?\")]))\n\t\t}\n\t}\n}", "is_vulnerable": 0}
{"code": "func gatewayBindAddressesIngress(ingress *structs.ConsulIngressConfigEntry) map[string]*structs.ConsulGatewayBindAddress {\n\tif ingress == nil || len(ingress.Listeners) == 0 {\n\t\treturn make(map[string]*structs.ConsulGatewayBindAddress)\n\t}\n\n\taddresses := make(map[string]*structs.ConsulGatewayBindAddress)\n\tfor _, listener := range ingress.Listeners {\n\t\tport := listener.Port\n\t\tfor _, service := range listener.Services {\n\t\t\taddresses[service.Name] = &structs.ConsulGatewayBindAddress{\n\t\t\t\tAddress: \"0.0.0.0\",\n\t\t\t\tPort:    port,\n\t\t\t}\n\t\t}\n\t}\n\treturn addresses\n}", "is_vulnerable": 1}
{"code": "func (s *Sync) Commit(dbw ethdb.Batch) error {\n\t// Dump the membatch into a database dbw\n\tfor key, value := range s.membatch.batch {\n\t\tif err := dbw.Put(key[:], value); err != nil {\n\t\t\treturn err\n\t\t}\n\t\ts.bloom.Add(key[:])\n\t}\n\t// Drop the membatch data and return\n\ts.membatch = newSyncMemBatch()\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *AllTypesOneOf) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: AllTypesOneOf: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: AllTypesOneOf: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &AllTypesOneOf_Field1{float64(math.Float64frombits(v))}\n\t\tcase 2:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &AllTypesOneOf_Field2{float32(math.Float32frombits(v))}\n\t\tcase 3:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_Field3{v}\n\t\tcase 4:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_Field4{v}\n\t\tcase 5:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_Field5{v}\n\t\tcase 6:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_Field6{v}\n\t\tcase 7:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\tm.TestOneof = &AllTypesOneOf_Field7{v}\n\t\tcase 8:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\tm.TestOneof = &AllTypesOneOf_Field8{int64(v)}\n\t\tcase 9:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\t\tvar v uint32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &AllTypesOneOf_Field9{v}\n\t\tcase 10:\n\t\t\tif wireType != 5 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\t\tvar v int32\n\t\t\tif (iNdEx + 4) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\tiNdEx += 4\n\t\t\tm.TestOneof = &AllTypesOneOf_Field10{v}\n\t\tcase 11:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\t\tvar v uint64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &AllTypesOneOf_Field11{v}\n\t\tcase 12:\n\t\t\tif wireType != 1 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tif (iNdEx + 8) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\tiNdEx += 8\n\t\t\tm.TestOneof = &AllTypesOneOf_Field12{v}\n\t\tcase 13:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\t\tvar v int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tb := bool(v != 0)\n\t\t\tm.TestOneof = &AllTypesOneOf_Field13{b}\n\t\tcase 14:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field14\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_Field14{string(dAtA[iNdEx:postIndex])}\n\t\t\tiNdEx = postIndex\n\t\tcase 15:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field15\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := make([]byte, postIndex-iNdEx)\n\t\t\tcopy(v, dAtA[iNdEx:postIndex])\n\t\t\tm.TestOneof = &AllTypesOneOf_Field15{v}\n\t\t\tiNdEx = postIndex\n\t\tcase 16:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field SubMessage\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tv := &Subby{}\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.TestOneof = &AllTypesOneOf_SubMessage{v}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetState() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetState\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetState))\n}", "is_vulnerable": 0}
{"code": "func (p *ProviderData) GetLoginURL(redirectURI, finalRedirect string) string {\n\tvar a url.URL\n\ta = *p.LoginURL\n\tparams, _ := url.ParseQuery(a.RawQuery)\n\tparams.Set(\"redirect_uri\", redirectURI)\n\tparams.Set(\"approval_prompt\", p.ApprovalPrompt)\n\tparams.Add(\"scope\", p.Scope)\n\tparams.Set(\"client_id\", p.ClientID)\n\tparams.Set(\"response_type\", \"code\")\n\tif strings.HasPrefix(finalRedirect, \"/\") && !strings.HasPrefix(finalRedirect,\"//\") {\n\t\tparams.Add(\"state\", finalRedirect)\n\t}\n\ta.RawQuery = params.Encode()\n\treturn a.String()\n}", "is_vulnerable": 0}
{"code": "\tt.Run(\"Patch username with a new username\", func(t *testing.T) {\n\t\t_, err := th.App.PatchUser(th.Context, testUser.Id, &model.UserPatch{\n\t\t\tUsername: model.NewString(model.NewId()),\n\t\t}, true)\n\n\t\trequire.Nil(t, err)\n\t})", "is_vulnerable": 1}
{"code": "\tcidr := func(s string) *net.IPNet {\n\t\t_, n, _ := net.ParseCIDR(s)\n\t\treturn n\n\t}\n\n\tflagSrc := []string{`-dev`}\n\tsrc := map[string]string{\n\t\t\"json\": `{\n\t\t\t\"acl_agent_master_token\": \"furuQD0b\",\n\t\t\t\"acl_agent_token\": \"cOshLOQ2\",\n\t\t\t\"acl_datacenter\": \"m3urck3z\",\n\t\t\t\"acl_default_policy\": \"ArK3WIfE\",\n\t\t\t\"acl_down_policy\": \"vZXMfMP0\",\n\t\t\t\"acl_enforce_version_8\": true,\n\t\t\t\"acl_enable_key_list_policy\": true,\n\t\t\t\"acl_master_token\": \"C1Q1oIwh\",\n\t\t\t\"acl_replication_token\": \"LMmgy5dO\",\n\t\t\t\"acl_token\": \"O1El0wan\",\n\t\t\t\"acl_ttl\": \"18060s\",\n\t\t\t\"acl\" : {\n\t\t\t\t\"enabled\" : true,\n\t\t\t\t\"down_policy\" : \"03eb2aee\",\n\t\t\t\t\"default_policy\" : \"72c2e7a0\",\n\t\t\t\t\"enable_key_list_policy\": false,\n\t\t\t\t\"enable_token_persistence\": true,\n\t\t\t\t\"policy_ttl\": \"1123s\",\n\t\t\t\t\"role_ttl\": \"9876s\",\n\t\t\t\t\"token_ttl\": \"3321s\",\n\t\t\t\t\"enable_token_replication\" : true,\n\t\t\t\t\"tokens\" : {\n\t\t\t\t\t\"master\" : \"8a19ac27\",\n\t\t\t\t\t\"agent_master\" : \"64fd0e08\",\n\t\t\t\t\t\"replication\" : \"5795983a\",\n\t\t\t\t\t\"agent\" : \"bed2377c\",\n\t\t\t\t\t\"default\" : \"418fdff1\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"addresses\": {\n\t\t\t\t\"dns\": \"93.95.95.81\",\n\t\t\t\t\"http\": \"83.39.91.39\",\n\t\t\t\t\"https\": \"95.17.17.19\",\n\t\t\t\t\"grpc\": \"32.31.61.91\"\n\t\t\t},\n\t\t\t\"advertise_addr\": \"17.99.29.16\",\n\t\t\t\"advertise_addr_wan\": \"78.63.37.19\",\n\t\t\t\"autopilot\": {\n\t\t\t\t\"cleanup_dead_servers\": true,\n\t\t\t\t\"disable_upgrade_migration\": true,\n\t\t\t\t\"last_contact_threshold\": \"12705s\",\n\t\t\t\t\"max_trailing_logs\": 17849,\n\t\t\t\t\"min_quorum\":\t\t 3,\n\t\t\t\t\"redundancy_zone_tag\": \"3IsufDJf\",\n\t\t\t\t\"server_stabilization_time\": \"23057s\",\n\t\t\t\t\"upgrade_version_tag\": \"W9pDwFAL\"\n\t\t\t},\n\t\t\t\"bind_addr\": \"16.99.34.17\",\n\t\t\t\"bootstrap\": true,\n\t\t\t\"bootstrap_expect\": 53,\n\t\t\t\"ca_file\": \"erA7T0PM\",\n\t\t\t\"ca_path\": \"mQEN1Mfp\",\n\t\t\t\"cert_file\": \"7s4QAzDk\",\n\t\t\t\"check\": {\n\t\t\t\t\"id\": \"fZaCAXww\",\n\t\t\t\t\"name\": \"OOM2eo0f\",\n\t\t\t\t\"notes\": \"zXzXI9Gt\",\n\t\t\t\t\"service_id\": \"L8G0QNmR\",\n\t\t\t\t\"token\": \"oo4BCTgJ\",\n\t\t\t\t\"status\": \"qLykAl5u\",\n\t\t\t\t\"args\": [\"f3BemRjy\", \"e5zgpef7\"],\n\t\t\t\t\"http\": \"29B93haH\",\n\t\t\t\t\"header\": {\n\t\t\t\t\t\"hBq0zn1q\": [ \"2a9o9ZKP\", \"vKwA5lR6\" ],\n\t\t\t\t\t\"f3r6xFtM\": [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t},\n\t\t\t\t\"method\": \"Dou0nGT5\",\n\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\"tcp\": \"JY6fTTcw\",\n\t\t\t\t\"interval\": \"18714s\",\n\t\t\t\t\"docker_container_id\": \"qF66POS9\",\n\t\t\t\t\"shell\": \"sOnDy228\",\n\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\"timeout\": \"5954s\",\n\t\t\t\t\"ttl\": \"30044s\",\n\t\t\t\t\"deregister_critical_service_after\": \"13209s\"\n\t\t\t},\n\t\t\t\"checks\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"uAjE6m9Z\",\n\t\t\t\t\t\"name\": \"QsZRGpYr\",\n\t\t\t\t\t\"notes\": \"VJ7Sk4BY\",\n\t\t\t\t\t\"service_id\": \"lSulPcyz\",\n\t\t\t\t\t\"token\": \"toO59sh8\",\n\t\t\t\t\t\"status\": \"9RlWsXMV\",\n\t\t\t\t\t\"args\": [\"4BAJttck\", \"4D2NPtTQ\"],\n\t\t\t\t\t\"http\": \"dohLcyQ2\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"ZBfTin3L\": [ \"1sDbEqYG\", \"lJGASsWK\" ],\n\t\t\t\t\t\t\"Ui0nU99X\": [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"aldrIQ4l\",\n\t\t\t\t\t\"tcp\": \"RJQND605\",\n\t\t\t\t\t\"interval\": \"22164s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\"shell\": \"qAeOYy0M\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"1813s\",\n\t\t\t\t\t\"ttl\": \"21743s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Cqq95BhP\",\n\t\t\t\t\t\"name\": \"3qXpkS0i\",\n\t\t\t\t\t\"notes\": \"sb5qLTex\",\n\t\t\t\t\t\"service_id\": \"CmUUcRna\",\n\t\t\t\t\t\"token\": \"a3nQzHuy\",\n\t\t\t\t\t\"status\": \"irj26nf3\",\n\t\t\t\t\t\"args\": [\"9s526ogY\", \"gSlOHj1w\"],\n\t\t\t\t\t\"http\": \"yzhgsQ7Y\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"zcqwA8dO\": [ \"qb1zx0DL\", \"sXCxPFsD\" ],\n\t\t\t\t\t\t\"qxvdnSE9\": [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"gLrztrNw\",\n\t\t\t\t\t\"tcp\": \"4jG5casb\",\n\t\t\t\t\t\"interval\": \"28767s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"THW6u7rL\",\n\t\t\t\t\t\"shell\": \"C1Zt3Zwh\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"18506s\",\n\t\t\t\t\t\"ttl\": \"31006s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"2366s\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"check_update_interval\": \"16507s\",\n\t\t\t\"client_addr\": \"93.83.18.19\",\n\t\t\t\"config_entries\": {\n\t\t\t\t\"bootstrap\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"kind\": \"proxy-defaults\",\n\t\t\t\t\t\t\"name\": \"global\",\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t\t\t\"bar\": 1.0\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t]\n                        },\n\t\t\t\"auto_encrypt\": {\n\t\t\t\t\"tls\": true,\n\t\t\t\t\"allow_tls\": true\n\t\t\t},\n\t\t\t\"connect\": {\n\t\t\t\t\"ca_provider\": \"consul\",\n\t\t\t\t\"ca_config\": {\n\t\t\t\t\t\"rotation_period\": \"90h\",\n\t\t\t\t\t\"leaf_cert_ttl\": \"1h\",\n\t\t\t\t\t\"csr_max_per_second\": 100,\n\t\t\t\t\t\"csr_max_concurrent\": 2\n\t\t\t\t},\n\t\t\t\t\"enabled\": true\n\t\t\t},\n\t\t\t\"gossip_lan\" : {\n\t\t\t\t\"gossip_nodes\": 6,\n\t\t\t\t\"gossip_interval\" : \"25252s\",\n\t\t\t\t\"retransmit_mult\" : 1234,\n\t\t\t\t\"suspicion_mult\"  : 1235,\n\t\t\t\t\"probe_interval\"  : \"101ms\",\n\t\t\t\t\"probe_timeout\"   : \"102ms\"\n\t\t\t},\n\t\t\t\"gossip_wan\" : {\n\t\t\t\t\"gossip_nodes\" : 2,\n\t\t\t\t\"gossip_interval\" : \"6966s\",\n\t\t\t\t\"retransmit_mult\" : 16384,\n\t\t\t\t\"suspicion_mult\"  : 16385,\n\t\t\t\t\"probe_interval\" : \"103ms\",\n\t\t\t\t\"probe_timeout\"  : \"104ms\"\n\t\t\t},\n\t\t\t\"data_dir\": \"` + dataDir + `\",\n\t\t\t\"datacenter\": \"rzo029wg\",\n\t\t\t\"disable_anonymous_signature\": true,\n\t\t\t\"disable_coordinates\": true,\n\t\t\t\"disable_host_node_id\": true,\n\t\t\t\"disable_http_unprintable_char_filter\": true,\n\t\t\t\"disable_keyring_file\": true,\n\t\t\t\"disable_remote_exec\": true,\n\t\t\t\"disable_update_check\": true,\n\t\t\t\"discard_check_output\": true,\n\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\"domain\": \"7W1xXSqd\",\n\t\t\t\"alt_domain\": \"1789hsd\",\n\t\t\t\"dns_config\": {\n\t\t\t\t\"allow_stale\": true,\n\t\t\t\t\"a_record_limit\": 29907,\n\t\t\t\t\"disable_compression\": true,\n\t\t\t\t\"enable_truncate\": true,\n\t\t\t\t\"max_stale\": \"29685s\",\n\t\t\t\t\"node_ttl\": \"7084s\",\n\t\t\t\t\"only_passing\": true,\n\t\t\t\t\"recursor_timeout\": \"4427s\",\n\t\t\t\t\"service_ttl\": {\n\t\t\t\t\t\"*\": \"32030s\"\n\t\t\t\t},\n\t\t\t\t\"udp_answer_limit\": 29909,\n\t\t\t\t\"use_cache\": true,\n\t\t\t\t\"cache_max_age\": \"5m\"\n\t\t\t},\n\t\t\t\"enable_acl_replication\": true,\n\t\t\t\"enable_agent_tls_for_checks\": true,\n\t\t\t\"enable_central_service_config\": true,\n\t\t\t\"enable_debug\": true,\n\t\t\t\"enable_script_checks\": true,\n\t\t\t\"enable_local_script_checks\": true,\n\t\t\t\"enable_syslog\": true,\n\t\t\t\"encrypt\": \"A4wELWqH\",\n\t\t\t\"encrypt_verify_incoming\": true,\n\t\t\t\"encrypt_verify_outgoing\": true,\n\t\t\t\"http_config\": {\n\t\t\t\t\"block_endpoints\": [ \"RBvAFcGD\", \"fWOWFznh\" ],\n\t\t\t\t\"allow_write_http_from\": [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ],\n\t\t\t\t\"response_headers\": {\n\t\t\t\t\t\"M6TKa9NP\": \"xjuxjOzQ\",\n\t\t\t\t\t\"JRCrHZed\": \"rl0mTx81\"\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"key_file\": \"IEkkwgIA\",\n\t\t\t\"leave_on_terminate\": true,\n\t\t\t\"limits\": {\n\t\t\t\t\"http_max_conns_per_client\": 9283,\n\t\t\t\t\"https_handshake_timeout\": \"2391ms\",\n\t\t\t\t\"rpc_handshake_timeout\": \"1932ms\",\n\t\t\t\t\"rpc_rate\": 12029.43,\n\t\t\t\t\"rpc_max_burst\": 44848,\n\t\t\t\t\"rpc_max_conns_per_client\": 2954,\n\t\t\t\t\"kv_max_value_size\": 1234567800000000\n\t\t\t},\n\t\t\t\"log_level\": \"k1zo9Spt\",\n\t\t\t\"node_id\": \"AsUIlw99\",\n\t\t\t\"node_meta\": {\n\t\t\t\t\"5mgGQMBk\": \"mJLtVMSG\",\n\t\t\t\t\"A7ynFMJB\": \"0Nx6RGab\"\n\t\t\t},\n\t\t\t\"node_name\": \"otlLxGaI\",\n\t\t\t\"non_voting_server\": true,\n\t\t\t\"performance\": {\n\t\t\t\t\"leave_drain_time\": \"8265s\",\n\t\t\t\t\"raft_multiplier\": 5,\n\t\t\t\t\"rpc_hold_timeout\": \"15707s\"\n\t\t\t},\n\t\t\t\"pid_file\": \"43xN80Km\",\n\t\t\t\"ports\": {\n\t\t\t\t\"dns\": 7001,\n\t\t\t\t\"http\": 7999,\n\t\t\t\t\"https\": 15127,\n\t\t\t\t\"server\": 3757,\n\t\t\t\t\"grpc\": 4881,\n\t\t\t\t\"sidecar_min_port\": 8888,\n\t\t\t\t\"sidecar_max_port\": 9999,\n\t\t\t\t\"expose_min_port\": 1111,\n\t\t\t\t\"expose_max_port\": 2222\n\t\t\t},\n\t\t\t\"protocol\": 30793,\n\t\t\t\"primary_datacenter\": \"ejtmd43d\",\n\t\t\t\"raft_protocol\": 19016,\n\t\t\t\"raft_snapshot_threshold\": 16384,\n\t\t\t\"raft_snapshot_interval\": \"30s\",\n\t\t\t\"raft_trailing_logs\": 83749,\n\t\t\t\"reconnect_timeout\": \"23739s\",\n\t\t\t\"reconnect_timeout_wan\": \"26694s\",\n\t\t\t\"recursors\": [ \"63.38.39.58\", \"92.49.18.18\" ],\n\t\t\t\"rejoin_after_leave\": true,\n\t\t\t\"retry_interval\": \"8067s\",\n\t\t\t\"retry_interval_wan\": \"28866s\",\n\t\t\t\"retry_join\": [ \"pbsSFY7U\", \"l0qLtWij\" ],\n\t\t\t\"retry_join_wan\": [ \"PFsR02Ye\", \"rJdQIhER\" ],\n\t\t\t\"retry_max\": 913,\n\t\t\t\"retry_max_wan\": 23160,\n\t\t\t\"segment\": \"BC2NhTDi\",\n\t\t\t\"segments\": [\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"PExYMe2E\",\n\t\t\t\t\t\"bind\": \"36.73.36.19\",\n\t\t\t\t\t\"port\": 38295,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"name\": \"UzCvJgup\",\n\t\t\t\t\t\"bind\": \"37.58.38.19\",\n\t\t\t\t\t\"port\": 39292,\n\t\t\t\t\t\"rpc_listener\": true,\n\t\t\t\t\t\"advertise\": \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"serf_lan\": \"99.43.63.15\",\n\t\t\t\"serf_wan\": \"67.88.33.19\",\n\t\t\t\"server\": true,\n\t\t\t\"server_name\": \"Oerr9n1G\",\n\t\t\t\"service\": {\n\t\t\t\t\"id\": \"dLOXpSCI\",\n\t\t\t\t\"name\": \"o1ynPkp0\",\n\t\t\t\t\"meta\": {\n\t\t\t\t\t\"mymeta\": \"data\"\n\t\t\t\t},\n\t\t\t\t\"tagged_addresses\": {\n\t\t\t\t\t\"lan\": {\n\t\t\t\t\t\t\"address\": \"2d79888a\",\n\t\t\t\t\t\t\"port\": 2143\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": {\n\t\t\t\t\t\t\"address\": \"d4db85e2\",\n\t\t\t\t\t\t\"port\": 6109\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"tags\": [\"nkwshvM5\", \"NTDWn3ek\"],\n\t\t\t\t\"address\": \"cOlSOhbp\",\n\t\t\t\t\"token\": \"msy7iWER\",\n\t\t\t\t\"port\": 24237,\n\t\t\t\t\"weights\": {\n\t\t\t\t\t\"passing\": 100,\n\t\t\t\t\t\"warning\": 1\n\t\t\t\t},\n\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\"check\": {\n\t\t\t\t\t\"id\": \"RMi85Dv8\",\n\t\t\t\t\t\"name\": \"iehanzuq\",\n\t\t\t\t\t\"status\": \"rCvn53TH\",\n\t\t\t\t\t\"notes\": \"fti5lfF3\",\n\t\t\t\t\t\"args\": [\"16WRUmwS\", \"QWk7j7ae\"],\n\t\t\t\t\t\"http\": \"dl3Fgme3\",\n\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\"rjm4DEd3\": [\"2m3m2Fls\"],\n\t\t\t\t\t\t\"l4HwQ112\": [\"fk56MNlo\", \"dhLK56aZ\"]\n\t\t\t\t\t},\n\t\t\t\t\t\"method\": \"9afLm3Mj\",\n\t\t\t\t\t\"tcp\": \"fjiLFqVd\",\n\t\t\t\t\t\"interval\": \"23926s\",\n\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\"docker_container_id\": \"dO5TtRHk\",\n\t\t\t\t\t\"shell\": \"e6q2ttES\",\n\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\"timeout\": \"38483s\",\n\t\t\t\t\t\"ttl\": \"10943s\",\n\t\t\t\t\t\"deregister_critical_service_after\": \"68787s\"\n\t\t\t\t},\n\t\t\t\t\"checks\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"Zv99e9Ka\",\n\t\t\t\t\t\t\"name\": \"sgV4F7Pk\",\n\t\t\t\t\t\t\"notes\": \"yP5nKbW0\",\n\t\t\t\t\t\t\"status\": \"7oLMEyfu\",\n\t\t\t\t\t\t\"args\": [\"5wEZtZpv\", \"0Ihyk8cS\"],\n\t\t\t\t\t\t\"http\": \"KyDjGY9H\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"gv5qefTz\": [ \"5Olo2pMG\", \"PvvKWQU5\" ],\n\t\t\t\t\t\t\t\"SHOVq1Vv\": [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"T66MFBfR\",\n\t\t\t\t\t\t\"tcp\": \"bNnNfx2A\",\n\t\t\t\t\t\t\"interval\": \"22224s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ipgdFtjd\",\n\t\t\t\t\t\t\"shell\": \"omVZq7Sz\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"18913s\",\n\t\t\t\t\t\t\"ttl\": \"44743s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"id\": \"G79O6Mpr\",\n\t\t\t\t\t\t\"name\": \"IEqrzrsd\",\n\t\t\t\t\t\t\"notes\": \"SVqApqeM\",\n\t\t\t\t\t\t\"status\": \"XXkVoZXt\",\n\t\t\t\t\t\t\"args\": [\"wD05Bvao\", \"rLYB7kQC\"],\n\t\t\t\t\t\t\"http\": \"kyICZsn8\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"4ebP5vL4\": [ \"G20SrL5Q\", \"DwPKlMbo\" ],\n\t\t\t\t\t\t\t\"p2UI34Qz\": [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"ciYHWors\",\n\t\t\t\t\t\t\"tcp\": \"FfvCwlqH\",\n\t\t\t\t\t\t\"interval\": \"12356s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"HBndBU6R\",\n\t\t\t\t\t\t\"shell\": \"hVI33JjA\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38282s\",\n\t\t\t\t\t\t\"ttl\": \"1181s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"connect\": {\n\t\t\t\t\t\"native\": true\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"services\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"wI1dzxS4\",\n\t\t\t\t\t\"name\": \"7IszXMQ1\",\n\t\t\t\t\t\"tags\": [\"0Zwg8l6v\", \"zebELdN5\"],\n\t\t\t\t\t\"address\": \"9RhqPSPB\",\n\t\t\t\t\t\"token\": \"myjKJkWH\",\n\t\t\t\t\t\"port\": 72219,\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"check\": {\n\t\t\t\t\t\t\"id\": \"qmfeO5if\",\n\t\t\t\t\t\t\"name\": \"atDGP7n5\",\n\t\t\t\t\t\t\"status\": \"pDQKEhWL\",\n\t\t\t\t\t\t\"notes\": \"Yt8EDLev\",\n\t\t\t\t\t\t\"args\": [\"81EDZLPa\", \"bPY5X8xd\"],\n\t\t\t\t\t\t\"http\": \"qzHYvmJO\",\n\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\"UkpmZ3a3\": [\"2dfzXuxZ\"],\n\t\t\t\t\t\t\t\"cVFpko4u\": [\"gGqdEB6k\", \"9LsRo22u\"]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"method\": \"X5DrovFc\",\n\t\t\t\t\t\t\"tcp\": \"ICbxkpSF\",\n\t\t\t\t\t\t\"interval\": \"24392s\",\n\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\"docker_container_id\": \"ZKXr68Yb\",\n\t\t\t\t\t\t\"shell\": \"CEfzx0Fo\",\n\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\"timeout\": \"38333s\",\n\t\t\t\t\t\t\"ttl\": \"57201s\",\n\t\t\t\t\t\t\"deregister_critical_service_after\": \"44214s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"connect\": {\n\t\t\t\t\t\t\"sidecar_service\": {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"MRHVMZuD\",\n\t\t\t\t\t\"name\": \"6L6BVfgH\",\n\t\t\t\t\t\"tags\": [\"7Ale4y6o\", \"PMBW08hy\"],\n\t\t\t\t\t\"address\": \"R6H6g8h0\",\n\t\t\t\t\t\"token\": \"ZgY8gjMI\",\n\t\t\t\t\t\"port\": 38292,\n\t\t\t\t\t\"weights\": {\n\t\t\t\t\t\t\"passing\": 1979,\n\t\t\t\t\t\t\"warning\": 6\n\t\t\t\t\t},\n\t\t\t\t\t\"enable_tag_override\": true,\n\t\t\t\t\t\"checks\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"GTti9hCo\",\n\t\t\t\t\t\t\t\"name\": \"9OOS93ne\",\n\t\t\t\t\t\t\t\"notes\": \"CQy86DH0\",\n\t\t\t\t\t\t\t\"status\": \"P0SWDvrk\",\n\t\t\t\t\t\t\t\"args\": [\"EXvkYIuG\", \"BATOyt6h\"],\n\t\t\t\t\t\t\t\"http\": \"u97ByEiW\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"MUlReo8L\": [ \"AUZG7wHG\", \"gsN0Dc2N\" ],\n\t\t\t\t\t\t\t\t\"1UJXjVrT\": [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"5wkAxCUE\",\n\t\t\t\t\t\t\t\"tcp\": \"MN3oA9D2\",\n\t\t\t\t\t\t\t\"interval\": \"32718s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"cU15LMet\",\n\t\t\t\t\t\t\t\"shell\": \"nEz9qz2l\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"34738s\",\n\t\t\t\t\t\t\t\"ttl\": \"22773s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"UHsDeLxG\",\n\t\t\t\t\t\t\t\"name\": \"PQSaPWlT\",\n\t\t\t\t\t\t\t\"notes\": \"jKChDOdl\",\n\t\t\t\t\t\t\t\"status\": \"5qFz6OZn\",\n\t\t\t\t\t\t\t\"args\": [\"NMtYWlT9\", \"vj74JXsm\"],\n\t\t\t\t\t\t\t\"http\": \"1LBDJhw4\",\n\t\t\t\t\t\t\t\"header\": {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\": [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\": [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\"method\": \"wzByP903\",\n\t\t\t\t\t\t\t\"tcp\": \"2exjZIGE\",\n\t\t\t\t\t\t\t\"interval\": \"5656s\",\n\t\t\t\t\t\t\t\"output_max_size\": ` + strconv.Itoa(checks.DefaultBufSize) + `,\n\t\t\t\t\t\t\t\"docker_container_id\": \"5tDBWpfA\",\n\t\t\t\t\t\t\t\"shell\": \"rlTpLM8s\",\n\t\t\t\t\t\t\t\"tls_skip_verify\": true,\n\t\t\t\t\t\t\t\"timeout\": \"4868s\",\n\t\t\t\t\t\t\t\"ttl\": \"11222s\",\n\t\t\t\t\t\t\t\"deregister_critical_service_after\": \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t],\n\t\t\t\t\t\"connect\": {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"Kh81CPF6\",\n\t\t\t\t\t\"kind\": \"connect-proxy\",\n\t\t\t\t\t\"name\": \"Kh81CPF6-proxy\",\n\t\t\t\t\t\"port\": 31471,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"destination_service_id\": \"6L6BVfgH-id\",\n\t\t\t\t\t\t\"destination_service_name\": \"6L6BVfgH\",\n\t\t\t\t\t\t\"local_service_address\": \"127.0.0.2\",\n\t\t\t\t\t\t\"local_service_port\": 23759,\n\t\t\t\t\t\t\"expose\": {\n\t\t\t\t\t\t\t\"checks\": true,\n\t\t\t\t\t\t\t\"paths\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"path\": \"/health\",\n\t\t\t\t\t\t\t\t\t\"local_path_port\": 8080,\n\t\t\t\t\t\t\t\t\t\"listener_port\": 21500,\n\t\t\t\t\t\t\t\t\t\"protocol\": \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"upstreams\": [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KPtAj2cb\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 4051,\n\t\t\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\"destination_name\": \"KSd8HsRl\",\n\t\t\t\t\t\t\t\t\"destination_namespace\": \"9nakw0td\",\n\t\t\t\t\t\t\t\t\"destination_type\": \"prepared_query\",\n\t\t\t\t\t\t\t\t\"local_bind_address\": \"127.24.88.0\",\n\t\t\t\t\t\t\t\t\"local_bind_port\": 11884\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t]\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"kvVqbwSE\",\n\t\t\t\t\t\"kind\": \"mesh-gateway\",\n\t\t\t\t\t\"name\": \"gw-primary-dc\",\n\t\t\t\t\t\"port\": 27147,\n\t\t\t\t\t\"proxy\": {\n\t\t\t\t\t\t\"config\": {\n\t\t\t\t\t\t\t\"1CuJHVfw\" : \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"session_ttl_min\": \"26627s\",\n\t\t\t\"skip_leave_on_interrupt\": true,\n\t\t\t\"start_join\": [ \"LR3hGDoG\", \"MwVpZ4Up\" ],\n\t\t\t\"start_join_wan\": [ \"EbFSc3nA\", \"kwXTh623\" ],\n\t\t\t\"syslog_facility\": \"hHv79Uia\",\n\t\t\t\"tagged_addresses\": {\n\t\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\"\n\t\t\t},\n\t\t\t\"telemetry\": {\n\t\t\t\t\"circonus_api_app\": \"p4QOTe9j\",\n\t\t\t\t\"circonus_api_token\": \"E3j35V23\",\n\t\t\t\t\"circonus_api_url\": \"mEMjHpGg\",\n\t\t\t\t\"circonus_broker_id\": \"BHlxUhed\",\n\t\t\t\t\"circonus_broker_select_tag\": \"13xy1gHm\",\n\t\t\t\t\"circonus_check_display_name\": \"DRSlQR6n\",\n\t\t\t\t\"circonus_check_force_metric_activation\": \"Ua5FGVYf\",\n\t\t\t\t\"circonus_check_id\": \"kGorutad\",\n\t\t\t\t\"circonus_check_instance_id\": \"rwoOL6R4\",\n\t\t\t\t\"circonus_check_search_tag\": \"ovT4hT4f\",\n\t\t\t\t\"circonus_check_tags\": \"prvO4uBl\",\n\t\t\t\t\"circonus_submission_interval\": \"DolzaflP\",\n\t\t\t\t\"circonus_submission_url\": \"gTcbS93G\",\n\t\t\t\t\"disable_hostname\": true,\n\t\t\t\t\"dogstatsd_addr\": \"0wSndumK\",\n\t\t\t\t\"dogstatsd_tags\": [ \"3N81zSUB\",\"Xtj8AnXZ\" ],\n\t\t\t\t\"filter_default\": true,\n\t\t\t\t\"prefix_filter\": [ \"+oJotS8XJ\",\"-cazlEhGn\" ],\n\t\t\t\t\"metrics_prefix\": \"ftO6DySn\",\n\t\t\t\t\"prometheus_retention_time\": \"15s\",\n\t\t\t\t\"statsd_address\": \"drce87cy\",\n\t\t\t\t\"statsite_address\": \"HpFwKB8R\"\n\t\t\t},\n\t\t\t\"tls_cipher_suites\": \"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\n\t\t\t\"tls_min_version\": \"pAOWafkR\",\n\t\t\t\"tls_prefer_server_cipher_suites\": true,\n\t\t\t\"translate_wan_addrs\": true,\n\t\t\t\"ui\": true,\n\t\t\t\"ui_dir\": \"11IFzAUn\",\n\t\t\t\"unix_sockets\": {\n\t\t\t\t\"group\": \"8pFodrV8\",\n\t\t\t\t\"mode\": \"E8sAwOv4\",\n\t\t\t\t\"user\": \"E0nB1DwA\"\n\t\t\t},\n\t\t\t\"verify_incoming\": true,\n\t\t\t\"verify_incoming_https\": true,\n\t\t\t\"verify_incoming_rpc\": true,\n\t\t\t\"verify_outgoing\": true,\n\t\t\t\"verify_server_hostname\": true,\n\t\t\t\"watches\": [\n\t\t\t\t{\n\t\t\t\t\t\"type\": \"key\",\n\t\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\t\"key\": \"j9lF1Tve\",\n\t\t\t\t\t\"handler\": \"90N7S4LN\"\n\t\t\t\t}, {\n\t\t\t\t\t\"type\": \"keyprefix\",\n\t\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\t\"key\": \"sl3Dffu7\",\n\t\t\t\t\t\"args\": [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t\t}\n\t\t\t]\n\t\t}`,\n\t\t\"hcl\": `\n\t\t\tacl_agent_master_token = \"furuQD0b\"\n\t\t\tacl_agent_token = \"cOshLOQ2\"\n\t\t\tacl_datacenter = \"m3urck3z\"\n\t\t\tacl_default_policy = \"ArK3WIfE\"\n\t\t\tacl_down_policy = \"vZXMfMP0\"\n\t\t\tacl_enforce_version_8 = true\n\t\t\tacl_enable_key_list_policy = true\n\t\t\tacl_master_token = \"C1Q1oIwh\"\n\t\t\tacl_replication_token = \"LMmgy5dO\"\n\t\t\tacl_token = \"O1El0wan\"\n\t\t\tacl_ttl = \"18060s\"\n\t\t\tacl = {\n\t\t\t\tenabled = true\n\t\t\t\tdown_policy = \"03eb2aee\"\n\t\t\t\tdefault_policy = \"72c2e7a0\"\n\t\t\t\tenable_key_list_policy = false\n\t\t\t\tenable_token_persistence = true\n\t\t\t\tpolicy_ttl = \"1123s\"\n\t\t\t\trole_ttl = \"9876s\"\n\t\t\t\ttoken_ttl = \"3321s\"\n\t\t\t\tenable_token_replication = true\n\t\t\t\ttokens = {\n\t\t\t\t\tmaster = \"8a19ac27\",\n\t\t\t\t\tagent_master = \"64fd0e08\",\n\t\t\t\t\treplication = \"5795983a\",\n\t\t\t\t\tagent = \"bed2377c\",\n\t\t\t\t\tdefault = \"418fdff1\"\n\t\t\t\t}\n\t\t\t}\n\t\t\taddresses = {\n\t\t\t\tdns = \"93.95.95.81\"\n\t\t\t\thttp = \"83.39.91.39\"\n\t\t\t\thttps = \"95.17.17.19\"\n\t\t\t\tgrpc = \"32.31.61.91\"\n\t\t\t}\n\t\t\tadvertise_addr = \"17.99.29.16\"\n\t\t\tadvertise_addr_wan = \"78.63.37.19\"\n\t\t\tautopilot = {\n\t\t\t\tcleanup_dead_servers = true\n\t\t\t\tdisable_upgrade_migration = true\n\t\t\t\tlast_contact_threshold = \"12705s\"\n\t\t\t\tmax_trailing_logs = 17849\n\t\t\t\tmin_quorum = 3\n\t\t\t\tredundancy_zone_tag = \"3IsufDJf\"\n\t\t\t\tserver_stabilization_time = \"23057s\"\n\t\t\t\tupgrade_version_tag = \"W9pDwFAL\"\n\t\t\t}\n\t\t\tbind_addr = \"16.99.34.17\"\n\t\t\tbootstrap = true\n\t\t\tbootstrap_expect = 53\n\t\t\tca_file = \"erA7T0PM\"\n\t\t\tca_path = \"mQEN1Mfp\"\n\t\t\tcert_file = \"7s4QAzDk\"\n\t\t\tcheck = {\n\t\t\t\tid = \"fZaCAXww\"\n\t\t\t\tname = \"OOM2eo0f\"\n\t\t\t\tnotes = \"zXzXI9Gt\"\n\t\t\t\tservice_id = \"L8G0QNmR\"\n\t\t\t\ttoken = \"oo4BCTgJ\"\n\t\t\t\tstatus = \"qLykAl5u\"\n\t\t\t\targs = [\"f3BemRjy\", \"e5zgpef7\"]\n\t\t\t\thttp = \"29B93haH\"\n\t\t\t\theader = {\n\t\t\t\t\thBq0zn1q = [ \"2a9o9ZKP\", \"vKwA5lR6\" ]\n\t\t\t\t\tf3r6xFtM = [ \"RyuIdDWv\", \"QbxEcIUM\" ]\n\t\t\t\t}\n\t\t\t\tmethod = \"Dou0nGT5\"\n\t\t\t\ttcp = \"JY6fTTcw\"\n\t\t\t\tinterval = \"18714s\"\n\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\tdocker_container_id = \"qF66POS9\"\n\t\t\t\tshell = \"sOnDy228\"\n\t\t\t\ttls_skip_verify = true\n\t\t\t\ttimeout = \"5954s\"\n\t\t\t\tttl = \"30044s\"\n\t\t\t\tderegister_critical_service_after = \"13209s\"\n\t\t\t},\n\t\t\tchecks = [\n\t\t\t\t{\n\t\t\t\t\tid = \"uAjE6m9Z\"\n\t\t\t\t\tname = \"QsZRGpYr\"\n\t\t\t\t\tnotes = \"VJ7Sk4BY\"\n\t\t\t\t\tservice_id = \"lSulPcyz\"\n\t\t\t\t\ttoken = \"toO59sh8\"\n\t\t\t\t\tstatus = \"9RlWsXMV\"\n\t\t\t\t\targs = [\"4BAJttck\", \"4D2NPtTQ\"]\n\t\t\t\t\thttp = \"dohLcyQ2\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"ZBfTin3L\" = [ \"1sDbEqYG\", \"lJGASsWK\" ]\n\t\t\t\t\t\t\"Ui0nU99X\" = [ \"LMccm3Qe\", \"k5H5RggQ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"aldrIQ4l\"\n\t\t\t\t\ttcp = \"RJQND605\"\n\t\t\t\t\tinterval = \"22164s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\tshell = \"qAeOYy0M\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"1813s\"\n\t\t\t\t\tttl = \"21743s\"\n\t\t\t\t\tderegister_critical_service_after = \"14232s\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Cqq95BhP\"\n\t\t\t\t\tname = \"3qXpkS0i\"\n\t\t\t\t\tnotes = \"sb5qLTex\"\n\t\t\t\t\tservice_id = \"CmUUcRna\"\n\t\t\t\t\ttoken = \"a3nQzHuy\"\n\t\t\t\t\tstatus = \"irj26nf3\"\n\t\t\t\t\targs = [\"9s526ogY\", \"gSlOHj1w\"]\n\t\t\t\t\thttp = \"yzhgsQ7Y\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\t\"zcqwA8dO\" = [ \"qb1zx0DL\", \"sXCxPFsD\" ]\n\t\t\t\t\t\t\"qxvdnSE9\" = [ \"6wBPUYdF\", \"YYh8wtSZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"gLrztrNw\"\n\t\t\t\t\ttcp = \"4jG5casb\"\n\t\t\t\t\tinterval = \"28767s\"\n\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\tdocker_container_id = \"THW6u7rL\"\n\t\t\t\t\tshell = \"C1Zt3Zwh\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"18506s\"\n\t\t\t\t\tttl = \"31006s\"\n\t\t\t\t\tderegister_critical_service_after = \"2366s\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tcheck_update_interval = \"16507s\"\n\t\t\tclient_addr = \"93.83.18.19\"\n\t\t\tconfig_entries {\n\t\t\t\t# This is using the repeated block-to-array HCL magic\n\t\t\t\tbootstrap {\n\t\t\t\t\tkind = \"proxy-defaults\"\n\t\t\t\t\tname = \"global\"\n\t\t\t\t\tconfig {\n\t\t\t\t\t\tfoo = \"bar\"\n\t\t\t\t\t\tbar = 1.0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tauto_encrypt = {\n\t\t\t\ttls = true\n\t\t\t\tallow_tls = true\n\t\t\t}\n\t\t\tconnect {\n\t\t\t\tca_provider = \"consul\"\n\t\t\t\tca_config {\n\t\t\t\t\trotation_period = \"90h\"\n\t\t\t\t\tleaf_cert_ttl = \"1h\"\n\t\t\t\t\t# hack float since json parses numbers as float and we have to\n\t\t\t\t\t# assert against the same thing\n\t\t\t\t\tcsr_max_per_second = 100.0\n\t\t\t\t\tcsr_max_concurrent = 2.0\n\t\t\t\t}\n\t\t\t\tenabled = true\n\t\t\t}\n\t\t\tgossip_lan {\n\t\t\t\tgossip_nodes    = 6\n\t\t\t\tgossip_interval = \"25252s\"\n\t\t\t\tretransmit_mult = 1234\n\t\t\t\tsuspicion_mult  = 1235\n\t\t\t\tprobe_interval  = \"101ms\"\n\t\t\t\tprobe_timeout   = \"102ms\"\n\t\t\t}\n\t\t\tgossip_wan {\n\t\t\t\tgossip_nodes    = 2\n\t\t\t\tgossip_interval = \"6966s\"\n\t\t\t\tretransmit_mult = 16384\n\t\t\t\tsuspicion_mult  = 16385\n\t\t\t\tprobe_interval  = \"103ms\"\n\t\t\t\tprobe_timeout   = \"104ms\"\n\t\t\t}\n\t\t\tdata_dir = \"` + dataDir + `\"\n\t\t\tdatacenter = \"rzo029wg\"\n\t\t\tdisable_anonymous_signature = true\n\t\t\tdisable_coordinates = true\n\t\t\tdisable_host_node_id = true\n\t\t\tdisable_http_unprintable_char_filter = true\n\t\t\tdisable_keyring_file = true\n\t\t\tdisable_remote_exec = true\n\t\t\tdisable_update_check = true\n\t\t\tdiscard_check_output = true\n\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\tdomain = \"7W1xXSqd\"\n\t\t\talt_domain = \"1789hsd\"\n\t\t\tdns_config {\n\t\t\t\tallow_stale = true\n\t\t\t\ta_record_limit = 29907\n\t\t\t\tdisable_compression = true\n\t\t\t\tenable_truncate = true\n\t\t\t\tmax_stale = \"29685s\"\n\t\t\t\tnode_ttl = \"7084s\"\n\t\t\t\tonly_passing = true\n\t\t\t\trecursor_timeout = \"4427s\"\n\t\t\t\tservice_ttl = {\n\t\t\t\t\t\"*\" = \"32030s\"\n\t\t\t\t}\n\t\t\t\tudp_answer_limit = 29909\n\t\t\t\tuse_cache = true\n\t\t\t\tcache_max_age = \"5m\"\n\t\t\t}\n\t\t\tenable_acl_replication = true\n\t\t\tenable_agent_tls_for_checks = true\n\t\t\tenable_central_service_config = true\n\t\t\tenable_debug = true\n\t\t\tenable_script_checks = true\n\t\t\tenable_local_script_checks = true\n\t\t\tenable_syslog = true\n\t\t\tencrypt = \"A4wELWqH\"\n\t\t\tencrypt_verify_incoming = true\n\t\t\tencrypt_verify_outgoing = true\n\t\t\thttp_config {\n\t\t\t\tblock_endpoints = [ \"RBvAFcGD\", \"fWOWFznh\" ]\n\t\t\t\tallow_write_http_from = [ \"127.0.0.1/8\", \"22.33.44.55/32\", \"0.0.0.0/0\" ]\n\t\t\t\tresponse_headers = {\n\t\t\t\t\t\"M6TKa9NP\" = \"xjuxjOzQ\"\n\t\t\t\t\t\"JRCrHZed\" = \"rl0mTx81\"\n\t\t\t\t}\n\t\t\t}\n\t\t\tkey_file = \"IEkkwgIA\"\n\t\t\tleave_on_terminate = true\n\t\t\tlimits {\n\t\t\t\thttp_max_conns_per_client = 9283\n\t\t\t\thttps_handshake_timeout = \"2391ms\"\n\t\t\t\trpc_handshake_timeout = \"1932ms\"\n\t\t\t\trpc_rate = 12029.43\n\t\t\t\trpc_max_burst = 44848\n\t\t\t\trpc_max_conns_per_client = 2954\n\t\t\t\tkv_max_value_size = 1234567800000000\n\t\t\t}\n\t\t\tlog_level = \"k1zo9Spt\"\n\t\t\tnode_id = \"AsUIlw99\"\n\t\t\tnode_meta {\n\t\t\t\t\"5mgGQMBk\" = \"mJLtVMSG\"\n\t\t\t\t\"A7ynFMJB\" = \"0Nx6RGab\"\n\t\t\t}\n\t\t\tnode_name = \"otlLxGaI\"\n\t\t\tnon_voting_server = true\n\t\t\tperformance {\n\t\t\t\tleave_drain_time = \"8265s\"\n\t\t\t\traft_multiplier = 5\n\t\t\t\trpc_hold_timeout = \"15707s\"\n\t\t\t}\n\t\t\tpid_file = \"43xN80Km\"\n\t\t\tports {\n\t\t\t\tdns = 7001\n\t\t\t\thttp = 7999\n\t\t\t\thttps = 15127\n\t\t\t\tserver = 3757\n\t\t\t\tgrpc = 4881\n\t\t\t\tproxy_min_port = 2000\n\t\t\t\tproxy_max_port = 3000\n\t\t\t\tsidecar_min_port = 8888\n\t\t\t\tsidecar_max_port = 9999\n\t\t\t\texpose_min_port = 1111\n\t\t\t\texpose_max_port = 2222\n\t\t\t}\n\t\t\tprotocol = 30793\n\t\t\tprimary_datacenter = \"ejtmd43d\"\n\t\t\traft_protocol = 19016\n\t\t\traft_snapshot_threshold = 16384\n\t\t\traft_snapshot_interval = \"30s\"\n\t\t\traft_trailing_logs = 83749\n\t\t\treconnect_timeout = \"23739s\"\n\t\t\treconnect_timeout_wan = \"26694s\"\n\t\t\trecursors = [ \"63.38.39.58\", \"92.49.18.18\" ]\n\t\t\trejoin_after_leave = true\n\t\t\tretry_interval = \"8067s\"\n\t\t\tretry_interval_wan = \"28866s\"\n\t\t\tretry_join = [ \"pbsSFY7U\", \"l0qLtWij\" ]\n\t\t\tretry_join_wan = [ \"PFsR02Ye\", \"rJdQIhER\" ]\n\t\t\tretry_max = 913\n\t\t\tretry_max_wan = 23160\n\t\t\tsegment = \"BC2NhTDi\"\n\t\t\tsegments = [\n\t\t\t\t{\n\t\t\t\t\tname = \"PExYMe2E\"\n\t\t\t\t\tbind = \"36.73.36.19\"\n\t\t\t\t\tport = 38295\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"63.39.19.18\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tname = \"UzCvJgup\"\n\t\t\t\t\tbind = \"37.58.38.19\"\n\t\t\t\t\tport = 39292\n\t\t\t\t\trpc_listener = true\n\t\t\t\t\tadvertise = \"83.58.26.27\"\n\t\t\t\t}\n\t\t\t]\n\t\t\tserf_lan = \"99.43.63.15\"\n\t\t\tserf_wan = \"67.88.33.19\"\n\t\t\tserver = true\n\t\t\tserver_name = \"Oerr9n1G\"\n\t\t\tservice = {\n\t\t\t\tid = \"dLOXpSCI\"\n\t\t\t\tname = \"o1ynPkp0\"\n\t\t\t\tmeta = {\n\t\t\t\t\tmymeta = \"data\"\n\t\t\t\t}\n\t\t\t\ttagged_addresses = {\n\t\t\t\t\tlan = {\n\t\t\t\t\t\taddress = \"2d79888a\"\n\t\t\t\t\t\tport = 2143\n\t\t\t\t\t}\n\t\t\t\t\twan = {\n\t\t\t\t\t\taddress = \"d4db85e2\"\n\t\t\t\t\t\tport = 6109\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttags = [\"nkwshvM5\", \"NTDWn3ek\"]\n\t\t\t\taddress = \"cOlSOhbp\"\n\t\t\t\ttoken = \"msy7iWER\"\n\t\t\t\tport = 24237\n\t\t\t\tweights = {\n\t\t\t\t\tpassing = 100,\n\t\t\t\t\twarning = 1\n\t\t\t\t}\n\t\t\t\tenable_tag_override = true\n\t\t\t\tcheck = {\n\t\t\t\t\tid = \"RMi85Dv8\"\n\t\t\t\t\tname = \"iehanzuq\"\n\t\t\t\t\tstatus = \"rCvn53TH\"\n\t\t\t\t\tnotes = \"fti5lfF3\"\n\t\t\t\t\targs = [\"16WRUmwS\", \"QWk7j7ae\"]\n\t\t\t\t\thttp = \"dl3Fgme3\"\n\t\t\t\t\theader = {\n\t\t\t\t\t\trjm4DEd3 = [ \"2m3m2Fls\" ]\n\t\t\t\t\t\tl4HwQ112 = [ \"fk56MNlo\", \"dhLK56aZ\" ]\n\t\t\t\t\t}\n\t\t\t\t\tmethod = \"9afLm3Mj\"\n\t\t\t\t\ttcp = \"fjiLFqVd\"\n\t\t\t\t\tinterval = \"23926s\"\n\t\t\t\t\tdocker_container_id = \"dO5TtRHk\"\n\t\t\t\t\tshell = \"e6q2ttES\"\n\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\ttimeout = \"38483s\"\n\t\t\t\t\tttl = \"10943s\"\n\t\t\t\t\tderegister_critical_service_after = \"68787s\"\n\t\t\t\t}\n\t\t\t\tchecks = [\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"Zv99e9Ka\"\n\t\t\t\t\t\tname = \"sgV4F7Pk\"\n\t\t\t\t\t\tnotes = \"yP5nKbW0\"\n\t\t\t\t\t\tstatus = \"7oLMEyfu\"\n\t\t\t\t\t\targs = [\"5wEZtZpv\", \"0Ihyk8cS\"]\n\t\t\t\t\t\thttp = \"KyDjGY9H\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"gv5qefTz\" = [ \"5Olo2pMG\", \"PvvKWQU5\" ]\n\t\t\t\t\t\t\t\"SHOVq1Vv\" = [ \"jntFhyym\", \"GYJh32pp\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"T66MFBfR\"\n\t\t\t\t\t\ttcp = \"bNnNfx2A\"\n\t\t\t\t\t\tinterval = \"22224s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ipgdFtjd\"\n\t\t\t\t\t\tshell = \"omVZq7Sz\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"18913s\"\n\t\t\t\t\t\tttl = \"44743s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"8482s\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tid = \"G79O6Mpr\"\n\t\t\t\t\t\tname = \"IEqrzrsd\"\n\t\t\t\t\t\tnotes = \"SVqApqeM\"\n\t\t\t\t\t\tstatus = \"XXkVoZXt\"\n\t\t\t\t\t\targs = [\"wD05Bvao\", \"rLYB7kQC\"]\n\t\t\t\t\t\thttp = \"kyICZsn8\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\"4ebP5vL4\" = [ \"G20SrL5Q\", \"DwPKlMbo\" ]\n\t\t\t\t\t\t\t\"p2UI34Qz\" = [ \"UsG1D0Qh\", \"NHhRiB6s\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"ciYHWors\"\n\t\t\t\t\t\ttcp = \"FfvCwlqH\"\n\t\t\t\t\t\tinterval = \"12356s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"HBndBU6R\"\n\t\t\t\t\t\tshell = \"hVI33JjA\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38282s\"\n\t\t\t\t\t\tttl = \"1181s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"4992s\"\n\t\t\t\t\t}\n\t\t\t\t]\n\t\t\t\tconnect {\n\t\t\t\t\tnative = true\n\t\t\t\t}\n\t\t\t}\n\t\t\tservices = [\n\t\t\t\t{\n\t\t\t\t\tid = \"wI1dzxS4\"\n\t\t\t\t\tname = \"7IszXMQ1\"\n\t\t\t\t\ttags = [\"0Zwg8l6v\", \"zebELdN5\"]\n\t\t\t\t\taddress = \"9RhqPSPB\"\n\t\t\t\t\ttoken = \"myjKJkWH\"\n\t\t\t\t\tport = 72219\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tcheck = {\n\t\t\t\t\t\tid = \"qmfeO5if\"\n\t\t\t\t\t\tname = \"atDGP7n5\"\n\t\t\t\t\t\tstatus = \"pDQKEhWL\"\n\t\t\t\t\t\tnotes = \"Yt8EDLev\"\n\t\t\t\t\t\targs = [\"81EDZLPa\", \"bPY5X8xd\"]\n\t\t\t\t\t\thttp = \"qzHYvmJO\"\n\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\tUkpmZ3a3 = [ \"2dfzXuxZ\" ]\n\t\t\t\t\t\t\tcVFpko4u = [ \"gGqdEB6k\", \"9LsRo22u\" ]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmethod = \"X5DrovFc\"\n\t\t\t\t\t\ttcp = \"ICbxkpSF\"\n\t\t\t\t\t\tinterval = \"24392s\"\n\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\tdocker_container_id = \"ZKXr68Yb\"\n\t\t\t\t\t\tshell = \"CEfzx0Fo\"\n\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\ttimeout = \"38333s\"\n\t\t\t\t\t\tttl = \"57201s\"\n\t\t\t\t\t\tderegister_critical_service_after = \"44214s\"\n\t\t\t\t\t}\n\t\t\t\t\tconnect {\n\t\t\t\t\t\tsidecar_service {}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"MRHVMZuD\"\n\t\t\t\t\tname = \"6L6BVfgH\"\n\t\t\t\t\ttags = [\"7Ale4y6o\", \"PMBW08hy\"]\n\t\t\t\t\taddress = \"R6H6g8h0\"\n\t\t\t\t\ttoken = \"ZgY8gjMI\"\n\t\t\t\t\tport = 38292\n\t\t\t\t\tweights = {\n\t\t\t\t\t\tpassing = 1979,\n\t\t\t\t\t\twarning = 6\n\t\t\t\t\t}\n\t\t\t\t\tenable_tag_override = true\n\t\t\t\t\tchecks = [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"GTti9hCo\"\n\t\t\t\t\t\t\tname = \"9OOS93ne\"\n\t\t\t\t\t\t\tnotes = \"CQy86DH0\"\n\t\t\t\t\t\t\tstatus = \"P0SWDvrk\"\n\t\t\t\t\t\t\targs = [\"EXvkYIuG\", \"BATOyt6h\"]\n\t\t\t\t\t\t\thttp = \"u97ByEiW\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"MUlReo8L\" = [ \"AUZG7wHG\", \"gsN0Dc2N\" ]\n\t\t\t\t\t\t\t\t\"1UJXjVrT\" = [ \"OJgxzTfk\", \"xZZrFsq7\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"5wkAxCUE\"\n\t\t\t\t\t\t\ttcp = \"MN3oA9D2\"\n\t\t\t\t\t\t\tinterval = \"32718s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"cU15LMet\"\n\t\t\t\t\t\t\tshell = \"nEz9qz2l\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"34738s\"\n\t\t\t\t\t\t\tttl = \"22773s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"84282s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tid = \"UHsDeLxG\"\n\t\t\t\t\t\t\tname = \"PQSaPWlT\"\n\t\t\t\t\t\t\tnotes = \"jKChDOdl\"\n\t\t\t\t\t\t\tstatus = \"5qFz6OZn\"\n\t\t\t\t\t\t\targs = [\"NMtYWlT9\", \"vj74JXsm\"]\n\t\t\t\t\t\t\thttp = \"1LBDJhw4\"\n\t\t\t\t\t\t\theader = {\n\t\t\t\t\t\t\t\t\"cXPmnv1M\" = [ \"imDqfaBx\", \"NFxZ1bQe\" ],\n\t\t\t\t\t\t\t\t\"vr7wY7CS\" = [ \"EtCoNPPL\", \"9vAarJ5s\" ]\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmethod = \"wzByP903\"\n\t\t\t\t\t\t\ttcp = \"2exjZIGE\"\n\t\t\t\t\t\t\tinterval = \"5656s\"\n\t\t\t\t\t\t\toutput_max_size = ` + strconv.Itoa(checks.DefaultBufSize) + `\n\t\t\t\t\t\t\tdocker_container_id = \"5tDBWpfA\"\n\t\t\t\t\t\t\tshell = \"rlTpLM8s\"\n\t\t\t\t\t\t\ttls_skip_verify = true\n\t\t\t\t\t\t\ttimeout = \"4868s\"\n\t\t\t\t\t\t\tttl = \"11222s\"\n\t\t\t\t\t\t\tderegister_critical_service_after = \"68482s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t\tconnect {}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"Kh81CPF6\"\n\t\t\t\t\tname = \"Kh81CPF6-proxy\"\n\t\t\t\t\tport = 31471\n\t\t\t\t\tkind = \"connect-proxy\"\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tdestination_service_name = \"6L6BVfgH\"\n\t\t\t\t\t\tdestination_service_id = \"6L6BVfgH-id\"\n\t\t\t\t\t\tlocal_service_address = \"127.0.0.2\"\n\t\t\t\t\t\tlocal_service_port = 23759\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\tcedGGtZf = \"pWrUNiWw\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tupstreams = [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_name = \"KPtAj2cb\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 4051\n\t\t\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\t\tkzRnZOyd = \"nUNKoL8H\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tdestination_type = \"prepared_query\"\n\t\t\t\t\t\t\t\tdestination_namespace = \"9nakw0td\"\n\t\t\t\t\t\t\t\tdestination_name = \"KSd8HsRl\"\n\t\t\t\t\t\t\t\tlocal_bind_port = 11884\n\t\t\t\t\t\t\t\tlocal_bind_address = \"127.24.88.0\"\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t]\n\t\t\t\t\t\texpose {\n\t\t\t\t\t\t\tchecks = true\n\t\t\t\t\t\t\tpaths = [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tpath = \"/health\"\n\t\t\t\t\t\t\t\t\tlocal_path_port = 8080\n\t\t\t\t\t\t\t\t\tlistener_port = 21500\n\t\t\t\t\t\t\t\t\tprotocol = \"http\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tid = \"kvVqbwSE\"\n\t\t\t\t\tkind = \"mesh-gateway\"\n\t\t\t\t\tname = \"gw-primary-dc\"\n\t\t\t\t\tport = 27147\n\t\t\t\t\tproxy {\n\t\t\t\t\t\tconfig {\n\t\t\t\t\t\t\t\"1CuJHVfw\" = \"Kzqsa7yc\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t]\n\t\t\tsession_ttl_min = \"26627s\"\n\t\t\tskip_leave_on_interrupt = true\n\t\t\tstart_join = [ \"LR3hGDoG\", \"MwVpZ4Up\" ]\n\t\t\tstart_join_wan = [ \"EbFSc3nA\", \"kwXTh623\" ]\n\t\t\tsyslog_facility = \"hHv79Uia\"\n\t\t\ttagged_addresses = {\n\t\t\t\t\"7MYgHrYH\" = \"dALJAhLD\"\n\t\t\t\t\"h6DdBy6K\" = \"ebrr9zZ8\"\n\t\t\t}\n\t\t\ttelemetry {\n\t\t\t\tcirconus_api_app = \"p4QOTe9j\"\n\t\t\t\tcirconus_api_token = \"E3j35V23\"\n\t\t\t\tcirconus_api_url = \"mEMjHpGg\"\n\t\t\t\tcirconus_broker_id = \"BHlxUhed\"\n\t\t\t\tcirconus_broker_select_tag = \"13xy1gHm\"\n\t\t\t\tcirconus_check_display_name = \"DRSlQR6n\"\n\t\t\t\tcirconus_check_force_metric_activation = \"Ua5FGVYf\"\n\t\t\t\tcirconus_check_id = \"kGorutad\"\n\t\t\t\tcirconus_check_instance_id = \"rwoOL6R4\"\n\t\t\t\tcirconus_check_search_tag = \"ovT4hT4f\"\n\t\t\t\tcirconus_check_tags = \"prvO4uBl\"\n\t\t\t\tcirconus_submission_interval = \"DolzaflP\"\n\t\t\t\tcirconus_submission_url = \"gTcbS93G\"\n\t\t\t\tdisable_hostname = true\n\t\t\t\tdogstatsd_addr = \"0wSndumK\"\n\t\t\t\tdogstatsd_tags = [ \"3N81zSUB\",\"Xtj8AnXZ\" ]\n\t\t\t\tfilter_default = true\n\t\t\t\tprefix_filter = [ \"+oJotS8XJ\",\"-cazlEhGn\" ]\n\t\t\t\tmetrics_prefix = \"ftO6DySn\"\n\t\t\t\tprometheus_retention_time = \"15s\"\n\t\t\t\tstatsd_address = \"drce87cy\"\n\t\t\t\tstatsite_address = \"HpFwKB8R\"\n\t\t\t}\n\t\t\ttls_cipher_suites = \"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"\n\t\t\ttls_min_version = \"pAOWafkR\"\n\t\t\ttls_prefer_server_cipher_suites = true\n\t\t\ttranslate_wan_addrs = true\n\t\t\tui = true\n\t\t\tui_dir = \"11IFzAUn\"\n\t\t\tunix_sockets = {\n\t\t\t\tgroup = \"8pFodrV8\"\n\t\t\t\tmode = \"E8sAwOv4\"\n\t\t\t\tuser = \"E0nB1DwA\"\n\t\t\t}\n\t\t\tverify_incoming = true\n\t\t\tverify_incoming_https = true\n\t\t\tverify_incoming_rpc = true\n\t\t\tverify_outgoing = true\n\t\t\tverify_server_hostname = true\n\t\t\twatches = [{\n\t\t\t\ttype = \"key\"\n\t\t\t\tdatacenter = \"GyE6jpeW\"\n\t\t\t\tkey = \"j9lF1Tve\"\n\t\t\t\thandler = \"90N7S4LN\"\n\t\t\t}, {\n\t\t\t\ttype = \"keyprefix\"\n\t\t\t\tdatacenter = \"fYrl3F5d\"\n\t\t\t\tkey = \"sl3Dffu7\"\n\t\t\t\targs = [\"dltjDJ2a\", \"flEa7C2d\"]\n\t\t\t}]\n\t\t`}\n\n\ttail := map[string][]Source{\n\t\t\"json\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"acl_disabled_ttl\": \"957s\",\n\t\t\t\t\t\"acl\" : {\n\t\t\t\t\t\t\"disabled_ttl\" : \"957s\"\n\t\t\t\t\t},\n\t\t\t\t\t\"ae_interval\": \"10003s\",\n\t\t\t\t\t\"check_deregister_interval_min\": \"27870s\",\n\t\t\t\t\t\"check_reap_interval\": \"10662s\",\n\t\t\t\t\t\"discovery_max_stale\": \"5s\",\n\t\t\t\t\t\"segment_limit\": 24705,\n\t\t\t\t\t\"segment_name_limit\": 27046,\n\t\t\t\t\t\"sync_coordinate_interval_min\": \"27983s\",\n\t\t\t\t\t\"sync_coordinate_rate_target\": 137.81\n\t\t\t\t}`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.json\",\n\t\t\t\tFormat: \"json\",\n\t\t\t\tData: `\n\t\t\t\t{\n\t\t\t\t\t\"consul\": {\n\t\t\t\t\t\t\"coordinate\": {\n\t\t\t\t\t\t\t\"update_batch_size\": 9244,\n\t\t\t\t\t\t\t\"update_max_batches\": 15164,\n\t\t\t\t\t\t\t\"update_period\": \"25093s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"raft\": {\n\t\t\t\t\t\t\t\"election_timeout\": \"31947s\",\n\t\t\t\t\t\t\t\"heartbeat_timeout\": \"25699s\",\n\t\t\t\t\t\t\t\"leader_lease_timeout\": \"15351s\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"server\": {\n\t\t\t\t\t\t\t\"health_interval\": \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}`,\n\t\t\t},\n\t\t},\n\t\t\"hcl\": []Source{\n\t\t\t{\n\t\t\t\tName:   \"tail.non-user.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tacl_disabled_ttl = \"957s\"\n\t\t\t\t\tacl = {\n\t\t\t\t\t\tdisabled_ttl = \"957s\"\n\t\t\t\t\t}\n\t\t\t\t\tae_interval = \"10003s\"\n\t\t\t\t\tcheck_deregister_interval_min = \"27870s\"\n\t\t\t\t\tcheck_reap_interval = \"10662s\"\n\t\t\t\t\tdiscovery_max_stale = \"5s\"\n\t\t\t\t\tsegment_limit = 24705\n\t\t\t\t\tsegment_name_limit = 27046\n\t\t\t\t\tsync_coordinate_interval_min = \"27983s\"\n\t\t\t\t\tsync_coordinate_rate_target = 137.81\n\t\t\t\t`,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:   \"tail.consul.hcl\",\n\t\t\t\tFormat: \"hcl\",\n\t\t\t\tData: `\n\t\t\t\t\tconsul = {\n\t\t\t\t\t\tcoordinate = {\n\t\t\t\t\t\t\tupdate_batch_size = 9244\n\t\t\t\t\t\t\tupdate_max_batches = 15164\n\t\t\t\t\t\t\tupdate_period = \"25093s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\traft = {\n\t\t\t\t\t\t\telection_timeout = \"31947s\"\n\t\t\t\t\t\t\theartbeat_timeout = \"25699s\"\n\t\t\t\t\t\t\tleader_lease_timeout = \"15351s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tserver = {\n\t\t\t\t\t\t\thealth_interval = \"17455s\"\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t`,\n\t\t\t},\n\t\t},\n\t}\n\n\twant := RuntimeConfig{\n\t\t// non-user configurable values\n\t\tACLDisabledTTL:             957 * time.Second,\n\t\tAEInterval:                 10003 * time.Second,\n\t\tCheckDeregisterIntervalMin: 27870 * time.Second,\n\t\tCheckReapInterval:          10662 * time.Second,\n\t\tSegmentLimit:               24705,\n\t\tSegmentNameLimit:           27046,\n\t\tSyncCoordinateIntervalMin:  27983 * time.Second,\n\t\tSyncCoordinateRateTarget:   137.81,\n\n\t\tRevision:          \"JNtPSav3\",\n\t\tVersion:           \"R909Hblt\",\n\t\tVersionPrerelease: \"ZT1JOQLn\",\n\n\t\t// consul configuration\n\t\tConsulCoordinateUpdateBatchSize:  9244,\n\t\tConsulCoordinateUpdateMaxBatches: 15164,\n\t\tConsulCoordinateUpdatePeriod:     25093 * time.Second,\n\t\tConsulRaftElectionTimeout:        5 * 31947 * time.Second,\n\t\tConsulRaftHeartbeatTimeout:       5 * 25699 * time.Second,\n\t\tConsulRaftLeaderLeaseTimeout:     5 * 15351 * time.Second,\n\t\tGossipLANGossipInterval:          25252 * time.Second,\n\t\tGossipLANGossipNodes:             6,\n\t\tGossipLANProbeInterval:           101 * time.Millisecond,\n\t\tGossipLANProbeTimeout:            102 * time.Millisecond,\n\t\tGossipLANSuspicionMult:           1235,\n\t\tGossipLANRetransmitMult:          1234,\n\t\tGossipWANGossipInterval:          6966 * time.Second,\n\t\tGossipWANGossipNodes:             2,\n\t\tGossipWANProbeInterval:           103 * time.Millisecond,\n\t\tGossipWANProbeTimeout:            104 * time.Millisecond,\n\t\tGossipWANSuspicionMult:           16385,\n\t\tGossipWANRetransmitMult:          16384,\n\t\tConsulServerHealthInterval:       17455 * time.Second,\n\n\t\t// user configurable values\n\n\t\tACLAgentMasterToken:              \"64fd0e08\",\n\t\tACLAgentToken:                    \"bed2377c\",\n\t\tACLsEnabled:                      true,\n\t\tACLDatacenter:                    \"ejtmd43d\",\n\t\tACLDefaultPolicy:                 \"72c2e7a0\",\n\t\tACLDownPolicy:                    \"03eb2aee\",\n\t\tACLEnforceVersion8:               true,\n\t\tACLEnableKeyListPolicy:           false,\n\t\tACLEnableTokenPersistence:        true,\n\t\tACLMasterToken:                   \"8a19ac27\",\n\t\tACLReplicationToken:              \"5795983a\",\n\t\tACLTokenTTL:                      3321 * time.Second,\n\t\tACLPolicyTTL:                     1123 * time.Second,\n\t\tACLRoleTTL:                       9876 * time.Second,\n\t\tACLToken:                         \"418fdff1\",\n\t\tACLTokenReplication:              true,\n\t\tAdvertiseAddrLAN:                 ipAddr(\"17.99.29.16\"),\n\t\tAdvertiseAddrWAN:                 ipAddr(\"78.63.37.19\"),\n\t\tAutopilotCleanupDeadServers:      true,\n\t\tAutopilotDisableUpgradeMigration: true,\n\t\tAutopilotLastContactThreshold:    12705 * time.Second,\n\t\tAutopilotMaxTrailingLogs:         17849,\n\t\tAutopilotMinQuorum:               3,\n\t\tAutopilotRedundancyZoneTag:       \"3IsufDJf\",\n\t\tAutopilotServerStabilizationTime: 23057 * time.Second,\n\t\tAutopilotUpgradeVersionTag:       \"W9pDwFAL\",\n\t\tBindAddr:                         ipAddr(\"16.99.34.17\"),\n\t\tBootstrap:                        true,\n\t\tBootstrapExpect:                  53,\n\t\tCAFile:                           \"erA7T0PM\",\n\t\tCAPath:                           \"mQEN1Mfp\",\n\t\tCertFile:                         \"7s4QAzDk\",\n\t\tCheckOutputMaxSize:               checks.DefaultBufSize,\n\t\tChecks: []*structs.CheckDefinition{\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"uAjE6m9Z\",\n\t\t\t\tName:       \"QsZRGpYr\",\n\t\t\t\tNotes:      \"VJ7Sk4BY\",\n\t\t\t\tServiceID:  \"lSulPcyz\",\n\t\t\t\tToken:      \"toO59sh8\",\n\t\t\t\tStatus:     \"9RlWsXMV\",\n\t\t\t\tScriptArgs: []string{\"4BAJttck\", \"4D2NPtTQ\"},\n\t\t\t\tHTTP:       \"dohLcyQ2\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"ZBfTin3L\": []string{\"1sDbEqYG\", \"lJGASsWK\"},\n\t\t\t\t\t\"Ui0nU99X\": []string{\"LMccm3Qe\", \"k5H5RggQ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"aldrIQ4l\",\n\t\t\t\tTCP:                            \"RJQND605\",\n\t\t\t\tInterval:                       22164 * time.Second,\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\tShell:                          \"qAeOYy0M\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        1813 * time.Second,\n\t\t\t\tTTL:                            21743 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 14232 * time.Second,\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"Cqq95BhP\",\n\t\t\t\tName:       \"3qXpkS0i\",\n\t\t\t\tNotes:      \"sb5qLTex\",\n\t\t\t\tServiceID:  \"CmUUcRna\",\n\t\t\t\tToken:      \"a3nQzHuy\",\n\t\t\t\tStatus:     \"irj26nf3\",\n\t\t\t\tScriptArgs: []string{\"9s526ogY\", \"gSlOHj1w\"},\n\t\t\t\tHTTP:       \"yzhgsQ7Y\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"zcqwA8dO\": []string{\"qb1zx0DL\", \"sXCxPFsD\"},\n\t\t\t\t\t\"qxvdnSE9\": []string{\"6wBPUYdF\", \"YYh8wtSZ\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"gLrztrNw\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"4jG5casb\",\n\t\t\t\tInterval:                       28767 * time.Second,\n\t\t\t\tDockerContainerID:              \"THW6u7rL\",\n\t\t\t\tShell:                          \"C1Zt3Zwh\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        18506 * time.Second,\n\t\t\t\tTTL:                            31006 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 2366 * time.Second,\n\t\t\t},\n\t\t\t&structs.CheckDefinition{\n\t\t\t\tID:         \"fZaCAXww\",\n\t\t\t\tName:       \"OOM2eo0f\",\n\t\t\t\tNotes:      \"zXzXI9Gt\",\n\t\t\t\tServiceID:  \"L8G0QNmR\",\n\t\t\t\tToken:      \"oo4BCTgJ\",\n\t\t\t\tStatus:     \"qLykAl5u\",\n\t\t\t\tScriptArgs: []string{\"f3BemRjy\", \"e5zgpef7\"},\n\t\t\t\tHTTP:       \"29B93haH\",\n\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\"hBq0zn1q\": {\"2a9o9ZKP\", \"vKwA5lR6\"},\n\t\t\t\t\t\"f3r6xFtM\": {\"RyuIdDWv\", \"QbxEcIUM\"},\n\t\t\t\t},\n\t\t\t\tMethod:                         \"Dou0nGT5\",\n\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\tTCP:                            \"JY6fTTcw\",\n\t\t\t\tInterval:                       18714 * time.Second,\n\t\t\t\tDockerContainerID:              \"qF66POS9\",\n\t\t\t\tShell:                          \"sOnDy228\",\n\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\tTimeout:                        5954 * time.Second,\n\t\t\t\tTTL:                            30044 * time.Second,\n\t\t\t\tDeregisterCriticalServiceAfter: 13209 * time.Second,\n\t\t\t},\n\t\t},\n\t\tCheckUpdateInterval: 16507 * time.Second,\n\t\tClientAddrs:         []*net.IPAddr{ipAddr(\"93.83.18.19\")},\n\t\tConfigEntryBootstrap: []structs.ConfigEntry{\n\t\t\t&structs.ProxyConfigEntry{\n\t\t\t\tKind: structs.ProxyDefaults,\n\t\t\t\tName: structs.ProxyConfigGlobal,\n\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\"foo\": \"bar\",\n\t\t\t\t\t// has to be a float due to being a map[string]interface\n\t\t\t\t\t\"bar\": float64(1),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tAutoEncryptTLS:        true,\n\t\tAutoEncryptAllowTLS:   true,\n\t\tConnectEnabled:        true,\n\t\tConnectSidecarMinPort: 8888,\n\t\tConnectSidecarMaxPort: 9999,\n\t\tExposeMinPort:         1111,\n\t\tExposeMaxPort:         2222,\n\t\tConnectCAProvider:     \"consul\",\n\t\tConnectCAConfig: map[string]interface{}{\n\t\t\t\"RotationPeriod\":   \"90h\",\n\t\t\t\"LeafCertTTL\":      \"1h\",\n\t\t\t\"CSRMaxPerSecond\":  float64(100),\n\t\t\t\"CSRMaxConcurrent\": float64(2),\n\t\t},\n\t\tDNSAddrs:                         []net.Addr{tcpAddr(\"93.95.95.81:7001\"), udpAddr(\"93.95.95.81:7001\")},\n\t\tDNSARecordLimit:                  29907,\n\t\tDNSAllowStale:                    true,\n\t\tDNSDisableCompression:            true,\n\t\tDNSDomain:                        \"7W1xXSqd\",\n\t\tDNSAltDomain:                     \"1789hsd\",\n\t\tDNSEnableTruncate:                true,\n\t\tDNSMaxStale:                      29685 * time.Second,\n\t\tDNSNodeTTL:                       7084 * time.Second,\n\t\tDNSOnlyPassing:                   true,\n\t\tDNSPort:                          7001,\n\t\tDNSRecursorTimeout:               4427 * time.Second,\n\t\tDNSRecursors:                     []string{\"63.38.39.58\", \"92.49.18.18\"},\n\t\tDNSSOA:                           RuntimeSOAConfig{Refresh: 3600, Retry: 600, Expire: 86400, Minttl: 0},\n\t\tDNSServiceTTL:                    map[string]time.Duration{\"*\": 32030 * time.Second},\n\t\tDNSUDPAnswerLimit:                29909,\n\t\tDNSNodeMetaTXT:                   true,\n\t\tDNSUseCache:                      true,\n\t\tDNSCacheMaxAge:                   5 * time.Minute,\n\t\tDataDir:                          dataDir,\n\t\tDatacenter:                       \"rzo029wg\",\n\t\tDevMode:                          true,\n\t\tDisableAnonymousSignature:        true,\n\t\tDisableCoordinates:               true,\n\t\tDisableHostNodeID:                true,\n\t\tDisableHTTPUnprintableCharFilter: true,\n\t\tDisableKeyringFile:               true,\n\t\tDisableRemoteExec:                true,\n\t\tDisableUpdateCheck:               true,\n\t\tDiscardCheckOutput:               true,\n\t\tDiscoveryMaxStale:                5 * time.Second,\n\t\tEnableAgentTLSForChecks:          true,\n\t\tEnableCentralServiceConfig:       true,\n\t\tEnableDebug:                      true,\n\t\tEnableRemoteScriptChecks:         true,\n\t\tEnableLocalScriptChecks:          true,\n\t\tEnableSyslog:                     true,\n\t\tEnableUI:                         true,\n\t\tEncryptKey:                       \"A4wELWqH\",\n\t\tEncryptVerifyIncoming:            true,\n\t\tEncryptVerifyOutgoing:            true,\n\t\tGRPCPort:                         4881,\n\t\tGRPCAddrs:                        []net.Addr{tcpAddr(\"32.31.61.91:4881\")},\n\t\tHTTPAddrs:                        []net.Addr{tcpAddr(\"83.39.91.39:7999\")},\n\t\tHTTPBlockEndpoints:               []string{\"RBvAFcGD\", \"fWOWFznh\"},\n\t\tAllowWriteHTTPFrom:               []*net.IPNet{cidr(\"127.0.0.0/8\"), cidr(\"22.33.44.55/32\"), cidr(\"0.0.0.0/0\")},\n\t\tHTTPPort:                         7999,\n\t\tHTTPResponseHeaders:              map[string]string{\"M6TKa9NP\": \"xjuxjOzQ\", \"JRCrHZed\": \"rl0mTx81\"},\n\t\tHTTPSAddrs:                       []net.Addr{tcpAddr(\"95.17.17.19:15127\")},\n\t\tHTTPMaxConnsPerClient:            9283,\n\t\tHTTPSHandshakeTimeout:            2391 * time.Millisecond,\n\t\tHTTPSPort:                        15127,\n\t\tKeyFile:                          \"IEkkwgIA\",\n\t\tKVMaxValueSize:                   1234567800000000,\n\t\tLeaveDrainTime:                   8265 * time.Second,\n\t\tLeaveOnTerm:                      true,\n\t\tLogLevel:                         \"k1zo9Spt\",\n\t\tNodeID:                           types.NodeID(\"AsUIlw99\"),\n\t\tNodeMeta:                         map[string]string{\"5mgGQMBk\": \"mJLtVMSG\", \"A7ynFMJB\": \"0Nx6RGab\"},\n\t\tNodeName:                         \"otlLxGaI\",\n\t\tNonVotingServer:                  true,\n\t\tPidFile:                          \"43xN80Km\",\n\t\tPrimaryDatacenter:                \"ejtmd43d\",\n\t\tRPCAdvertiseAddr:                 tcpAddr(\"17.99.29.16:3757\"),\n\t\tRPCBindAddr:                      tcpAddr(\"16.99.34.17:3757\"),\n\t\tRPCHandshakeTimeout:              1932 * time.Millisecond,\n\t\tRPCHoldTimeout:                   15707 * time.Second,\n\t\tRPCProtocol:                      30793,\n\t\tRPCRateLimit:                     12029.43,\n\t\tRPCMaxBurst:                      44848,\n\t\tRPCMaxConnsPerClient:             2954,\n\t\tRaftProtocol:                     19016,\n\t\tRaftSnapshotThreshold:            16384,\n\t\tRaftSnapshotInterval:             30 * time.Second,\n\t\tRaftTrailingLogs:                 83749,\n\t\tReconnectTimeoutLAN:              23739 * time.Second,\n\t\tReconnectTimeoutWAN:              26694 * time.Second,\n\t\tRejoinAfterLeave:                 true,\n\t\tRetryJoinIntervalLAN:             8067 * time.Second,\n\t\tRetryJoinIntervalWAN:             28866 * time.Second,\n\t\tRetryJoinLAN:                     []string{\"pbsSFY7U\", \"l0qLtWij\"},\n\t\tRetryJoinMaxAttemptsLAN:          913,\n\t\tRetryJoinMaxAttemptsWAN:          23160,\n\t\tRetryJoinWAN:                     []string{\"PFsR02Ye\", \"rJdQIhER\"},\n\t\tSegmentName:                      \"BC2NhTDi\",\n\t\tSegments: []structs.NetworkSegment{\n\t\t\t{\n\t\t\t\tName:        \"PExYMe2E\",\n\t\t\t\tBind:        tcpAddr(\"36.73.36.19:38295\"),\n\t\t\t\tAdvertise:   tcpAddr(\"63.39.19.18:38295\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:        \"UzCvJgup\",\n\t\t\t\tBind:        tcpAddr(\"37.58.38.19:39292\"),\n\t\t\t\tAdvertise:   tcpAddr(\"83.58.26.27:39292\"),\n\t\t\t\tRPCListener: true,\n\t\t\t},\n\t\t},\n\t\tSerfPortLAN: 8301,\n\t\tSerfPortWAN: 8302,\n\t\tServerMode:  true,\n\t\tServerName:  \"Oerr9n1G\",\n\t\tServerPort:  3757,\n\t\tServices: []*structs.ServiceDefinition{\n\t\t\t{\n\t\t\t\tID:      \"wI1dzxS4\",\n\t\t\t\tName:    \"7IszXMQ1\",\n\t\t\t\tTags:    []string{\"0Zwg8l6v\", \"zebELdN5\"},\n\t\t\t\tAddress: \"9RhqPSPB\",\n\t\t\t\tToken:   \"myjKJkWH\",\n\t\t\t\tPort:    72219,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: []*structs.CheckType{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"qmfeO5if\",\n\t\t\t\t\t\tName:       \"atDGP7n5\",\n\t\t\t\t\t\tStatus:     \"pDQKEhWL\",\n\t\t\t\t\t\tNotes:      \"Yt8EDLev\",\n\t\t\t\t\t\tScriptArgs: []string{\"81EDZLPa\", \"bPY5X8xd\"},\n\t\t\t\t\t\tHTTP:       \"qzHYvmJO\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"UkpmZ3a3\": {\"2dfzXuxZ\"},\n\t\t\t\t\t\t\t\"cVFpko4u\": {\"gGqdEB6k\", \"9LsRo22u\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"X5DrovFc\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"ICbxkpSF\",\n\t\t\t\t\t\tInterval:                       24392 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ZKXr68Yb\",\n\t\t\t\t\t\tShell:                          \"CEfzx0Fo\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38333 * time.Second,\n\t\t\t\t\t\tTTL:                            57201 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 44214 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t// Note that although this SidecarService is only syntax sugar for\n\t\t\t\t// registering another service, that has to happen in the agent code so\n\t\t\t\t// it can make intelligent decisions about automatic port assignments\n\t\t\t\t// etc. So we expect config just to pass it through verbatim.\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tSidecarService: &structs.ServiceDefinition{\n\t\t\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\t\t\tPassing: 1,\n\t\t\t\t\t\t\tWarning: 1,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:      \"MRHVMZuD\",\n\t\t\t\tName:    \"6L6BVfgH\",\n\t\t\t\tTags:    []string{\"7Ale4y6o\", \"PMBW08hy\"},\n\t\t\t\tAddress: \"R6H6g8h0\",\n\t\t\t\tToken:   \"ZgY8gjMI\",\n\t\t\t\tPort:    38292,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1979,\n\t\t\t\t\tWarning: 6,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"GTti9hCo\",\n\t\t\t\t\t\tName:       \"9OOS93ne\",\n\t\t\t\t\t\tNotes:      \"CQy86DH0\",\n\t\t\t\t\t\tStatus:     \"P0SWDvrk\",\n\t\t\t\t\t\tScriptArgs: []string{\"EXvkYIuG\", \"BATOyt6h\"},\n\t\t\t\t\t\tHTTP:       \"u97ByEiW\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"MUlReo8L\": {\"AUZG7wHG\", \"gsN0Dc2N\"},\n\t\t\t\t\t\t\t\"1UJXjVrT\": {\"OJgxzTfk\", \"xZZrFsq7\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"5wkAxCUE\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"MN3oA9D2\",\n\t\t\t\t\t\tInterval:                       32718 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"cU15LMet\",\n\t\t\t\t\t\tShell:                          \"nEz9qz2l\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        34738 * time.Second,\n\t\t\t\t\t\tTTL:                            22773 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 84282 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"UHsDeLxG\",\n\t\t\t\t\t\tName:       \"PQSaPWlT\",\n\t\t\t\t\t\tNotes:      \"jKChDOdl\",\n\t\t\t\t\t\tStatus:     \"5qFz6OZn\",\n\t\t\t\t\t\tScriptArgs: []string{\"NMtYWlT9\", \"vj74JXsm\"},\n\t\t\t\t\t\tHTTP:       \"1LBDJhw4\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"cXPmnv1M\": {\"imDqfaBx\", \"NFxZ1bQe\"},\n\t\t\t\t\t\t\t\"vr7wY7CS\": {\"EtCoNPPL\", \"9vAarJ5s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"wzByP903\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"2exjZIGE\",\n\t\t\t\t\t\tInterval:                       5656 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"5tDBWpfA\",\n\t\t\t\t\t\tShell:                          \"rlTpLM8s\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        4868 * time.Second,\n\t\t\t\t\t\tTTL:                            11222 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tConnect: &structs.ServiceConnect{},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"Kh81CPF6\",\n\t\t\t\tName: \"Kh81CPF6-proxy\",\n\t\t\t\tPort: 31471,\n\t\t\t\tKind: \"connect-proxy\",\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tDestinationServiceName: \"6L6BVfgH\",\n\t\t\t\t\tDestinationServiceID:   \"6L6BVfgH-id\",\n\t\t\t\t\tLocalServiceAddress:    \"127.0.0.2\",\n\t\t\t\t\tLocalServicePort:       23759,\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"cedGGtZf\": \"pWrUNiWw\",\n\t\t\t\t\t},\n\t\t\t\t\tUpstreams: structs.Upstreams{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType: \"service\", // Default should be explicitly filled\n\t\t\t\t\t\t\tDestinationName: \"KPtAj2cb\",\n\t\t\t\t\t\t\tLocalBindPort:   4051,\n\t\t\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\t\t\"kzRnZOyd\": \"nUNKoL8H\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tDestinationType:      \"prepared_query\",\n\t\t\t\t\t\t\tDestinationNamespace: \"9nakw0td\",\n\t\t\t\t\t\t\tDestinationName:      \"KSd8HsRl\",\n\t\t\t\t\t\t\tLocalBindPort:        11884,\n\t\t\t\t\t\t\tLocalBindAddress:     \"127.24.88.0\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tExpose: structs.ExposeConfig{\n\t\t\t\t\t\tChecks: true,\n\t\t\t\t\t\tPaths: []structs.ExposePath{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tPath:          \"/health\",\n\t\t\t\t\t\t\t\tLocalPathPort: 8080,\n\t\t\t\t\t\t\t\tListenerPort:  21500,\n\t\t\t\t\t\t\t\tProtocol:      \"http\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"kvVqbwSE\",\n\t\t\t\tKind: \"mesh-gateway\",\n\t\t\t\tName: \"gw-primary-dc\",\n\t\t\t\tPort: 27147,\n\t\t\t\tProxy: &structs.ConnectProxyConfig{\n\t\t\t\t\tConfig: map[string]interface{}{\n\t\t\t\t\t\t\"1CuJHVfw\": \"Kzqsa7yc\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 1,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tID:   \"dLOXpSCI\",\n\t\t\t\tName: \"o1ynPkp0\",\n\t\t\t\tTaggedAddresses: map[string]structs.ServiceAddress{\n\t\t\t\t\t\"lan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"2d79888a\",\n\t\t\t\t\t\tPort:    2143,\n\t\t\t\t\t},\n\t\t\t\t\t\"wan\": structs.ServiceAddress{\n\t\t\t\t\t\tAddress: \"d4db85e2\",\n\t\t\t\t\t\tPort:    6109,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tTags:    []string{\"nkwshvM5\", \"NTDWn3ek\"},\n\t\t\t\tAddress: \"cOlSOhbp\",\n\t\t\t\tToken:   \"msy7iWER\",\n\t\t\t\tMeta:    map[string]string{\"mymeta\": \"data\"},\n\t\t\t\tPort:    24237,\n\t\t\t\tWeights: &structs.Weights{\n\t\t\t\t\tPassing: 100,\n\t\t\t\t\tWarning: 1,\n\t\t\t\t},\n\t\t\t\tEnableTagOverride: true,\n\t\t\t\tConnect: &structs.ServiceConnect{\n\t\t\t\t\tNative: true,\n\t\t\t\t},\n\t\t\t\tChecks: structs.CheckTypes{\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"Zv99e9Ka\",\n\t\t\t\t\t\tName:       \"sgV4F7Pk\",\n\t\t\t\t\t\tNotes:      \"yP5nKbW0\",\n\t\t\t\t\t\tStatus:     \"7oLMEyfu\",\n\t\t\t\t\t\tScriptArgs: []string{\"5wEZtZpv\", \"0Ihyk8cS\"},\n\t\t\t\t\t\tHTTP:       \"KyDjGY9H\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"gv5qefTz\": {\"5Olo2pMG\", \"PvvKWQU5\"},\n\t\t\t\t\t\t\t\"SHOVq1Vv\": {\"jntFhyym\", \"GYJh32pp\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"T66MFBfR\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"bNnNfx2A\",\n\t\t\t\t\t\tInterval:                       22224 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"ipgdFtjd\",\n\t\t\t\t\t\tShell:                          \"omVZq7Sz\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        18913 * time.Second,\n\t\t\t\t\t\tTTL:                            44743 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 8482 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"G79O6Mpr\",\n\t\t\t\t\t\tName:       \"IEqrzrsd\",\n\t\t\t\t\t\tNotes:      \"SVqApqeM\",\n\t\t\t\t\t\tStatus:     \"XXkVoZXt\",\n\t\t\t\t\t\tScriptArgs: []string{\"wD05Bvao\", \"rLYB7kQC\"},\n\t\t\t\t\t\tHTTP:       \"kyICZsn8\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"4ebP5vL4\": {\"G20SrL5Q\", \"DwPKlMbo\"},\n\t\t\t\t\t\t\t\"p2UI34Qz\": {\"UsG1D0Qh\", \"NHhRiB6s\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"ciYHWors\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"FfvCwlqH\",\n\t\t\t\t\t\tInterval:                       12356 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"HBndBU6R\",\n\t\t\t\t\t\tShell:                          \"hVI33JjA\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38282 * time.Second,\n\t\t\t\t\t\tTTL:                            1181 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 4992 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t\t&structs.CheckType{\n\t\t\t\t\t\tCheckID:    \"RMi85Dv8\",\n\t\t\t\t\t\tName:       \"iehanzuq\",\n\t\t\t\t\t\tStatus:     \"rCvn53TH\",\n\t\t\t\t\t\tNotes:      \"fti5lfF3\",\n\t\t\t\t\t\tScriptArgs: []string{\"16WRUmwS\", \"QWk7j7ae\"},\n\t\t\t\t\t\tHTTP:       \"dl3Fgme3\",\n\t\t\t\t\t\tHeader: map[string][]string{\n\t\t\t\t\t\t\t\"rjm4DEd3\": {\"2m3m2Fls\"},\n\t\t\t\t\t\t\t\"l4HwQ112\": {\"fk56MNlo\", \"dhLK56aZ\"},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tMethod:                         \"9afLm3Mj\",\n\t\t\t\t\t\tOutputMaxSize:                  checks.DefaultBufSize,\n\t\t\t\t\t\tTCP:                            \"fjiLFqVd\",\n\t\t\t\t\t\tInterval:                       23926 * time.Second,\n\t\t\t\t\t\tDockerContainerID:              \"dO5TtRHk\",\n\t\t\t\t\t\tShell:                          \"e6q2ttES\",\n\t\t\t\t\t\tTLSSkipVerify:                  true,\n\t\t\t\t\t\tTimeout:                        38483 * time.Second,\n\t\t\t\t\t\tTTL:                            10943 * time.Second,\n\t\t\t\t\t\tDeregisterCriticalServiceAfter: 68787 * time.Second,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tSerfAdvertiseAddrLAN: tcpAddr(\"17.99.29.16:8301\"),\n\t\tSerfAdvertiseAddrWAN: tcpAddr(\"78.63.37.19:8302\"),\n\t\tSerfBindAddrLAN:      tcpAddr(\"99.43.63.15:8301\"),\n\t\tSerfBindAddrWAN:      tcpAddr(\"67.88.33.19:8302\"),\n\t\tSessionTTLMin:        26627 * time.Second,\n\t\tSkipLeaveOnInt:       true,\n\t\tStartJoinAddrsLAN:    []string{\"LR3hGDoG\", \"MwVpZ4Up\"},\n\t\tStartJoinAddrsWAN:    []string{\"EbFSc3nA\", \"kwXTh623\"},\n\t\tSyslogFacility:       \"hHv79Uia\",\n\t\tTelemetry: lib.TelemetryConfig{\n\t\t\tCirconusAPIApp:                     \"p4QOTe9j\",\n\t\t\tCirconusAPIToken:                   \"E3j35V23\",\n\t\t\tCirconusAPIURL:                     \"mEMjHpGg\",\n\t\t\tCirconusBrokerID:                   \"BHlxUhed\",\n\t\t\tCirconusBrokerSelectTag:            \"13xy1gHm\",\n\t\t\tCirconusCheckDisplayName:           \"DRSlQR6n\",\n\t\t\tCirconusCheckForceMetricActivation: \"Ua5FGVYf\",\n\t\t\tCirconusCheckID:                    \"kGorutad\",\n\t\t\tCirconusCheckInstanceID:            \"rwoOL6R4\",\n\t\t\tCirconusCheckSearchTag:             \"ovT4hT4f\",\n\t\t\tCirconusCheckTags:                  \"prvO4uBl\",\n\t\t\tCirconusSubmissionInterval:         \"DolzaflP\",\n\t\t\tCirconusSubmissionURL:              \"gTcbS93G\",\n\t\t\tDisableHostname:                    true,\n\t\t\tDogstatsdAddr:                      \"0wSndumK\",\n\t\t\tDogstatsdTags:                      []string{\"3N81zSUB\", \"Xtj8AnXZ\"},\n\t\t\tFilterDefault:                      true,\n\t\t\tAllowedPrefixes:                    []string{\"oJotS8XJ\"},\n\t\t\tBlockedPrefixes:                    []string{\"cazlEhGn\"},\n\t\t\tMetricsPrefix:                      \"ftO6DySn\",\n\t\t\tPrometheusRetentionTime:            15 * time.Second,\n\t\t\tStatsdAddr:                         \"drce87cy\",\n\t\t\tStatsiteAddr:                       \"HpFwKB8R\",\n\t\t},\n\t\tTLSCipherSuites:             []uint16{tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384},\n\t\tTLSMinVersion:               \"pAOWafkR\",\n\t\tTLSPreferServerCipherSuites: true,\n\t\tTaggedAddresses: map[string]string{\n\t\t\t\"7MYgHrYH\": \"dALJAhLD\",\n\t\t\t\"h6DdBy6K\": \"ebrr9zZ8\",\n\t\t\t\"lan\":      \"17.99.29.16\",\n\t\t\t\"wan\":      \"78.63.37.19\",\n\t\t},\n\t\tTranslateWANAddrs:    true,\n\t\tUIContentPath:        \"/ui/\",\n\t\tUIDir:                \"11IFzAUn\",\n\t\tUnixSocketUser:       \"E0nB1DwA\",\n\t\tUnixSocketGroup:      \"8pFodrV8\",\n\t\tUnixSocketMode:       \"E8sAwOv4\",\n\t\tVerifyIncoming:       true,\n\t\tVerifyIncomingHTTPS:  true,\n\t\tVerifyIncomingRPC:    true,\n\t\tVerifyOutgoing:       true,\n\t\tVerifyServerHostname: true,\n\t\tWatches: []map[string]interface{}{\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"key\",\n\t\t\t\t\"datacenter\": \"GyE6jpeW\",\n\t\t\t\t\"key\":        \"j9lF1Tve\",\n\t\t\t\t\"handler\":    \"90N7S4LN\",\n\t\t\t},\n\t\t\tmap[string]interface{}{\n\t\t\t\t\"type\":       \"keyprefix\",\n\t\t\t\t\"datacenter\": \"fYrl3F5d\",\n\t\t\t\t\"key\":        \"sl3Dffu7\",\n\t\t\t\t\"args\":       []interface{}{\"dltjDJ2a\", \"flEa7C2d\"},\n\t\t\t},\n\t\t},\n\t}\n\n\twarns := []string{\n\t\t`The 'acl_datacenter' field is deprecated. Use the 'primary_datacenter' field instead.`,\n\t\t`bootstrap_expect > 0: expecting 53 servers`,\n\t}\n\n\t// ensure that all fields are set to unique non-zero values\n\t// todo(fs): This currently fails since ServiceDefinition.Check is not used\n\t// todo(fs): not sure on how to work around this. Possible options are:\n\t// todo(fs):  * move first check into the Check field\n\t// todo(fs):  * ignore the Check field\n\t// todo(fs): both feel like a hack\n\tif err := nonZero(\"RuntimeConfig\", nil, want); err != nil {\n\t\tt.Log(err)\n\t}\n\n\tfor format, data := range src {\n\t\tt.Run(format, func(t *testing.T) {\n\t\t\t// parse the flags since this is the only way we can set the\n\t\t\t// DevMode flag\n\t\t\tvar flags Flags\n\t\t\tfs := flag.NewFlagSet(\"\", flag.ContinueOnError)\n\t\t\tAddFlags(fs, &flags)\n\t\t\tif err := fs.Parse(flagSrc); err != nil {\n\t\t\t\tt.Fatalf(\"ParseFlags: %s\", err)\n\t\t\t}\n\n\t\t\t// ensure that all fields are set to unique non-zero values\n\t\t\t// if err := nonZero(\"Config\", nil, c); err != nil {\n\t\t\t// \tt.Fatal(err)\n\t\t\t// }\n\n\t\t\tb, err := NewBuilder(flags)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"NewBuilder: %s\", err)\n\t\t\t}\n\t\t\tb.Sources = append(b.Sources, Source{Name: \"full.\" + format, Data: data})\n\t\t\tb.Tail = append(b.Tail, tail[format]...)\n\t\t\tb.Tail = append(b.Tail, VersionSource(\"JNtPSav3\", \"R909Hblt\", \"ZT1JOQLn\"))\n\n\t\t\t// construct the runtime config\n\t\t\trt, err := b.Build()\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Build: %s\", err)\n\t\t\t}\n\n\t\t\t// verify that all fields are set\n\t\t\tif !verify.Values(t, \"runtime_config\", rt, want) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\n\t\t\t// at this point we have confirmed that the parsing worked\n\t\t\t// for all fields but the validation will fail since certain\n\t\t\t// combinations are not allowed. Since it is not possible to have\n\t\t\t// all fields with non-zero values and to have a valid configuration\n\t\t\t// we are patching a handful of safe fields to make validation pass.\n\t\t\trt.Bootstrap = false\n\t\t\trt.DevMode = false\n\t\t\trt.EnableUI = false\n\t\t\trt.SegmentName = \"\"\n\t\t\trt.Segments = nil\n\n\t\t\t// validate the runtime config\n\t\t\tif err := b.Validate(rt); err != nil {\n\t\t\t\tt.Fatalf(\"Validate: %s\", err)\n\t\t\t}\n\n\t\t\t// check the warnings\n\t\t\tif got, want := b.Warnings, warns; !verify.Values(t, \"warnings\", got, want) {\n\t\t\t\tt.FailNow()\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestImportSubjectValidation(t *testing.T) {\n\tak := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\tactivation := NewActivationClaims(akp)\n\tactivation.Expires = time.Now().Add(time.Hour).UTC().Unix()\n\tactivation.ImportSubject = \"one.*\"\n\tactivation.ImportType = Stream\n\n\tak2 := createAccountNKey(t)\n\takp2 := publicKey(ak2, t)\n\ti := &Import{Subject: \"one.two\", Account: akp2, To: \"bar\", Type: Stream}\n\n\tactJWT := encode(activation, ak2, t)\n\ti.Token = actJWT\n\tvr := CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Log(vr.Issues[0].Description)\n\t\tt.Errorf(\"imports with valid contains subject should be valid\")\n\t}\n\n\tactivation.ImportSubject = \"two\"\n\tactivation.ImportType = Stream\n\tactJWT = encode(activation, ak2, t)\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports with non-contains subject should be not valid\")\n\t}\n\n\tactivation.ImportSubject = \">\"\n\tactivation.ImportType = Stream\n\tactJWT = encode(activation, ak2, t)\n\ti.Token = actJWT\n\tvr = CreateValidationResults()\n\ti.Validate(akp, vr)\n\n\tif !vr.IsEmpty() {\n\t\tt.Errorf(\"imports with valid contains subject should be valid\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func GetRandomStringFromRange(a, b int) string {\n\tvar i int\n\tif a > b {\n\t\ti = rand.Intn(a-b) + b\n\t} else {\n\t\ti = rand.Intn(b-a) + a\n\t}\n\treturn gen(i, charset)\n}", "is_vulnerable": 1}
{"code": "func HTTP(c *HTTPContext) {\n\tfor _, route := range routes {\n\t\treqPath := strings.ToLower(c.Req.URL.Path)\n\t\tm := route.re.FindStringSubmatch(reqPath)\n\t\tif m == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\t// We perform check here because route matched in cmd/web.go is wider than needed,\n\t\t// but we only want to output this message only if user is really trying to access\n\t\t// Git HTTP endpoints.\n\t\tif conf.Repository.DisableHTTPGit {\n\t\t\tc.Error(http.StatusForbidden, \"Interacting with repositories by HTTP protocol is disabled\")\n\t\t\treturn\n\t\t}\n\n\t\tif route.method != c.Req.Method {\n\t\t\tc.Error(http.StatusNotFound)\n\t\t\treturn\n\t\t}\n\n\t\tcleaned := pathutil.Clean(m[1])\n\t\tif m[1] != \"/\"+cleaned {\n\t\t\tc.Error(http.StatusBadRequest, \"Request path contains suspicious characters\")\n\t\t\treturn\n\t\t}\n\n\t\tfile := strings.TrimPrefix(reqPath, cleaned)\n\t\tdir, err := getGitRepoPath(cleaned)\n\t\tif err != nil {\n\t\t\tlog.Warn(\"HTTP.getGitRepoPath: %v\", err)\n\t\t\tc.Error(http.StatusNotFound)\n\t\t\treturn\n\t\t}\n\n\t\troute.handler(serviceHandler{\n\t\t\tw:    c.Resp,\n\t\t\tr:    c.Req.Request,\n\t\t\tdir:  dir,\n\t\t\tfile: file,\n\n\t\t\tauthUser:  c.AuthUser,\n\t\t\townerName: c.OwnerName,\n\t\t\townerSalt: c.OwnerSalt,\n\t\t\trepoID:    c.RepoID,\n\t\t\trepoName:  c.RepoName,\n\t\t})\n\t\treturn\n\t}\n\n\tc.Error(http.StatusNotFound)\n}", "is_vulnerable": 0}
{"code": "\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tgot := hasPrefixCaseInsensitive(tc.path, tc.prefix)\n\t\t\tmust.Eq(t, tc.expected, got)\n\t\t})", "is_vulnerable": 0}
{"code": "func (p Precompile) Clawback(\n\tctx sdk.Context,\n\tcontract *vm.Contract,\n\torigin common.Address,\n\tstateDB vm.StateDB,\n\tmethod *abi.Method,\n\targs []interface{},\n) ([]byte, error) {\n\tmsg, funderAddr, accountAddr, destAddr, err := NewMsgClawback(args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// if caller address is origin, the funder MUST match the origin\n\tif contract.CallerAddress == origin && origin != funderAddr {\n\t\treturn nil, fmt.Errorf(ErrDifferentFunderOrigin, origin, funderAddr)\n\t}\n\n\tp.Logger(ctx).Debug(\n\t\t\"tx called\",\n\t\t\"method\", method.Name,\n\t\t\"args\", fmt.Sprintf(\n\t\t\t\"{ funder_address: %s, account_address: %s, dest_address: %s }\",\n\t\t\tmsg.FunderAddress, msg.AccountAddress, msg.DestAddress,\n\t\t),\n\t)\n\n\tif contract.CallerAddress != origin {\n\t\t// check if authorization exists\n\t\t_, _, err := authorization.CheckAuthzExists(ctx, p.AuthzKeeper, contract.CallerAddress, origin, ClawbackMsgURL)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(authorization.ErrAuthzDoesNotExistOrExpired, contract.CallerAddress, origin)\n\t\t}\n\t}\n\n\tresponse, err := p.vestingKeeper.Clawback(sdk.WrapSDKContext(ctx), msg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err = p.EmitClawbackEvent(ctx, stateDB, funderAddr, accountAddr, destAddr); err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := new(ClawbackOutput).FromResponse(response)\n\n\treturn method.Outputs.Pack(out.Coins)\n}", "is_vulnerable": 1}
{"code": "func (d apngGenerator) GetOriginDimensions(b []byte, contentType string, ctx rcontext.RequestContext) (bool, int, int, error) {\n\ti, err := apng.DecodeConfig(bytes.NewBuffer(b))\n\tif err != nil {\n\t\treturn false, 0, 0, err\n\t}\n\treturn true, i.Width, i.Height, nil\n}", "is_vulnerable": 0}
{"code": "func TestAccessLog(t *testing.T) {\n\tserver := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {}))\n\n\tt.Cleanup(func() { server.Close() })\n\n\ttestCases := []struct {\n\t\tdesc              string\n\t\troutersConfig     map[string]*dynamic.Router\n\t\tserviceConfig     map[string]*dynamic.Service\n\t\tmiddlewaresConfig map[string]*dynamic.Middleware\n\t\tentryPoints       []string\n\t\texpected          string\n\t}{\n\t\t{\n\t\t\tdesc: \"apply routerName in accesslog (first match)\",\n\t\t\troutersConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: server.URL,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tentryPoints: []string{\"web\"},\n\t\t\texpected:    \"foo\",\n\t\t},\n\t\t{\n\t\t\tdesc: \"apply routerName in accesslog (second match)\",\n\t\t\troutersConfig: map[string]*dynamic.Router{\n\t\t\t\t\"foo\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`bar.foo`)\",\n\t\t\t\t},\n\t\t\t\t\"bar\": {\n\t\t\t\t\tEntryPoints: []string{\"web\"},\n\t\t\t\t\tService:     \"foo-service\",\n\t\t\t\t\tRule:        \"Host(`foo.bar`)\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tserviceConfig: map[string]*dynamic.Service{\n\t\t\t\t\"foo-service\": {\n\t\t\t\t\tLoadBalancer: &dynamic.ServersLoadBalancer{\n\t\t\t\t\t\tServers: []dynamic.Server{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tURL: server.URL,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tentryPoints: []string{\"web\"},\n\t\t\texpected:    \"bar\",\n\t\t},\n\t}\n\n\tfor _, test := range testCases {\n\t\tt.Run(test.desc, func(t *testing.T) {\n\t\t\trtConf := runtime.NewConfig(dynamic.Configuration{\n\t\t\t\tHTTP: &dynamic.HTTPConfiguration{\n\t\t\t\t\tServices:    test.serviceConfig,\n\t\t\t\t\tRouters:     test.routersConfig,\n\t\t\t\t\tMiddlewares: test.middlewaresConfig,\n\t\t\t\t},\n\t\t\t})\n\n\t\t\troundTripperManager := service.NewRoundTripperManager()\n\t\t\troundTripperManager.Update(map[string]*dynamic.ServersTransport{\"default@internal\": {}})\n\t\t\tserviceManager := service.NewManager(rtConf.Services, nil, nil, roundTripperManager)\n\t\t\tmiddlewaresBuilder := middleware.NewBuilder(rtConf.Middlewares, serviceManager, nil)\n\t\t\tchainBuilder := middleware.NewChainBuilder(nil, nil, nil)\n\n\t\t\trouterManager := NewManager(rtConf, serviceManager, middlewaresBuilder, chainBuilder, metrics.NewVoidRegistry())\n\n\t\t\thandlers := routerManager.BuildHandlers(context.Background(), test.entryPoints, false)\n\n\t\t\tw := httptest.NewRecorder()\n\t\t\treq := testhelpers.MustNewRequest(http.MethodGet, \"http://foo.bar/\", nil)\n\n\t\t\taccesslogger, err := accesslog.NewHandler(&types.AccessLog{\n\t\t\t\tFormat: \"json\",\n\t\t\t})\n\t\t\trequire.NoError(t, err)\n\n\t\t\treqHost := requestdecorator.New(nil)\n\n\t\t\tchain := alice.New()\n\t\t\tchain = chain.Append(capture.Wrap)\n\t\t\tchain = chain.Append(accesslog.WrapHandler(accesslogger))\n\t\t\thandler, err := chain.Then(http.HandlerFunc(func(rw http.ResponseWriter, req *http.Request) {\n\t\t\t\treqHost.ServeHTTP(w, req, handlers[\"web\"].ServeHTTP)\n\n\t\t\t\tdata := accesslog.GetLogData(req)\n\t\t\t\trequire.NotNil(t, data)\n\n\t\t\t\tassert.Equal(t, test.expected, data.Core[accesslog.RouterName])\n\t\t\t}))\n\t\t\trequire.NoError(t, err)\n\n\t\t\thandler.ServeHTTP(w, req)\n\t\t})\n\t}\n}", "is_vulnerable": 1}
{"code": "func (s *store) Watch(ctx context.Context, key string, opts storage.ListOptions) (watch.Interface, error) {\n\trev, err := s.versioner.ParseResourceVersion(opts.ResourceVersion)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkey = path.Join(s.pathPrefix, key)\n\treturn s.watcher.Watch(ctx, key, int64(rev), opts.Recursive, opts.ProgressNotify, s.transformer, opts.Predicate)\n}", "is_vulnerable": 1}
{"code": "func (n *errorKeyingTransport) setInitialKEXDone() {}", "is_vulnerable": 0}
{"code": "func toValidName(name string) string {\n\tp := filepath.Clean(name)\n\tif strings.HasPrefix(p, \"/\") {\n\t\tp = p[len(\"/\"):]\n\t}\n\tfor strings.HasPrefix(p, \"../\") {\n\t\tp = p[len(\"../\"):]\n\t}\n\treturn p\n}", "is_vulnerable": 0}
{"code": "func DevelopmentHandler(next http.Handler, sessionManager *scs.SessionManager, accessToken string, clientSetsCreator clientSetsCreator) http.Handler {\n\tgob.Register(userapiv1.User{})\n\n\treturn http.HandlerFunc(func(rw http.ResponseWriter, req *http.Request) {\n\n\t\tkubeconfig := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(\n\t\t\tclientcmd.NewDefaultClientConfigLoadingRules(),\n\t\t\t&clientcmd.ConfigOverrides{},\n\t\t)\n\n\t\tconfig, err := kubeconfig.ClientConfig()\n\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Failed to build config : %v\", err)\n\t\t\thttp.Error(rw, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t\t_, userclient, coreClient, err := clientSetsCreator(config)\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Failed to build client set : %v\", err)\n\t\t\thttp.Error(rw, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tvar loggedOnUser userapiv1.User\n\t\tif sessionManager.Exists(req.Context(), loggedOnUserSessionAttribute) {\n\t\t\tloggedOnUser = sessionManager.Get(req.Context(), loggedOnUserSessionAttribute).(userapiv1.User)\n\t\t} else {\n\t\t\tloggedOnUser = getLoggedOnUser(req, userclient, \"\")\n\t\t\tsessionManager.Put(req.Context(), loggedOnUserSessionAttribute, loggedOnUser)\n\t\t}\n\n\t\trequestState := &server.RequestState{\n\t\t\tEnmasseV1beta1Client: coreClient,\n\t\t\tAccessController:     accesscontroller.NewAllowAllAccessController(),\n\t\t\tUser:                 loggedOnUser,\n\t\t\tUserAccessToken:      accessToken,\n\t\t\tUseSession:           true,\n\t\t\tImpersonatedUser:     \"\",\n\t\t}\n\n\t\tctx := server.ContextWithRequestState(requestState, req.Context())\n\t\tnext.ServeHTTP(rw, req.WithContext(ctx))\n\t})\n}", "is_vulnerable": 0}
{"code": "func fieldSeccompProfile(scmp *v1.SeccompProfile, profileRootPath string, fallbackToRuntimeDefault bool) *runtimeapi.SecurityProfile {\n\tif scmp == nil {\n\t\tif fallbackToRuntimeDefault {\n\t\t\treturn &runtimeapi.SecurityProfile{\n\t\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t\t}\n\t\t}\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t\t}\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeRuntimeDefault {\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType: runtimeapi.SecurityProfile_RuntimeDefault,\n\t\t}\n\t}\n\tif scmp.Type == v1.SeccompProfileTypeLocalhost && scmp.LocalhostProfile != nil && len(*scmp.LocalhostProfile) > 0 {\n\t\tfname := filepath.Join(profileRootPath, *scmp.LocalhostProfile)\n\t\treturn &runtimeapi.SecurityProfile{\n\t\t\tProfileType:  runtimeapi.SecurityProfile_Localhost,\n\t\t\tLocalhostRef: fname,\n\t\t}\n\t}\n\treturn &runtimeapi.SecurityProfile{\n\t\tProfileType: runtimeapi.SecurityProfile_Unconfined,\n\t}\n}", "is_vulnerable": 1}
{"code": "\tstream := dispatchpkg.NewHandlingDispatchStream(ctx, func(result *dispatch.DispatchLookupResourcesResponse) error {\n\t\tfound := result.ResolvedResource\n\n\t\tdispatchpkg.AddResponseMetadata(respMetadata, result.Metadata)\n\t\tcurrentCursor = result.AfterResponseCursor\n\n\t\tvar partial *v1.PartialCaveatInfo\n\t\tpermissionship := v1.LookupPermissionship_LOOKUP_PERMISSIONSHIP_HAS_PERMISSION\n\t\tif found.Permissionship == dispatch.ResolvedResource_CONDITIONALLY_HAS_PERMISSION {\n\t\t\tpermissionship = v1.LookupPermissionship_LOOKUP_PERMISSIONSHIP_CONDITIONAL_PERMISSION\n\t\t\tpartial = &v1.PartialCaveatInfo{\n\t\t\t\tMissingRequiredContext: found.MissingRequiredContext,\n\t\t\t}\n\t\t} else if req.OptionalLimit == 0 {\n\t\t\tif _, ok := alreadyPublishedPermissionedResourceIds[found.ResourceId]; ok {\n\t\t\t\t// Skip publishing the duplicate.\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\talreadyPublishedPermissionedResourceIds[found.ResourceId] = struct{}{}\n\t\t}\n\n\t\tencodedCursor, err := cursor.EncodeFromDispatchCursor(result.AfterResponseCursor, lrRequestHash)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = resp.Send(&v1.LookupResourcesResponse{\n\t\t\tLookedUpAt:        revisionReadAt,\n\t\t\tResourceObjectId:  found.ResourceId,\n\t\t\tPermissionship:    permissionship,\n\t\t\tPartialCaveatInfo: partial,\n\t\t\tAfterResultCursor: encodedCursor,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})", "is_vulnerable": 0}
{"code": "func (lt *limitTracker) markAlreadyPublished(count uint32) error {\n\tif !lt.hasLimit {\n\t\treturn nil\n\t}\n\n\tif count > lt.currentLimit {\n\t\treturn spiceerrors.MustBugf(\"given published count of %d exceeds the remaining limit of %d\", count, lt.currentLimit)\n\t}\n\n\tlt.currentLimit -= count\n\tif lt.currentLimit == 0 {\n\t\treturn nil\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) Reconfigure(ctx context.Context, in *sliverpb.ReconfigureReq, opts ...grpc.CallOption) (*sliverpb.Reconfigure, error) {\n\tout := new(sliverpb.Reconfigure)\n\terr := c.cc.Invoke(ctx, SliverRPC_Reconfigure_FullMethodName, in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 1}
{"code": "func (fs *Filesystem) ReadDir(path string) ([]ufs.DirEntry, error) {\n\treturn fs.unixFS.ReadDir(path)\n}", "is_vulnerable": 0}
{"code": "func (t *SecureTrie) hashKey(key []byte) []byte {\n\th := newHasher(false)\n\th.sha.Reset()\n\th.sha.Write(key)\n\th.sha.Read(t.hashKeyBuf[:])\n\treturnHasherToPool(h)\n\treturn t.hashKeyBuf[:]\n}", "is_vulnerable": 0}
{"code": "func (m *CustomOneof) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: CustomOneof: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: CustomOneof: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 34:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Stringy\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_Stringy{string(dAtA[iNdEx:postIndex])}\n\t\t\tiNdEx = postIndex\n\t\tcase 35:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CustomType\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar vv github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tv := &vv\n\t\t\tif err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_CustomType{*v}\n\t\t\tiNdEx = postIndex\n\t\tcase 36:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field CastType\", wireType)\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_casttype.MyUint64Type\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= github_com_gogo_protobuf_test_casttype.MyUint64Type(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_CastType{v}\n\t\tcase 37:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field MyCustomName\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Custom = &CustomOneof_MyCustomName{v}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (a *Assertions) LessOrEqual(e1 interface{}, e2 interface{}, msgAndArgs ...interface{}) {\n\tif h, ok := a.t.(tHelper); ok {\n\t\th.Helper()\n\t}\n\tLessOrEqual(a.t, e1, e2, msgAndArgs...)\n}", "is_vulnerable": 0}
{"code": "func (m *Mock) findExpectedCall(method string, arguments ...interface{}) (int, *Call) {\n\tfor i, call := range m.ExpectedCalls {\n\t\tif call.Method == method && call.Repeatability > -1 {\n\n\t\t\t_, diffCount := call.Arguments.Diff(arguments)\n\t\t\tif diffCount == 0 {\n\t\t\t\treturn i, call\n\t\t\t}\n\n\t\t}\n\t}\n\treturn -1, nil\n}", "is_vulnerable": 1}
{"code": "\tt.Run(\"should add a mentions entry for the current user\", func(t *testing.T) {\n\t\tmsg := platform.MakeHookedWebSocketEvent(model.NewWebSocketEvent(model.WebsocketEventPosted, \"\", \"\", \"\", nil, \"\"))\n\n\t\trequire.Nil(t, msg.Event().GetData()[\"mentions\"])\n\n\t\thook.Process(msg, webConn, map[string]any{\n\t\t\t\"mentions\": model.StringArray{userID},\n\t\t})\n\n\t\tassert.Equal(t, `[\"`+userID+`\"]`, msg.Event().GetData()[\"mentions\"])\n\t\tassert.Nil(t, msg.Event().GetData()[\"followers\"])\n\t})", "is_vulnerable": 0}
{"code": "func parseED25519(in []byte) (out PublicKey, rest []byte, err error) {\n\tvar w struct {\n\t\tKeyBytes []byte\n\t\tRest     []byte `ssh:\"rest\"`\n\t}\n\n\tif err := Unmarshal(in, &w); err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tif l := len(w.KeyBytes); l != ed25519.PublicKeySize {\n\t\treturn nil, nil, fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\n\t}\n\n\treturn ed25519PublicKey(w.KeyBytes), w.Rest, nil\n}", "is_vulnerable": 0}
{"code": "func TestCEKFactoryNoCEK(t *testing.T) {\n\tkey, _ := hex.DecodeString(\"31bdadd96698c204aa9ce1448ea94ae1fb4a9a0b3c9d773b51bb1822666b8f22\")\n\tkeyB64 := base64.URLEncoding.EncodeToString(key)\n\tts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintln(w, fmt.Sprintf(\"%s%s%s\", `{\"KeyId\":\"test-key-id\",\"Plaintext\":\"`, keyB64, `\"}`))\n\t}))\n\tdefer ts.Close()\n\n\tsess := unit.Session.Copy(&aws.Config{\n\t\tMaxRetries:       aws.Int(0),\n\t\tEndpoint:         aws.String(ts.URL),\n\t\tDisableSSL:       aws.Bool(true),\n\t\tS3ForcePathStyle: aws.Bool(true),\n\t\tRegion:           aws.String(\"us-west-2\"),\n\t})\n\n\tc := DecryptionClient{\n\t\tWrapRegistry: map[string]WrapEntry{\n\t\t\tKMSWrap: (kmsKeyHandler{\n\t\t\t\tkms: kms.New(sess),\n\t\t\t}).decryptHandler,\n\t\t},\n\t\tCEKRegistry: map[string]CEKEntry{\n\t\t\tAESGCMNoPadding: newAESGCMContentCipher,\n\t\t},\n\t\tPadderRegistry: map[string]Padder{\n\t\t\tNoPadder.Name(): NoPadder,\n\t\t},\n\t}\n\tiv, err := hex.DecodeString(\"0d18e06c7c725ac9e362e1ce\")\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\tivB64 := base64.URLEncoding.EncodeToString(iv)\n\n\tcipherKey, err := hex.DecodeString(\"31bdadd96698c204aa9ce1448ea94ae1fb4a9a0b3c9d773b51bb1822666b8f22\")\n\tif err != nil {\n\t\tt.Errorf(\"expected no error, but received %v\", err)\n\t}\n\tcipherKeyB64 := base64.URLEncoding.EncodeToString(cipherKey)\n\n\tenv := Envelope{\n\t\tWrapAlg:   KMSWrap,\n\t\tCEKAlg:    \"none\",\n\t\tCipherKey: cipherKeyB64,\n\t\tIV:        ivB64,\n\t\tMatDesc:   `{\"kms_cmk_id\":\"\"}`,\n\t}\n\twrap, err := c.wrapFromEnvelope(env)\n\tcek, err := c.cekFromEnvelope(aws.BackgroundContext(), env, wrap)\n\n\tif err == nil {\n\t\tt.Error(\"expected error, but received none\")\n\t}\n\tif cek != nil {\n\t\tt.Errorf(\"expected nil cek value, received %v\", wrap)\n\t}\n}", "is_vulnerable": 1}
{"code": "func (rfs *rootFs) CreateServerFile(p string, c []byte) error {\n\tf, err := os.Create(filepath.Join(rfs.root, \"server\", p))\n\n\tif err == nil {\n\t\t_, _ = f.Write(c)\n\t\t_ = f.Close()\n\t}\n\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func memstatNamespace(s string) string {\n\treturn \"go_memstats_\" + s\n}", "is_vulnerable": 1}
{"code": "func TestClientAuthNone(t *testing.T) {\n\tuser := \"testuser\"\n\tserverConfig := &ServerConfig{\n\t\tNoClientAuth: true,\n\t}\n\tserverConfig.AddHostKey(testSigners[\"rsa\"])\n\n\tclientConfig := &ClientConfig{\n\t\tUser:            user,\n\t\tHostKeyCallback: InsecureIgnoreHostKey(),\n\t}\n\n\tc1, c2, err := netPipe()\n\tif err != nil {\n\t\tt.Fatalf(\"netPipe: %v\", err)\n\t}\n\tdefer c1.Close()\n\tdefer c2.Close()\n\n\tgo NewClientConn(c2, \"\", clientConfig)\n\tserverConn, err := newServer(c1, serverConfig)\n\tif err != nil {\n\t\tt.Fatalf(\"newServer: %v\", err)\n\t}\n\tif serverConn.User() != user {\n\t\tt.Fatalf(\"server: got %q, want %q\", serverConn.User(), user)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (mr *MockRequesterMockRecorder) SetSession(arg0 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"SetSession\", reflect.TypeOf((*MockRequester)(nil).SetSession), arg0)\n}", "is_vulnerable": 0}
{"code": "func (c *sliverRPCClient) MonitorListConfig(ctx context.Context, in *commonpb.Empty, opts ...grpc.CallOption) (*clientpb.MonitoringProviders, error) {\n\tout := new(clientpb.MonitoringProviders)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.SliverRPC/MonitorListConfig\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}", "is_vulnerable": 0}
{"code": "func (e *EgressDNS) Add(namespace, dnsName string) (addressset.AddressSet, error) {\n\te.lock.Lock()\n\tdefer e.lock.Unlock()\n\n\tif _, exists := e.dnsEntries[dnsName]; !exists {\n\t\tvar err error\n\t\tdnsEntry := dnsEntry{\n\t\t\tnamespaces: make(map[string]struct{}),\n\t\t}\n\t\tif e.addressSetFactory == nil {\n\t\t\treturn nil, fmt.Errorf(\"error adding EgressFirewall DNS rule for host %s, in namespace %s: addressSetFactory is nil\", dnsName, namespace)\n\t\t}\n\t\tdnsEntry.dnsAddressSet, err = e.addressSetFactory.NewAddressSet(dnsName, nil)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot create addressSet for %s: %v\", dnsName, err)\n\t\t}\n\t\te.dnsEntries[dnsName] = &dnsEntry\n\t\tgo e.addToDNS(dnsName)\n\t}\n\te.dnsEntries[dnsName].namespaces[namespace] = struct{}{}\n\treturn e.dnsEntries[dnsName].dnsAddressSet, nil\n\n}", "is_vulnerable": 0}
{"code": "func (c *Context) SetEngineInfo(proto Protocol, fileName, homeDir string) error {\n\tvar cfn, chome *C.char\n\tif fileName != \"\" {\n\t\tcfn = C.CString(fileName)\n\t\tdefer C.free(unsafe.Pointer(cfn))\n\t}\n\tif homeDir != \"\" {\n\t\tchome = C.CString(homeDir)\n\t\tdefer C.free(unsafe.Pointer(chome))\n\t}\n\treturn handleError(C.gpgme_ctx_set_engine_info(c.ctx, C.gpgme_protocol_t(proto), cfn, chome))\n}", "is_vulnerable": 1}
{"code": "func NewMigrator(engine *xorm.Engine) *Migrator {\n\tmg := &Migrator{}\n\tmg.x = engine\n\tmg.Logger = log.New(\"migrator\")\n\tmg.migrations = make([]Migration, 0)\n\tmg.dialect = NewDialect(mg.x.DriverName())\n\treturn mg\n}", "is_vulnerable": 1}
{"code": "func (in *OpenshiftOAuthService) ValidateToken(token string) error {\n\tk8sConfig, err := kubernetes.ConfigClient()\n\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not connect to Openshift: %v\", err)\n\t}\n\n\tk8sConfig.BearerToken = token\n\n\tk8s, err := kube.NewForConfig(k8sConfig)\n\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not get Openshift cluster config: %v\", err)\n\t}\n\n\t_, err = k8s.Discovery().ServerVersion()\n\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not get info from Openshift: %v\", err)\n\t}\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (m *NinRepPackedNative) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNative: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NinRepPackedNative: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field1) == 0 {\n\t\t\t\t\tm.Field1 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field1 = append(m.Field1, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\tcase 2:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field2) == 0 {\n\t\t\t\t\tm.Field2 = make([]float32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tv2 := float32(math.Float32frombits(v))\n\t\t\t\t\tm.Field2 = append(m.Field2, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field2\", wireType)\n\t\t\t}\n\t\tcase 3:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field3 = append(m.Field3, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 4:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field4) == 0 {\n\t\t\t\t\tm.Field4 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field4 = append(m.Field4, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field4\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field5) == 0 {\n\t\t\t\t\tm.Field5 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field5 = append(m.Field5, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field5\", wireType)\n\t\t\t}\n\t\tcase 6:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field6) == 0 {\n\t\t\t\t\tm.Field6 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field6 = append(m.Field6, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field6\", wireType)\n\t\t\t}\n\t\tcase 7:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int32\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field7) == 0 {\n\t\t\t\t\tm.Field7 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int32(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = int32((uint32(v) >> 1) ^ uint32(((v&1)<<31)>>31))\n\t\t\t\t\tm.Field7 = append(m.Field7, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field7\", wireType)\n\t\t\t}\n\t\tcase 8:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v uint64\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\tvar count int\n\t\t\t\tfor _, integer := range dAtA[iNdEx:postIndex] {\n\t\t\t\t\tif integer < 128 {\n\t\t\t\t\t\tcount++\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telementCount = count\n\t\t\t\tif elementCount != 0 && len(m.Field8) == 0 {\n\t\t\t\t\tm.Field8 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= uint64(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv = (v >> 1) ^ uint64((int64(v&1)<<63)>>63)\n\t\t\t\t\tm.Field8 = append(m.Field8, int64(v))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field8\", wireType)\n\t\t\t}\n\t\tcase 9:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v uint32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field9) == 0 {\n\t\t\t\t\tm.Field9 = make([]uint32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field9 = append(m.Field9, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field9\", wireType)\n\t\t\t}\n\t\tcase 10:\n\t\t\tif wireType == 5 {\n\t\t\t\tvar v int32\n\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 4\n\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 4\n\t\t\t\tif elementCount != 0 && len(m.Field10) == 0 {\n\t\t\t\t\tm.Field10 = make([]int32, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int32\n\t\t\t\t\tif (iNdEx + 4) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 4\n\t\t\t\t\tm.Field10 = append(m.Field10, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field10\", wireType)\n\t\t\t}\n\t\tcase 11:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field11) == 0 {\n\t\t\t\t\tm.Field11 = make([]uint64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field11 = append(m.Field11, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field11\", wireType)\n\t\t\t}\n\t\tcase 12:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v int64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field12) == 0 {\n\t\t\t\t\tm.Field12 = make([]int64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = int64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tm.Field12 = append(m.Field12, v)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field12\", wireType)\n\t\t\t}\n\t\tcase 13:\n\t\t\tif wireType == 0 {\n\t\t\t\tvar v int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen\n\t\t\t\tif elementCount != 0 && len(m.Field13) == 0 {\n\t\t\t\t\tm.Field13 = make([]bool, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v int\n\t\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t\t}\n\t\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\t\tiNdEx++\n\t\t\t\t\t\tv |= int(b&0x7F) << shift\n\t\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tm.Field13 = append(m.Field13, bool(v != 0))\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field13\", wireType)\n\t\t\t}\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func initRand() *mrand.Rand {\n\tvar seed [8]byte\n\tcrand.Read(seed[:])\n\trnd := mrand.New(mrand.NewSource(int64(binary.LittleEndian.Uint64(seed[:]))))\n\treturn rnd\n}", "is_vulnerable": 0}
{"code": "func (r *genreRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\treturn r.count(Select(), r.parseRestOptions(options...))\n}", "is_vulnerable": 1}
{"code": "func (src *NotificationResponse) Encode(dst []byte) ([]byte, error) {\n\tdst, sp := beginMessage(dst, 'A')\n\tdst = pgio.AppendUint32(dst, src.PID)\n\tdst = append(dst, src.Channel...)\n\tdst = append(dst, 0)\n\tdst = append(dst, src.Payload...)\n\tdst = append(dst, 0)\n\treturn finishMessage(dst, sp)\n}", "is_vulnerable": 0}
{"code": "func Index(ctx *macaron.Context) string {\n\tloginLogModel := new(models.LoginLog)\n\tparams := models.CommonMap{}\n\tbase.ParsePageAndPageSize(ctx, params)\n\ttotal, err := loginLogModel.Total()\n\tif err != nil {\n\t\tlogger.Error(err)\n\t}\n\tloginLogs, err := loginLogModel.List(params)\n\tif err != nil {\n\t\tlogger.Error(err)\n\t}\n\n\tjsonResp := utils.JsonResponse{}\n\n\treturn jsonResp.Success(utils.SuccessContent, map[string]interface{}{\n\t\t\"total\": total,\n\t\t\"data\":  loginLogs,\n\t})\n}", "is_vulnerable": 0}
{"code": "func (c *WriteCommand) validateNoUsersetForRelationReferencedInTupleset(authModel *openfgapb.AuthorizationModel, tk *openfgapb.TupleKey) error {\n\tif !tupleUtils.IsObjectRelation(tk.GetUser()) {\n\t\treturn nil\n\t}\n\n\tobjType := tupleUtils.GetType(tk.GetObject())\n\n\t// at this point we know tk.User is a userset\n\t// if tk.Relation is used in a `x from y` definition (in the `y` part), throw an error\n\tts := typesystem.New(authModel)\n\tfor _, arrayOfTtus := range ts.GetAllTupleToUsersetsDefinitions()[objType] {\n\t\tfor _, tupleToUserSetDef := range arrayOfTtus {\n\t\t\tif tupleToUserSetDef.Tupleset.Relation == tk.Relation {\n\t\t\t\treturn serverErrors.InvalidTuple(fmt.Sprintf(\"Userset '%s' is not allowed to have relation '%s' with '%s'\", tk.User, tk.Relation, tk.Object), tk)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *Server) CreateCertificate(ctx context.Context, request *pb.IstioCertificateRequest) (\n\t*pb.IstioCertificateResponse, error,\n) {\n\ts.monitoring.CSR.Increment()\n\tcaller := Authenticate(ctx, s.Authenticators)\n\tif caller == nil {\n\t\ts.monitoring.AuthnError.Increment()\n\t\treturn nil, status.Error(codes.Unauthenticated, \"request authenticate failure\")\n\t}\n\t// TODO: Call authorizer.\n\tcrMetadata := request.Metadata.GetFields()\n\tcertSigner := crMetadata[security.CertSigner].GetStringValue()\n\tlog.Debugf(\"cert signer from workload %s\", certSigner)\n\t_, _, certChainBytes, rootCertBytes := s.ca.GetCAKeyCertBundle().GetAll()\n\tcertOpts := ca.CertOpts{\n\t\tSubjectIDs: caller.Identities,\n\t\tTTL:        time.Duration(request.ValidityDuration) * time.Second,\n\t\tForCA:      false,\n\t\tCertSigner: certSigner,\n\t}\n\tvar signErr error\n\tvar cert []byte\n\tvar respCertChain []string\n\tif certSigner == \"\" {\n\t\tcert, signErr = s.ca.Sign([]byte(request.Csr), certOpts)\n\t} else {\n\t\trespCertChain, signErr = s.ca.SignWithCertChain([]byte(request.Csr), certOpts)\n\t}\n\tif signErr != nil {\n\t\tserverCaLog.Errorf(\"CSR signing error (%v)\", signErr.Error())\n\t\ts.monitoring.GetCertSignError(signErr.(*caerror.Error).ErrorType()).Increment()\n\t\treturn nil, status.Errorf(signErr.(*caerror.Error).HTTPErrorCode(), \"CSR signing error (%v)\", signErr.(*caerror.Error))\n\t}\n\tif certSigner == \"\" {\n\t\trespCertChain = []string{string(cert)}\n\t\tif len(certChainBytes) != 0 {\n\t\t\trespCertChain = append(respCertChain, string(certChainBytes))\n\t\t}\n\t}\n\tif len(rootCertBytes) != 0 {\n\t\trespCertChain = append(respCertChain, string(rootCertBytes))\n\t}\n\tresponse := &pb.IstioCertificateResponse{\n\t\tCertChain: respCertChain,\n\t}\n\ts.monitoring.Success.Increment()\n\tserverCaLog.Debug(\"CSR successfully signed.\")\n\treturn response, nil\n}", "is_vulnerable": 1}
{"code": "func NewParser(r resolver.Resolver) parser.IngressAnnotation {\n\treturn streamSnippet{r}\n}", "is_vulnerable": 1}
{"code": "func (e *NoRewardEngine) FinalizeAndAssemble(chain consensus.ChainHeaderReader, header *types.Header, statedb *state.StateDB, txs []*types.Transaction,\n\tuncles []*types.Header, receipts []*types.Receipt) (*types.Block, error) {\n\tif e.rewardsOn {\n\t\treturn e.inner.FinalizeAndAssemble(chain, header, statedb, txs, uncles, receipts)\n\t} else {\n\t\te.accumulateRewards(chain.Config(), statedb, header, uncles)\n\t\theader.Root = statedb.IntermediateRoot(chain.Config().IsEIP158(header.Number))\n\n\t\t// Header seems complete, assemble into a block and return\n\t\treturn types.NewBlock(header, txs, uncles, receipts), nil\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tviper.Reset()\n\n\t\t\tvar out bytes.Buffer\n\n\t\t\tcmd := NewRootCmd(RootCommandConfig{\n\t\t\t\tName: \"func\",\n\t\t\t\tVersion: Version{\n\t\t\t\t\tDate: \"1970-01-01\",\n\t\t\t\t\tVers: \"v0.42.0\",\n\t\t\t\t\tHash: \"cafe\",\n\t\t\t\t}})\n\n\t\t\tcmd.SetArgs(tt.args)\n\t\t\tcmd.SetOut(&out)\n\t\t\tif err := cmd.Execute(); err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\n\t\t\tif out.String() != tt.want {\n\t\t\t\tt.Errorf(\"expected output: %q but got: %q\", tt.want, out.String())\n\t\t\t}\n\t\t})", "is_vulnerable": 1}
{"code": "func (b *SystemBackend) raftStoragePaths() []*framework.Path {\n\treturn []*framework.Path{\n\t\t{\n\t\t\tPattern: \"storage/raft/bootstrap/answer\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"answer\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"cluster_addr\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t\t\"non_voter\": {\n\t\t\t\t\tType: framework.TypeBool,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftBootstrapAnswerWrite(),\n\t\t\t\t\tSummary:  \"Accepts an answer from the peer to be joined to the fact cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-answer\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-answer\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/bootstrap/challenge\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftBootstrapChallengeWrite(),\n\t\t\t\t\tSummary:  \"Creates a challenge for the new peer to be joined to the raft cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-challenge\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-bootstrap-challenge\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/remove-peer\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"dr_operation_token\": {\n\t\t\t\t\tType:        framework.TypeString,\n\t\t\t\t\tDescription: \"DR operation token used to authorize this request (if a DR secondary node).\",\n\t\t\t\t},\n\t\t\t\t\"server_id\": {\n\t\t\t\t\tType: framework.TypeString,\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.verifyDROperationToken(b.handleRaftRemovePeerUpdate(), false),\n\t\t\t\t\tSummary:  \"Remove a peer from the raft cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-remove-peer\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-remove-peer\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/configuration\",\n\n\t\t\tFields: map[string]*framework.FieldSchema{\n\t\t\t\t\"dr_operation_token\": {\n\t\t\t\t\tType:        framework.TypeString,\n\t\t\t\t\tDescription: \"DR operation token used to authorize this request (if a DR secondary node).\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.ReadOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleRaftConfigurationGet(),\n\t\t\t\t\tSummary:  \"Returns the configuration of the raft cluster.\",\n\t\t\t\t},\n\t\t\t\t// Reading configuration on a DR secondary cluster is an update\n\t\t\t\t// operation to allow consuming the DR operation token for\n\t\t\t\t// authenticating the request.\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.verifyDROperationToken(b.handleRaftConfigurationGet(), false),\n\t\t\t\t\tSummary:  \"Returns the configuration of the raft cluster in a DR secondary cluster.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-configuration\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-configuration\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/snapshot\",\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.ReadOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotRead(),\n\t\t\t\t\tSummary:  \"Returns a snapshot of the current state of vault.\",\n\t\t\t\t},\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotWrite(false),\n\t\t\t\t\tSummary:  \"Installs the provided snapshot, returning the cluster to the state defined in it.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-snapshot\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-snapshot\"][1]),\n\t\t},\n\t\t{\n\t\t\tPattern: \"storage/raft/snapshot-force\",\n\t\t\tOperations: map[logical.Operation]framework.OperationHandler{\n\t\t\t\tlogical.UpdateOperation: &framework.PathOperation{\n\t\t\t\t\tCallback: b.handleStorageRaftSnapshotWrite(true),\n\t\t\t\t\tSummary:  \"Installs the provided snapshot, returning the cluster to the state defined in it. This bypasses checks ensuring the current Autounseal or Shamir keys are consistent with the snapshot data.\",\n\t\t\t\t},\n\t\t\t},\n\n\t\t\tHelpSynopsis:    strings.TrimSpace(sysRaftHelp[\"raft-snapshot-force\"][0]),\n\t\t\tHelpDescription: strings.TrimSpace(sysRaftHelp[\"raft-snapshot-force\"][1]),\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func DeleteExecutionsWorkflow(ctx workflow.Context, params DeleteExecutionsParams) (DeleteExecutionsResult, error) {\n\tlogger := workflow.GetLogger(ctx)\n\tlogger.Info(\"Workflow started.\", tag.WorkflowType(WorkflowName))\n\tresult := DeleteExecutionsResult{\n\t\tSuccessCount: params.PreviousSuccessCount,\n\t\tErrorCount:   params.PreviousErrorCount,\n\t}\n\n\tif err := validateParams(&params); err != nil {\n\t\treturn result, err\n\t}\n\tlogger.Info(\"Effective config.\", tag.Value(params.Config.String()))\n\n\tvar a *Activities\n\tnextPageToken := params.NextPageToken\n\trunningDeleteExecutionsActivityCount := 0\n\trunningDeleteExecutionsSelector := workflow.NewSelector(ctx)\n\tvar lastDeleteExecutionsActivityErr error\n\n\t// Two activities DeleteExecutionsActivity and GetNextPageTokenActivity are executed here essentially in reverse order\n\t// because Get is called immediately for GetNextPageTokenActivity but not for DeleteExecutionsActivity.\n\t// These activities scan visibility storage independently but GetNextPageTokenActivity considered to be quick and can be done synchronously.\n\t// It reads nextPageToken and pass it DeleteExecutionsActivity. This allocates block of workflow executions to delete for\n\t// DeleteExecutionsActivity which takes much longer to complete. This is why this workflow starts\n\t// ConcurrentDeleteExecutionsActivities number of them and executes them concurrently on available workers.\n\tfor i := 0; i < params.Config.PagesPerExecution; i++ {\n\t\tctx1 := workflow.WithActivityOptions(ctx, deleteWorkflowExecutionsActivityOptions)\n\t\tdeleteExecutionsFuture := workflow.ExecuteActivity(ctx1, a.DeleteExecutionsActivity, &DeleteExecutionsActivityParams{\n\t\t\tNamespace:     params.Namespace,\n\t\t\tNamespaceID:   params.NamespaceID,\n\t\t\tRPS:           params.Config.DeleteActivityRPS,\n\t\t\tListPageSize:  params.Config.PageSize,\n\t\t\tNextPageToken: nextPageToken,\n\t\t})\n\n\t\tctx2 := workflow.WithLocalActivityOptions(ctx, localActivityOptions)\n\t\terr := workflow.ExecuteLocalActivity(ctx2, a.GetNextPageTokenActivity, GetNextPageTokenParams{\n\t\t\tNamespaceID:   params.NamespaceID,\n\t\t\tNamespace:     params.Namespace,\n\t\t\tPageSize:      params.Config.PageSize,\n\t\t\tNextPageToken: nextPageToken,\n\t\t}).Get(ctx, &nextPageToken)\n\t\tif err != nil {\n\t\t\treturn result, fmt.Errorf(\"%w: GetNextPageTokenActivity: %v\", errors.ErrUnableToExecuteActivity, err)\n\t\t}\n\n\t\trunningDeleteExecutionsActivityCount++\n\t\trunningDeleteExecutionsSelector.AddFuture(deleteExecutionsFuture, func(f workflow.Future) {\n\t\t\trunningDeleteExecutionsActivityCount--\n\t\t\tvar der DeleteExecutionsActivityResult\n\t\t\tdeErr := f.Get(ctx, &der)\n\t\t\tif deErr != nil {\n\t\t\t\tlastDeleteExecutionsActivityErr = deErr\n\t\t\t\treturn\n\t\t\t}\n\t\t\tresult.SuccessCount += der.SuccessCount\n\t\t\tresult.ErrorCount += der.ErrorCount\n\t\t})\n\n\t\tif runningDeleteExecutionsActivityCount >= params.Config.ConcurrentDeleteExecutionsActivities {\n\t\t\t// Wait for one of running activities to complete.\n\t\t\trunningDeleteExecutionsSelector.Select(ctx)\n\t\t\tif lastDeleteExecutionsActivityErr != nil {\n\t\t\t\treturn result, fmt.Errorf(\"%w: DeleteExecutionsActivity: %v\", errors.ErrUnableToExecuteActivity, lastDeleteExecutionsActivityErr)\n\t\t\t}\n\t\t}\n\n\t\tif nextPageToken == nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Wait for all running activities to complete.\n\tfor runningDeleteExecutionsActivityCount > 0 {\n\t\trunningDeleteExecutionsSelector.Select(ctx)\n\t\tif lastDeleteExecutionsActivityErr != nil {\n\t\t\treturn result, fmt.Errorf(\"%w: DeleteExecutionsActivity: %v\", errors.ErrUnableToExecuteActivity, lastDeleteExecutionsActivityErr)\n\t\t}\n\t}\n\n\t// If nextPageToken is nil then there are no more workflow executions to delete.\n\tif nextPageToken == nil {\n\t\tif result.ErrorCount == 0 {\n\t\t\tlogger.Info(\"Successfully deleted workflow executions.\", tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount))\n\t\t} else {\n\t\t\tlogger.Error(\"Finish deleting workflow executions with some errors.\", tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount), tag.DeletedExecutionsErrorCount(result.ErrorCount))\n\t\t}\n\t\treturn result, nil\n\t}\n\n\t// Too many workflow executions, and ConcurrentDeleteExecutionsActivities number of activities has been completed already.\n\t// Continue as new to prevent workflow history size explosion.\n\n\tparams.PreviousSuccessCount = result.SuccessCount\n\tparams.PreviousErrorCount = result.ErrorCount\n\tparams.ContinueAsNewCount++\n\tparams.NextPageToken = nextPageToken\n\n\tlogger.Info(\"There are more workflows to delete. Continuing workflow as new.\", tag.WorkflowType(WorkflowName), tag.WorkflowNamespace(params.Namespace.String()), tag.DeletedExecutionsCount(result.SuccessCount), tag.DeletedExecutionsErrorCount(result.ErrorCount), tag.Counter(params.ContinueAsNewCount))\n\treturn result, workflow.NewContinueAsNewError(ctx, DeleteExecutionsWorkflow, params)\n}", "is_vulnerable": 0}
{"code": "func WithMaxQueuedWantlistEntriesPerPeer(count uint) Option {\n\treturn func(e *Engine) {\n\t\te.maxQueuedWantlistEntriesPerPeer = count\n\t}\n}", "is_vulnerable": 0}
{"code": "func CopyDirIfExists(src, dst string) error {\n\tsrcInfo, err := os.Stat(src)\n\tif os.IsNotExist(err) {\n\t\treturn nil\n\t}\n\tif err = os.MkdirAll(dst, srcInfo.Mode()); err != nil {\n\t\treturn err\n\t}\n\tdirInfo, err := ioutil.ReadDir(src)\n\tfor _, info := range dirInfo {\n\t\tsrcPath := filepath.Join(src, info.Name())\n\t\tdstPath := filepath.Join(dst, info.Name())\n\t\tif info.IsDir() {\n\t\t\terr = CopyDirIfExists(srcPath, dstPath)\n\t\t} else {\n\t\t\terr = CopyFileIfExists(srcPath, dstPath)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (g *GitGetter) update(ctx context.Context, dst, sshKeyFile, ref string, depth int) error {\n\t// Determine if we're a branch. If we're NOT a branch, then we just\n\t// switch to master prior to checking out\n\tcmd := exec.CommandContext(ctx, \"git\", \"show-ref\", \"-q\", \"--verify\", \"refs/heads/\"+ref)\n\tcmd.Dir = dst\n\n\tif getRunCommand(cmd) != nil {\n\t\t// Not a branch, switch to default branch. This will also catch\n\t\t// non-existent branches, in which case we want to switch to default\n\t\t// and then checkout the proper branch later.\n\t\tref = findDefaultBranch(dst)\n\t}\n\n\t// We have to be on a branch to pull\n\tif err := g.checkout(dst, ref); err != nil {\n\t\treturn err\n\t}\n\n\tif depth > 0 {\n\t\tcmd = exec.Command(\"git\", \"pull\", \"--depth\", strconv.Itoa(depth), \"--ff-only\")\n\t} else {\n\t\tcmd = exec.Command(\"git\", \"pull\", \"--ff-only\")\n\t}\n\n\tcmd.Dir = dst\n\tsetupGitEnv(cmd, sshKeyFile)\n\treturn getRunCommand(cmd)\n}", "is_vulnerable": 1}
{"code": "func (q *ListObjectsQuery) ExecuteStreamed(ctx context.Context, req *openfgav1.StreamedListObjectsRequest, srv openfgav1.OpenFGAService_StreamedListObjectsServer) (*reverseexpand.ResolutionMetadata, error) {\n\tmaxResults := uint32(math.MaxUint32)\n\t// make a buffered channel so that writer goroutines aren't blocked when attempting to send a result\n\tresultsChan := make(chan ListObjectsResult, streamedBufferSize)\n\n\ttimeoutCtx := ctx\n\tif q.listObjectsDeadline != 0 {\n\t\tvar cancel context.CancelFunc\n\t\ttimeoutCtx, cancel = context.WithTimeout(ctx, q.listObjectsDeadline)\n\t\tdefer cancel()\n\t}\n\n\tresolutionMetadata := reverseexpand.NewResolutionMetadata()\n\n\terr := q.evaluate(timeoutCtx, req, resultsChan, maxResults, resolutionMetadata)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor {\n\t\tselect {\n\t\tcase <-timeoutCtx.Done():\n\t\t\tq.logger.WarnWithContext(\n\t\t\t\tctx, fmt.Sprintf(\"list objects timeout after %s\", q.listObjectsDeadline.String()),\n\t\t\t)\n\t\t\treturn resolutionMetadata, nil\n\n\t\tcase result, channelOpen := <-resultsChan:\n\t\t\tif !channelOpen {\n\t\t\t\t// Channel closed! No more results.\n\t\t\t\treturn resolutionMetadata, nil\n\t\t\t}\n\n\t\t\tif result.Err != nil {\n\t\t\t\tif errors.Is(result.Err, serverErrors.AuthorizationModelResolutionTooComplex) {\n\t\t\t\t\treturn nil, result.Err\n\t\t\t\t}\n\n\t\t\t\tif errors.Is(result.Err, condition.ErrEvaluationFailed) {\n\t\t\t\t\treturn nil, serverErrors.ValidationError(result.Err)\n\t\t\t\t}\n\n\t\t\t\treturn nil, serverErrors.HandleError(\"\", result.Err)\n\t\t\t}\n\n\t\t\tif err := srv.Send(&openfgav1.StreamedListObjectsResponse{\n\t\t\t\tObject: result.ObjectID,\n\t\t\t}); err != nil {\n\t\t\t\treturn nil, serverErrors.NewInternalError(\"\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "is_vulnerable": 1}
{"code": "func (src *CancelRequest) Encode(dst []byte) ([]byte, error) {\n\tdst = pgio.AppendInt32(dst, 16)\n\tdst = pgio.AppendInt32(dst, cancelRequestCode)\n\tdst = pgio.AppendUint32(dst, src.ProcessID)\n\tdst = pgio.AppendUint32(dst, src.SecretKey)\n\treturn dst, nil\n}", "is_vulnerable": 0}
{"code": "func includeElement(list interface{}, element interface{}) (ok, found bool) {\n\n\tlistValue := reflect.ValueOf(list)\n\tlistKind := reflect.TypeOf(list).Kind()\n\tdefer func() {\n\t\tif e := recover(); e != nil {\n\t\t\tok = false\n\t\t\tfound = false\n\t\t}\n\t}()\n\n\tif listKind == reflect.String {\n\t\telementValue := reflect.ValueOf(element)\n\t\treturn true, strings.Contains(listValue.String(), elementValue.String())\n\t}\n\n\tif listKind == reflect.Map {\n\t\tmapKeys := listValue.MapKeys()\n\t\tfor i := 0; i < len(mapKeys); i++ {\n\t\t\tif ObjectsAreEqual(mapKeys[i].Interface(), element) {\n\t\t\t\treturn true, true\n\t\t\t}\n\t\t}\n\t\treturn true, false\n\t}\n\n\tfor i := 0; i < listValue.Len(); i++ {\n\t\tif ObjectsAreEqual(listValue.Index(i).Interface(), element) {\n\t\t\treturn true, true\n\t\t}\n\t}\n\treturn true, false\n\n}", "is_vulnerable": 0}
{"code": "func (self *InventoryService) addAllVersions(\n\tctx context.Context, config_obj *config_proto.Config,\n\ttool *artifacts_proto.Tool) *artifacts_proto.Tool {\n\tresult := proto.Clone(tool).(*artifacts_proto.Tool)\n\n\tversions, _ := self.versions[tool.Name]\n\tresult.Versions = nil\n\n\tfor _, v := range versions {\n\t\tif tool.Version != \"\" && tool.Version != v.Version {\n\t\t\tcontinue\n\t\t}\n\n\t\tresult.Versions = append(result.Versions, v)\n\t}\n\n\t// Merge the parent's versions as well.\n\tif self.parent != nil {\n\t\tparent_tool, err := self.parent.ProbeToolInfo(ctx, config_obj, tool.Name, \"\")\n\t\tif err == nil {\n\t\t\tresult.Versions = append(result.Versions, parent_tool.Versions...)\n\t\t}\n\t}\n\n\treturn result\n}", "is_vulnerable": 0}
{"code": "func TestGet(t *testing.T) {\n\ttests := []struct {\n\t\tname         string\n\t\tbaseLayers   int\n\t\tappendLayers int\n\t\twantError    error\n\t}{\n\t\t{\n\t\t\tname:         \"within limit\",\n\t\t\tbaseLayers:   1,\n\t\t\tappendLayers: 1,\n\t\t\twantError:    nil,\n\t\t},\n\t\t{\n\t\t\tname:         \"base exceeds limit\",\n\t\t\tbaseLayers:   2000,\n\t\t\tappendLayers: 1,\n\t\t\twantError:    errors.New(\"number of layers (2001) exceeded the limit (1000)\"),\n\t\t},\n\t\t{\n\t\t\tname:         \"append exceeds limit\",\n\t\t\tbaseLayers:   1,\n\t\t\tappendLayers: 1300,\n\t\t\twantError:    errors.New(\"number of layers (1301) exceeded the limit (1000)\"),\n\t\t},\n\t\t{\n\t\t\tname:         \"sum exceeds limit\",\n\t\t\tbaseLayers:   666,\n\t\t\tappendLayers: 666,\n\t\t\twantError:    errors.New(\"number of layers (1332) exceeded the limit (1000)\"),\n\t\t},\n\t}\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tsa := sigAppender{\n\t\t\t\tbase: &mockOCISignatures{\n\t\t\t\t\tsignatures: make([]oci.Signature, test.baseLayers),\n\t\t\t\t},\n\t\t\t\tsigs: make([]oci.Signature, test.appendLayers),\n\t\t\t}\n\t\t\t_, err := sa.Get()\n\t\t\tif test.wantError != nil && test.wantError.Error() != err.Error() {\n\t\t\t\tt.Fatalf(\"Get() = %v, wanted %v\", err, test.wantError)\n\t\t\t}\n\t\t\tif test.wantError == nil && err != nil {\n\t\t\t\tt.Fatalf(\"Get() = %v, wanted %v\", err, test.wantError)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func TestSortParameter_Ascending(t *testing.T) {\n\tsortParameter, err := NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"name\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"name asc\", sortParameter.GetGormOrderExpr())\n}", "is_vulnerable": 1}
{"code": "func extractCerts(e *models.LogEntryAnon) ([]*x509.Certificate, error) {\n\tb, err := base64.StdEncoding.DecodeString(e.Body.(string))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tpe, err := models.UnmarshalProposedEntry(bytes.NewReader(b), runtime.JSONConsumer())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teimpl, err := types.NewEntry(pe)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar publicKeyB64 []byte\n\tswitch e := eimpl.(type) {\n\tcase *rekord.V001Entry:\n\t\tpublicKeyB64, err = e.RekordObj.Signature.PublicKey.Content.MarshalText()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tcase *hashedrekord.V001Entry:\n\t\tpublicKeyB64, err = e.HashedRekordObj.Signature.PublicKey.Content.MarshalText()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\tdefault:\n\t\treturn nil, errors.New(\"unexpected tlog entry type\")\n\t}\n\n\tpublicKey, err := base64.StdEncoding.DecodeString(string(publicKeyB64))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcerts, err := cryptoutils.UnmarshalCertificatesFromPEM(publicKey)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(certs) == 0 {\n\t\treturn nil, errors.New(\"no certs found in pem tlog\")\n\t}\n\n\treturn certs, err\n}", "is_vulnerable": 1}
{"code": "\t\trebuild: func() BuildResult {\n\t\t\tif atomic.LoadInt32(&shouldStop) != 0 {\n\t\t\t\t// Don't start more rebuilds if we were told to stop\n\t\t\t\treturn BuildResult{}\n\t\t\t} else {\n\t\t\t\treturn ctx.activeBuildOrRecentBuildOrRebuild()\n\t\t\t}\n\t\t},\n\t\tfs: ctx.realFS,\n\t}", "is_vulnerable": 0}
{"code": "func (n *errorKeyingTransport) setStrictMode() error { return nil }", "is_vulnerable": 0}
{"code": "func Shmctl(t *kernel.Task, args arch.SyscallArguments) (uintptr, *kernel.SyscallControl, error) {\n\tid := args[0].Int()\n\tcmd := args[1].Int()\n\tbuf := args[2].Pointer()\n\n\tr := t.IPCNamespace().ShmRegistry()\n\n\tswitch cmd {\n\tcase linux.SHM_STAT:\n\t\t// Technically, we should be treating id as \"an index into the kernel's\n\t\t// internal array that maintains information about all shared memory\n\t\t// segments on the system\". Since we don't track segments in an array,\n\t\t// we'll just pretend the shmid is the index and do the same thing as\n\t\t// IPC_STAT. Linux also uses the index as the shmid.\n\t\tfallthrough\n\tcase linux.IPC_STAT:\n\t\tsegment, err := findSegment(t, id)\n\t\tif err != nil {\n\t\t\treturn 0, nil, syserror.EINVAL\n\t\t}\n\n\t\tstat, err := segment.IPCStat(t)\n\t\tif err == nil {\n\t\t\t_, err = t.CopyOut(buf, stat)\n\t\t}\n\t\treturn 0, nil, err\n\n\tcase linux.IPC_INFO:\n\t\tparams := r.IPCInfo()\n\t\t_, err := t.CopyOut(buf, params)\n\t\treturn 0, nil, err\n\n\tcase linux.SHM_INFO:\n\t\tinfo := r.ShmInfo()\n\t\t_, err := t.CopyOut(buf, info)\n\t\treturn 0, nil, err\n\t}\n\n\t// Remaining commands refer to a specific segment.\n\tsegment, err := findSegment(t, id)\n\tif err != nil {\n\t\treturn 0, nil, syserror.EINVAL\n\t}\n\n\tswitch cmd {\n\tcase linux.IPC_SET:\n\t\tvar ds linux.ShmidDS\n\t\t_, err = t.CopyIn(buf, &ds)\n\t\tif err != nil {\n\t\t\treturn 0, nil, err\n\t\t}\n\t\terr = segment.Set(t, &ds)\n\t\treturn 0, nil, err\n\n\tcase linux.IPC_RMID:\n\t\tsegment.MarkDestroyed()\n\t\treturn 0, nil, nil\n\n\tcase linux.SHM_LOCK, linux.SHM_UNLOCK:\n\t\t// We currently do not support memory locking anywhere.\n\t\t// mlock(2)/munlock(2) are currently stubbed out as no-ops so do the\n\t\t// same here.\n\t\tt.Kernel().EmitUnimplementedEvent(t)\n\t\treturn 0, nil, nil\n\n\tdefault:\n\t\treturn 0, nil, syserror.EINVAL\n\t}\n}", "is_vulnerable": 0}
{"code": "func Test_IsTrusted_shouldReturnTrueForSubfolderOfTrustedFolders_Linux(t *testing.T) {\n\ttestutil.IntegTest(t)\n\ttestutil.NotOnWindows(t, \"Unix/macOS file paths are incompatible with Windows\")\n\tconfig.CurrentConfig().SetTrustedFolderFeatureEnabled(true)\n\tconfig.CurrentConfig().SetTrustedFolders([]string{\"/dummy\"})\n\tf := NewFolder(\"/dummy/dummyF\", \"dummy\", snyk.NewTestScanner(), hover.NewFakeHoverService())\n\tassert.True(t, f.IsTrusted())\n}", "is_vulnerable": 0}
{"code": "func TestExpandQuery(t *testing.T, datastore storage.OpenFGADatastore) {\n\ttests := []struct {\n\t\tname            string\n\t\ttypeDefinitions []*openfgapb.TypeDefinition\n\t\ttuples          []*openfgapb.TupleKey\n\t\trequest         *openfgapb.ExpandRequest\n\t\texpected        *openfgapb.ExpandResponse\n\t}{\n\t\t{\n\t\t\tname: \"simple direct\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Users{\n\t\t\t\t\t\t\t\t\tUsers: &openfgapb.UsersetTree_Users{\n\t\t\t\t\t\t\t\t\t\tUsers: []string{\"github|jon.allie@openfga\"},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"computed userset\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {},\n\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"tuple to userset\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"manager\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"repo_admin\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\tUser:     \"org:openfga\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tObject:   \"org:openfga\",\n\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.UsersetTree_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: \"repo:openfga/foo#manager\",\n\t\t\t\t\t\t\t\t\t\tComputed: []*openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"org:openfga#repo_admin\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"tuple to userset II\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"manager\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"repo_admin\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\tUser:     \"org:openfga\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tObject:   \"org:openfga\",\n\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\tUser:     \"amy\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.UsersetTree_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: \"repo:openfga/foo#manager\",\n\t\t\t\t\t\t\t\t\t\tComputed: []*openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"org:openfga#repo_admin\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"tuple to userset implicit\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"manager\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"repo_admin\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"manager\",\n\t\t\t\t\tUser:     \"org:openfga\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tObject:   \"org:openfga\",\n\t\t\t\t\tRelation: \"repo_admin\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_TupleToUserset{\n\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.UsersetTree_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\tTupleset: \"repo:openfga/foo#manager\",\n\t\t\t\t\t\t\t\t\t\tComputed: []*openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"org:openfga#repo_admin\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"simple union\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {},\n\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{\n\t\t\t\t\t\t\t\t\t\t\t\tThis: &openfgapb.DirectUserset{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Union{\n\t\t\t\t\t\t\tUnion: &openfgapb.UsersetTree_Nodes{\n\t\t\t\t\t\t\t\tNodes: []*openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: &openfgapb.UsersetTree_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: []string{\"github|jon.allie@openfga\"},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"simple difference\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\":  {},\n\t\t\t\t\t\t\"banned\": {},\n\t\t\t\t\t\t\"active_admin\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"banned\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"active_admin\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#active_admin\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Difference{\n\t\t\t\t\t\t\tDifference: &openfgapb.UsersetTree_Difference{\n\t\t\t\t\t\t\t\tBase: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#active_admin\",\n\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tSubtract: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#active_admin\",\n\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#banned\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"simple intersection\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\t// Writers must be both directly in 'writers', and in 'admins'\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\": {},\n\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Intersection{\n\t\t\t\t\t\t\t\tIntersection: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{\n\t\t\t\t\t\t\t\t\t\t\t\tThis: &openfgapb.DirectUserset{},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"admin\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Intersection{\n\t\t\t\t\t\t\tIntersection: &openfgapb.UsersetTree_Nodes{\n\t\t\t\t\t\t\t\tNodes: []*openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: &openfgapb.UsersetTree_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: []string{},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#admin\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"complex tree\",\n\t\t\t// Users can write if they are direct members of writers, or repo_writers\n\t\t\t// in the org, unless they are also in banned_writers\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"repo\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"admin\":         {},\n\t\t\t\t\t\t\"owner\":         {},\n\t\t\t\t\t\t\"banned_writer\": {},\n\t\t\t\t\t\t\"writer\": {\n\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Difference{\n\t\t\t\t\t\t\t\tDifference: &openfgapb.Difference{\n\t\t\t\t\t\t\t\t\tBase: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_Union{\n\t\t\t\t\t\t\t\t\t\t\tUnion: &openfgapb.Usersets{\n\t\t\t\t\t\t\t\t\t\t\t\tChild: []*openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_This{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tThis: &openfgapb.DirectUserset{},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTupleset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tObject:   \"$TUPLE_USERSET_OBJECT\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"repo_writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\tSubtract: &openfgapb.Userset{\n\t\t\t\t\t\t\t\t\t\tUserset: &openfgapb.Userset_ComputedUserset{\n\t\t\t\t\t\t\t\t\t\t\tComputedUserset: &openfgapb.ObjectRelation{\n\t\t\t\t\t\t\t\t\t\t\t\tRelation: \"banned_writer\",\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tType: \"org\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"repo_writer\": {},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"owner\",\n\t\t\t\t\tUser:     \"org:openfga\",\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t\tUser:     \"github|jon.allie@openfga\",\n\t\t\t\t},\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: &openfgapb.TupleKey{\n\t\t\t\t\tObject:   \"repo:openfga/foo\",\n\t\t\t\t\tRelation: \"writer\",\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Difference{\n\t\t\t\t\t\t\tDifference: &openfgapb.UsersetTree_Difference{\n\t\t\t\t\t\t\t\tBase: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Union{\n\t\t\t\t\t\t\t\t\t\tUnion: &openfgapb.UsersetTree_Nodes{\n\t\t\t\t\t\t\t\t\t\t\tNodes: []*openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: &openfgapb.UsersetTree_Users{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUsers: []string{\"github|jon.allie@openfga\"},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTupleToUserset: &openfgapb.UsersetTree_TupleToUserset{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tTupleset: \"repo:openfga/foo#owner\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tComputed: []*openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t{Userset: \"org:openfga#repo_writer\"},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tSubtract: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\t\t\t\tName: \"repo:openfga/foo#writer\",\n\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\tComputed: &openfgapb.UsersetTree_Computed{\n\t\t\t\t\t\t\t\t\t\t\t\t\tUserset: \"repo:openfga/foo#banned_writer\",\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname: \"Tuple involving userset that is not involved in TTU rewrite\",\n\t\t\ttypeDefinitions: []*openfgapb.TypeDefinition{\n\t\t\t\t{\n\t\t\t\t\tType: \"document\",\n\t\t\t\t\tRelations: map[string]*openfgapb.Userset{\n\t\t\t\t\t\t\"parent\": typesystem.This(),\n\t\t\t\t\t\t\"editor\": typesystem.This(),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttuples: []*openfgapb.TupleKey{\n\t\t\t\ttuple.NewTupleKey(\"document:1\", \"parent\", \"document:2#editor\"),\n\t\t\t},\n\t\t\trequest: &openfgapb.ExpandRequest{\n\t\t\t\tTupleKey: tuple.NewTupleKey(\"document:1\", \"parent\", \"\"),\n\t\t\t},\n\t\t\texpected: &openfgapb.ExpandResponse{\n\t\t\t\tTree: &openfgapb.UsersetTree{\n\t\t\t\t\tRoot: &openfgapb.UsersetTree_Node{\n\t\t\t\t\t\tName: \"document:1#parent\",\n\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Node_Leaf{\n\t\t\t\t\t\t\tLeaf: &openfgapb.UsersetTree_Leaf{\n\t\t\t\t\t\t\t\tValue: &openfgapb.UsersetTree_Leaf_Users{\n\t\t\t\t\t\t\t\t\tUsers: &openfgapb.UsersetTree_Users{\n\t\t\t\t\t\t\t\t\t\tUsers: []string{\"document:2#editor\"},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\trequire := require.New(t)\n\tctx := context.Background()\n\ttracer := telemetry.NewNoopTracer()\n\tlogger := logger.NewNoopLogger()\n\n\tfor _, test := range tests {\n\t\tt.Run(test.name, func(t *testing.T) {\n\t\t\tstore := testutils.CreateRandomString(20)\n\t\t\tmodelID, err := setUp(ctx, store, datastore, test.typeDefinitions, test.tuples)\n\t\t\trequire.NoError(err)\n\n\t\t\tquery := commands.NewExpandQuery(datastore, tracer, logger)\n\t\t\ttest.request.StoreId = store\n\t\t\ttest.request.AuthorizationModelId = modelID\n\t\t\tgot, err := query.Execute(ctx, test.request)\n\t\t\trequire.NoError(err)\n\n\t\t\tif diff := cmp.Diff(test.expected, got, protocmp.Transform()); diff != \"\" {\n\t\t\t\tt.Fatalf(\"%s: Execute() (-want, +got):\\n%s\", test.name, diff)\n\t\t\t}\n\t\t})\n\t}\n}", "is_vulnerable": 0}
{"code": "func loadKeyPair(certFile, keyFile string) (*tls.Certificate, error) {\n\tif certFile == \"\" || keyFile == \"\" {\n\t\treturn nil, nil\n\t}\n\tcert, err := tls.LoadX509KeyPair(certFile, keyFile)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to load cert/key pair: %v\", err)\n\t}\n\treturn &cert, nil\n}", "is_vulnerable": 0}
{"code": "\tdefer func() {\n\t\tstopFunc()\n\t\t//goleak.VerifyNone(t)\n\t}()", "is_vulnerable": 1}
{"code": "func (src *BindComplete) Encode(dst []byte) ([]byte, error) {\n\treturn append(dst, '2', 0, 0, 0, 4), nil\n}", "is_vulnerable": 0}
{"code": "func tlogFindEntry(ctx context.Context, client *client.Rekor,\n\tblobBytes []byte, sig string, pem []byte) (*models.LogEntryAnon, error) {\n\tb64sig := base64.StdEncoding.EncodeToString([]byte(sig))\n\treturn cosign.FindTlogEntry(ctx, client, b64sig, blobBytes, pem)\n}", "is_vulnerable": 0}
{"code": "func (mr *MockStorageMockRecorder) GetClient(arg0, arg1 interface{}) *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetClient\", reflect.TypeOf((*MockStorage)(nil).GetClient), arg0, arg1)\n}", "is_vulnerable": 0}
{"code": "func (n *IntegrationNetwork) configureAndInitChain() error {\n\t// Create funded accounts based on the config and\n\t// create genesis accounts\n\tcoin := sdktypes.NewCoin(n.cfg.denom, PrefundedAccountInitialBalance)\n\tgenAccounts := createGenesisAccounts(n.cfg.preFundedAccounts)\n\tfundedAccountBalances := createBalances(n.cfg.preFundedAccounts, coin)\n\n\t// Create validator set with the amount of validators specified in the config\n\t// with the default power of 1.\n\tvalSet, valSigners := createValidatorSetAndSigners(n.cfg.amountOfValidators)\n\ttotalBonded := bondedAmt.Mul(sdktypes.NewInt(int64(n.cfg.amountOfValidators)))\n\n\t// Build staking type validators and delegations\n\tvalidators, err := createStakingValidators(valSet.Validators, bondedAmt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfundedAccountBalances = addBondedModuleAccountToFundedBalances(fundedAccountBalances, sdktypes.NewCoin(n.cfg.denom, totalBonded))\n\n\tdelegations := createDelegations(valSet.Validators, genAccounts[0].GetAddress())\n\n\t// Create a new EvmosApp with the following params\n\tevmosApp := createEvmosApp(n.cfg.chainID)\n\n\t// Configure Genesis state\n\tgenesisState := app.NewDefaultGenesisState()\n\n\tgenesisState = setAuthGenesisState(evmosApp, genesisState, genAccounts)\n\n\tstakingParams := StakingCustomGenesisState{\n\t\tdenom:       n.cfg.denom,\n\t\tvalidators:  validators,\n\t\tdelegations: delegations,\n\t}\n\tgenesisState = setStakingGenesisState(evmosApp, genesisState, stakingParams)\n\n\tgenesisState = setInflationGenesisState(evmosApp, genesisState)\n\n\ttotalSupply := calculateTotalSupply(fundedAccountBalances)\n\tbankParams := BankCustomGenesisState{\n\t\ttotalSupply: totalSupply,\n\t\tbalances:    fundedAccountBalances,\n\t}\n\tgenesisState = setBankGenesisState(evmosApp, genesisState, bankParams)\n\n\t// Init chain\n\tstateBytes, err := json.MarshalIndent(genesisState, \"\", \" \")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tevmosApp.InitChain(\n\t\tabcitypes.RequestInitChain{\n\t\t\tChainId:         n.cfg.chainID,\n\t\t\tValidators:      []abcitypes.ValidatorUpdate{},\n\t\t\tConsensusParams: app.DefaultConsensusParams,\n\t\t\tAppStateBytes:   stateBytes,\n\t\t},\n\t)\n\t// Commit genesis changes\n\tevmosApp.Commit()\n\n\theader := tmproto.Header{\n\t\tChainID:            n.cfg.chainID,\n\t\tHeight:             evmosApp.LastBlockHeight() + 1,\n\t\tAppHash:            evmosApp.LastCommitID().Hash,\n\t\tValidatorsHash:     valSet.Hash(),\n\t\tNextValidatorsHash: valSet.Hash(),\n\t\tProposerAddress:    valSet.Proposer.Address,\n\t}\n\tevmosApp.BeginBlock(abcitypes.RequestBeginBlock{Header: header})\n\n\t// Set networks global parameters\n\tn.app = evmosApp\n\t// TODO - this might not be the best way to initilize the context\n\tn.ctx = evmosApp.BaseApp.NewContext(false, header)\n\tn.validators = validators\n\tn.valSet = valSet\n\tn.valSigners = valSigners\n\n\t// Register EVMOS in denom metadata\n\tevmosMetadata := banktypes.Metadata{\n\t\tDescription: \"The native token of Evmos\",\n\t\tBase:        n.cfg.denom,\n\t\t// NOTE: Denom units MUST be increasing\n\t\tDenomUnits: []*banktypes.DenomUnit{\n\t\t\t{\n\t\t\t\tDenom:    n.cfg.denom,\n\t\t\t\tExponent: 0,\n\t\t\t\tAliases:  []string{n.cfg.denom},\n\t\t\t},\n\t\t\t{\n\t\t\t\tDenom:    n.cfg.denom,\n\t\t\t\tExponent: 18,\n\t\t\t},\n\t\t},\n\t\tName:    \"Evmos\",\n\t\tSymbol:  \"EVMOS\",\n\t\tDisplay: n.cfg.denom,\n\t}\n\tevmosApp.BankKeeper.SetDenomMetaData(n.ctx, evmosMetadata)\n\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func SetsockoptTCPRepairOpt(fd, level, opt int, o []TCPRepairOpt) (err error) {\n\tif len(o) == 0 {\n\t\treturn EINVAL\n\t}\n\treturn setsockopt(fd, level, opt, unsafe.Pointer(&o[0]), uintptr(SizeofTCPRepairOpt*len(o)))\n}", "is_vulnerable": 0}
{"code": "func TestCustomHandleCrash(t *testing.T) {\n\tch := make(chan struct{}, 1)\n\tdefer func() {\n\t\tselect {\n\t\tcase <-ch:\n\t\t\tt.Logf(\"crash handler called\")\n\t\tcase <-time.After(1 * time.Second):\n\t\t\tt.Errorf(\"Custom handler not called\")\n\t\t}\n\t}()\n\n\tdefer HandleCrash(func() {\n\t\tch <- struct{}{}\n\t})\n\n\tpanic(\"test\")\n}", "is_vulnerable": 0}
{"code": "func register(client autorest.Client, originalReq *http.Request, re RequestError) error {\n\tsubID := getSubscription(originalReq.URL.Path)\n\tif subID == \"\" {\n\t\treturn errors.New(\"missing parameter subscriptionID to register resource provider\")\n\t}\n\tproviderName, err := getProvider(re)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"missing parameter provider to register resource provider: %s\", err)\n\t}\n\tnewURL := url.URL{\n\t\tScheme: originalReq.URL.Scheme,\n\t\tHost:   originalReq.URL.Host,\n\t}\n\n\t// taken from the resources SDK\n\t// with almost identical code, this sections are easier to mantain\n\t// It is also not a good idea to import the SDK here\n\t// https://github.com/Azure/azure-sdk-for-go/blob/9f366792afa3e0ddaecdc860e793ba9d75e76c27/arm/resources/resources/providers.go#L252\n\tpathParameters := map[string]interface{}{\n\t\t\"resourceProviderNamespace\": autorest.Encode(\"path\", providerName),\n\t\t\"subscriptionId\":            autorest.Encode(\"path\", subID),\n\t}\n\n\tconst APIVersion = \"2016-09-01\"\n\tqueryParameters := map[string]interface{}{\n\t\t\"api-version\": APIVersion,\n\t}\n\n\tpreparer := autorest.CreatePreparer(\n\t\tautorest.AsPost(),\n\t\tautorest.WithBaseURL(newURL.String()),\n\t\tautorest.WithPathParameters(\"/subscriptions/{subscriptionId}/providers/{resourceProviderNamespace}/register\", pathParameters),\n\t\tautorest.WithQueryParameters(queryParameters),\n\t)\n\n\treq, err := preparer.Prepare(&http.Request{})\n\tif err != nil {\n\t\treturn err\n\t}\n\treq = req.WithContext(originalReq.Context())\n\n\tresp, err := autorest.SendWithSender(client, req,\n\t\tautorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\ttype Provider struct {\n\t\tRegistrationState *string `json:\"registrationState,omitempty\"`\n\t}\n\tvar provider Provider\n\n\terr = autorest.Respond(\n\t\tresp,\n\t\tWithErrorUnlessStatusCode(http.StatusOK),\n\t\tautorest.ByUnmarshallingJSON(&provider),\n\t\tautorest.ByClosing(),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// poll for registered provisioning state\n\tregistrationStartTime := time.Now()\n\tfor err == nil && (client.PollingDuration == 0 || (client.PollingDuration != 0 && time.Since(registrationStartTime) < client.PollingDuration)) {\n\t\t// taken from the resources SDK\n\t\t// https://github.com/Azure/azure-sdk-for-go/blob/9f366792afa3e0ddaecdc860e793ba9d75e76c27/arm/resources/resources/providers.go#L45\n\t\tpreparer := autorest.CreatePreparer(\n\t\t\tautorest.AsGet(),\n\t\t\tautorest.WithBaseURL(newURL.String()),\n\t\t\tautorest.WithPathParameters(\"/subscriptions/{subscriptionId}/providers/{resourceProviderNamespace}\", pathParameters),\n\t\t\tautorest.WithQueryParameters(queryParameters),\n\t\t)\n\t\treq, err = preparer.Prepare(&http.Request{})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treq = req.WithContext(originalReq.Context())\n\n\t\tresp, err := autorest.SendWithSender(client, req,\n\t\t\tautorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\terr = autorest.Respond(\n\t\t\tresp,\n\t\t\tWithErrorUnlessStatusCode(http.StatusOK),\n\t\t\tautorest.ByUnmarshallingJSON(&provider),\n\t\t\tautorest.ByClosing(),\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif provider.RegistrationState != nil &&\n\t\t\t*provider.RegistrationState == \"Registered\" {\n\t\t\tbreak\n\t\t}\n\n\t\tdelayed := autorest.DelayWithRetryAfter(resp, originalReq.Context().Done())\n\t\tif !delayed && !autorest.DelayForBackoff(client.PollingDelay, 0, originalReq.Context().Done()) {\n\t\t\treturn originalReq.Context().Err()\n\t\t}\n\t}\n\tif client.PollingDuration != 0 && !(time.Since(registrationStartTime) < client.PollingDuration) {\n\t\treturn errors.New(\"polling for resource provider registration has exceeded the polling duration\")\n\t}\n\treturn err\n}", "is_vulnerable": 0}
{"code": "func NewSync(root common.Hash, database ethdb.KeyValueReader, callback LeafCallback, bloom *SyncBloom) *Sync {\n\tts := &Sync{\n\t\tdatabase: database,\n\t\tmembatch: newSyncMemBatch(),\n\t\trequests: make(map[common.Hash]*request),\n\t\tqueue:    prque.New(nil),\n\t\tbloom:    bloom,\n\t}\n\tts.AddSubTrie(root, 0, common.Hash{}, callback)\n\treturn ts\n}", "is_vulnerable": 1}
{"code": "func TestReverseExpandRespectsContextCancellation(t *testing.T) {\n\tdefer goleak.VerifyNone(t)\n\n\tstore := ulid.Make().String()\n\n\tmodel := testutils.MustTransformDSLToProtoWithID(`model\n  schema 1.1\ntype user\ntype document\n  relations\n\tdefine viewer: [user]`)\n\n\ttypeSystem := typesystem.New(model)\n\tmockController := gomock.NewController(t)\n\tdefer mockController.Finish()\n\n\tvar tuples []*openfgav1.Tuple\n\tfor i := 0; i < 100; i++ {\n\t\tobj := fmt.Sprintf(\"document:%s\", strconv.Itoa(i))\n\t\ttuples = append(tuples, &openfgav1.Tuple{Key: tuple.NewTupleKey(obj, \"viewer\", \"user:maria\")})\n\t}\n\n\tmockDatastore := mocks.NewMockOpenFGADatastore(mockController)\n\tmockDatastore.EXPECT().ReadStartingWithUser(gomock.Any(), store, gomock.Any()).\n\t\tTimes(1).\n\t\tDoAndReturn(func(_ context.Context, _ string, _ storage.ReadStartingWithUserFilter) (storage.TupleIterator, error) {\n\t\t\t// simulate many goroutines trying to write to the results channel\n\t\t\titerator := storage.NewStaticTupleIterator(tuples)\n\t\t\tt.Logf(\"returning tuple iterator\")\n\t\t\treturn iterator, nil\n\t\t})\n\tctx, cancelFunc := context.WithCancel(context.Background())\n\n\tresultChan := make(chan *ReverseExpandResult)\n\n\tdone := make(chan struct{})\n\n\t// process query in one goroutine, but it will be cancelled almost right away\n\tgo func() {\n\t\treverseExpandQuery := NewReverseExpandQuery(mockDatastore, typeSystem)\n\t\tt.Logf(\"before execute reverse expand\")\n\t\treverseExpandQuery.Execute(ctx, &ReverseExpandRequest{\n\t\t\tStoreID:    store,\n\t\t\tObjectType: \"document\",\n\t\t\tRelation:   \"viewer\",\n\t\t\tUser: &UserRefObject{\n\t\t\t\tObject: &openfgav1.Object{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tId:   \"maria\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tContextualTuples: []*openfgav1.TupleKey{},\n\t\t}, resultChan, NewResolutionMetadata())\n\t\tt.Logf(\"after execute reverse expand\")\n\t\tdone <- struct{}{}\n\t}()\n\tgo func() {\n\t\t// simulate max_results=1\n\t\tt.Logf(\"before receive one result\")\n\t\tres := <-resultChan\n\t\tt.Logf(\"after receive one result\")\n\t\tcancelFunc()\n\t\tt.Logf(\"after send cancellation\")\n\t\trequire.NotNil(t, res.Object)\n\t\trequire.NoError(t, res.Err)\n\t}()\n\n\tselect {\n\tcase <-done:\n\t\tt.Log(\"OK!\")\n\t\treturn\n\tcase <-time.After(30 * time.Millisecond):\n\t\trequire.FailNow(t, \"timed out\")\n\t}\n}", "is_vulnerable": 1}
{"code": "\t\tcheckingStream := newCheckingResourceStream(lookupContext, reachableContext, func() {\n\t\t\tcancelReachable(errCanceledBecauseNoAdditionalResourcesNeeded)\n\t\t}, req, cl.c, parentStream, limits, cl.concurrencyLimit)", "is_vulnerable": 0}
{"code": "func CryptoRandom(count int, start int, end int, letters bool, numbers bool, chars ...rune) (string, error) {\n\tif count == 0 {\n\t\treturn \"\", nil\n\t} else if count < 0 {\n\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Requested random string length %v is less than 0.\", count) // equiv to err := errors.New(\"...\")\n\t\treturn \"\", err\n\t}\n\tif chars != nil && len(chars) == 0 {\n\t\terr := fmt.Errorf(\"randomstringutils illegal argument: The chars array must not be empty\")\n\t\treturn \"\", err\n\t}\n\n\tif start == 0 && end == 0 {\n\t\tif chars != nil {\n\t\t\tend = len(chars)\n\t\t} else {\n\t\t\tif !letters && !numbers {\n\t\t\t\tend = math.MaxInt32\n\t\t\t} else {\n\t\t\t\tend = 'z' + 1\n\t\t\t\tstart = ' '\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif end <= start {\n\t\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Parameter end (%v) must be greater than start (%v)\", end, start)\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tif chars != nil && end > len(chars) {\n\t\t\terr := fmt.Errorf(\"randomstringutils illegal argument: Parameter end (%v) cannot be greater than len(chars) (%v)\", end, len(chars))\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\n\tbuffer := make([]rune, count)\n\tgap := end - start\n\n\t// high-surrogates range, (\\uD800-\\uDBFF) = 55296 - 56319\n\t//  low-surrogates range, (\\uDC00-\\uDFFF) = 56320 - 57343\n\n\tfor count != 0 {\n\t\tcount--\n\t\tvar ch rune\n\t\tif chars == nil {\n\t\t\tch = rune(getCryptoRandomInt(gap) + int64(start))\n\t\t} else {\n\t\t\tch = chars[getCryptoRandomInt(gap)+int64(start)]\n\t\t}\n\n\t\tif letters && unicode.IsLetter(ch) || numbers && unicode.IsDigit(ch) || !letters && !numbers {\n\t\t\tif ch >= 56320 && ch <= 57343 { // low surrogate range\n\t\t\t\tif count == 0 {\n\t\t\t\t\tcount++\n\t\t\t\t} else {\n\t\t\t\t\t// Insert low surrogate\n\t\t\t\t\tbuffer[count] = ch\n\t\t\t\t\tcount--\n\t\t\t\t\t// Insert high surrogate\n\t\t\t\t\tbuffer[count] = rune(55296 + getCryptoRandomInt(128))\n\t\t\t\t}\n\t\t\t} else if ch >= 55296 && ch <= 56191 { // High surrogates range (Partial)\n\t\t\t\tif count == 0 {\n\t\t\t\t\tcount++\n\t\t\t\t} else {\n\t\t\t\t\t// Insert low surrogate\n\t\t\t\t\tbuffer[count] = rune(56320 + getCryptoRandomInt(128))\n\t\t\t\t\tcount--\n\t\t\t\t\t// Insert high surrogate\n\t\t\t\t\tbuffer[count] = ch\n\t\t\t\t}\n\t\t\t} else if ch >= 56192 && ch <= 56319 {\n\t\t\t\t// private high surrogate, skip it\n\t\t\t\tcount++\n\t\t\t} else {\n\t\t\t\t// not one of the surrogates*\n\t\t\t\tbuffer[count] = ch\n\t\t\t}\n\t\t} else {\n\t\t\tcount++\n\t\t}\n\t}\n\treturn string(buffer), nil\n}", "is_vulnerable": 0}
{"code": "func (src *Describe) Encode(dst []byte) []byte {\n\tdst = append(dst, 'D')\n\tsp := len(dst)\n\tdst = pgio.AppendInt32(dst, -1)\n\n\tdst = append(dst, src.ObjectType)\n\tdst = append(dst, src.Name...)\n\tdst = append(dst, 0)\n\n\tpgio.SetInt32(dst[sp:], int32(len(dst[sp:])))\n\n\treturn dst\n}", "is_vulnerable": 1}
{"code": "func TestListNodeExecutions_NothingToReturn(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{}, nil\n\t\t})\n\tvar listExecutionsCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.ExecutionCollectionOutput, error) {\n\t\t\tlistExecutionsCalled = true\n\t\t\treturn interfaces.ExecutionCollectionOutput{}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\n\t_, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t})\n\n\tassert.NoError(t, err)\n\tassert.False(t, listExecutionsCalled)\n}", "is_vulnerable": 0}
{"code": "func (he *HookedWebSocketEvent) Get(key string) any {\n\tif he.copy == nil {\n\t\treturn he.original.GetData()[key]\n\t}\n\n\treturn he.copy.GetData()[key]\n}", "is_vulnerable": 0}
{"code": "\tIt(\"podman run with user (integer, not in /etc/passwd)\", func() {\n\t\tsession := podmanTest.Podman([]string{\"run\", \"--rm\", \"--user=1234\", ALPINE, \"id\"})\n\t\tsession.WaitWithDefaultTimeout()\n\t\tExpect(session).Should(Exit(0))\n\t\tExpect(session.OutputToString()).To(Equal(\"uid=1234(1234) gid=0(root)\"))\n\t})", "is_vulnerable": 1}
{"code": "func (j JuiceFileUtils) GetFileCount(juiceSubPath string) (fileCount int64, err error) {\n\tvar (\n\t\t//strs    = \"du -ah juiceSubPath |grep ^- |wc -l \"\n\t\tstrs    = fmt.Sprintf(\"ls -lR %s |grep ^- |wc -l \", security.EscapeBashStr(juiceSubPath))\n\t\tcommand = []string{\"bash\", \"-c\", strs}\n\t\tstdout  string\n\t\tstderr  string\n\t)\n\tstdout, stderr, err = j.exec(command)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"execute command %v with expectedErr: %v stdout %s and stderr %s\", command, err, stdout, stderr)\n\t\treturn\n\t}\n\n\t// eg: Master.FilesCompleted  (Type: COUNTER, Value: 6,367,897)\n\tstr := strings.Split(stdout, \"\\n\")\n\n\tif len(str) != 1 {\n\t\terr = fmt.Errorf(\"failed to parse %s in Count method\", str)\n\t\treturn\n\t}\n\n\tdata := strings.Fields(str[0])\n\tif len(data) != 1 {\n\t\terr = fmt.Errorf(\"failed to parse %s in Count method\", data)\n\t\treturn\n\t}\n\n\tfileCount, err = strconv.ParseInt(data[0], 10, 64)\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn fileCount, nil\n}", "is_vulnerable": 0}
{"code": "func (m *Subby) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Subby: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Subby: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sub\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\ts := string(dAtA[iNdEx:postIndex])\n\t\t\tm.Sub = &s\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (t *SingleResolver) TenantID(ctx context.Context) (string, error) {\n\t//lint:ignore faillint wrapper around upstream method\n\tid, err := user.ExtractOrgID(ctx)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif containsUnsafePathSegments(id) {\n\t\treturn \"\", errInvalidTenantID\n\t}\n\n\treturn id, nil\n}", "is_vulnerable": 0}
{"code": "func baseGenerateComponent(pCtx process.Context, wl *Workload, appName, ns string) (*types.ComponentManifest, error) {\n\tvar err error\n\tpCtx.PushData(model.ContextComponentType, wl.Type)\n\tfor _, tr := range wl.Traits {\n\t\tif err := tr.EvalContext(pCtx); err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"evaluate template trait=%s app=%s\", tr.Name, wl.Name)\n\t\t}\n\t}\n\tif patcher := wl.Patch; patcher != nil {\n\t\tworkload, auxiliaries := pCtx.Output()\n\t\tif p, err := patcher.LookupValue(\"workload\"); err == nil {\n\t\t\tif err := workload.Unify(p.CueValue()); err != nil {\n\t\t\t\treturn nil, errors.WithMessage(err, \"patch workload\")\n\t\t\t}\n\t\t}\n\t\tfor _, aux := range auxiliaries {\n\t\t\tif p, err := patcher.LookupByScript(fmt.Sprintf(\"traits[\\\"%s\\\"]\", aux.Name)); err == nil && p.CueValue().Err() == nil {\n\t\t\t\tif err := aux.Ins.Unify(p.CueValue()); err != nil {\n\t\t\t\t\treturn nil, errors.WithMessagef(err, \"patch outputs.%s\", aux.Name)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tcompManifest, err := evalWorkloadWithContext(pCtx, wl, ns, appName, wl.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcompManifest.Name = wl.Name\n\tcompManifest.Namespace = ns\n\t// we record the external revision name in ExternalRevision field\n\tcompManifest.ExternalRevision = wl.ExternalRevision\n\n\tcompManifest.Scopes = make([]*corev1.ObjectReference, len(wl.Scopes))\n\tfor i, s := range wl.Scopes {\n\t\tcompManifest.Scopes[i] = &corev1.ObjectReference{\n\t\t\tAPIVersion: metav1.GroupVersion{\n\t\t\t\tGroup:   s.GVK.Group,\n\t\t\t\tVersion: s.GVK.Version,\n\t\t\t}.String(),\n\t\t\tKind: s.GVK.Kind,\n\t\t\tName: s.Name,\n\t\t}\n\t}\n\treturn compManifest, nil\n}", "is_vulnerable": 1}
{"code": "func New(model *openfgapb.AuthorizationModel) *TypeSystem {\n\ttds := make(map[string]*openfgapb.TypeDefinition, len(model.GetTypeDefinitions()))\n\trelations := make(map[string]map[string]*openfgapb.Relation, len(model.GetTypeDefinitions()))\n\n\tfor _, td := range model.GetTypeDefinitions() {\n\t\ttypeName := td.GetType()\n\n\t\ttds[typeName] = td\n\t\ttdRelations := make(map[string]*openfgapb.Relation, len(td.GetRelations()))\n\n\t\tfor relation, rewrite := range td.GetRelations() {\n\t\t\tr := &openfgapb.Relation{\n\t\t\t\tName:     relation,\n\t\t\t\tRewrite:  rewrite,\n\t\t\t\tTypeInfo: &openfgapb.RelationTypeInfo{},\n\t\t\t}\n\n\t\t\tif metadata, ok := td.GetMetadata().GetRelations()[relation]; ok {\n\t\t\t\tr.TypeInfo.DirectlyRelatedUserTypes = metadata.GetDirectlyRelatedUserTypes()\n\t\t\t}\n\n\t\t\ttdRelations[relation] = r\n\t\t}\n\t\trelations[typeName] = tdRelations\n\t}\n\n\treturn &TypeSystem{\n\t\tmodelID:         model.GetId(),\n\t\tschemaVersion:   model.GetSchemaVersion(),\n\t\ttypeDefinitions: tds,\n\t\trelations:       relations,\n\t}\n}", "is_vulnerable": 0}
{"code": "func (e *MaxLayersExceeded) Error() string {\n\treturn fmt.Sprintf(\"number of layers (%d) exceeded the limit (%d)\", e.value, e.maximum)\n}", "is_vulnerable": 0}
{"code": "func (cvss20 CVSS20) Vector() string {\n\ts := \"\"\n\t// Base\n\ts += \"AV:\" + cvss20.AccessVector\n\ts += \"/AC:\" + cvss20.AccessComplexity\n\ts += \"/Au:\" + cvss20.Authentication\n\ts += \"/C:\" + cvss20.ConfidentialityImpact\n\ts += \"/I:\" + cvss20.IntegrityImpact\n\ts += \"/A:\" + cvss20.AvailabilityImpact\n\t// Temporal, if any is defined\n\tif cvss20.Exploitability != \"ND\" || cvss20.RemediationLevel != \"ND\" || cvss20.ReportConfidence != \"ND\" {\n\t\ts += \"/E:\" + cvss20.Exploitability\n\t\ts += \"/RL:\" + cvss20.RemediationLevel\n\t\ts += \"/RC:\" + cvss20.ReportConfidence\n\t}\n\t// Environmental, if any is defined\n\tif cvss20.CollateralDamagePotential != \"ND\" || cvss20.TargetDistribution != \"ND\" || cvss20.ConfidentialityRequirement != \"ND\" || cvss20.IntegrityRequirement != \"ND\" || cvss20.AvailabilityRequirement != \"ND\" {\n\t\ts += \"/CDP:\" + cvss20.CollateralDamagePotential\n\t\ts += \"/TD:\" + cvss20.TargetDistribution\n\t\ts += \"/CR:\" + cvss20.ConfidentialityRequirement\n\t\ts += \"/IR:\" + cvss20.IntegrityRequirement\n\t\ts += \"/AR:\" + cvss20.AvailabilityRequirement\n\t}\n\treturn s\n}", "is_vulnerable": 1}
{"code": "func TestEventHandler(t *testing.T) {\n\tconvey.Convey(\"Given a route that receives an event\", t, func() {\n\t\trouter := &Router{\n\t\t\troute:            webhook.GetFakeRoute(),\n\t\t\tslackEventSource: &v1alpha1.SlackEventSource{},\n\t\t}\n\n\t\tconvey.Convey(\"Test an event notification\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tevent := []byte(`\n{\n\"type\": \"name_of_event\",\n\"event_ts\": \"1234567890.123456\",\n\"user\": \"UXXXXXXX1\"\n}\n`)\n\n\t\t\tj := json.RawMessage(event)\n\t\t\tce := slackevents.EventsAPICallbackEvent{\n\t\t\t\tToken:     \"Jhj5dZrVaK7ZwHHjRyZWjbDl\",\n\t\t\t\tType:      slackevents.CallbackEvent,\n\t\t\t\tEventTime: 1234567890,\n\t\t\t\tAPIAppID:  \"AXXXXXXXXX\",\n\t\t\t\tAuthedUsers: []string{\n\t\t\t\t\t\"UXXXXXXX1\",\n\t\t\t\t\t\"UXXXXXXX2\",\n\t\t\t\t},\n\t\t\t\tEventID:    \"Ev08MFMKH6\",\n\t\t\t\tInnerEvent: &j,\n\t\t\t}\n\t\t\tpayload, err := yaml.Marshal(ce)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.route.Active = true\n\n\t\t\tgo func() {\n\t\t\t\t<-router.route.DataCh\n\t\t\t}()\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewBuffer(payload)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusInternalServerError)\n\t\t})\n\t})\n}", "is_vulnerable": 1}
{"code": "\t\t\tgo func() {\n\t\t\t\tresult := h.rebuild()\n\t\t\t\th.rebuild = result.Rebuild\n\t\t\t\tbuild.result = result\n\t\t\t\tbuild.waitGroup.Done()\n\n\t\t\t\t// Build results stay valid for a little bit afterward since a page\n\t\t\t\t// load may involve multiple requests and don't want to rebuild\n\t\t\t\t// separately for each of those requests.\n\t\t\t\ttime.Sleep(250 * time.Millisecond)\n\t\t\t\th.mutex.Lock()\n\t\t\t\tdefer h.mutex.Unlock()\n\t\t\t\th.currentBuild = nil\n\t\t\t}()", "is_vulnerable": 1}
{"code": "func LoadKey2(rw io.ReadWriter, keyBlob []byte, srkAuth []byte) (tpmutil.Handle, error) {\n\t// Deserialize the keyBlob as a key\n\tvar k key\n\tif _, err := tpmutil.Unpack(keyBlob, &k); err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run OSAP for the SRK, reading a random OddOSAP for our initial\n\t// command and getting back a secret and a handle. LoadKey2 needs an\n\t// OSAP session for the SRK because the private part of a TPM_KEY or\n\t// TPM_KEY12 is sealed against the SRK.\n\tsharedSecret, osapr, err := newOSAPSession(rw, etSRK, khSRK, srkAuth)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\tdefer osapr.Close(rw)\n\tdefer zeroBytes(sharedSecret[:])\n\n\tauthIn := []interface{}{ordLoadKey2, k}\n\tca, err := newCommandAuth(osapr.AuthHandle, osapr.NonceEven, nil, sharedSecret[:], authIn)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\thandle, ra, ret, err := loadKey2(rw, &k, ca)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Check the response authentication.\n\traIn := []interface{}{ret, ordLoadKey2}\n\tif err := ra.verify(ca.NonceOdd, sharedSecret[:], raIn); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn handle, nil\n}", "is_vulnerable": 0}
{"code": "func getGateway(ctx *statsContext) error {\n\tgatewayID := helpers.GetGatewayID(&ctx.gatewayStats)\n\tgw, err := storage.GetAndCacheGateway(ctx.ctx, storage.DB(), gatewayID)\n\tif err != nil {\n\t\tif errors.Cause(err) == storage.ErrDoesNotExist {\n\t\t\tlog.WithFields(log.Fields{\n\t\t\t\t\"ctx_id\":     ctx.ctx.Value(logging.ContextIDKey),\n\t\t\t\t\"gateway_id\": gatewayID,\n\t\t\t}).Warning(\"gateway/stats: stats received by unknown gateway\")\n\t\t\treturn ErrAbort\n\t\t} else {\n\t\t\treturn errors.Wrap(err, \"get gateway error\")\n\t\t}\n\t}\n\n\tctx.gateway = gw\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (l *StringList) UnmarshalJSON(data []byte) error {\n\tif len(data) == 0 || string(data) == `\"\"` {\n\t\t*l = []string{}\n\t} else {\n\t\t*l = strings.Split(string(data[1:len(data)-1]), \",\")\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func TestPostgresInjectionUser(t *testing.T) {\n\tctx := context.Background()\n\ttestCtx := setupTestContext(ctx, t, withSelfHostedPostgres(\"postgres\"))\n\tgo testCtx.startHandlingConnections()\n\n\tpostgresServer := testCtx.postgres[\"postgres\"].db\n\n\t// Make sure the role allows wildcard database users and names.\n\ttestCtx.createUserAndRole(ctx, t, \"alice\", \"admin\", []string{types.Wildcard}, []string{types.Wildcard})\n\n\t// Construct malicious username that simulates the connection string.\n\tuser := fmt.Sprintf(\"alice@localhost:%v?database=prod&foo=\", postgresServer.Port())\n\n\t// Connect and make sure startup parameters are as expected.\n\tpsql, err := testCtx.postgresClient(ctx, \"alice\", \"postgres\", user, \"test\")\n\trequire.NoError(t, err)\n\n\tselect {\n\tcase p := <-postgresServer.ParametersCh():\n\t\trequire.Equal(t, map[string]string{\"user\": user, \"database\": \"test\"}, p)\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"didn't receive startup message parameters after 1s\")\n\t}\n\n\terr = psql.Close(ctx)\n\trequire.NoError(t, err)\n}", "is_vulnerable": 0}
{"code": "func TestAuth(t *testing.T) {\n\ta, b, err := netPipe()\n\tif err != nil {\n\t\tt.Fatalf(\"netPipe: %v\", err)\n\t}\n\n\tdefer a.Close()\n\tdefer b.Close()\n\n\tagent, _, cleanup := startAgent(t)\n\tdefer cleanup()\n\n\tif err := agent.Add(AddedKey{PrivateKey: testPrivateKeys[\"rsa\"], Comment: \"comment\"}); err != nil {\n\t\tt.Errorf(\"Add: %v\", err)\n\t}\n\n\tserverConf := ssh.ServerConfig{}\n\tserverConf.AddHostKey(testSigners[\"rsa\"])\n\tserverConf.PublicKeyCallback = func(c ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n\t\tif bytes.Equal(key.Marshal(), testPublicKeys[\"rsa\"].Marshal()) {\n\t\t\treturn nil, nil\n\t\t}\n\n\t\treturn nil, errors.New(\"pubkey rejected\")\n\t}\n\n\tgo func() {\n\t\tconn, _, _, err := ssh.NewServerConn(a, &serverConf)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Server: %v\", err)\n\t\t}\n\t\tconn.Close()\n\t}()\n\n\tconf := ssh.ClientConfig{}\n\tconf.Auth = append(conf.Auth, ssh.PublicKeysCallback(agent.Signers))\n\tconn, _, _, err := ssh.NewClientConn(b, \"\", &conf)\n\tif err != nil {\n\t\tt.Fatalf(\"NewClientConn: %v\", err)\n\t}\n\tconn.Close()\n}", "is_vulnerable": 1}
{"code": "func (mt *MultiTenantServicePrincipalToken) RefreshWithContext(ctx context.Context) error {\n\tif err := mt.PrimaryToken.RefreshWithContext(ctx); err != nil {\n\t\treturn fmt.Errorf(\"failed to refresh primary token: %v\", err)\n\t}\n\tfor _, aux := range mt.AuxiliaryTokens {\n\t\tif err := aux.RefreshWithContext(ctx); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to refresh auxiliary token: %v\", err)\n\t\t}\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (e *ERC20LogicView) FindBridgeStopped(\n\tal *types.ERC20EventBridgeStopped,\n\tblockNumber,\n\tlogIndex uint64,\n\ttxHash string,\n) error {\n\tbf, err := bridgecontract.NewErc20BridgeLogicRestrictedFilterer(\n\t\te.clt.CollateralBridgeAddress(), e.clt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tresp := \"ok\"\n\tdefer func() {\n\t\tmetrics.EthCallInc(\"find_bridge_stopped\", resp)\n\t}()\n\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\titer, err := bf.FilterBridgeStopped(\n\t\t&bind.FilterOpts{\n\t\t\tStart:   blockNumber - 1,\n\t\t\tContext: ctx,\n\t\t},\n\t)\n\tif err != nil {\n\t\tresp = getMaybeHTTPStatus(err)\n\t\treturn err\n\t}\n\tdefer iter.Close()\n\n\tvar event *bridgecontract.Erc20BridgeLogicRestrictedBridgeStopped\n\n\tfor iter.Next() {\n\t\tif iter.Event.Raw.BlockNumber == blockNumber &&\n\t\t\tuint64(iter.Event.Raw.Index) == logIndex &&\n\t\t\titer.Event.Raw.TxHash.Hex() == txHash {\n\t\t\tevent = iter.Event\n\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif event == nil {\n\t\treturn ErrUnableToFindERC20BridgeStopped\n\t}\n\n\t// now ensure we have enough confirmations\n\tif err := e.ethConfs.Check(event.Raw.BlockNumber); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (st *ReturnStack) push(d uint64) {\n\tst.data = append(st.data, d)\n}", "is_vulnerable": 1}
{"code": "\toriginValidator := func(origin string) bool {\n\t\tif strings.HasSuffix(origin, \".example.com\") {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\t}", "is_vulnerable": 0}
{"code": "func (src *CopyDone) Encode(dst []byte) []byte {\n\treturn append(dst, 'c', 0, 0, 0, 4)\n}", "is_vulnerable": 1}
{"code": "func NewFutureFromResponse(resp *http.Response) (Future, error) {\n\tpt, err := createPollingTracker(resp)\n\tif err != nil {\n\t\treturn Future{}, err\n\t}\n\treturn Future{pt: pt}, nil\n}", "is_vulnerable": 1}
{"code": "func (hs *HTTPServer) makePluginResourceRequest(w http.ResponseWriter, req *http.Request, pCtx backend.PluginContext) error {\n\tkeepCookieModel := struct {\n\t\tKeepCookies []string `json:\"keepCookies\"`\n\t}{}\n\tif dis := pCtx.DataSourceInstanceSettings; dis != nil {\n\t\terr := json.Unmarshal(dis.JSONData, &keepCookieModel)\n\t\tif err != nil {\n\t\t\ths.log.Warn(\"failed to to unpack JSONData in datasource instance settings\", \"err\", err)\n\t\t}\n\t}\n\n\tlist := contexthandler.AuthHTTPHeaderListFromContext(req.Context())\n\tif list != nil {\n\t\tfor _, name := range list.Items {\n\t\t\treq.Header.Del(name)\n\t\t}\n\t}\n\n\tproxyutil.ClearCookieHeader(req, keepCookieModel.KeepCookies)\n\tproxyutil.PrepareProxyRequest(req)\n\n\tbody, err := ioutil.ReadAll(req.Body)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to read request body: %w\", err)\n\t}\n\n\tcrReq := &backend.CallResourceRequest{\n\t\tPluginContext: pCtx,\n\t\tPath:          req.URL.Path,\n\t\tMethod:        req.Method,\n\t\tURL:           req.URL.String(),\n\t\tHeaders:       req.Header,\n\t\tBody:          body,\n\t}\n\n\tchildCtx, cancel := context.WithCancel(req.Context())\n\tdefer cancel()\n\tstream := newCallResourceResponseStream(childCtx)\n\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\n\tdefer func() {\n\t\tif err := stream.Close(); err != nil {\n\t\t\ths.log.Warn(\"Failed to close plugin resource stream\", \"err\", err)\n\t\t}\n\t\twg.Wait()\n\t}()\n\n\tvar flushStreamErr error\n\tgo func() {\n\t\tflushStreamErr = hs.flushStream(stream, w)\n\t\twg.Done()\n\t}()\n\n\tif err := hs.pluginClient.CallResource(req.Context(), crReq, stream); err != nil {\n\t\treturn err\n\t}\n\n\treturn flushStreamErr\n}", "is_vulnerable": 0}
{"code": "func (s *Server) CheckDeletionToken(deletionToken, token, filename string) error {\n\ts.Lock(token, filename)\n\tdefer s.Unlock(token, filename)\n\n\tvar metadata Metadata\n\n\tr, _, err := s.storage.Get(token, fmt.Sprintf(\"%s.metadata\", filename))\n\tif s.storage.IsNotExist(err) {\n\t\treturn errors.New(\"Metadata doesn't exist\")\n\t} else if err != nil {\n\t\treturn err\n\t}\n\n\tdefer r.Close()\n\n\tif err := json.NewDecoder(r).Decode(&metadata); err != nil {\n\t\treturn err\n\t} else if metadata.DeletionToken != deletionToken {\n\t\treturn errors.New(\"Deletion token doesn't match.\")\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *Subby) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowOne\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Subby: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Subby: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Sub\", wireType)\n\t\t\t}\n\t\t\tvar stringLen uint64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowOne\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tstringLen |= uint64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tintStringLen := int(stringLen)\n\t\t\tif intStringLen < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tpostIndex := iNdEx + intStringLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Sub = string(dAtA[iNdEx:postIndex])\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipOne(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthOne\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func substituteVariables(rule kyvernov1.Rule, ctx enginecontext.EvalInterface, logger logr.Logger) (*kyvernov1.Rule, error) {\n\t// remove attestations as variables are not substituted in them\n\truleCopy := *rule.DeepCopy()\n\tfor i := range ruleCopy.VerifyImages {\n\t\tfor j := range ruleCopy.VerifyImages[i].Attestations {\n\t\t\truleCopy.VerifyImages[i].Attestations[j].Conditions = nil\n\t\t}\n\t}\n\tvar err error\n\truleCopy, err = variables.SubstituteAllInRule(logger, ctx, ruleCopy)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// replace attestations\n\tfor i := range ruleCopy.VerifyImages {\n\t\tfor j := range ruleCopy.VerifyImages[i].Attestations {\n\t\t\truleCopy.VerifyImages[i].Attestations[j].Conditions = rule.VerifyImages[i].Attestations[j].Conditions\n\t\t}\n\t}\n\treturn &ruleCopy, nil\n}", "is_vulnerable": 0}
{"code": "func (a upstreamVhost) GetDocumentation() parser.AnnotationFields {\n\treturn a.annotationConfig.Annotations\n}", "is_vulnerable": 0}
{"code": "func (m *NidRepCustom) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepCustom: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NidRepCustom: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Id\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v Uuid\n\t\t\tm.Id = append(m.Id, v)\n\t\t\tif err := m.Id[len(m.Id)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Value\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowThetest\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tvar v github_com_gogo_protobuf_test_custom.Uint128\n\t\t\tm.Value = append(m.Value, v)\n\t\t\tif err := m.Value[len(m.Value)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipThetest(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthThetest\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "\tt.Run(fmt.Sprintf(\"%s-Gas=%d\", test.Name, contract.Gas), func(t *testing.T) {\n\t\tif res, err := RunPrecompiledContract(p, in, contract); err != nil {\n\t\t\tt.Error(err)\n\t\t} else if common.Bytes2Hex(res) != test.Expected {\n\t\t\tt.Errorf(\"Expected %v, got %v\", test.Expected, common.Bytes2Hex(res))\n\t\t}\n\t\t// Verify that the precompile did not touch the input buffer\n\t\texp := common.Hex2Bytes(test.Input)\n\t\tif !bytes.Equal(in, exp) {\n\t\t\tt.Errorf(\"Precompiled %v modified input data\", addr)\n\t\t}\n\t})", "is_vulnerable": 1}
{"code": "func (s *state) WriteRsyncFileOnDisk(path string, data []byte, withdraw bool) error {\n\tfPath, err := syncpki.GetDownloadPath(path, true)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = os.MkdirAll(filepath.Join(s.Basepath, fPath), os.ModePerm)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfPath, err = syncpki.GetDownloadPath(path, false)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// GHSA-cqh2-vc2f-q4fh: Prevent parent directory writes outside of Basepath\n\tfPath = strings.ReplaceAll(fPath, \"../\", \"\")\n\n\tf, err := os.Create(filepath.Join(s.Basepath, fPath))\n\tif err != nil {\n\t\treturn err\n\t}\n\tf.Write(data)\n\tf.Close()\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (m *MockERC20BridgeView) FindAssetList(arg0 *types.ERC20AssetList, arg1, arg2 uint64) error {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"FindAssetList\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "is_vulnerable": 1}
{"code": "func (client GroupsClient) ExportTemplate(ctx context.Context, resourceGroupName string, parameters ExportTemplateRequest) (result GroupExportResult, err error) {\n\tif tracing.IsEnabled() {\n\t\tctx = tracing.StartSpan(ctx, fqdn+\"/GroupsClient.ExportTemplate\")\n\t\tdefer func() {\n\t\t\tsc := -1\n\t\t\tif result.Response.Response != nil {\n\t\t\t\tsc = result.Response.Response.StatusCode\n\t\t\t}\n\t\t\ttracing.EndSpan(ctx, sc, err)\n\t\t}()\n\t}\n\tif err := validation.Validate([]validation.Validation{\n\t\t{TargetValue: resourceGroupName,\n\t\t\tConstraints: []validation.Constraint{{Target: \"resourceGroupName\", Name: validation.MaxLength, Rule: 90, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.MinLength, Rule: 1, Chain: nil},\n\t\t\t\t{Target: \"resourceGroupName\", Name: validation.Pattern, Rule: `^[-\\p{L}\\._\\(\\)\\w]+$`, Chain: nil}}}}); err != nil {\n\t\treturn result, validation.NewError(\"resources.GroupsClient\", \"ExportTemplate\", err.Error())\n\t}\n\n\treq, err := client.ExportTemplatePreparer(ctx, resourceGroupName, parameters)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", nil, \"Failure preparing request\")\n\t\treturn\n\t}\n\n\tresp, err := client.ExportTemplateSender(req)\n\tif err != nil {\n\t\tresult.Response = autorest.Response{Response: resp}\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", resp, \"Failure sending request\")\n\t\treturn\n\t}\n\n\tresult, err = client.ExportTemplateResponder(resp)\n\tif err != nil {\n\t\terr = autorest.NewErrorWithError(err, \"resources.GroupsClient\", \"ExportTemplate\", resp, \"Failure responding to request\")\n\t}\n\n\treturn\n}", "is_vulnerable": 0}
{"code": "func (dra *DuplicateResolutionAlgorithm) UnmarshalJSON(data []byte) error {\n\treturn dra.FromStringValue(strings.Trim(string(data), `\"`))\n}\n\nfunc (dra DuplicateResolutionAlgorithm) String() string {\n\tswitch dra {\n\tcase DupeResAlgRecord:\n\t\treturn \"record\"\n\tcase DupeResAlgNone:\n\t\treturn \"none\"\n\tcase DupeResAlgRemove:\n\t\treturn \"remove\"\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"invalid duplicate-resolution type '%d'\", dra))\n\t}\n}\n\n// PostRestore has some options which will be executed after kv restored.\ntype PostRestore struct {\n\tChecksum          PostOpLevel `toml:\"checksum\" json:\"checksum\"`\n\tAnalyze           PostOpLevel `toml:\"analyze\" json:\"analyze\"`\n\tLevel1Compact     bool        `toml:\"level-1-compact\" json:\"level-1-compact\"`\n\tPostProcessAtLast bool        `toml:\"post-process-at-last\" json:\"post-process-at-last\"`\n\tCompact           bool        `toml:\"compact\" json:\"compact\"`\n}\n\ntype CSVConfig struct {\n\t// Separator, Delimiter and Terminator should all be in utf8mb4 encoding.\n\tSeparator       string `toml:\"separator\" json:\"separator\"`\n\tDelimiter       string `toml:\"delimiter\" json:\"delimiter\"`\n\tTerminator      string `toml:\"terminator\" json:\"terminator\"`\n\tNull            string `toml:\"null\" json:\"null\"`\n\tHeader          bool   `toml:\"header\" json:\"header\"`\n\tTrimLastSep     bool   `toml:\"trim-last-separator\" json:\"trim-last-separator\"`\n\tNotNull         bool   `toml:\"not-null\" json:\"not-null\"`\n\tBackslashEscape bool   `toml:\"backslash-escape\" json:\"backslash-escape\"`\n}\n\ntype MydumperRuntime struct {\n\tReadBlockSize    ByteSize         `toml:\"read-block-size\" json:\"read-block-size\"`\n\tBatchSize        ByteSize         `toml:\"batch-size\" json:\"batch-size\"`\n\tBatchImportRatio float64          `toml:\"batch-import-ratio\" json:\"batch-import-ratio\"`\n\tSourceDir        string           `toml:\"data-source-dir\" json:\"data-source-dir\"`\n\tCharacterSet     string           `toml:\"character-set\" json:\"character-set\"`\n\tCSV              CSVConfig        `toml:\"csv\" json:\"csv\"`\n\tMaxRegionSize    ByteSize         `toml:\"max-region-size\" json:\"max-region-size\"`\n\tFilter           []string         `toml:\"filter\" json:\"filter\"`\n\tFileRouters      []*FileRouteRule `toml:\"files\" json:\"files\"`\n\t// Deprecated: only used to keep the compatibility.\n\tNoSchema         bool             `toml:\"no-schema\" json:\"no-schema\"`\n\tCaseSensitive    bool             `toml:\"case-sensitive\" json:\"case-sensitive\"`\n\tStrictFormat     bool             `toml:\"strict-format\" json:\"strict-format\"`\n\tDefaultFileRules bool             `toml:\"default-file-rules\" json:\"default-file-rules\"`\n\tIgnoreColumns    AllIgnoreColumns `toml:\"ignore-data-columns\" json:\"ignore-data-columns\"`\n\t// DataCharacterSet is the character set of the source file. Only CSV files are supported now. The following options are supported.\n\t//   - utf8mb4\n\t//   - GB18030\n\t//   - GBK: an extension of the GB2312 character set and is also known as Code Page 936.\n\t//   - binary: no attempt to convert the encoding.\n\t// Leave DataCharacterSet empty will make it use `binary` by default.\n\tDataCharacterSet string `toml:\"data-character-set\" json:\"data-character-set\"`\n\t// DataInvalidCharReplace is the replacement characters for non-compatible characters, which shouldn't duplicate with the separators or line breaks.\n\t// Changing the default value will result in increased parsing time. Non-compatible characters do not cause an increase in error.\n\tDataInvalidCharReplace string `toml:\"data-invalid-char-replace\" json:\"data-invalid-char-replace\"`\n}\n\ntype AllIgnoreColumns []*IgnoreColumns\n\ntype IgnoreColumns struct {\n\tDB          string   `toml:\"db\" json:\"db\"`\n\tTable       string   `toml:\"table\" json:\"table\"`\n\tTableFilter []string `toml:\"table-filter\" json:\"table-filter\"`\n\tColumns     []string `toml:\"columns\" json:\"columns\"`\n}\n\nfunc (ic *IgnoreColumns) ColumnsMap() map[string]struct{} {\n\tcolumnMap := make(map[string]struct{}, len(ic.Columns))\n\tfor _, c := range ic.Columns {\n\t\tcolumnMap[c] = struct{}{}\n\t}\n\treturn columnMap\n}\n\n// GetIgnoreColumns gets Ignore config by schema name/regex and table name/regex.\nfunc (igCols AllIgnoreColumns) GetIgnoreColumns(db string, table string, caseSensitive bool) (*IgnoreColumns, error) {\n\tif !caseSensitive {\n\t\tdb = strings.ToLower(db)\n\t\ttable = strings.ToLower(table)\n\t}\n\tfor i, ig := range igCols {\n\t\tif ig.DB == db && ig.Table == table {\n\t\t\treturn igCols[i], nil\n\t\t}\n\t\tf, err := filter.Parse(ig.TableFilter)\n\t\tif err != nil {\n\t\t\treturn nil, common.ErrInvalidConfig.GenWithStack(\"invalid table filter %s in ignore columns\", strings.Join(ig.TableFilter, \",\"))\n\t\t}\n\t\tif f.MatchTable(db, table) {\n\t\t\treturn igCols[i], nil\n\t\t}\n\t}\n\treturn &IgnoreColumns{Columns: make([]string, 0)}, nil\n}\n\ntype FileRouteRule struct {\n\tPattern     string `json:\"pattern\" toml:\"pattern\" yaml:\"pattern\"`\n\tPath        string `json:\"path\" toml:\"path\" yaml:\"path\"`\n\tSchema      string `json:\"schema\" toml:\"schema\" yaml:\"schema\"`\n\tTable       string `json:\"table\" toml:\"table\" yaml:\"table\"`\n\tType        string `json:\"type\" toml:\"type\" yaml:\"type\"`\n\tKey         string `json:\"key\" toml:\"key\" yaml:\"key\"`\n\tCompression string `json:\"compression\" toml:\"compression\" yaml:\"compression\"`\n\t// unescape the schema/table name only used in lightning's internal logic now.\n\tUnescape bool `json:\"-\" toml:\"-\" yaml:\"-\"`\n\t// TODO: DataCharacterSet here can override the same field in [mydumper.csv] with a higher level.\n\t// This could provide users a more flexible usage to configure different files with\n\t// different data charsets.\n\t// DataCharacterSet string `toml:\"data-character-set\" json:\"data-character-set\"`\n}\n\ntype TikvImporter struct {\n\t// Deprecated: only used to keep the compatibility.\n\tAddr                string                       `toml:\"addr\" json:\"addr\"`\n\tBackend             string                       `toml:\"backend\" json:\"backend\"`\n\tOnDuplicate         string                       `toml:\"on-duplicate\" json:\"on-duplicate\"`\n\tMaxKVPairs          int                          `toml:\"max-kv-pairs\" json:\"max-kv-pairs\"`\n\tSendKVPairs         int                          `toml:\"send-kv-pairs\" json:\"send-kv-pairs\"`\n\tRegionSplitSize     ByteSize                     `toml:\"region-split-size\" json:\"region-split-size\"`\n\tRegionSplitKeys     int                          `toml:\"region-split-keys\" json:\"region-split-keys\"`\n\tSortedKVDir         string                       `toml:\"sorted-kv-dir\" json:\"sorted-kv-dir\"`\n\tDiskQuota           ByteSize                     `toml:\"disk-quota\" json:\"disk-quota\"`\n\tRangeConcurrency    int                          `toml:\"range-concurrency\" json:\"range-concurrency\"`\n\tDuplicateResolution DuplicateResolutionAlgorithm `toml:\"duplicate-resolution\" json:\"duplicate-resolution\"`\n\tIncrementalImport   bool                         `toml:\"incremental-import\" json:\"incremental-import\"`\n\n\tEngineMemCacheSize      ByteSize `toml:\"engine-mem-cache-size\" json:\"engine-mem-cache-size\"`\n\tLocalWriterMemCacheSize ByteSize `toml:\"local-writer-mem-cache-size\" json:\"local-writer-mem-cache-size\"`\n\tStoreWriteBWLimit       ByteSize `toml:\"store-write-bwlimit\" json:\"store-write-bwlimit\"`\n}\n\ntype Checkpoint struct {\n\tSchema           string                    `toml:\"schema\" json:\"schema\"`\n\tDSN              string                    `toml:\"dsn\" json:\"-\"` // DSN may contain password, don't expose this to JSON.\n\tMySQLParam       *common.MySQLConnectParam `toml:\"-\" json:\"-\"`   // For some security reason, we use MySQLParam instead of DSN.\n\tDriver           string                    `toml:\"driver\" json:\"driver\"`\n\tEnable           bool                      `toml:\"enable\" json:\"enable\"`\n\tKeepAfterSuccess CheckpointKeepStrategy    `toml:\"keep-after-success\" json:\"keep-after-success\"`\n}\n\ntype Cron struct {\n\tSwitchMode     Duration `toml:\"switch-mode\" json:\"switch-mode\"`\n\tLogProgress    Duration `toml:\"log-progress\" json:\"log-progress\"`\n\tCheckDiskQuota Duration `toml:\"check-disk-quota\" json:\"check-disk-quota\"`\n}\n\ntype Security struct {\n\tCAPath   string `toml:\"ca-path\" json:\"ca-path\"`\n\tCertPath string `toml:\"cert-path\" json:\"cert-path\"`\n\tKeyPath  string `toml:\"key-path\" json:\"key-path\"`\n\t// RedactInfoLog indicates that whether enabling redact log\n\tRedactInfoLog bool `toml:\"redact-info-log\" json:\"redact-info-log\"`\n\n\t// TLSConfigName is used to set tls config for lightning in DM, so we don't expose this field to user\n\t// DM may running many lightning instances at same time, so we need to set different tls config name for each lightning\n\tTLSConfigName string `toml:\"-\" json:\"-\"`\n\n\t// When DM/engine uses lightning as a library, it can directly pass in the content\n\tCABytes   []byte `toml:\"-\" json:\"-\"`\n\tCertBytes []byte `toml:\"-\" json:\"-\"`\n\tKeyBytes  []byte `toml:\"-\" json:\"-\"`\n}\n\n// RegisterMySQL registers the TLS config with name \"cluster\" or security.TLSConfigName\n// for use in `sql.Open()`. This method is goroutine-safe.\nfunc (sec *Security) RegisterMySQL() error {\n\tif sec == nil {\n\t\treturn nil\n\t}\n\n\ttlsConfig, err := util.NewTLSConfig(\n\t\tutil.WithCAPath(sec.CAPath),\n\t\tutil.WithCertAndKeyPath(sec.CertPath, sec.KeyPath),\n\t\tutil.WithCAContent(sec.CABytes),\n\t\tutil.WithCertAndKeyContent(sec.CertBytes, sec.KeyBytes),\n\t)\n\tif err != nil {\n\t\treturn errors.Trace(err)\n\t}\n\tif tlsConfig != nil {\n\t\t// error happens only when the key coincides with the built-in names.\n\t\t_ = gomysql.RegisterTLSConfig(sec.TLSConfigName, tlsConfig)\n\t}\n\treturn nil\n}\n\n// DeregisterMySQL deregisters the TLS config with security.TLSConfigName\nfunc (sec *Security) DeregisterMySQL() {\n\tif sec == nil || len(sec.CAPath) == 0 {\n\t\treturn\n\t}\n\tgomysql.DeregisterTLSConfig(sec.TLSConfigName)\n}\n\n// A duration which can be deserialized from a TOML string.\n// Implemented as https://github.com/BurntSushi/toml#using-the-encodingtextunmarshaler-interface\ntype Duration struct {\n\ttime.Duration\n}\n\nfunc (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn errors.Trace(err)\n}\n\nfunc (d Duration) MarshalText() ([]byte, error) {\n\treturn []byte(d.String()), nil\n}\n\nfunc (d *Duration) MarshalJSON() ([]byte, error) {\n\treturn []byte(fmt.Sprintf(`\"%s\"`, d.Duration)), nil\n}\n\n// Charset defines character set\ntype Charset int\n\nconst (\n\tBinary Charset = iota\n\tUTF8MB4\n\tGB18030\n\tGBK\n)\n\n// String return the string value of charset\nfunc (c Charset) String() string {\n\tswitch c {\n\tcase Binary:\n\t\treturn \"binary\"\n\tcase UTF8MB4:\n\t\treturn \"utf8mb4\"\n\tcase GB18030:\n\t\treturn \"gb18030\"\n\tcase GBK:\n\t\treturn \"gbk\"\n\tdefault:\n\t\treturn \"unknown_charset\"\n\t}\n}\n\n// ParseCharset parser character set for string\nfunc ParseCharset(dataCharacterSet string) (Charset, error) {\n\tswitch strings.ToLower(dataCharacterSet) {\n\tcase \"\", \"binary\":\n\t\treturn Binary, nil\n\tcase \"utf8mb4\":\n\t\treturn UTF8MB4, nil\n\tcase \"gb18030\":\n\t\treturn GB18030, nil\n\tcase \"gbk\":\n\t\treturn GBK, nil\n\tdefault:\n\t\treturn Binary, errors.Errorf(\"found unsupported data-character-set: %s\", dataCharacterSet)\n\t}\n}\n\nfunc NewConfig() *Config {\n\treturn &Config{\n\t\tApp: Lightning{\n\t\t\tRegionConcurrency: runtime.NumCPU(),\n\t\t\tTableConcurrency:  0,\n\t\t\tIndexConcurrency:  0,\n\t\t\tIOConcurrency:     5,\n\t\t\tCheckRequirements: true,\n\t\t\tMaxError: MaxError{\n\t\t\t\tCharset:  *atomic.NewInt64(math.MaxInt64),\n\t\t\t\tConflict: *atomic.NewInt64(math.MaxInt64),\n\t\t\t},\n\t\t\tTaskInfoSchemaName: defaultTaskInfoSchemaName,\n\t\t},\n\t\tCheckpoint: Checkpoint{\n\t\t\tEnable: true,\n\t\t},\n\t\tTiDB: DBStore{\n\t\t\tHost:                       \"127.0.0.1\",\n\t\t\tUser:                       \"root\",\n\t\t\tStatusPort:                 10080,\n\t\t\tStrSQLMode:                 \"ONLY_FULL_GROUP_BY,NO_AUTO_CREATE_USER\",\n\t\t\tMaxAllowedPacket:           defaultMaxAllowedPacket,\n\t\t\tBuildStatsConcurrency:      defaultBuildStatsConcurrency,\n\t\t\tDistSQLScanConcurrency:     defaultDistSQLScanConcurrency,\n\t\t\tIndexSerialScanConcurrency: defaultIndexSerialScanConcurrency,\n\t\t\tChecksumTableConcurrency:   defaultChecksumTableConcurrency,\n\t\t},\n\t\tCron: Cron{\n\t\t\tSwitchMode:     Duration{Duration: 5 * time.Minute},\n\t\t\tLogProgress:    Duration{Duration: 5 * time.Minute},\n\t\t\tCheckDiskQuota: Duration{Duration: 1 * time.Minute},\n\t\t},\n\t\tMydumper: MydumperRuntime{\n\t\t\tReadBlockSize: ReadBlockSize,\n\t\t\tCSV: CSVConfig{\n\t\t\t\tSeparator:       \",\",\n\t\t\t\tDelimiter:       `\"`,\n\t\t\t\tHeader:          true,\n\t\t\t\tNotNull:         false,\n\t\t\t\tNull:            `\\N`,\n\t\t\t\tBackslashEscape: true,\n\t\t\t\tTrimLastSep:     false,\n\t\t\t},", "is_vulnerable": 0}
{"code": "func typeFields(t reflect.Type) []field {\n\t// Anonymous fields to explore at the current level and the next.\n\tcurrent := []field{}\n\tnext := []field{{typ: t}}\n\n\t// Count of queued names for current level and the next.\n\tcount := map[reflect.Type]int{}\n\tnextCount := map[reflect.Type]int{}\n\n\t// Types already visited at an earlier level.\n\tvisited := map[reflect.Type]bool{}\n\n\t// Fields found.\n\tvar fields []field\n\n\tfor len(next) > 0 {\n\t\tcurrent, next = next, current[:0]\n\t\tcount, nextCount = nextCount, map[reflect.Type]int{}\n\n\t\tfor _, f := range current {\n\t\t\tif visited[f.typ] {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tvisited[f.typ] = true\n\n\t\t\t// Scan f.typ for fields to include.\n\t\t\tfor i := 0; i < f.typ.NumField(); i++ {\n\t\t\t\tsf := f.typ.Field(i)\n\t\t\t\tif sf.PkgPath != \"\" { // unexported\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\ttag := sf.Tag.Get(\"json\")\n\t\t\t\tif tag == \"-\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tname, opts := parseTag(tag)\n\t\t\t\tif !isValidTag(name) {\n\t\t\t\t\tname = \"\"\n\t\t\t\t}\n\t\t\t\tindex := make([]int, len(f.index)+1)\n\t\t\t\tcopy(index, f.index)\n\t\t\t\tindex[len(f.index)] = i\n\n\t\t\t\tft := sf.Type\n\t\t\t\tif ft.Name() == \"\" && ft.Kind() == reflect.Ptr {\n\t\t\t\t\t// Follow pointer.\n\t\t\t\t\tft = ft.Elem()\n\t\t\t\t}\n\n\t\t\t\t// Record found field and index sequence.\n\t\t\t\tif name != \"\" || !sf.Anonymous || ft.Kind() != reflect.Struct {\n\t\t\t\t\ttagged := name != \"\"\n\t\t\t\t\tif name == \"\" {\n\t\t\t\t\t\tname = sf.Name\n\t\t\t\t\t}\n\t\t\t\t\tfields = append(fields, fillField(field{\n\t\t\t\t\t\tname:      name,\n\t\t\t\t\t\ttag:       tagged,\n\t\t\t\t\t\tindex:     index,\n\t\t\t\t\t\ttyp:       ft,\n\t\t\t\t\t\tomitEmpty: opts.Contains(\"omitempty\"),\n\t\t\t\t\t\tquoted:    opts.Contains(\"string\"),\n\t\t\t\t\t}))\n\t\t\t\t\tif count[f.typ] > 1 {\n\t\t\t\t\t\t// If there were multiple instances, add a second,\n\t\t\t\t\t\t// so that the annihilation code will see a duplicate.\n\t\t\t\t\t\t// It only cares about the distinction between 1 or 2,\n\t\t\t\t\t\t// so don't bother generating any more copies.\n\t\t\t\t\t\tfields = append(fields, fields[len(fields)-1])\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Record new anonymous struct to explore in next round.\n\t\t\t\tnextCount[ft]++\n\t\t\t\tif nextCount[ft] == 1 {\n\t\t\t\t\tnext = append(next, fillField(field{name: ft.Name(), index: index, typ: ft}))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tsort.Sort(byName(fields))\n\n\t// Delete all fields that are hidden by the Go rules for embedded fields,\n\t// except that fields with JSON tags are promoted.\n\n\t// The fields are sorted in primary order of name, secondary order\n\t// of field index length. Loop over names; for each name, delete\n\t// hidden fields by choosing the one dominant field that survives.\n\tout := fields[:0]\n\tfor advance, i := 0, 0; i < len(fields); i += advance {\n\t\t// One iteration per name.\n\t\t// Find the sequence of fields with the name of this first field.\n\t\tfi := fields[i]\n\t\tname := fi.name\n\t\tfor advance = 1; i+advance < len(fields); advance++ {\n\t\t\tfj := fields[i+advance]\n\t\t\tif fj.name != name {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif advance == 1 { // Only one field with this name\n\t\t\tout = append(out, fi)\n\t\t\tcontinue\n\t\t}\n\t\tdominant, ok := dominantField(fields[i : i+advance])\n\t\tif ok {\n\t\t\tout = append(out, dominant)\n\t\t}\n\t}\n\n\tfields = out\n\tsort.Sort(byIndex(fields))\n\n\treturn fields\n}", "is_vulnerable": 1}
{"code": "func (a *Authorize) getMatchingPolicy(routeID uint64) *config.Policy {\n\toptions := a.currentOptions.Load()\n\n\tfor _, p := range options.GetAllPolicies() {\n\t\tid, _ := p.RouteID()\n\t\tif id == routeID {\n\t\t\treturn &p\n\t\t}\n\t}\n\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (c RuntimeConfig) UpstreamEnvoyID() string {\n\tu := c.Upstreams[c.ServiceName]\n\treturn u.EnvoyID\n}", "is_vulnerable": 0}
{"code": "func mountToRootfs(m *configs.Mount, rootfs, mountLabel string, enableCgroupns bool) error {\n\tvar (\n\t\tdest = m.Destination\n\t)\n\tif !strings.HasPrefix(dest, rootfs) {\n\t\tdest = filepath.Join(rootfs, dest)\n\t}\n\n\tswitch m.Device {\n\tcase \"proc\", \"sysfs\":\n\t\t// If the destination already exists and is not a directory, we bail\n\t\t// out This is to avoid mounting through a symlink or similar -- which\n\t\t// has been a \"fun\" attack scenario in the past.\n\t\t// TODO: This won't be necessary once we switch to libpathrs and we can\n\t\t//       stop all of these symlink-exchange attacks.\n\t\tif fi, err := os.Lstat(dest); err != nil {\n\t\t\tif !os.IsNotExist(err) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else if fi.Mode()&os.ModeDir == 0 {\n\t\t\treturn fmt.Errorf(\"filesystem %q must be mounted on ordinary directory\", m.Device)\n\t\t}\n\t\tif err := os.MkdirAll(dest, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Selinux kernels do not support labeling of /proc or /sys\n\t\treturn mountPropagate(m, rootfs, \"\")\n\tcase \"mqueue\":\n\t\tif err := os.MkdirAll(dest, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := mountPropagate(m, rootfs, mountLabel); err != nil {\n\t\t\t// older kernels do not support labeling of /dev/mqueue\n\t\t\tif err := mountPropagate(m, rootfs, \"\"); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn label.SetFileLabel(dest, mountLabel)\n\t\t}\n\t\treturn nil\n\tcase \"tmpfs\":\n\t\tcopyUp := m.Extensions&configs.EXT_COPYUP == configs.EXT_COPYUP\n\t\ttmpDir := \"\"\n\t\tstat, err := os.Stat(dest)\n\t\tif err != nil {\n\t\t\tif err := os.MkdirAll(dest, 0755); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif copyUp {\n\t\t\ttmpdir, err := prepareTmp(\"/tmp\")\n\t\t\tif err != nil {\n\t\t\t\treturn newSystemErrorWithCause(err, \"tmpcopyup: failed to setup tmpdir\")\n\t\t\t}\n\t\t\tdefer cleanupTmp(tmpdir)\n\t\t\ttmpDir, err = ioutil.TempDir(tmpdir, \"runctmpdir\")\n\t\t\tif err != nil {\n\t\t\t\treturn newSystemErrorWithCause(err, \"tmpcopyup: failed to create tmpdir\")\n\t\t\t}\n\t\t\tdefer os.RemoveAll(tmpDir)\n\t\t\tm.Destination = tmpDir\n\t\t}\n\t\tif err := mountPropagate(m, rootfs, mountLabel); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif copyUp {\n\t\t\tif err := fileutils.CopyDirectory(dest, tmpDir); err != nil {\n\t\t\t\terrMsg := fmt.Errorf(\"tmpcopyup: failed to copy %s to %s: %v\", dest, tmpDir, err)\n\t\t\t\tif err1 := unix.Unmount(tmpDir, unix.MNT_DETACH); err1 != nil {\n\t\t\t\t\treturn newSystemErrorWithCausef(err1, \"tmpcopyup: %v: failed to unmount\", errMsg)\n\t\t\t\t}\n\t\t\t\treturn errMsg\n\t\t\t}\n\t\t\tif err := unix.Mount(tmpDir, dest, \"\", unix.MS_MOVE, \"\"); err != nil {\n\t\t\t\terrMsg := fmt.Errorf(\"tmpcopyup: failed to move mount %s to %s: %v\", tmpDir, dest, err)\n\t\t\t\tif err1 := unix.Unmount(tmpDir, unix.MNT_DETACH); err1 != nil {\n\t\t\t\t\treturn newSystemErrorWithCausef(err1, \"tmpcopyup: %v: failed to unmount\", errMsg)\n\t\t\t\t}\n\t\t\t\treturn errMsg\n\t\t\t}\n\t\t}\n\t\tif stat != nil {\n\t\t\tif err = os.Chmod(dest, stat.Mode()); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\tcase \"bind\":\n\t\tif err := prepareBindMount(m, rootfs); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := mountPropagate(m, rootfs, mountLabel); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// bind mount won't change mount options, we need remount to make mount options effective.\n\t\t// first check that we have non-default options required before attempting a remount\n\t\tif m.Flags&^(unix.MS_REC|unix.MS_REMOUNT|unix.MS_BIND) != 0 {\n\t\t\t// only remount if unique mount options are set\n\t\t\tif err := remount(m, rootfs); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tif m.Relabel != \"\" {\n\t\t\tif err := label.Validate(m.Relabel); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tshared := label.IsShared(m.Relabel)\n\t\t\tif err := label.Relabel(m.Source, mountLabel, shared); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase \"cgroup\":\n\t\tif cgroups.IsCgroup2UnifiedMode() {\n\t\t\tif err := mountCgroupV2(m, rootfs, mountLabel, enableCgroupns); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\n\t\t\tif err := mountCgroupV1(m, rootfs, mountLabel, enableCgroupns); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif m.Flags&unix.MS_RDONLY != 0 {\n\t\t\t// remount cgroup root as readonly\n\t\t\tmcgrouproot := &configs.Mount{\n\t\t\t\tSource:      m.Destination,\n\t\t\t\tDevice:      \"bind\",\n\t\t\t\tDestination: m.Destination,\n\t\t\t\tFlags:       defaultMountFlags | unix.MS_RDONLY | unix.MS_BIND,\n\t\t\t}\n\t\t\tif err := remount(mcgrouproot, rootfs); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tdefault:\n\t\t// ensure that the destination of the mount is resolved of symlinks at mount time because\n\t\t// any previous mounts can invalidate the next mount's destination.\n\t\t// this can happen when a user specifies mounts within other mounts to cause breakouts or other\n\t\t// evil stuff to try to escape the container's rootfs.\n\t\tvar err error\n\t\tif dest, err = securejoin.SecureJoin(rootfs, m.Destination); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := checkProcMount(rootfs, dest, m.Source); err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// update the mount with the correct dest after symlinks are resolved.\n\t\tm.Destination = dest\n\t\tif err := os.MkdirAll(dest, 0755); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn mountPropagate(m, rootfs, mountLabel)\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func startsWithFilter(field string, value interface{}) Sqlizer {\n\treturn Like{field: fmt.Sprintf(\"%s%%\", value)}\n}", "is_vulnerable": 1}
{"code": "func removeIntentionPrecedence(rbacIxns []*rbacIntention, intentionDefaultAction intentionAction) []*rbacIntention {\n\t// Remove source precedence. After this completes precedence doesn't matter\n\t// between any two intentions.\n\trbacIxns = removeSourcePrecedence(rbacIxns, intentionDefaultAction)\n\n\tfor _, rbacIxn := range rbacIxns {\n\t\t// Remove permission precedence. After this completes precedence\n\t\t// doesn't matter between any two permissions on this intention.\n\t\trbacIxn.Permissions = removePermissionPrecedence(rbacIxn.Permissions, intentionDefaultAction)\n\t}\n\n\treturn rbacIxns\n}", "is_vulnerable": 1}
{"code": "func NewDeploymentListResultPage(getNextPage func(context.Context, DeploymentListResult) (DeploymentListResult, error)) DeploymentListResultPage {\n\treturn DeploymentListResultPage{fn: getNextPage}\n}", "is_vulnerable": 0}
{"code": "func (w *Workspace) TrustFoldersAndScan(ctx context.Context, foldersToBeTrusted []*Folder) {\n\tcurrentConfig := config.CurrentConfig()\n\ttrustedFolderPaths := currentConfig.TrustedFolders()\n\tfor _, f := range foldersToBeTrusted {\n\t\t// we need to append and set the trusted path to the config before the scan, as the scan is checking for trust\n\t\ttrustedFolderPaths = append(trustedFolderPaths, f.Path())\n\t\tcurrentConfig.SetTrustedFolders(trustedFolderPaths)\n\t\tgo f.ScanFolder(ctx)\n\t}\n\tnotification.Send(lsp.SnykTrustedFoldersParams{TrustedFolders: trustedFolderPaths})\n}", "is_vulnerable": 0}
{"code": "func (h *httpController) fileExplorerHandler(c *gin.Context) {\n\tvar req request.FileExplorerRequestForm\n\tif err := c.ShouldBind(&req); err != nil {\n\t\tc.String(http.StatusBadRequest, err.Error())\n\t\treturn\n\t}\n\tpath, err := utilities.DecodeBase64(req.Path)\n\tif err != nil {\n\t\tc.String(http.StatusBadRequest, err.Error())\n\t\treturn\n\t}\n\n\tctxWithTimeout, cancel := context.WithTimeout(c, 15*time.Second)\n\tdefer cancel()\n\n\tpayload, err := h.ClientService.SendCommand(ctxWithTimeout, services.SendCommandInput{\n\t\tMacAddress: req.Address,\n\t\tRequest:    fmt.Sprint(\"explore \", path),\n\t})\n\tif err != nil {\n\t\tc.HTML(http.StatusOK, \"explorer.html\", gin.H{\"error\": fmt.Sprintf(\"Error: %s\", err.Error())})\n\t\treturn\n\t}\n\n\tvar fileExplorer entities.FileExplorer\n\terr = json.Unmarshal(utilities.StringToByte(payload.Response), &fileExplorer)\n\tif err != nil {\n\t\tc.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()})\n\t\treturn\n\t}\n\tc.HTML(http.StatusOK, \"explorer.html\", gin.H{\n\t\t\"FileExplorer\": fileExplorer,\n\t})\n\treturn\n}", "is_vulnerable": 1}
{"code": "func TestStrategyLoginMissingExpiration(t *testing.T) {\n\t// Set some config values to a known state\n\trand.Seed(time.Now().UnixNano())\n\tcfg := config.NewConfig()\n\tcfg.Auth.Strategy = config.AuthStrategyLogin\n\tcfg.LoginToken.SigningKey = util.RandomString(10)\n\tcfg.Server.Credentials.Username = \"foo\"\n\tcfg.Server.Credentials.Passphrase = \"bar\"\n\tconfig.Set(cfg)\n\n\t// Let's create a valid token that does not expire.\n\tcustomClaims := config.IanaClaims{\n\t\tStandardClaims: jwt.StandardClaims{\n\t\t\tSubject: \"foo\",\n\t\t\t// ExpiresAt: timeExpire.Unix(),\n\t\t\tIssuer: config.AuthStrategyLoginIssuer,\n\t\t},\n\t}\n\n\ttoken, _ := config.GetSignedTokenString(customClaims)\n\n\t// Let's simulate a request\n\trequest := httptest.NewRequest(\"GET\", \"http://kiali/api/foo\", nil)\n\tcookie := http.Cookie{\n\t\tName:  config.TokenCookieName,\n\t\tValue: token,\n\t}\n\trequest.AddCookie(&cookie)\n\n\tauthenticationHandler, _ := NewAuthenticationHandler()\n\thandler := authenticationHandler.Handle(new(dummyHandler))\n\n\tresponseRecorder := httptest.NewRecorder()\n\thandler.ServeHTTP(responseRecorder, request)\n\tresponse := responseRecorder.Result()\n\n\t// Server should return an unauthorized response code.\n\t// Body should be the text explanation of the HTTP error\n\tbody, _ := ioutil.ReadAll(response.Body)\n\tassert.Equal(t, http.StatusUnauthorized, response.StatusCode)\n\tassert.Equal(t, fmt.Sprintln(http.StatusText(http.StatusUnauthorized)), string(body))\n}", "is_vulnerable": 0}
{"code": "\t\tconvey.Convey(\"Inactive route should return error\", func() {\n\t\t\twriter := &webhook.FakeHttpWriter{}\n\t\t\tgithubEventSource := &v1alpha1.GithubEventSource{\n\t\t\t\tWebhook: &v1alpha1.WebhookContext{\n\t\t\t\t\tEndpoint: \"/push\",\n\t\t\t\t\tURL:      \"http://webhook-gateway-svc\",\n\t\t\t\t\tPort:     \"12000\",\n\t\t\t\t},\n\t\t\t\tRepositories: []v1alpha1.OwnedRepositories{\n\t\t\t\t\t{\n\t\t\t\t\t\tOwner: \"fake\",\n\t\t\t\t\t\tNames: []string{\n\t\t\t\t\t\t\t\"fake0\", \"fake1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tEvents: []string{\n\t\t\t\t\t\"PushEvent\",\n\t\t\t\t},\n\t\t\t\tAPIToken: &corev1.SecretKeySelector{\n\t\t\t\t\tKey: \"accessKey\",\n\t\t\t\t\tLocalObjectReference: corev1.LocalObjectReference{\n\t\t\t\t\t\tName: \"github-access\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tbody, err := yaml.Marshal(githubEventSource)\n\t\t\tconvey.So(err, convey.ShouldBeNil)\n\n\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t})\n\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\n\t\t\tconvey.Convey(\"Active route should return success\", func() {\n\t\t\t\troute.Active = true\n\n\t\t\t\trouter.HandleRoute(writer, &http.Request{\n\t\t\t\t\tBody: ioutil.NopCloser(bytes.NewReader(body)),\n\t\t\t\t})\n\n\t\t\t\tconvey.So(writer.HeaderStatus, convey.ShouldEqual, http.StatusBadRequest)\n\t\t\t})\n\t\t})", "is_vulnerable": 1}
{"code": "func (p Precompile) Redelegations(\n\tctx sdk.Context,\n\tmethod *abi.Method,\n\t_ *vm.Contract,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewRedelegationsRequest(method, args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: &p.stakingKeeper}\n\n\tres, err := queryServer.Redelegations(ctx, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tout := new(RedelegationsOutput).FromResponse(res)\n\n\treturn out.Pack(method.Outputs)\n}", "is_vulnerable": 1}
{"code": "func NewEvent(s subtype, opt ...Option) (*auditEvent, error) {\n\tconst op = \"audit.newEvent\"\n\n\t// Get the default options\n\topts, err := getOpts(opt...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: error applying options: %w\", op, err)\n\t}\n\n\tif opts.withID == \"\" {\n\t\tvar err error\n\n\t\topts.withID, err = event.NewID(string(event.AuditType))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%s: error creating ID for event: %w\", op, err)\n\t\t}\n\t}\n\n\taudit := &auditEvent{\n\t\tID:        opts.withID,\n\t\tTimestamp: opts.withNow,\n\t\tVersion:   version,\n\t\tSubtype:   s,\n\t}\n\n\tif err := audit.validate(); err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: %w\", op, err)\n\t}\n\treturn audit, nil\n}", "is_vulnerable": 1}
{"code": "\t\tfunc(argoDB db.ArgoDB, appInformer cache.SharedIndexInformer, settingsMgr *settings.SettingsManager, server *metrics.MetricsServer) statecache.LiveStateCache {\n\t\t\treturn &liveStateCache\n\t\t},\n\t\tnormalizers.IgnoreNormalizerOpts{},\n\t)\n\n\tif !assert.NoError(t, err) {\n\t\treturn\n\t}\n\n\tassert.Equal(t, result[0].Health.Status, health.HealthStatusMissing)\n\tassert.Equal(t, result[0].Sync.Status, v1alpha1.SyncStatusCodeOutOfSync)\n}", "is_vulnerable": 0}
{"code": "func (m *B) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: B: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: B: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field C\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.C == nil {\n\t\t\t\tm.C = &C{}\n\t\t\t}\n\t\t\tif err := m.C.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 2:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field D\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.D == nil {\n\t\t\t\tm.D = &D{}\n\t\t\t}\n\t\t\tif err := m.D.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field F\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognized\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.F == nil {\n\t\t\t\tm.F = &OldC{}\n\t\t\t}\n\t\t\tif err := m.F.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognized(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognized\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func bitField(nd data.UnixFSData) (bitfield.Bitfield, error) {\n\tfanout := int(nd.FieldFanout().Must().Int())\n\tif fanout > maximumHamtWidth {\n\t\treturn nil, fmt.Errorf(\"hamt witdh (%d) exceed maximum allowed (%d)\", fanout, maximumHamtWidth)\n\t}\n\tbf := bitfield.NewBitfield(fanout)\n\tbf.SetBytes(nd.FieldData().Must().Bytes())\n\treturn bf, nil\n}", "is_vulnerable": 0}
{"code": "func newBearerTokenAuth(cfg *Config, logger *zap.Logger) *BearerTokenAuth {\n\tif cfg.Filename != \"\" && cfg.BearerToken != \"\" {\n\t\tlogger.Warn(\"a filename is specified. Configured token is ignored!\")\n\t}\n\ta := &BearerTokenAuth{\n\t\tscheme:   cfg.Scheme,\n\t\tfilename: cfg.Filename,\n\t\tlogger:   logger,\n\t}\n\ta.setAuthorizationValue(string(cfg.BearerToken))\n\treturn a\n}", "is_vulnerable": 0}
{"code": "func RunNucleiBareArgsAndGetResults(debug bool, extra ...string) ([]string, error) {\n\tcmd := exec.Command(\"./nuclei\")\n\textra = append(extra, ExtraDebugArgs...)\n\tcmd.Args = append(cmd.Args, extra...)\n\tcmd.Args = append(cmd.Args, \"-duc\") // disable auto updates\n\tcmd.Args = append(cmd.Args, \"-interactions-poll-duration\", \"1\")\n\tcmd.Args = append(cmd.Args, \"-interactions-cooldown-period\", \"10\")\n\tcmd.Args = append(cmd.Args, \"-allow-local-file-access\")\n\tif debug {\n\t\tcmd.Args = append(cmd.Args, \"-debug\")\n\t\tcmd.Stderr = os.Stderr\n\t\tfmt.Println(cmd.String())\n\t} else {\n\t\tcmd.Args = append(cmd.Args, \"-silent\")\n\t}\n\tdata, err := cmd.Output()\n\tif debug {\n\t\tfmt.Println(string(data))\n\t}\n\tif len(data) < 1 && err != nil {\n\t\treturn nil, fmt.Errorf(\"%v: %v\", err.Error(), string(data))\n\t}\n\tvar parts []string\n\titems := strings.Split(string(data), \"\\n\")\n\tfor _, i := range items {\n\t\tif i != \"\" {\n\t\t\tparts = append(parts, i)\n\t\t}\n\t}\n\treturn parts, nil\n}", "is_vulnerable": 0}
{"code": "func TestImportsValidation(t *testing.T) {\n\tak := createAccountNKey(t)\n\takp := publicKey(ak, t)\n\ti := &Import{Subject: \"foo\", Account: akp, To: \"bar\", Type: Stream}\n\ti2 := &Import{Subject: \"foo.*\", Account: akp, To: \"bar\", Type: Service}\n\n\timports := &Imports{}\n\timports.Add(i, i2)\n\n\tvr := CreateValidationResults()\n\timports.Validate(\"\", vr)\n\n\tif len(vr.Issues) != 3 {\n\t\tt.Errorf(\"imports without token or url should warn the caller x2, wildcard service as well\")\n\t}\n\n\tif !vr.IsBlocking(true) {\n\t\tt.Errorf(\"expected service import with a wildcard subject to be a blocking error\")\n\t}\n}", "is_vulnerable": 1}
{"code": "func (h *apiHandler) broadcastBuildResult(result BuildResult, newSummary buildSummary) {\n\th.mutex.Lock()\n\n\tvar added []string\n\tvar removed []string\n\tvar updated []string\n\n\turlForPath := func(absPath string) (string, bool) {\n\t\tif relPath, ok := h.fs.Rel(h.servedir, absPath); ok {\n\t\t\tpublicPath := h.publicPath\n\t\t\tslash := \"/\"\n\t\t\tif publicPath != \"\" && strings.HasSuffix(h.publicPath, \"/\") {\n\t\t\t\tslash = \"\"\n\t\t\t}\n\t\t\treturn fmt.Sprintf(\"%s%s%s\", publicPath, slash, strings.ReplaceAll(relPath, \"\\\\\", \"/\")), true\n\t\t}\n\t\treturn \"\", false\n\t}\n\n\t// Diff the old and new states, but only if the build succeeded. We shouldn't\n\t// make it appear as if all files were removed when there is a build error.\n\tif len(result.Errors) == 0 {\n\t\toldSummary := h.buildSummary\n\t\th.buildSummary = newSummary\n\n\t\tfor absPath, newHash := range newSummary {\n\t\t\tif oldHash, ok := oldSummary[absPath]; !ok {\n\t\t\t\tif url, ok := urlForPath(absPath); ok {\n\t\t\t\t\tadded = append(added, url)\n\t\t\t\t}\n\t\t\t} else if newHash != oldHash {\n\t\t\t\tif url, ok := urlForPath(absPath); ok {\n\t\t\t\t\tupdated = append(updated, url)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor absPath := range oldSummary {\n\t\t\tif _, ok := newSummary[absPath]; !ok {\n\t\t\t\tif url, ok := urlForPath(absPath); ok {\n\t\t\t\t\tremoved = append(removed, url)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Only notify listeners if there's a change that's worth sending. That way\n\t// you can implement a simple \"reload on any change\" script without having\n\t// to do this check in the script.\n\tif len(added) > 0 || len(removed) > 0 || len(updated) > 0 {\n\t\tsort.Strings(added)\n\t\tsort.Strings(removed)\n\t\tsort.Strings(updated)\n\n\t\t// Assemble the diff\n\t\tvar sb strings.Builder\n\t\tsb.WriteString(\"{\\\"added\\\":[\")\n\t\tfor i, path := range added {\n\t\t\tif i > 0 {\n\t\t\t\tsb.WriteRune(',')\n\t\t\t}\n\t\t\tsb.Write(helpers.QuoteForJSON(path, false))\n\t\t}\n\t\tsb.WriteString(\"],\\\"removed\\\":[\")\n\t\tfor i, path := range removed {\n\t\t\tif i > 0 {\n\t\t\t\tsb.WriteRune(',')\n\t\t\t}\n\t\t\tsb.Write(helpers.QuoteForJSON(path, false))\n\t\t}\n\t\tsb.WriteString(\"],\\\"updated\\\":[\")\n\t\tfor i, path := range updated {\n\t\t\tif i > 0 {\n\t\t\t\tsb.WriteRune(',')\n\t\t\t}\n\t\t\tsb.Write(helpers.QuoteForJSON(path, false))\n\t\t}\n\t\tsb.WriteString(\"]}\")\n\t\tjson := sb.String()\n\n\t\t// Broadcast the diff to all streams\n\t\tfor _, stream := range h.activeStreams {\n\t\t\tstream <- serverSentEvent{event: \"change\", data: json}\n\t\t}\n\t}\n\n\th.mutex.Unlock()\n}", "is_vulnerable": 0}
{"code": "func TestIterativeStateSyncBatched(t *testing.T)    { testIterativeStateSync(t, 100) }", "is_vulnerable": 1}
{"code": "func (p Precompile) Validator(\n\tctx sdk.Context,\n\tmethod *abi.Method,\n\t_ *vm.Contract,\n\targs []interface{},\n) ([]byte, error) {\n\treq, err := NewValidatorRequest(args)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryServer := stakingkeeper.Querier{Keeper: &p.stakingKeeper}\n\n\tres, err := queryServer.Validator(sdk.WrapSDKContext(ctx), req)\n\tif err != nil {\n\t\t// return empty validator info if the validator is not found\n\t\texpError := fmt.Sprintf(\"validator %s not found\", req.ValidatorAddr)\n\t\tif strings.Contains(err.Error(), expError) {\n\t\t\treturn method.Outputs.Pack(DefaultValidatorOutput().Validator)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tout := new(ValidatorOutput).FromResponse(res)\n\n\treturn method.Outputs.Pack(out.Validator)\n}", "is_vulnerable": 1}
{"code": "func newApiServerClusterRoleBinding(namespace string) *rbacv1.ClusterRoleBinding {\n\treturn &rbacv1.ClusterRoleBinding{\n\t\tTypeMeta: metav1.TypeMeta{\n\t\t\tAPIVersion: VersionNamev1,\n\t\t\tKind:       \"ClusterRoleBinding\",\n\t\t},\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName: components.ApiServiceAccountName,\n\t\t\tLabels: map[string]string{\n\t\t\t\tvirtv1.AppLabel: \"\",\n\t\t\t},\n\t\t},\n\t\tRoleRef: rbacv1.RoleRef{\n\t\t\tAPIGroup: VersionName,\n\t\t\tKind:     \"ClusterRole\",\n\t\t\tName:     components.ApiServiceAccountName,\n\t\t},\n\t\tSubjects: []rbacv1.Subject{\n\t\t\t{\n\t\t\t\tKind:      \"ServiceAccount\",\n\t\t\t\tNamespace: namespace,\n\t\t\t\tName:      components.ApiServiceAccountName,\n\t\t\t},\n\t\t},\n\t}\n}", "is_vulnerable": 0}
{"code": "func (r *userRepository) Count(options ...rest.QueryOptions) (int64, error) {\n\tusr := loggedUser(r.ctx)\n\tif !usr.IsAdmin {\n\t\treturn 0, rest.ErrPermissionDenied\n\t}\n\treturn r.CountAll(r.parseRestOptions(options...))\n}", "is_vulnerable": 1}
{"code": "func (mr *MockAuthorizeRequesterMockRecorder) GetRedirectURI() *gomock.Call {\n\tmr.mock.ctrl.T.Helper()\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetRedirectURI\", reflect.TypeOf((*MockAuthorizeRequester)(nil).GetRedirectURI))\n}", "is_vulnerable": 0}
{"code": "func TestEscapeJSONString(t *testing.T) {\n\tfor _, str := range []string{\"\", \"foobar\", `foo\"bar`, `foo\\bar`, \"foo\\n\\tbar\"} {\n\t\tescaped := EscapeJSONString(str)\n\t\tvar unmarshaled string\n\t\terr := json.Unmarshal([]byte(`\"`+escaped+`\"`), &unmarshaled)\n\t\trequire.NoError(t, err, str)\n\t\tassert.Equal(t, str, unmarshaled, str)\n\t}\n}", "is_vulnerable": 0}
{"code": "func (m *Foo) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowProto\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: Foo: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Bar\", wireType)\n\t\t\t}\n\t\t\tvar byteLen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowProto\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tbyteLen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif byteLen < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tpostIndex := iNdEx + byteLen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.Bar = append(m.Bar[:0], dAtA[iNdEx:postIndex]...)\n\t\t\tif m.Bar == nil {\n\t\t\t\tm.Bar = []byte{}\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipProto(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif (skippy < 0) || (iNdEx+skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthProto\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (cvss20 *CVSS20) Set(abv string, value string) error {\n\tswitch abv {\n\t// Base\n\tcase \"AV\":\n\t\tif err := validate(value, []string{\"L\", \"A\", \"N\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.AccessVector = value\n\tcase \"AC\":\n\t\tif err := validate(value, []string{\"H\", \"M\", \"L\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.AccessComplexity = value\n\tcase \"Au\":\n\t\tif err := validate(value, []string{\"M\", \"S\", \"N\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.Authentication = value\n\tcase \"C\":\n\t\tif err := validate(value, []string{\"N\", \"P\", \"C\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.ConfidentialityImpact = value\n\tcase \"I\":\n\t\tif err := validate(value, []string{\"N\", \"P\", \"C\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.IntegrityImpact = value\n\tcase \"A\":\n\t\tif err := validate(value, []string{\"N\", \"P\", \"C\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.AvailabilityImpact = value\n\t// Temporal\n\tcase \"E\":\n\t\tif err := validate(value, []string{\"U\", \"POC\", \"F\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.Exploitability = value\n\tcase \"RL\":\n\t\tif err := validate(value, []string{\"OF\", \"TF\", \"W\", \"U\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.RemediationLevel = value\n\tcase \"RC\":\n\t\tif err := validate(value, []string{\"UC\", \"UR\", \"C\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.ReportConfidence = value\n\t// Environmental\n\tcase \"CDP\":\n\t\tif err := validate(value, []string{\"N\", \"L\", \"LM\", \"MH\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.CollateralDamagePotential = value\n\tcase \"TD\":\n\t\tif err := validate(value, []string{\"N\", \"L\", \"M\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.TargetDistribution = value\n\tcase \"CR\":\n\t\tif err := validate(value, []string{\"L\", \"M\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.ConfidentialityRequirement = value\n\tcase \"IR\":\n\t\tif err := validate(value, []string{\"L\", \"M\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.IntegrityRequirement = value\n\tcase \"AR\":\n\t\tif err := validate(value, []string{\"L\", \"M\", \"H\", \"ND\"}); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcvss20.AvailabilityRequirement = value\n\tdefault:\n\t\treturn &ErrInvalidMetric{Abv: abv}\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func (fwfs readWriteFSImpl) OpenAppendable(name string) (WritableFile, error) {\n\tif err := os.MkdirAll(filepath.Dir(name), os.ModePerm); err != nil {\n\t\treturn nil, err\n\t}\n\tfile, err := os.OpenFile(name, os.O_CREATE|os.O_RDWR, 0644)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t_, err = file.Seek(0, os.SEEK_END)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn file, nil\n}", "is_vulnerable": 0}
{"code": "func (k *Key) CanSign() bool {\n\treturn C.key_can_sign(k.k) != 0\n}", "is_vulnerable": 1}
{"code": "func TestHubStopWithMultipleConnections(t *testing.T) {\n\tth := Setup(t).InitBasic()\n\tdefer th.TearDown()\n\n\ts := httptest.NewServer(dummyWebsocketHandler(t))\n\tdefer s.Close()\n\n\tsession, err := th.Service.CreateSession(&model.Session{\n\t\tUserId: th.BasicUser.Id,\n\t})\n\trequire.NoError(t, err)\n\n\tth.Service.Start()\n\twc1 := registerDummyWebConn(t, th, s.Listener.Addr(), session)\n\twc2 := registerDummyWebConn(t, th, s.Listener.Addr(), session)\n\twc3 := registerDummyWebConn(t, th, s.Listener.Addr(), session)\n\tdefer wc1.Close()\n\tdefer wc2.Close()\n\tdefer wc3.Close()\n}", "is_vulnerable": 1}
{"code": "func (c *criService) containerSpec(\n\tid string,\n\tsandboxID string,\n\tsandboxPid uint32,\n\tnetNSPath string,\n\tcontainerName string,\n\timageName string,\n\tconfig *runtime.ContainerConfig,\n\tsandboxConfig *runtime.PodSandboxConfig,\n\timageConfig *imagespec.ImageConfig,\n\textraMounts []*runtime.Mount,\n\tociRuntime config.Runtime,\n) (_ *runtimespec.Spec, retErr error) {\n\tspecOpts := []oci.SpecOpts{\n\t\toci.WithoutRunMount,\n\t}\n\t// only clear the default security settings if the runtime does not have a custom\n\t// base runtime spec spec.  Admins can use this functionality to define\n\t// default ulimits, seccomp, or other default settings.\n\tif ociRuntime.BaseRuntimeSpec == \"\" {\n\t\tspecOpts = append(specOpts, customopts.WithoutDefaultSecuritySettings)\n\t}\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithRelativeRoot(relativeRootfsPath),\n\t\tcustomopts.WithProcessArgs(config, imageConfig),\n\t\toci.WithDefaultPathEnv,\n\t\t// this will be set based on the security context below\n\t\toci.WithNewPrivileges,\n\t)\n\tif config.GetWorkingDir() != \"\" {\n\t\tspecOpts = append(specOpts, oci.WithProcessCwd(config.GetWorkingDir()))\n\t} else if imageConfig.WorkingDir != \"\" {\n\t\tspecOpts = append(specOpts, oci.WithProcessCwd(imageConfig.WorkingDir))\n\t}\n\n\tif config.GetTty() {\n\t\tspecOpts = append(specOpts, oci.WithTTY)\n\t}\n\n\t// Add HOSTNAME env.\n\tvar (\n\t\terr      error\n\t\thostname = sandboxConfig.GetHostname()\n\t)\n\tif hostname == \"\" {\n\t\tif hostname, err = c.os.Hostname(); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tspecOpts = append(specOpts, oci.WithEnv([]string{hostnameEnv + \"=\" + hostname}))\n\n\t// Apply envs from image config first, so that envs from container config\n\t// can override them.\n\tenv := append([]string{}, imageConfig.Env...)\n\tfor _, e := range config.GetEnvs() {\n\t\tenv = append(env, e.GetKey()+\"=\"+e.GetValue())\n\t}\n\tspecOpts = append(specOpts, oci.WithEnv(env))\n\n\tsecurityContext := config.GetLinux().GetSecurityContext()\n\tlabelOptions, err := toLabel(securityContext.GetSelinuxOptions())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(labelOptions) == 0 {\n\t\t// Use pod level SELinux config\n\t\tif sandbox, err := c.sandboxStore.Get(sandboxID); err == nil {\n\t\t\tlabelOptions, err = selinux.DupSecOpt(sandbox.ProcessLabel)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t}\n\n\tprocessLabel, mountLabel, err := label.InitLabels(labelOptions)\n\tif err != nil {\n\t\treturn nil, errors.Wrapf(err, \"failed to init selinux options %+v\", securityContext.GetSelinuxOptions())\n\t}\n\tdefer func() {\n\t\tif retErr != nil {\n\t\t\t_ = label.ReleaseLabel(processLabel)\n\t\t}\n\t}()\n\n\tspecOpts = append(specOpts, customopts.WithMounts(c.os, config, extraMounts, mountLabel), customopts.WithRelabeledContainerMounts(mountLabel))\n\n\tif !c.config.DisableProcMount {\n\t\t// Change the default masked/readonly paths to empty slices\n\t\t// See https://github.com/containerd/containerd/issues/5029\n\t\t// TODO: Provide an option to set default paths to the ones in oci.populateDefaultUnixSpec()\n\t\tspecOpts = append(specOpts, oci.WithMaskedPaths([]string{}), oci.WithReadonlyPaths([]string{}))\n\n\t\t// Apply masked paths if specified.\n\t\t// If the container is privileged, this will be cleared later on.\n\t\tif maskedPaths := securityContext.GetMaskedPaths(); maskedPaths != nil {\n\t\t\tspecOpts = append(specOpts, oci.WithMaskedPaths(maskedPaths))\n\t\t}\n\n\t\t// Apply readonly paths if specified.\n\t\t// If the container is privileged, this will be cleared later on.\n\t\tif readonlyPaths := securityContext.GetReadonlyPaths(); readonlyPaths != nil {\n\t\t\tspecOpts = append(specOpts, oci.WithReadonlyPaths(readonlyPaths))\n\t\t}\n\t}\n\n\tspecOpts = append(specOpts, customopts.WithDevices(c.os, config),\n\t\tcustomopts.WithCapabilities(securityContext, c.allCaps))\n\n\tif securityContext.GetPrivileged() {\n\t\tif !sandboxConfig.GetLinux().GetSecurityContext().GetPrivileged() {\n\t\t\treturn nil, errors.New(\"no privileged container allowed in sandbox\")\n\t\t}\n\t\tspecOpts = append(specOpts, oci.WithPrivileged)\n\t\tif !ociRuntime.PrivilegedWithoutHostDevices {\n\t\t\tspecOpts = append(specOpts, oci.WithHostDevices, oci.WithAllDevicesAllowed)\n\t\t}\n\t}\n\n\t// Clear all ambient capabilities. The implication of non-root + caps\n\t// is not clearly defined in Kubernetes.\n\t// See https://github.com/kubernetes/kubernetes/issues/56374\n\t// Keep docker's behavior for now.\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithoutAmbientCaps,\n\t\tcustomopts.WithSelinuxLabels(processLabel, mountLabel),\n\t)\n\n\t// TODO: Figure out whether we should set no new privilege for sandbox container by default\n\tif securityContext.GetNoNewPrivs() {\n\t\tspecOpts = append(specOpts, oci.WithNoNewPrivileges)\n\t}\n\t// TODO(random-liu): [P1] Set selinux options (privileged or not).\n\tif securityContext.GetReadonlyRootfs() {\n\t\tspecOpts = append(specOpts, oci.WithRootFSReadonly())\n\t}\n\n\tif c.config.DisableCgroup {\n\t\tspecOpts = append(specOpts, customopts.WithDisabledCgroups)\n\t} else {\n\t\tspecOpts = append(specOpts, customopts.WithResources(config.GetLinux().GetResources(), c.config.TolerateMissingHugetlbController, c.config.DisableHugetlbController))\n\t\tif sandboxConfig.GetLinux().GetCgroupParent() != \"\" {\n\t\t\tcgroupsPath := getCgroupsPath(sandboxConfig.GetLinux().GetCgroupParent(), id)\n\t\t\tspecOpts = append(specOpts, oci.WithCgroup(cgroupsPath))\n\t\t}\n\t}\n\n\tsupplementalGroups := securityContext.GetSupplementalGroups()\n\n\tfor pKey, pValue := range getPassthroughAnnotations(sandboxConfig.Annotations,\n\t\tociRuntime.PodAnnotations) {\n\t\tspecOpts = append(specOpts, customopts.WithAnnotation(pKey, pValue))\n\t}\n\n\tfor pKey, pValue := range getPassthroughAnnotations(config.Annotations,\n\t\tociRuntime.ContainerAnnotations) {\n\t\tspecOpts = append(specOpts, customopts.WithAnnotation(pKey, pValue))\n\t}\n\n\t// Default target PID namespace is the sandbox PID.\n\ttargetPid := sandboxPid\n\t// If the container targets another container's PID namespace,\n\t// set targetPid to the PID of that container.\n\tnsOpts := securityContext.GetNamespaceOptions()\n\tif nsOpts.GetPid() == runtime.NamespaceMode_TARGET {\n\t\ttargetContainer, err := c.validateTargetContainer(sandboxID, nsOpts.TargetId)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrapf(err, \"invalid target container\")\n\t\t}\n\n\t\tstatus := targetContainer.Status.Get()\n\t\ttargetPid = status.Pid\n\t}\n\n\tspecOpts = append(specOpts,\n\t\tcustomopts.WithOOMScoreAdj(config, c.config.RestrictOOMScoreAdj),\n\t\tcustomopts.WithPodNamespaces(securityContext, sandboxPid, targetPid),\n\t\tcustomopts.WithSupplementalGroups(supplementalGroups),\n\t\tcustomopts.WithAnnotation(annotations.ContainerType, annotations.ContainerTypeContainer),\n\t\tcustomopts.WithAnnotation(annotations.SandboxID, sandboxID),\n\t\tcustomopts.WithAnnotation(annotations.SandboxNamespace, sandboxConfig.GetMetadata().GetNamespace()),\n\t\tcustomopts.WithAnnotation(annotations.SandboxName, sandboxConfig.GetMetadata().GetName()),\n\t\tcustomopts.WithAnnotation(annotations.ContainerName, containerName),\n\t\tcustomopts.WithAnnotation(annotations.ImageName, imageName),\n\t)\n\t// cgroupns is used for hiding /sys/fs/cgroup from containers.\n\t// For compatibility, cgroupns is not used when running in cgroup v1 mode or in privileged.\n\t// https://github.com/containers/libpod/issues/4363\n\t// https://github.com/kubernetes/enhancements/blob/0e409b47497e398b369c281074485c8de129694f/keps/sig-node/20191118-cgroups-v2.md#cgroup-namespace\n\tif cgroups.Mode() == cgroups.Unified && !securityContext.GetPrivileged() {\n\t\tspecOpts = append(specOpts, oci.WithLinuxNamespace(\n\t\t\truntimespec.LinuxNamespace{\n\t\t\t\tType: runtimespec.CgroupNamespace,\n\t\t\t}))\n\t}\n\treturn c.runtimeSpec(id, ociRuntime.BaseRuntimeSpec, specOpts...)\n}", "is_vulnerable": 1}
{"code": "func versionAndHelpAction(ctx *cli.Context) {\n\tif ctx.IsSet(\"version\") {\n\t\tconsole.Printf(\"%s version %s\\n\", ctx.App.Name, ReleaseTag)\n\t\tconsole.Printf(\"commit: %s\\n\", CommitID)\n\t\tconsole.Printf(\"go version: %s\\n\", runtime.Version())\n\n\t\treturn\n\t}\n\n\tcli.ShowAppHelpAndExit(ctx, 1)\n}", "is_vulnerable": 0}
{"code": "func (m *MockCoreStrategy) AuthorizeCodeSignature(arg0 string) string {\n\tm.ctrl.T.Helper()\n\tret := m.ctrl.Call(m, \"AuthorizeCodeSignature\", arg0)\n\tret0, _ := ret[0].(string)\n\treturn ret0\n}", "is_vulnerable": 0}
{"code": "func (m *NewNoGroup) Unmarshal(dAtA []byte) error {\n\tl := len(dAtA)\n\tiNdEx := 0\n\tfor iNdEx < l {\n\t\tpreIndex := iNdEx\n\t\tvar wire uint64\n\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\tif shift >= 64 {\n\t\t\t\treturn ErrIntOverflowUnrecognizedgroup\n\t\t\t}\n\t\t\tif iNdEx >= l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tb := dAtA[iNdEx]\n\t\t\tiNdEx++\n\t\t\twire |= uint64(b&0x7F) << shift\n\t\t\tif b < 0x80 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tfieldNum := int32(wire >> 3)\n\t\twireType := int(wire & 0x7)\n\t\tif wireType == 4 {\n\t\t\treturn fmt.Errorf(\"proto: NewNoGroup: wiretype end group for non-group\")\n\t\t}\n\t\tif fieldNum <= 0 {\n\t\t\treturn fmt.Errorf(\"proto: NewNoGroup: illegal tag %d (wire type %d)\", fieldNum, wire)\n\t\t}\n\t\tswitch fieldNum {\n\t\tcase 1:\n\t\t\tif wireType != 0 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field1\", wireType)\n\t\t\t}\n\t\t\tvar v int64\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognizedgroup\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tv |= int64(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tm.Field1 = &v\n\t\tcase 3:\n\t\t\tif wireType == 1 {\n\t\t\t\tvar v uint64\n\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\tiNdEx += 8\n\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\tm.Field3 = append(m.Field3, v2)\n\t\t\t} else if wireType == 2 {\n\t\t\t\tvar packedLen int\n\t\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\t\tif shift >= 64 {\n\t\t\t\t\t\treturn ErrIntOverflowUnrecognizedgroup\n\t\t\t\t\t}\n\t\t\t\t\tif iNdEx >= l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\t\tiNdEx++\n\t\t\t\t\tpackedLen |= int(b&0x7F) << shift\n\t\t\t\t\tif b < 0x80 {\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif packedLen < 0 {\n\t\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t\t}\n\t\t\t\tpostIndex := iNdEx + packedLen\n\t\t\t\tif postIndex < 0 {\n\t\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t\t}\n\t\t\t\tif postIndex > l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tvar elementCount int\n\t\t\t\telementCount = packedLen / 8\n\t\t\t\tif elementCount != 0 && len(m.Field3) == 0 {\n\t\t\t\t\tm.Field3 = make([]float64, 0, elementCount)\n\t\t\t\t}\n\t\t\t\tfor iNdEx < postIndex {\n\t\t\t\t\tvar v uint64\n\t\t\t\t\tif (iNdEx + 8) > l {\n\t\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t\t}\n\t\t\t\t\tv = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))\n\t\t\t\t\tiNdEx += 8\n\t\t\t\t\tv2 := float64(math.Float64frombits(v))\n\t\t\t\t\tm.Field3 = append(m.Field3, v2)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field Field3\", wireType)\n\t\t\t}\n\t\tcase 5:\n\t\t\tif wireType != 2 {\n\t\t\t\treturn fmt.Errorf(\"proto: wrong wireType = %d for field A\", wireType)\n\t\t\t}\n\t\t\tvar msglen int\n\t\t\tfor shift := uint(0); ; shift += 7 {\n\t\t\t\tif shift >= 64 {\n\t\t\t\t\treturn ErrIntOverflowUnrecognizedgroup\n\t\t\t\t}\n\t\t\t\tif iNdEx >= l {\n\t\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t\t}\n\t\t\t\tb := dAtA[iNdEx]\n\t\t\t\tiNdEx++\n\t\t\t\tmsglen |= int(b&0x7F) << shift\n\t\t\t\tif b < 0x80 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif msglen < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t}\n\t\t\tpostIndex := iNdEx + msglen\n\t\t\tif postIndex < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t}\n\t\t\tif postIndex > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tif m.A == nil {\n\t\t\t\tm.A = &A{}\n\t\t\t}\n\t\t\tif err := m.A.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiNdEx = postIndex\n\t\tdefault:\n\t\t\tiNdEx = preIndex\n\t\t\tskippy, err := skipUnrecognizedgroup(dAtA[iNdEx:])\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif skippy < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t}\n\t\t\tif (iNdEx + skippy) < 0 {\n\t\t\t\treturn ErrInvalidLengthUnrecognizedgroup\n\t\t\t}\n\t\t\tif (iNdEx + skippy) > l {\n\t\t\t\treturn io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\tm.XXX_unrecognized = append(m.XXX_unrecognized, dAtA[iNdEx:iNdEx+skippy]...)\n\t\t\tiNdEx += skippy\n\t\t}\n\t}\n\n\tif iNdEx > l {\n\t\treturn io.ErrUnexpectedEOF\n\t}\n\treturn nil\n}", "is_vulnerable": 1}
{"code": "func NewParser(resolver resolver.Resolver) parser.IngressAnnotation {\n\treturn modSecurity{\n\t\tr:                resolver,\n\t\tannotationConfig: modsecurityAnnotation,\n\t}\n}", "is_vulnerable": 0}
{"code": "func buildDaemonlessImage(sc types.SystemContext, store storage.Store, isolation buildah.Isolation, contextDir string, optimization buildapiv1.ImageOptimizationPolicy, opts *docker.BuildImageOptions, blobCacheDirectory string) error {\n\tlog.V(2).Infof(\"Building...\")\n\n\targs := make(map[string]string)\n\tfor _, ev := range opts.BuildArgs {\n\t\targs[ev.Name] = ev.Value\n\t}\n\n\tpullPolicy := buildah.PullIfMissing\n\tif opts.Pull {\n\t\tlog.V(2).Infof(\"Forcing fresh pull of base image.\")\n\t\tpullPolicy = buildah.PullAlways\n\t}\n\n\tlayers := false\n\tswitch optimization {\n\tcase buildapiv1.ImageOptimizationSkipLayers, buildapiv1.ImageOptimizationSkipLayersAndWarn:\n\t\tlayers = false\n\tcase buildapiv1.ImageOptimizationNone:\n\t\tlayers = true\n\tdefault:\n\t\treturn fmt.Errorf(\"internal error: image optimization policy %q not fully implemented\", string(optimization))\n\t}\n\n\tsystemContext := sc\n\t// if credsDir, ok := os.LookupEnv(\"PULL_DOCKERCFG_PATH\"); ok {\n\t// \tsystemContext.AuthFilePath = filepath.Join(credsDir, \"config.json\")\n\t// }\n\tsystemContext.AuthFilePath = \"/tmp/config.json\"\n\n\tfor registry, ac := range opts.AuthConfigs.Configs {\n\t\tlog.V(5).Infof(\"Setting authentication for registry %q at %q.\", registry, ac.ServerAddress)\n\t\tif err := config.SetAuthentication(&systemContext, registry, ac.Username, ac.Password); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := config.SetAuthentication(&systemContext, ac.ServerAddress, ac.Username, ac.Password); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tvar transientMounts []string\n\tif st, err := os.Stat(\"/run/secrets\"); err == nil && st.IsDir() {\n\t\t// Add a bind of /run/secrets, to pass along anything that the\n\t\t// runtime mounted from the node into our /run/secrets.\n\t\ttransientMounts = append(transientMounts, \"/run/secrets:/run/secrets:ro,nodev,noexec,nosuid\")\n\t}\n\n\t// Use a profile provided in the image instead of the default provided\n\t// in runtime-tools's generator logic.\n\tseccompProfilePath := \"/usr/share/containers/seccomp.json\"\n\n\toptions := imagebuildah.BuildOptions{\n\t\tContextDirectory: contextDir,\n\t\tPullPolicy:       pullPolicy,\n\t\tIsolation:        isolation,\n\t\tTransientMounts:  transientMounts,\n\t\tArgs:             args,\n\t\tOutput:           opts.Name,\n\t\tOut:              opts.OutputStream,\n\t\tErr:              opts.OutputStream,\n\t\tReportWriter:     opts.OutputStream,\n\t\tOutputFormat:     buildah.Dockerv2ImageManifest,\n\t\tSystemContext:    &systemContext,\n\t\tNamespaceOptions: buildah.NamespaceOptions{\n\t\t\t{Name: string(specs.NetworkNamespace), Host: true},\n\t\t},\n\t\tCommonBuildOpts: &buildah.CommonBuildOptions{\n\t\t\tHTTPProxy:          true,\n\t\t\tMemory:             opts.Memory,\n\t\t\tMemorySwap:         opts.Memswap,\n\t\t\tCgroupParent:       opts.CgroupParent,\n\t\t\tUlimit:             daemonlessProcessLimits(),\n\t\t\tSeccompProfilePath: seccompProfilePath,\n\t\t},\n\t\tLayers:                  layers,\n\t\tNoCache:                 opts.NoCache,\n\t\tRemoveIntermediateCtrs:  opts.RmTmpContainer,\n\t\tForceRmIntermediateCtrs: true,\n\t\tBlobDirectory:           blobCacheDirectory,\n\t\tDropCapabilities:        dropCapabilities(),\n\t}\n\n\t_, _, err := imagebuildah.BuildDockerfiles(opts.Context, store, options, opts.Dockerfile)\n\treturn err\n}", "is_vulnerable": 1}
{"code": "func TestGitGetter_sshSCPStyle(t *testing.T) {\n\tif !testHasGit {\n\t\tt.Skip(\"git not found, skipping\")\n\t}\n\n\tctx := context.Background()\n\tdst := testing_helper.TempDir(t)\n\n\tencodedKey := base64.StdEncoding.EncodeToString([]byte(testGitToken))\n\n\t// avoid getting locked by a github authenticity validation prompt\n\tos.Setenv(\"GIT_SSH_COMMAND\", \"ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes\")\n\tdefer os.Setenv(\"GIT_SSH_COMMAND\", \"\")\n\n\t// This test exercises the combination of the git detector and the\n\t// git getter, to make sure that together they make scp-style URLs work.\n\treq := &Request{\n\t\tSrc: \"git@github.com:hashicorp/test-private-repo?sshkey=\" + encodedKey,\n\t\tDst: dst,\n\t\tPwd: \".\",\n\n\t\tGetMode: ModeDir,\n\t}\n\tgetter := &GitGetter{\n\t\tDetectors: []Detector{\n\t\t\tnew(GitDetector),\n\t\t\tnew(BitBucketDetector),\n\t\t\tnew(GitHubDetector),\n\t\t},\n\t}\n\tclient := &Client{\n\t\tGetters: []Getter{getter},\n\t}\n\n\tif _, err := client.Get(ctx, req); err != nil {\n\t\tt.Fatalf(\"client.Get failed: %s\", err)\n\t}\n\n\treadmePath := filepath.Join(dst, \"README.md\")\n\tif _, err := os.Stat(readmePath); err != nil {\n\t\tt.Fatalf(\"err: %s\", err)\n\t}\n}", "is_vulnerable": 0}
{"code": "func MkdirAllWithPathCheck(path string, perm os.FileMode) error {\n\tif dir, err := os.Lstat(path); err == nil {\n\t\t// If the path exists already,\n\t\t// 1. for Unix/Linux OS, check if the path is directory.\n\t\t// 2. for windows NTFS, check if the path is symlink instead of directory.\n\t\tif dir.IsDir() ||\n\t\t\t(runtime.GOOS == \"windows\" && (dir.Mode()&os.ModeSymlink != 0)) {\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"path %v exists but is not a directory\", path)\n\t}\n\t// If existence of path not known, attempt to create it.\n\tif err := MkdirAll(path, perm); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}", "is_vulnerable": 0}
{"code": "func (s *Syncer) cleanPath(batch ethdb.Batch, owner common.Hash, path []byte) {\n\tif owner == (common.Hash{}) && rawdb.ExistsAccountTrieNode(s.db, path) {\n\t\trawdb.DeleteAccountTrieNode(batch, path)\n\t\tdeletionGauge.Inc(1)\n\t}\n\tif owner != (common.Hash{}) && rawdb.ExistsStorageTrieNode(s.db, owner, path) {\n\t\trawdb.DeleteStorageTrieNode(batch, owner, path)\n\t\tdeletionGauge.Inc(1)\n\t}\n\tlookupGauge.Inc(1)\n}", "is_vulnerable": 1}
{"code": "func TestSanity(t *testing.T) {\n\tt.Run(\"sanity: Verify with single key\", func(t *testing.T) {\n\t\tkey, err := jwk.ParseKey([]byte(`{\n    \"kty\": \"oct\",\n    \"k\": \"AyM1SysPpbyDfgZld3umj1qzKObwVMkoqQ-EstJQLr_T-1qS0gZH75aKtMN3Yj0iPS4hcgUuTwjAzZr1Z9CAow\"\n  }`))\n\t\tif !assert.NoError(t, err, `jwk.ParseKey should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tpayload, err := jws.Verify([]byte(exampleCompactSerialization), jws.WithKey(jwa.HS256, key))\n\t\tif !assert.NoError(t, err, `jws.Verify should succeed`) {\n\t\t\treturn\n\t\t}\n\n\t\tif !assert.Equal(t, []byte(examplePayload), payload, `payloads should match`) {\n\t\t\treturn\n\t\t}\n\t})\n}", "is_vulnerable": 1}
